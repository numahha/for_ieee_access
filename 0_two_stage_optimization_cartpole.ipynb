{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early, cfg_penalty_lam_coef\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "penalty_lam_coef=cfg_penalty_lam_coef\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(1117.7324)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    \"penalty_lam_coef\" : penalty_lam_coef\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 473.03085  validloss 482.15948±0.00000  bestvalidloss 482.15948  last_update 0\n",
      "train: iter 1  trainloss 368.54796  validloss 342.76883±0.00000  bestvalidloss 342.76883  last_update 0\n",
      "train: iter 2  trainloss 312.46836  validloss 295.33724±0.00000  bestvalidloss 295.33724  last_update 0\n",
      "train: iter 3  trainloss 251.32427  validloss 253.47605±0.00000  bestvalidloss 253.47605  last_update 0\n",
      "train: iter 4  trainloss 268.88173  validloss 153.58544±0.00000  bestvalidloss 153.58544  last_update 0\n",
      "train: iter 5  trainloss 169.67809  validloss 161.46630±0.00000  bestvalidloss 153.58544  last_update 1\n",
      "train: iter 6  trainloss 68.87226  validloss 13.24253±0.00000  bestvalidloss 13.24253  last_update 0\n",
      "train: iter 7  trainloss -16.66788  validloss -54.49434±0.00000  bestvalidloss -54.49434  last_update 0\n",
      "train: iter 8  trainloss 83.44404  validloss -38.17530±0.00000  bestvalidloss -54.49434  last_update 1\n",
      "train: iter 9  trainloss -77.68646  validloss -160.47697±0.00000  bestvalidloss -160.47697  last_update 0\n",
      "train: iter 10  trainloss -90.34967  validloss -186.58043±0.00000  bestvalidloss -186.58043  last_update 0\n",
      "train: iter 11  trainloss -97.02884  validloss -233.32002±0.00000  bestvalidloss -233.32002  last_update 0\n",
      "train: iter 12  trainloss -116.03534  validloss -215.19029±0.00000  bestvalidloss -233.32002  last_update 1\n",
      "train: iter 13  trainloss -86.92762  validloss -234.63925±0.00000  bestvalidloss -234.63925  last_update 0\n",
      "train: iter 14  trainloss -136.48587  validloss -279.62737±0.00000  bestvalidloss -279.62737  last_update 0\n",
      "train: iter 15  trainloss -148.86688  validloss -267.83295±0.00000  bestvalidloss -279.62737  last_update 1\n",
      "train: iter 16  trainloss -125.54980  validloss -202.71349±0.00000  bestvalidloss -279.62737  last_update 2\n",
      "train: iter 17  trainloss -165.22343  validloss -208.43318±0.00000  bestvalidloss -279.62737  last_update 3\n",
      "train: iter 18  trainloss -189.05229  validloss -335.48961±0.00000  bestvalidloss -335.48961  last_update 0\n",
      "train: iter 19  trainloss -215.05702  validloss -299.40984±0.00000  bestvalidloss -335.48961  last_update 1\n",
      "train: iter 20  trainloss -224.36081  validloss -355.70250±0.00000  bestvalidloss -355.70250  last_update 0\n",
      "train: iter 21  trainloss -237.12359  validloss -367.02620±0.00000  bestvalidloss -367.02620  last_update 0\n",
      "train: iter 22  trainloss -112.11824  validloss -403.65255±0.00000  bestvalidloss -403.65255  last_update 0\n",
      "train: iter 23  trainloss -200.59404  validloss -138.65996±0.00000  bestvalidloss -403.65255  last_update 1\n",
      "train: iter 24  trainloss -259.05199  validloss -439.98293±0.00000  bestvalidloss -439.98293  last_update 0\n",
      "train: iter 25  trainloss -275.56249  validloss -445.14930±0.00000  bestvalidloss -445.14930  last_update 0\n",
      "train: iter 26  trainloss -259.60912  validloss -395.42255±0.00000  bestvalidloss -445.14930  last_update 1\n",
      "train: iter 27  trainloss -299.82118  validloss -442.37879±0.00000  bestvalidloss -445.14930  last_update 2\n",
      "train: iter 28  trainloss -264.03491  validloss -38.56877±0.00000  bestvalidloss -445.14930  last_update 3\n",
      "train: iter 29  trainloss -311.19742  validloss -482.68037±0.00000  bestvalidloss -482.68037  last_update 0\n",
      "train: iter 30  trainloss -363.32993  validloss -536.96716±0.00000  bestvalidloss -536.96716  last_update 0\n",
      "train: iter 31  trainloss -383.89774  validloss -510.91051±0.00000  bestvalidloss -536.96716  last_update 1\n",
      "train: iter 32  trainloss -410.98158  validloss -556.31555±0.00000  bestvalidloss -556.31555  last_update 0\n",
      "train: iter 33  trainloss -378.14135  validloss -591.97673±0.00000  bestvalidloss -591.97673  last_update 0\n",
      "train: iter 34  trainloss -404.39075  validloss -530.15750±0.00000  bestvalidloss -591.97673  last_update 1\n",
      "train: iter 35  trainloss -417.85306  validloss -611.03789±0.00000  bestvalidloss -611.03789  last_update 0\n",
      "train: iter 36  trainloss -434.51356  validloss -608.01040±0.00000  bestvalidloss -611.03789  last_update 1\n",
      "train: iter 37  trainloss -265.99748  validloss -600.93461±0.00000  bestvalidloss -611.03789  last_update 2\n",
      "train: iter 38  trainloss -395.95628  validloss -594.55839±0.00000  bestvalidloss -611.03789  last_update 3\n",
      "train: iter 39  trainloss -422.76478  validloss -587.63367±0.00000  bestvalidloss -611.03789  last_update 4\n",
      "train: iter 40  trainloss -447.00937  validloss -622.34063±0.00000  bestvalidloss -622.34063  last_update 0\n",
      "train: iter 41  trainloss -454.65357  validloss -620.41036±0.00000  bestvalidloss -622.34063  last_update 1\n",
      "train: iter 42  trainloss -459.45755  validloss -610.92939±0.00000  bestvalidloss -622.34063  last_update 2\n",
      "train: iter 43  trainloss -451.99811  validloss -604.53586±0.00000  bestvalidloss -622.34063  last_update 3\n",
      "train: iter 44  trainloss -468.22559  validloss -633.37879±0.00000  bestvalidloss -633.37879  last_update 0\n",
      "train: iter 45  trainloss -468.67312  validloss -586.50613±0.00000  bestvalidloss -633.37879  last_update 1\n",
      "train: iter 46  trainloss -465.97596  validloss -640.75686±0.00000  bestvalidloss -640.75686  last_update 0\n",
      "train: iter 47  trainloss -473.53657  validloss -657.82854±0.00000  bestvalidloss -657.82854  last_update 0\n",
      "train: iter 48  trainloss -474.60598  validloss -632.13691±0.00000  bestvalidloss -657.82854  last_update 1\n",
      "train: iter 49  trainloss -416.16499  validloss -612.95053±0.00000  bestvalidloss -657.82854  last_update 2\n",
      "train: iter 50  trainloss -490.64083  validloss -630.64479±0.00000  bestvalidloss -657.82854  last_update 3\n",
      "train: iter 51  trainloss -470.67609  validloss -648.21903±0.00000  bestvalidloss -657.82854  last_update 4\n",
      "train: iter 52  trainloss -484.62243  validloss -570.02104±0.00000  bestvalidloss -657.82854  last_update 5\n",
      "train: iter 53  trainloss -481.02888  validloss -661.27790±0.00000  bestvalidloss -661.27790  last_update 0\n",
      "train: iter 54  trainloss -441.33259  validloss -620.97081±0.00000  bestvalidloss -661.27790  last_update 1\n",
      "train: iter 55  trainloss -498.73346  validloss -656.15875±0.00000  bestvalidloss -661.27790  last_update 2\n",
      "train: iter 56  trainloss -473.46304  validloss -651.83826±0.00000  bestvalidloss -661.27790  last_update 3\n",
      "train: iter 57  trainloss -490.69633  validloss -659.09981±0.00000  bestvalidloss -661.27790  last_update 4\n",
      "train: iter 58  trainloss -501.66034  validloss -656.86829±0.00000  bestvalidloss -661.27790  last_update 5\n",
      "train: iter 59  trainloss -509.99872  validloss -621.28371±0.00000  bestvalidloss -661.27790  last_update 6\n",
      "train: iter 60  trainloss -519.13484  validloss -666.22635±0.00000  bestvalidloss -666.22635  last_update 0\n",
      "train: iter 61  trainloss -511.44462  validloss -685.30404±0.00000  bestvalidloss -685.30404  last_update 0\n",
      "train: iter 62  trainloss -522.70458  validloss -682.80386±0.00000  bestvalidloss -685.30404  last_update 1\n",
      "train: iter 63  trainloss -517.96834  validloss -690.99668±0.00000  bestvalidloss -690.99668  last_update 0\n",
      "train: iter 64  trainloss -522.88167  validloss -680.79549±0.00000  bestvalidloss -690.99668  last_update 1\n",
      "train: iter 65  trainloss -510.86577  validloss -682.77397±0.00000  bestvalidloss -690.99668  last_update 2\n",
      "train: iter 66  trainloss -508.08538  validloss -646.17701±0.00000  bestvalidloss -690.99668  last_update 3\n",
      "train: iter 67  trainloss -520.58881  validloss -509.99862±0.00000  bestvalidloss -690.99668  last_update 4\n",
      "train: iter 68  trainloss -540.85604  validloss -661.64641±0.00000  bestvalidloss -690.99668  last_update 5\n",
      "train: iter 69  trainloss -527.97568  validloss -696.86215±0.00000  bestvalidloss -696.86215  last_update 0\n",
      "train: iter 70  trainloss -531.74064  validloss -694.41156±0.00000  bestvalidloss -696.86215  last_update 1\n",
      "train: iter 71  trainloss -542.91198  validloss -694.98603±0.00000  bestvalidloss -696.86215  last_update 2\n",
      "train: iter 72  trainloss -535.43410  validloss -695.67535±0.00000  bestvalidloss -696.86215  last_update 3\n",
      "train: iter 73  trainloss -545.08866  validloss -686.76289±0.00000  bestvalidloss -696.86215  last_update 4\n",
      "train: iter 74  trainloss -546.11703  validloss -666.19891±0.00000  bestvalidloss -696.86215  last_update 5\n",
      "train: iter 75  trainloss -546.74668  validloss -693.16278±0.00000  bestvalidloss -696.86215  last_update 6\n",
      "train: iter 76  trainloss -544.23670  validloss -706.28720±0.00000  bestvalidloss -706.28720  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -541.54555  validloss -690.11627±0.00000  bestvalidloss -706.28720  last_update 1\n",
      "train: iter 78  trainloss -557.45675  validloss -695.08763±0.00000  bestvalidloss -706.28720  last_update 2\n",
      "train: iter 79  trainloss -545.91255  validloss -689.87110±0.00000  bestvalidloss -706.28720  last_update 3\n",
      "train: iter 80  trainloss -559.06912  validloss -662.43371±0.00000  bestvalidloss -706.28720  last_update 4\n",
      "train: iter 81  trainloss -539.58679  validloss -714.22335±0.00000  bestvalidloss -714.22335  last_update 0\n",
      "train: iter 82  trainloss -545.61093  validloss -720.54251±0.00000  bestvalidloss -720.54251  last_update 0\n",
      "train: iter 83  trainloss -561.53578  validloss -737.88671±0.00000  bestvalidloss -737.88671  last_update 0\n",
      "train: iter 84  trainloss -538.52105  validloss -729.05252±0.00000  bestvalidloss -737.88671  last_update 1\n",
      "train: iter 85  trainloss -511.18739  validloss -701.75181±0.00000  bestvalidloss -737.88671  last_update 2\n",
      "train: iter 86  trainloss -562.97466  validloss -712.34191±0.00000  bestvalidloss -737.88671  last_update 3\n",
      "train: iter 87  trainloss -571.48321  validloss -678.03887±0.00000  bestvalidloss -737.88671  last_update 4\n",
      "train: iter 88  trainloss -571.17913  validloss -711.28028±0.00000  bestvalidloss -737.88671  last_update 5\n",
      "train: iter 89  trainloss -568.31892  validloss -689.82005±0.00000  bestvalidloss -737.88671  last_update 6\n",
      "train: iter 90  trainloss -547.53641  validloss -715.02775±0.00000  bestvalidloss -737.88671  last_update 7\n",
      "train: iter 91  trainloss -573.03680  validloss -719.21723±0.00000  bestvalidloss -737.88671  last_update 8\n",
      "train: iter 92  trainloss -572.10798  validloss -744.43184±0.00000  bestvalidloss -744.43184  last_update 0\n",
      "train: iter 93  trainloss -547.26278  validloss -734.99517±0.00000  bestvalidloss -744.43184  last_update 1\n",
      "train: iter 94  trainloss -575.68721  validloss -726.06341±0.00000  bestvalidloss -744.43184  last_update 2\n",
      "train: iter 95  trainloss -567.20558  validloss -730.84714±0.00000  bestvalidloss -744.43184  last_update 3\n",
      "train: iter 96  trainloss -467.91332  validloss -745.91321±0.00000  bestvalidloss -745.91321  last_update 0\n",
      "train: iter 97  trainloss -580.28941  validloss -703.55087±0.00000  bestvalidloss -745.91321  last_update 1\n",
      "train: iter 98  trainloss -575.30830  validloss -720.55186±0.00000  bestvalidloss -745.91321  last_update 2\n",
      "train: iter 99  trainloss -576.19067  validloss -730.42447±0.00000  bestvalidloss -745.91321  last_update 3\n",
      "train: iter 100  trainloss -577.90530  validloss -747.68073±0.00000  bestvalidloss -747.68073  last_update 0\n",
      "train: iter 101  trainloss -586.25680  validloss -678.12344±0.00000  bestvalidloss -747.68073  last_update 1\n",
      "train: iter 102  trainloss -590.79257  validloss -759.57086±0.00000  bestvalidloss -759.57086  last_update 0\n",
      "train: iter 103  trainloss -597.57516  validloss -736.40832±0.00000  bestvalidloss -759.57086  last_update 1\n",
      "train: iter 104  trainloss -598.88437  validloss -758.75279±0.00000  bestvalidloss -759.57086  last_update 2\n",
      "train: iter 105  trainloss -591.92114  validloss -744.18447±0.00000  bestvalidloss -759.57086  last_update 3\n",
      "train: iter 106  trainloss -584.35652  validloss -736.23225±0.00000  bestvalidloss -759.57086  last_update 4\n",
      "train: iter 107  trainloss -602.66766  validloss -744.80732±0.00000  bestvalidloss -759.57086  last_update 5\n",
      "train: iter 108  trainloss -582.51291  validloss -745.60774±0.00000  bestvalidloss -759.57086  last_update 6\n",
      "train: iter 109  trainloss -593.56712  validloss -740.31215±0.00000  bestvalidloss -759.57086  last_update 7\n",
      "train: iter 110  trainloss -595.89583  validloss -746.52856±0.00000  bestvalidloss -759.57086  last_update 8\n",
      "train: iter 111  trainloss -594.78602  validloss -749.72908±0.00000  bestvalidloss -759.57086  last_update 9\n",
      "train: iter 112  trainloss -596.70652  validloss -754.25979±0.00000  bestvalidloss -759.57086  last_update 10\n",
      "train: iter 113  trainloss -583.27239  validloss -740.91762±0.00000  bestvalidloss -759.57086  last_update 11\n",
      "train: iter 114  trainloss -608.84397  validloss -758.93514±0.00000  bestvalidloss -759.57086  last_update 12\n",
      "train: iter 115  trainloss -604.10851  validloss -763.33789±0.00000  bestvalidloss -763.33789  last_update 0\n",
      "train: iter 116  trainloss -609.13626  validloss -759.23771±0.00000  bestvalidloss -763.33789  last_update 1\n",
      "train: iter 117  trainloss -588.40537  validloss -768.58568±0.00000  bestvalidloss -768.58568  last_update 0\n",
      "train: iter 118  trainloss -602.36826  validloss -767.68103±0.00000  bestvalidloss -768.58568  last_update 1\n",
      "train: iter 119  trainloss -609.26699  validloss -718.67312±0.00000  bestvalidloss -768.58568  last_update 2\n",
      "train: iter 120  trainloss -609.23267  validloss -788.18219±0.00000  bestvalidloss -788.18219  last_update 0\n",
      "train: iter 121  trainloss -599.50176  validloss -781.16433±0.00000  bestvalidloss -788.18219  last_update 1\n",
      "train: iter 122  trainloss -604.03262  validloss -712.91086±0.00000  bestvalidloss -788.18219  last_update 2\n",
      "train: iter 123  trainloss -616.16252  validloss -753.41562±0.00000  bestvalidloss -788.18219  last_update 3\n",
      "train: iter 124  trainloss -614.25710  validloss -757.29957±0.00000  bestvalidloss -788.18219  last_update 4\n",
      "train: iter 125  trainloss -618.66180  validloss -765.42197±0.00000  bestvalidloss -788.18219  last_update 5\n",
      "train: iter 126  trainloss -601.05242  validloss -777.60826±0.00000  bestvalidloss -788.18219  last_update 6\n",
      "train: iter 127  trainloss -615.03945  validloss -744.50071±0.00000  bestvalidloss -788.18219  last_update 7\n",
      "train: iter 128  trainloss -613.08881  validloss -782.66607±0.00000  bestvalidloss -788.18219  last_update 8\n",
      "train: iter 129  trainloss -617.20450  validloss -764.87621±0.00000  bestvalidloss -788.18219  last_update 9\n",
      "train: iter 130  trainloss -608.04590  validloss -797.90381±0.00000  bestvalidloss -797.90381  last_update 0\n",
      "train: iter 131  trainloss -588.23390  validloss -764.34628±0.00000  bestvalidloss -797.90381  last_update 1\n",
      "train: iter 132  trainloss -606.27597  validloss -735.70729±0.00000  bestvalidloss -797.90381  last_update 2\n",
      "train: iter 133  trainloss -599.01162  validloss -779.08521±0.00000  bestvalidloss -797.90381  last_update 3\n",
      "train: iter 134  trainloss -603.71585  validloss -714.11139±0.00000  bestvalidloss -797.90381  last_update 4\n",
      "train: iter 135  trainloss -623.52775  validloss -720.75085±0.00000  bestvalidloss -797.90381  last_update 5\n",
      "train: iter 136  trainloss -629.21920  validloss -777.68825±0.00000  bestvalidloss -797.90381  last_update 6\n",
      "train: iter 137  trainloss -621.40980  validloss -794.21491±0.00000  bestvalidloss -797.90381  last_update 7\n",
      "train: iter 138  trainloss -610.91946  validloss -777.42914±0.00000  bestvalidloss -797.90381  last_update 8\n",
      "train: iter 139  trainloss -620.82865  validloss -792.30291±0.00000  bestvalidloss -797.90381  last_update 9\n",
      "train: iter 140  trainloss -600.98658  validloss -792.21303±0.00000  bestvalidloss -797.90381  last_update 10\n",
      "train: iter 141  trainloss -631.03730  validloss -794.61823±0.00000  bestvalidloss -797.90381  last_update 11\n",
      "train: iter 142  trainloss -629.82960  validloss -791.91392±0.00000  bestvalidloss -797.90381  last_update 12\n",
      "train: iter 143  trainloss -620.89851  validloss -787.81245±0.00000  bestvalidloss -797.90381  last_update 13\n",
      "train: iter 144  trainloss -633.94192  validloss -804.93254±0.00000  bestvalidloss -804.93254  last_update 0\n",
      "train: iter 145  trainloss -632.70747  validloss -803.39024±0.00000  bestvalidloss -804.93254  last_update 1\n",
      "train: iter 146  trainloss -624.31739  validloss -791.32292±0.00000  bestvalidloss -804.93254  last_update 2\n",
      "train: iter 147  trainloss -612.86032  validloss -752.28909±0.00000  bestvalidloss -804.93254  last_update 3\n",
      "train: iter 148  trainloss -630.61717  validloss -777.11557±0.00000  bestvalidloss -804.93254  last_update 4\n",
      "train: iter 149  trainloss -617.49074  validloss -799.77249±0.00000  bestvalidloss -804.93254  last_update 5\n",
      "train: iter 150  trainloss -613.67735  validloss -798.11140±0.00000  bestvalidloss -804.93254  last_update 6\n",
      "train: iter 151  trainloss -614.29667  validloss -751.36016±0.00000  bestvalidloss -804.93254  last_update 7\n",
      "train: iter 152  trainloss -638.46023  validloss -795.57861±0.00000  bestvalidloss -804.93254  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -638.53735  validloss -808.09913±0.00000  bestvalidloss -808.09913  last_update 0\n",
      "train: iter 154  trainloss -621.22306  validloss -785.60795±0.00000  bestvalidloss -808.09913  last_update 1\n",
      "train: iter 155  trainloss -578.84125  validloss -802.64379±0.00000  bestvalidloss -808.09913  last_update 2\n",
      "train: iter 156  trainloss -613.28165  validloss -740.31841±0.00000  bestvalidloss -808.09913  last_update 3\n",
      "train: iter 157  trainloss -353.04687  validloss -752.50411±0.00000  bestvalidloss -808.09913  last_update 4\n",
      "train: iter 158  trainloss -474.56745  validloss -458.42727±0.00000  bestvalidloss -808.09913  last_update 5\n",
      "train: iter 159  trainloss -595.81296  validloss -726.05726±0.00000  bestvalidloss -808.09913  last_update 6\n",
      "train: iter 160  trainloss -617.49193  validloss -769.04681±0.00000  bestvalidloss -808.09913  last_update 7\n",
      "train: iter 161  trainloss -622.14757  validloss -792.89532±0.00000  bestvalidloss -808.09913  last_update 8\n",
      "train: iter 162  trainloss -637.69944  validloss -797.04867±0.00000  bestvalidloss -808.09913  last_update 9\n",
      "train: iter 163  trainloss -622.29344  validloss -782.18023±0.00000  bestvalidloss -808.09913  last_update 10\n",
      "train: iter 164  trainloss -631.73315  validloss -785.70439±0.00000  bestvalidloss -808.09913  last_update 11\n",
      "train: iter 165  trainloss -639.82038  validloss -802.33133±0.00000  bestvalidloss -808.09913  last_update 12\n",
      "train: iter 166  trainloss -630.02899  validloss -810.84576±0.00000  bestvalidloss -810.84576  last_update 0\n",
      "train: iter 167  trainloss -639.75421  validloss -783.13864±0.00000  bestvalidloss -810.84576  last_update 1\n",
      "train: iter 168  trainloss -631.56122  validloss -815.87277±0.00000  bestvalidloss -815.87277  last_update 0\n",
      "train: iter 169  trainloss -632.82259  validloss -791.78114±0.00000  bestvalidloss -815.87277  last_update 1\n",
      "train: iter 170  trainloss -645.53457  validloss -807.86827±0.00000  bestvalidloss -815.87277  last_update 2\n",
      "train: iter 171  trainloss -648.10823  validloss -809.97431±0.00000  bestvalidloss -815.87277  last_update 3\n",
      "train: iter 172  trainloss -640.95405  validloss -823.42149±0.00000  bestvalidloss -823.42149  last_update 0\n",
      "train: iter 173  trainloss -638.53922  validloss -809.09864±0.00000  bestvalidloss -823.42149  last_update 1\n",
      "train: iter 174  trainloss -631.84076  validloss -798.20335±0.00000  bestvalidloss -823.42149  last_update 2\n",
      "train: iter 175  trainloss -642.96937  validloss -814.45253±0.00000  bestvalidloss -823.42149  last_update 3\n",
      "train: iter 176  trainloss -641.00944  validloss -795.23003±0.00000  bestvalidloss -823.42149  last_update 4\n",
      "train: iter 177  trainloss -627.62092  validloss -798.71564±0.00000  bestvalidloss -823.42149  last_update 5\n",
      "train: iter 178  trainloss -652.24386  validloss -773.55809±0.00000  bestvalidloss -823.42149  last_update 6\n",
      "train: iter 179  trainloss -646.04408  validloss -831.52610±0.00000  bestvalidloss -831.52610  last_update 0\n",
      "train: iter 180  trainloss -651.43794  validloss -772.59686±0.00000  bestvalidloss -831.52610  last_update 1\n",
      "train: iter 181  trainloss -657.14348  validloss -831.39444±0.00000  bestvalidloss -831.52610  last_update 2\n",
      "train: iter 182  trainloss -643.25919  validloss -817.02704±0.00000  bestvalidloss -831.52610  last_update 3\n",
      "train: iter 183  trainloss -644.06373  validloss -821.20465±0.00000  bestvalidloss -831.52610  last_update 4\n",
      "train: iter 184  trainloss -629.05812  validloss -802.30506±0.00000  bestvalidloss -831.52610  last_update 5\n",
      "train: iter 185  trainloss -641.60584  validloss -734.42341±0.00000  bestvalidloss -831.52610  last_update 6\n",
      "train: iter 186  trainloss -645.60923  validloss -755.62195±0.00000  bestvalidloss -831.52610  last_update 7\n",
      "train: iter 187  trainloss -619.45140  validloss -782.06967±0.00000  bestvalidloss -831.52610  last_update 8\n",
      "train: iter 188  trainloss -648.72370  validloss -810.89721±0.00000  bestvalidloss -831.52610  last_update 9\n",
      "train: iter 189  trainloss -630.82090  validloss -825.16407±0.00000  bestvalidloss -831.52610  last_update 10\n",
      "train: iter 190  trainloss -654.60959  validloss -815.62012±0.00000  bestvalidloss -831.52610  last_update 11\n",
      "train: iter 191  trainloss -653.17142  validloss -805.19966±0.00000  bestvalidloss -831.52610  last_update 12\n",
      "train: iter 192  trainloss -641.75471  validloss -811.05080±0.00000  bestvalidloss -831.52610  last_update 13\n",
      "train: iter 193  trainloss -650.84259  validloss -826.12104±0.00000  bestvalidloss -831.52610  last_update 14\n",
      "train: iter 194  trainloss -659.88084  validloss -834.37746±0.00000  bestvalidloss -834.37746  last_update 0\n",
      "train: iter 195  trainloss -622.78016  validloss -838.63799±0.00000  bestvalidloss -838.63799  last_update 0\n",
      "train: iter 196  trainloss -612.38849  validloss -727.94013±0.00000  bestvalidloss -838.63799  last_update 1\n",
      "train: iter 197  trainloss -651.64812  validloss -741.61105±0.00000  bestvalidloss -838.63799  last_update 2\n",
      "train: iter 198  trainloss -642.37819  validloss -831.86745±0.00000  bestvalidloss -838.63799  last_update 3\n",
      "train: iter 199  trainloss -622.92878  validloss -835.51846±0.00000  bestvalidloss -838.63799  last_update 4\n",
      "train: iter 200  trainloss -645.68320  validloss -831.16683±0.00000  bestvalidloss -838.63799  last_update 5\n",
      "train: iter 201  trainloss -646.41492  validloss -831.68075±0.00000  bestvalidloss -838.63799  last_update 6\n",
      "train: iter 202  trainloss -647.14599  validloss -808.83017±0.00000  bestvalidloss -838.63799  last_update 7\n",
      "train: iter 203  trainloss -660.61780  validloss -840.76150±0.00000  bestvalidloss -840.76150  last_update 0\n",
      "train: iter 204  trainloss -643.45456  validloss -817.76900±0.00000  bestvalidloss -840.76150  last_update 1\n",
      "train: iter 205  trainloss -655.63682  validloss -808.82613±0.00000  bestvalidloss -840.76150  last_update 2\n",
      "train: iter 206  trainloss -665.44049  validloss -817.44424±0.00000  bestvalidloss -840.76150  last_update 3\n",
      "train: iter 207  trainloss -659.37725  validloss -775.68423±0.00000  bestvalidloss -840.76150  last_update 4\n",
      "train: iter 208  trainloss -662.88207  validloss -776.27670±0.00000  bestvalidloss -840.76150  last_update 5\n",
      "train: iter 209  trainloss -640.36988  validloss -835.20520±0.00000  bestvalidloss -840.76150  last_update 6\n",
      "train: iter 210  trainloss -660.45972  validloss -822.77220±0.00000  bestvalidloss -840.76150  last_update 7\n",
      "train: iter 211  trainloss -634.13561  validloss -664.67937±0.00000  bestvalidloss -840.76150  last_update 8\n",
      "train: iter 212  trainloss -651.08871  validloss -783.17530±0.00000  bestvalidloss -840.76150  last_update 9\n",
      "train: iter 213  trainloss -661.91861  validloss -758.44618±0.00000  bestvalidloss -840.76150  last_update 10\n",
      "train: iter 214  trainloss -631.70370  validloss -842.24915±0.00000  bestvalidloss -842.24915  last_update 0\n",
      "train: iter 215  trainloss -652.89247  validloss -788.62971±0.00000  bestvalidloss -842.24915  last_update 1\n",
      "train: iter 216  trainloss -619.16687  validloss -772.89105±0.00000  bestvalidloss -842.24915  last_update 2\n",
      "train: iter 217  trainloss -601.70565  validloss -769.58823±0.00000  bestvalidloss -842.24915  last_update 3\n",
      "train: iter 218  trainloss -663.47521  validloss -825.76967±0.00000  bestvalidloss -842.24915  last_update 4\n",
      "train: iter 219  trainloss -640.83895  validloss -832.92051±0.00000  bestvalidloss -842.24915  last_update 5\n",
      "train: iter 220  trainloss -650.55514  validloss -818.77341±0.00000  bestvalidloss -842.24915  last_update 6\n",
      "train: iter 221  trainloss -661.98651  validloss -827.80705±0.00000  bestvalidloss -842.24915  last_update 7\n",
      "train: iter 222  trainloss -636.26248  validloss -741.96269±0.00000  bestvalidloss -842.24915  last_update 8\n",
      "train: iter 223  trainloss -656.58107  validloss -771.99048±0.00000  bestvalidloss -842.24915  last_update 9\n",
      "train: iter 224  trainloss -665.63691  validloss -833.19145±0.00000  bestvalidloss -842.24915  last_update 10\n",
      "train: iter 225  trainloss -673.86148  validloss -804.76069±0.00000  bestvalidloss -842.24915  last_update 11\n",
      "train: iter 226  trainloss -657.22536  validloss -837.18210±0.00000  bestvalidloss -842.24915  last_update 12\n",
      "train: iter 227  trainloss -663.31500  validloss -828.57065±0.00000  bestvalidloss -842.24915  last_update 13\n",
      "train: iter 228  trainloss -662.83385  validloss -838.25762±0.00000  bestvalidloss -842.24915  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 229  trainloss -682.37187  validloss -828.58205±0.00000  bestvalidloss -842.24915  last_update 15\n",
      "train: iter 230  trainloss -640.66535  validloss -849.03770±0.00000  bestvalidloss -849.03770  last_update 0\n",
      "train: iter 231  trainloss -660.11351  validloss -804.69615±0.00000  bestvalidloss -849.03770  last_update 1\n",
      "train: iter 232  trainloss -652.73722  validloss -784.13101±0.00000  bestvalidloss -849.03770  last_update 2\n",
      "train: iter 233  trainloss -664.82121  validloss -790.59631±0.00000  bestvalidloss -849.03770  last_update 3\n",
      "train: iter 234  trainloss -669.64454  validloss -836.01167±0.00000  bestvalidloss -849.03770  last_update 4\n",
      "train: iter 235  trainloss -668.87608  validloss -827.95844±0.00000  bestvalidloss -849.03770  last_update 5\n",
      "train: iter 236  trainloss -642.90950  validloss -822.27744±0.00000  bestvalidloss -849.03770  last_update 6\n",
      "train: iter 237  trainloss -655.22975  validloss -704.81411±0.00000  bestvalidloss -849.03770  last_update 7\n",
      "train: iter 238  trainloss -671.83035  validloss -805.82054±0.00000  bestvalidloss -849.03770  last_update 8\n",
      "train: iter 239  trainloss -661.30538  validloss -863.96081±0.00000  bestvalidloss -863.96081  last_update 0\n",
      "train: iter 240  trainloss -663.67450  validloss -825.80927±0.00000  bestvalidloss -863.96081  last_update 1\n",
      "train: iter 241  trainloss -670.00000  validloss -809.21438±0.00000  bestvalidloss -863.96081  last_update 2\n",
      "train: iter 242  trainloss -655.85213  validloss -853.77798±0.00000  bestvalidloss -863.96081  last_update 3\n",
      "train: iter 243  trainloss -672.31062  validloss -832.49963±0.00000  bestvalidloss -863.96081  last_update 4\n",
      "train: iter 244  trainloss -674.19399  validloss -858.91549±0.00000  bestvalidloss -863.96081  last_update 5\n",
      "train: iter 245  trainloss -663.19887  validloss -765.40982±0.00000  bestvalidloss -863.96081  last_update 6\n",
      "train: iter 246  trainloss -667.05574  validloss -837.45420±0.00000  bestvalidloss -863.96081  last_update 7\n",
      "train: iter 247  trainloss -653.07824  validloss -840.14701±0.00000  bestvalidloss -863.96081  last_update 8\n",
      "train: iter 248  trainloss -669.76694  validloss -804.20570±0.00000  bestvalidloss -863.96081  last_update 9\n",
      "train: iter 249  trainloss -672.77229  validloss -854.07810±0.00000  bestvalidloss -863.96081  last_update 10\n",
      "train: iter 250  trainloss -676.21174  validloss -844.99225±0.00000  bestvalidloss -863.96081  last_update 11\n",
      "train: iter 251  trainloss -675.06513  validloss -834.02489±0.00000  bestvalidloss -863.96081  last_update 12\n",
      "train: iter 252  trainloss -651.64211  validloss -711.74464±0.00000  bestvalidloss -863.96081  last_update 13\n",
      "train: iter 253  trainloss -666.52630  validloss -866.30384±0.00000  bestvalidloss -866.30384  last_update 0\n",
      "train: iter 254  trainloss -662.37453  validloss -819.49201±0.00000  bestvalidloss -866.30384  last_update 1\n",
      "train: iter 255  trainloss -664.61501  validloss -771.36773±0.00000  bestvalidloss -866.30384  last_update 2\n",
      "train: iter 256  trainloss -650.28537  validloss -749.10359±0.00000  bestvalidloss -866.30384  last_update 3\n",
      "train: iter 257  trainloss -670.00373  validloss -833.65692±0.00000  bestvalidloss -866.30384  last_update 4\n",
      "train: iter 258  trainloss -677.50331  validloss -861.40840±0.00000  bestvalidloss -866.30384  last_update 5\n",
      "train: iter 259  trainloss -664.78444  validloss -782.08372±0.00000  bestvalidloss -866.30384  last_update 6\n",
      "train: iter 260  trainloss -668.46939  validloss -780.12760±0.00000  bestvalidloss -866.30384  last_update 7\n",
      "train: iter 261  trainloss 17218.23824  validloss -832.84802±0.00000  bestvalidloss -866.30384  last_update 8\n",
      "train: iter 262  trainloss 57.15915  validloss -10.65669±0.00000  bestvalidloss -866.30384  last_update 9\n",
      "train: iter 263  trainloss -11.37659  validloss -88.09186±0.00000  bestvalidloss -866.30384  last_update 10\n",
      "train: iter 264  trainloss -50.33147  validloss -145.93500±0.00000  bestvalidloss -866.30384  last_update 11\n",
      "train: iter 265  trainloss -79.32935  validloss -186.04669±0.00000  bestvalidloss -866.30384  last_update 12\n",
      "train: iter 266  trainloss -106.74317  validloss -212.87917±0.00000  bestvalidloss -866.30384  last_update 13\n",
      "train: iter 267  trainloss -125.41775  validloss -218.06694±0.00000  bestvalidloss -866.30384  last_update 14\n",
      "train: iter 268  trainloss -151.39799  validloss -271.36597±0.00000  bestvalidloss -866.30384  last_update 15\n",
      "train: iter 269  trainloss -171.30385  validloss -295.96731±0.00000  bestvalidloss -866.30384  last_update 16\n",
      "train: iter 270  trainloss -196.26961  validloss -313.04756±0.00000  bestvalidloss -866.30384  last_update 17\n",
      "train: iter 271  trainloss 385.71512  validloss -346.65032±0.00000  bestvalidloss -866.30384  last_update 18\n",
      "train: iter 272  trainloss 326.59603  validloss 435.01085±0.00000  bestvalidloss -866.30384  last_update 19\n",
      "train: iter 273  trainloss 31.33638  validloss 159.76843±0.00000  bestvalidloss -866.30384  last_update 20\n",
      "train: iter 274  trainloss -137.86685  validloss -247.15806±0.00000  bestvalidloss -866.30384  last_update 21\n",
      "train: iter 275  trainloss -167.74901  validloss -285.43286±0.00000  bestvalidloss -866.30384  last_update 22\n",
      "train: iter 276  trainloss -190.14251  validloss -311.98528±0.00000  bestvalidloss -866.30384  last_update 23\n",
      "train: iter 277  trainloss -209.42647  validloss -333.07364±0.00000  bestvalidloss -866.30384  last_update 24\n",
      "train: iter 278  trainloss -224.51607  validloss -357.89649±0.00000  bestvalidloss -866.30384  last_update 25\n",
      "train: iter 279  trainloss -237.29505  validloss -372.06846±0.00000  bestvalidloss -866.30384  last_update 26\n",
      "train: iter 280  trainloss -246.76820  validloss -388.01795±0.00000  bestvalidloss -866.30384  last_update 27\n",
      "train: iter 281  trainloss -255.45407  validloss -399.84371±0.00000  bestvalidloss -866.30384  last_update 28\n",
      "train: iter 282  trainloss -261.42949  validloss -412.01882±0.00000  bestvalidloss -866.30384  last_update 29\n",
      "train: iter 283  trainloss -271.08679  validloss -414.02598±0.00000  bestvalidloss -866.30384  last_update 30\n",
      "train: iter 284  trainloss -278.12046  validloss -426.64317±0.00000  bestvalidloss -866.30384  last_update 31\n",
      "train: iter 285  trainloss -287.84823  validloss -430.08745±0.00000  bestvalidloss -866.30384  last_update 32\n",
      "train: iter 286  trainloss -291.35981  validloss -443.90234±0.00000  bestvalidloss -866.30384  last_update 33\n",
      "train: iter 287  trainloss -301.64209  validloss -439.48555±0.00000  bestvalidloss -866.30384  last_update 34\n",
      "train: iter 288  trainloss -309.60145  validloss -461.68704±0.00000  bestvalidloss -866.30384  last_update 35\n",
      "train: iter 289  trainloss -315.32434  validloss -459.77337±0.00000  bestvalidloss -866.30384  last_update 36\n",
      "train: iter 290  trainloss -321.99378  validloss -473.62324±0.00000  bestvalidloss -866.30384  last_update 37\n",
      "train: iter 291  trainloss -334.40314  validloss -485.06693±0.00000  bestvalidloss -866.30384  last_update 38\n",
      "train: iter 292  trainloss -343.83099  validloss -494.79547±0.00000  bestvalidloss -866.30384  last_update 39\n",
      "train: iter 293  trainloss -353.98390  validloss -506.72370±0.00000  bestvalidloss -866.30384  last_update 40\n",
      "train: iter 294  trainloss -363.81537  validloss -506.29792±0.00000  bestvalidloss -866.30384  last_update 41\n",
      "train: iter 295  trainloss -381.83250  validloss -535.70613±0.00000  bestvalidloss -866.30384  last_update 42\n",
      "train: iter 296  trainloss -396.55682  validloss -546.81965±0.00000  bestvalidloss -866.30384  last_update 43\n",
      "train: iter 297  trainloss -414.80372  validloss -575.47304±0.00000  bestvalidloss -866.30384  last_update 44\n",
      "train: iter 298  trainloss -434.21541  validloss -603.42851±0.00000  bestvalidloss -866.30384  last_update 45\n",
      "train: iter 299  trainloss -457.42801  validloss -641.09674±0.00000  bestvalidloss -866.30384  last_update 46\n",
      "train: iter 300  trainloss -473.07606  validloss -656.02826±0.00000  bestvalidloss -866.30384  last_update 47\n",
      "train: iter 301  trainloss -484.46836  validloss -658.26107±0.00000  bestvalidloss -866.30384  last_update 48\n",
      "train: iter 302  trainloss -511.76814  validloss -698.96714±0.00000  bestvalidloss -866.30384  last_update 49\n",
      "train: iter 303  trainloss -525.56650  validloss -711.31600±0.00000  bestvalidloss -866.30384  last_update 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 304  trainloss -538.55673  validloss -704.00949±0.00000  bestvalidloss -866.30384  last_update 51\n",
      "train: iter 305  trainloss -553.10558  validloss -717.34184±0.00000  bestvalidloss -866.30384  last_update 52\n",
      "train: iter 306  trainloss -564.78753  validloss -761.96248±0.00000  bestvalidloss -866.30384  last_update 53\n",
      "train: iter 307  trainloss -574.34808  validloss -748.06036±0.00000  bestvalidloss -866.30384  last_update 54\n",
      "train: iter 308  trainloss -579.85932  validloss -759.35558±0.00000  bestvalidloss -866.30384  last_update 55\n",
      "train: iter 309  trainloss -592.65210  validloss -772.49839±0.00000  bestvalidloss -866.30384  last_update 56\n",
      "train: iter 310  trainloss -600.36932  validloss -788.91398±0.00000  bestvalidloss -866.30384  last_update 57\n",
      "train: iter 311  trainloss -600.75674  validloss -802.88652±0.00000  bestvalidloss -866.30384  last_update 58\n",
      "train: iter 312  trainloss -603.70185  validloss -762.03236±0.00000  bestvalidloss -866.30384  last_update 59\n",
      "train: iter 313  trainloss -606.23189  validloss -748.02341±0.00000  bestvalidloss -866.30384  last_update 60\n",
      "train: iter 314  trainloss -614.64202  validloss -808.13509±0.00000  bestvalidloss -866.30384  last_update 61\n",
      "train: iter 315  trainloss -623.16974  validloss -776.25920±0.00000  bestvalidloss -866.30384  last_update 62\n",
      "train: iter 316  trainloss -617.82577  validloss -791.83250±0.00000  bestvalidloss -866.30384  last_update 63\n",
      "train: iter 317  trainloss -613.58900  validloss -811.37050±0.00000  bestvalidloss -866.30384  last_update 64\n",
      "train: iter 318  trainloss -627.90059  validloss -772.14291±0.00000  bestvalidloss -866.30384  last_update 65\n",
      "train: iter 319  trainloss -632.58770  validloss -809.30898±0.00000  bestvalidloss -866.30384  last_update 66\n",
      "train: iter 320  trainloss -634.32227  validloss -809.09245±0.00000  bestvalidloss -866.30384  last_update 67\n",
      "train: iter 321  trainloss -638.32214  validloss -823.77411±0.00000  bestvalidloss -866.30384  last_update 68\n",
      "train: iter 322  trainloss -642.22051  validloss -828.88970±0.00000  bestvalidloss -866.30384  last_update 69\n",
      "train: iter 323  trainloss -650.57263  validloss -813.37912±0.00000  bestvalidloss -866.30384  last_update 70\n",
      "train: iter 324  trainloss -646.70060  validloss -816.47824±0.00000  bestvalidloss -866.30384  last_update 71\n",
      "train: iter 325  trainloss -639.68279  validloss -808.55643±0.00000  bestvalidloss -866.30384  last_update 72\n",
      "train: iter 326  trainloss -644.30194  validloss -839.60642±0.00000  bestvalidloss -866.30384  last_update 73\n",
      "train: iter 327  trainloss -653.09615  validloss -815.42654±0.00000  bestvalidloss -866.30384  last_update 74\n",
      "train: iter 328  trainloss -654.69494  validloss -848.87057±0.00000  bestvalidloss -866.30384  last_update 75\n",
      "train: iter 329  trainloss -660.40852  validloss -835.85971±0.00000  bestvalidloss -866.30384  last_update 76\n",
      "train: iter 330  trainloss -660.15549  validloss -846.36720±0.00000  bestvalidloss -866.30384  last_update 77\n",
      "train: iter 331  trainloss -666.84097  validloss -806.78628±0.00000  bestvalidloss -866.30384  last_update 78\n",
      "train: iter 332  trainloss -650.34106  validloss -864.25482±0.00000  bestvalidloss -866.30384  last_update 79\n",
      "train: iter 333  trainloss -657.57889  validloss -825.65634±0.00000  bestvalidloss -866.30384  last_update 80\n",
      "train: iter 334  trainloss -646.12840  validloss -768.22374±0.00000  bestvalidloss -866.30384  last_update 81\n",
      "train: iter 335  trainloss -656.99569  validloss -833.24859±0.00000  bestvalidloss -866.30384  last_update 82\n",
      "train: iter 336  trainloss -666.79138  validloss -837.94565±0.00000  bestvalidloss -866.30384  last_update 83\n",
      "train: iter 337  trainloss -649.23234  validloss -817.88080±0.00000  bestvalidloss -866.30384  last_update 84\n",
      "train: iter 338  trainloss -659.32248  validloss -798.30211±0.00000  bestvalidloss -866.30384  last_update 85\n",
      "train: iter 339  trainloss -664.32464  validloss -857.95002±0.00000  bestvalidloss -866.30384  last_update 86\n",
      "train: iter 340  trainloss -670.22359  validloss -809.00389±0.00000  bestvalidloss -866.30384  last_update 87\n",
      "train: iter 341  trainloss -654.37162  validloss -825.34842±0.00000  bestvalidloss -866.30384  last_update 88\n",
      "train: iter 342  trainloss -669.13137  validloss -863.75925±0.00000  bestvalidloss -866.30384  last_update 89\n",
      "train: iter 343  trainloss -671.04262  validloss -864.70356±0.00000  bestvalidloss -866.30384  last_update 90\n",
      "train: iter 344  trainloss -664.17955  validloss -845.06076±0.00000  bestvalidloss -866.30384  last_update 91\n",
      "train: iter 345  trainloss -670.38582  validloss -828.21568±0.00000  bestvalidloss -866.30384  last_update 92\n",
      "train: iter 346  trainloss -675.84843  validloss -809.97594±0.00000  bestvalidloss -866.30384  last_update 93\n",
      "train: iter 347  trainloss -676.38980  validloss -843.47373±0.00000  bestvalidloss -866.30384  last_update 94\n",
      "train: iter 348  trainloss -660.97229  validloss -811.00939±0.00000  bestvalidloss -866.30384  last_update 95\n",
      "train: iter 349  trainloss -657.80656  validloss -788.14094±0.00000  bestvalidloss -866.30384  last_update 96\n",
      "train: iter 350  trainloss -663.85251  validloss -842.08351±0.00000  bestvalidloss -866.30384  last_update 97\n",
      "train: iter 351  trainloss -677.59038  validloss -850.17686±0.00000  bestvalidloss -866.30384  last_update 98\n",
      "train: iter 352  trainloss -674.19566  validloss -838.66090±0.00000  bestvalidloss -866.30384  last_update 99\n",
      "train: iter 353  trainloss -668.14499  validloss -823.48566±0.00000  bestvalidloss -866.30384  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-5.2999) penalty_target_max tensor(60.2785)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.81183  validloss 11.64342±0.00000  bestvalidloss 11.64342  last_update 0\n",
      "train: iter 1  trainloss 8.97578  validloss 10.58487±0.00000  bestvalidloss 10.58487  last_update 0\n",
      "train: iter 2  trainloss 8.24487  validloss 9.69750±0.00000  bestvalidloss 9.69750  last_update 0\n",
      "train: iter 3  trainloss 7.60055  validloss 8.89608±0.00000  bestvalidloss 8.89608  last_update 0\n",
      "train: iter 4  trainloss 7.06911  validloss 8.24464±0.00000  bestvalidloss 8.24464  last_update 0\n",
      "train: iter 5  trainloss 6.58649  validloss 7.64569±0.00000  bestvalidloss 7.64569  last_update 0\n",
      "train: iter 6  trainloss 6.16703  validloss 7.16553±0.00000  bestvalidloss 7.16553  last_update 0\n",
      "train: iter 7  trainloss 5.80182  validloss 6.71165±0.00000  bestvalidloss 6.71165  last_update 0\n",
      "train: iter 8  trainloss 5.46456  validloss 6.29427±0.00000  bestvalidloss 6.29427  last_update 0\n",
      "train: iter 9  trainloss 5.17030  validloss 5.94810±0.00000  bestvalidloss 5.94810  last_update 0\n",
      "train: iter 10  trainloss 4.91057  validloss 5.62991±0.00000  bestvalidloss 5.62991  last_update 0\n",
      "train: iter 11  trainloss 4.67919  validloss 5.33346±0.00000  bestvalidloss 5.33346  last_update 0\n",
      "train: iter 12  trainloss 4.46238  validloss 5.09574±0.00000  bestvalidloss 5.09574  last_update 0\n",
      "train: iter 13  trainloss 4.27348  validloss 4.84401±0.00000  bestvalidloss 4.84401  last_update 0\n",
      "train: iter 14  trainloss 4.10258  validloss 4.64500±0.00000  bestvalidloss 4.64500  last_update 0\n",
      "train: iter 15  trainloss 3.94608  validloss 4.45448±0.00000  bestvalidloss 4.45448  last_update 0\n",
      "train: iter 16  trainloss 3.80739  validloss 4.28358±0.00000  bestvalidloss 4.28358  last_update 0\n",
      "train: iter 17  trainloss 3.66847  validloss 4.11752±0.00000  bestvalidloss 4.11752  last_update 0\n",
      "train: iter 18  trainloss 3.56011  validloss 3.97180±0.00000  bestvalidloss 3.97180  last_update 0\n",
      "train: iter 19  trainloss 3.44693  validloss 3.83924±0.00000  bestvalidloss 3.83924  last_update 0\n",
      "train: iter 20  trainloss 3.34982  validloss 3.72093±0.00000  bestvalidloss 3.72093  last_update 0\n",
      "train: iter 21  trainloss 3.26145  validloss 3.60521±0.00000  bestvalidloss 3.60521  last_update 0\n",
      "train: iter 22  trainloss 3.17517  validloss 3.49345±0.00000  bestvalidloss 3.49345  last_update 0\n",
      "train: iter 23  trainloss 3.10386  validloss 3.40272±0.00000  bestvalidloss 3.40272  last_update 0\n",
      "train: iter 24  trainloss 3.03090  validloss 3.32426±0.00000  bestvalidloss 3.32426  last_update 0\n",
      "train: iter 25  trainloss 2.96100  validloss 3.23598±0.00000  bestvalidloss 3.23598  last_update 0\n",
      "train: iter 26  trainloss 2.89544  validloss 3.15742±0.00000  bestvalidloss 3.15742  last_update 0\n",
      "train: iter 27  trainloss 2.84634  validloss 3.08816±0.00000  bestvalidloss 3.08816  last_update 0\n",
      "train: iter 28  trainloss 2.79438  validloss 3.02744±0.00000  bestvalidloss 3.02744  last_update 0\n",
      "train: iter 29  trainloss 2.74036  validloss 2.96124±0.00000  bestvalidloss 2.96124  last_update 0\n",
      "train: iter 30  trainloss 2.69829  validloss 2.89948±0.00000  bestvalidloss 2.89948  last_update 0\n",
      "train: iter 31  trainloss 2.65385  validloss 2.84810±0.00000  bestvalidloss 2.84810  last_update 0\n",
      "train: iter 32  trainloss 2.61608  validloss 2.80430±0.00000  bestvalidloss 2.80430  last_update 0\n",
      "train: iter 33  trainloss 2.57673  validloss 2.75916±0.00000  bestvalidloss 2.75916  last_update 0\n",
      "train: iter 34  trainloss 2.53961  validloss 2.71608±0.00000  bestvalidloss 2.71608  last_update 0\n",
      "train: iter 35  trainloss 2.50966  validloss 2.67164±0.00000  bestvalidloss 2.67164  last_update 0\n",
      "train: iter 36  trainloss 2.47773  validloss 2.64205±0.00000  bestvalidloss 2.64205  last_update 0\n",
      "train: iter 37  trainloss 2.45168  validloss 2.59469±0.00000  bestvalidloss 2.59469  last_update 0\n",
      "train: iter 38  trainloss 2.42318  validloss 2.56271±0.00000  bestvalidloss 2.56271  last_update 0\n",
      "train: iter 39  trainloss 2.39561  validloss 2.53258±0.00000  bestvalidloss 2.53258  last_update 0\n",
      "train: iter 40  trainloss 2.37408  validloss 2.50029±0.00000  bestvalidloss 2.50029  last_update 0\n",
      "train: iter 41  trainloss 2.35203  validloss 2.46949±0.00000  bestvalidloss 2.46949  last_update 0\n",
      "train: iter 42  trainloss 2.32494  validloss 2.44409±0.00000  bestvalidloss 2.44409  last_update 0\n",
      "train: iter 43  trainloss 2.30665  validloss 2.41229±0.00000  bestvalidloss 2.41229  last_update 0\n",
      "train: iter 44  trainloss 2.28659  validloss 2.39202±0.00000  bestvalidloss 2.39202  last_update 0\n",
      "train: iter 45  trainloss 2.26518  validloss 2.36429±0.00000  bestvalidloss 2.36429  last_update 0\n",
      "train: iter 46  trainloss 2.24685  validloss 2.34339±0.00000  bestvalidloss 2.34339  last_update 0\n",
      "train: iter 47  trainloss 2.22711  validloss 2.31505±0.00000  bestvalidloss 2.31505  last_update 0\n",
      "train: iter 48  trainloss 2.21518  validloss 2.29358±0.00000  bestvalidloss 2.29358  last_update 0\n",
      "train: iter 49  trainloss 2.19611  validloss 2.27284±0.00000  bestvalidloss 2.27284  last_update 0\n",
      "train: iter 50  trainloss 2.17885  validloss 2.25435±0.00000  bestvalidloss 2.25435  last_update 0\n",
      "train: iter 51  trainloss 2.15940  validloss 2.23140±0.00000  bestvalidloss 2.23140  last_update 0\n",
      "train: iter 52  trainloss 2.14421  validloss 2.20853±0.00000  bestvalidloss 2.20853  last_update 0\n",
      "train: iter 53  trainloss 2.12840  validloss 2.19094±0.00000  bestvalidloss 2.19094  last_update 0\n",
      "train: iter 54  trainloss 2.11358  validloss 2.17779±0.00000  bestvalidloss 2.17779  last_update 0\n",
      "train: iter 55  trainloss 2.09841  validloss 2.15253±0.00000  bestvalidloss 2.15253  last_update 0\n",
      "train: iter 56  trainloss 2.08358  validloss 2.13298±0.00000  bestvalidloss 2.13298  last_update 0\n",
      "train: iter 57  trainloss 2.06690  validloss 2.11711±0.00000  bestvalidloss 2.11711  last_update 0\n",
      "train: iter 58  trainloss 2.05276  validloss 2.09626±0.00000  bestvalidloss 2.09626  last_update 0\n",
      "train: iter 59  trainloss 2.03733  validloss 2.07747±0.00000  bestvalidloss 2.07747  last_update 0\n",
      "train: iter 60  trainloss 2.02425  validloss 2.05811±0.00000  bestvalidloss 2.05811  last_update 0\n",
      "train: iter 61  trainloss 2.00963  validloss 2.03893±0.00000  bestvalidloss 2.03893  last_update 0\n",
      "train: iter 62  trainloss 1.99004  validloss 2.01712±0.00000  bestvalidloss 2.01712  last_update 0\n",
      "train: iter 63  trainloss 1.97756  validloss 1.99385±0.00000  bestvalidloss 1.99385  last_update 0\n",
      "train: iter 64  trainloss 1.95952  validloss 1.97802±0.00000  bestvalidloss 1.97802  last_update 0\n",
      "train: iter 65  trainloss 1.94409  validloss 1.95874±0.00000  bestvalidloss 1.95874  last_update 0\n",
      "train: iter 66  trainloss 1.93189  validloss 1.93656±0.00000  bestvalidloss 1.93656  last_update 0\n",
      "train: iter 67  trainloss 1.91522  validloss 1.91121±0.00000  bestvalidloss 1.91121  last_update 0\n",
      "train: iter 68  trainloss 1.89874  validloss 1.89045±0.00000  bestvalidloss 1.89045  last_update 0\n",
      "train: iter 69  trainloss 1.88083  validloss 1.87066±0.00000  bestvalidloss 1.87066  last_update 0\n",
      "train: iter 70  trainloss 1.86127  validloss 1.84961±0.00000  bestvalidloss 1.84961  last_update 0\n",
      "train: iter 71  trainloss 1.85039  validloss 1.82096±0.00000  bestvalidloss 1.82096  last_update 0\n",
      "train: iter 72  trainloss 1.82832  validloss 1.80198±0.00000  bestvalidloss 1.80198  last_update 0\n",
      "train: iter 73  trainloss 1.81394  validloss 1.77814±0.00000  bestvalidloss 1.77814  last_update 0\n",
      "train: iter 74  trainloss 1.79391  validloss 1.75606±0.00000  bestvalidloss 1.75606  last_update 0\n",
      "train: iter 75  trainloss 1.78201  validloss 1.72768±0.00000  bestvalidloss 1.72768  last_update 0\n",
      "train: iter 76  trainloss 1.76757  validloss 1.70432±0.00000  bestvalidloss 1.70432  last_update 0\n",
      "train: iter 77  trainloss 1.74604  validloss 1.67835±0.00000  bestvalidloss 1.67835  last_update 0\n",
      "train: iter 78  trainloss 1.72912  validloss 1.65441±0.00000  bestvalidloss 1.65441  last_update 0\n",
      "train: iter 79  trainloss 1.71459  validloss 1.62647±0.00000  bestvalidloss 1.62647  last_update 0\n",
      "train: iter 80  trainloss 1.69773  validloss 1.60305±0.00000  bestvalidloss 1.60305  last_update 0\n",
      "train: iter 81  trainloss 1.68766  validloss 1.57723±0.00000  bestvalidloss 1.57723  last_update 0\n",
      "train: iter 82  trainloss 1.67489  validloss 1.55218±0.00000  bestvalidloss 1.55218  last_update 0\n",
      "train: iter 83  trainloss 1.66038  validloss 1.52615±0.00000  bestvalidloss 1.52615  last_update 0\n",
      "train: iter 84  trainloss 1.65354  validloss 1.50469±0.00000  bestvalidloss 1.50469  last_update 0\n",
      "train: iter 85  trainloss 1.63738  validloss 1.47870±0.00000  bestvalidloss 1.47870  last_update 0\n",
      "train: iter 86  trainloss 1.62563  validloss 1.45965±0.00000  bestvalidloss 1.45965  last_update 0\n",
      "train: iter 87  trainloss 1.61781  validloss 1.43579±0.00000  bestvalidloss 1.43579  last_update 0\n",
      "train: iter 88  trainloss 1.60608  validloss 1.41819±0.00000  bestvalidloss 1.41819  last_update 0\n",
      "train: iter 89  trainloss 1.60382  validloss 1.39785±0.00000  bestvalidloss 1.39785  last_update 0\n",
      "train: iter 90  trainloss 1.59679  validloss 1.38066±0.00000  bestvalidloss 1.38066  last_update 0\n",
      "train: iter 91  trainloss 1.59138  validloss 1.36160±0.00000  bestvalidloss 1.36160  last_update 0\n",
      "train: iter 92  trainloss 1.58449  validloss 1.34873±0.00000  bestvalidloss 1.34873  last_update 0\n",
      "train: iter 93  trainloss 1.57581  validloss 1.33033±0.00000  bestvalidloss 1.33033  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 94  trainloss 1.57478  validloss 1.32254±0.00000  bestvalidloss 1.32254  last_update 0\n",
      "train: iter 95  trainloss 1.56718  validloss 1.31046±0.00000  bestvalidloss 1.31046  last_update 0\n",
      "train: iter 96  trainloss 1.56893  validloss 1.29683±0.00000  bestvalidloss 1.29683  last_update 0\n",
      "train: iter 97  trainloss 1.54635  validloss 1.28608±0.00000  bestvalidloss 1.28608  last_update 0\n",
      "train: iter 98  trainloss 1.55044  validloss 1.27258±0.00000  bestvalidloss 1.27258  last_update 0\n",
      "train: iter 99  trainloss 1.56271  validloss 1.26031±0.00000  bestvalidloss 1.26031  last_update 0\n",
      "train: iter 100  trainloss 1.56889  validloss 1.25324±0.00000  bestvalidloss 1.25324  last_update 0\n",
      "train: iter 101  trainloss 1.55079  validloss 1.24840±0.00000  bestvalidloss 1.24840  last_update 0\n",
      "train: iter 102  trainloss 1.55062  validloss 1.23952±0.00000  bestvalidloss 1.23952  last_update 0\n",
      "train: iter 103  trainloss 1.54698  validloss 1.23404±0.00000  bestvalidloss 1.23404  last_update 0\n",
      "train: iter 104  trainloss 1.54527  validloss 1.22064±0.00000  bestvalidloss 1.22064  last_update 0\n",
      "train: iter 105  trainloss 1.55335  validloss 1.21363±0.00000  bestvalidloss 1.21363  last_update 0\n",
      "train: iter 106  trainloss 1.53718  validloss 1.21119±0.00000  bestvalidloss 1.21119  last_update 0\n",
      "train: iter 107  trainloss 1.54938  validloss 1.20518±0.00000  bestvalidloss 1.20518  last_update 0\n",
      "train: iter 108  trainloss 1.53364  validloss 1.20362±0.00000  bestvalidloss 1.20362  last_update 0\n",
      "train: iter 109  trainloss 1.54911  validloss 1.19115±0.00000  bestvalidloss 1.19115  last_update 0\n",
      "train: iter 110  trainloss 1.54318  validloss 1.19054±0.00000  bestvalidloss 1.19054  last_update 0\n",
      "train: iter 111  trainloss 1.55687  validloss 1.18634±0.00000  bestvalidloss 1.18634  last_update 0\n",
      "train: iter 112  trainloss 1.53974  validloss 1.18531±0.00000  bestvalidloss 1.18531  last_update 0\n",
      "train: iter 113  trainloss 1.53806  validloss 1.18120±0.00000  bestvalidloss 1.18120  last_update 0\n",
      "train: iter 114  trainloss 1.54578  validloss 1.17842±0.00000  bestvalidloss 1.17842  last_update 0\n",
      "train: iter 115  trainloss 1.55292  validloss 1.17407±0.00000  bestvalidloss 1.17407  last_update 0\n",
      "train: iter 116  trainloss 1.54479  validloss 1.17056±0.00000  bestvalidloss 1.17056  last_update 0\n",
      "train: iter 117  trainloss 1.53130  validloss 1.17093±0.00000  bestvalidloss 1.17056  last_update 1\n",
      "train: iter 118  trainloss 1.55939  validloss 1.16805±0.00000  bestvalidloss 1.16805  last_update 0\n",
      "train: iter 119  trainloss 1.54860  validloss 1.16397±0.00000  bestvalidloss 1.16397  last_update 0\n",
      "train: iter 120  trainloss 1.55240  validloss 1.16453±0.00000  bestvalidloss 1.16397  last_update 1\n",
      "train: iter 121  trainloss 1.53546  validloss 1.16191±0.00000  bestvalidloss 1.16191  last_update 0\n",
      "train: iter 122  trainloss 1.56586  validloss 1.15822±0.00000  bestvalidloss 1.15822  last_update 0\n",
      "train: iter 123  trainloss 1.54890  validloss 1.16244±0.00000  bestvalidloss 1.15822  last_update 1\n",
      "train: iter 124  trainloss 1.55433  validloss 1.15614±0.00000  bestvalidloss 1.15614  last_update 0\n",
      "train: iter 125  trainloss 1.53465  validloss 1.15798±0.00000  bestvalidloss 1.15614  last_update 1\n",
      "train: iter 126  trainloss 1.54432  validloss 1.15719±0.00000  bestvalidloss 1.15614  last_update 2\n",
      "train: iter 127  trainloss 1.53360  validloss 1.15057±0.00000  bestvalidloss 1.15057  last_update 0\n",
      "train: iter 128  trainloss 1.53960  validloss 1.15321±0.00000  bestvalidloss 1.15057  last_update 1\n",
      "train: iter 129  trainloss 1.53766  validloss 1.14594±0.00000  bestvalidloss 1.14594  last_update 0\n",
      "train: iter 130  trainloss 1.53087  validloss 1.14789±0.00000  bestvalidloss 1.14594  last_update 1\n",
      "train: iter 131  trainloss 1.55178  validloss 1.14589±0.00000  bestvalidloss 1.14589  last_update 0\n",
      "train: iter 132  trainloss 1.54790  validloss 1.14461±0.00000  bestvalidloss 1.14461  last_update 0\n",
      "train: iter 133  trainloss 1.52865  validloss 1.14573±0.00000  bestvalidloss 1.14461  last_update 1\n",
      "train: iter 134  trainloss 1.54245  validloss 1.14324±0.00000  bestvalidloss 1.14324  last_update 0\n",
      "train: iter 135  trainloss 1.53881  validloss 1.14255±0.00000  bestvalidloss 1.14255  last_update 0\n",
      "train: iter 136  trainloss 1.54125  validloss 1.14015±0.00000  bestvalidloss 1.14015  last_update 0\n",
      "train: iter 137  trainloss 1.54157  validloss 1.13937±0.00000  bestvalidloss 1.13937  last_update 0\n",
      "train: iter 138  trainloss 1.53710  validloss 1.13548±0.00000  bestvalidloss 1.13548  last_update 0\n",
      "train: iter 139  trainloss 1.55130  validloss 1.13832±0.00000  bestvalidloss 1.13548  last_update 1\n",
      "train: iter 140  trainloss 1.54340  validloss 1.13616±0.00000  bestvalidloss 1.13548  last_update 2\n",
      "train: iter 141  trainloss 1.56208  validloss 1.13724±0.00000  bestvalidloss 1.13548  last_update 3\n",
      "train: iter 142  trainloss 1.54160  validloss 1.13976±0.00000  bestvalidloss 1.13548  last_update 4\n",
      "train: iter 143  trainloss 1.53744  validloss 1.13798±0.00000  bestvalidloss 1.13548  last_update 5\n",
      "train: iter 144  trainloss 1.53727  validloss 1.13857±0.00000  bestvalidloss 1.13548  last_update 6\n",
      "train: iter 145  trainloss 1.53694  validloss 1.13360±0.00000  bestvalidloss 1.13360  last_update 0\n",
      "train: iter 146  trainloss 1.54601  validloss 1.13026±0.00000  bestvalidloss 1.13026  last_update 0\n",
      "train: iter 147  trainloss 1.55041  validloss 1.13031±0.00000  bestvalidloss 1.13026  last_update 1\n",
      "train: iter 148  trainloss 1.54335  validloss 1.13342±0.00000  bestvalidloss 1.13026  last_update 2\n",
      "train: iter 149  trainloss 1.53658  validloss 1.13779±0.00000  bestvalidloss 1.13026  last_update 3\n",
      "train: iter 150  trainloss 1.54424  validloss 1.13326±0.00000  bestvalidloss 1.13026  last_update 4\n",
      "train: iter 151  trainloss 1.53865  validloss 1.13369±0.00000  bestvalidloss 1.13026  last_update 5\n",
      "train: iter 152  trainloss 1.55945  validloss 1.13063±0.00000  bestvalidloss 1.13026  last_update 6\n",
      "train: iter 153  trainloss 1.55236  validloss 1.13350±0.00000  bestvalidloss 1.13026  last_update 7\n",
      "train: iter 154  trainloss 1.53925  validloss 1.13369±0.00000  bestvalidloss 1.13026  last_update 8\n",
      "train: iter 155  trainloss 1.53795  validloss 1.13327±0.00000  bestvalidloss 1.13026  last_update 9\n",
      "train: iter 156  trainloss 1.54269  validloss 1.12902±0.00000  bestvalidloss 1.12902  last_update 0\n",
      "train: iter 157  trainloss 1.54148  validloss 1.13359±0.00000  bestvalidloss 1.12902  last_update 1\n",
      "train: iter 158  trainloss 1.54796  validloss 1.13055±0.00000  bestvalidloss 1.12902  last_update 2\n",
      "train: iter 159  trainloss 1.55017  validloss 1.13141±0.00000  bestvalidloss 1.12902  last_update 3\n",
      "train: iter 160  trainloss 1.54382  validloss 1.12974±0.00000  bestvalidloss 1.12902  last_update 4\n",
      "train: iter 161  trainloss 1.53299  validloss 1.12782±0.00000  bestvalidloss 1.12782  last_update 0\n",
      "train: iter 162  trainloss 1.54825  validloss 1.12980±0.00000  bestvalidloss 1.12782  last_update 1\n",
      "train: iter 163  trainloss 1.53397  validloss 1.12830±0.00000  bestvalidloss 1.12782  last_update 2\n",
      "train: iter 164  trainloss 1.53366  validloss 1.12788±0.00000  bestvalidloss 1.12782  last_update 3\n",
      "train: iter 165  trainloss 1.54698  validloss 1.12753±0.00000  bestvalidloss 1.12753  last_update 0\n",
      "train: iter 166  trainloss 1.53663  validloss 1.12976±0.00000  bestvalidloss 1.12753  last_update 1\n",
      "train: iter 167  trainloss 1.52608  validloss 1.12600±0.00000  bestvalidloss 1.12600  last_update 0\n",
      "train: iter 168  trainloss 1.54024  validloss 1.12879±0.00000  bestvalidloss 1.12600  last_update 1\n",
      "train: iter 169  trainloss 1.53630  validloss 1.12501±0.00000  bestvalidloss 1.12501  last_update 0\n",
      "train: iter 170  trainloss 1.53935  validloss 1.12498±0.00000  bestvalidloss 1.12498  last_update 0\n",
      "train: iter 171  trainloss 1.52154  validloss 1.12933±0.00000  bestvalidloss 1.12498  last_update 1\n",
      "train: iter 172  trainloss 1.54372  validloss 1.12634±0.00000  bestvalidloss 1.12498  last_update 2\n",
      "train: iter 173  trainloss 1.53950  validloss 1.12296±0.00000  bestvalidloss 1.12296  last_update 0\n",
      "train: iter 174  trainloss 1.52188  validloss 1.12439±0.00000  bestvalidloss 1.12296  last_update 1\n",
      "train: iter 175  trainloss 1.54537  validloss 1.12468±0.00000  bestvalidloss 1.12296  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 176  trainloss 1.55209  validloss 1.12252±0.00000  bestvalidloss 1.12252  last_update 0\n",
      "train: iter 177  trainloss 1.54046  validloss 1.12678±0.00000  bestvalidloss 1.12252  last_update 1\n",
      "train: iter 178  trainloss 1.54928  validloss 1.12220±0.00000  bestvalidloss 1.12220  last_update 0\n",
      "train: iter 179  trainloss 1.55527  validloss 1.12200±0.00000  bestvalidloss 1.12200  last_update 0\n",
      "train: iter 180  trainloss 1.54295  validloss 1.12463±0.00000  bestvalidloss 1.12200  last_update 1\n",
      "train: iter 181  trainloss 1.53887  validloss 1.12720±0.00000  bestvalidloss 1.12200  last_update 2\n",
      "train: iter 182  trainloss 1.56779  validloss 1.12444±0.00000  bestvalidloss 1.12200  last_update 3\n",
      "train: iter 183  trainloss 1.53494  validloss 1.12827±0.00000  bestvalidloss 1.12200  last_update 4\n",
      "train: iter 184  trainloss 1.54143  validloss 1.12224±0.00000  bestvalidloss 1.12200  last_update 5\n",
      "train: iter 185  trainloss 1.53718  validloss 1.12439±0.00000  bestvalidloss 1.12200  last_update 6\n",
      "train: iter 186  trainloss 1.55386  validloss 1.12180±0.00000  bestvalidloss 1.12180  last_update 0\n",
      "train: iter 187  trainloss 1.53972  validloss 1.12321±0.00000  bestvalidloss 1.12180  last_update 1\n",
      "train: iter 188  trainloss 1.55076  validloss 1.12780±0.00000  bestvalidloss 1.12180  last_update 2\n",
      "train: iter 189  trainloss 1.52678  validloss 1.12432±0.00000  bestvalidloss 1.12180  last_update 3\n",
      "train: iter 190  trainloss 1.55643  validloss 1.12700±0.00000  bestvalidloss 1.12180  last_update 4\n",
      "train: iter 191  trainloss 1.54042  validloss 1.13003±0.00000  bestvalidloss 1.12180  last_update 5\n",
      "train: iter 192  trainloss 1.55038  validloss 1.11925±0.00000  bestvalidloss 1.11925  last_update 0\n",
      "train: iter 193  trainloss 1.52574  validloss 1.12527±0.00000  bestvalidloss 1.11925  last_update 1\n",
      "train: iter 194  trainloss 1.52942  validloss 1.12295±0.00000  bestvalidloss 1.11925  last_update 2\n",
      "train: iter 195  trainloss 1.52978  validloss 1.12447±0.00000  bestvalidloss 1.11925  last_update 3\n",
      "train: iter 196  trainloss 1.56242  validloss 1.12216±0.00000  bestvalidloss 1.11925  last_update 4\n",
      "train: iter 197  trainloss 1.53625  validloss 1.12134±0.00000  bestvalidloss 1.11925  last_update 5\n",
      "train: iter 198  trainloss 1.55932  validloss 1.12289±0.00000  bestvalidloss 1.11925  last_update 6\n",
      "train: iter 199  trainloss 1.54396  validloss 1.12464±0.00000  bestvalidloss 1.11925  last_update 7\n",
      "train: iter 200  trainloss 1.55112  validloss 1.12134±0.00000  bestvalidloss 1.11925  last_update 8\n",
      "train: iter 201  trainloss 1.54100  validloss 1.12483±0.00000  bestvalidloss 1.11925  last_update 9\n",
      "train: iter 202  trainloss 1.53983  validloss 1.12239±0.00000  bestvalidloss 1.11925  last_update 10\n",
      "train: iter 203  trainloss 1.54850  validloss 1.11579±0.00000  bestvalidloss 1.11579  last_update 0\n",
      "train: iter 204  trainloss 1.54278  validloss 1.12196±0.00000  bestvalidloss 1.11579  last_update 1\n",
      "train: iter 205  trainloss 1.54503  validloss 1.12221±0.00000  bestvalidloss 1.11579  last_update 2\n",
      "train: iter 206  trainloss 1.54360  validloss 1.12285±0.00000  bestvalidloss 1.11579  last_update 3\n",
      "train: iter 207  trainloss 1.54008  validloss 1.12341±0.00000  bestvalidloss 1.11579  last_update 4\n",
      "train: iter 208  trainloss 1.55782  validloss 1.12052±0.00000  bestvalidloss 1.11579  last_update 5\n",
      "train: iter 209  trainloss 1.54595  validloss 1.12597±0.00000  bestvalidloss 1.11579  last_update 6\n",
      "train: iter 210  trainloss 1.56001  validloss 1.12401±0.00000  bestvalidloss 1.11579  last_update 7\n",
      "train: iter 211  trainloss 1.53543  validloss 1.12289±0.00000  bestvalidloss 1.11579  last_update 8\n",
      "train: iter 212  trainloss 1.54514  validloss 1.12202±0.00000  bestvalidloss 1.11579  last_update 9\n",
      "train: iter 213  trainloss 1.53872  validloss 1.12551±0.00000  bestvalidloss 1.11579  last_update 10\n",
      "train: iter 214  trainloss 1.54515  validloss 1.12408±0.00000  bestvalidloss 1.11579  last_update 11\n",
      "train: iter 215  trainloss 1.53378  validloss 1.12609±0.00000  bestvalidloss 1.11579  last_update 12\n",
      "train: iter 216  trainloss 1.54562  validloss 1.12321±0.00000  bestvalidloss 1.11579  last_update 13\n",
      "train: iter 217  trainloss 1.53644  validloss 1.11928±0.00000  bestvalidloss 1.11579  last_update 14\n",
      "train: iter 218  trainloss 1.53992  validloss 1.12676±0.00000  bestvalidloss 1.11579  last_update 15\n",
      "train: iter 219  trainloss 1.54764  validloss 1.12208±0.00000  bestvalidloss 1.11579  last_update 16\n",
      "train: iter 220  trainloss 1.53709  validloss 1.12524±0.00000  bestvalidloss 1.11579  last_update 17\n",
      "train: iter 221  trainloss 1.53418  validloss 1.12220±0.00000  bestvalidloss 1.11579  last_update 18\n",
      "train: iter 222  trainloss 1.54645  validloss 1.12272±0.00000  bestvalidloss 1.11579  last_update 19\n",
      "train: iter 223  trainloss 1.55321  validloss 1.12460±0.00000  bestvalidloss 1.11579  last_update 20\n",
      "train: iter 224  trainloss 1.54251  validloss 1.12461±0.00000  bestvalidloss 1.11579  last_update 21\n",
      "train: iter 225  trainloss 1.54110  validloss 1.12332±0.00000  bestvalidloss 1.11579  last_update 22\n",
      "train: iter 226  trainloss 1.55533  validloss 1.12348±0.00000  bestvalidloss 1.11579  last_update 23\n",
      "train: iter 227  trainloss 1.53736  validloss 1.12603±0.00000  bestvalidloss 1.11579  last_update 24\n",
      "train: iter 228  trainloss 1.54900  validloss 1.12652±0.00000  bestvalidloss 1.11579  last_update 25\n",
      "train: iter 229  trainloss 1.53687  validloss 1.12455±0.00000  bestvalidloss 1.11579  last_update 26\n",
      "train: iter 230  trainloss 1.55697  validloss 1.12269±0.00000  bestvalidloss 1.11579  last_update 27\n",
      "train: iter 231  trainloss 1.53899  validloss 1.12556±0.00000  bestvalidloss 1.11579  last_update 28\n",
      "train: iter 232  trainloss 1.54785  validloss 1.12223±0.00000  bestvalidloss 1.11579  last_update 29\n",
      "train: iter 233  trainloss 1.54260  validloss 1.12309±0.00000  bestvalidloss 1.11579  last_update 30\n",
      "train: iter 234  trainloss 1.53463  validloss 1.12235±0.00000  bestvalidloss 1.11579  last_update 31\n",
      "train: iter 235  trainloss 1.54224  validloss 1.12375±0.00000  bestvalidloss 1.11579  last_update 32\n",
      "train: iter 236  trainloss 1.55251  validloss 1.12257±0.00000  bestvalidloss 1.11579  last_update 33\n",
      "train: iter 237  trainloss 1.55318  validloss 1.11886±0.00000  bestvalidloss 1.11579  last_update 34\n",
      "train: iter 238  trainloss 1.53105  validloss 1.12286±0.00000  bestvalidloss 1.11579  last_update 35\n",
      "train: iter 239  trainloss 1.54749  validloss 1.12158±0.00000  bestvalidloss 1.11579  last_update 36\n",
      "train: iter 240  trainloss 1.53679  validloss 1.12483±0.00000  bestvalidloss 1.11579  last_update 37\n",
      "train: iter 241  trainloss 1.55199  validloss 1.12155±0.00000  bestvalidloss 1.11579  last_update 38\n",
      "train: iter 242  trainloss 1.55047  validloss 1.12716±0.00000  bestvalidloss 1.11579  last_update 39\n",
      "train: iter 243  trainloss 1.54421  validloss 1.12494±0.00000  bestvalidloss 1.11579  last_update 40\n",
      "train: iter 244  trainloss 1.54114  validloss 1.12474±0.00000  bestvalidloss 1.11579  last_update 41\n",
      "train: iter 245  trainloss 1.53134  validloss 1.12776±0.00000  bestvalidloss 1.11579  last_update 42\n",
      "train: iter 246  trainloss 1.55881  validloss 1.12434±0.00000  bestvalidloss 1.11579  last_update 43\n",
      "train: iter 247  trainloss 1.52873  validloss 1.12356±0.00000  bestvalidloss 1.11579  last_update 44\n",
      "train: iter 248  trainloss 1.53475  validloss 1.12121±0.00000  bestvalidloss 1.11579  last_update 45\n",
      "train: iter 249  trainloss 1.52702  validloss 1.12221±0.00000  bestvalidloss 1.11579  last_update 46\n",
      "train: iter 250  trainloss 1.53773  validloss 1.12212±0.00000  bestvalidloss 1.11579  last_update 47\n",
      "train: iter 251  trainloss 1.55568  validloss 1.12007±0.00000  bestvalidloss 1.11579  last_update 48\n",
      "train: iter 252  trainloss 1.54418  validloss 1.12573±0.00000  bestvalidloss 1.11579  last_update 49\n",
      "train: iter 253  trainloss 1.54271  validloss 1.11885±0.00000  bestvalidloss 1.11579  last_update 50\n",
      "train: iter 254  trainloss 1.54506  validloss 1.12516±0.00000  bestvalidloss 1.11579  last_update 51\n",
      "train: iter 255  trainloss 1.53269  validloss 1.12301±0.00000  bestvalidloss 1.11579  last_update 52\n",
      "train: iter 256  trainloss 1.53221  validloss 1.12304±0.00000  bestvalidloss 1.11579  last_update 53\n",
      "train: iter 257  trainloss 1.54183  validloss 1.12122±0.00000  bestvalidloss 1.11579  last_update 54\n",
      "train: iter 258  trainloss 1.54126  validloss 1.12207±0.00000  bestvalidloss 1.11579  last_update 55\n",
      "train: iter 259  trainloss 1.53212  validloss 1.12412±0.00000  bestvalidloss 1.11579  last_update 56\n",
      "train: iter 260  trainloss 1.55273  validloss 1.12328±0.00000  bestvalidloss 1.11579  last_update 57\n",
      "train: iter 261  trainloss 1.53911  validloss 1.12473±0.00000  bestvalidloss 1.11579  last_update 58\n",
      "train: iter 262  trainloss 1.54627  validloss 1.12352±0.00000  bestvalidloss 1.11579  last_update 59\n",
      "train: iter 263  trainloss 1.52889  validloss 1.11724±0.00000  bestvalidloss 1.11579  last_update 60\n",
      "train: iter 264  trainloss 1.56033  validloss 1.11773±0.00000  bestvalidloss 1.11579  last_update 61\n",
      "train: iter 265  trainloss 1.53650  validloss 1.12063±0.00000  bestvalidloss 1.11579  last_update 62\n",
      "train: iter 266  trainloss 1.52973  validloss 1.12213±0.00000  bestvalidloss 1.11579  last_update 63\n",
      "train: iter 267  trainloss 1.54101  validloss 1.11838±0.00000  bestvalidloss 1.11579  last_update 64\n",
      "train: iter 268  trainloss 1.53619  validloss 1.11844±0.00000  bestvalidloss 1.11579  last_update 65\n",
      "train: iter 269  trainloss 1.54603  validloss 1.12126±0.00000  bestvalidloss 1.11579  last_update 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 270  trainloss 1.54011  validloss 1.12155±0.00000  bestvalidloss 1.11579  last_update 67\n",
      "train: iter 271  trainloss 1.53322  validloss 1.12129±0.00000  bestvalidloss 1.11579  last_update 68\n",
      "train: iter 272  trainloss 1.54204  validloss 1.12061±0.00000  bestvalidloss 1.11579  last_update 69\n",
      "train: iter 273  trainloss 1.54606  validloss 1.12223±0.00000  bestvalidloss 1.11579  last_update 70\n",
      "train: iter 274  trainloss 1.52325  validloss 1.12401±0.00000  bestvalidloss 1.11579  last_update 71\n",
      "train: iter 275  trainloss 1.53779  validloss 1.11974±0.00000  bestvalidloss 1.11579  last_update 72\n",
      "train: iter 276  trainloss 1.53143  validloss 1.11956±0.00000  bestvalidloss 1.11579  last_update 73\n",
      "train: iter 277  trainloss 1.54665  validloss 1.11688±0.00000  bestvalidloss 1.11579  last_update 74\n",
      "train: iter 278  trainloss 1.54474  validloss 1.11699±0.00000  bestvalidloss 1.11579  last_update 75\n",
      "train: iter 279  trainloss 1.53902  validloss 1.12336±0.00000  bestvalidloss 1.11579  last_update 76\n",
      "train: iter 280  trainloss 1.54214  validloss 1.12176±0.00000  bestvalidloss 1.11579  last_update 77\n",
      "train: iter 281  trainloss 1.54953  validloss 1.12100±0.00000  bestvalidloss 1.11579  last_update 78\n",
      "train: iter 282  trainloss 1.54738  validloss 1.12315±0.00000  bestvalidloss 1.11579  last_update 79\n",
      "train: iter 283  trainloss 1.54962  validloss 1.12007±0.00000  bestvalidloss 1.11579  last_update 80\n",
      "train: iter 284  trainloss 1.54333  validloss 1.12151±0.00000  bestvalidloss 1.11579  last_update 81\n",
      "train: iter 285  trainloss 1.54983  validloss 1.12272±0.00000  bestvalidloss 1.11579  last_update 82\n",
      "train: iter 286  trainloss 1.54516  validloss 1.12347±0.00000  bestvalidloss 1.11579  last_update 83\n",
      "train: iter 287  trainloss 1.53405  validloss 1.11765±0.00000  bestvalidloss 1.11579  last_update 84\n",
      "train: iter 288  trainloss 1.54405  validloss 1.12236±0.00000  bestvalidloss 1.11579  last_update 85\n",
      "train: iter 289  trainloss 1.53799  validloss 1.12119±0.00000  bestvalidloss 1.11579  last_update 86\n",
      "train: iter 290  trainloss 1.55258  validloss 1.11786±0.00000  bestvalidloss 1.11579  last_update 87\n",
      "train: iter 291  trainloss 1.53922  validloss 1.12567±0.00000  bestvalidloss 1.11579  last_update 88\n",
      "train: iter 292  trainloss 1.54004  validloss 1.12196±0.00000  bestvalidloss 1.11579  last_update 89\n",
      "train: iter 293  trainloss 1.54109  validloss 1.12337±0.00000  bestvalidloss 1.11579  last_update 90\n",
      "train: iter 294  trainloss 1.54872  validloss 1.12234±0.00000  bestvalidloss 1.11579  last_update 91\n",
      "train: iter 295  trainloss 1.54100  validloss 1.12154±0.00000  bestvalidloss 1.11579  last_update 92\n",
      "train: iter 296  trainloss 1.53932  validloss 1.11968±0.00000  bestvalidloss 1.11579  last_update 93\n",
      "train: iter 297  trainloss 1.53798  validloss 1.12030±0.00000  bestvalidloss 1.11579  last_update 94\n",
      "train: iter 298  trainloss 1.54301  validloss 1.12029±0.00000  bestvalidloss 1.11579  last_update 95\n",
      "train: iter 299  trainloss 1.55967  validloss 1.12391±0.00000  bestvalidloss 1.11579  last_update 96\n",
      "train: iter 300  trainloss 1.53993  validloss 1.12194±0.00000  bestvalidloss 1.11579  last_update 97\n",
      "train: iter 301  trainloss 1.54781  validloss 1.12581±0.00000  bestvalidloss 1.11579  last_update 98\n",
      "train: iter 302  trainloss 1.53486  validloss 1.12104±0.00000  bestvalidloss 1.11579  last_update 99\n",
      "train: iter 303  trainloss 1.54661  validloss 1.12151±0.00000  bestvalidloss 1.11579  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-4.1829,  0.2425], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 15.73258  validloss 23.75995±0.00000  bestvalidloss 23.75995  last_update 0\n",
      "train: iter 1  trainloss 10.04231  validloss 15.86321±0.00000  bestvalidloss 15.86321  last_update 0\n",
      "train: iter 2  trainloss 6.68247  validloss 9.42719±0.00000  bestvalidloss 9.42719  last_update 0\n",
      "train: iter 3  trainloss 5.50495  validloss 5.94633±0.00000  bestvalidloss 5.94633  last_update 0\n",
      "train: iter 4  trainloss 4.90360  validloss 4.86731±0.00000  bestvalidloss 4.86731  last_update 0\n",
      "train: iter 5  trainloss 4.65234  validloss 4.20493±0.00000  bestvalidloss 4.20493  last_update 0\n",
      "train: iter 6  trainloss 4.54244  validloss 3.82237±0.00000  bestvalidloss 3.82237  last_update 0\n",
      "train: iter 7  trainloss 4.32359  validloss 3.87698±0.00000  bestvalidloss 3.82237  last_update 1\n",
      "train: iter 8  trainloss 4.30722  validloss 3.58195±0.00000  bestvalidloss 3.58195  last_update 0\n",
      "train: iter 9  trainloss 4.16052  validloss 3.55931±0.00000  bestvalidloss 3.55931  last_update 0\n",
      "train: iter 10  trainloss 3.94761  validloss 3.81690±0.00000  bestvalidloss 3.55931  last_update 1\n",
      "train: iter 11  trainloss 3.65095  validloss 3.20070±0.00000  bestvalidloss 3.20070  last_update 0\n",
      "train: iter 12  trainloss 3.27727  validloss 3.69410±0.00000  bestvalidloss 3.20070  last_update 1\n",
      "train: iter 13  trainloss 2.93256  validloss 3.61247±0.00000  bestvalidloss 3.20070  last_update 2\n",
      "train: iter 14  trainloss 2.65307  validloss 3.09205±0.00000  bestvalidloss 3.09205  last_update 0\n",
      "train: iter 15  trainloss 2.51763  validloss 3.05710±0.00000  bestvalidloss 3.05710  last_update 0\n",
      "train: iter 16  trainloss 2.47863  validloss 3.08246±0.00000  bestvalidloss 3.05710  last_update 1\n",
      "train: iter 17  trainloss 2.49183  validloss 2.96297±0.00000  bestvalidloss 2.96297  last_update 0\n",
      "train: iter 18  trainloss 2.55344  validloss 2.87678±0.00000  bestvalidloss 2.87678  last_update 0\n",
      "train: iter 19  trainloss 2.48011  validloss 2.85181±0.00000  bestvalidloss 2.85181  last_update 0\n",
      "train: iter 20  trainloss 2.45499  validloss 3.14559±0.00000  bestvalidloss 2.85181  last_update 1\n",
      "train: iter 21  trainloss 2.56530  validloss 2.99337±0.00000  bestvalidloss 2.85181  last_update 2\n",
      "train: iter 22  trainloss 2.55604  validloss 3.27502±0.00000  bestvalidloss 2.85181  last_update 3\n",
      "train: iter 23  trainloss 2.46984  validloss 3.27411±0.00000  bestvalidloss 2.85181  last_update 4\n",
      "train: iter 24  trainloss 2.47987  validloss 2.98670±0.00000  bestvalidloss 2.85181  last_update 5\n",
      "train: iter 25  trainloss 2.48563  validloss 3.04041±0.00000  bestvalidloss 2.85181  last_update 6\n",
      "train: iter 26  trainloss 2.51816  validloss 2.82438±0.00000  bestvalidloss 2.82438  last_update 0\n",
      "train: iter 27  trainloss 2.64289  validloss 2.92015±0.00000  bestvalidloss 2.82438  last_update 1\n",
      "train: iter 28  trainloss 2.50727  validloss 3.44802±0.00000  bestvalidloss 2.82438  last_update 2\n",
      "train: iter 29  trainloss 2.55250  validloss 3.40617±0.00000  bestvalidloss 2.82438  last_update 3\n",
      "train: iter 30  trainloss 2.51462  validloss 2.79888±0.00000  bestvalidloss 2.79888  last_update 0\n",
      "train: iter 31  trainloss 2.43790  validloss 3.18449±0.00000  bestvalidloss 2.79888  last_update 1\n",
      "train: iter 32  trainloss 2.47176  validloss 2.77007±0.00000  bestvalidloss 2.77007  last_update 0\n",
      "train: iter 33  trainloss 2.51914  validloss 3.49042±0.00000  bestvalidloss 2.77007  last_update 1\n",
      "train: iter 34  trainloss 2.56431  validloss 3.04998±0.00000  bestvalidloss 2.77007  last_update 2\n",
      "train: iter 35  trainloss 2.63367  validloss 2.88479±0.00000  bestvalidloss 2.77007  last_update 3\n",
      "train: iter 36  trainloss 2.46978  validloss 3.23115±0.00000  bestvalidloss 2.77007  last_update 4\n",
      "train: iter 37  trainloss 2.51656  validloss 2.99840±0.00000  bestvalidloss 2.77007  last_update 5\n",
      "train: iter 38  trainloss 2.54835  validloss 2.92827±0.00000  bestvalidloss 2.77007  last_update 6\n",
      "train: iter 39  trainloss 2.49327  validloss 2.83308±0.00000  bestvalidloss 2.77007  last_update 7\n",
      "train: iter 40  trainloss 2.47425  validloss 2.78161±0.00000  bestvalidloss 2.77007  last_update 8\n",
      "train: iter 41  trainloss 2.54135  validloss 3.09816±0.00000  bestvalidloss 2.77007  last_update 9\n",
      "train: iter 42  trainloss 2.53532  validloss 3.07890±0.00000  bestvalidloss 2.77007  last_update 10\n",
      "train: iter 43  trainloss 2.59225  validloss 3.01392±0.00000  bestvalidloss 2.77007  last_update 11\n",
      "train: iter 44  trainloss 2.47059  validloss 3.14521±0.00000  bestvalidloss 2.77007  last_update 12\n",
      "train: iter 45  trainloss 2.46608  validloss 2.95896±0.00000  bestvalidloss 2.77007  last_update 13\n",
      "train: iter 46  trainloss 2.53187  validloss 2.99377±0.00000  bestvalidloss 2.77007  last_update 14\n",
      "train: iter 47  trainloss 2.55104  validloss 2.95926±0.00000  bestvalidloss 2.77007  last_update 15\n",
      "train: iter 48  trainloss 2.43911  validloss 3.39614±0.00000  bestvalidloss 2.77007  last_update 16\n",
      "train: iter 49  trainloss 2.41340  validloss 3.40378±0.00000  bestvalidloss 2.77007  last_update 17\n",
      "train: iter 50  trainloss 2.47972  validloss 2.92256±0.00000  bestvalidloss 2.77007  last_update 18\n",
      "train: iter 51  trainloss 2.50609  validloss 3.00895±0.00000  bestvalidloss 2.77007  last_update 19\n",
      "train: iter 52  trainloss 2.63403  validloss 3.20754±0.00000  bestvalidloss 2.77007  last_update 20\n",
      "train: iter 53  trainloss 2.43306  validloss 3.03500±0.00000  bestvalidloss 2.77007  last_update 21\n",
      "train: iter 54  trainloss 2.64467  validloss 3.22413±0.00000  bestvalidloss 2.77007  last_update 22\n",
      "train: iter 55  trainloss 2.52958  validloss 2.98541±0.00000  bestvalidloss 2.77007  last_update 23\n",
      "train: iter 56  trainloss 2.39937  validloss 2.99705±0.00000  bestvalidloss 2.77007  last_update 24\n",
      "train: iter 57  trainloss 2.52443  validloss 3.05339±0.00000  bestvalidloss 2.77007  last_update 25\n",
      "train: iter 58  trainloss 2.51738  validloss 2.76156±0.00000  bestvalidloss 2.76156  last_update 0\n",
      "train: iter 59  trainloss 2.47723  validloss 3.33583±0.00000  bestvalidloss 2.76156  last_update 1\n",
      "train: iter 60  trainloss 2.42656  validloss 3.25663±0.00000  bestvalidloss 2.76156  last_update 2\n",
      "train: iter 61  trainloss 2.47534  validloss 3.21900±0.00000  bestvalidloss 2.76156  last_update 3\n",
      "train: iter 62  trainloss 2.49670  validloss 3.19509±0.00000  bestvalidloss 2.76156  last_update 4\n",
      "train: iter 63  trainloss 2.44748  validloss 3.19853±0.00000  bestvalidloss 2.76156  last_update 5\n",
      "train: iter 64  trainloss 2.49189  validloss 3.21563±0.00000  bestvalidloss 2.76156  last_update 6\n",
      "train: iter 65  trainloss 2.46990  validloss 3.26863±0.00000  bestvalidloss 2.76156  last_update 7\n",
      "train: iter 66  trainloss 2.50826  validloss 2.96591±0.00000  bestvalidloss 2.76156  last_update 8\n",
      "train: iter 67  trainloss 2.46681  validloss 3.26231±0.00000  bestvalidloss 2.76156  last_update 9\n",
      "train: iter 68  trainloss 2.41865  validloss 3.33344±0.00000  bestvalidloss 2.76156  last_update 10\n",
      "train: iter 69  trainloss 2.50941  validloss 2.87327±0.00000  bestvalidloss 2.76156  last_update 11\n",
      "train: iter 70  trainloss 2.38445  validloss 2.95704±0.00000  bestvalidloss 2.76156  last_update 12\n",
      "train: iter 71  trainloss 2.50595  validloss 3.15133±0.00000  bestvalidloss 2.76156  last_update 13\n",
      "train: iter 72  trainloss 2.47237  validloss 3.27456±0.00000  bestvalidloss 2.76156  last_update 14\n",
      "train: iter 73  trainloss 2.46196  validloss 3.08985±0.00000  bestvalidloss 2.76156  last_update 15\n",
      "train: iter 74  trainloss 2.47248  validloss 2.79703±0.00000  bestvalidloss 2.76156  last_update 16\n",
      "train: iter 75  trainloss 2.48849  validloss 3.12599±0.00000  bestvalidloss 2.76156  last_update 17\n",
      "train: iter 76  trainloss 2.52214  validloss 2.83896±0.00000  bestvalidloss 2.76156  last_update 18\n",
      "train: iter 77  trainloss 2.60597  validloss 3.12352±0.00000  bestvalidloss 2.76156  last_update 19\n",
      "train: iter 78  trainloss 2.42710  validloss 3.28645±0.00000  bestvalidloss 2.76156  last_update 20\n",
      "train: iter 79  trainloss 2.50379  validloss 2.72548±0.00000  bestvalidloss 2.72548  last_update 0\n",
      "train: iter 80  trainloss 2.43771  validloss 3.37284±0.00000  bestvalidloss 2.72548  last_update 1\n",
      "train: iter 81  trainloss 2.50803  validloss 2.89093±0.00000  bestvalidloss 2.72548  last_update 2\n",
      "train: iter 82  trainloss 2.49495  validloss 3.09568±0.00000  bestvalidloss 2.72548  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 2.46155  validloss 3.20628±0.00000  bestvalidloss 2.72548  last_update 4\n",
      "train: iter 84  trainloss 2.53073  validloss 2.91963±0.00000  bestvalidloss 2.72548  last_update 5\n",
      "train: iter 85  trainloss 2.43713  validloss 2.84314±0.00000  bestvalidloss 2.72548  last_update 6\n",
      "train: iter 86  trainloss 2.45264  validloss 3.47439±0.00000  bestvalidloss 2.72548  last_update 7\n",
      "train: iter 87  trainloss 2.37106  validloss 3.39459±0.00000  bestvalidloss 2.72548  last_update 8\n",
      "train: iter 88  trainloss 2.41645  validloss 3.02813±0.00000  bestvalidloss 2.72548  last_update 9\n",
      "train: iter 89  trainloss 2.61227  validloss 3.22677±0.00000  bestvalidloss 2.72548  last_update 10\n",
      "train: iter 90  trainloss 2.59235  validloss 2.97373±0.00000  bestvalidloss 2.72548  last_update 11\n",
      "train: iter 91  trainloss 2.47271  validloss 2.61041±0.00000  bestvalidloss 2.61041  last_update 0\n",
      "train: iter 92  trainloss 2.47274  validloss 3.59866±0.00000  bestvalidloss 2.61041  last_update 1\n",
      "train: iter 93  trainloss 2.51496  validloss 2.86558±0.00000  bestvalidloss 2.61041  last_update 2\n",
      "train: iter 94  trainloss 2.55983  validloss 2.94226±0.00000  bestvalidloss 2.61041  last_update 3\n",
      "train: iter 95  trainloss 2.52995  validloss 3.17140±0.00000  bestvalidloss 2.61041  last_update 4\n",
      "train: iter 96  trainloss 2.55017  validloss 2.99398±0.00000  bestvalidloss 2.61041  last_update 5\n",
      "train: iter 97  trainloss 2.54594  validloss 2.86506±0.00000  bestvalidloss 2.61041  last_update 6\n",
      "train: iter 98  trainloss 2.52936  validloss 3.30211±0.00000  bestvalidloss 2.61041  last_update 7\n",
      "train: iter 99  trainloss 2.50412  validloss 2.82256±0.00000  bestvalidloss 2.61041  last_update 8\n",
      "train: iter 100  trainloss 2.55728  validloss 2.75744±0.00000  bestvalidloss 2.61041  last_update 9\n",
      "train: iter 101  trainloss 2.54493  validloss 3.04297±0.00000  bestvalidloss 2.61041  last_update 10\n",
      "train: iter 102  trainloss 2.56618  validloss 3.03303±0.00000  bestvalidloss 2.61041  last_update 11\n",
      "train: iter 103  trainloss 2.47765  validloss 2.77846±0.00000  bestvalidloss 2.61041  last_update 12\n",
      "train: iter 104  trainloss 2.50196  validloss 3.06855±0.00000  bestvalidloss 2.61041  last_update 13\n",
      "train: iter 105  trainloss 2.46869  validloss 3.27273±0.00000  bestvalidloss 2.61041  last_update 14\n",
      "train: iter 106  trainloss 2.56646  validloss 2.93528±0.00000  bestvalidloss 2.61041  last_update 15\n",
      "train: iter 107  trainloss 2.46226  validloss 2.84783±0.00000  bestvalidloss 2.61041  last_update 16\n",
      "train: iter 108  trainloss 2.48267  validloss 3.26582±0.00000  bestvalidloss 2.61041  last_update 17\n",
      "train: iter 109  trainloss 2.49979  validloss 2.88325±0.00000  bestvalidloss 2.61041  last_update 18\n",
      "train: iter 110  trainloss 2.42203  validloss 2.72007±0.00000  bestvalidloss 2.61041  last_update 19\n",
      "train: iter 111  trainloss 2.38926  validloss 2.78861±0.00000  bestvalidloss 2.61041  last_update 20\n",
      "train: iter 112  trainloss 2.42885  validloss 2.94182±0.00000  bestvalidloss 2.61041  last_update 21\n",
      "train: iter 113  trainloss 2.45658  validloss 3.03515±0.00000  bestvalidloss 2.61041  last_update 22\n",
      "train: iter 114  trainloss 2.57610  validloss 3.26394±0.00000  bestvalidloss 2.61041  last_update 23\n",
      "train: iter 115  trainloss 2.58912  validloss 2.62542±0.00000  bestvalidloss 2.61041  last_update 24\n",
      "train: iter 116  trainloss 2.57117  validloss 2.69722±0.00000  bestvalidloss 2.61041  last_update 25\n",
      "train: iter 117  trainloss 2.56530  validloss 3.44217±0.00000  bestvalidloss 2.61041  last_update 26\n",
      "train: iter 118  trainloss 2.59350  validloss 3.12319±0.00000  bestvalidloss 2.61041  last_update 27\n",
      "train: iter 119  trainloss 2.45555  validloss 2.92220±0.00000  bestvalidloss 2.61041  last_update 28\n",
      "train: iter 120  trainloss 2.45206  validloss 3.04209±0.00000  bestvalidloss 2.61041  last_update 29\n",
      "train: iter 121  trainloss 2.41838  validloss 2.70120±0.00000  bestvalidloss 2.61041  last_update 30\n",
      "train: iter 122  trainloss 2.41163  validloss 3.18233±0.00000  bestvalidloss 2.61041  last_update 31\n",
      "train: iter 123  trainloss 2.53159  validloss 3.47260±0.00000  bestvalidloss 2.61041  last_update 32\n",
      "train: iter 124  trainloss 2.50406  validloss 3.21118±0.00000  bestvalidloss 2.61041  last_update 33\n",
      "train: iter 125  trainloss 2.58471  validloss 3.05682±0.00000  bestvalidloss 2.61041  last_update 34\n",
      "train: iter 126  trainloss 2.48783  validloss 3.20032±0.00000  bestvalidloss 2.61041  last_update 35\n",
      "train: iter 127  trainloss 2.57671  validloss 3.44534±0.00000  bestvalidloss 2.61041  last_update 36\n",
      "train: iter 128  trainloss 2.46934  validloss 3.09947±0.00000  bestvalidloss 2.61041  last_update 37\n",
      "train: iter 129  trainloss 2.45372  validloss 3.06621±0.00000  bestvalidloss 2.61041  last_update 38\n",
      "train: iter 130  trainloss 2.42558  validloss 3.26540±0.00000  bestvalidloss 2.61041  last_update 39\n",
      "train: iter 131  trainloss 2.42941  validloss 3.06259±0.00000  bestvalidloss 2.61041  last_update 40\n",
      "train: iter 132  trainloss 2.61197  validloss 3.06351±0.00000  bestvalidloss 2.61041  last_update 41\n",
      "train: iter 133  trainloss 2.44644  validloss 3.21467±0.00000  bestvalidloss 2.61041  last_update 42\n",
      "train: iter 134  trainloss 2.44700  validloss 3.03595±0.00000  bestvalidloss 2.61041  last_update 43\n",
      "train: iter 135  trainloss 2.43626  validloss 3.05527±0.00000  bestvalidloss 2.61041  last_update 44\n",
      "train: iter 136  trainloss 2.44808  validloss 3.27229±0.00000  bestvalidloss 2.61041  last_update 45\n",
      "train: iter 137  trainloss 2.46391  validloss 2.90257±0.00000  bestvalidloss 2.61041  last_update 46\n",
      "train: iter 138  trainloss 2.44082  validloss 3.00628±0.00000  bestvalidloss 2.61041  last_update 47\n",
      "train: iter 139  trainloss 2.50278  validloss 2.98307±0.00000  bestvalidloss 2.61041  last_update 48\n",
      "train: iter 140  trainloss 2.47038  validloss 2.99992±0.00000  bestvalidloss 2.61041  last_update 49\n",
      "train: iter 141  trainloss 2.56060  validloss 3.19343±0.00000  bestvalidloss 2.61041  last_update 50\n",
      "train: iter 142  trainloss 2.52407  validloss 3.28092±0.00000  bestvalidloss 2.61041  last_update 51\n",
      "train: iter 143  trainloss 2.47135  validloss 3.39815±0.00000  bestvalidloss 2.61041  last_update 52\n",
      "train: iter 144  trainloss 2.46289  validloss 3.23960±0.00000  bestvalidloss 2.61041  last_update 53\n",
      "train: iter 145  trainloss 2.59010  validloss 2.93482±0.00000  bestvalidloss 2.61041  last_update 54\n",
      "train: iter 146  trainloss 2.56496  validloss 3.58655±0.00000  bestvalidloss 2.61041  last_update 55\n",
      "train: iter 147  trainloss 2.39789  validloss 3.25609±0.00000  bestvalidloss 2.61041  last_update 56\n",
      "train: iter 148  trainloss 2.46086  validloss 3.52865±0.00000  bestvalidloss 2.61041  last_update 57\n",
      "train: iter 149  trainloss 2.51409  validloss 3.03998±0.00000  bestvalidloss 2.61041  last_update 58\n",
      "train: iter 150  trainloss 2.48605  validloss 2.89016±0.00000  bestvalidloss 2.61041  last_update 59\n",
      "train: iter 151  trainloss 2.47700  validloss 3.38179±0.00000  bestvalidloss 2.61041  last_update 60\n",
      "train: iter 152  trainloss 2.36864  validloss 2.92135±0.00000  bestvalidloss 2.61041  last_update 61\n",
      "train: iter 153  trainloss 2.51608  validloss 3.01110±0.00000  bestvalidloss 2.61041  last_update 62\n",
      "train: iter 154  trainloss 2.58549  validloss 3.08038±0.00000  bestvalidloss 2.61041  last_update 63\n",
      "train: iter 155  trainloss 2.43810  validloss 2.89566±0.00000  bestvalidloss 2.61041  last_update 64\n",
      "train: iter 156  trainloss 2.42950  validloss 2.89907±0.00000  bestvalidloss 2.61041  last_update 65\n",
      "train: iter 157  trainloss 2.39162  validloss 2.70940±0.00000  bestvalidloss 2.61041  last_update 66\n",
      "train: iter 158  trainloss 2.47271  validloss 2.60150±0.00000  bestvalidloss 2.60150  last_update 0\n",
      "train: iter 159  trainloss 2.48363  validloss 2.77271±0.00000  bestvalidloss 2.60150  last_update 1\n",
      "train: iter 160  trainloss 2.51672  validloss 2.76258±0.00000  bestvalidloss 2.60150  last_update 2\n",
      "train: iter 161  trainloss 2.56442  validloss 3.31804±0.00000  bestvalidloss 2.60150  last_update 3\n",
      "train: iter 162  trainloss 2.52901  validloss 2.97277±0.00000  bestvalidloss 2.60150  last_update 4\n",
      "train: iter 163  trainloss 2.64368  validloss 3.03006±0.00000  bestvalidloss 2.60150  last_update 5\n",
      "train: iter 164  trainloss 2.43855  validloss 3.18094±0.00000  bestvalidloss 2.60150  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 165  trainloss 2.49363  validloss 3.11321±0.00000  bestvalidloss 2.60150  last_update 7\n",
      "train: iter 166  trainloss 2.48847  validloss 3.37751±0.00000  bestvalidloss 2.60150  last_update 8\n",
      "train: iter 167  trainloss 2.54428  validloss 2.89522±0.00000  bestvalidloss 2.60150  last_update 9\n",
      "train: iter 168  trainloss 2.53064  validloss 3.49822±0.00000  bestvalidloss 2.60150  last_update 10\n",
      "train: iter 169  trainloss 2.49378  validloss 2.54001±0.00000  bestvalidloss 2.54001  last_update 0\n",
      "train: iter 170  trainloss 2.42952  validloss 3.05715±0.00000  bestvalidloss 2.54001  last_update 1\n",
      "train: iter 171  trainloss 2.51609  validloss 3.44856±0.00000  bestvalidloss 2.54001  last_update 2\n",
      "train: iter 172  trainloss 2.52398  validloss 2.90705±0.00000  bestvalidloss 2.54001  last_update 3\n",
      "train: iter 173  trainloss 2.43436  validloss 3.15647±0.00000  bestvalidloss 2.54001  last_update 4\n",
      "train: iter 174  trainloss 2.41046  validloss 3.03821±0.00000  bestvalidloss 2.54001  last_update 5\n",
      "train: iter 175  trainloss 2.55712  validloss 3.03021±0.00000  bestvalidloss 2.54001  last_update 6\n",
      "train: iter 176  trainloss 2.48484  validloss 3.33400±0.00000  bestvalidloss 2.54001  last_update 7\n",
      "train: iter 177  trainloss 2.43663  validloss 3.37677±0.00000  bestvalidloss 2.54001  last_update 8\n",
      "train: iter 178  trainloss 2.49383  validloss 3.16721±0.00000  bestvalidloss 2.54001  last_update 9\n",
      "train: iter 179  trainloss 2.52262  validloss 3.04610±0.00000  bestvalidloss 2.54001  last_update 10\n",
      "train: iter 180  trainloss 2.47550  validloss 3.44273±0.00000  bestvalidloss 2.54001  last_update 11\n",
      "train: iter 181  trainloss 2.44160  validloss 2.78564±0.00000  bestvalidloss 2.54001  last_update 12\n",
      "train: iter 182  trainloss 2.61089  validloss 3.29023±0.00000  bestvalidloss 2.54001  last_update 13\n",
      "train: iter 183  trainloss 2.51924  validloss 3.36798±0.00000  bestvalidloss 2.54001  last_update 14\n",
      "train: iter 184  trainloss 2.57193  validloss 3.10564±0.00000  bestvalidloss 2.54001  last_update 15\n",
      "train: iter 185  trainloss 2.40991  validloss 3.22934±0.00000  bestvalidloss 2.54001  last_update 16\n",
      "train: iter 186  trainloss 2.41166  validloss 2.90604±0.00000  bestvalidloss 2.54001  last_update 17\n",
      "train: iter 187  trainloss 2.44433  validloss 3.29234±0.00000  bestvalidloss 2.54001  last_update 18\n",
      "train: iter 188  trainloss 2.47844  validloss 2.78007±0.00000  bestvalidloss 2.54001  last_update 19\n",
      "train: iter 189  trainloss 2.48063  validloss 3.34277±0.00000  bestvalidloss 2.54001  last_update 20\n",
      "train: iter 190  trainloss 2.54519  validloss 3.13656±0.00000  bestvalidloss 2.54001  last_update 21\n",
      "train: iter 191  trainloss 2.43424  validloss 3.39307±0.00000  bestvalidloss 2.54001  last_update 22\n",
      "train: iter 192  trainloss 2.46855  validloss 3.08530±0.00000  bestvalidloss 2.54001  last_update 23\n",
      "train: iter 193  trainloss 2.44047  validloss 2.66047±0.00000  bestvalidloss 2.54001  last_update 24\n",
      "train: iter 194  trainloss 2.52740  validloss 2.98376±0.00000  bestvalidloss 2.54001  last_update 25\n",
      "train: iter 195  trainloss 2.43214  validloss 2.70195±0.00000  bestvalidloss 2.54001  last_update 26\n",
      "train: iter 196  trainloss 2.41657  validloss 3.09260±0.00000  bestvalidloss 2.54001  last_update 27\n",
      "train: iter 197  trainloss 2.47662  validloss 2.84925±0.00000  bestvalidloss 2.54001  last_update 28\n",
      "train: iter 198  trainloss 2.38933  validloss 2.78783±0.00000  bestvalidloss 2.54001  last_update 29\n",
      "train: iter 199  trainloss 2.47041  validloss 2.73906±0.00000  bestvalidloss 2.54001  last_update 30\n",
      "train: iter 200  trainloss 2.52282  validloss 3.02398±0.00000  bestvalidloss 2.54001  last_update 31\n",
      "train: iter 201  trainloss 2.41150  validloss 2.85865±0.00000  bestvalidloss 2.54001  last_update 32\n",
      "train: iter 202  trainloss 2.46153  validloss 2.82530±0.00000  bestvalidloss 2.54001  last_update 33\n",
      "train: iter 203  trainloss 2.57325  validloss 2.94478±0.00000  bestvalidloss 2.54001  last_update 34\n",
      "train: iter 204  trainloss 2.56202  validloss 3.12250±0.00000  bestvalidloss 2.54001  last_update 35\n",
      "train: iter 205  trainloss 2.41441  validloss 3.08384±0.00000  bestvalidloss 2.54001  last_update 36\n",
      "train: iter 206  trainloss 2.51288  validloss 2.91144±0.00000  bestvalidloss 2.54001  last_update 37\n",
      "train: iter 207  trainloss 2.49041  validloss 3.14046±0.00000  bestvalidloss 2.54001  last_update 38\n",
      "train: iter 208  trainloss 2.49252  validloss 2.98125±0.00000  bestvalidloss 2.54001  last_update 39\n",
      "train: iter 209  trainloss 2.59735  validloss 2.75085±0.00000  bestvalidloss 2.54001  last_update 40\n",
      "train: iter 210  trainloss 2.44197  validloss 3.23952±0.00000  bestvalidloss 2.54001  last_update 41\n",
      "train: iter 211  trainloss 2.43813  validloss 2.85198±0.00000  bestvalidloss 2.54001  last_update 42\n",
      "train: iter 212  trainloss 2.54797  validloss 2.93999±0.00000  bestvalidloss 2.54001  last_update 43\n",
      "train: iter 213  trainloss 2.46627  validloss 2.57635±0.00000  bestvalidloss 2.54001  last_update 44\n",
      "train: iter 214  trainloss 2.52527  validloss 3.28803±0.00000  bestvalidloss 2.54001  last_update 45\n",
      "train: iter 215  trainloss 2.48638  validloss 3.54958±0.00000  bestvalidloss 2.54001  last_update 46\n",
      "train: iter 216  trainloss 2.43348  validloss 3.31064±0.00000  bestvalidloss 2.54001  last_update 47\n",
      "train: iter 217  trainloss 2.50433  validloss 2.90170±0.00000  bestvalidloss 2.54001  last_update 48\n",
      "train: iter 218  trainloss 2.48236  validloss 3.37986±0.00000  bestvalidloss 2.54001  last_update 49\n",
      "train: iter 219  trainloss 2.50960  validloss 2.76333±0.00000  bestvalidloss 2.54001  last_update 50\n",
      "train: iter 220  trainloss 2.32531  validloss 2.84907±0.00000  bestvalidloss 2.54001  last_update 51\n",
      "train: iter 221  trainloss 2.46496  validloss 3.08002±0.00000  bestvalidloss 2.54001  last_update 52\n",
      "train: iter 222  trainloss 2.42414  validloss 2.67552±0.00000  bestvalidloss 2.54001  last_update 53\n",
      "train: iter 223  trainloss 2.46767  validloss 2.95338±0.00000  bestvalidloss 2.54001  last_update 54\n",
      "train: iter 224  trainloss 2.56937  validloss 3.03899±0.00000  bestvalidloss 2.54001  last_update 55\n",
      "train: iter 225  trainloss 2.53814  validloss 3.07997±0.00000  bestvalidloss 2.54001  last_update 56\n",
      "train: iter 226  trainloss 2.44793  validloss 2.89304±0.00000  bestvalidloss 2.54001  last_update 57\n",
      "train: iter 227  trainloss 2.49925  validloss 3.61867±0.00000  bestvalidloss 2.54001  last_update 58\n",
      "train: iter 228  trainloss 2.50542  validloss 3.02318±0.00000  bestvalidloss 2.54001  last_update 59\n",
      "train: iter 229  trainloss 2.50174  validloss 3.34951±0.00000  bestvalidloss 2.54001  last_update 60\n",
      "train: iter 230  trainloss 2.44416  validloss 3.26571±0.00000  bestvalidloss 2.54001  last_update 61\n",
      "train: iter 231  trainloss 2.42630  validloss 3.16730±0.00000  bestvalidloss 2.54001  last_update 62\n",
      "train: iter 232  trainloss 2.49168  validloss 2.78597±0.00000  bestvalidloss 2.54001  last_update 63\n",
      "train: iter 233  trainloss 2.48032  validloss 3.56362±0.00000  bestvalidloss 2.54001  last_update 64\n",
      "train: iter 234  trainloss 2.48474  validloss 3.22392±0.00000  bestvalidloss 2.54001  last_update 65\n",
      "train: iter 235  trainloss 2.41915  validloss 3.24949±0.00000  bestvalidloss 2.54001  last_update 66\n",
      "train: iter 236  trainloss 2.44059  validloss 3.46949±0.00000  bestvalidloss 2.54001  last_update 67\n",
      "train: iter 237  trainloss 2.46754  validloss 2.92907±0.00000  bestvalidloss 2.54001  last_update 68\n",
      "train: iter 238  trainloss 2.39856  validloss 2.47894±0.00000  bestvalidloss 2.47894  last_update 0\n",
      "train: iter 239  trainloss 2.49523  validloss 3.40519±0.00000  bestvalidloss 2.47894  last_update 1\n",
      "train: iter 240  trainloss 2.37962  validloss 2.78426±0.00000  bestvalidloss 2.47894  last_update 2\n",
      "train: iter 241  trainloss 2.34073  validloss 3.40688±0.00000  bestvalidloss 2.47894  last_update 3\n",
      "train: iter 242  trainloss 2.58556  validloss 2.90919±0.00000  bestvalidloss 2.47894  last_update 4\n",
      "train: iter 243  trainloss 2.40790  validloss 3.18171±0.00000  bestvalidloss 2.47894  last_update 5\n",
      "train: iter 244  trainloss 2.44301  validloss 2.85469±0.00000  bestvalidloss 2.47894  last_update 6\n",
      "train: iter 245  trainloss 2.52706  validloss 2.92046±0.00000  bestvalidloss 2.47894  last_update 7\n",
      "train: iter 246  trainloss 2.46071  validloss 2.57951±0.00000  bestvalidloss 2.47894  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 247  trainloss 2.54672  validloss 2.70180±0.00000  bestvalidloss 2.47894  last_update 9\n",
      "train: iter 248  trainloss 2.47734  validloss 2.67370±0.00000  bestvalidloss 2.47894  last_update 10\n",
      "train: iter 249  trainloss 2.44332  validloss 3.46695±0.00000  bestvalidloss 2.47894  last_update 11\n",
      "train: iter 250  trainloss 2.44295  validloss 3.23036±0.00000  bestvalidloss 2.47894  last_update 12\n",
      "train: iter 251  trainloss 2.47919  validloss 3.09009±0.00000  bestvalidloss 2.47894  last_update 13\n",
      "train: iter 252  trainloss 2.60222  validloss 3.24870±0.00000  bestvalidloss 2.47894  last_update 14\n",
      "train: iter 253  trainloss 2.49750  validloss 2.95452±0.00000  bestvalidloss 2.47894  last_update 15\n",
      "train: iter 254  trainloss 2.40437  validloss 2.98914±0.00000  bestvalidloss 2.47894  last_update 16\n",
      "train: iter 255  trainloss 2.50287  validloss 3.03192±0.00000  bestvalidloss 2.47894  last_update 17\n",
      "train: iter 256  trainloss 2.54810  validloss 2.98597±0.00000  bestvalidloss 2.47894  last_update 18\n",
      "train: iter 257  trainloss 2.58923  validloss 3.05656±0.00000  bestvalidloss 2.47894  last_update 19\n",
      "train: iter 258  trainloss 2.39983  validloss 2.92644±0.00000  bestvalidloss 2.47894  last_update 20\n",
      "train: iter 259  trainloss 2.58006  validloss 3.52412±0.00000  bestvalidloss 2.47894  last_update 21\n",
      "train: iter 260  trainloss 2.45337  validloss 3.17425±0.00000  bestvalidloss 2.47894  last_update 22\n",
      "train: iter 261  trainloss 2.44816  validloss 2.96161±0.00000  bestvalidloss 2.47894  last_update 23\n",
      "train: iter 262  trainloss 2.45022  validloss 3.02978±0.00000  bestvalidloss 2.47894  last_update 24\n",
      "train: iter 263  trainloss 2.37110  validloss 2.94158±0.00000  bestvalidloss 2.47894  last_update 25\n",
      "train: iter 264  trainloss 2.41014  validloss 2.73748±0.00000  bestvalidloss 2.47894  last_update 26\n",
      "train: iter 265  trainloss 2.44334  validloss 3.30837±0.00000  bestvalidloss 2.47894  last_update 27\n",
      "train: iter 266  trainloss 2.44000  validloss 2.66443±0.00000  bestvalidloss 2.47894  last_update 28\n",
      "train: iter 267  trainloss 2.42943  validloss 2.99553±0.00000  bestvalidloss 2.47894  last_update 29\n",
      "train: iter 268  trainloss 2.48539  validloss 3.27893±0.00000  bestvalidloss 2.47894  last_update 30\n",
      "train: iter 269  trainloss 2.49563  validloss 2.60989±0.00000  bestvalidloss 2.47894  last_update 31\n",
      "train: iter 270  trainloss 2.47666  validloss 3.19844±0.00000  bestvalidloss 2.47894  last_update 32\n",
      "train: iter 271  trainloss 2.54710  validloss 2.69344±0.00000  bestvalidloss 2.47894  last_update 33\n",
      "train: iter 272  trainloss 2.44203  validloss 3.07541±0.00000  bestvalidloss 2.47894  last_update 34\n",
      "train: iter 273  trainloss 2.44791  validloss 2.85259±0.00000  bestvalidloss 2.47894  last_update 35\n",
      "train: iter 274  trainloss 2.53935  validloss 3.15895±0.00000  bestvalidloss 2.47894  last_update 36\n",
      "train: iter 275  trainloss 2.45194  validloss 2.73801±0.00000  bestvalidloss 2.47894  last_update 37\n",
      "train: iter 276  trainloss 2.57217  validloss 3.06358±0.00000  bestvalidloss 2.47894  last_update 38\n",
      "train: iter 277  trainloss 2.44930  validloss 3.21273±0.00000  bestvalidloss 2.47894  last_update 39\n",
      "train: iter 278  trainloss 2.45494  validloss 2.95339±0.00000  bestvalidloss 2.47894  last_update 40\n",
      "train: iter 279  trainloss 2.49012  validloss 3.21378±0.00000  bestvalidloss 2.47894  last_update 41\n",
      "train: iter 280  trainloss 2.49525  validloss 3.17216±0.00000  bestvalidloss 2.47894  last_update 42\n",
      "train: iter 281  trainloss 2.44505  validloss 2.90648±0.00000  bestvalidloss 2.47894  last_update 43\n",
      "train: iter 282  trainloss 2.61362  validloss 3.34493±0.00000  bestvalidloss 2.47894  last_update 44\n",
      "train: iter 283  trainloss 2.53907  validloss 3.16575±0.00000  bestvalidloss 2.47894  last_update 45\n",
      "train: iter 284  trainloss 2.46123  validloss 3.19001±0.00000  bestvalidloss 2.47894  last_update 46\n",
      "train: iter 285  trainloss 2.44422  validloss 2.79293±0.00000  bestvalidloss 2.47894  last_update 47\n",
      "train: iter 286  trainloss 2.61259  validloss 2.87138±0.00000  bestvalidloss 2.47894  last_update 48\n",
      "train: iter 287  trainloss 2.55078  validloss 2.79434±0.00000  bestvalidloss 2.47894  last_update 49\n",
      "train: iter 288  trainloss 2.55294  validloss 3.06107±0.00000  bestvalidloss 2.47894  last_update 50\n",
      "train: iter 289  trainloss 2.44607  validloss 3.03194±0.00000  bestvalidloss 2.47894  last_update 51\n",
      "train: iter 290  trainloss 2.43514  validloss 3.22378±0.00000  bestvalidloss 2.47894  last_update 52\n",
      "train: iter 291  trainloss 2.37026  validloss 2.96761±0.00000  bestvalidloss 2.47894  last_update 53\n",
      "train: iter 292  trainloss 2.36193  validloss 3.01531±0.00000  bestvalidloss 2.47894  last_update 54\n",
      "train: iter 293  trainloss 2.44199  validloss 2.62252±0.00000  bestvalidloss 2.47894  last_update 55\n",
      "train: iter 294  trainloss 2.42888  validloss 3.06607±0.00000  bestvalidloss 2.47894  last_update 56\n",
      "train: iter 295  trainloss 2.42372  validloss 3.28790±0.00000  bestvalidloss 2.47894  last_update 57\n",
      "train: iter 296  trainloss 2.47327  validloss 3.04333±0.00000  bestvalidloss 2.47894  last_update 58\n",
      "train: iter 297  trainloss 2.50243  validloss 3.37181±0.00000  bestvalidloss 2.47894  last_update 59\n",
      "train: iter 298  trainloss 2.46008  validloss 3.36916±0.00000  bestvalidloss 2.47894  last_update 60\n",
      "train: iter 299  trainloss 2.45355  validloss 2.82638±0.00000  bestvalidloss 2.47894  last_update 61\n",
      "train: iter 300  trainloss 2.48968  validloss 3.85646±0.00000  bestvalidloss 2.47894  last_update 62\n",
      "train: iter 301  trainloss 2.41445  validloss 2.66539±0.00000  bestvalidloss 2.47894  last_update 63\n",
      "train: iter 302  trainloss 2.49361  validloss 3.00850±0.00000  bestvalidloss 2.47894  last_update 64\n",
      "train: iter 303  trainloss 2.45017  validloss 3.00406±0.00000  bestvalidloss 2.47894  last_update 65\n",
      "train: iter 304  trainloss 2.56931  validloss 3.21402±0.00000  bestvalidloss 2.47894  last_update 66\n",
      "train: iter 305  trainloss 2.40894  validloss 2.95265±0.00000  bestvalidloss 2.47894  last_update 67\n",
      "train: iter 306  trainloss 2.49522  validloss 3.33403±0.00000  bestvalidloss 2.47894  last_update 68\n",
      "train: iter 307  trainloss 2.45356  validloss 3.50271±0.00000  bestvalidloss 2.47894  last_update 69\n",
      "train: iter 308  trainloss 2.48264  validloss 2.95031±0.00000  bestvalidloss 2.47894  last_update 70\n",
      "train: iter 309  trainloss 2.52439  validloss 2.94415±0.00000  bestvalidloss 2.47894  last_update 71\n",
      "train: iter 310  trainloss 2.34174  validloss 2.94120±0.00000  bestvalidloss 2.47894  last_update 72\n",
      "train: iter 311  trainloss 2.40915  validloss 3.00276±0.00000  bestvalidloss 2.47894  last_update 73\n",
      "train: iter 312  trainloss 2.36377  validloss 2.73141±0.00000  bestvalidloss 2.47894  last_update 74\n",
      "train: iter 313  trainloss 2.45127  validloss 3.08054±0.00000  bestvalidloss 2.47894  last_update 75\n",
      "train: iter 314  trainloss 2.56767  validloss 2.96968±0.00000  bestvalidloss 2.47894  last_update 76\n",
      "train: iter 315  trainloss 2.38023  validloss 3.37571±0.00000  bestvalidloss 2.47894  last_update 77\n",
      "train: iter 316  trainloss 2.56680  validloss 3.15841±0.00000  bestvalidloss 2.47894  last_update 78\n",
      "train: iter 317  trainloss 2.57053  validloss 3.39361±0.00000  bestvalidloss 2.47894  last_update 79\n",
      "train: iter 318  trainloss 2.47879  validloss 3.36001±0.00000  bestvalidloss 2.47894  last_update 80\n",
      "train: iter 319  trainloss 2.35698  validloss 3.27646±0.00000  bestvalidloss 2.47894  last_update 81\n",
      "train: iter 320  trainloss 2.41715  validloss 2.83919±0.00000  bestvalidloss 2.47894  last_update 82\n",
      "train: iter 321  trainloss 2.50494  validloss 2.92013±0.00000  bestvalidloss 2.47894  last_update 83\n",
      "train: iter 322  trainloss 2.44248  validloss 2.81302±0.00000  bestvalidloss 2.47894  last_update 84\n",
      "train: iter 323  trainloss 2.40499  validloss 2.97987±0.00000  bestvalidloss 2.47894  last_update 85\n",
      "train: iter 324  trainloss 2.51493  validloss 2.91789±0.00000  bestvalidloss 2.47894  last_update 86\n",
      "train: iter 325  trainloss 2.40459  validloss 2.91351±0.00000  bestvalidloss 2.47894  last_update 87\n",
      "train: iter 326  trainloss 2.40148  validloss 2.50844±0.00000  bestvalidloss 2.47894  last_update 88\n",
      "train: iter 327  trainloss 2.37649  validloss 2.95334±0.00000  bestvalidloss 2.47894  last_update 89\n",
      "train: iter 328  trainloss 2.54221  validloss 3.05872±0.00000  bestvalidloss 2.47894  last_update 90\n",
      "train: iter 329  trainloss 2.44091  validloss 3.38385±0.00000  bestvalidloss 2.47894  last_update 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 330  trainloss 2.60322  validloss 3.56358±0.00000  bestvalidloss 2.47894  last_update 92\n",
      "train: iter 331  trainloss 2.47434  validloss 3.03713±0.00000  bestvalidloss 2.47894  last_update 93\n",
      "train: iter 332  trainloss 2.42186  validloss 2.98317±0.00000  bestvalidloss 2.47894  last_update 94\n",
      "train: iter 333  trainloss 2.36626  validloss 3.14814±0.00000  bestvalidloss 2.47894  last_update 95\n",
      "train: iter 334  trainloss 2.42697  validloss 3.32784±0.00000  bestvalidloss 2.47894  last_update 96\n",
      "train: iter 335  trainloss 2.42777  validloss 3.03575±0.00000  bestvalidloss 2.47894  last_update 97\n",
      "train: iter 336  trainloss 2.49827  validloss 3.24412±0.00000  bestvalidloss 2.47894  last_update 98\n",
      "train: iter 337  trainloss 2.55660  validloss 3.19632±0.00000  bestvalidloss 2.47894  last_update 99\n",
      "train: iter 338  trainloss 2.45894  validloss 3.09831±0.00000  bestvalidloss 2.47894  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_pendulum_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-3.9404)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-4.6625)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3723402208699682\n",
      "tensor([0.4438])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
