{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(10196.7881)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 8127.43986  validloss 331300.10906±0.00000  bestvalidloss 331300.10906  last_update 0\n",
      "train: iter 1  trainloss 1370.05141  validloss 10560.84131±0.00000  bestvalidloss 10560.84131  last_update 0\n",
      "train: iter 2  trainloss 1145.95099  validloss 2226.67050±0.00000  bestvalidloss 2226.67050  last_update 0\n",
      "train: iter 3  trainloss 1045.69858  validloss 2376.21435±0.00000  bestvalidloss 2226.67050  last_update 1\n",
      "train: iter 4  trainloss 959.77880  validloss 1596.00425±0.00000  bestvalidloss 1596.00425  last_update 0\n",
      "train: iter 5  trainloss 892.82001  validloss 1557.11229±0.00000  bestvalidloss 1557.11229  last_update 0\n",
      "train: iter 6  trainloss 845.74345  validloss 1508.53335±0.00000  bestvalidloss 1508.53335  last_update 0\n",
      "train: iter 7  trainloss 824.79009  validloss 1969.60122±0.00000  bestvalidloss 1508.53335  last_update 1\n",
      "train: iter 8  trainloss 833.67252  validloss 2288.69890±0.00000  bestvalidloss 1508.53335  last_update 2\n",
      "train: iter 9  trainloss 853.28072  validloss 1554.97031±0.00000  bestvalidloss 1508.53335  last_update 3\n",
      "train: iter 10  trainloss 750.21986  validloss 1322.41800±0.00000  bestvalidloss 1322.41800  last_update 0\n",
      "train: iter 11  trainloss 727.89715  validloss 1715.06521±0.00000  bestvalidloss 1322.41800  last_update 1\n",
      "train: iter 12  trainloss 697.62756  validloss 1126.50878±0.00000  bestvalidloss 1126.50878  last_update 0\n",
      "train: iter 13  trainloss 733.61809  validloss 1028.05169±0.00000  bestvalidloss 1028.05169  last_update 0\n",
      "train: iter 14  trainloss 654.23801  validloss 911.74256±0.00000  bestvalidloss 911.74256  last_update 0\n",
      "train: iter 15  trainloss 566.77571  validloss 736.66008±0.00000  bestvalidloss 736.66008  last_update 0\n",
      "train: iter 16  trainloss 493.70812  validloss 914.90441±0.00000  bestvalidloss 736.66008  last_update 1\n",
      "train: iter 17  trainloss 422.44618  validloss 648.85720±0.00000  bestvalidloss 648.85720  last_update 0\n",
      "train: iter 18  trainloss 385.40248  validloss 597.64726±0.00000  bestvalidloss 597.64726  last_update 0\n",
      "train: iter 19  trainloss 303.87107  validloss 626.83013±0.00000  bestvalidloss 597.64726  last_update 1\n",
      "train: iter 20  trainloss 184.69890  validloss 376.83275±0.00000  bestvalidloss 376.83275  last_update 0\n",
      "train: iter 21  trainloss 199.07195  validloss 481.19994±0.00000  bestvalidloss 376.83275  last_update 1\n",
      "train: iter 22  trainloss 95.02215  validloss 255.95425±0.00000  bestvalidloss 255.95425  last_update 0\n",
      "train: iter 23  trainloss 158.78462  validloss 299.43177±0.00000  bestvalidloss 255.95425  last_update 1\n",
      "train: iter 24  trainloss 81.50925  validloss 269.24065±0.00000  bestvalidloss 255.95425  last_update 2\n",
      "train: iter 25  trainloss 56.93126  validloss 251.52962±0.00000  bestvalidloss 251.52962  last_update 0\n",
      "train: iter 26  trainloss 56.31485  validloss 433.09361±0.00000  bestvalidloss 251.52962  last_update 1\n",
      "train: iter 27  trainloss 19.29510  validloss 151.10406±0.00000  bestvalidloss 151.10406  last_update 0\n",
      "train: iter 28  trainloss -52.92185  validloss 92.24180±0.00000  bestvalidloss 92.24180  last_update 0\n",
      "train: iter 29  trainloss -149.92978  validloss 178.85887±0.00000  bestvalidloss 92.24180  last_update 1\n",
      "train: iter 30  trainloss -227.60299  validloss -33.74348±0.00000  bestvalidloss -33.74348  last_update 0\n",
      "train: iter 31  trainloss -199.51297  validloss -3.67543±0.00000  bestvalidloss -33.74348  last_update 1\n",
      "train: iter 32  trainloss -100.30099  validloss -36.39992±0.00000  bestvalidloss -36.39992  last_update 0\n",
      "train: iter 33  trainloss 21.14497  validloss 140.30507±0.00000  bestvalidloss -36.39992  last_update 1\n",
      "train: iter 34  trainloss -48.72363  validloss 145.77568±0.00000  bestvalidloss -36.39992  last_update 2\n",
      "train: iter 35  trainloss -253.86972  validloss -83.97392±0.00000  bestvalidloss -83.97392  last_update 0\n",
      "train: iter 36  trainloss -299.97476  validloss -133.64362±0.00000  bestvalidloss -133.64362  last_update 0\n",
      "train: iter 37  trainloss -365.63138  validloss -183.83037±0.00000  bestvalidloss -183.83037  last_update 0\n",
      "train: iter 38  trainloss -364.07216  validloss -261.93709±0.00000  bestvalidloss -261.93709  last_update 0\n",
      "train: iter 39  trainloss -366.92677  validloss -41.65125±0.00000  bestvalidloss -261.93709  last_update 1\n",
      "train: iter 40  trainloss -399.25087  validloss -96.20434±0.00000  bestvalidloss -261.93709  last_update 2\n",
      "train: iter 41  trainloss -409.34243  validloss -261.17031±0.00000  bestvalidloss -261.93709  last_update 3\n",
      "train: iter 42  trainloss 104.10546  validloss -164.60622±0.00000  bestvalidloss -261.93709  last_update 4\n",
      "train: iter 43  trainloss -214.72917  validloss 258.84060±0.00000  bestvalidloss -261.93709  last_update 5\n",
      "train: iter 44  trainloss -447.07295  validloss -171.65418±0.00000  bestvalidloss -261.93709  last_update 6\n",
      "train: iter 45  trainloss -374.15493  validloss -380.01948±0.00000  bestvalidloss -380.01948  last_update 0\n",
      "train: iter 46  trainloss -495.24946  validloss -367.26272±0.00000  bestvalidloss -380.01948  last_update 1\n",
      "train: iter 47  trainloss -408.16067  validloss -423.63428±0.00000  bestvalidloss -423.63428  last_update 0\n",
      "train: iter 48  trainloss -420.03623  validloss -345.64541±0.00000  bestvalidloss -423.63428  last_update 1\n",
      "train: iter 49  trainloss -501.39454  validloss -202.80128±0.00000  bestvalidloss -423.63428  last_update 2\n",
      "train: iter 50  trainloss -465.39775  validloss -412.99717±0.00000  bestvalidloss -423.63428  last_update 3\n",
      "train: iter 51  trainloss -437.09626  validloss -362.77978±0.00000  bestvalidloss -423.63428  last_update 4\n",
      "train: iter 52  trainloss -441.60840  validloss -463.86469±0.00000  bestvalidloss -463.86469  last_update 0\n",
      "train: iter 53  trainloss -352.56781  validloss -385.97333±0.00000  bestvalidloss -463.86469  last_update 1\n",
      "train: iter 54  trainloss -440.13246  validloss -318.24172±0.00000  bestvalidloss -463.86469  last_update 2\n",
      "train: iter 55  trainloss -469.59889  validloss -505.81532±0.00000  bestvalidloss -505.81532  last_update 0\n",
      "train: iter 56  trainloss -462.22365  validloss -265.21733±0.00000  bestvalidloss -505.81532  last_update 1\n",
      "train: iter 57  trainloss -550.01749  validloss -373.05282±0.00000  bestvalidloss -505.81532  last_update 2\n",
      "train: iter 58  trainloss -578.07307  validloss -439.98205±0.00000  bestvalidloss -505.81532  last_update 3\n",
      "train: iter 59  trainloss -599.08371  validloss -524.73487±0.00000  bestvalidloss -524.73487  last_update 0\n",
      "train: iter 60  trainloss -652.37549  validloss -545.79173±0.00000  bestvalidloss -545.79173  last_update 0\n",
      "train: iter 61  trainloss -558.10466  validloss -611.48921±0.00000  bestvalidloss -611.48921  last_update 0\n",
      "train: iter 62  trainloss -607.30153  validloss -511.47987±0.00000  bestvalidloss -611.48921  last_update 1\n",
      "train: iter 63  trainloss -601.99481  validloss -610.25095±0.00000  bestvalidloss -611.48921  last_update 2\n",
      "train: iter 64  trainloss -677.27611  validloss -551.93912±0.00000  bestvalidloss -611.48921  last_update 3\n",
      "train: iter 65  trainloss -627.21324  validloss -589.39203±0.00000  bestvalidloss -611.48921  last_update 4\n",
      "train: iter 66  trainloss -722.96202  validloss -572.92222±0.00000  bestvalidloss -611.48921  last_update 5\n",
      "train: iter 67  trainloss -496.78071  validloss -572.86437±0.00000  bestvalidloss -611.48921  last_update 6\n",
      "train: iter 68  trainloss -656.64856  validloss -450.24687±0.00000  bestvalidloss -611.48921  last_update 7\n",
      "train: iter 69  trainloss -682.02940  validloss -609.76717±0.00000  bestvalidloss -611.48921  last_update 8\n",
      "train: iter 70  trainloss -723.59117  validloss -535.64474±0.00000  bestvalidloss -611.48921  last_update 9\n",
      "train: iter 71  trainloss -711.00638  validloss -593.07081±0.00000  bestvalidloss -611.48921  last_update 10\n",
      "train: iter 72  trainloss -714.64101  validloss -639.51442±0.00000  bestvalidloss -639.51442  last_update 0\n",
      "train: iter 73  trainloss -582.09208  validloss -512.51137±0.00000  bestvalidloss -639.51442  last_update 1\n",
      "train: iter 74  trainloss -557.68332  validloss -447.42873±0.00000  bestvalidloss -639.51442  last_update 2\n",
      "train: iter 75  trainloss -626.21585  validloss -305.37559±0.00000  bestvalidloss -639.51442  last_update 3\n",
      "train: iter 76  trainloss -711.83079  validloss -570.74190±0.00000  bestvalidloss -639.51442  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -736.88609  validloss -529.63827±0.00000  bestvalidloss -639.51442  last_update 5\n",
      "train: iter 78  trainloss -763.55423  validloss -722.09453±0.00000  bestvalidloss -722.09453  last_update 0\n",
      "train: iter 79  trainloss -661.09254  validloss -656.01348±0.00000  bestvalidloss -722.09453  last_update 1\n",
      "train: iter 80  trainloss -761.71185  validloss -447.59387±0.00000  bestvalidloss -722.09453  last_update 2\n",
      "train: iter 81  trainloss -686.71525  validloss -745.57929±0.00000  bestvalidloss -745.57929  last_update 0\n",
      "train: iter 82  trainloss -538.77528  validloss -480.89989±0.00000  bestvalidloss -745.57929  last_update 1\n",
      "train: iter 83  trainloss -446.41278  validloss -571.46364±0.00000  bestvalidloss -745.57929  last_update 2\n",
      "train: iter 84  trainloss -501.38770  validloss 37.91164±0.00000  bestvalidloss -745.57929  last_update 3\n",
      "train: iter 85  trainloss -789.64118  validloss -589.99635±0.00000  bestvalidloss -745.57929  last_update 4\n",
      "train: iter 86  trainloss -718.33989  validloss -652.42579±0.00000  bestvalidloss -745.57929  last_update 5\n",
      "train: iter 87  trainloss -798.06619  validloss -540.35997±0.00000  bestvalidloss -745.57929  last_update 6\n",
      "train: iter 88  trainloss -814.19092  validloss -610.63229±0.00000  bestvalidloss -745.57929  last_update 7\n",
      "train: iter 89  trainloss -603.33253  validloss -739.02654±0.00000  bestvalidloss -745.57929  last_update 8\n",
      "train: iter 90  trainloss -636.79861  validloss -526.65775±0.00000  bestvalidloss -745.57929  last_update 9\n",
      "train: iter 91  trainloss -783.06304  validloss -662.76135±0.00000  bestvalidloss -745.57929  last_update 10\n",
      "train: iter 92  trainloss -765.11570  validloss -514.41839±0.00000  bestvalidloss -745.57929  last_update 11\n",
      "train: iter 93  trainloss -759.01363  validloss -691.70794±0.00000  bestvalidloss -745.57929  last_update 12\n",
      "train: iter 94  trainloss -817.82003  validloss -713.50202±0.00000  bestvalidloss -745.57929  last_update 13\n",
      "train: iter 95  trainloss -747.23335  validloss -777.55509±0.00000  bestvalidloss -777.55509  last_update 0\n",
      "train: iter 96  trainloss -851.76669  validloss -747.00318±0.00000  bestvalidloss -777.55509  last_update 1\n",
      "train: iter 97  trainloss -670.77139  validloss -776.29335±0.00000  bestvalidloss -777.55509  last_update 2\n",
      "train: iter 98  trainloss -719.98214  validloss -574.68833±0.00000  bestvalidloss -777.55509  last_update 3\n",
      "train: iter 99  trainloss -600.91113  validloss -504.66392±0.00000  bestvalidloss -777.55509  last_update 4\n",
      "train: iter 100  trainloss -817.95344  validloss -587.50893±0.00000  bestvalidloss -777.55509  last_update 5\n",
      "train: iter 101  trainloss -750.79958  validloss -657.87442±0.00000  bestvalidloss -777.55509  last_update 6\n",
      "train: iter 102  trainloss -852.99900  validloss -685.39534±0.00000  bestvalidloss -777.55509  last_update 7\n",
      "train: iter 103  trainloss -741.16266  validloss -664.20043±0.00000  bestvalidloss -777.55509  last_update 8\n",
      "train: iter 104  trainloss -795.47493  validloss -640.37550±0.00000  bestvalidloss -777.55509  last_update 9\n",
      "train: iter 105  trainloss -650.60605  validloss -769.42629±0.00000  bestvalidloss -777.55509  last_update 10\n",
      "train: iter 106  trainloss -889.17066  validloss -674.59292±0.00000  bestvalidloss -777.55509  last_update 11\n",
      "train: iter 107  trainloss -907.73874  validloss -838.48555±0.00000  bestvalidloss -838.48555  last_update 0\n",
      "train: iter 108  trainloss -834.99808  validloss -803.90424±0.00000  bestvalidloss -838.48555  last_update 1\n",
      "train: iter 109  trainloss -879.60013  validloss -787.06414±0.00000  bestvalidloss -838.48555  last_update 2\n",
      "train: iter 110  trainloss -787.48477  validloss -788.24441±0.00000  bestvalidloss -838.48555  last_update 3\n",
      "train: iter 111  trainloss -885.84541  validloss -824.63214±0.00000  bestvalidloss -838.48555  last_update 4\n",
      "train: iter 112  trainloss -919.65114  validloss -821.62569±0.00000  bestvalidloss -838.48555  last_update 5\n",
      "train: iter 113  trainloss -837.26290  validloss -745.73989±0.00000  bestvalidloss -838.48555  last_update 6\n",
      "train: iter 114  trainloss -883.37974  validloss -849.60850±0.00000  bestvalidloss -849.60850  last_update 0\n",
      "train: iter 115  trainloss -838.36713  validloss -826.39717±0.00000  bestvalidloss -849.60850  last_update 1\n",
      "train: iter 116  trainloss -836.30516  validloss -611.88396±0.00000  bestvalidloss -849.60850  last_update 2\n",
      "train: iter 117  trainloss -810.40210  validloss -797.17182±0.00000  bestvalidloss -849.60850  last_update 3\n",
      "train: iter 118  trainloss -892.05713  validloss -638.48937±0.00000  bestvalidloss -849.60850  last_update 4\n",
      "train: iter 119  trainloss -927.52689  validloss -875.12076±0.00000  bestvalidloss -875.12076  last_update 0\n",
      "train: iter 120  trainloss -812.27845  validloss -458.48559±0.00000  bestvalidloss -875.12076  last_update 1\n",
      "train: iter 121  trainloss -852.94066  validloss -764.75617±0.00000  bestvalidloss -875.12076  last_update 2\n",
      "train: iter 122  trainloss -938.67219  validloss -640.25256±0.00000  bestvalidloss -875.12076  last_update 3\n",
      "train: iter 123  trainloss -839.19306  validloss -636.24940±0.00000  bestvalidloss -875.12076  last_update 4\n",
      "train: iter 124  trainloss -985.08489  validloss -688.63683±0.00000  bestvalidloss -875.12076  last_update 5\n",
      "train: iter 125  trainloss -974.41170  validloss -876.09118±0.00000  bestvalidloss -876.09118  last_update 0\n",
      "train: iter 126  trainloss -990.71458  validloss -714.89811±0.00000  bestvalidloss -876.09118  last_update 1\n",
      "train: iter 127  trainloss -910.17324  validloss -894.60721±0.00000  bestvalidloss -894.60721  last_update 0\n",
      "train: iter 128  trainloss -826.97337  validloss -775.13385±0.00000  bestvalidloss -894.60721  last_update 1\n",
      "train: iter 129  trainloss -908.80795  validloss -778.70644±0.00000  bestvalidloss -894.60721  last_update 2\n",
      "train: iter 130  trainloss -921.29581  validloss -757.15323±0.00000  bestvalidloss -894.60721  last_update 3\n",
      "train: iter 131  trainloss -942.38922  validloss -592.54982±0.00000  bestvalidloss -894.60721  last_update 4\n",
      "train: iter 132  trainloss -827.88347  validloss -719.48874±0.00000  bestvalidloss -894.60721  last_update 5\n",
      "train: iter 133  trainloss -873.85564  validloss -638.99043±0.00000  bestvalidloss -894.60721  last_update 6\n",
      "train: iter 134  trainloss -994.07621  validloss -806.78134±0.00000  bestvalidloss -894.60721  last_update 7\n",
      "train: iter 135  trainloss -896.59571  validloss -886.12289±0.00000  bestvalidloss -894.60721  last_update 8\n",
      "train: iter 136  trainloss -876.75414  validloss -795.79623±0.00000  bestvalidloss -894.60721  last_update 9\n",
      "train: iter 137  trainloss -964.67921  validloss -857.98289±0.00000  bestvalidloss -894.60721  last_update 10\n",
      "train: iter 138  trainloss -740.45488  validloss -948.49175±0.00000  bestvalidloss -948.49175  last_update 0\n",
      "train: iter 139  trainloss -892.70455  validloss -783.32563±0.00000  bestvalidloss -948.49175  last_update 1\n",
      "train: iter 140  trainloss -793.28161  validloss -779.15201±0.00000  bestvalidloss -948.49175  last_update 2\n",
      "train: iter 141  trainloss -993.06245  validloss -875.62268±0.00000  bestvalidloss -948.49175  last_update 3\n",
      "train: iter 142  trainloss -942.79413  validloss -893.66375±0.00000  bestvalidloss -948.49175  last_update 4\n",
      "train: iter 143  trainloss -973.12305  validloss -934.73866±0.00000  bestvalidloss -948.49175  last_update 5\n",
      "train: iter 144  trainloss -1017.49906  validloss -823.69684±0.00000  bestvalidloss -948.49175  last_update 6\n",
      "train: iter 145  trainloss -1065.88430  validloss -908.73398±0.00000  bestvalidloss -948.49175  last_update 7\n",
      "train: iter 146  trainloss -1061.75063  validloss -917.10915±0.00000  bestvalidloss -948.49175  last_update 8\n",
      "train: iter 147  trainloss -1023.43016  validloss -934.10742±0.00000  bestvalidloss -948.49175  last_update 9\n",
      "train: iter 148  trainloss -1062.40248  validloss -906.82843±0.00000  bestvalidloss -948.49175  last_update 10\n",
      "train: iter 149  trainloss -968.27522  validloss -871.40442±0.00000  bestvalidloss -948.49175  last_update 11\n",
      "train: iter 150  trainloss -873.74722  validloss -765.85875±0.00000  bestvalidloss -948.49175  last_update 12\n",
      "train: iter 151  trainloss -1059.30625  validloss -864.24474±0.00000  bestvalidloss -948.49175  last_update 13\n",
      "train: iter 152  trainloss -1020.64284  validloss -931.27909±0.00000  bestvalidloss -948.49175  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -922.12612  validloss -371.59996±0.00000  bestvalidloss -948.49175  last_update 15\n",
      "train: iter 154  trainloss -936.24886  validloss -862.19925±0.00000  bestvalidloss -948.49175  last_update 16\n",
      "train: iter 155  trainloss -796.14108  validloss -820.04410±0.00000  bestvalidloss -948.49175  last_update 17\n",
      "train: iter 156  trainloss -789.50362  validloss -290.43966±0.00000  bestvalidloss -948.49175  last_update 18\n",
      "train: iter 157  trainloss -1019.86686  validloss -870.45268±0.00000  bestvalidloss -948.49175  last_update 19\n",
      "train: iter 158  trainloss -983.07868  validloss -943.36139±0.00000  bestvalidloss -948.49175  last_update 20\n",
      "train: iter 159  trainloss -1033.81366  validloss -848.90444±0.00000  bestvalidloss -948.49175  last_update 21\n",
      "train: iter 160  trainloss -1035.33221  validloss -972.43788±0.00000  bestvalidloss -972.43788  last_update 0\n",
      "train: iter 161  trainloss -1035.15799  validloss -921.62621±0.00000  bestvalidloss -972.43788  last_update 1\n",
      "train: iter 162  trainloss -1072.68384  validloss -945.27122±0.00000  bestvalidloss -972.43788  last_update 2\n",
      "train: iter 163  trainloss -1098.47069  validloss -853.42448±0.00000  bestvalidloss -972.43788  last_update 3\n",
      "train: iter 164  trainloss -1038.71719  validloss -908.12293±0.00000  bestvalidloss -972.43788  last_update 4\n",
      "train: iter 165  trainloss -1004.25478  validloss -802.28763±0.00000  bestvalidloss -972.43788  last_update 5\n",
      "train: iter 166  trainloss -935.84786  validloss -906.11328±0.00000  bestvalidloss -972.43788  last_update 6\n",
      "train: iter 167  trainloss -885.18777  validloss -990.29735±0.00000  bestvalidloss -990.29735  last_update 0\n",
      "train: iter 168  trainloss -940.39566  validloss -390.71220±0.00000  bestvalidloss -990.29735  last_update 1\n",
      "train: iter 169  trainloss -1004.36050  validloss -727.97058±0.00000  bestvalidloss -990.29735  last_update 2\n",
      "train: iter 170  trainloss -1102.15642  validloss -975.34474±0.00000  bestvalidloss -990.29735  last_update 3\n",
      "train: iter 171  trainloss -1058.99118  validloss -748.18946±0.00000  bestvalidloss -990.29735  last_update 4\n",
      "train: iter 172  trainloss -960.23857  validloss -998.68040±0.00000  bestvalidloss -998.68040  last_update 0\n",
      "train: iter 173  trainloss -1086.69292  validloss -961.90176±0.00000  bestvalidloss -998.68040  last_update 1\n",
      "train: iter 174  trainloss -1017.91036  validloss -984.94728±0.00000  bestvalidloss -998.68040  last_update 2\n",
      "train: iter 175  trainloss -1019.78604  validloss -839.16717±0.00000  bestvalidloss -998.68040  last_update 3\n",
      "train: iter 176  trainloss -1103.32440  validloss -1019.36974±0.00000  bestvalidloss -1019.36974  last_update 0\n",
      "train: iter 177  trainloss -969.12829  validloss -757.62868±0.00000  bestvalidloss -1019.36974  last_update 1\n",
      "train: iter 178  trainloss -989.36019  validloss -931.19282±0.00000  bestvalidloss -1019.36974  last_update 2\n",
      "train: iter 179  trainloss -1078.74059  validloss -911.22030±0.00000  bestvalidloss -1019.36974  last_update 3\n",
      "train: iter 180  trainloss -1051.15218  validloss -766.35856±0.00000  bestvalidloss -1019.36974  last_update 4\n",
      "train: iter 181  trainloss -902.34650  validloss -844.97608±0.00000  bestvalidloss -1019.36974  last_update 5\n",
      "train: iter 182  trainloss -1097.81695  validloss -814.73468±0.00000  bestvalidloss -1019.36974  last_update 6\n",
      "train: iter 183  trainloss -971.29825  validloss -999.70129±0.00000  bestvalidloss -1019.36974  last_update 7\n",
      "train: iter 184  trainloss -869.70477  validloss -915.27325±0.00000  bestvalidloss -1019.36974  last_update 8\n",
      "train: iter 185  trainloss -779.78251  validloss -319.64159±0.00000  bestvalidloss -1019.36974  last_update 9\n",
      "train: iter 186  trainloss -1080.51107  validloss -875.73424±0.00000  bestvalidloss -1019.36974  last_update 10\n",
      "train: iter 187  trainloss -1122.47008  validloss -865.65943±0.00000  bestvalidloss -1019.36974  last_update 11\n",
      "train: iter 188  trainloss -1023.79776  validloss -984.91863±0.00000  bestvalidloss -1019.36974  last_update 12\n",
      "train: iter 189  trainloss -1049.78167  validloss -706.05031±0.00000  bestvalidloss -1019.36974  last_update 13\n",
      "train: iter 190  trainloss -1072.85976  validloss -941.47082±0.00000  bestvalidloss -1019.36974  last_update 14\n",
      "train: iter 191  trainloss -1001.68156  validloss -930.83692±0.00000  bestvalidloss -1019.36974  last_update 15\n",
      "train: iter 192  trainloss -1154.86025  validloss -963.34250±0.00000  bestvalidloss -1019.36974  last_update 16\n",
      "train: iter 193  trainloss -1113.99544  validloss -937.28089±0.00000  bestvalidloss -1019.36974  last_update 17\n",
      "train: iter 194  trainloss -1061.58184  validloss -902.56973±0.00000  bestvalidloss -1019.36974  last_update 18\n",
      "train: iter 195  trainloss -1033.80368  validloss -941.81475±0.00000  bestvalidloss -1019.36974  last_update 19\n",
      "train: iter 196  trainloss -1115.55793  validloss -872.99005±0.00000  bestvalidloss -1019.36974  last_update 20\n",
      "train: iter 197  trainloss -1123.52929  validloss -914.30537±0.00000  bestvalidloss -1019.36974  last_update 21\n",
      "train: iter 198  trainloss -1079.41806  validloss -1037.80055±0.00000  bestvalidloss -1037.80055  last_update 0\n",
      "train: iter 199  trainloss -1118.00338  validloss -734.46552±0.00000  bestvalidloss -1037.80055  last_update 1\n",
      "train: iter 200  trainloss -1156.22733  validloss -967.57953±0.00000  bestvalidloss -1037.80055  last_update 2\n",
      "train: iter 201  trainloss -1173.79474  validloss -892.82642±0.00000  bestvalidloss -1037.80055  last_update 3\n",
      "train: iter 202  trainloss -1007.54031  validloss -754.61457±0.00000  bestvalidloss -1037.80055  last_update 4\n",
      "train: iter 203  trainloss -859.56085  validloss -861.02177±0.00000  bestvalidloss -1037.80055  last_update 5\n",
      "train: iter 204  trainloss -1136.67989  validloss -849.77740±0.00000  bestvalidloss -1037.80055  last_update 6\n",
      "train: iter 205  trainloss -1102.11238  validloss -881.34610±0.00000  bestvalidloss -1037.80055  last_update 7\n",
      "train: iter 206  trainloss -1150.29432  validloss -1086.93474±0.00000  bestvalidloss -1086.93474  last_update 0\n",
      "train: iter 207  trainloss -1134.63710  validloss -955.76783±0.00000  bestvalidloss -1086.93474  last_update 1\n",
      "train: iter 208  trainloss -1052.30730  validloss -957.11252±0.00000  bestvalidloss -1086.93474  last_update 2\n",
      "train: iter 209  trainloss -1050.23683  validloss -644.03347±0.00000  bestvalidloss -1086.93474  last_update 3\n",
      "train: iter 210  trainloss -1149.51076  validloss -1014.77308±0.00000  bestvalidloss -1086.93474  last_update 4\n",
      "train: iter 211  trainloss -1138.29455  validloss -988.22068±0.00000  bestvalidloss -1086.93474  last_update 5\n",
      "train: iter 212  trainloss -1079.38809  validloss -793.13202±0.00000  bestvalidloss -1086.93474  last_update 6\n",
      "train: iter 213  trainloss -1199.35167  validloss -913.57719±0.00000  bestvalidloss -1086.93474  last_update 7\n",
      "train: iter 214  trainloss -1157.42569  validloss -736.37610±0.00000  bestvalidloss -1086.93474  last_update 8\n",
      "train: iter 215  trainloss -1006.59261  validloss -843.83687±0.00000  bestvalidloss -1086.93474  last_update 9\n",
      "train: iter 216  trainloss -985.82416  validloss -834.31377±0.00000  bestvalidloss -1086.93474  last_update 10\n",
      "train: iter 217  trainloss -980.62490  validloss -788.05101±0.00000  bestvalidloss -1086.93474  last_update 11\n",
      "train: iter 218  trainloss -1149.36156  validloss -938.92353±0.00000  bestvalidloss -1086.93474  last_update 12\n",
      "train: iter 219  trainloss -1040.77670  validloss -855.62848±0.00000  bestvalidloss -1086.93474  last_update 13\n",
      "train: iter 220  trainloss -1119.82743  validloss -899.51379±0.00000  bestvalidloss -1086.93474  last_update 14\n",
      "train: iter 221  trainloss -1041.97349  validloss -959.24068±0.00000  bestvalidloss -1086.93474  last_update 15\n",
      "train: iter 222  trainloss -1052.56162  validloss -1052.57961±0.00000  bestvalidloss -1086.93474  last_update 16\n",
      "train: iter 223  trainloss -1145.08509  validloss -1061.75741±0.00000  bestvalidloss -1086.93474  last_update 17\n",
      "train: iter 224  trainloss -1149.76148  validloss -795.42997±0.00000  bestvalidloss -1086.93474  last_update 18\n",
      "train: iter 225  trainloss -1189.17714  validloss -1063.05115±0.00000  bestvalidloss -1086.93474  last_update 19\n",
      "train: iter 226  trainloss -1151.85264  validloss -817.31369±0.00000  bestvalidloss -1086.93474  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 227  trainloss -1168.05748  validloss -1012.56834±0.00000  bestvalidloss -1086.93474  last_update 21\n",
      "train: iter 228  trainloss -1170.10890  validloss -1112.67066±0.00000  bestvalidloss -1112.67066  last_update 0\n",
      "train: iter 229  trainloss -1196.48105  validloss -1048.44716±0.00000  bestvalidloss -1112.67066  last_update 1\n",
      "train: iter 230  trainloss -1018.27570  validloss -917.90222±0.00000  bestvalidloss -1112.67066  last_update 2\n",
      "train: iter 231  trainloss -1062.71869  validloss -947.25729±0.00000  bestvalidloss -1112.67066  last_update 3\n",
      "train: iter 232  trainloss -1085.75816  validloss -1021.06132±0.00000  bestvalidloss -1112.67066  last_update 4\n",
      "train: iter 233  trainloss -1121.02056  validloss -1004.36691±0.00000  bestvalidloss -1112.67066  last_update 5\n",
      "train: iter 234  trainloss -1180.35529  validloss -1099.09804±0.00000  bestvalidloss -1112.67066  last_update 6\n",
      "train: iter 235  trainloss -916.94897  validloss -1140.82609±0.00000  bestvalidloss -1140.82609  last_update 0\n",
      "train: iter 236  trainloss -1034.25035  validloss -880.34196±0.00000  bestvalidloss -1140.82609  last_update 1\n",
      "train: iter 237  trainloss -1222.23711  validloss -986.65213±0.00000  bestvalidloss -1140.82609  last_update 2\n",
      "train: iter 238  trainloss -1212.82621  validloss -1123.42847±0.00000  bestvalidloss -1140.82609  last_update 3\n",
      "train: iter 239  trainloss -1214.58667  validloss -1132.06264±0.00000  bestvalidloss -1140.82609  last_update 4\n",
      "train: iter 240  trainloss -1130.37145  validloss -901.94637±0.00000  bestvalidloss -1140.82609  last_update 5\n",
      "train: iter 241  trainloss -1214.29755  validloss -1121.38894±0.00000  bestvalidloss -1140.82609  last_update 6\n",
      "train: iter 242  trainloss -963.27499  validloss -932.30519±0.00000  bestvalidloss -1140.82609  last_update 7\n",
      "train: iter 243  trainloss -1061.63489  validloss -790.25014±0.00000  bestvalidloss -1140.82609  last_update 8\n",
      "train: iter 244  trainloss -1159.17679  validloss -980.14726±0.00000  bestvalidloss -1140.82609  last_update 9\n",
      "train: iter 245  trainloss -1225.54997  validloss -1068.29168±0.00000  bestvalidloss -1140.82609  last_update 10\n",
      "train: iter 246  trainloss -1217.79746  validloss -1129.45620±0.00000  bestvalidloss -1140.82609  last_update 11\n",
      "train: iter 247  trainloss -1143.89023  validloss -923.27991±0.00000  bestvalidloss -1140.82609  last_update 12\n",
      "train: iter 248  trainloss -1115.79544  validloss -979.55533±0.00000  bestvalidloss -1140.82609  last_update 13\n",
      "train: iter 249  trainloss -1198.01008  validloss -1061.14576±0.00000  bestvalidloss -1140.82609  last_update 14\n",
      "train: iter 250  trainloss -1000.05727  validloss -1056.27454±0.00000  bestvalidloss -1140.82609  last_update 15\n",
      "train: iter 251  trainloss -1077.11542  validloss -1081.55753±0.00000  bestvalidloss -1140.82609  last_update 16\n",
      "train: iter 252  trainloss -1191.88143  validloss -1119.04433±0.00000  bestvalidloss -1140.82609  last_update 17\n",
      "train: iter 253  trainloss -1211.72388  validloss -1149.40872±0.00000  bestvalidloss -1149.40872  last_update 0\n",
      "train: iter 254  trainloss -1190.47320  validloss -745.43876±0.00000  bestvalidloss -1149.40872  last_update 1\n",
      "train: iter 255  trainloss -1181.49367  validloss -1143.47652±0.00000  bestvalidloss -1149.40872  last_update 2\n",
      "train: iter 256  trainloss -1171.68968  validloss -973.10463±0.00000  bestvalidloss -1149.40872  last_update 3\n",
      "train: iter 257  trainloss -1194.25903  validloss -885.78512±0.00000  bestvalidloss -1149.40872  last_update 4\n",
      "train: iter 258  trainloss -1120.15731  validloss -1176.42401±0.00000  bestvalidloss -1176.42401  last_update 0\n",
      "train: iter 259  trainloss -947.56213  validloss -799.70513±0.00000  bestvalidloss -1176.42401  last_update 1\n",
      "train: iter 260  trainloss -1152.44585  validloss -1031.77870±0.00000  bestvalidloss -1176.42401  last_update 2\n",
      "train: iter 261  trainloss -1137.49433  validloss -1062.66719±0.00000  bestvalidloss -1176.42401  last_update 3\n",
      "train: iter 262  trainloss -1146.36182  validloss -1071.03288±0.00000  bestvalidloss -1176.42401  last_update 4\n",
      "train: iter 263  trainloss -1248.52942  validloss -1151.80228±0.00000  bestvalidloss -1176.42401  last_update 5\n",
      "train: iter 264  trainloss -1239.24062  validloss -1150.94552±0.00000  bestvalidloss -1176.42401  last_update 6\n",
      "train: iter 265  trainloss -1129.10371  validloss -1204.24149±0.00000  bestvalidloss -1204.24149  last_update 0\n",
      "train: iter 266  trainloss -1226.52139  validloss -1050.98508±0.00000  bestvalidloss -1204.24149  last_update 1\n",
      "train: iter 267  trainloss -1161.72686  validloss -1077.83191±0.00000  bestvalidloss -1204.24149  last_update 2\n",
      "train: iter 268  trainloss -1228.08093  validloss -982.71973±0.00000  bestvalidloss -1204.24149  last_update 3\n",
      "train: iter 269  trainloss -1198.57166  validloss -1206.42142±0.00000  bestvalidloss -1206.42142  last_update 0\n",
      "train: iter 270  trainloss -1064.87941  validloss -526.25131±0.00000  bestvalidloss -1206.42142  last_update 1\n",
      "train: iter 271  trainloss -1204.26576  validloss -1028.62356±0.00000  bestvalidloss -1206.42142  last_update 2\n",
      "train: iter 272  trainloss -1223.84462  validloss -1204.56223±0.00000  bestvalidloss -1206.42142  last_update 3\n",
      "train: iter 273  trainloss -1210.35870  validloss -950.83812±0.00000  bestvalidloss -1206.42142  last_update 4\n",
      "train: iter 274  trainloss -1217.57991  validloss -1135.58738±0.00000  bestvalidloss -1206.42142  last_update 5\n",
      "train: iter 275  trainloss -1255.65391  validloss -1210.75403±0.00000  bestvalidloss -1210.75403  last_update 0\n",
      "train: iter 276  trainloss -1203.85708  validloss -1116.92779±0.00000  bestvalidloss -1210.75403  last_update 1\n",
      "train: iter 277  trainloss -1227.75891  validloss -1125.67925±0.00000  bestvalidloss -1210.75403  last_update 2\n",
      "train: iter 278  trainloss -1161.08436  validloss -981.42168±0.00000  bestvalidloss -1210.75403  last_update 3\n",
      "train: iter 279  trainloss -1225.48882  validloss -930.25348±0.00000  bestvalidloss -1210.75403  last_update 4\n",
      "train: iter 280  trainloss -1282.35470  validloss -1165.81057±0.00000  bestvalidloss -1210.75403  last_update 5\n",
      "train: iter 281  trainloss -1120.66350  validloss -1231.46243±0.00000  bestvalidloss -1231.46243  last_update 0\n",
      "train: iter 282  trainloss -1253.96407  validloss -1073.23342±0.00000  bestvalidloss -1231.46243  last_update 1\n",
      "train: iter 283  trainloss -1164.83992  validloss -1052.12128±0.00000  bestvalidloss -1231.46243  last_update 2\n",
      "train: iter 284  trainloss -1227.02479  validloss -1119.92272±0.00000  bestvalidloss -1231.46243  last_update 3\n",
      "train: iter 285  trainloss -1182.46958  validloss -1148.94189±0.00000  bestvalidloss -1231.46243  last_update 4\n",
      "train: iter 286  trainloss -1271.29583  validloss -1072.99397±0.00000  bestvalidloss -1231.46243  last_update 5\n",
      "train: iter 287  trainloss -1130.86908  validloss -1167.70159±0.00000  bestvalidloss -1231.46243  last_update 6\n",
      "train: iter 288  trainloss -1296.74738  validloss -1165.05164±0.00000  bestvalidloss -1231.46243  last_update 7\n",
      "train: iter 289  trainloss -1261.96400  validloss -1182.11992±0.00000  bestvalidloss -1231.46243  last_update 8\n",
      "train: iter 290  trainloss -1107.84457  validloss -389.77102±0.00000  bestvalidloss -1231.46243  last_update 9\n",
      "train: iter 291  trainloss -1277.77979  validloss -1149.27798±0.00000  bestvalidloss -1231.46243  last_update 10\n",
      "train: iter 292  trainloss -1218.32737  validloss -961.74114±0.00000  bestvalidloss -1231.46243  last_update 11\n",
      "train: iter 293  trainloss -1003.10457  validloss -1222.20650±0.00000  bestvalidloss -1231.46243  last_update 12\n",
      "train: iter 294  trainloss -1190.65433  validloss -1096.16057±0.00000  bestvalidloss -1231.46243  last_update 13\n",
      "train: iter 295  trainloss -1198.21502  validloss -1058.34756±0.00000  bestvalidloss -1231.46243  last_update 14\n",
      "train: iter 296  trainloss -1229.73846  validloss -1079.26648±0.00000  bestvalidloss -1231.46243  last_update 15\n",
      "train: iter 297  trainloss -1273.11238  validloss -771.84307±0.00000  bestvalidloss -1231.46243  last_update 16\n",
      "train: iter 298  trainloss -1133.74889  validloss -1149.16761±0.00000  bestvalidloss -1231.46243  last_update 17\n",
      "train: iter 299  trainloss -1291.33012  validloss -1152.13156±0.00000  bestvalidloss -1231.46243  last_update 18\n",
      "train: iter 300  trainloss -1278.14878  validloss -1199.03882±0.00000  bestvalidloss -1231.46243  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 301  trainloss -1064.10669  validloss -1123.16266±0.00000  bestvalidloss -1231.46243  last_update 20\n",
      "train: iter 302  trainloss -1256.27587  validloss -1004.52530±0.00000  bestvalidloss -1231.46243  last_update 21\n",
      "train: iter 303  trainloss -1285.01005  validloss -1027.69158±0.00000  bestvalidloss -1231.46243  last_update 22\n",
      "train: iter 304  trainloss -1004.19061  validloss -1257.37804±0.00000  bestvalidloss -1257.37804  last_update 0\n",
      "train: iter 305  trainloss -1206.16439  validloss -959.06793±0.00000  bestvalidloss -1257.37804  last_update 1\n",
      "train: iter 306  trainloss -1269.02611  validloss -1182.48320±0.00000  bestvalidloss -1257.37804  last_update 2\n",
      "train: iter 307  trainloss -1238.07916  validloss -1185.48084±0.00000  bestvalidloss -1257.37804  last_update 3\n",
      "train: iter 308  trainloss -1337.04102  validloss -1198.83258±0.00000  bestvalidloss -1257.37804  last_update 4\n",
      "train: iter 309  trainloss -1142.46552  validloss -1284.81594±0.00000  bestvalidloss -1284.81594  last_update 0\n",
      "train: iter 310  trainloss -1288.25183  validloss -1079.46289±0.00000  bestvalidloss -1284.81594  last_update 1\n",
      "train: iter 311  trainloss -1179.58787  validloss -1220.99854±0.00000  bestvalidloss -1284.81594  last_update 2\n",
      "train: iter 312  trainloss -1170.53635  validloss -626.79024±0.00000  bestvalidloss -1284.81594  last_update 3\n",
      "train: iter 313  trainloss -1215.63801  validloss -811.84520±0.00000  bestvalidloss -1284.81594  last_update 4\n",
      "train: iter 314  trainloss -1346.12940  validloss -1230.58019±0.00000  bestvalidloss -1284.81594  last_update 5\n",
      "train: iter 315  trainloss -1191.51948  validloss -1176.99262±0.00000  bestvalidloss -1284.81594  last_update 6\n",
      "train: iter 316  trainloss -1328.33946  validloss -1232.34254±0.00000  bestvalidloss -1284.81594  last_update 7\n",
      "train: iter 317  trainloss -1189.28931  validloss -1234.33665±0.00000  bestvalidloss -1284.81594  last_update 8\n",
      "train: iter 318  trainloss -1284.21541  validloss -1017.40163±0.00000  bestvalidloss -1284.81594  last_update 9\n",
      "train: iter 319  trainloss -1281.27478  validloss -1245.91870±0.00000  bestvalidloss -1284.81594  last_update 10\n",
      "train: iter 320  trainloss -1153.99279  validloss -1120.88785±0.00000  bestvalidloss -1284.81594  last_update 11\n",
      "train: iter 321  trainloss -1329.15777  validloss -1237.06678±0.00000  bestvalidloss -1284.81594  last_update 12\n",
      "train: iter 322  trainloss -1266.25208  validloss -1191.11247±0.00000  bestvalidloss -1284.81594  last_update 13\n",
      "train: iter 323  trainloss -1310.76174  validloss -1183.22698±0.00000  bestvalidloss -1284.81594  last_update 14\n",
      "train: iter 324  trainloss -1315.69842  validloss -1235.73012±0.00000  bestvalidloss -1284.81594  last_update 15\n",
      "train: iter 325  trainloss -1175.95357  validloss -1146.20426±0.00000  bestvalidloss -1284.81594  last_update 16\n",
      "train: iter 326  trainloss -1365.12116  validloss -1245.10362±0.00000  bestvalidloss -1284.81594  last_update 17\n",
      "train: iter 327  trainloss -1241.49478  validloss -1190.75428±0.00000  bestvalidloss -1284.81594  last_update 18\n",
      "train: iter 328  trainloss -1207.68696  validloss -1072.27547±0.00000  bestvalidloss -1284.81594  last_update 19\n",
      "train: iter 329  trainloss -1329.66144  validloss -1188.65127±0.00000  bestvalidloss -1284.81594  last_update 20\n",
      "train: iter 330  trainloss -1363.58432  validloss -1147.92840±0.00000  bestvalidloss -1284.81594  last_update 21\n",
      "train: iter 331  trainloss -1265.25397  validloss -1233.80889±0.00000  bestvalidloss -1284.81594  last_update 22\n",
      "train: iter 332  trainloss -1298.25361  validloss -1153.26552±0.00000  bestvalidloss -1284.81594  last_update 23\n",
      "train: iter 333  trainloss -1315.95209  validloss -1195.15879±0.00000  bestvalidloss -1284.81594  last_update 24\n",
      "train: iter 334  trainloss -1338.43068  validloss -1257.85448±0.00000  bestvalidloss -1284.81594  last_update 25\n",
      "train: iter 335  trainloss -1284.23083  validloss -1253.84182±0.00000  bestvalidloss -1284.81594  last_update 26\n",
      "train: iter 336  trainloss -1088.83042  validloss -1150.05178±0.00000  bestvalidloss -1284.81594  last_update 27\n",
      "train: iter 337  trainloss -1273.44844  validloss -1172.01114±0.00000  bestvalidloss -1284.81594  last_update 28\n",
      "train: iter 338  trainloss -1350.83283  validloss -1220.80657±0.00000  bestvalidloss -1284.81594  last_update 29\n",
      "train: iter 339  trainloss -1362.50474  validloss -1230.27557±0.00000  bestvalidloss -1284.81594  last_update 30\n",
      "train: iter 340  trainloss -1324.80860  validloss -1301.29884±0.00000  bestvalidloss -1301.29884  last_update 0\n",
      "train: iter 341  trainloss -1115.03406  validloss -1232.37145±0.00000  bestvalidloss -1301.29884  last_update 1\n",
      "train: iter 342  trainloss -1119.17083  validloss -316.42159±0.00000  bestvalidloss -1301.29884  last_update 2\n",
      "train: iter 343  trainloss -1333.30995  validloss -1119.68107±0.00000  bestvalidloss -1301.29884  last_update 3\n",
      "train: iter 344  trainloss -1190.19238  validloss -1293.07524±0.00000  bestvalidloss -1301.29884  last_update 4\n",
      "train: iter 345  trainloss -1253.60360  validloss -683.35809±0.00000  bestvalidloss -1301.29884  last_update 5\n",
      "train: iter 346  trainloss -1330.46789  validloss -1095.29570±0.00000  bestvalidloss -1301.29884  last_update 6\n",
      "train: iter 347  trainloss -1383.88449  validloss -1335.15853±0.00000  bestvalidloss -1335.15853  last_update 0\n",
      "train: iter 348  trainloss -1253.05812  validloss -549.85092±0.00000  bestvalidloss -1335.15853  last_update 1\n",
      "train: iter 349  trainloss -1298.17676  validloss -1209.03508±0.00000  bestvalidloss -1335.15853  last_update 2\n",
      "train: iter 350  trainloss -1288.38395  validloss -1173.98608±0.00000  bestvalidloss -1335.15853  last_update 3\n",
      "train: iter 351  trainloss -1277.49690  validloss -895.09388±0.00000  bestvalidloss -1335.15853  last_update 4\n",
      "train: iter 352  trainloss -1351.87831  validloss -1126.53294±0.00000  bestvalidloss -1335.15853  last_update 5\n",
      "train: iter 353  trainloss -1339.74854  validloss -1111.28494±0.00000  bestvalidloss -1335.15853  last_update 6\n",
      "train: iter 354  trainloss -1359.20440  validloss -1194.64243±0.00000  bestvalidloss -1335.15853  last_update 7\n",
      "train: iter 355  trainloss -1296.91201  validloss -1242.22716±0.00000  bestvalidloss -1335.15853  last_update 8\n",
      "train: iter 356  trainloss -1300.39788  validloss -1110.85782±0.00000  bestvalidloss -1335.15853  last_update 9\n",
      "train: iter 357  trainloss -1298.58945  validloss -1014.82182±0.00000  bestvalidloss -1335.15853  last_update 10\n",
      "train: iter 358  trainloss -1248.58223  validloss -1291.48554±0.00000  bestvalidloss -1335.15853  last_update 11\n",
      "train: iter 359  trainloss -1237.51276  validloss -974.10241±0.00000  bestvalidloss -1335.15853  last_update 12\n",
      "train: iter 360  trainloss -1181.67095  validloss -1004.34997±0.00000  bestvalidloss -1335.15853  last_update 13\n",
      "train: iter 361  trainloss -1383.90604  validloss -1261.44460±0.00000  bestvalidloss -1335.15853  last_update 14\n",
      "train: iter 362  trainloss -1409.90919  validloss -1307.03757±0.00000  bestvalidloss -1335.15853  last_update 15\n",
      "train: iter 363  trainloss -1366.94909  validloss -1267.56204±0.00000  bestvalidloss -1335.15853  last_update 16\n",
      "train: iter 364  trainloss -1372.83653  validloss -1302.77864±0.00000  bestvalidloss -1335.15853  last_update 17\n",
      "train: iter 365  trainloss -1039.44578  validloss -1215.68698±0.00000  bestvalidloss -1335.15853  last_update 18\n",
      "train: iter 366  trainloss -1306.81036  validloss -1155.10484±0.00000  bestvalidloss -1335.15853  last_update 19\n",
      "train: iter 367  trainloss -1386.53049  validloss -1270.87230±0.00000  bestvalidloss -1335.15853  last_update 20\n",
      "train: iter 368  trainloss -1362.65821  validloss -1307.47417±0.00000  bestvalidloss -1335.15853  last_update 21\n",
      "train: iter 369  trainloss -1269.15752  validloss -1197.89994±0.00000  bestvalidloss -1335.15853  last_update 22\n",
      "train: iter 370  trainloss -96.56979  validloss -129.62007±0.00000  bestvalidloss -1335.15853  last_update 23\n",
      "train: iter 371  trainloss -834.91143  validloss -663.67724±0.00000  bestvalidloss -1335.15853  last_update 24\n",
      "train: iter 372  trainloss -1170.53910  validloss -976.08340±0.00000  bestvalidloss -1335.15853  last_update 25\n",
      "train: iter 373  trainloss -1220.41562  validloss -1115.92530±0.00000  bestvalidloss -1335.15853  last_update 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 374  trainloss -1310.45466  validloss -1168.99796±0.00000  bestvalidloss -1335.15853  last_update 27\n",
      "train: iter 375  trainloss -1328.18365  validloss -1188.98141±0.00000  bestvalidloss -1335.15853  last_update 28\n",
      "train: iter 376  trainloss -1242.27824  validloss -838.50778±0.00000  bestvalidloss -1335.15853  last_update 29\n",
      "train: iter 377  trainloss -1307.41387  validloss -1239.86012±0.00000  bestvalidloss -1335.15853  last_update 30\n",
      "train: iter 378  trainloss -1334.92233  validloss -1245.22395±0.00000  bestvalidloss -1335.15853  last_update 31\n",
      "train: iter 379  trainloss -1264.35337  validloss -1279.29815±0.00000  bestvalidloss -1335.15853  last_update 32\n",
      "train: iter 380  trainloss -1374.68015  validloss -1268.84681±0.00000  bestvalidloss -1335.15853  last_update 33\n",
      "train: iter 381  trainloss -1383.87511  validloss -1288.81850±0.00000  bestvalidloss -1335.15853  last_update 34\n",
      "train: iter 382  trainloss -1400.35123  validloss -1284.79749±0.00000  bestvalidloss -1335.15853  last_update 35\n",
      "train: iter 383  trainloss -1320.87056  validloss -1262.18327±0.00000  bestvalidloss -1335.15853  last_update 36\n",
      "train: iter 384  trainloss -1220.46358  validloss -806.51003±0.00000  bestvalidloss -1335.15853  last_update 37\n",
      "train: iter 385  trainloss -1357.24680  validloss -972.27054±0.00000  bestvalidloss -1335.15853  last_update 38\n",
      "train: iter 386  trainloss -1412.46501  validloss -1288.57307±0.00000  bestvalidloss -1335.15853  last_update 39\n",
      "train: iter 387  trainloss -1429.35410  validloss -1326.23855±0.00000  bestvalidloss -1335.15853  last_update 40\n",
      "train: iter 388  trainloss -1359.96273  validloss -1161.97963±0.00000  bestvalidloss -1335.15853  last_update 41\n",
      "train: iter 389  trainloss -1328.36765  validloss -1146.93295±0.00000  bestvalidloss -1335.15853  last_update 42\n",
      "train: iter 390  trainloss -1414.67721  validloss -1304.06282±0.00000  bestvalidloss -1335.15853  last_update 43\n",
      "train: iter 391  trainloss -1389.66782  validloss -1305.95540±0.00000  bestvalidloss -1335.15853  last_update 44\n",
      "train: iter 392  trainloss -1277.64241  validloss -1219.07643±0.00000  bestvalidloss -1335.15853  last_update 45\n",
      "train: iter 393  trainloss -1268.38690  validloss -961.26218±0.00000  bestvalidloss -1335.15853  last_update 46\n",
      "train: iter 394  trainloss -1370.94771  validloss -1227.63047±0.00000  bestvalidloss -1335.15853  last_update 47\n",
      "train: iter 395  trainloss -1357.66143  validloss -1271.98061±0.00000  bestvalidloss -1335.15853  last_update 48\n",
      "train: iter 396  trainloss -1266.24093  validloss -1347.56290±0.00000  bestvalidloss -1347.56290  last_update 0\n",
      "train: iter 397  trainloss -1375.94962  validloss -1196.84583±0.00000  bestvalidloss -1347.56290  last_update 1\n",
      "train: iter 398  trainloss -1421.97720  validloss -1264.31570±0.00000  bestvalidloss -1347.56290  last_update 2\n",
      "train: iter 399  trainloss -1362.57085  validloss -1343.61760±0.00000  bestvalidloss -1347.56290  last_update 3\n",
      "train: iter 400  trainloss -1343.92981  validloss -1280.34310±0.00000  bestvalidloss -1347.56290  last_update 4\n",
      "train: iter 401  trainloss -1249.27022  validloss -957.98619±0.00000  bestvalidloss -1347.56290  last_update 5\n",
      "train: iter 402  trainloss -1205.33128  validloss -973.60510±0.00000  bestvalidloss -1347.56290  last_update 6\n",
      "train: iter 403  trainloss -1384.21143  validloss -1134.15670±0.00000  bestvalidloss -1347.56290  last_update 7\n",
      "train: iter 404  trainloss -1231.27968  validloss -1338.38656±0.00000  bestvalidloss -1347.56290  last_update 8\n",
      "train: iter 405  trainloss -1339.10784  validloss -1281.26604±0.00000  bestvalidloss -1347.56290  last_update 9\n",
      "train: iter 406  trainloss -1420.04663  validloss -1324.01961±0.00000  bestvalidloss -1347.56290  last_update 10\n",
      "train: iter 407  trainloss -1433.33960  validloss -1335.01402±0.00000  bestvalidloss -1347.56290  last_update 11\n",
      "train: iter 408  trainloss -1391.53599  validloss -1343.61536±0.00000  bestvalidloss -1347.56290  last_update 12\n",
      "train: iter 409  trainloss -1084.99928  validloss -1234.54940±0.00000  bestvalidloss -1347.56290  last_update 13\n",
      "train: iter 410  trainloss -1225.62202  validloss -936.42694±0.00000  bestvalidloss -1347.56290  last_update 14\n",
      "train: iter 411  trainloss -1128.69637  validloss -1117.85117±0.00000  bestvalidloss -1347.56290  last_update 15\n",
      "train: iter 412  trainloss -1407.03373  validloss -1213.56735±0.00000  bestvalidloss -1347.56290  last_update 16\n",
      "train: iter 413  trainloss -1384.73034  validloss -1325.79839±0.00000  bestvalidloss -1347.56290  last_update 17\n",
      "train: iter 414  trainloss -1403.06659  validloss -1271.34452±0.00000  bestvalidloss -1347.56290  last_update 18\n",
      "train: iter 415  trainloss -1403.57262  validloss -1312.36469±0.00000  bestvalidloss -1347.56290  last_update 19\n",
      "train: iter 416  trainloss -1429.95279  validloss -1351.40756±0.00000  bestvalidloss -1351.40756  last_update 0\n",
      "train: iter 417  trainloss -1365.15730  validloss -1264.19537±0.00000  bestvalidloss -1351.40756  last_update 1\n",
      "train: iter 418  trainloss -1381.49919  validloss -1382.97216±0.00000  bestvalidloss -1382.97216  last_update 0\n",
      "train: iter 419  trainloss -1371.04500  validloss -1285.81622±0.00000  bestvalidloss -1382.97216  last_update 1\n",
      "train: iter 420  trainloss -1390.53570  validloss -1314.31616±0.00000  bestvalidloss -1382.97216  last_update 2\n",
      "train: iter 421  trainloss -1426.93994  validloss -1297.30746±0.00000  bestvalidloss -1382.97216  last_update 3\n",
      "train: iter 422  trainloss -1348.12765  validloss -1363.30383±0.00000  bestvalidloss -1382.97216  last_update 4\n",
      "train: iter 423  trainloss -1409.71756  validloss -1296.28250±0.00000  bestvalidloss -1382.97216  last_update 5\n",
      "train: iter 424  trainloss -1371.68742  validloss -1288.68766±0.00000  bestvalidloss -1382.97216  last_update 6\n",
      "train: iter 425  trainloss -1404.83321  validloss -1136.26673±0.00000  bestvalidloss -1382.97216  last_update 7\n",
      "train: iter 426  trainloss -1392.44103  validloss -1367.05667±0.00000  bestvalidloss -1382.97216  last_update 8\n",
      "train: iter 427  trainloss -1276.38769  validloss -1368.36955±0.00000  bestvalidloss -1382.97216  last_update 9\n",
      "train: iter 428  trainloss -1388.93285  validloss -1238.91798±0.00000  bestvalidloss -1382.97216  last_update 10\n",
      "train: iter 429  trainloss -1455.63466  validloss -1351.00320±0.00000  bestvalidloss -1382.97216  last_update 11\n",
      "train: iter 430  trainloss -1366.38862  validloss -1365.31602±0.00000  bestvalidloss -1382.97216  last_update 12\n",
      "train: iter 431  trainloss -1342.21468  validloss -1346.87200±0.00000  bestvalidloss -1382.97216  last_update 13\n",
      "train: iter 432  trainloss -1220.78262  validloss -1273.21004±0.00000  bestvalidloss -1382.97216  last_update 14\n",
      "train: iter 433  trainloss -1318.63135  validloss -1288.74049±0.00000  bestvalidloss -1382.97216  last_update 15\n",
      "train: iter 434  trainloss -1424.61822  validloss -1356.87042±0.00000  bestvalidloss -1382.97216  last_update 16\n",
      "train: iter 435  trainloss -1361.60576  validloss -1296.08834±0.00000  bestvalidloss -1382.97216  last_update 17\n",
      "train: iter 436  trainloss -1454.59444  validloss -1338.86703±0.00000  bestvalidloss -1382.97216  last_update 18\n",
      "train: iter 437  trainloss -1474.83887  validloss -1372.15949±0.00000  bestvalidloss -1382.97216  last_update 19\n",
      "train: iter 438  trainloss -1253.88696  validloss -1391.64576±0.00000  bestvalidloss -1391.64576  last_update 0\n",
      "train: iter 439  trainloss -1407.27536  validloss -1202.83984±0.00000  bestvalidloss -1391.64576  last_update 1\n",
      "train: iter 440  trainloss -1399.22861  validloss -1289.10113±0.00000  bestvalidloss -1391.64576  last_update 2\n",
      "train: iter 441  trainloss -1347.93914  validloss -975.09778±0.00000  bestvalidloss -1391.64576  last_update 3\n",
      "train: iter 442  trainloss -1460.95567  validloss -1379.12496±0.00000  bestvalidloss -1391.64576  last_update 4\n",
      "train: iter 443  trainloss -1394.33598  validloss -1255.76500±0.00000  bestvalidloss -1391.64576  last_update 5\n",
      "train: iter 444  trainloss -1419.26461  validloss -1315.52798±0.00000  bestvalidloss -1391.64576  last_update 6\n",
      "train: iter 445  trainloss -1443.07878  validloss -1367.36259±0.00000  bestvalidloss -1391.64576  last_update 7\n",
      "train: iter 446  trainloss -1271.27297  validloss -1117.78018±0.00000  bestvalidloss -1391.64576  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 447  trainloss -1385.49204  validloss -1274.48588±0.00000  bestvalidloss -1391.64576  last_update 9\n",
      "train: iter 448  trainloss -1429.36226  validloss -1346.53327±0.00000  bestvalidloss -1391.64576  last_update 10\n",
      "train: iter 449  trainloss -1314.99870  validloss -1387.80646±0.00000  bestvalidloss -1391.64576  last_update 11\n",
      "train: iter 450  trainloss -1382.96784  validloss -1276.34202±0.00000  bestvalidloss -1391.64576  last_update 12\n",
      "train: iter 451  trainloss -1479.71202  validloss -1320.70258±0.00000  bestvalidloss -1391.64576  last_update 13\n",
      "train: iter 452  trainloss -1416.19918  validloss -1420.85123±0.00000  bestvalidloss -1420.85123  last_update 0\n",
      "train: iter 453  trainloss -1015.63801  validloss -1273.40971±0.00000  bestvalidloss -1420.85123  last_update 1\n",
      "train: iter 454  trainloss -1223.73624  validloss -681.99562±0.00000  bestvalidloss -1420.85123  last_update 2\n",
      "train: iter 455  trainloss -1296.02162  validloss -658.23105±0.00000  bestvalidloss -1420.85123  last_update 3\n",
      "train: iter 456  trainloss -1420.62303  validloss -1286.83231±0.00000  bestvalidloss -1420.85123  last_update 4\n",
      "train: iter 457  trainloss -1442.79567  validloss -1352.67366±0.00000  bestvalidloss -1420.85123  last_update 5\n",
      "train: iter 458  trainloss -1322.38551  validloss -1284.96500±0.00000  bestvalidloss -1420.85123  last_update 6\n",
      "train: iter 459  trainloss -1387.32916  validloss -989.20864±0.00000  bestvalidloss -1420.85123  last_update 7\n",
      "train: iter 460  trainloss -1468.13727  validloss -1387.68138±0.00000  bestvalidloss -1420.85123  last_update 8\n",
      "train: iter 461  trainloss -1380.58391  validloss -1407.61026±0.00000  bestvalidloss -1420.85123  last_update 9\n",
      "train: iter 462  trainloss -1378.43574  validloss -1218.89724±0.00000  bestvalidloss -1420.85123  last_update 10\n",
      "train: iter 463  trainloss -1474.33010  validloss -1345.54356±0.00000  bestvalidloss -1420.85123  last_update 11\n",
      "train: iter 464  trainloss -1409.36238  validloss -1356.95731±0.00000  bestvalidloss -1420.85123  last_update 12\n",
      "train: iter 465  trainloss -1435.49632  validloss -1287.73504±0.00000  bestvalidloss -1420.85123  last_update 13\n",
      "train: iter 466  trainloss -1336.54811  validloss -1292.42807±0.00000  bestvalidloss -1420.85123  last_update 14\n",
      "train: iter 467  trainloss -1383.27577  validloss -1257.81773±0.00000  bestvalidloss -1420.85123  last_update 15\n",
      "train: iter 468  trainloss -1343.71153  validloss -1039.90171±0.00000  bestvalidloss -1420.85123  last_update 16\n",
      "train: iter 469  trainloss -1457.60574  validloss -1338.41800±0.00000  bestvalidloss -1420.85123  last_update 17\n",
      "train: iter 470  trainloss -1301.49672  validloss -1395.37820±0.00000  bestvalidloss -1420.85123  last_update 18\n",
      "train: iter 471  trainloss -1237.97828  validloss -1000.51500±0.00000  bestvalidloss -1420.85123  last_update 19\n",
      "train: iter 472  trainloss -1460.78239  validloss -1322.98579±0.00000  bestvalidloss -1420.85123  last_update 20\n",
      "train: iter 473  trainloss -1426.04564  validloss -1395.43846±0.00000  bestvalidloss -1420.85123  last_update 21\n",
      "train: iter 474  trainloss -1493.94745  validloss -1382.64932±0.00000  bestvalidloss -1420.85123  last_update 22\n",
      "train: iter 475  trainloss -1379.22279  validloss -1317.67712±0.00000  bestvalidloss -1420.85123  last_update 23\n",
      "train: iter 476  trainloss -1378.02492  validloss -1135.72814±0.00000  bestvalidloss -1420.85123  last_update 24\n",
      "train: iter 477  trainloss -1439.72070  validloss -1356.10999±0.00000  bestvalidloss -1420.85123  last_update 25\n",
      "train: iter 478  trainloss -1455.53275  validloss -1338.69448±0.00000  bestvalidloss -1420.85123  last_update 26\n",
      "train: iter 479  trainloss -1482.65753  validloss -1367.82446±0.00000  bestvalidloss -1420.85123  last_update 27\n",
      "train: iter 480  trainloss -1359.55970  validloss -1332.07984±0.00000  bestvalidloss -1420.85123  last_update 28\n",
      "train: iter 481  trainloss -1415.46699  validloss -1181.81412±0.00000  bestvalidloss -1420.85123  last_update 29\n",
      "train: iter 482  trainloss -1470.06780  validloss -1368.49473±0.00000  bestvalidloss -1420.85123  last_update 30\n",
      "train: iter 483  trainloss -984.05828  validloss -1365.37607±0.00000  bestvalidloss -1420.85123  last_update 31\n",
      "train: iter 484  trainloss -1254.44833  validloss -770.40384±0.00000  bestvalidloss -1420.85123  last_update 32\n",
      "train: iter 485  trainloss -1390.18912  validloss -1190.74907±0.00000  bestvalidloss -1420.85123  last_update 33\n",
      "train: iter 486  trainloss -1440.14818  validloss -1267.86064±0.00000  bestvalidloss -1420.85123  last_update 34\n",
      "train: iter 487  trainloss -1450.21294  validloss -1368.12686±0.00000  bestvalidloss -1420.85123  last_update 35\n",
      "train: iter 488  trainloss -1457.56885  validloss -1301.57743±0.00000  bestvalidloss -1420.85123  last_update 36\n",
      "train: iter 489  trainloss -1463.50533  validloss -1250.57634±0.00000  bestvalidloss -1420.85123  last_update 37\n",
      "train: iter 490  trainloss -1365.11960  validloss -1195.98962±0.00000  bestvalidloss -1420.85123  last_update 38\n",
      "train: iter 491  trainloss -1362.05147  validloss -1312.72224±0.00000  bestvalidloss -1420.85123  last_update 39\n",
      "train: iter 492  trainloss -1403.08548  validloss -1206.42974±0.00000  bestvalidloss -1420.85123  last_update 40\n",
      "train: iter 493  trainloss -1329.18542  validloss -1285.95702±0.00000  bestvalidloss -1420.85123  last_update 41\n",
      "train: iter 494  trainloss -814.04393  validloss -44.91845±0.00000  bestvalidloss -1420.85123  last_update 42\n",
      "train: iter 495  trainloss -1182.87570  validloss -902.75018±0.00000  bestvalidloss -1420.85123  last_update 43\n",
      "train: iter 496  trainloss -1292.08755  validloss -1030.28363±0.00000  bestvalidloss -1420.85123  last_update 44\n",
      "train: iter 497  trainloss -1382.05580  validloss -1221.97744±0.00000  bestvalidloss -1420.85123  last_update 45\n",
      "train: iter 498  trainloss -1406.17092  validloss -1252.77793±0.00000  bestvalidloss -1420.85123  last_update 46\n",
      "train: iter 499  trainloss -1469.87720  validloss -1323.92449±0.00000  bestvalidloss -1420.85123  last_update 47\n",
      "train: iter 500  trainloss -1466.69428  validloss -1363.64844±0.00000  bestvalidloss -1420.85123  last_update 48\n",
      "train: iter 501  trainloss -1448.29588  validloss -1195.65397±0.00000  bestvalidloss -1420.85123  last_update 49\n",
      "train: iter 502  trainloss -1436.70723  validloss -1333.84915±0.00000  bestvalidloss -1420.85123  last_update 50\n",
      "train: iter 503  trainloss -1427.02430  validloss -1375.93070±0.00000  bestvalidloss -1420.85123  last_update 51\n",
      "train: iter 504  trainloss -1445.17764  validloss -1250.82577±0.00000  bestvalidloss -1420.85123  last_update 52\n",
      "train: iter 505  trainloss -1416.50547  validloss -1339.62140±0.00000  bestvalidloss -1420.85123  last_update 53\n",
      "train: iter 506  trainloss -1351.60260  validloss -1325.81798±0.00000  bestvalidloss -1420.85123  last_update 54\n",
      "train: iter 507  trainloss -1415.19726  validloss -1281.96206±0.00000  bestvalidloss -1420.85123  last_update 55\n",
      "train: iter 508  trainloss -1463.01171  validloss -1368.75041±0.00000  bestvalidloss -1420.85123  last_update 56\n",
      "train: iter 509  trainloss -1445.20471  validloss -1323.93440±0.00000  bestvalidloss -1420.85123  last_update 57\n",
      "train: iter 510  trainloss -1452.96909  validloss -1341.82161±0.00000  bestvalidloss -1420.85123  last_update 58\n",
      "train: iter 511  trainloss -1381.37803  validloss -1394.20644±0.00000  bestvalidloss -1420.85123  last_update 59\n",
      "train: iter 512  trainloss -1425.68516  validloss -1339.12703±0.00000  bestvalidloss -1420.85123  last_update 60\n",
      "train: iter 513  trainloss -1518.04855  validloss -1401.64043±0.00000  bestvalidloss -1420.85123  last_update 61\n",
      "train: iter 514  trainloss -1349.66135  validloss -1392.28432±0.00000  bestvalidloss -1420.85123  last_update 62\n",
      "train: iter 515  trainloss -1440.41196  validloss -1365.68713±0.00000  bestvalidloss -1420.85123  last_update 63\n",
      "train: iter 516  trainloss -1351.21235  validloss -1264.75338±0.00000  bestvalidloss -1420.85123  last_update 64\n",
      "train: iter 517  trainloss -1329.57734  validloss -1102.87188±0.00000  bestvalidloss -1420.85123  last_update 65\n",
      "train: iter 518  trainloss -1512.52906  validloss -1355.29991±0.00000  bestvalidloss -1420.85123  last_update 66\n",
      "train: iter 519  trainloss -1474.28758  validloss -1397.84494±0.00000  bestvalidloss -1420.85123  last_update 67\n",
      "train: iter 520  trainloss -1357.06688  validloss -1248.68840±0.00000  bestvalidloss -1420.85123  last_update 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 521  trainloss -1477.00417  validloss -1371.34752±0.00000  bestvalidloss -1420.85123  last_update 69\n",
      "train: iter 522  trainloss -1463.12017  validloss -1402.07131±0.00000  bestvalidloss -1420.85123  last_update 70\n",
      "train: iter 523  trainloss -1430.94597  validloss -1246.20914±0.00000  bestvalidloss -1420.85123  last_update 71\n",
      "train: iter 524  trainloss -1480.83287  validloss -1426.20462±0.00000  bestvalidloss -1426.20462  last_update 0\n",
      "train: iter 525  trainloss -1406.96016  validloss -1169.66577±0.00000  bestvalidloss -1426.20462  last_update 1\n",
      "train: iter 526  trainloss -1442.05254  validloss -1380.69867±0.00000  bestvalidloss -1426.20462  last_update 2\n",
      "train: iter 527  trainloss -1376.65991  validloss -1072.64895±0.00000  bestvalidloss -1426.20462  last_update 3\n",
      "train: iter 528  trainloss -1401.10120  validloss -652.52409±0.00000  bestvalidloss -1426.20462  last_update 4\n",
      "train: iter 529  trainloss -1464.92362  validloss -1365.14262±0.00000  bestvalidloss -1426.20462  last_update 5\n",
      "train: iter 530  trainloss -1469.27695  validloss -1325.75618±0.00000  bestvalidloss -1426.20462  last_update 6\n",
      "train: iter 531  trainloss -1423.00978  validloss -1332.84356±0.00000  bestvalidloss -1426.20462  last_update 7\n",
      "train: iter 532  trainloss -1456.66128  validloss -1323.24639±0.00000  bestvalidloss -1426.20462  last_update 8\n",
      "train: iter 533  trainloss -1356.36194  validloss -1404.34866±0.00000  bestvalidloss -1426.20462  last_update 9\n",
      "train: iter 534  trainloss -1439.44282  validloss -958.64061±0.00000  bestvalidloss -1426.20462  last_update 10\n",
      "train: iter 535  trainloss -1473.04625  validloss -1397.76632±0.00000  bestvalidloss -1426.20462  last_update 11\n",
      "train: iter 536  trainloss -1444.36479  validloss -1400.51560±0.00000  bestvalidloss -1426.20462  last_update 12\n",
      "train: iter 537  trainloss -1452.00349  validloss -1222.63609±0.00000  bestvalidloss -1426.20462  last_update 13\n",
      "train: iter 538  trainloss -1421.42772  validloss -1422.27086±0.00000  bestvalidloss -1426.20462  last_update 14\n",
      "train: iter 539  trainloss -1419.60665  validloss -1285.27488±0.00000  bestvalidloss -1426.20462  last_update 15\n",
      "train: iter 540  trainloss -1324.98679  validloss -1079.95771±0.00000  bestvalidloss -1426.20462  last_update 16\n",
      "train: iter 541  trainloss -1437.27320  validloss -1339.48422±0.00000  bestvalidloss -1426.20462  last_update 17\n",
      "train: iter 542  trainloss -1495.38109  validloss -1397.18992±0.00000  bestvalidloss -1426.20462  last_update 18\n",
      "train: iter 543  trainloss -1388.84805  validloss -1387.74102±0.00000  bestvalidloss -1426.20462  last_update 19\n",
      "train: iter 544  trainloss -1485.98509  validloss -1400.76429±0.00000  bestvalidloss -1426.20462  last_update 20\n",
      "train: iter 545  trainloss -1489.78710  validloss -1439.12243±0.00000  bestvalidloss -1439.12243  last_update 0\n",
      "train: iter 546  trainloss -1472.45713  validloss -1382.89038±0.00000  bestvalidloss -1439.12243  last_update 1\n",
      "train: iter 547  trainloss -1444.80657  validloss -1030.05638±0.00000  bestvalidloss -1439.12243  last_update 2\n",
      "train: iter 548  trainloss -1475.95883  validloss -1432.99125±0.00000  bestvalidloss -1439.12243  last_update 3\n",
      "train: iter 549  trainloss -1390.27847  validloss -1349.04673±0.00000  bestvalidloss -1439.12243  last_update 4\n",
      "train: iter 550  trainloss -1476.41003  validloss -1379.27531±0.00000  bestvalidloss -1439.12243  last_update 5\n",
      "train: iter 551  trainloss -1278.80130  validloss -1423.28123±0.00000  bestvalidloss -1439.12243  last_update 6\n",
      "train: iter 552  trainloss -1397.95152  validloss -1038.64123±0.00000  bestvalidloss -1439.12243  last_update 7\n",
      "train: iter 553  trainloss -1300.40868  validloss -1268.77329±0.00000  bestvalidloss -1439.12243  last_update 8\n",
      "train: iter 554  trainloss -1454.59973  validloss -1260.63644±0.00000  bestvalidloss -1439.12243  last_update 9\n",
      "train: iter 555  trainloss -1492.77628  validloss -1391.61108±0.00000  bestvalidloss -1439.12243  last_update 10\n",
      "train: iter 556  trainloss -1383.94571  validloss -1432.19894±0.00000  bestvalidloss -1439.12243  last_update 11\n",
      "train: iter 557  trainloss -1227.86909  validloss -1284.26568±0.00000  bestvalidloss -1439.12243  last_update 12\n",
      "train: iter 558  trainloss -1449.84395  validloss -1332.46420±0.00000  bestvalidloss -1439.12243  last_update 13\n",
      "train: iter 559  trainloss -1487.59540  validloss -1350.14192±0.00000  bestvalidloss -1439.12243  last_update 14\n",
      "train: iter 560  trainloss -1494.83457  validloss -1424.69994±0.00000  bestvalidloss -1439.12243  last_update 15\n",
      "train: iter 561  trainloss -1502.25347  validloss -1445.12581±0.00000  bestvalidloss -1445.12581  last_update 0\n",
      "train: iter 562  trainloss -1401.71105  validloss -1428.84809±0.00000  bestvalidloss -1445.12581  last_update 1\n",
      "train: iter 563  trainloss -1427.36033  validloss -1079.51936±0.00000  bestvalidloss -1445.12581  last_update 2\n",
      "train: iter 564  trainloss -1452.86233  validloss -1372.18443±0.00000  bestvalidloss -1445.12581  last_update 3\n",
      "train: iter 565  trainloss -1347.49084  validloss -1167.50274±0.00000  bestvalidloss -1445.12581  last_update 4\n",
      "train: iter 566  trainloss -1408.24929  validloss -1313.61392±0.00000  bestvalidloss -1445.12581  last_update 5\n",
      "train: iter 567  trainloss -1508.89200  validloss -1397.35840±0.00000  bestvalidloss -1445.12581  last_update 6\n",
      "train: iter 568  trainloss -1445.47957  validloss -1431.29221±0.00000  bestvalidloss -1445.12581  last_update 7\n",
      "train: iter 569  trainloss -1448.02982  validloss -1311.50114±0.00000  bestvalidloss -1445.12581  last_update 8\n",
      "train: iter 570  trainloss -1435.06646  validloss -1315.40900±0.00000  bestvalidloss -1445.12581  last_update 9\n",
      "train: iter 571  trainloss -1186.18610  validloss -1417.87113±0.00000  bestvalidloss -1445.12581  last_update 10\n",
      "train: iter 572  trainloss -1025.43597  validloss -490.33131±0.00000  bestvalidloss -1445.12581  last_update 11\n",
      "train: iter 573  trainloss -1367.04200  validloss -1157.10511±0.00000  bestvalidloss -1445.12581  last_update 12\n",
      "train: iter 574  trainloss -1439.83416  validloss -1265.81615±0.00000  bestvalidloss -1445.12581  last_update 13\n",
      "train: iter 575  trainloss -1434.39429  validloss -1349.02509±0.00000  bestvalidloss -1445.12581  last_update 14\n",
      "train: iter 576  trainloss -1459.46302  validloss -1297.59157±0.00000  bestvalidloss -1445.12581  last_update 15\n",
      "train: iter 577  trainloss -1508.71439  validloss -1360.76446±0.00000  bestvalidloss -1445.12581  last_update 16\n",
      "train: iter 578  trainloss -1480.56279  validloss -1420.27268±0.00000  bestvalidloss -1445.12581  last_update 17\n",
      "train: iter 579  trainloss -1496.87566  validloss -1379.96800±0.00000  bestvalidloss -1445.12581  last_update 18\n",
      "train: iter 580  trainloss -1460.50542  validloss -1428.18237±0.00000  bestvalidloss -1445.12581  last_update 19\n",
      "train: iter 581  trainloss -1367.69224  validloss -1364.41795±0.00000  bestvalidloss -1445.12581  last_update 20\n",
      "train: iter 582  trainloss -1488.42693  validloss -1340.89541±0.00000  bestvalidloss -1445.12581  last_update 21\n",
      "train: iter 583  trainloss -1469.34017  validloss -1432.38984±0.00000  bestvalidloss -1445.12581  last_update 22\n",
      "train: iter 584  trainloss -1477.82330  validloss -1375.33730±0.00000  bestvalidloss -1445.12581  last_update 23\n",
      "train: iter 585  trainloss -1231.44358  validloss -1326.98944±0.00000  bestvalidloss -1445.12581  last_update 24\n",
      "train: iter 586  trainloss -1309.35512  validloss -1088.99288±0.00000  bestvalidloss -1445.12581  last_update 25\n",
      "train: iter 587  trainloss -1477.30274  validloss -1250.20849±0.00000  bestvalidloss -1445.12581  last_update 26\n",
      "train: iter 588  trainloss -1399.48063  validloss -1406.51216±0.00000  bestvalidloss -1445.12581  last_update 27\n",
      "train: iter 589  trainloss -1456.13205  validloss -1328.98331±0.00000  bestvalidloss -1445.12581  last_update 28\n",
      "train: iter 590  trainloss -1403.41562  validloss -1343.10714±0.00000  bestvalidloss -1445.12581  last_update 29\n",
      "train: iter 591  trainloss -1480.34950  validloss -1346.81998±0.00000  bestvalidloss -1445.12581  last_update 30\n",
      "train: iter 592  trainloss -1521.15351  validloss -1376.49614±0.00000  bestvalidloss -1445.12581  last_update 31\n",
      "train: iter 593  trainloss -1257.37303  validloss -1299.74478±0.00000  bestvalidloss -1445.12581  last_update 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 594  trainloss -1435.05202  validloss -1248.09251±0.00000  bestvalidloss -1445.12581  last_update 33\n",
      "train: iter 595  trainloss -1494.78811  validloss -1358.38217±0.00000  bestvalidloss -1445.12581  last_update 34\n",
      "train: iter 596  trainloss -1453.70286  validloss -1279.48940±0.00000  bestvalidloss -1445.12581  last_update 35\n",
      "train: iter 597  trainloss -1489.30225  validloss -1236.78884±0.00000  bestvalidloss -1445.12581  last_update 36\n",
      "train: iter 598  trainloss -1391.43199  validloss -1452.86035±0.00000  bestvalidloss -1452.86035  last_update 0\n",
      "train: iter 599  trainloss -1424.64434  validloss -1293.43823±0.00000  bestvalidloss -1452.86035  last_update 1\n",
      "train: iter 600  trainloss -1532.20699  validloss -1417.23624±0.00000  bestvalidloss -1452.86035  last_update 2\n",
      "train: iter 601  trainloss -1505.29144  validloss -1460.17431±0.00000  bestvalidloss -1460.17431  last_update 0\n",
      "train: iter 602  trainloss -1483.57710  validloss -1344.22360±0.00000  bestvalidloss -1460.17431  last_update 1\n",
      "train: iter 603  trainloss -1450.44597  validloss -1400.71224±0.00000  bestvalidloss -1460.17431  last_update 2\n",
      "train: iter 604  trainloss -1407.57430  validloss -1217.45838±0.00000  bestvalidloss -1460.17431  last_update 3\n",
      "train: iter 605  trainloss -1520.50731  validloss -1414.05522±0.00000  bestvalidloss -1460.17431  last_update 4\n",
      "train: iter 606  trainloss -1500.91289  validloss -1454.61126±0.00000  bestvalidloss -1460.17431  last_update 5\n",
      "train: iter 607  trainloss -1483.75259  validloss -1388.85322±0.00000  bestvalidloss -1460.17431  last_update 6\n",
      "train: iter 608  trainloss -1493.04614  validloss -1393.08983±0.00000  bestvalidloss -1460.17431  last_update 7\n",
      "train: iter 609  trainloss -1404.31662  validloss -1246.09303±0.00000  bestvalidloss -1460.17431  last_update 8\n",
      "train: iter 610  trainloss -1429.01378  validloss -1375.15325±0.00000  bestvalidloss -1460.17431  last_update 9\n",
      "train: iter 611  trainloss -1329.42303  validloss -1239.87930±0.00000  bestvalidloss -1460.17431  last_update 10\n",
      "train: iter 612  trainloss -1500.45653  validloss -1318.14686±0.00000  bestvalidloss -1460.17431  last_update 11\n",
      "train: iter 613  trainloss -1531.96803  validloss -1425.05578±0.00000  bestvalidloss -1460.17431  last_update 12\n",
      "train: iter 614  trainloss -1468.11066  validloss -1454.49498±0.00000  bestvalidloss -1460.17431  last_update 13\n",
      "train: iter 615  trainloss -1496.89622  validloss -1347.65670±0.00000  bestvalidloss -1460.17431  last_update 14\n",
      "train: iter 616  trainloss -1453.82852  validloss -1389.08532±0.00000  bestvalidloss -1460.17431  last_update 15\n",
      "train: iter 617  trainloss -1449.58617  validloss -1301.76333±0.00000  bestvalidloss -1460.17431  last_update 16\n",
      "train: iter 618  trainloss -1310.56828  validloss -1440.83824±0.00000  bestvalidloss -1460.17431  last_update 17\n",
      "train: iter 619  trainloss -1407.16026  validloss -1235.85061±0.00000  bestvalidloss -1460.17431  last_update 18\n",
      "train: iter 620  trainloss -1468.67245  validloss -1303.60586±0.00000  bestvalidloss -1460.17431  last_update 19\n",
      "train: iter 621  trainloss -1485.65186  validloss -1429.26664±0.00000  bestvalidloss -1460.17431  last_update 20\n",
      "train: iter 622  trainloss -760.00934  validloss -996.00808±0.00000  bestvalidloss -1460.17431  last_update 21\n",
      "train: iter 623  trainloss -1155.52720  validloss -724.00442±0.00000  bestvalidloss -1460.17431  last_update 22\n",
      "train: iter 624  trainloss -1332.28488  validloss -1202.61570±0.00000  bestvalidloss -1460.17431  last_update 23\n",
      "train: iter 625  trainloss -1382.11771  validloss -1143.22083±0.00000  bestvalidloss -1460.17431  last_update 24\n",
      "train: iter 626  trainloss -1447.98816  validloss -1324.90325±0.00000  bestvalidloss -1460.17431  last_update 25\n",
      "train: iter 627  trainloss -1343.67235  validloss -990.65677±0.00000  bestvalidloss -1460.17431  last_update 26\n",
      "train: iter 628  trainloss -1379.11042  validloss -1224.48493±0.00000  bestvalidloss -1460.17431  last_update 27\n",
      "train: iter 629  trainloss -1432.28684  validloss -1290.74890±0.00000  bestvalidloss -1460.17431  last_update 28\n",
      "train: iter 630  trainloss -1432.46687  validloss -717.15919±0.00000  bestvalidloss -1460.17431  last_update 29\n",
      "train: iter 631  trainloss -1454.50711  validloss -1337.47384±0.00000  bestvalidloss -1460.17431  last_update 30\n",
      "train: iter 632  trainloss -1488.36943  validloss -1378.51853±0.00000  bestvalidloss -1460.17431  last_update 31\n",
      "train: iter 633  trainloss -1470.49586  validloss -1386.52567±0.00000  bestvalidloss -1460.17431  last_update 32\n",
      "train: iter 634  trainloss -1343.54297  validloss -1367.78448±0.00000  bestvalidloss -1460.17431  last_update 33\n",
      "train: iter 635  trainloss -1431.06571  validloss -1247.72591±0.00000  bestvalidloss -1460.17431  last_update 34\n",
      "train: iter 636  trainloss -1488.59114  validloss -1399.21015±0.00000  bestvalidloss -1460.17431  last_update 35\n",
      "train: iter 637  trainloss -1096.75596  validloss -1260.76226±0.00000  bestvalidloss -1460.17431  last_update 36\n",
      "train: iter 638  trainloss -1357.78302  validloss -1272.12517±0.00000  bestvalidloss -1460.17431  last_update 37\n",
      "train: iter 639  trainloss -1502.00683  validloss -1358.21444±0.00000  bestvalidloss -1460.17431  last_update 38\n",
      "train: iter 640  trainloss -1494.15443  validloss -1387.47530±0.00000  bestvalidloss -1460.17431  last_update 39\n",
      "train: iter 641  trainloss -1442.72668  validloss -1348.53530±0.00000  bestvalidloss -1460.17431  last_update 40\n",
      "train: iter 642  trainloss -1508.98962  validloss -1445.75551±0.00000  bestvalidloss -1460.17431  last_update 41\n",
      "train: iter 643  trainloss -1442.65247  validloss -1252.97295±0.00000  bestvalidloss -1460.17431  last_update 42\n",
      "train: iter 644  trainloss -1531.62501  validloss -1430.56486±0.00000  bestvalidloss -1460.17431  last_update 43\n",
      "train: iter 645  trainloss -1506.24713  validloss -1469.15301±0.00000  bestvalidloss -1469.15301  last_update 0\n",
      "train: iter 646  trainloss -1451.78364  validloss -1355.32694±0.00000  bestvalidloss -1469.15301  last_update 1\n",
      "train: iter 647  trainloss -1483.73214  validloss -1265.24244±0.00000  bestvalidloss -1469.15301  last_update 2\n",
      "train: iter 648  trainloss -1539.27970  validloss -1444.55594±0.00000  bestvalidloss -1469.15301  last_update 3\n",
      "train: iter 649  trainloss -1532.65024  validloss -1446.80086±0.00000  bestvalidloss -1469.15301  last_update 4\n",
      "train: iter 650  trainloss -1331.66133  validloss -1428.45760±0.00000  bestvalidloss -1469.15301  last_update 5\n",
      "train: iter 651  trainloss -1408.40127  validloss -1121.06614±0.00000  bestvalidloss -1469.15301  last_update 6\n",
      "train: iter 652  trainloss -1470.84041  validloss -1365.42771±0.00000  bestvalidloss -1469.15301  last_update 7\n",
      "train: iter 653  trainloss -1540.32890  validloss -1426.81376±0.00000  bestvalidloss -1469.15301  last_update 8\n",
      "train: iter 654  trainloss -1514.02244  validloss -1463.30999±0.00000  bestvalidloss -1469.15301  last_update 9\n",
      "train: iter 655  trainloss -1449.23957  validloss -1331.64303±0.00000  bestvalidloss -1469.15301  last_update 10\n",
      "train: iter 656  trainloss -1466.75474  validloss -1149.00989±0.00000  bestvalidloss -1469.15301  last_update 11\n",
      "train: iter 657  trainloss -1525.54314  validloss -1382.29331±0.00000  bestvalidloss -1469.15301  last_update 12\n",
      "train: iter 658  trainloss -1529.94531  validloss -1424.54779±0.00000  bestvalidloss -1469.15301  last_update 13\n",
      "train: iter 659  trainloss -1448.91032  validloss -1440.62753±0.00000  bestvalidloss -1469.15301  last_update 14\n",
      "train: iter 660  trainloss -1382.14178  validloss -1252.93465±0.00000  bestvalidloss -1469.15301  last_update 15\n",
      "train: iter 661  trainloss -1467.33562  validloss -1336.76504±0.00000  bestvalidloss -1469.15301  last_update 16\n",
      "train: iter 662  trainloss -1416.70882  validloss -1075.45327±0.00000  bestvalidloss -1469.15301  last_update 17\n",
      "train: iter 663  trainloss -1340.09289  validloss -1431.17982±0.00000  bestvalidloss -1469.15301  last_update 18\n",
      "train: iter 664  trainloss -1481.30584  validloss -1305.60477±0.00000  bestvalidloss -1469.15301  last_update 19\n",
      "train: iter 665  trainloss -1532.35076  validloss -1399.36811±0.00000  bestvalidloss -1469.15301  last_update 20\n",
      "train: iter 666  trainloss -1513.68416  validloss -1380.18513±0.00000  bestvalidloss -1469.15301  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 667  trainloss -1441.19561  validloss -1265.67201±0.00000  bestvalidloss -1469.15301  last_update 22\n",
      "train: iter 668  trainloss -1486.59156  validloss -1407.09101±0.00000  bestvalidloss -1469.15301  last_update 23\n",
      "train: iter 669  trainloss -1535.75773  validloss -1362.62189±0.00000  bestvalidloss -1469.15301  last_update 24\n",
      "train: iter 670  trainloss -1514.22196  validloss -1475.79296±0.00000  bestvalidloss -1475.79296  last_update 0\n",
      "train: iter 671  trainloss -1321.19401  validloss -1075.10116±0.00000  bestvalidloss -1475.79296  last_update 1\n",
      "train: iter 672  trainloss -1473.70589  validloss -1346.00424±0.00000  bestvalidloss -1475.79296  last_update 2\n",
      "train: iter 673  trainloss -1429.28009  validloss -1344.41488±0.00000  bestvalidloss -1475.79296  last_update 3\n",
      "train: iter 674  trainloss -1514.36024  validloss -1324.30040±0.00000  bestvalidloss -1475.79296  last_update 4\n",
      "train: iter 675  trainloss -1487.37311  validloss -1413.73065±0.00000  bestvalidloss -1475.79296  last_update 5\n",
      "train: iter 676  trainloss -1026.90081  validloss -977.77098±0.00000  bestvalidloss -1475.79296  last_update 6\n",
      "train: iter 677  trainloss -1419.86945  validloss -1221.74755±0.00000  bestvalidloss -1475.79296  last_update 7\n",
      "train: iter 678  trainloss -1403.28574  validloss -1038.01290±0.00000  bestvalidloss -1475.79296  last_update 8\n",
      "train: iter 679  trainloss -1466.16077  validloss -1336.77708±0.00000  bestvalidloss -1475.79296  last_update 9\n",
      "train: iter 680  trainloss -1400.27316  validloss -1431.22131±0.00000  bestvalidloss -1475.79296  last_update 10\n",
      "train: iter 681  trainloss -1492.46489  validloss -1382.97179±0.00000  bestvalidloss -1475.79296  last_update 11\n",
      "train: iter 682  trainloss -1390.13535  validloss -1321.23568±0.00000  bestvalidloss -1475.79296  last_update 12\n",
      "train: iter 683  trainloss -1383.24941  validloss -1090.85871±0.00000  bestvalidloss -1475.79296  last_update 13\n",
      "train: iter 684  trainloss -1497.01913  validloss -1334.28472±0.00000  bestvalidloss -1475.79296  last_update 14\n",
      "train: iter 685  trainloss -1519.72300  validloss -1401.99592±0.00000  bestvalidloss -1475.79296  last_update 15\n",
      "train: iter 686  trainloss -1546.39072  validloss -1394.84827±0.00000  bestvalidloss -1475.79296  last_update 16\n",
      "train: iter 687  trainloss -1540.43270  validloss -1440.95853±0.00000  bestvalidloss -1475.79296  last_update 17\n",
      "train: iter 688  trainloss -1516.49675  validloss -1453.51456±0.00000  bestvalidloss -1475.79296  last_update 18\n",
      "train: iter 689  trainloss -1443.14101  validloss -1469.60288±0.00000  bestvalidloss -1475.79296  last_update 19\n",
      "train: iter 690  trainloss -1481.75225  validloss -1390.38821±0.00000  bestvalidloss -1475.79296  last_update 20\n",
      "train: iter 691  trainloss -1328.74263  validloss -1134.28732±0.00000  bestvalidloss -1475.79296  last_update 21\n",
      "train: iter 692  trainloss -1517.64841  validloss -1326.90619±0.00000  bestvalidloss -1475.79296  last_update 22\n",
      "train: iter 693  trainloss -1524.08376  validloss -1411.65231±0.00000  bestvalidloss -1475.79296  last_update 23\n",
      "train: iter 694  trainloss -1235.72567  validloss -1319.56182±0.00000  bestvalidloss -1475.79296  last_update 24\n",
      "train: iter 695  trainloss -1497.45407  validloss -1325.42794±0.00000  bestvalidloss -1475.79296  last_update 25\n",
      "train: iter 696  trainloss -1534.38885  validloss -1427.93269±0.00000  bestvalidloss -1475.79296  last_update 26\n",
      "train: iter 697  trainloss -1502.94104  validloss -1442.02066±0.00000  bestvalidloss -1475.79296  last_update 27\n",
      "train: iter 698  trainloss -1523.76273  validloss -1352.33645±0.00000  bestvalidloss -1475.79296  last_update 28\n",
      "train: iter 699  trainloss -1518.80915  validloss -1396.55344±0.00000  bestvalidloss -1475.79296  last_update 29\n",
      "train: iter 700  trainloss -1321.08626  validloss -1370.50579±0.00000  bestvalidloss -1475.79296  last_update 30\n",
      "train: iter 701  trainloss -1438.13875  validloss -1146.53203±0.00000  bestvalidloss -1475.79296  last_update 31\n",
      "train: iter 702  trainloss -1536.69614  validloss -1416.56106±0.00000  bestvalidloss -1475.79296  last_update 32\n",
      "train: iter 703  trainloss -1515.76697  validloss -1454.57322±0.00000  bestvalidloss -1475.79296  last_update 33\n",
      "train: iter 704  trainloss -1532.04711  validloss -1392.40755±0.00000  bestvalidloss -1475.79296  last_update 34\n",
      "train: iter 705  trainloss -1304.38160  validloss -1449.27141±0.00000  bestvalidloss -1475.79296  last_update 35\n",
      "train: iter 706  trainloss -1467.97172  validloss -1272.64479±0.00000  bestvalidloss -1475.79296  last_update 36\n",
      "train: iter 707  trainloss -1515.26227  validloss -1387.63746±0.00000  bestvalidloss -1475.79296  last_update 37\n",
      "train: iter 708  trainloss -1512.47478  validloss -1432.19239±0.00000  bestvalidloss -1475.79296  last_update 38\n",
      "train: iter 709  trainloss -1502.17642  validloss -1381.29808±0.00000  bestvalidloss -1475.79296  last_update 39\n",
      "train: iter 710  trainloss -1554.33626  validloss -1435.80115±0.00000  bestvalidloss -1475.79296  last_update 40\n",
      "train: iter 711  trainloss -1430.72876  validloss -1477.44295±0.00000  bestvalidloss -1477.44295  last_update 0\n",
      "train: iter 712  trainloss -1238.97242  validloss -61.20536±0.00000  bestvalidloss -1477.44295  last_update 1\n",
      "train: iter 713  trainloss -1500.97040  validloss -1363.40411±0.00000  bestvalidloss -1477.44295  last_update 2\n",
      "train: iter 714  trainloss -1521.64533  validloss -1401.75241±0.00000  bestvalidloss -1477.44295  last_update 3\n",
      "train: iter 715  trainloss -1496.13325  validloss -1419.19365±0.00000  bestvalidloss -1477.44295  last_update 4\n",
      "train: iter 716  trainloss -1473.59529  validloss -1255.10458±0.00000  bestvalidloss -1477.44295  last_update 5\n",
      "train: iter 717  trainloss -1527.60571  validloss -1441.15560±0.00000  bestvalidloss -1477.44295  last_update 6\n",
      "train: iter 718  trainloss -1400.45248  validloss -1458.53096±0.00000  bestvalidloss -1477.44295  last_update 7\n",
      "train: iter 719  trainloss -1487.82188  validloss -1369.76483±0.00000  bestvalidloss -1477.44295  last_update 8\n",
      "train: iter 720  trainloss -1523.16023  validloss -1439.15825±0.00000  bestvalidloss -1477.44295  last_update 9\n",
      "train: iter 721  trainloss -1480.08018  validloss -1285.78382±0.00000  bestvalidloss -1477.44295  last_update 10\n",
      "train: iter 722  trainloss -1503.74699  validloss -1380.71109±0.00000  bestvalidloss -1477.44295  last_update 11\n",
      "train: iter 723  trainloss -1378.98019  validloss -1457.48481±0.00000  bestvalidloss -1477.44295  last_update 12\n",
      "train: iter 724  trainloss -1326.84825  validloss -651.47157±0.00000  bestvalidloss -1477.44295  last_update 13\n",
      "train: iter 725  trainloss -1463.01428  validloss -1362.54919±0.00000  bestvalidloss -1477.44295  last_update 14\n",
      "train: iter 726  trainloss -1509.09747  validloss -1348.87266±0.00000  bestvalidloss -1477.44295  last_update 15\n",
      "train: iter 727  trainloss -1507.40473  validloss -1404.82632±0.00000  bestvalidloss -1477.44295  last_update 16\n",
      "train: iter 728  trainloss -1531.90131  validloss -1367.10321±0.00000  bestvalidloss -1477.44295  last_update 17\n",
      "train: iter 729  trainloss -1525.76173  validloss -1443.14008±0.00000  bestvalidloss -1477.44295  last_update 18\n",
      "train: iter 730  trainloss -1119.18859  validloss -1433.77719±0.00000  bestvalidloss -1477.44295  last_update 19\n",
      "train: iter 731  trainloss -1295.20075  validloss -859.40812±0.00000  bestvalidloss -1477.44295  last_update 20\n",
      "train: iter 732  trainloss -1480.40897  validloss -1323.25973±0.00000  bestvalidloss -1477.44295  last_update 21\n",
      "train: iter 733  trainloss -1518.03339  validloss -1352.93536±0.00000  bestvalidloss -1477.44295  last_update 22\n",
      "train: iter 734  trainloss -1475.06144  validloss -1361.74353±0.00000  bestvalidloss -1477.44295  last_update 23\n",
      "train: iter 735  trainloss -1513.10788  validloss -1347.20721±0.00000  bestvalidloss -1477.44295  last_update 24\n",
      "train: iter 736  trainloss -1471.82039  validloss -1441.47355±0.00000  bestvalidloss -1477.44295  last_update 25\n",
      "train: iter 737  trainloss -1460.62735  validloss -1289.13824±0.00000  bestvalidloss -1477.44295  last_update 26\n",
      "train: iter 738  trainloss -1533.50702  validloss -1393.27511±0.00000  bestvalidloss -1477.44295  last_update 27\n",
      "train: iter 739  trainloss -1498.24869  validloss -1430.15000±0.00000  bestvalidloss -1477.44295  last_update 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 740  trainloss -1488.16393  validloss -1304.93577±0.00000  bestvalidloss -1477.44295  last_update 29\n",
      "train: iter 741  trainloss -1547.62611  validloss -1412.24011±0.00000  bestvalidloss -1477.44295  last_update 30\n",
      "train: iter 742  trainloss -1514.87143  validloss -1472.52605±0.00000  bestvalidloss -1477.44295  last_update 31\n",
      "train: iter 743  trainloss -1437.37364  validloss -1066.84410±0.00000  bestvalidloss -1477.44295  last_update 32\n",
      "train: iter 744  trainloss -1535.71172  validloss -1404.73266±0.00000  bestvalidloss -1477.44295  last_update 33\n",
      "train: iter 745  trainloss -1470.22580  validloss -1377.73666±0.00000  bestvalidloss -1477.44295  last_update 34\n",
      "train: iter 746  trainloss -1529.67126  validloss -1324.41585±0.00000  bestvalidloss -1477.44295  last_update 35\n",
      "train: iter 747  trainloss -1511.08805  validloss -1447.20122±0.00000  bestvalidloss -1477.44295  last_update 36\n",
      "train: iter 748  trainloss -1558.92151  validloss -1433.68962±0.00000  bestvalidloss -1477.44295  last_update 37\n",
      "train: iter 749  trainloss -1406.84805  validloss -1432.83005±0.00000  bestvalidloss -1477.44295  last_update 38\n",
      "train: iter 750  trainloss -1436.41297  validloss -1322.14191±0.00000  bestvalidloss -1477.44295  last_update 39\n",
      "train: iter 751  trainloss -1520.78870  validloss -1397.97661±0.00000  bestvalidloss -1477.44295  last_update 40\n",
      "train: iter 752  trainloss -1549.67763  validloss -1453.20299±0.00000  bestvalidloss -1477.44295  last_update 41\n",
      "train: iter 753  trainloss -1486.98953  validloss -1311.76721±0.00000  bestvalidloss -1477.44295  last_update 42\n",
      "train: iter 754  trainloss -1528.40912  validloss -1435.31998±0.00000  bestvalidloss -1477.44295  last_update 43\n",
      "train: iter 755  trainloss -1434.89459  validloss -1463.81720±0.00000  bestvalidloss -1477.44295  last_update 44\n",
      "train: iter 756  trainloss -1478.92810  validloss -1281.45197±0.00000  bestvalidloss -1477.44295  last_update 45\n",
      "train: iter 757  trainloss -1514.90811  validloss -1320.90989±0.00000  bestvalidloss -1477.44295  last_update 46\n",
      "train: iter 758  trainloss -1527.26076  validloss -1389.10589±0.00000  bestvalidloss -1477.44295  last_update 47\n",
      "train: iter 759  trainloss -1517.18688  validloss -1448.04753±0.00000  bestvalidloss -1477.44295  last_update 48\n",
      "train: iter 760  trainloss -1518.47689  validloss -1269.27124±0.00000  bestvalidloss -1477.44295  last_update 49\n",
      "train: iter 761  trainloss -1432.67989  validloss -1422.69602±0.00000  bestvalidloss -1477.44295  last_update 50\n",
      "train: iter 762  trainloss -1506.39549  validloss -1410.72020±0.00000  bestvalidloss -1477.44295  last_update 51\n",
      "train: iter 763  trainloss -1500.27372  validloss -1394.20854±0.00000  bestvalidloss -1477.44295  last_update 52\n",
      "train: iter 764  trainloss -1519.33197  validloss -1476.84302±0.00000  bestvalidloss -1477.44295  last_update 53\n",
      "train: iter 765  trainloss -1280.58248  validloss -1390.52642±0.00000  bestvalidloss -1477.44295  last_update 54\n",
      "train: iter 766  trainloss -1353.49090  validloss -962.74694±0.00000  bestvalidloss -1477.44295  last_update 55\n",
      "train: iter 767  trainloss -1497.23617  validloss -1364.14092±0.00000  bestvalidloss -1477.44295  last_update 56\n",
      "train: iter 768  trainloss -1503.84202  validloss -1398.79908±0.00000  bestvalidloss -1477.44295  last_update 57\n",
      "train: iter 769  trainloss -1410.24456  validloss -1283.85331±0.00000  bestvalidloss -1477.44295  last_update 58\n",
      "train: iter 770  trainloss -1504.42908  validloss -1416.10724±0.00000  bestvalidloss -1477.44295  last_update 59\n",
      "train: iter 771  trainloss -1517.37540  validloss -1422.21780±0.00000  bestvalidloss -1477.44295  last_update 60\n",
      "train: iter 772  trainloss -1518.28903  validloss -1437.03132±0.00000  bestvalidloss -1477.44295  last_update 61\n",
      "train: iter 773  trainloss -1496.40614  validloss -1397.24437±0.00000  bestvalidloss -1477.44295  last_update 62\n",
      "train: iter 774  trainloss -1502.45912  validloss -1425.15068±0.00000  bestvalidloss -1477.44295  last_update 63\n",
      "train: iter 775  trainloss -1510.36618  validloss -1329.06489±0.00000  bestvalidloss -1477.44295  last_update 64\n",
      "train: iter 776  trainloss -1487.68093  validloss -1440.70326±0.00000  bestvalidloss -1477.44295  last_update 65\n",
      "train: iter 777  trainloss -1543.53340  validloss -1407.28809±0.00000  bestvalidloss -1477.44295  last_update 66\n",
      "train: iter 778  trainloss -1409.98436  validloss -1490.28341±0.00000  bestvalidloss -1490.28341  last_update 0\n",
      "train: iter 779  trainloss -1454.33412  validloss -1329.08159±0.00000  bestvalidloss -1490.28341  last_update 1\n",
      "train: iter 780  trainloss -1508.46692  validloss -1279.06803±0.00000  bestvalidloss -1490.28341  last_update 2\n",
      "train: iter 781  trainloss -1495.82221  validloss -1471.35389±0.00000  bestvalidloss -1490.28341  last_update 3\n",
      "train: iter 782  trainloss -1487.37405  validloss -1277.79458±0.00000  bestvalidloss -1490.28341  last_update 4\n",
      "train: iter 783  trainloss -1553.27591  validloss -1441.40494±0.00000  bestvalidloss -1490.28341  last_update 5\n",
      "train: iter 784  trainloss -1505.84165  validloss -1442.42625±0.00000  bestvalidloss -1490.28341  last_update 6\n",
      "train: iter 785  trainloss -1541.63551  validloss -1408.96009±0.00000  bestvalidloss -1490.28341  last_update 7\n",
      "train: iter 786  trainloss -1496.03797  validloss -1414.75096±0.00000  bestvalidloss -1490.28341  last_update 8\n",
      "train: iter 787  trainloss -1463.48384  validloss -1255.54471±0.00000  bestvalidloss -1490.28341  last_update 9\n",
      "train: iter 788  trainloss -1529.78219  validloss -1416.25673±0.00000  bestvalidloss -1490.28341  last_update 10\n",
      "train: iter 789  trainloss -1555.99836  validloss -1383.46378±0.00000  bestvalidloss -1490.28341  last_update 11\n",
      "train: iter 790  trainloss -1483.42945  validloss -1425.40136±0.00000  bestvalidloss -1490.28341  last_update 12\n",
      "train: iter 791  trainloss -1505.44878  validloss -1281.49493±0.00000  bestvalidloss -1490.28341  last_update 13\n",
      "train: iter 792  trainloss -1415.51691  validloss -1317.09602±0.00000  bestvalidloss -1490.28341  last_update 14\n",
      "train: iter 793  trainloss -1468.92130  validloss -1057.39636±0.00000  bestvalidloss -1490.28341  last_update 15\n",
      "train: iter 794  trainloss -1556.70384  validloss -1445.97144±0.00000  bestvalidloss -1490.28341  last_update 16\n",
      "train: iter 795  trainloss -1539.30357  validloss -1454.06480±0.00000  bestvalidloss -1490.28341  last_update 17\n",
      "train: iter 796  trainloss -1065.12013  validloss -1365.67017±0.00000  bestvalidloss -1490.28341  last_update 18\n",
      "train: iter 797  trainloss -1373.95136  validloss -1169.25267±0.00000  bestvalidloss -1490.28341  last_update 19\n",
      "train: iter 798  trainloss -1462.16602  validloss -1322.44943±0.00000  bestvalidloss -1490.28341  last_update 20\n",
      "train: iter 799  trainloss -1474.57340  validloss -1391.73173±0.00000  bestvalidloss -1490.28341  last_update 21\n",
      "train: iter 800  trainloss -1500.05144  validloss -1412.72318±0.00000  bestvalidloss -1490.28341  last_update 22\n",
      "train: iter 801  trainloss -1479.11822  validloss -1472.21145±0.00000  bestvalidloss -1490.28341  last_update 23\n",
      "train: iter 802  trainloss -1524.36085  validloss -1400.66709±0.00000  bestvalidloss -1490.28341  last_update 24\n",
      "train: iter 803  trainloss -1521.58131  validloss -1463.34408±0.00000  bestvalidloss -1490.28341  last_update 25\n",
      "train: iter 804  trainloss -1470.30402  validloss -1353.71225±0.00000  bestvalidloss -1490.28341  last_update 26\n",
      "train: iter 805  trainloss -1548.76369  validloss -1449.14238±0.00000  bestvalidloss -1490.28341  last_update 27\n",
      "train: iter 806  trainloss -1542.22522  validloss -1373.51872±0.00000  bestvalidloss -1490.28341  last_update 28\n",
      "train: iter 807  trainloss -1526.07407  validloss -1427.04499±0.00000  bestvalidloss -1490.28341  last_update 29\n",
      "train: iter 808  trainloss -1444.16828  validloss -363.17213±0.00000  bestvalidloss -1490.28341  last_update 30\n",
      "train: iter 809  trainloss -1529.72022  validloss -1349.58655±0.00000  bestvalidloss -1490.28341  last_update 31\n",
      "train: iter 810  trainloss -1482.70550  validloss -1434.67504±0.00000  bestvalidloss -1490.28341  last_update 32\n",
      "train: iter 811  trainloss -1449.88564  validloss -1299.44707±0.00000  bestvalidloss -1490.28341  last_update 33\n",
      "train: iter 812  trainloss -1453.32749  validloss -1391.11243±0.00000  bestvalidloss -1490.28341  last_update 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 813  trainloss -1533.08285  validloss -1374.54068±0.00000  bestvalidloss -1490.28341  last_update 35\n",
      "train: iter 814  trainloss -1570.28538  validloss -1434.12164±0.00000  bestvalidloss -1490.28341  last_update 36\n",
      "train: iter 815  trainloss -1547.69215  validloss -1482.13781±0.00000  bestvalidloss -1490.28341  last_update 37\n",
      "train: iter 816  trainloss -1313.13602  validloss -1444.84071±0.00000  bestvalidloss -1490.28341  last_update 38\n",
      "train: iter 817  trainloss -1535.04219  validloss -1374.82112±0.00000  bestvalidloss -1490.28341  last_update 39\n",
      "train: iter 818  trainloss -1535.18041  validloss -1465.04856±0.00000  bestvalidloss -1490.28341  last_update 40\n",
      "train: iter 819  trainloss -1526.04203  validloss -1394.84250±0.00000  bestvalidloss -1490.28341  last_update 41\n",
      "train: iter 820  trainloss -1526.55931  validloss -1511.27047±0.00000  bestvalidloss -1511.27047  last_update 0\n",
      "train: iter 821  trainloss -1460.06487  validloss -893.56743±0.00000  bestvalidloss -1511.27047  last_update 1\n",
      "train: iter 822  trainloss -1530.26328  validloss -1406.00552±0.00000  bestvalidloss -1511.27047  last_update 2\n",
      "train: iter 823  trainloss -1545.56352  validloss -1441.76971±0.00000  bestvalidloss -1511.27047  last_update 3\n",
      "train: iter 824  trainloss -1511.30589  validloss -1427.55517±0.00000  bestvalidloss -1511.27047  last_update 4\n",
      "train: iter 825  trainloss -1445.89596  validloss -1131.18547±0.00000  bestvalidloss -1511.27047  last_update 5\n",
      "train: iter 826  trainloss -1548.48527  validloss -1439.76372±0.00000  bestvalidloss -1511.27047  last_update 6\n",
      "train: iter 827  trainloss -1544.02004  validloss -1479.07342±0.00000  bestvalidloss -1511.27047  last_update 7\n",
      "train: iter 828  trainloss -1445.66629  validloss -1424.63064±0.00000  bestvalidloss -1511.27047  last_update 8\n",
      "train: iter 829  trainloss -922.20343  validloss -765.35951±0.00000  bestvalidloss -1511.27047  last_update 9\n",
      "train: iter 830  trainloss -1443.17643  validloss -1265.15098±0.00000  bestvalidloss -1511.27047  last_update 10\n",
      "train: iter 831  trainloss -1479.29300  validloss -1432.75150±0.00000  bestvalidloss -1511.27047  last_update 11\n",
      "train: iter 832  trainloss -1550.43814  validloss -1441.00262±0.00000  bestvalidloss -1511.27047  last_update 12\n",
      "train: iter 833  trainloss -1472.27167  validloss -1336.88273±0.00000  bestvalidloss -1511.27047  last_update 13\n",
      "train: iter 834  trainloss -1541.01452  validloss -1353.71794±0.00000  bestvalidloss -1511.27047  last_update 14\n",
      "train: iter 835  trainloss -1568.45279  validloss -1459.24306±0.00000  bestvalidloss -1511.27047  last_update 15\n",
      "train: iter 836  trainloss -1415.82591  validloss -1391.41712±0.00000  bestvalidloss -1511.27047  last_update 16\n",
      "train: iter 837  trainloss -1526.37115  validloss -1375.82514±0.00000  bestvalidloss -1511.27047  last_update 17\n",
      "train: iter 838  trainloss -1521.03177  validloss -1354.46429±0.00000  bestvalidloss -1511.27047  last_update 18\n",
      "train: iter 839  trainloss -1373.54861  validloss -1405.88935±0.00000  bestvalidloss -1511.27047  last_update 19\n",
      "train: iter 840  trainloss -1122.52811  validloss 680.52740±0.00000  bestvalidloss -1511.27047  last_update 20\n",
      "train: iter 841  trainloss -1521.07629  validloss -1366.32700±0.00000  bestvalidloss -1511.27047  last_update 21\n",
      "train: iter 842  trainloss -1529.51389  validloss -1422.96840±0.00000  bestvalidloss -1511.27047  last_update 22\n",
      "train: iter 843  trainloss -1430.12115  validloss -1330.54355±0.00000  bestvalidloss -1511.27047  last_update 23\n",
      "train: iter 844  trainloss -1534.47767  validloss -1397.38547±0.00000  bestvalidloss -1511.27047  last_update 24\n",
      "train: iter 845  trainloss -1555.63128  validloss -1456.20780±0.00000  bestvalidloss -1511.27047  last_update 25\n",
      "train: iter 846  trainloss -1561.81816  validloss -1456.32487±0.00000  bestvalidloss -1511.27047  last_update 26\n",
      "train: iter 847  trainloss -1549.91358  validloss -1456.50380±0.00000  bestvalidloss -1511.27047  last_update 27\n",
      "train: iter 848  trainloss -1549.95786  validloss -1388.48403±0.00000  bestvalidloss -1511.27047  last_update 28\n",
      "train: iter 849  trainloss -1565.80121  validloss -1480.52008±0.00000  bestvalidloss -1511.27047  last_update 29\n",
      "train: iter 850  trainloss -1527.50963  validloss -1452.82826±0.00000  bestvalidloss -1511.27047  last_update 30\n",
      "train: iter 851  trainloss -1540.50721  validloss -1372.72417±0.00000  bestvalidloss -1511.27047  last_update 31\n",
      "train: iter 852  trainloss -1545.00413  validloss -1420.00442±0.00000  bestvalidloss -1511.27047  last_update 32\n",
      "train: iter 853  trainloss -1511.24884  validloss -1466.63626±0.00000  bestvalidloss -1511.27047  last_update 33\n",
      "train: iter 854  trainloss -1010.48740  validloss -1234.72514±0.00000  bestvalidloss -1511.27047  last_update 34\n",
      "train: iter 855  trainloss -1519.46599  validloss -1318.56525±0.00000  bestvalidloss -1511.27047  last_update 35\n",
      "train: iter 856  trainloss -1542.51407  validloss -1445.83731±0.00000  bestvalidloss -1511.27047  last_update 36\n",
      "train: iter 857  trainloss -1516.73037  validloss -1444.23820±0.00000  bestvalidloss -1511.27047  last_update 37\n",
      "train: iter 858  trainloss -1546.83809  validloss -1421.78041±0.00000  bestvalidloss -1511.27047  last_update 38\n",
      "train: iter 859  trainloss -1508.32662  validloss -1424.27148±0.00000  bestvalidloss -1511.27047  last_update 39\n",
      "train: iter 860  trainloss -1439.88809  validloss -1454.16278±0.00000  bestvalidloss -1511.27047  last_update 40\n",
      "train: iter 861  trainloss -1559.51586  validloss -1421.70553±0.00000  bestvalidloss -1511.27047  last_update 41\n",
      "train: iter 862  trainloss -1570.11036  validloss -1470.69157±0.00000  bestvalidloss -1511.27047  last_update 42\n",
      "train: iter 863  trainloss -1552.42827  validloss -1428.51839±0.00000  bestvalidloss -1511.27047  last_update 43\n",
      "train: iter 864  trainloss -1446.74322  validloss -1482.75979±0.00000  bestvalidloss -1511.27047  last_update 44\n",
      "train: iter 865  trainloss -996.61827  validloss -1214.30581±0.00000  bestvalidloss -1511.27047  last_update 45\n",
      "train: iter 866  trainloss -1403.98776  validloss -1019.26439±0.00000  bestvalidloss -1511.27047  last_update 46\n",
      "train: iter 867  trainloss -1524.25167  validloss -1337.20335±0.00000  bestvalidloss -1511.27047  last_update 47\n",
      "train: iter 868  trainloss -1514.33820  validloss -1424.37787±0.00000  bestvalidloss -1511.27047  last_update 48\n",
      "train: iter 869  trainloss -1557.54012  validloss -1423.17001±0.00000  bestvalidloss -1511.27047  last_update 49\n",
      "train: iter 870  trainloss -1513.15970  validloss -1409.14594±0.00000  bestvalidloss -1511.27047  last_update 50\n",
      "train: iter 871  trainloss -1553.00167  validloss -1419.05061±0.00000  bestvalidloss -1511.27047  last_update 51\n",
      "train: iter 872  trainloss -1493.15754  validloss -1375.74703±0.00000  bestvalidloss -1511.27047  last_update 52\n",
      "train: iter 873  trainloss -1556.70292  validloss -1462.23538±0.00000  bestvalidloss -1511.27047  last_update 53\n",
      "train: iter 874  trainloss -1503.97057  validloss -1411.91646±0.00000  bestvalidloss -1511.27047  last_update 54\n",
      "train: iter 875  trainloss -1541.07928  validloss -1440.10690±0.00000  bestvalidloss -1511.27047  last_update 55\n",
      "train: iter 876  trainloss -1498.36226  validloss -1462.29939±0.00000  bestvalidloss -1511.27047  last_update 56\n",
      "train: iter 877  trainloss -1500.93890  validloss -1402.49175±0.00000  bestvalidloss -1511.27047  last_update 57\n",
      "train: iter 878  trainloss -1496.91025  validloss -1424.37808±0.00000  bestvalidloss -1511.27047  last_update 58\n",
      "train: iter 879  trainloss -1542.78309  validloss -1408.62462±0.00000  bestvalidloss -1511.27047  last_update 59\n",
      "train: iter 880  trainloss -1554.68530  validloss -1472.37700±0.00000  bestvalidloss -1511.27047  last_update 60\n",
      "train: iter 881  trainloss -1349.72217  validloss -1461.24848±0.00000  bestvalidloss -1511.27047  last_update 61\n",
      "train: iter 882  trainloss -1515.16091  validloss -1270.17127±0.00000  bestvalidloss -1511.27047  last_update 62\n",
      "train: iter 883  trainloss -1537.81246  validloss -1462.82668±0.00000  bestvalidloss -1511.27047  last_update 63\n",
      "train: iter 884  trainloss -1538.66605  validloss -1442.06818±0.00000  bestvalidloss -1511.27047  last_update 64\n",
      "train: iter 885  trainloss -1576.75842  validloss -1476.78144±0.00000  bestvalidloss -1511.27047  last_update 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 886  trainloss -1512.05130  validloss -1467.48972±0.00000  bestvalidloss -1511.27047  last_update 66\n",
      "train: iter 887  trainloss -1549.11521  validloss -1366.68558±0.00000  bestvalidloss -1511.27047  last_update 67\n",
      "train: iter 888  trainloss -1524.60550  validloss -1473.75477±0.00000  bestvalidloss -1511.27047  last_update 68\n",
      "train: iter 889  trainloss -1495.02516  validloss -1403.46242±0.00000  bestvalidloss -1511.27047  last_update 69\n",
      "train: iter 890  trainloss -1568.13222  validloss -1424.64607±0.00000  bestvalidloss -1511.27047  last_update 70\n",
      "train: iter 891  trainloss -1548.84734  validloss -1479.27227±0.00000  bestvalidloss -1511.27047  last_update 71\n",
      "train: iter 892  trainloss -1525.01956  validloss -1509.04295±0.00000  bestvalidloss -1511.27047  last_update 72\n",
      "train: iter 893  trainloss -1216.07837  validloss -1421.73908±0.00000  bestvalidloss -1511.27047  last_update 73\n",
      "train: iter 894  trainloss -1455.52858  validloss -1120.39336±0.00000  bestvalidloss -1511.27047  last_update 74\n",
      "train: iter 895  trainloss -1550.04801  validloss -1415.53553±0.00000  bestvalidloss -1511.27047  last_update 75\n",
      "train: iter 896  trainloss -1556.43982  validloss -1411.00373±0.00000  bestvalidloss -1511.27047  last_update 76\n",
      "train: iter 897  trainloss -1573.93063  validloss -1468.03099±0.00000  bestvalidloss -1511.27047  last_update 77\n",
      "train: iter 898  trainloss -1559.32257  validloss -1444.89425±0.00000  bestvalidloss -1511.27047  last_update 78\n",
      "train: iter 899  trainloss -1532.74048  validloss -1433.39112±0.00000  bestvalidloss -1511.27047  last_update 79\n",
      "train: iter 900  trainloss -1548.53615  validloss -1426.64613±0.00000  bestvalidloss -1511.27047  last_update 80\n",
      "train: iter 901  trainloss -1558.90518  validloss -1443.58121±0.00000  bestvalidloss -1511.27047  last_update 81\n",
      "train: iter 902  trainloss -1564.72806  validloss -1486.81578±0.00000  bestvalidloss -1511.27047  last_update 82\n",
      "train: iter 903  trainloss -1542.18122  validloss -1410.66431±0.00000  bestvalidloss -1511.27047  last_update 83\n",
      "train: iter 904  trainloss -1555.13786  validloss -1455.98076±0.00000  bestvalidloss -1511.27047  last_update 84\n",
      "train: iter 905  trainloss -1428.09698  validloss -1241.98443±0.00000  bestvalidloss -1511.27047  last_update 85\n",
      "train: iter 906  trainloss -1480.24276  validloss -1428.19907±0.00000  bestvalidloss -1511.27047  last_update 86\n",
      "train: iter 907  trainloss -1507.06850  validloss -1300.14372±0.00000  bestvalidloss -1511.27047  last_update 87\n",
      "train: iter 908  trainloss -1553.45443  validloss -1456.55423±0.00000  bestvalidloss -1511.27047  last_update 88\n",
      "train: iter 909  trainloss -1530.18976  validloss -1280.51853±0.00000  bestvalidloss -1511.27047  last_update 89\n",
      "train: iter 910  trainloss -1210.03758  validloss -1483.86668±0.00000  bestvalidloss -1511.27047  last_update 90\n",
      "train: iter 911  trainloss -1340.42185  validloss -895.85432±0.00000  bestvalidloss -1511.27047  last_update 91\n",
      "train: iter 912  trainloss -1514.16276  validloss -1364.12781±0.00000  bestvalidloss -1511.27047  last_update 92\n",
      "train: iter 913  trainloss -1526.84714  validloss -1413.20905±0.00000  bestvalidloss -1511.27047  last_update 93\n",
      "train: iter 914  trainloss -1457.95556  validloss -1377.39416±0.00000  bestvalidloss -1511.27047  last_update 94\n",
      "train: iter 915  trainloss -1445.51787  validloss -1097.23051±0.00000  bestvalidloss -1511.27047  last_update 95\n",
      "train: iter 916  trainloss -1545.70322  validloss -1404.73814±0.00000  bestvalidloss -1511.27047  last_update 96\n",
      "train: iter 917  trainloss -1547.45816  validloss -1437.26028±0.00000  bestvalidloss -1511.27047  last_update 97\n",
      "train: iter 918  trainloss -1534.17208  validloss -1384.37889±0.00000  bestvalidloss -1511.27047  last_update 98\n",
      "train: iter 919  trainloss -1558.03951  validloss -1437.87466±0.00000  bestvalidloss -1511.27047  last_update 99\n",
      "train: iter 920  trainloss -1584.45820  validloss -1467.01913±0.00000  bestvalidloss -1511.27047  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.0937) penalty_target_max tensor(10.0831)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 6.28300  validloss 6.60712±0.00000  bestvalidloss 6.60712  last_update 0\n",
      "train: iter 1  trainloss 5.76794  validloss 6.04515±0.00000  bestvalidloss 6.04515  last_update 0\n",
      "train: iter 2  trainloss 5.34979  validloss 5.55691±0.00000  bestvalidloss 5.55691  last_update 0\n",
      "train: iter 3  trainloss 5.00356  validloss 5.19412±0.00000  bestvalidloss 5.19412  last_update 0\n",
      "train: iter 4  trainloss 4.71537  validloss 4.87512±0.00000  bestvalidloss 4.87512  last_update 0\n",
      "train: iter 5  trainloss 4.47103  validloss 4.60383±0.00000  bestvalidloss 4.60383  last_update 0\n",
      "train: iter 6  trainloss 4.26541  validloss 4.38208±0.00000  bestvalidloss 4.38208  last_update 0\n",
      "train: iter 7  trainloss 4.08082  validloss 4.20052±0.00000  bestvalidloss 4.20052  last_update 0\n",
      "train: iter 8  trainloss 3.92219  validloss 4.01004±0.00000  bestvalidloss 4.01004  last_update 0\n",
      "train: iter 9  trainloss 3.77176  validloss 3.85893±0.00000  bestvalidloss 3.85893  last_update 0\n",
      "train: iter 10  trainloss 3.63605  validloss 3.71811±0.00000  bestvalidloss 3.71811  last_update 0\n",
      "train: iter 11  trainloss 3.50306  validloss 3.58298±0.00000  bestvalidloss 3.58298  last_update 0\n",
      "train: iter 12  trainloss 3.37971  validloss 3.45738±0.00000  bestvalidloss 3.45738  last_update 0\n",
      "train: iter 13  trainloss 3.26335  validloss 3.34768±0.00000  bestvalidloss 3.34768  last_update 0\n",
      "train: iter 14  trainloss 3.14425  validloss 3.20505±0.00000  bestvalidloss 3.20505  last_update 0\n",
      "train: iter 15  trainloss 3.02156  validloss 3.09757±0.00000  bestvalidloss 3.09757  last_update 0\n",
      "train: iter 16  trainloss 2.90383  validloss 2.97684±0.00000  bestvalidloss 2.97684  last_update 0\n",
      "train: iter 17  trainloss 2.78903  validloss 2.85674±0.00000  bestvalidloss 2.85674  last_update 0\n",
      "train: iter 18  trainloss 2.66551  validloss 2.73395±0.00000  bestvalidloss 2.73395  last_update 0\n",
      "train: iter 19  trainloss 2.55452  validloss 2.62304±0.00000  bestvalidloss 2.62304  last_update 0\n",
      "train: iter 20  trainloss 2.43990  validloss 2.50614±0.00000  bestvalidloss 2.50614  last_update 0\n",
      "train: iter 21  trainloss 2.33085  validloss 2.39222±0.00000  bestvalidloss 2.39222  last_update 0\n",
      "train: iter 22  trainloss 2.22228  validloss 2.28610±0.00000  bestvalidloss 2.28610  last_update 0\n",
      "train: iter 23  trainloss 2.12441  validloss 2.18093±0.00000  bestvalidloss 2.18093  last_update 0\n",
      "train: iter 24  trainloss 2.03179  validloss 2.08057±0.00000  bestvalidloss 2.08057  last_update 0\n",
      "train: iter 25  trainloss 1.94214  validloss 1.99415±0.00000  bestvalidloss 1.99415  last_update 0\n",
      "train: iter 26  trainloss 1.85399  validloss 1.90005±0.00000  bestvalidloss 1.90005  last_update 0\n",
      "train: iter 27  trainloss 1.77276  validloss 1.81339±0.00000  bestvalidloss 1.81339  last_update 0\n",
      "train: iter 28  trainloss 1.68934  validloss 1.73545±0.00000  bestvalidloss 1.73545  last_update 0\n",
      "train: iter 29  trainloss 1.61033  validloss 1.64983±0.00000  bestvalidloss 1.64983  last_update 0\n",
      "train: iter 30  trainloss 1.52923  validloss 1.56939±0.00000  bestvalidloss 1.56939  last_update 0\n",
      "train: iter 31  trainloss 1.44795  validloss 1.48759±0.00000  bestvalidloss 1.48759  last_update 0\n",
      "train: iter 32  trainloss 1.36680  validloss 1.40318±0.00000  bestvalidloss 1.40318  last_update 0\n",
      "train: iter 33  trainloss 1.28244  validloss 1.32402±0.00000  bestvalidloss 1.32402  last_update 0\n",
      "train: iter 34  trainloss 1.20176  validloss 1.24978±0.00000  bestvalidloss 1.24978  last_update 0\n",
      "train: iter 35  trainloss 1.11550  validloss 1.15783±0.00000  bestvalidloss 1.15783  last_update 0\n",
      "train: iter 36  trainloss 1.03113  validloss 1.07911±0.00000  bestvalidloss 1.07911  last_update 0\n",
      "train: iter 37  trainloss 0.94533  validloss 0.98379±0.00000  bestvalidloss 0.98379  last_update 0\n",
      "train: iter 38  trainloss 0.85849  validloss 0.90968±0.00000  bestvalidloss 0.90968  last_update 0\n",
      "train: iter 39  trainloss 0.76830  validloss 0.81238±0.00000  bestvalidloss 0.81238  last_update 0\n",
      "train: iter 40  trainloss 0.67832  validloss 0.71889±0.00000  bestvalidloss 0.71889  last_update 0\n",
      "train: iter 41  trainloss 0.59027  validloss 0.63208±0.00000  bestvalidloss 0.63208  last_update 0\n",
      "train: iter 42  trainloss 0.50042  validloss 0.53761±0.00000  bestvalidloss 0.53761  last_update 0\n",
      "train: iter 43  trainloss 0.41301  validloss 0.44881±0.00000  bestvalidloss 0.44881  last_update 0\n",
      "train: iter 44  trainloss 0.32609  validloss 0.35471±0.00000  bestvalidloss 0.35471  last_update 0\n",
      "train: iter 45  trainloss 0.23574  validloss 0.27722±0.00000  bestvalidloss 0.27722  last_update 0\n",
      "train: iter 46  trainloss 0.14642  validloss 0.18733±0.00000  bestvalidloss 0.18733  last_update 0\n",
      "train: iter 47  trainloss 0.05943  validloss 0.08849±0.00000  bestvalidloss 0.08849  last_update 0\n",
      "train: iter 48  trainloss -0.02962  validloss 0.00304±0.00000  bestvalidloss 0.00304  last_update 0\n",
      "train: iter 49  trainloss -0.08757  validloss -0.07037±0.00000  bestvalidloss -0.07037  last_update 0\n",
      "train: iter 50  trainloss -0.17508  validloss -0.16252±0.00000  bestvalidloss -0.16252  last_update 0\n",
      "train: iter 51  trainloss -0.24738  validloss -0.23503±0.00000  bestvalidloss -0.23503  last_update 0\n",
      "train: iter 52  trainloss -0.33270  validloss -0.31651±0.00000  bestvalidloss -0.31651  last_update 0\n",
      "train: iter 53  trainloss -0.38694  validloss -0.37399±0.00000  bestvalidloss -0.37399  last_update 0\n",
      "train: iter 54  trainloss -0.46292  validloss -0.46855±0.00000  bestvalidloss -0.46855  last_update 0\n",
      "train: iter 55  trainloss -0.53650  validloss -0.51632±0.00000  bestvalidloss -0.51632  last_update 0\n",
      "train: iter 56  trainloss -0.61217  validloss -0.59150±0.00000  bestvalidloss -0.59150  last_update 0\n",
      "train: iter 57  trainloss -0.68464  validloss -0.66587±0.00000  bestvalidloss -0.66587  last_update 0\n",
      "train: iter 58  trainloss -0.74693  validloss -0.72571±0.00000  bestvalidloss -0.72571  last_update 0\n",
      "train: iter 59  trainloss -0.79702  validloss -0.81247±0.00000  bestvalidloss -0.81247  last_update 0\n",
      "train: iter 60  trainloss -0.86768  validloss -0.88057±0.00000  bestvalidloss -0.88057  last_update 0\n",
      "train: iter 61  trainloss -0.90553  validloss -0.90282±0.00000  bestvalidloss -0.90282  last_update 0\n",
      "train: iter 62  trainloss -0.98460  validloss -0.98577±0.00000  bestvalidloss -0.98577  last_update 0\n",
      "train: iter 63  trainloss -1.04683  validloss -1.04998±0.00000  bestvalidloss -1.04998  last_update 0\n",
      "train: iter 64  trainloss -1.09338  validloss -1.10574±0.00000  bestvalidloss -1.10574  last_update 0\n",
      "train: iter 65  trainloss -1.14581  validloss -1.16391±0.00000  bestvalidloss -1.16391  last_update 0\n",
      "train: iter 66  trainloss -1.18055  validloss -1.20717±0.00000  bestvalidloss -1.20717  last_update 0\n",
      "train: iter 67  trainloss -1.22207  validloss -1.27459±0.00000  bestvalidloss -1.27459  last_update 0\n",
      "train: iter 68  trainloss -1.29727  validloss -1.31393±0.00000  bestvalidloss -1.31393  last_update 0\n",
      "train: iter 69  trainloss -1.35674  validloss -1.39014±0.00000  bestvalidloss -1.39014  last_update 0\n",
      "train: iter 70  trainloss -1.39856  validloss -1.43194±0.00000  bestvalidloss -1.43194  last_update 0\n",
      "train: iter 71  trainloss -1.42884  validloss -1.47130±0.00000  bestvalidloss -1.47130  last_update 0\n",
      "train: iter 72  trainloss -1.45670  validloss -1.55818±0.00000  bestvalidloss -1.55818  last_update 0\n",
      "train: iter 73  trainloss -1.51691  validloss -1.57104±0.00000  bestvalidloss -1.57104  last_update 0\n",
      "train: iter 74  trainloss -1.56144  validloss -1.60318±0.00000  bestvalidloss -1.60318  last_update 0\n",
      "train: iter 75  trainloss -1.62073  validloss -1.67830±0.00000  bestvalidloss -1.67830  last_update 0\n",
      "train: iter 76  trainloss -1.65332  validloss -1.63474±0.00000  bestvalidloss -1.67830  last_update 1\n",
      "train: iter 77  trainloss -1.68988  validloss -1.71848±0.00000  bestvalidloss -1.71848  last_update 0\n",
      "train: iter 78  trainloss -1.71198  validloss -1.77922±0.00000  bestvalidloss -1.77922  last_update 0\n",
      "train: iter 79  trainloss -1.73892  validloss -1.77324±0.00000  bestvalidloss -1.77922  last_update 1\n",
      "train: iter 80  trainloss -1.69021  validloss -1.86674±0.00000  bestvalidloss -1.86674  last_update 0\n",
      "train: iter 81  trainloss -1.78799  validloss -1.86835±0.00000  bestvalidloss -1.86835  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 82  trainloss -1.79887  validloss -1.89351±0.00000  bestvalidloss -1.89351  last_update 0\n",
      "train: iter 83  trainloss -1.88108  validloss -1.95154±0.00000  bestvalidloss -1.95154  last_update 0\n",
      "train: iter 84  trainloss -1.83204  validloss -1.98106±0.00000  bestvalidloss -1.98106  last_update 0\n",
      "train: iter 85  trainloss -1.89617  validloss -2.00642±0.00000  bestvalidloss -2.00642  last_update 0\n",
      "train: iter 86  trainloss -1.97386  validloss -1.98540±0.00000  bestvalidloss -2.00642  last_update 1\n",
      "train: iter 87  trainloss -1.89185  validloss -2.04332±0.00000  bestvalidloss -2.04332  last_update 0\n",
      "train: iter 88  trainloss -1.89657  validloss -2.07187±0.00000  bestvalidloss -2.07187  last_update 0\n",
      "train: iter 89  trainloss -1.93047  validloss -2.03696±0.00000  bestvalidloss -2.07187  last_update 1\n",
      "train: iter 90  trainloss -2.00151  validloss -2.11616±0.00000  bestvalidloss -2.11616  last_update 0\n",
      "train: iter 91  trainloss -1.94135  validloss -2.05782±0.00000  bestvalidloss -2.11616  last_update 1\n",
      "train: iter 92  trainloss -2.05028  validloss -2.11767±0.00000  bestvalidloss -2.11767  last_update 0\n",
      "train: iter 93  trainloss -1.99690  validloss -2.06812±0.00000  bestvalidloss -2.11767  last_update 1\n",
      "train: iter 94  trainloss -2.04679  validloss -2.15812±0.00000  bestvalidloss -2.15812  last_update 0\n",
      "train: iter 95  trainloss -2.01383  validloss -2.22317±0.00000  bestvalidloss -2.22317  last_update 0\n",
      "train: iter 96  trainloss -2.06739  validloss -2.20594±0.00000  bestvalidloss -2.22317  last_update 1\n",
      "train: iter 97  trainloss -2.03138  validloss -2.11374±0.00000  bestvalidloss -2.22317  last_update 2\n",
      "train: iter 98  trainloss -2.07881  validloss -2.14331±0.00000  bestvalidloss -2.22317  last_update 3\n",
      "train: iter 99  trainloss -2.04975  validloss -2.15422±0.00000  bestvalidloss -2.22317  last_update 4\n",
      "train: iter 100  trainloss -2.11443  validloss -2.16587±0.00000  bestvalidloss -2.22317  last_update 5\n",
      "train: iter 101  trainloss -2.03021  validloss -2.21832±0.00000  bestvalidloss -2.22317  last_update 6\n",
      "train: iter 102  trainloss -2.09701  validloss -2.21153±0.00000  bestvalidloss -2.22317  last_update 7\n",
      "train: iter 103  trainloss -2.11973  validloss -2.28484±0.00000  bestvalidloss -2.28484  last_update 0\n",
      "train: iter 104  trainloss -2.03151  validloss -2.15376±0.00000  bestvalidloss -2.28484  last_update 1\n",
      "train: iter 105  trainloss -2.04677  validloss -2.19743±0.00000  bestvalidloss -2.28484  last_update 2\n",
      "train: iter 106  trainloss -2.05301  validloss -2.31679±0.00000  bestvalidloss -2.31679  last_update 0\n",
      "train: iter 107  trainloss -2.11019  validloss -2.25902±0.00000  bestvalidloss -2.31679  last_update 1\n",
      "train: iter 108  trainloss -2.10510  validloss -2.27512±0.00000  bestvalidloss -2.31679  last_update 2\n",
      "train: iter 109  trainloss -2.16028  validloss -2.20154±0.00000  bestvalidloss -2.31679  last_update 3\n",
      "train: iter 110  trainloss -2.12051  validloss -2.13568±0.00000  bestvalidloss -2.31679  last_update 4\n",
      "train: iter 111  trainloss -2.08040  validloss -2.23784±0.00000  bestvalidloss -2.31679  last_update 5\n",
      "train: iter 112  trainloss -2.17989  validloss -2.20814±0.00000  bestvalidloss -2.31679  last_update 6\n",
      "train: iter 113  trainloss -2.10390  validloss -2.24333±0.00000  bestvalidloss -2.31679  last_update 7\n",
      "train: iter 114  trainloss -2.09454  validloss -2.30382±0.00000  bestvalidloss -2.31679  last_update 8\n",
      "train: iter 115  trainloss -2.07251  validloss -2.24765±0.00000  bestvalidloss -2.31679  last_update 9\n",
      "train: iter 116  trainloss -2.18834  validloss -2.21272±0.00000  bestvalidloss -2.31679  last_update 10\n",
      "train: iter 117  trainloss -2.15418  validloss -2.30395±0.00000  bestvalidloss -2.31679  last_update 11\n",
      "train: iter 118  trainloss -2.16702  validloss -2.25886±0.00000  bestvalidloss -2.31679  last_update 12\n",
      "train: iter 119  trainloss -2.17827  validloss -2.25149±0.00000  bestvalidloss -2.31679  last_update 13\n",
      "train: iter 120  trainloss -2.14420  validloss -2.25941±0.00000  bestvalidloss -2.31679  last_update 14\n",
      "train: iter 121  trainloss -2.18326  validloss -2.08084±0.00000  bestvalidloss -2.31679  last_update 15\n",
      "train: iter 122  trainloss -2.14676  validloss -2.29219±0.00000  bestvalidloss -2.31679  last_update 16\n",
      "train: iter 123  trainloss -2.14552  validloss -2.25562±0.00000  bestvalidloss -2.31679  last_update 17\n",
      "train: iter 124  trainloss -2.08903  validloss -2.26596±0.00000  bestvalidloss -2.31679  last_update 18\n",
      "train: iter 125  trainloss -2.19451  validloss -2.30502±0.00000  bestvalidloss -2.31679  last_update 19\n",
      "train: iter 126  trainloss -2.11070  validloss -2.27015±0.00000  bestvalidloss -2.31679  last_update 20\n",
      "train: iter 127  trainloss -2.19045  validloss -2.23008±0.00000  bestvalidloss -2.31679  last_update 21\n",
      "train: iter 128  trainloss -2.08993  validloss -2.31858±0.00000  bestvalidloss -2.31858  last_update 0\n",
      "train: iter 129  trainloss -2.13050  validloss -2.18363±0.00000  bestvalidloss -2.31858  last_update 1\n",
      "train: iter 130  trainloss -2.19128  validloss -2.09917±0.00000  bestvalidloss -2.31858  last_update 2\n",
      "train: iter 131  trainloss -2.20878  validloss -2.22896±0.00000  bestvalidloss -2.31858  last_update 3\n",
      "train: iter 132  trainloss -2.19391  validloss -2.16721±0.00000  bestvalidloss -2.31858  last_update 4\n",
      "train: iter 133  trainloss -2.18383  validloss -2.22313±0.00000  bestvalidloss -2.31858  last_update 5\n",
      "train: iter 134  trainloss -2.22075  validloss -2.33386±0.00000  bestvalidloss -2.33386  last_update 0\n",
      "train: iter 135  trainloss -2.11986  validloss -2.27317±0.00000  bestvalidloss -2.33386  last_update 1\n",
      "train: iter 136  trainloss -2.10371  validloss -2.32706±0.00000  bestvalidloss -2.33386  last_update 2\n",
      "train: iter 137  trainloss -2.15098  validloss -2.41206±0.00000  bestvalidloss -2.41206  last_update 0\n",
      "train: iter 138  trainloss -2.08494  validloss -2.32819±0.00000  bestvalidloss -2.41206  last_update 1\n",
      "train: iter 139  trainloss -2.05281  validloss -2.21692±0.00000  bestvalidloss -2.41206  last_update 2\n",
      "train: iter 140  trainloss -2.09887  validloss -2.28906±0.00000  bestvalidloss -2.41206  last_update 3\n",
      "train: iter 141  trainloss -2.11465  validloss -2.33667±0.00000  bestvalidloss -2.41206  last_update 4\n",
      "train: iter 142  trainloss -2.12011  validloss -2.17568±0.00000  bestvalidloss -2.41206  last_update 5\n",
      "train: iter 143  trainloss -2.07675  validloss -2.32803±0.00000  bestvalidloss -2.41206  last_update 6\n",
      "train: iter 144  trainloss -2.14767  validloss -2.36385±0.00000  bestvalidloss -2.41206  last_update 7\n",
      "train: iter 145  trainloss -2.15178  validloss -2.30275±0.00000  bestvalidloss -2.41206  last_update 8\n",
      "train: iter 146  trainloss -2.14126  validloss -2.18763±0.00000  bestvalidloss -2.41206  last_update 9\n",
      "train: iter 147  trainloss -2.16581  validloss -2.29507±0.00000  bestvalidloss -2.41206  last_update 10\n",
      "train: iter 148  trainloss -2.25760  validloss -2.34917±0.00000  bestvalidloss -2.41206  last_update 11\n",
      "train: iter 149  trainloss -2.12165  validloss -2.34146±0.00000  bestvalidloss -2.41206  last_update 12\n",
      "train: iter 150  trainloss -2.26259  validloss -2.29069±0.00000  bestvalidloss -2.41206  last_update 13\n",
      "train: iter 151  trainloss -2.16939  validloss -2.26975±0.00000  bestvalidloss -2.41206  last_update 14\n",
      "train: iter 152  trainloss -2.20953  validloss -2.23164±0.00000  bestvalidloss -2.41206  last_update 15\n",
      "train: iter 153  trainloss -2.07050  validloss -2.24915±0.00000  bestvalidloss -2.41206  last_update 16\n",
      "train: iter 154  trainloss -2.15747  validloss -2.24853±0.00000  bestvalidloss -2.41206  last_update 17\n",
      "train: iter 155  trainloss -2.11459  validloss -2.20126±0.00000  bestvalidloss -2.41206  last_update 18\n",
      "train: iter 156  trainloss -2.12858  validloss -2.35861±0.00000  bestvalidloss -2.41206  last_update 19\n",
      "train: iter 157  trainloss -2.16752  validloss -2.27260±0.00000  bestvalidloss -2.41206  last_update 20\n",
      "train: iter 158  trainloss -2.18776  validloss -2.22730±0.00000  bestvalidloss -2.41206  last_update 21\n",
      "train: iter 159  trainloss -2.09297  validloss -2.30093±0.00000  bestvalidloss -2.41206  last_update 22\n",
      "train: iter 160  trainloss -2.18463  validloss -2.29420±0.00000  bestvalidloss -2.41206  last_update 23\n",
      "train: iter 161  trainloss -2.20403  validloss -2.05234±0.00000  bestvalidloss -2.41206  last_update 24\n",
      "train: iter 162  trainloss -2.18683  validloss -2.32170±0.00000  bestvalidloss -2.41206  last_update 25\n",
      "train: iter 163  trainloss -2.07142  validloss -2.38309±0.00000  bestvalidloss -2.41206  last_update 26\n",
      "train: iter 164  trainloss -2.16201  validloss -2.36157±0.00000  bestvalidloss -2.41206  last_update 27\n",
      "train: iter 165  trainloss -2.17913  validloss -2.27390±0.00000  bestvalidloss -2.41206  last_update 28\n",
      "train: iter 166  trainloss -2.12673  validloss -2.33801±0.00000  bestvalidloss -2.41206  last_update 29\n",
      "train: iter 167  trainloss -2.17066  validloss -2.29063±0.00000  bestvalidloss -2.41206  last_update 30\n",
      "train: iter 168  trainloss -2.16092  validloss -2.39874±0.00000  bestvalidloss -2.41206  last_update 31\n",
      "train: iter 169  trainloss -2.21493  validloss -2.29716±0.00000  bestvalidloss -2.41206  last_update 32\n",
      "train: iter 170  trainloss -2.12326  validloss -2.32718±0.00000  bestvalidloss -2.41206  last_update 33\n",
      "train: iter 171  trainloss -2.13116  validloss -2.29289±0.00000  bestvalidloss -2.41206  last_update 34\n",
      "train: iter 172  trainloss -2.20180  validloss -2.28073±0.00000  bestvalidloss -2.41206  last_update 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 173  trainloss -2.19674  validloss -2.22018±0.00000  bestvalidloss -2.41206  last_update 36\n",
      "train: iter 174  trainloss -2.17969  validloss -2.35419±0.00000  bestvalidloss -2.41206  last_update 37\n",
      "train: iter 175  trainloss -2.11638  validloss -2.32466±0.00000  bestvalidloss -2.41206  last_update 38\n",
      "train: iter 176  trainloss -2.17215  validloss -2.34381±0.00000  bestvalidloss -2.41206  last_update 39\n",
      "train: iter 177  trainloss -2.16085  validloss -2.33615±0.00000  bestvalidloss -2.41206  last_update 40\n",
      "train: iter 178  trainloss -2.22936  validloss -2.20957±0.00000  bestvalidloss -2.41206  last_update 41\n",
      "train: iter 179  trainloss -2.18424  validloss -2.30116±0.00000  bestvalidloss -2.41206  last_update 42\n",
      "train: iter 180  trainloss -2.21455  validloss -2.25527±0.00000  bestvalidloss -2.41206  last_update 43\n",
      "train: iter 181  trainloss -2.19687  validloss -2.26270±0.00000  bestvalidloss -2.41206  last_update 44\n",
      "train: iter 182  trainloss -2.10576  validloss -2.17947±0.00000  bestvalidloss -2.41206  last_update 45\n",
      "train: iter 183  trainloss -2.13958  validloss -2.26156±0.00000  bestvalidloss -2.41206  last_update 46\n",
      "train: iter 184  trainloss -2.07082  validloss -2.26086±0.00000  bestvalidloss -2.41206  last_update 47\n",
      "train: iter 185  trainloss -2.08923  validloss -2.26656±0.00000  bestvalidloss -2.41206  last_update 48\n",
      "train: iter 186  trainloss -2.04299  validloss -2.24597±0.00000  bestvalidloss -2.41206  last_update 49\n",
      "train: iter 187  trainloss -2.14078  validloss -2.24120±0.00000  bestvalidloss -2.41206  last_update 50\n",
      "train: iter 188  trainloss -2.17274  validloss -2.12499±0.00000  bestvalidloss -2.41206  last_update 51\n",
      "train: iter 189  trainloss -2.07950  validloss -2.20440±0.00000  bestvalidloss -2.41206  last_update 52\n",
      "train: iter 190  trainloss -2.16510  validloss -2.38124±0.00000  bestvalidloss -2.41206  last_update 53\n",
      "train: iter 191  trainloss -2.12376  validloss -2.24486±0.00000  bestvalidloss -2.41206  last_update 54\n",
      "train: iter 192  trainloss -2.04724  validloss -2.25210±0.00000  bestvalidloss -2.41206  last_update 55\n",
      "train: iter 193  trainloss -2.22951  validloss -2.32222±0.00000  bestvalidloss -2.41206  last_update 56\n",
      "train: iter 194  trainloss -2.10517  validloss -2.28457±0.00000  bestvalidloss -2.41206  last_update 57\n",
      "train: iter 195  trainloss -2.18087  validloss -2.26871±0.00000  bestvalidloss -2.41206  last_update 58\n",
      "train: iter 196  trainloss -2.07009  validloss -2.20359±0.00000  bestvalidloss -2.41206  last_update 59\n",
      "train: iter 197  trainloss -2.12430  validloss -2.26837±0.00000  bestvalidloss -2.41206  last_update 60\n",
      "train: iter 198  trainloss -2.15809  validloss -2.32444±0.00000  bestvalidloss -2.41206  last_update 61\n",
      "train: iter 199  trainloss -2.15583  validloss -2.25546±0.00000  bestvalidloss -2.41206  last_update 62\n",
      "train: iter 200  trainloss -2.06276  validloss -2.35645±0.00000  bestvalidloss -2.41206  last_update 63\n",
      "train: iter 201  trainloss -2.07765  validloss -2.16142±0.00000  bestvalidloss -2.41206  last_update 64\n",
      "train: iter 202  trainloss -2.11522  validloss -2.25164±0.00000  bestvalidloss -2.41206  last_update 65\n",
      "train: iter 203  trainloss -2.18131  validloss -2.28246±0.00000  bestvalidloss -2.41206  last_update 66\n",
      "train: iter 204  trainloss -2.05101  validloss -2.31171±0.00000  bestvalidloss -2.41206  last_update 67\n",
      "train: iter 205  trainloss -2.17236  validloss -2.31058±0.00000  bestvalidloss -2.41206  last_update 68\n",
      "train: iter 206  trainloss -2.07193  validloss -2.30401±0.00000  bestvalidloss -2.41206  last_update 69\n",
      "train: iter 207  trainloss -2.17726  validloss -2.19885±0.00000  bestvalidloss -2.41206  last_update 70\n",
      "train: iter 208  trainloss -2.19899  validloss -2.32952±0.00000  bestvalidloss -2.41206  last_update 71\n",
      "train: iter 209  trainloss -2.12951  validloss -2.31455±0.00000  bestvalidloss -2.41206  last_update 72\n",
      "train: iter 210  trainloss -2.08228  validloss -2.21575±0.00000  bestvalidloss -2.41206  last_update 73\n",
      "train: iter 211  trainloss -2.02231  validloss -2.44428±0.00000  bestvalidloss -2.44428  last_update 0\n",
      "train: iter 212  trainloss -2.07022  validloss -2.28735±0.00000  bestvalidloss -2.44428  last_update 1\n",
      "train: iter 213  trainloss -2.12424  validloss -2.19649±0.00000  bestvalidloss -2.44428  last_update 2\n",
      "train: iter 214  trainloss -2.06885  validloss -2.38143±0.00000  bestvalidloss -2.44428  last_update 3\n",
      "train: iter 215  trainloss -2.14454  validloss -2.34445±0.00000  bestvalidloss -2.44428  last_update 4\n",
      "train: iter 216  trainloss -2.13856  validloss -2.26007±0.00000  bestvalidloss -2.44428  last_update 5\n",
      "train: iter 217  trainloss -2.19468  validloss -2.28286±0.00000  bestvalidloss -2.44428  last_update 6\n",
      "train: iter 218  trainloss -2.13885  validloss -2.10824±0.00000  bestvalidloss -2.44428  last_update 7\n",
      "train: iter 219  trainloss -2.12045  validloss -2.27347±0.00000  bestvalidloss -2.44428  last_update 8\n",
      "train: iter 220  trainloss -2.19066  validloss -2.37560±0.00000  bestvalidloss -2.44428  last_update 9\n",
      "train: iter 221  trainloss -2.14599  validloss -2.38019±0.00000  bestvalidloss -2.44428  last_update 10\n",
      "train: iter 222  trainloss -2.17407  validloss -2.30474±0.00000  bestvalidloss -2.44428  last_update 11\n",
      "train: iter 223  trainloss -2.15386  validloss -2.31138±0.00000  bestvalidloss -2.44428  last_update 12\n",
      "train: iter 224  trainloss -2.12231  validloss -2.38386±0.00000  bestvalidloss -2.44428  last_update 13\n",
      "train: iter 225  trainloss -2.09192  validloss -2.33152±0.00000  bestvalidloss -2.44428  last_update 14\n",
      "train: iter 226  trainloss -2.25670  validloss -2.29474±0.00000  bestvalidloss -2.44428  last_update 15\n",
      "train: iter 227  trainloss -2.14952  validloss -2.28277±0.00000  bestvalidloss -2.44428  last_update 16\n",
      "train: iter 228  trainloss -2.16625  validloss -2.18500±0.00000  bestvalidloss -2.44428  last_update 17\n",
      "train: iter 229  trainloss -2.10690  validloss -2.45752±0.00000  bestvalidloss -2.45752  last_update 0\n",
      "train: iter 230  trainloss -2.25437  validloss -2.13552±0.00000  bestvalidloss -2.45752  last_update 1\n",
      "train: iter 231  trainloss -2.25679  validloss -2.27802±0.00000  bestvalidloss -2.45752  last_update 2\n",
      "train: iter 232  trainloss -2.10273  validloss -2.25314±0.00000  bestvalidloss -2.45752  last_update 3\n",
      "train: iter 233  trainloss -2.11770  validloss -2.36583±0.00000  bestvalidloss -2.45752  last_update 4\n",
      "train: iter 234  trainloss -2.13870  validloss -2.21504±0.00000  bestvalidloss -2.45752  last_update 5\n",
      "train: iter 235  trainloss -2.09460  validloss -2.27152±0.00000  bestvalidloss -2.45752  last_update 6\n",
      "train: iter 236  trainloss -2.13976  validloss -2.30002±0.00000  bestvalidloss -2.45752  last_update 7\n",
      "train: iter 237  trainloss -2.07732  validloss -2.33626±0.00000  bestvalidloss -2.45752  last_update 8\n",
      "train: iter 238  trainloss -2.17809  validloss -2.29783±0.00000  bestvalidloss -2.45752  last_update 9\n",
      "train: iter 239  trainloss -2.18416  validloss -2.30495±0.00000  bestvalidloss -2.45752  last_update 10\n",
      "train: iter 240  trainloss -2.18636  validloss -2.14391±0.00000  bestvalidloss -2.45752  last_update 11\n",
      "train: iter 241  trainloss -2.21647  validloss -2.30985±0.00000  bestvalidloss -2.45752  last_update 12\n",
      "train: iter 242  trainloss -2.14616  validloss -2.31143±0.00000  bestvalidloss -2.45752  last_update 13\n",
      "train: iter 243  trainloss -2.14159  validloss -2.30726±0.00000  bestvalidloss -2.45752  last_update 14\n",
      "train: iter 244  trainloss -2.12834  validloss -2.27708±0.00000  bestvalidloss -2.45752  last_update 15\n",
      "train: iter 245  trainloss -2.12597  validloss -2.32012±0.00000  bestvalidloss -2.45752  last_update 16\n",
      "train: iter 246  trainloss -2.14362  validloss -2.28955±0.00000  bestvalidloss -2.45752  last_update 17\n",
      "train: iter 247  trainloss -2.13508  validloss -2.21976±0.00000  bestvalidloss -2.45752  last_update 18\n",
      "train: iter 248  trainloss -2.14707  validloss -2.20708±0.00000  bestvalidloss -2.45752  last_update 19\n",
      "train: iter 249  trainloss -2.16626  validloss -2.17670±0.00000  bestvalidloss -2.45752  last_update 20\n",
      "train: iter 250  trainloss -2.24670  validloss -2.34108±0.00000  bestvalidloss -2.45752  last_update 21\n",
      "train: iter 251  trainloss -2.17435  validloss -2.24488±0.00000  bestvalidloss -2.45752  last_update 22\n",
      "train: iter 252  trainloss -2.13649  validloss -2.34753±0.00000  bestvalidloss -2.45752  last_update 23\n",
      "train: iter 253  trainloss -2.11123  validloss -2.20811±0.00000  bestvalidloss -2.45752  last_update 24\n",
      "train: iter 254  trainloss -2.12928  validloss -2.31594±0.00000  bestvalidloss -2.45752  last_update 25\n",
      "train: iter 255  trainloss -2.12556  validloss -2.26884±0.00000  bestvalidloss -2.45752  last_update 26\n",
      "train: iter 256  trainloss -2.17390  validloss -2.32280±0.00000  bestvalidloss -2.45752  last_update 27\n",
      "train: iter 257  trainloss -2.10697  validloss -2.33534±0.00000  bestvalidloss -2.45752  last_update 28\n",
      "train: iter 258  trainloss -2.06428  validloss -2.39246±0.00000  bestvalidloss -2.45752  last_update 29\n",
      "train: iter 259  trainloss -2.16901  validloss -2.38560±0.00000  bestvalidloss -2.45752  last_update 30\n",
      "train: iter 260  trainloss -2.23349  validloss -2.25419±0.00000  bestvalidloss -2.45752  last_update 31\n",
      "train: iter 261  trainloss -2.14426  validloss -2.33018±0.00000  bestvalidloss -2.45752  last_update 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 262  trainloss -2.09037  validloss -2.33085±0.00000  bestvalidloss -2.45752  last_update 33\n",
      "train: iter 263  trainloss -2.19641  validloss -2.32416±0.00000  bestvalidloss -2.45752  last_update 34\n",
      "train: iter 264  trainloss -2.13563  validloss -2.29289±0.00000  bestvalidloss -2.45752  last_update 35\n",
      "train: iter 265  trainloss -2.18856  validloss -2.33347±0.00000  bestvalidloss -2.45752  last_update 36\n",
      "train: iter 266  trainloss -2.09278  validloss -2.26372±0.00000  bestvalidloss -2.45752  last_update 37\n",
      "train: iter 267  trainloss -2.14719  validloss -2.27098±0.00000  bestvalidloss -2.45752  last_update 38\n",
      "train: iter 268  trainloss -2.11373  validloss -2.24034±0.00000  bestvalidloss -2.45752  last_update 39\n",
      "train: iter 269  trainloss -2.21322  validloss -2.27767±0.00000  bestvalidloss -2.45752  last_update 40\n",
      "train: iter 270  trainloss -2.20031  validloss -2.30069±0.00000  bestvalidloss -2.45752  last_update 41\n",
      "train: iter 271  trainloss -2.08659  validloss -2.43833±0.00000  bestvalidloss -2.45752  last_update 42\n",
      "train: iter 272  trainloss -2.21088  validloss -2.31476±0.00000  bestvalidloss -2.45752  last_update 43\n",
      "train: iter 273  trainloss -2.14531  validloss -2.33538±0.00000  bestvalidloss -2.45752  last_update 44\n",
      "train: iter 274  trainloss -2.09251  validloss -2.35184±0.00000  bestvalidloss -2.45752  last_update 45\n",
      "train: iter 275  trainloss -2.08192  validloss -2.21952±0.00000  bestvalidloss -2.45752  last_update 46\n",
      "train: iter 276  trainloss -2.16990  validloss -2.23152±0.00000  bestvalidloss -2.45752  last_update 47\n",
      "train: iter 277  trainloss -2.12975  validloss -2.31827±0.00000  bestvalidloss -2.45752  last_update 48\n",
      "train: iter 278  trainloss -2.09894  validloss -2.38266±0.00000  bestvalidloss -2.45752  last_update 49\n",
      "train: iter 279  trainloss -2.16738  validloss -2.42470±0.00000  bestvalidloss -2.45752  last_update 50\n",
      "train: iter 280  trainloss -2.11395  validloss -2.33884±0.00000  bestvalidloss -2.45752  last_update 51\n",
      "train: iter 281  trainloss -2.22722  validloss -2.28046±0.00000  bestvalidloss -2.45752  last_update 52\n",
      "train: iter 282  trainloss -2.06231  validloss -2.31336±0.00000  bestvalidloss -2.45752  last_update 53\n",
      "train: iter 283  trainloss -2.10213  validloss -2.24611±0.00000  bestvalidloss -2.45752  last_update 54\n",
      "train: iter 284  trainloss -2.13690  validloss -2.26728±0.00000  bestvalidloss -2.45752  last_update 55\n",
      "train: iter 285  trainloss -2.15152  validloss -2.29899±0.00000  bestvalidloss -2.45752  last_update 56\n",
      "train: iter 286  trainloss -2.18581  validloss -2.34855±0.00000  bestvalidloss -2.45752  last_update 57\n",
      "train: iter 287  trainloss -2.16808  validloss -2.29415±0.00000  bestvalidloss -2.45752  last_update 58\n",
      "train: iter 288  trainloss -2.13973  validloss -2.26210±0.00000  bestvalidloss -2.45752  last_update 59\n",
      "train: iter 289  trainloss -2.18894  validloss -2.32125±0.00000  bestvalidloss -2.45752  last_update 60\n",
      "train: iter 290  trainloss -2.12337  validloss -2.23358±0.00000  bestvalidloss -2.45752  last_update 61\n",
      "train: iter 291  trainloss -2.06100  validloss -2.26291±0.00000  bestvalidloss -2.45752  last_update 62\n",
      "train: iter 292  trainloss -2.18853  validloss -2.29927±0.00000  bestvalidloss -2.45752  last_update 63\n",
      "train: iter 293  trainloss -2.18631  validloss -2.29082±0.00000  bestvalidloss -2.45752  last_update 64\n",
      "train: iter 294  trainloss -2.09643  validloss -2.27788±0.00000  bestvalidloss -2.45752  last_update 65\n",
      "train: iter 295  trainloss -2.11463  validloss -2.29882±0.00000  bestvalidloss -2.45752  last_update 66\n",
      "train: iter 296  trainloss -2.18791  validloss -2.19599±0.00000  bestvalidloss -2.45752  last_update 67\n",
      "train: iter 297  trainloss -2.11665  validloss -2.46597±0.00000  bestvalidloss -2.46597  last_update 0\n",
      "train: iter 298  trainloss -2.09873  validloss -2.26568±0.00000  bestvalidloss -2.46597  last_update 1\n",
      "train: iter 299  trainloss -2.05869  validloss -2.20799±0.00000  bestvalidloss -2.46597  last_update 2\n",
      "train: iter 300  trainloss -2.09577  validloss -2.22213±0.00000  bestvalidloss -2.46597  last_update 3\n",
      "train: iter 301  trainloss -2.19635  validloss -2.24789±0.00000  bestvalidloss -2.46597  last_update 4\n",
      "train: iter 302  trainloss -2.13405  validloss -2.26647±0.00000  bestvalidloss -2.46597  last_update 5\n",
      "train: iter 303  trainloss -2.13103  validloss -2.20793±0.00000  bestvalidloss -2.46597  last_update 6\n",
      "train: iter 304  trainloss -2.21236  validloss -2.35993±0.00000  bestvalidloss -2.46597  last_update 7\n",
      "train: iter 305  trainloss -2.12132  validloss -2.23856±0.00000  bestvalidloss -2.46597  last_update 8\n",
      "train: iter 306  trainloss -2.04508  validloss -2.27000±0.00000  bestvalidloss -2.46597  last_update 9\n",
      "train: iter 307  trainloss -2.18078  validloss -2.24956±0.00000  bestvalidloss -2.46597  last_update 10\n",
      "train: iter 308  trainloss -2.16758  validloss -2.26530±0.00000  bestvalidloss -2.46597  last_update 11\n",
      "train: iter 309  trainloss -2.15330  validloss -2.36586±0.00000  bestvalidloss -2.46597  last_update 12\n",
      "train: iter 310  trainloss -2.16544  validloss -2.35281±0.00000  bestvalidloss -2.46597  last_update 13\n",
      "train: iter 311  trainloss -2.25228  validloss -2.26055±0.00000  bestvalidloss -2.46597  last_update 14\n",
      "train: iter 312  trainloss -2.12665  validloss -2.29170±0.00000  bestvalidloss -2.46597  last_update 15\n",
      "train: iter 313  trainloss -2.19079  validloss -2.39578±0.00000  bestvalidloss -2.46597  last_update 16\n",
      "train: iter 314  trainloss -2.11597  validloss -2.37428±0.00000  bestvalidloss -2.46597  last_update 17\n",
      "train: iter 315  trainloss -2.12034  validloss -2.34414±0.00000  bestvalidloss -2.46597  last_update 18\n",
      "train: iter 316  trainloss -2.21029  validloss -2.34548±0.00000  bestvalidloss -2.46597  last_update 19\n",
      "train: iter 317  trainloss -2.10601  validloss -2.31843±0.00000  bestvalidloss -2.46597  last_update 20\n",
      "train: iter 318  trainloss -2.04877  validloss -2.23668±0.00000  bestvalidloss -2.46597  last_update 21\n",
      "train: iter 319  trainloss -2.13456  validloss -2.32145±0.00000  bestvalidloss -2.46597  last_update 22\n",
      "train: iter 320  trainloss -2.12939  validloss -2.17481±0.00000  bestvalidloss -2.46597  last_update 23\n",
      "train: iter 321  trainloss -2.11047  validloss -2.23783±0.00000  bestvalidloss -2.46597  last_update 24\n",
      "train: iter 322  trainloss -2.08866  validloss -2.26961±0.00000  bestvalidloss -2.46597  last_update 25\n",
      "train: iter 323  trainloss -2.06286  validloss -2.33300±0.00000  bestvalidloss -2.46597  last_update 26\n",
      "train: iter 324  trainloss -2.15904  validloss -2.26824±0.00000  bestvalidloss -2.46597  last_update 27\n",
      "train: iter 325  trainloss -2.14595  validloss -2.24833±0.00000  bestvalidloss -2.46597  last_update 28\n",
      "train: iter 326  trainloss -2.05505  validloss -2.32498±0.00000  bestvalidloss -2.46597  last_update 29\n",
      "train: iter 327  trainloss -2.14934  validloss -2.28650±0.00000  bestvalidloss -2.46597  last_update 30\n",
      "train: iter 328  trainloss -2.15647  validloss -2.27606±0.00000  bestvalidloss -2.46597  last_update 31\n",
      "train: iter 329  trainloss -2.15412  validloss -2.27807±0.00000  bestvalidloss -2.46597  last_update 32\n",
      "train: iter 330  trainloss -2.13277  validloss -2.29027±0.00000  bestvalidloss -2.46597  last_update 33\n",
      "train: iter 331  trainloss -2.13806  validloss -2.14364±0.00000  bestvalidloss -2.46597  last_update 34\n",
      "train: iter 332  trainloss -2.11520  validloss -2.35479±0.00000  bestvalidloss -2.46597  last_update 35\n",
      "train: iter 333  trainloss -2.18668  validloss -2.29519±0.00000  bestvalidloss -2.46597  last_update 36\n",
      "train: iter 334  trainloss -2.18141  validloss -2.22209±0.00000  bestvalidloss -2.46597  last_update 37\n",
      "train: iter 335  trainloss -2.19332  validloss -2.34623±0.00000  bestvalidloss -2.46597  last_update 38\n",
      "train: iter 336  trainloss -2.15490  validloss -2.34016±0.00000  bestvalidloss -2.46597  last_update 39\n",
      "train: iter 337  trainloss -2.16899  validloss -2.31260±0.00000  bestvalidloss -2.46597  last_update 40\n",
      "train: iter 338  trainloss -2.22229  validloss -2.22299±0.00000  bestvalidloss -2.46597  last_update 41\n",
      "train: iter 339  trainloss -2.14929  validloss -2.25419±0.00000  bestvalidloss -2.46597  last_update 42\n",
      "train: iter 340  trainloss -2.16103  validloss -2.35887±0.00000  bestvalidloss -2.46597  last_update 43\n",
      "train: iter 341  trainloss -2.09736  validloss -2.25708±0.00000  bestvalidloss -2.46597  last_update 44\n",
      "train: iter 342  trainloss -2.16951  validloss -2.31907±0.00000  bestvalidloss -2.46597  last_update 45\n",
      "train: iter 343  trainloss -2.18963  validloss -2.41574±0.00000  bestvalidloss -2.46597  last_update 46\n",
      "train: iter 344  trainloss -2.20591  validloss -2.26133±0.00000  bestvalidloss -2.46597  last_update 47\n",
      "train: iter 345  trainloss -2.14442  validloss -2.32667±0.00000  bestvalidloss -2.46597  last_update 48\n",
      "train: iter 346  trainloss -2.13646  validloss -2.25510±0.00000  bestvalidloss -2.46597  last_update 49\n",
      "train: iter 347  trainloss -2.17801  validloss -2.39641±0.00000  bestvalidloss -2.46597  last_update 50\n",
      "train: iter 348  trainloss -2.14133  validloss -2.26035±0.00000  bestvalidloss -2.46597  last_update 51\n",
      "train: iter 349  trainloss -2.14681  validloss -2.08555±0.00000  bestvalidloss -2.46597  last_update 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 350  trainloss -2.18165  validloss -2.27112±0.00000  bestvalidloss -2.46597  last_update 53\n",
      "train: iter 351  trainloss -2.13885  validloss -2.30956±0.00000  bestvalidloss -2.46597  last_update 54\n",
      "train: iter 352  trainloss -2.10133  validloss -2.25043±0.00000  bestvalidloss -2.46597  last_update 55\n",
      "train: iter 353  trainloss -2.05935  validloss -2.41434±0.00000  bestvalidloss -2.46597  last_update 56\n",
      "train: iter 354  trainloss -2.15322  validloss -2.39327±0.00000  bestvalidloss -2.46597  last_update 57\n",
      "train: iter 355  trainloss -2.19883  validloss -2.25365±0.00000  bestvalidloss -2.46597  last_update 58\n",
      "train: iter 356  trainloss -2.13110  validloss -2.35685±0.00000  bestvalidloss -2.46597  last_update 59\n",
      "train: iter 357  trainloss -2.09984  validloss -2.28263±0.00000  bestvalidloss -2.46597  last_update 60\n",
      "train: iter 358  trainloss -2.12273  validloss -2.25002±0.00000  bestvalidloss -2.46597  last_update 61\n",
      "train: iter 359  trainloss -2.10267  validloss -2.33343±0.00000  bestvalidloss -2.46597  last_update 62\n",
      "train: iter 360  trainloss -2.25278  validloss -2.39583±0.00000  bestvalidloss -2.46597  last_update 63\n",
      "train: iter 361  trainloss -2.18419  validloss -2.21700±0.00000  bestvalidloss -2.46597  last_update 64\n",
      "train: iter 362  trainloss -2.01183  validloss -2.39516±0.00000  bestvalidloss -2.46597  last_update 65\n",
      "train: iter 363  trainloss -2.11669  validloss -2.35295±0.00000  bestvalidloss -2.46597  last_update 66\n",
      "train: iter 364  trainloss -2.15003  validloss -2.34471±0.00000  bestvalidloss -2.46597  last_update 67\n",
      "train: iter 365  trainloss -2.17450  validloss -2.26356±0.00000  bestvalidloss -2.46597  last_update 68\n",
      "train: iter 366  trainloss -2.05828  validloss -2.25672±0.00000  bestvalidloss -2.46597  last_update 69\n",
      "train: iter 367  trainloss -2.22191  validloss -2.28023±0.00000  bestvalidloss -2.46597  last_update 70\n",
      "train: iter 368  trainloss -2.17143  validloss -2.33765±0.00000  bestvalidloss -2.46597  last_update 71\n",
      "train: iter 369  trainloss -2.10872  validloss -2.29909±0.00000  bestvalidloss -2.46597  last_update 72\n",
      "train: iter 370  trainloss -2.13914  validloss -2.30518±0.00000  bestvalidloss -2.46597  last_update 73\n",
      "train: iter 371  trainloss -2.13844  validloss -2.14046±0.00000  bestvalidloss -2.46597  last_update 74\n",
      "train: iter 372  trainloss -2.16597  validloss -2.24962±0.00000  bestvalidloss -2.46597  last_update 75\n",
      "train: iter 373  trainloss -2.11513  validloss -2.39134±0.00000  bestvalidloss -2.46597  last_update 76\n",
      "train: iter 374  trainloss -2.14117  validloss -2.38080±0.00000  bestvalidloss -2.46597  last_update 77\n",
      "train: iter 375  trainloss -2.18028  validloss -2.39752±0.00000  bestvalidloss -2.46597  last_update 78\n",
      "train: iter 376  trainloss -2.17391  validloss -2.26719±0.00000  bestvalidloss -2.46597  last_update 79\n",
      "train: iter 377  trainloss -2.16296  validloss -2.31263±0.00000  bestvalidloss -2.46597  last_update 80\n",
      "train: iter 378  trainloss -2.15714  validloss -2.31026±0.00000  bestvalidloss -2.46597  last_update 81\n",
      "train: iter 379  trainloss -2.15770  validloss -2.40032±0.00000  bestvalidloss -2.46597  last_update 82\n",
      "train: iter 380  trainloss -2.19748  validloss -2.25456±0.00000  bestvalidloss -2.46597  last_update 83\n",
      "train: iter 381  trainloss -2.10836  validloss -2.39344±0.00000  bestvalidloss -2.46597  last_update 84\n",
      "train: iter 382  trainloss -2.10310  validloss -2.35194±0.00000  bestvalidloss -2.46597  last_update 85\n",
      "train: iter 383  trainloss -2.05203  validloss -2.38318±0.00000  bestvalidloss -2.46597  last_update 86\n",
      "train: iter 384  trainloss -2.17264  validloss -2.22767±0.00000  bestvalidloss -2.46597  last_update 87\n",
      "train: iter 385  trainloss -2.10656  validloss -2.25721±0.00000  bestvalidloss -2.46597  last_update 88\n",
      "train: iter 386  trainloss -2.10473  validloss -2.20573±0.00000  bestvalidloss -2.46597  last_update 89\n",
      "train: iter 387  trainloss -2.09220  validloss -2.26863±0.00000  bestvalidloss -2.46597  last_update 90\n",
      "train: iter 388  trainloss -2.19383  validloss -2.27356±0.00000  bestvalidloss -2.46597  last_update 91\n",
      "train: iter 389  trainloss -2.15233  validloss -2.19537±0.00000  bestvalidloss -2.46597  last_update 92\n",
      "train: iter 390  trainloss -2.02352  validloss -2.29904±0.00000  bestvalidloss -2.46597  last_update 93\n",
      "train: iter 391  trainloss -2.13248  validloss -2.31416±0.00000  bestvalidloss -2.46597  last_update 94\n",
      "train: iter 392  trainloss -2.16924  validloss -2.31937±0.00000  bestvalidloss -2.46597  last_update 95\n",
      "train: iter 393  trainloss -2.20075  validloss -2.30475±0.00000  bestvalidloss -2.46597  last_update 96\n",
      "train: iter 394  trainloss -2.09885  validloss -2.34978±0.00000  bestvalidloss -2.46597  last_update 97\n",
      "train: iter 395  trainloss -2.09695  validloss -2.21908±0.00000  bestvalidloss -2.46597  last_update 98\n",
      "train: iter 396  trainloss -2.19995  validloss -2.33036±0.00000  bestvalidloss -2.46597  last_update 99\n",
      "train: iter 397  trainloss -2.16314  validloss -2.24673±0.00000  bestvalidloss -2.46597  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.5908, -2.6323, -5.5467, -4.4183], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 68.84001  validloss 73.12857±0.00000  bestvalidloss 73.12857  last_update 0\n",
      "train: iter 1  trainloss 48.91132  validloss 58.48966±0.00000  bestvalidloss 58.48966  last_update 0\n",
      "train: iter 2  trainloss 31.93014  validloss 38.99240±0.00000  bestvalidloss 38.99240  last_update 0\n",
      "train: iter 3  trainloss 22.84652  validloss 27.09224±0.00000  bestvalidloss 27.09224  last_update 0\n",
      "train: iter 4  trainloss 17.46308  validloss 20.83030±0.00000  bestvalidloss 20.83030  last_update 0\n",
      "train: iter 5  trainloss 13.86371  validloss 16.88943±0.00000  bestvalidloss 16.88943  last_update 0\n",
      "train: iter 6  trainloss 11.42465  validloss 14.29758±0.00000  bestvalidloss 14.29758  last_update 0\n",
      "train: iter 7  trainloss 9.71676  validloss 12.49165±0.00000  bestvalidloss 12.49165  last_update 0\n",
      "train: iter 8  trainloss 8.52993  validloss 11.41335±0.00000  bestvalidloss 11.41335  last_update 0\n",
      "train: iter 9  trainloss 7.67736  validloss 10.65209±0.00000  bestvalidloss 10.65209  last_update 0\n",
      "train: iter 10  trainloss 7.08716  validloss 10.00287±0.00000  bestvalidloss 10.00287  last_update 0\n",
      "train: iter 11  trainloss 6.68077  validloss 9.64267±0.00000  bestvalidloss 9.64267  last_update 0\n",
      "train: iter 12  trainloss 6.38291  validloss 9.32181±0.00000  bestvalidloss 9.32181  last_update 0\n",
      "train: iter 13  trainloss 6.09894  validloss 8.92895±0.00000  bestvalidloss 8.92895  last_update 0\n",
      "train: iter 14  trainloss 5.81768  validloss 8.52843±0.00000  bestvalidloss 8.52843  last_update 0\n",
      "train: iter 15  trainloss 5.59190  validloss 8.00664±0.00000  bestvalidloss 8.00664  last_update 0\n",
      "train: iter 16  trainloss 5.36612  validloss 7.48206±0.00000  bestvalidloss 7.48206  last_update 0\n",
      "train: iter 17  trainloss 5.22727  validloss 7.13417±0.00000  bestvalidloss 7.13417  last_update 0\n",
      "train: iter 18  trainloss 5.07690  validloss 6.92778±0.00000  bestvalidloss 6.92778  last_update 0\n",
      "train: iter 19  trainloss 4.98613  validloss 6.80005±0.00000  bestvalidloss 6.80005  last_update 0\n",
      "train: iter 20  trainloss 4.86421  validloss 6.48259±0.00000  bestvalidloss 6.48259  last_update 0\n",
      "train: iter 21  trainloss 4.75141  validloss 6.41219±0.00000  bestvalidloss 6.41219  last_update 0\n",
      "train: iter 22  trainloss 4.63551  validloss 6.24113±0.00000  bestvalidloss 6.24113  last_update 0\n",
      "train: iter 23  trainloss 4.53535  validloss 6.16730±0.00000  bestvalidloss 6.16730  last_update 0\n",
      "train: iter 24  trainloss 4.48954  validloss 6.17097±0.00000  bestvalidloss 6.16730  last_update 1\n",
      "train: iter 25  trainloss 4.38117  validloss 5.89353±0.00000  bestvalidloss 5.89353  last_update 0\n",
      "train: iter 26  trainloss 4.32088  validloss 5.93856±0.00000  bestvalidloss 5.89353  last_update 1\n",
      "train: iter 27  trainloss 4.22301  validloss 5.85465±0.00000  bestvalidloss 5.85465  last_update 0\n",
      "train: iter 28  trainloss 4.20140  validloss 5.84453±0.00000  bestvalidloss 5.84453  last_update 0\n",
      "train: iter 29  trainloss 4.10215  validloss 5.64042±0.00000  bestvalidloss 5.64042  last_update 0\n",
      "train: iter 30  trainloss 4.05553  validloss 5.65166±0.00000  bestvalidloss 5.64042  last_update 1\n",
      "train: iter 31  trainloss 4.01183  validloss 5.57683±0.00000  bestvalidloss 5.57683  last_update 0\n",
      "train: iter 32  trainloss 3.97599  validloss 5.56512±0.00000  bestvalidloss 5.56512  last_update 0\n",
      "train: iter 33  trainloss 3.94374  validloss 5.45851±0.00000  bestvalidloss 5.45851  last_update 0\n",
      "train: iter 34  trainloss 3.91227  validloss 5.48516±0.00000  bestvalidloss 5.45851  last_update 1\n",
      "train: iter 35  trainloss 3.89835  validloss 5.41973±0.00000  bestvalidloss 5.41973  last_update 0\n",
      "train: iter 36  trainloss 3.89414  validloss 5.55567±0.00000  bestvalidloss 5.41973  last_update 1\n",
      "train: iter 37  trainloss 3.83640  validloss 5.32659±0.00000  bestvalidloss 5.32659  last_update 0\n",
      "train: iter 38  trainloss 3.84036  validloss 5.36222±0.00000  bestvalidloss 5.32659  last_update 1\n",
      "train: iter 39  trainloss 3.81694  validloss 5.20544±0.00000  bestvalidloss 5.20544  last_update 0\n",
      "train: iter 40  trainloss 3.79482  validloss 5.31842±0.00000  bestvalidloss 5.20544  last_update 1\n",
      "train: iter 41  trainloss 3.76538  validloss 5.23455±0.00000  bestvalidloss 5.20544  last_update 2\n",
      "train: iter 42  trainloss 3.74284  validloss 5.35085±0.00000  bestvalidloss 5.20544  last_update 3\n",
      "train: iter 43  trainloss 3.78530  validloss 5.11671±0.00000  bestvalidloss 5.11671  last_update 0\n",
      "train: iter 44  trainloss 3.75129  validloss 5.23271±0.00000  bestvalidloss 5.11671  last_update 1\n",
      "train: iter 45  trainloss 3.74600  validloss 5.11772±0.00000  bestvalidloss 5.11671  last_update 2\n",
      "train: iter 46  trainloss 3.73378  validloss 5.15615±0.00000  bestvalidloss 5.11671  last_update 3\n",
      "train: iter 47  trainloss 3.71993  validloss 5.13557±0.00000  bestvalidloss 5.11671  last_update 4\n",
      "train: iter 48  trainloss 3.68572  validloss 5.18451±0.00000  bestvalidloss 5.11671  last_update 5\n",
      "train: iter 49  trainloss 3.69329  validloss 5.15544±0.00000  bestvalidloss 5.11671  last_update 6\n",
      "train: iter 50  trainloss 3.66833  validloss 5.13246±0.00000  bestvalidloss 5.11671  last_update 7\n",
      "train: iter 51  trainloss 3.64968  validloss 5.05023±0.00000  bestvalidloss 5.05023  last_update 0\n",
      "train: iter 52  trainloss 3.64614  validloss 5.07659±0.00000  bestvalidloss 5.05023  last_update 1\n",
      "train: iter 53  trainloss 3.57902  validloss 5.04989±0.00000  bestvalidloss 5.04989  last_update 0\n",
      "train: iter 54  trainloss 3.62326  validloss 5.04339±0.00000  bestvalidloss 5.04339  last_update 0\n",
      "train: iter 55  trainloss 3.58219  validloss 5.00090±0.00000  bestvalidloss 5.00090  last_update 0\n",
      "train: iter 56  trainloss 3.57554  validloss 4.92461±0.00000  bestvalidloss 4.92461  last_update 0\n",
      "train: iter 57  trainloss 3.54192  validloss 4.97626±0.00000  bestvalidloss 4.92461  last_update 1\n",
      "train: iter 58  trainloss 3.53845  validloss 5.04323±0.00000  bestvalidloss 4.92461  last_update 2\n",
      "train: iter 59  trainloss 3.52536  validloss 5.06363±0.00000  bestvalidloss 4.92461  last_update 3\n",
      "train: iter 60  trainloss 3.52589  validloss 4.97044±0.00000  bestvalidloss 4.92461  last_update 4\n",
      "train: iter 61  trainloss 3.49504  validloss 4.98835±0.00000  bestvalidloss 4.92461  last_update 5\n",
      "train: iter 62  trainloss 3.48610  validloss 4.83935±0.00000  bestvalidloss 4.83935  last_update 0\n",
      "train: iter 63  trainloss 3.48454  validloss 4.88233±0.00000  bestvalidloss 4.83935  last_update 1\n",
      "train: iter 64  trainloss 3.50270  validloss 4.87352±0.00000  bestvalidloss 4.83935  last_update 2\n",
      "train: iter 65  trainloss 3.48756  validloss 4.93540±0.00000  bestvalidloss 4.83935  last_update 3\n",
      "train: iter 66  trainloss 3.45696  validloss 4.92410±0.00000  bestvalidloss 4.83935  last_update 4\n",
      "train: iter 67  trainloss 3.48140  validloss 4.88902±0.00000  bestvalidloss 4.83935  last_update 5\n",
      "train: iter 68  trainloss 3.48508  validloss 4.87930±0.00000  bestvalidloss 4.83935  last_update 6\n",
      "train: iter 69  trainloss 3.49128  validloss 4.79556±0.00000  bestvalidloss 4.79556  last_update 0\n",
      "train: iter 70  trainloss 3.48396  validloss 4.82345±0.00000  bestvalidloss 4.79556  last_update 1\n",
      "train: iter 71  trainloss 3.51857  validloss 4.81563±0.00000  bestvalidloss 4.79556  last_update 2\n",
      "train: iter 72  trainloss 3.51805  validloss 4.84293±0.00000  bestvalidloss 4.79556  last_update 3\n",
      "train: iter 73  trainloss 3.48631  validloss 4.90585±0.00000  bestvalidloss 4.79556  last_update 4\n",
      "train: iter 74  trainloss 3.49756  validloss 4.87910±0.00000  bestvalidloss 4.79556  last_update 5\n",
      "train: iter 75  trainloss 3.44136  validloss 4.87383±0.00000  bestvalidloss 4.79556  last_update 6\n",
      "train: iter 76  trainloss 3.50935  validloss 4.89610±0.00000  bestvalidloss 4.79556  last_update 7\n",
      "train: iter 77  trainloss 3.47476  validloss 4.82348±0.00000  bestvalidloss 4.79556  last_update 8\n",
      "train: iter 78  trainloss 3.42868  validloss 4.71851±0.00000  bestvalidloss 4.71851  last_update 0\n",
      "train: iter 79  trainloss 3.47430  validloss 4.83919±0.00000  bestvalidloss 4.71851  last_update 1\n",
      "train: iter 80  trainloss 3.44637  validloss 4.85927±0.00000  bestvalidloss 4.71851  last_update 2\n",
      "train: iter 81  trainloss 3.45352  validloss 4.77371±0.00000  bestvalidloss 4.71851  last_update 3\n",
      "train: iter 82  trainloss 3.47538  validloss 4.79605±0.00000  bestvalidloss 4.71851  last_update 4\n",
      "train: iter 83  trainloss 3.44315  validloss 4.80580±0.00000  bestvalidloss 4.71851  last_update 5\n",
      "train: iter 84  trainloss 3.43845  validloss 4.85068±0.00000  bestvalidloss 4.71851  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 3.40992  validloss 4.76463±0.00000  bestvalidloss 4.71851  last_update 7\n",
      "train: iter 86  trainloss 3.41981  validloss 4.93738±0.00000  bestvalidloss 4.71851  last_update 8\n",
      "train: iter 87  trainloss 3.46072  validloss 4.85193±0.00000  bestvalidloss 4.71851  last_update 9\n",
      "train: iter 88  trainloss 3.44357  validloss 4.79661±0.00000  bestvalidloss 4.71851  last_update 10\n",
      "train: iter 89  trainloss 3.45620  validloss 4.91514±0.00000  bestvalidloss 4.71851  last_update 11\n",
      "train: iter 90  trainloss 3.42384  validloss 4.74351±0.00000  bestvalidloss 4.71851  last_update 12\n",
      "train: iter 91  trainloss 3.42089  validloss 4.71484±0.00000  bestvalidloss 4.71484  last_update 0\n",
      "train: iter 92  trainloss 3.43941  validloss 4.93919±0.00000  bestvalidloss 4.71484  last_update 1\n",
      "train: iter 93  trainloss 3.46616  validloss 4.76503±0.00000  bestvalidloss 4.71484  last_update 2\n",
      "train: iter 94  trainloss 3.43298  validloss 4.75331±0.00000  bestvalidloss 4.71484  last_update 3\n",
      "train: iter 95  trainloss 3.45888  validloss 4.74382±0.00000  bestvalidloss 4.71484  last_update 4\n",
      "train: iter 96  trainloss 3.42805  validloss 4.74090±0.00000  bestvalidloss 4.71484  last_update 5\n",
      "train: iter 97  trainloss 3.41361  validloss 4.71477±0.00000  bestvalidloss 4.71477  last_update 0\n",
      "train: iter 98  trainloss 3.41757  validloss 4.82063±0.00000  bestvalidloss 4.71477  last_update 1\n",
      "train: iter 99  trainloss 3.45302  validloss 4.73008±0.00000  bestvalidloss 4.71477  last_update 2\n",
      "train: iter 100  trainloss 3.39812  validloss 4.75960±0.00000  bestvalidloss 4.71477  last_update 3\n",
      "train: iter 101  trainloss 3.43429  validloss 4.90604±0.00000  bestvalidloss 4.71477  last_update 4\n",
      "train: iter 102  trainloss 3.44535  validloss 4.69506±0.00000  bestvalidloss 4.69506  last_update 0\n",
      "train: iter 103  trainloss 3.41128  validloss 4.74143±0.00000  bestvalidloss 4.69506  last_update 1\n",
      "train: iter 104  trainloss 3.41757  validloss 4.82195±0.00000  bestvalidloss 4.69506  last_update 2\n",
      "train: iter 105  trainloss 3.42579  validloss 4.71699±0.00000  bestvalidloss 4.69506  last_update 3\n",
      "train: iter 106  trainloss 3.41014  validloss 4.79981±0.00000  bestvalidloss 4.69506  last_update 4\n",
      "train: iter 107  trainloss 3.45252  validloss 4.80107±0.00000  bestvalidloss 4.69506  last_update 5\n",
      "train: iter 108  trainloss 3.42024  validloss 4.74881±0.00000  bestvalidloss 4.69506  last_update 6\n",
      "train: iter 109  trainloss 3.41359  validloss 4.80558±0.00000  bestvalidloss 4.69506  last_update 7\n",
      "train: iter 110  trainloss 3.44414  validloss 4.73973±0.00000  bestvalidloss 4.69506  last_update 8\n",
      "train: iter 111  trainloss 3.40041  validloss 4.76483±0.00000  bestvalidloss 4.69506  last_update 9\n",
      "train: iter 112  trainloss 3.40568  validloss 4.75033±0.00000  bestvalidloss 4.69506  last_update 10\n",
      "train: iter 113  trainloss 3.43082  validloss 4.74215±0.00000  bestvalidloss 4.69506  last_update 11\n",
      "train: iter 114  trainloss 3.45889  validloss 4.65454±0.00000  bestvalidloss 4.65454  last_update 0\n",
      "train: iter 115  trainloss 3.43370  validloss 4.64144±0.00000  bestvalidloss 4.64144  last_update 0\n",
      "train: iter 116  trainloss 3.43035  validloss 4.72758±0.00000  bestvalidloss 4.64144  last_update 1\n",
      "train: iter 117  trainloss 3.40524  validloss 4.74592±0.00000  bestvalidloss 4.64144  last_update 2\n",
      "train: iter 118  trainloss 3.40486  validloss 4.79115±0.00000  bestvalidloss 4.64144  last_update 3\n",
      "train: iter 119  trainloss 3.39080  validloss 4.67956±0.00000  bestvalidloss 4.64144  last_update 4\n",
      "train: iter 120  trainloss 3.40929  validloss 4.75799±0.00000  bestvalidloss 4.64144  last_update 5\n",
      "train: iter 121  trainloss 3.40627  validloss 4.70068±0.00000  bestvalidloss 4.64144  last_update 6\n",
      "train: iter 122  trainloss 3.38416  validloss 4.85658±0.00000  bestvalidloss 4.64144  last_update 7\n",
      "train: iter 123  trainloss 3.44957  validloss 4.75062±0.00000  bestvalidloss 4.64144  last_update 8\n",
      "train: iter 124  trainloss 3.37246  validloss 4.76866±0.00000  bestvalidloss 4.64144  last_update 9\n",
      "train: iter 125  trainloss 3.38920  validloss 4.68342±0.00000  bestvalidloss 4.64144  last_update 10\n",
      "train: iter 126  trainloss 3.40782  validloss 4.80108±0.00000  bestvalidloss 4.64144  last_update 11\n",
      "train: iter 127  trainloss 3.39389  validloss 4.73128±0.00000  bestvalidloss 4.64144  last_update 12\n",
      "train: iter 128  trainloss 3.36713  validloss 4.83110±0.00000  bestvalidloss 4.64144  last_update 13\n",
      "train: iter 129  trainloss 3.43925  validloss 4.73909±0.00000  bestvalidloss 4.64144  last_update 14\n",
      "train: iter 130  trainloss 3.39602  validloss 4.67715±0.00000  bestvalidloss 4.64144  last_update 15\n",
      "train: iter 131  trainloss 3.40825  validloss 4.77341±0.00000  bestvalidloss 4.64144  last_update 16\n",
      "train: iter 132  trainloss 3.40731  validloss 4.69465±0.00000  bestvalidloss 4.64144  last_update 17\n",
      "train: iter 133  trainloss 3.39024  validloss 4.70922±0.00000  bestvalidloss 4.64144  last_update 18\n",
      "train: iter 134  trainloss 3.38601  validloss 4.68899±0.00000  bestvalidloss 4.64144  last_update 19\n",
      "train: iter 135  trainloss 3.40083  validloss 4.95215±0.00000  bestvalidloss 4.64144  last_update 20\n",
      "train: iter 136  trainloss 3.39425  validloss 4.72131±0.00000  bestvalidloss 4.64144  last_update 21\n",
      "train: iter 137  trainloss 3.39018  validloss 4.69081±0.00000  bestvalidloss 4.64144  last_update 22\n",
      "train: iter 138  trainloss 3.39381  validloss 4.82347±0.00000  bestvalidloss 4.64144  last_update 23\n",
      "train: iter 139  trainloss 3.41389  validloss 4.82658±0.00000  bestvalidloss 4.64144  last_update 24\n",
      "train: iter 140  trainloss 3.39510  validloss 4.73833±0.00000  bestvalidloss 4.64144  last_update 25\n",
      "train: iter 141  trainloss 3.38746  validloss 4.74467±0.00000  bestvalidloss 4.64144  last_update 26\n",
      "train: iter 142  trainloss 3.38476  validloss 4.81273±0.00000  bestvalidloss 4.64144  last_update 27\n",
      "train: iter 143  trainloss 3.38805  validloss 4.67659±0.00000  bestvalidloss 4.64144  last_update 28\n",
      "train: iter 144  trainloss 3.38866  validloss 4.70575±0.00000  bestvalidloss 4.64144  last_update 29\n",
      "train: iter 145  trainloss 3.36578  validloss 4.66282±0.00000  bestvalidloss 4.64144  last_update 30\n",
      "train: iter 146  trainloss 3.39877  validloss 4.77024±0.00000  bestvalidloss 4.64144  last_update 31\n",
      "train: iter 147  trainloss 3.39051  validloss 4.77561±0.00000  bestvalidloss 4.64144  last_update 32\n",
      "train: iter 148  trainloss 3.37329  validloss 4.71981±0.00000  bestvalidloss 4.64144  last_update 33\n",
      "train: iter 149  trainloss 3.39083  validloss 4.66162±0.00000  bestvalidloss 4.64144  last_update 34\n",
      "train: iter 150  trainloss 3.38100  validloss 4.67934±0.00000  bestvalidloss 4.64144  last_update 35\n",
      "train: iter 151  trainloss 3.38724  validloss 4.59511±0.00000  bestvalidloss 4.59511  last_update 0\n",
      "train: iter 152  trainloss 3.39349  validloss 4.79410±0.00000  bestvalidloss 4.59511  last_update 1\n",
      "train: iter 153  trainloss 3.38208  validloss 4.75042±0.00000  bestvalidloss 4.59511  last_update 2\n",
      "train: iter 154  trainloss 3.39345  validloss 4.76147±0.00000  bestvalidloss 4.59511  last_update 3\n",
      "train: iter 155  trainloss 3.37661  validloss 4.71257±0.00000  bestvalidloss 4.59511  last_update 4\n",
      "train: iter 156  trainloss 3.38451  validloss 4.63592±0.00000  bestvalidloss 4.59511  last_update 5\n",
      "train: iter 157  trainloss 3.35912  validloss 4.74147±0.00000  bestvalidloss 4.59511  last_update 6\n",
      "train: iter 158  trainloss 3.34419  validloss 4.71545±0.00000  bestvalidloss 4.59511  last_update 7\n",
      "train: iter 159  trainloss 3.34481  validloss 4.79477±0.00000  bestvalidloss 4.59511  last_update 8\n",
      "train: iter 160  trainloss 3.38800  validloss 4.72740±0.00000  bestvalidloss 4.59511  last_update 9\n",
      "train: iter 161  trainloss 3.36769  validloss 4.67203±0.00000  bestvalidloss 4.59511  last_update 10\n",
      "train: iter 162  trainloss 3.37999  validloss 4.76901±0.00000  bestvalidloss 4.59511  last_update 11\n",
      "train: iter 163  trainloss 3.36679  validloss 4.64216±0.00000  bestvalidloss 4.59511  last_update 12\n",
      "train: iter 164  trainloss 3.36741  validloss 4.68014±0.00000  bestvalidloss 4.59511  last_update 13\n",
      "train: iter 165  trainloss 3.38636  validloss 4.74767±0.00000  bestvalidloss 4.59511  last_update 14\n",
      "train: iter 166  trainloss 3.36865  validloss 4.71688±0.00000  bestvalidloss 4.59511  last_update 15\n",
      "train: iter 167  trainloss 3.36138  validloss 4.68623±0.00000  bestvalidloss 4.59511  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 3.36449  validloss 4.67932±0.00000  bestvalidloss 4.59511  last_update 17\n",
      "train: iter 169  trainloss 3.37121  validloss 4.81728±0.00000  bestvalidloss 4.59511  last_update 18\n",
      "train: iter 170  trainloss 3.37242  validloss 4.78142±0.00000  bestvalidloss 4.59511  last_update 19\n",
      "train: iter 171  trainloss 3.35781  validloss 4.73253±0.00000  bestvalidloss 4.59511  last_update 20\n",
      "train: iter 172  trainloss 3.38288  validloss 4.81599±0.00000  bestvalidloss 4.59511  last_update 21\n",
      "train: iter 173  trainloss 3.36955  validloss 4.73870±0.00000  bestvalidloss 4.59511  last_update 22\n",
      "train: iter 174  trainloss 3.35787  validloss 4.69746±0.00000  bestvalidloss 4.59511  last_update 23\n",
      "train: iter 175  trainloss 3.37480  validloss 4.80436±0.00000  bestvalidloss 4.59511  last_update 24\n",
      "train: iter 176  trainloss 3.37297  validloss 4.63424±0.00000  bestvalidloss 4.59511  last_update 25\n",
      "train: iter 177  trainloss 3.37481  validloss 4.77984±0.00000  bestvalidloss 4.59511  last_update 26\n",
      "train: iter 178  trainloss 3.37073  validloss 4.66131±0.00000  bestvalidloss 4.59511  last_update 27\n",
      "train: iter 179  trainloss 3.35831  validloss 4.72830±0.00000  bestvalidloss 4.59511  last_update 28\n",
      "train: iter 180  trainloss 3.36371  validloss 4.78511±0.00000  bestvalidloss 4.59511  last_update 29\n",
      "train: iter 181  trainloss 3.35699  validloss 4.69521±0.00000  bestvalidloss 4.59511  last_update 30\n",
      "train: iter 182  trainloss 3.38147  validloss 4.59601±0.00000  bestvalidloss 4.59511  last_update 31\n",
      "train: iter 183  trainloss 3.38840  validloss 4.66688±0.00000  bestvalidloss 4.59511  last_update 32\n",
      "train: iter 184  trainloss 3.39198  validloss 4.63372±0.00000  bestvalidloss 4.59511  last_update 33\n",
      "train: iter 185  trainloss 3.36144  validloss 4.63408±0.00000  bestvalidloss 4.59511  last_update 34\n",
      "train: iter 186  trainloss 3.38143  validloss 4.75026±0.00000  bestvalidloss 4.59511  last_update 35\n",
      "train: iter 187  trainloss 3.38583  validloss 4.71170±0.00000  bestvalidloss 4.59511  last_update 36\n",
      "train: iter 188  trainloss 3.34517  validloss 4.73430±0.00000  bestvalidloss 4.59511  last_update 37\n",
      "train: iter 189  trainloss 3.36078  validloss 4.64509±0.00000  bestvalidloss 4.59511  last_update 38\n",
      "train: iter 190  trainloss 3.35879  validloss 4.60687±0.00000  bestvalidloss 4.59511  last_update 39\n",
      "train: iter 191  trainloss 3.36811  validloss 4.66369±0.00000  bestvalidloss 4.59511  last_update 40\n",
      "train: iter 192  trainloss 3.37370  validloss 4.64370±0.00000  bestvalidloss 4.59511  last_update 41\n",
      "train: iter 193  trainloss 3.35875  validloss 4.77998±0.00000  bestvalidloss 4.59511  last_update 42\n",
      "train: iter 194  trainloss 3.35270  validloss 4.71608±0.00000  bestvalidloss 4.59511  last_update 43\n",
      "train: iter 195  trainloss 3.34904  validloss 4.75825±0.00000  bestvalidloss 4.59511  last_update 44\n",
      "train: iter 196  trainloss 3.35577  validloss 4.75794±0.00000  bestvalidloss 4.59511  last_update 45\n",
      "train: iter 197  trainloss 3.36454  validloss 4.63530±0.00000  bestvalidloss 4.59511  last_update 46\n",
      "train: iter 198  trainloss 3.37133  validloss 4.74058±0.00000  bestvalidloss 4.59511  last_update 47\n",
      "train: iter 199  trainloss 3.33866  validloss 4.73018±0.00000  bestvalidloss 4.59511  last_update 48\n",
      "train: iter 200  trainloss 3.37241  validloss 4.80986±0.00000  bestvalidloss 4.59511  last_update 49\n",
      "train: iter 201  trainloss 3.35867  validloss 4.73269±0.00000  bestvalidloss 4.59511  last_update 50\n",
      "train: iter 202  trainloss 3.34701  validloss 4.69778±0.00000  bestvalidloss 4.59511  last_update 51\n",
      "train: iter 203  trainloss 3.35108  validloss 4.77940±0.00000  bestvalidloss 4.59511  last_update 52\n",
      "train: iter 204  trainloss 3.37173  validloss 4.66071±0.00000  bestvalidloss 4.59511  last_update 53\n",
      "train: iter 205  trainloss 3.35739  validloss 4.68870±0.00000  bestvalidloss 4.59511  last_update 54\n",
      "train: iter 206  trainloss 3.39227  validloss 4.69198±0.00000  bestvalidloss 4.59511  last_update 55\n",
      "train: iter 207  trainloss 3.38887  validloss 4.73105±0.00000  bestvalidloss 4.59511  last_update 56\n",
      "train: iter 208  trainloss 3.35346  validloss 4.69371±0.00000  bestvalidloss 4.59511  last_update 57\n",
      "train: iter 209  trainloss 3.36989  validloss 4.69365±0.00000  bestvalidloss 4.59511  last_update 58\n",
      "train: iter 210  trainloss 3.34191  validloss 4.69175±0.00000  bestvalidloss 4.59511  last_update 59\n",
      "train: iter 211  trainloss 3.38767  validloss 4.65920±0.00000  bestvalidloss 4.59511  last_update 60\n",
      "train: iter 212  trainloss 3.35810  validloss 4.65753±0.00000  bestvalidloss 4.59511  last_update 61\n",
      "train: iter 213  trainloss 3.35399  validloss 4.74431±0.00000  bestvalidloss 4.59511  last_update 62\n",
      "train: iter 214  trainloss 3.35835  validloss 4.71331±0.00000  bestvalidloss 4.59511  last_update 63\n",
      "train: iter 215  trainloss 3.36629  validloss 4.68047±0.00000  bestvalidloss 4.59511  last_update 64\n",
      "train: iter 216  trainloss 3.33540  validloss 4.62387±0.00000  bestvalidloss 4.59511  last_update 65\n",
      "train: iter 217  trainloss 3.36706  validloss 4.77582±0.00000  bestvalidloss 4.59511  last_update 66\n",
      "train: iter 218  trainloss 3.36202  validloss 4.73845±0.00000  bestvalidloss 4.59511  last_update 67\n",
      "train: iter 219  trainloss 3.37795  validloss 4.67390±0.00000  bestvalidloss 4.59511  last_update 68\n",
      "train: iter 220  trainloss 3.36716  validloss 4.76706±0.00000  bestvalidloss 4.59511  last_update 69\n",
      "train: iter 221  trainloss 3.33362  validloss 4.74718±0.00000  bestvalidloss 4.59511  last_update 70\n",
      "train: iter 222  trainloss 3.34491  validloss 4.74450±0.00000  bestvalidloss 4.59511  last_update 71\n",
      "train: iter 223  trainloss 3.36496  validloss 4.80963±0.00000  bestvalidloss 4.59511  last_update 72\n",
      "train: iter 224  trainloss 3.34748  validloss 4.78700±0.00000  bestvalidloss 4.59511  last_update 73\n",
      "train: iter 225  trainloss 3.35283  validloss 4.72479±0.00000  bestvalidloss 4.59511  last_update 74\n",
      "train: iter 226  trainloss 3.35579  validloss 4.67240±0.00000  bestvalidloss 4.59511  last_update 75\n",
      "train: iter 227  trainloss 3.36507  validloss 4.73659±0.00000  bestvalidloss 4.59511  last_update 76\n",
      "train: iter 228  trainloss 3.33077  validloss 4.67838±0.00000  bestvalidloss 4.59511  last_update 77\n",
      "train: iter 229  trainloss 3.35276  validloss 4.95570±0.00000  bestvalidloss 4.59511  last_update 78\n",
      "train: iter 230  trainloss 3.37094  validloss 4.70520±0.00000  bestvalidloss 4.59511  last_update 79\n",
      "train: iter 231  trainloss 3.34816  validloss 4.85867±0.00000  bestvalidloss 4.59511  last_update 80\n",
      "train: iter 232  trainloss 3.34300  validloss 4.65460±0.00000  bestvalidloss 4.59511  last_update 81\n",
      "train: iter 233  trainloss 3.36086  validloss 4.77689±0.00000  bestvalidloss 4.59511  last_update 82\n",
      "train: iter 234  trainloss 3.34630  validloss 4.73328±0.00000  bestvalidloss 4.59511  last_update 83\n",
      "train: iter 235  trainloss 3.34199  validloss 4.71839±0.00000  bestvalidloss 4.59511  last_update 84\n",
      "train: iter 236  trainloss 3.33204  validloss 4.80737±0.00000  bestvalidloss 4.59511  last_update 85\n",
      "train: iter 237  trainloss 3.33675  validloss 4.81380±0.00000  bestvalidloss 4.59511  last_update 86\n",
      "train: iter 238  trainloss 3.34079  validloss 4.67078±0.00000  bestvalidloss 4.59511  last_update 87\n",
      "train: iter 239  trainloss 3.34780  validloss 4.74297±0.00000  bestvalidloss 4.59511  last_update 88\n",
      "train: iter 240  trainloss 3.34413  validloss 4.72531±0.00000  bestvalidloss 4.59511  last_update 89\n",
      "train: iter 241  trainloss 3.33580  validloss 4.72657±0.00000  bestvalidloss 4.59511  last_update 90\n",
      "train: iter 242  trainloss 3.33524  validloss 4.80201±0.00000  bestvalidloss 4.59511  last_update 91\n",
      "train: iter 243  trainloss 3.35368  validloss 4.71727±0.00000  bestvalidloss 4.59511  last_update 92\n",
      "train: iter 244  trainloss 3.34916  validloss 4.68392±0.00000  bestvalidloss 4.59511  last_update 93\n",
      "train: iter 245  trainloss 3.31758  validloss 4.74939±0.00000  bestvalidloss 4.59511  last_update 94\n",
      "train: iter 246  trainloss 3.36115  validloss 4.80801±0.00000  bestvalidloss 4.59511  last_update 95\n",
      "train: iter 247  trainloss 3.33118  validloss 4.84305±0.00000  bestvalidloss 4.59511  last_update 96\n",
      "train: iter 248  trainloss 3.33756  validloss 4.67627±0.00000  bestvalidloss 4.59511  last_update 97\n",
      "train: iter 249  trainloss 3.32894  validloss 4.71952±0.00000  bestvalidloss 4.59511  last_update 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 250  trainloss 3.33019  validloss 4.82243±0.00000  bestvalidloss 4.59511  last_update 99\n",
      "train: iter 251  trainloss 3.34715  validloss 4.75480±0.00000  bestvalidloss 4.59511  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-11.0065)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-2.3922)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01371343466575043\n",
      "tensor([-1.3513])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b4761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebe843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c8317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220513b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7adb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
