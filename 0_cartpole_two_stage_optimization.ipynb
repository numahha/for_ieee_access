{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-3237.6421)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 9628.78181  validloss 145387.74301±0.00000  bestvalidloss 145387.74301  last_update 0\n",
      "train: iter 1  trainloss 1602.82315  validloss 1308.59082±0.00000  bestvalidloss 1308.59082  last_update 0\n",
      "train: iter 2  trainloss 1211.60794  validloss 1882.29360±0.00000  bestvalidloss 1308.59082  last_update 1\n",
      "train: iter 3  trainloss 1037.39418  validloss 1270.23140±0.00000  bestvalidloss 1270.23140  last_update 0\n",
      "train: iter 4  trainloss 1049.77237  validloss 1131.20697±0.00000  bestvalidloss 1131.20697  last_update 0\n",
      "train: iter 5  trainloss 942.96856  validloss 1025.91362±0.00000  bestvalidloss 1025.91362  last_update 0\n",
      "train: iter 6  trainloss 901.62190  validloss 907.96852±0.00000  bestvalidloss 907.96852  last_update 0\n",
      "train: iter 7  trainloss 865.15896  validloss 889.73529±0.00000  bestvalidloss 889.73529  last_update 0\n",
      "train: iter 8  trainloss 837.50042  validloss 871.04382±0.00000  bestvalidloss 871.04382  last_update 0\n",
      "train: iter 9  trainloss 812.85901  validloss 844.93710±0.00000  bestvalidloss 844.93710  last_update 0\n",
      "train: iter 10  trainloss 832.26312  validloss 843.29950±0.00000  bestvalidloss 843.29950  last_update 0\n",
      "train: iter 11  trainloss 785.26924  validloss 818.69009±0.00000  bestvalidloss 818.69009  last_update 0\n",
      "train: iter 12  trainloss 783.65239  validloss 795.47641±0.00000  bestvalidloss 795.47641  last_update 0\n",
      "train: iter 13  trainloss 730.55653  validloss 746.75695±0.00000  bestvalidloss 746.75695  last_update 0\n",
      "train: iter 14  trainloss 692.89314  validloss 738.82713±0.00000  bestvalidloss 738.82713  last_update 0\n",
      "train: iter 15  trainloss 700.12209  validloss 724.15729±0.00000  bestvalidloss 724.15729  last_update 0\n",
      "train: iter 16  trainloss 610.22483  validloss 669.37566±0.00000  bestvalidloss 669.37566  last_update 0\n",
      "train: iter 17  trainloss 534.78390  validloss 621.72222±0.00000  bestvalidloss 621.72222  last_update 0\n",
      "train: iter 18  trainloss 480.16329  validloss 604.58786±0.00000  bestvalidloss 604.58786  last_update 0\n",
      "train: iter 19  trainloss 374.34597  validloss 482.76102±0.00000  bestvalidloss 482.76102  last_update 0\n",
      "train: iter 20  trainloss 296.40732  validloss 348.03359±0.00000  bestvalidloss 348.03359  last_update 0\n",
      "train: iter 21  trainloss 242.38054  validloss 291.63911±0.00000  bestvalidloss 291.63911  last_update 0\n",
      "train: iter 22  trainloss 246.90679  validloss 408.56609±0.00000  bestvalidloss 291.63911  last_update 1\n",
      "train: iter 23  trainloss 221.73739  validloss 246.91163±0.00000  bestvalidloss 246.91163  last_update 0\n",
      "train: iter 24  trainloss 120.87295  validloss 196.45255±0.00000  bestvalidloss 196.45255  last_update 0\n",
      "train: iter 25  trainloss 80.40764  validloss 220.83432±0.00000  bestvalidloss 196.45255  last_update 1\n",
      "train: iter 26  trainloss 39.55891  validloss 155.44316±0.00000  bestvalidloss 155.44316  last_update 0\n",
      "train: iter 27  trainloss 6.80086  validloss 69.02376±0.00000  bestvalidloss 69.02376  last_update 0\n",
      "train: iter 28  trainloss -54.23621  validloss 44.51058±0.00000  bestvalidloss 44.51058  last_update 0\n",
      "train: iter 29  trainloss -44.55462  validloss 59.94146±0.00000  bestvalidloss 44.51058  last_update 1\n",
      "train: iter 30  trainloss -117.50838  validloss -6.46861±0.00000  bestvalidloss -6.46861  last_update 0\n",
      "train: iter 31  trainloss -120.47864  validloss -84.69630±0.00000  bestvalidloss -84.69630  last_update 0\n",
      "train: iter 32  trainloss -58.86446  validloss 34.22713±0.00000  bestvalidloss -84.69630  last_update 1\n",
      "train: iter 33  trainloss -162.02336  validloss -97.95608±0.00000  bestvalidloss -97.95608  last_update 0\n",
      "train: iter 34  trainloss -203.59767  validloss -139.70317±0.00000  bestvalidloss -139.70317  last_update 0\n",
      "train: iter 35  trainloss -205.12598  validloss -155.47739±0.00000  bestvalidloss -155.47739  last_update 0\n",
      "train: iter 36  trainloss -236.08213  validloss -145.26075±0.00000  bestvalidloss -155.47739  last_update 1\n",
      "train: iter 37  trainloss -196.69634  validloss -87.35274±0.00000  bestvalidloss -155.47739  last_update 2\n",
      "train: iter 38  trainloss -268.28528  validloss -93.99523±0.00000  bestvalidloss -155.47739  last_update 3\n",
      "train: iter 39  trainloss -238.55401  validloss -132.75218±0.00000  bestvalidloss -155.47739  last_update 4\n",
      "train: iter 40  trainloss -334.27486  validloss -243.08621±0.00000  bestvalidloss -243.08621  last_update 0\n",
      "train: iter 41  trainloss -294.71982  validloss -57.90268±0.00000  bestvalidloss -243.08621  last_update 1\n",
      "train: iter 42  trainloss -314.25103  validloss -267.31320±0.00000  bestvalidloss -267.31320  last_update 0\n",
      "train: iter 43  trainloss -384.38976  validloss -309.13525±0.00000  bestvalidloss -309.13525  last_update 0\n",
      "train: iter 44  trainloss -398.43907  validloss -208.78485±0.00000  bestvalidloss -309.13525  last_update 1\n",
      "train: iter 45  trainloss -386.29974  validloss -113.65207±0.00000  bestvalidloss -309.13525  last_update 2\n",
      "train: iter 46  trainloss -389.64361  validloss -267.98198±0.00000  bestvalidloss -309.13525  last_update 3\n",
      "train: iter 47  trainloss -393.29964  validloss -316.58865±0.00000  bestvalidloss -316.58865  last_update 0\n",
      "train: iter 48  trainloss -335.61614  validloss -279.23789±0.00000  bestvalidloss -316.58865  last_update 1\n",
      "train: iter 49  trainloss -325.32787  validloss -309.71050±0.00000  bestvalidloss -316.58865  last_update 2\n",
      "train: iter 50  trainloss -459.75110  validloss -387.89139±0.00000  bestvalidloss -387.89139  last_update 0\n",
      "train: iter 51  trainloss -302.68088  validloss -227.21075±0.00000  bestvalidloss -387.89139  last_update 1\n",
      "train: iter 52  trainloss -265.40725  validloss -233.52017±0.00000  bestvalidloss -387.89139  last_update 2\n",
      "train: iter 53  trainloss -501.37149  validloss -436.30995±0.00000  bestvalidloss -436.30995  last_update 0\n",
      "train: iter 54  trainloss -509.26415  validloss -416.48374±0.00000  bestvalidloss -436.30995  last_update 1\n",
      "train: iter 55  trainloss -526.07806  validloss -485.12163±0.00000  bestvalidloss -485.12163  last_update 0\n",
      "train: iter 56  trainloss -482.64797  validloss -308.28428±0.00000  bestvalidloss -485.12163  last_update 1\n",
      "train: iter 57  trainloss -510.37429  validloss -409.68428±0.00000  bestvalidloss -485.12163  last_update 2\n",
      "train: iter 58  trainloss -334.05103  validloss -287.00760±0.00000  bestvalidloss -485.12163  last_update 3\n",
      "train: iter 59  trainloss -573.47598  validloss -461.33176±0.00000  bestvalidloss -485.12163  last_update 4\n",
      "train: iter 60  trainloss -575.96611  validloss -402.41251±0.00000  bestvalidloss -485.12163  last_update 5\n",
      "train: iter 61  trainloss -577.98218  validloss -520.38774±0.00000  bestvalidloss -520.38774  last_update 0\n",
      "train: iter 62  trainloss -569.63186  validloss -519.23585±0.00000  bestvalidloss -520.38774  last_update 1\n",
      "train: iter 63  trainloss -638.49208  validloss -517.83978±0.00000  bestvalidloss -520.38774  last_update 2\n",
      "train: iter 64  trainloss -643.23116  validloss -511.67582±0.00000  bestvalidloss -520.38774  last_update 3\n",
      "train: iter 65  trainloss -617.20141  validloss -549.95222±0.00000  bestvalidloss -549.95222  last_update 0\n",
      "train: iter 66  trainloss -631.36212  validloss -514.47554±0.00000  bestvalidloss -549.95222  last_update 1\n",
      "train: iter 67  trainloss -651.25894  validloss -352.27622±0.00000  bestvalidloss -549.95222  last_update 2\n",
      "train: iter 68  trainloss -469.18351  validloss -553.56456±0.00000  bestvalidloss -553.56456  last_update 0\n",
      "train: iter 69  trainloss -441.90733  validloss -122.78662±0.00000  bestvalidloss -553.56456  last_update 1\n",
      "train: iter 70  trainloss -692.58917  validloss -586.09183±0.00000  bestvalidloss -586.09183  last_update 0\n",
      "train: iter 71  trainloss -601.52822  validloss -627.54835±0.00000  bestvalidloss -627.54835  last_update 0\n",
      "train: iter 72  trainloss -586.20078  validloss -569.89803±0.00000  bestvalidloss -627.54835  last_update 1\n",
      "train: iter 73  trainloss -615.69850  validloss -573.09343±0.00000  bestvalidloss -627.54835  last_update 2\n",
      "train: iter 74  trainloss -663.19674  validloss -525.32929±0.00000  bestvalidloss -627.54835  last_update 3\n",
      "train: iter 75  trainloss -658.35251  validloss -665.63492±0.00000  bestvalidloss -665.63492  last_update 0\n",
      "train: iter 76  trainloss -698.35205  validloss -522.29709±0.00000  bestvalidloss -665.63492  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -725.48785  validloss -706.40923±0.00000  bestvalidloss -706.40923  last_update 0\n",
      "train: iter 78  trainloss -742.02817  validloss -725.76196±0.00000  bestvalidloss -725.76196  last_update 0\n",
      "train: iter 79  trainloss -695.48756  validloss -615.90422±0.00000  bestvalidloss -725.76196  last_update 1\n",
      "train: iter 80  trainloss -494.16154  validloss -468.33003±0.00000  bestvalidloss -725.76196  last_update 2\n",
      "train: iter 81  trainloss -674.88547  validloss -548.54527±0.00000  bestvalidloss -725.76196  last_update 3\n",
      "train: iter 82  trainloss -680.38605  validloss -602.75893±0.00000  bestvalidloss -725.76196  last_update 4\n",
      "train: iter 83  trainloss -782.48152  validloss -692.98703±0.00000  bestvalidloss -725.76196  last_update 5\n",
      "train: iter 84  trainloss -750.47007  validloss -704.46642±0.00000  bestvalidloss -725.76196  last_update 6\n",
      "train: iter 85  trainloss -716.97749  validloss -612.64568±0.00000  bestvalidloss -725.76196  last_update 7\n",
      "train: iter 86  trainloss -804.95307  validloss -741.85679±0.00000  bestvalidloss -741.85679  last_update 0\n",
      "train: iter 87  trainloss -780.51680  validloss -711.02816±0.00000  bestvalidloss -741.85679  last_update 1\n",
      "train: iter 88  trainloss -814.36302  validloss -739.72394±0.00000  bestvalidloss -741.85679  last_update 2\n",
      "train: iter 89  trainloss -692.82063  validloss -693.29284±0.00000  bestvalidloss -741.85679  last_update 3\n",
      "train: iter 90  trainloss -793.83761  validloss -759.62645±0.00000  bestvalidloss -759.62645  last_update 0\n",
      "train: iter 91  trainloss -784.18947  validloss -644.25407±0.00000  bestvalidloss -759.62645  last_update 1\n",
      "train: iter 92  trainloss -802.63654  validloss -747.83212±0.00000  bestvalidloss -759.62645  last_update 2\n",
      "train: iter 93  trainloss -783.78516  validloss -750.13485±0.00000  bestvalidloss -759.62645  last_update 3\n",
      "train: iter 94  trainloss -704.90994  validloss -604.58936±0.00000  bestvalidloss -759.62645  last_update 4\n",
      "train: iter 95  trainloss -655.23583  validloss -822.95293±0.00000  bestvalidloss -822.95293  last_update 0\n",
      "train: iter 96  trainloss -774.35243  validloss -600.17300±0.00000  bestvalidloss -822.95293  last_update 1\n",
      "train: iter 97  trainloss -751.11750  validloss -635.32876±0.00000  bestvalidloss -822.95293  last_update 2\n",
      "train: iter 98  trainloss -830.59541  validloss -682.95670±0.00000  bestvalidloss -822.95293  last_update 3\n",
      "train: iter 99  trainloss -656.60518  validloss -740.03614±0.00000  bestvalidloss -822.95293  last_update 4\n",
      "train: iter 100  trainloss -759.12050  validloss -686.18795±0.00000  bestvalidloss -822.95293  last_update 5\n",
      "train: iter 101  trainloss -798.85173  validloss -841.94203±0.00000  bestvalidloss -841.94203  last_update 0\n",
      "train: iter 102  trainloss -817.25664  validloss -766.32965±0.00000  bestvalidloss -841.94203  last_update 1\n",
      "train: iter 103  trainloss -855.36895  validloss -764.98959±0.00000  bestvalidloss -841.94203  last_update 2\n",
      "train: iter 104  trainloss -915.59640  validloss -806.82583±0.00000  bestvalidloss -841.94203  last_update 3\n",
      "train: iter 105  trainloss -584.91360  validloss -788.13534±0.00000  bestvalidloss -841.94203  last_update 4\n",
      "train: iter 106  trainloss -662.48078  validloss -693.56211±0.00000  bestvalidloss -841.94203  last_update 5\n",
      "train: iter 107  trainloss -782.04489  validloss -651.99207±0.00000  bestvalidloss -841.94203  last_update 6\n",
      "train: iter 108  trainloss -751.46865  validloss -740.00212±0.00000  bestvalidloss -841.94203  last_update 7\n",
      "train: iter 109  trainloss -767.13524  validloss -721.35357±0.00000  bestvalidloss -841.94203  last_update 8\n",
      "train: iter 110  trainloss -848.46456  validloss -825.76664±0.00000  bestvalidloss -841.94203  last_update 9\n",
      "train: iter 111  trainloss -796.59334  validloss -823.86573±0.00000  bestvalidloss -841.94203  last_update 10\n",
      "train: iter 112  trainloss -913.66880  validloss -873.10391±0.00000  bestvalidloss -873.10391  last_update 0\n",
      "train: iter 113  trainloss -854.79789  validloss -876.67054±0.00000  bestvalidloss -876.67054  last_update 0\n",
      "train: iter 114  trainloss -904.70171  validloss -845.89051±0.00000  bestvalidloss -876.67054  last_update 1\n",
      "train: iter 115  trainloss -858.60980  validloss -882.55872±0.00000  bestvalidloss -882.55872  last_update 0\n",
      "train: iter 116  trainloss -922.94515  validloss -918.64751±0.00000  bestvalidloss -918.64751  last_update 0\n",
      "train: iter 117  trainloss -833.32270  validloss -846.87804±0.00000  bestvalidloss -918.64751  last_update 1\n",
      "train: iter 118  trainloss -891.82279  validloss -795.44533±0.00000  bestvalidloss -918.64751  last_update 2\n",
      "train: iter 119  trainloss -892.86889  validloss -875.90307±0.00000  bestvalidloss -918.64751  last_update 3\n",
      "train: iter 120  trainloss -845.30162  validloss -797.49714±0.00000  bestvalidloss -918.64751  last_update 4\n",
      "train: iter 121  trainloss -906.28473  validloss -893.75466±0.00000  bestvalidloss -918.64751  last_update 5\n",
      "train: iter 122  trainloss -630.38209  validloss -827.52023±0.00000  bestvalidloss -918.64751  last_update 6\n",
      "train: iter 123  trainloss -881.01639  validloss -560.21554±0.00000  bestvalidloss -918.64751  last_update 7\n",
      "train: iter 124  trainloss -840.70360  validloss -876.74925±0.00000  bestvalidloss -918.64751  last_update 8\n",
      "train: iter 125  trainloss -866.05130  validloss -732.82470±0.00000  bestvalidloss -918.64751  last_update 9\n",
      "train: iter 126  trainloss -919.38739  validloss -696.03558±0.00000  bestvalidloss -918.64751  last_update 10\n",
      "train: iter 127  trainloss -944.56898  validloss -934.03951±0.00000  bestvalidloss -934.03951  last_update 0\n",
      "train: iter 128  trainloss -1003.14566  validloss -923.16509±0.00000  bestvalidloss -934.03951  last_update 1\n",
      "train: iter 129  trainloss -946.29556  validloss -938.62651±0.00000  bestvalidloss -938.62651  last_update 0\n",
      "train: iter 130  trainloss -868.30945  validloss -928.17731±0.00000  bestvalidloss -938.62651  last_update 1\n",
      "train: iter 131  trainloss -818.94874  validloss -561.28129±0.00000  bestvalidloss -938.62651  last_update 2\n",
      "train: iter 132  trainloss -963.51416  validloss -872.47429±0.00000  bestvalidloss -938.62651  last_update 3\n",
      "train: iter 133  trainloss -850.20042  validloss -935.12402±0.00000  bestvalidloss -938.62651  last_update 4\n",
      "train: iter 134  trainloss -869.66872  validloss -593.83598±0.00000  bestvalidloss -938.62651  last_update 5\n",
      "train: iter 135  trainloss -937.67099  validloss -919.64806±0.00000  bestvalidloss -938.62651  last_update 6\n",
      "train: iter 136  trainloss -936.47308  validloss -905.64156±0.00000  bestvalidloss -938.62651  last_update 7\n",
      "train: iter 137  trainloss -911.65769  validloss -921.94546±0.00000  bestvalidloss -938.62651  last_update 8\n",
      "train: iter 138  trainloss -874.85368  validloss -962.30985±0.00000  bestvalidloss -962.30985  last_update 0\n",
      "train: iter 139  trainloss -933.11757  validloss -895.05756±0.00000  bestvalidloss -962.30985  last_update 1\n",
      "train: iter 140  trainloss -993.21609  validloss -845.32259±0.00000  bestvalidloss -962.30985  last_update 2\n",
      "train: iter 141  trainloss -983.90114  validloss -854.48036±0.00000  bestvalidloss -962.30985  last_update 3\n",
      "train: iter 142  trainloss -946.27373  validloss -823.09797±0.00000  bestvalidloss -962.30985  last_update 4\n",
      "train: iter 143  trainloss -988.50799  validloss -911.61665±0.00000  bestvalidloss -962.30985  last_update 5\n",
      "train: iter 144  trainloss -1050.15869  validloss -1012.27430±0.00000  bestvalidloss -1012.27430  last_update 0\n",
      "train: iter 145  trainloss -1038.71730  validloss -953.65859±0.00000  bestvalidloss -1012.27430  last_update 1\n",
      "train: iter 146  trainloss -854.90615  validloss -824.38680±0.00000  bestvalidloss -1012.27430  last_update 2\n",
      "train: iter 147  trainloss -996.44672  validloss -924.40447±0.00000  bestvalidloss -1012.27430  last_update 3\n",
      "train: iter 148  trainloss -976.79625  validloss -857.85058±0.00000  bestvalidloss -1012.27430  last_update 4\n",
      "train: iter 149  trainloss -1018.74780  validloss -844.78662±0.00000  bestvalidloss -1012.27430  last_update 5\n",
      "train: iter 150  trainloss -863.36655  validloss -920.83668±0.00000  bestvalidloss -1012.27430  last_update 6\n",
      "train: iter 151  trainloss -827.24587  validloss -467.07195±0.00000  bestvalidloss -1012.27430  last_update 7\n",
      "train: iter 152  trainloss -1025.50853  validloss -889.11797±0.00000  bestvalidloss -1012.27430  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -998.45880  validloss -1053.19674±0.00000  bestvalidloss -1053.19674  last_update 0\n",
      "train: iter 154  trainloss -1012.52669  validloss -901.55830±0.00000  bestvalidloss -1053.19674  last_update 1\n",
      "train: iter 155  trainloss -645.35456  validloss -807.54348±0.00000  bestvalidloss -1053.19674  last_update 2\n",
      "train: iter 156  trainloss -613.91693  validloss -467.96801±0.00000  bestvalidloss -1053.19674  last_update 3\n",
      "train: iter 157  trainloss -654.95817  validloss -212.02460±0.00000  bestvalidloss -1053.19674  last_update 4\n",
      "train: iter 158  trainloss -937.53009  validloss -822.39913±0.00000  bestvalidloss -1053.19674  last_update 5\n",
      "train: iter 159  trainloss -970.74425  validloss -901.43059±0.00000  bestvalidloss -1053.19674  last_update 6\n",
      "train: iter 160  trainloss -1021.25822  validloss -937.10359±0.00000  bestvalidloss -1053.19674  last_update 7\n",
      "train: iter 161  trainloss -957.23495  validloss -982.16740±0.00000  bestvalidloss -1053.19674  last_update 8\n",
      "train: iter 162  trainloss -925.61025  validloss -813.19858±0.00000  bestvalidloss -1053.19674  last_update 9\n",
      "train: iter 163  trainloss -1003.31508  validloss -1020.34215±0.00000  bestvalidloss -1053.19674  last_update 10\n",
      "train: iter 164  trainloss -869.93080  validloss -705.21259±0.00000  bestvalidloss -1053.19674  last_update 11\n",
      "train: iter 165  trainloss -998.47955  validloss -961.85102±0.00000  bestvalidloss -1053.19674  last_update 12\n",
      "train: iter 166  trainloss -902.72601  validloss -970.19681±0.00000  bestvalidloss -1053.19674  last_update 13\n",
      "train: iter 167  trainloss -798.72627  validloss -601.07315±0.00000  bestvalidloss -1053.19674  last_update 14\n",
      "train: iter 168  trainloss -1002.59002  validloss -860.54898±0.00000  bestvalidloss -1053.19674  last_update 15\n",
      "train: iter 169  trainloss -1110.32245  validloss -1051.77831±0.00000  bestvalidloss -1053.19674  last_update 16\n",
      "train: iter 170  trainloss -786.94365  validloss -1019.60610±0.00000  bestvalidloss -1053.19674  last_update 17\n",
      "train: iter 171  trainloss -962.24717  validloss -929.93520±0.00000  bestvalidloss -1053.19674  last_update 18\n",
      "train: iter 172  trainloss -1106.27034  validloss -1066.21219±0.00000  bestvalidloss -1066.21219  last_update 0\n",
      "train: iter 173  trainloss -1038.12557  validloss -898.32016±0.00000  bestvalidloss -1066.21219  last_update 1\n",
      "train: iter 174  trainloss -1065.76622  validloss -923.50859±0.00000  bestvalidloss -1066.21219  last_update 2\n",
      "train: iter 175  trainloss -1098.03797  validloss -1108.43365±0.00000  bestvalidloss -1108.43365  last_update 0\n",
      "train: iter 176  trainloss -1108.05606  validloss -1118.71010±0.00000  bestvalidloss -1118.71010  last_update 0\n",
      "train: iter 177  trainloss -1013.97199  validloss -1033.87209±0.00000  bestvalidloss -1118.71010  last_update 1\n",
      "train: iter 178  trainloss -1089.19726  validloss -1049.71935±0.00000  bestvalidloss -1118.71010  last_update 2\n",
      "train: iter 179  trainloss -1122.76908  validloss -958.68281±0.00000  bestvalidloss -1118.71010  last_update 3\n",
      "train: iter 180  trainloss -1040.86370  validloss -1116.41975±0.00000  bestvalidloss -1118.71010  last_update 4\n",
      "train: iter 181  trainloss -1101.95197  validloss -1041.88342±0.00000  bestvalidloss -1118.71010  last_update 5\n",
      "train: iter 182  trainloss -1090.95141  validloss -1061.18611±0.00000  bestvalidloss -1118.71010  last_update 6\n",
      "train: iter 183  trainloss -1001.12414  validloss -1128.99836±0.00000  bestvalidloss -1128.99836  last_update 0\n",
      "train: iter 184  trainloss -1069.76490  validloss -771.09685±0.00000  bestvalidloss -1128.99836  last_update 1\n",
      "train: iter 185  trainloss -1091.51219  validloss -1054.11875±0.00000  bestvalidloss -1128.99836  last_update 2\n",
      "train: iter 186  trainloss -1111.40369  validloss -1065.40812±0.00000  bestvalidloss -1128.99836  last_update 3\n",
      "train: iter 187  trainloss -1111.44389  validloss -1003.08484±0.00000  bestvalidloss -1128.99836  last_update 4\n",
      "train: iter 188  trainloss -1148.53053  validloss -1020.52986±0.00000  bestvalidloss -1128.99836  last_update 5\n",
      "train: iter 189  trainloss -1122.23456  validloss -888.48604±0.00000  bestvalidloss -1128.99836  last_update 6\n",
      "train: iter 190  trainloss -1116.36656  validloss -1014.33717±0.00000  bestvalidloss -1128.99836  last_update 7\n",
      "train: iter 191  trainloss -1188.44129  validloss -1157.33405±0.00000  bestvalidloss -1157.33405  last_update 0\n",
      "train: iter 192  trainloss -1074.68375  validloss -1114.56561±0.00000  bestvalidloss -1157.33405  last_update 1\n",
      "train: iter 193  trainloss -1025.10320  validloss -1088.23656±0.00000  bestvalidloss -1157.33405  last_update 2\n",
      "train: iter 194  trainloss -1115.80019  validloss -1009.17484±0.00000  bestvalidloss -1157.33405  last_update 3\n",
      "train: iter 195  trainloss -989.24767  validloss -1016.27788±0.00000  bestvalidloss -1157.33405  last_update 4\n",
      "train: iter 196  trainloss -1131.31853  validloss -1055.41684±0.00000  bestvalidloss -1157.33405  last_update 5\n",
      "train: iter 197  trainloss -1050.96353  validloss -1069.98042±0.00000  bestvalidloss -1157.33405  last_update 6\n",
      "train: iter 198  trainloss -1079.26583  validloss -1056.56311±0.00000  bestvalidloss -1157.33405  last_update 7\n",
      "train: iter 199  trainloss -1202.65292  validloss -1136.19292±0.00000  bestvalidloss -1157.33405  last_update 8\n",
      "train: iter 200  trainloss -1210.99347  validloss -1148.10321±0.00000  bestvalidloss -1157.33405  last_update 9\n",
      "train: iter 201  trainloss -1043.40552  validloss -1162.33799±0.00000  bestvalidloss -1162.33799  last_update 0\n",
      "train: iter 202  trainloss -995.17043  validloss -899.97212±0.00000  bestvalidloss -1162.33799  last_update 1\n",
      "train: iter 203  trainloss -1036.33940  validloss -824.06742±0.00000  bestvalidloss -1162.33799  last_update 2\n",
      "train: iter 204  trainloss -1072.44287  validloss -1060.28708±0.00000  bestvalidloss -1162.33799  last_update 3\n",
      "train: iter 205  trainloss -1184.02866  validloss -1138.14151±0.00000  bestvalidloss -1162.33799  last_update 4\n",
      "train: iter 206  trainloss -1144.20767  validloss -1141.23954±0.00000  bestvalidloss -1162.33799  last_update 5\n",
      "train: iter 207  trainloss -1193.34993  validloss -1126.29739±0.00000  bestvalidloss -1162.33799  last_update 6\n",
      "train: iter 208  trainloss -1122.63821  validloss -1169.01659±0.00000  bestvalidloss -1169.01659  last_update 0\n",
      "train: iter 209  trainloss -1171.35453  validloss -1121.10717±0.00000  bestvalidloss -1169.01659  last_update 1\n",
      "train: iter 210  trainloss -1190.46175  validloss -1191.75193±0.00000  bestvalidloss -1191.75193  last_update 0\n",
      "train: iter 211  trainloss -1153.89029  validloss -1039.13443±0.00000  bestvalidloss -1191.75193  last_update 1\n",
      "train: iter 212  trainloss -1207.19444  validloss -1129.30516±0.00000  bestvalidloss -1191.75193  last_update 2\n",
      "train: iter 213  trainloss -1128.92934  validloss -1155.69023±0.00000  bestvalidloss -1191.75193  last_update 3\n",
      "train: iter 214  trainloss -1126.96007  validloss -1020.40610±0.00000  bestvalidloss -1191.75193  last_update 4\n",
      "train: iter 215  trainloss -1222.70827  validloss -1095.42267±0.00000  bestvalidloss -1191.75193  last_update 5\n",
      "train: iter 216  trainloss -1042.36164  validloss -1211.49632±0.00000  bestvalidloss -1211.49632  last_update 0\n",
      "train: iter 217  trainloss -1093.47796  validloss -1065.03854±0.00000  bestvalidloss -1211.49632  last_update 1\n",
      "train: iter 218  trainloss -1150.52281  validloss -976.22985±0.00000  bestvalidloss -1211.49632  last_update 2\n",
      "train: iter 219  trainloss -1240.73127  validloss -1114.64125±0.00000  bestvalidloss -1211.49632  last_update 3\n",
      "train: iter 220  trainloss -1213.59117  validloss -1215.42001±0.00000  bestvalidloss -1215.42001  last_update 0\n",
      "train: iter 221  trainloss -1039.74013  validloss -1138.83098±0.00000  bestvalidloss -1215.42001  last_update 1\n",
      "train: iter 222  trainloss -1220.26506  validloss -1060.82275±0.00000  bestvalidloss -1215.42001  last_update 2\n",
      "train: iter 223  trainloss -1256.46470  validloss -1227.30662±0.00000  bestvalidloss -1227.30662  last_update 0\n",
      "train: iter 224  trainloss -1085.66221  validloss -815.98072±0.00000  bestvalidloss -1227.30662  last_update 1\n",
      "train: iter 225  trainloss -1103.12332  validloss -1071.37745±0.00000  bestvalidloss -1227.30662  last_update 2\n",
      "train: iter 226  trainloss -1066.31439  validloss -834.77975±0.00000  bestvalidloss -1227.30662  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 227  trainloss -1193.17946  validloss -1170.82000±0.00000  bestvalidloss -1227.30662  last_update 4\n",
      "train: iter 228  trainloss -1196.32607  validloss -1131.52504±0.00000  bestvalidloss -1227.30662  last_update 5\n",
      "train: iter 229  trainloss -1258.22914  validloss -1171.80625±0.00000  bestvalidloss -1227.30662  last_update 6\n",
      "train: iter 230  trainloss -1254.26547  validloss -1241.31862±0.00000  bestvalidloss -1241.31862  last_update 0\n",
      "train: iter 231  trainloss -1138.46404  validloss -1192.89447±0.00000  bestvalidloss -1241.31862  last_update 1\n",
      "train: iter 232  trainloss -1189.56068  validloss -1143.29841±0.00000  bestvalidloss -1241.31862  last_update 2\n",
      "train: iter 233  trainloss -1248.49881  validloss -1181.12134±0.00000  bestvalidloss -1241.31862  last_update 3\n",
      "train: iter 234  trainloss -1240.89950  validloss -1227.09728±0.00000  bestvalidloss -1241.31862  last_update 4\n",
      "train: iter 235  trainloss -1193.19250  validloss -1150.65998±0.00000  bestvalidloss -1241.31862  last_update 5\n",
      "train: iter 236  trainloss -1207.72840  validloss -1097.60614±0.00000  bestvalidloss -1241.31862  last_update 6\n",
      "train: iter 237  trainloss -1049.53756  validloss -1146.11715±0.00000  bestvalidloss -1241.31862  last_update 7\n",
      "train: iter 238  trainloss -1275.55730  validloss -1183.31682±0.00000  bestvalidloss -1241.31862  last_update 8\n",
      "train: iter 239  trainloss -1239.88876  validloss -1237.54218±0.00000  bestvalidloss -1241.31862  last_update 9\n",
      "train: iter 240  trainloss -1186.89634  validloss -1226.88492±0.00000  bestvalidloss -1241.31862  last_update 10\n",
      "train: iter 241  trainloss -1282.75285  validloss -1250.01590±0.00000  bestvalidloss -1250.01590  last_update 0\n",
      "train: iter 242  trainloss -1288.70529  validloss -1218.67441±0.00000  bestvalidloss -1250.01590  last_update 1\n",
      "train: iter 243  trainloss -1251.59728  validloss -1236.70796±0.00000  bestvalidloss -1250.01590  last_update 2\n",
      "train: iter 244  trainloss -1285.67132  validloss -1235.75531±0.00000  bestvalidloss -1250.01590  last_update 3\n",
      "train: iter 245  trainloss -1171.63065  validloss -1156.17580±0.00000  bestvalidloss -1250.01590  last_update 4\n",
      "train: iter 246  trainloss -1263.36659  validloss -1190.26229±0.00000  bestvalidloss -1250.01590  last_update 5\n",
      "train: iter 247  trainloss -1203.98165  validloss -1194.54097±0.00000  bestvalidloss -1250.01590  last_update 6\n",
      "train: iter 248  trainloss -1255.82323  validloss -1078.12081±0.00000  bestvalidloss -1250.01590  last_update 7\n",
      "train: iter 249  trainloss -1268.63579  validloss -1235.48391±0.00000  bestvalidloss -1250.01590  last_update 8\n",
      "train: iter 250  trainloss -1274.83043  validloss -1174.35815±0.00000  bestvalidloss -1250.01590  last_update 9\n",
      "train: iter 251  trainloss -1262.02048  validloss -1241.43322±0.00000  bestvalidloss -1250.01590  last_update 10\n",
      "train: iter 252  trainloss -1219.39557  validloss -1026.58514±0.00000  bestvalidloss -1250.01590  last_update 11\n",
      "train: iter 253  trainloss -1311.02394  validloss -1212.44224±0.00000  bestvalidloss -1250.01590  last_update 12\n",
      "train: iter 254  trainloss -1269.80999  validloss -1303.00768±0.00000  bestvalidloss -1303.00768  last_update 0\n",
      "train: iter 255  trainloss -1283.24927  validloss -1180.01237±0.00000  bestvalidloss -1303.00768  last_update 1\n",
      "train: iter 256  trainloss -934.03170  validloss -1222.65484±0.00000  bestvalidloss -1303.00768  last_update 2\n",
      "train: iter 257  trainloss -1216.08798  validloss -1032.70135±0.00000  bestvalidloss -1303.00768  last_update 3\n",
      "train: iter 258  trainloss -1305.40286  validloss -1213.70241±0.00000  bestvalidloss -1303.00768  last_update 4\n",
      "train: iter 259  trainloss -1173.15179  validloss -1216.35913±0.00000  bestvalidloss -1303.00768  last_update 5\n",
      "train: iter 260  trainloss -1251.00751  validloss -1197.00343±0.00000  bestvalidloss -1303.00768  last_update 6\n",
      "train: iter 261  trainloss -1183.89952  validloss -1199.28767±0.00000  bestvalidloss -1303.00768  last_update 7\n",
      "train: iter 262  trainloss -1138.58692  validloss -1126.00834±0.00000  bestvalidloss -1303.00768  last_update 8\n",
      "train: iter 263  trainloss -1285.60028  validloss -842.53763±0.00000  bestvalidloss -1303.00768  last_update 9\n",
      "train: iter 264  trainloss -1312.03535  validloss -1238.63295±0.00000  bestvalidloss -1303.00768  last_update 10\n",
      "train: iter 265  trainloss -1324.34894  validloss -1244.86105±0.00000  bestvalidloss -1303.00768  last_update 11\n",
      "train: iter 266  trainloss -1352.95656  validloss -1326.27064±0.00000  bestvalidloss -1326.27064  last_update 0\n",
      "train: iter 267  trainloss -1214.01939  validloss -1243.70449±0.00000  bestvalidloss -1326.27064  last_update 1\n",
      "train: iter 268  trainloss -1200.73251  validloss -1083.26094±0.00000  bestvalidloss -1326.27064  last_update 2\n",
      "train: iter 269  trainloss -1272.96342  validloss -1217.60886±0.00000  bestvalidloss -1326.27064  last_update 3\n",
      "train: iter 270  trainloss -1306.68810  validloss -1292.43364±0.00000  bestvalidloss -1326.27064  last_update 4\n",
      "train: iter 271  trainloss -1127.99294  validloss -1280.84118±0.00000  bestvalidloss -1326.27064  last_update 5\n",
      "train: iter 272  trainloss -1313.17505  validloss -1207.93857±0.00000  bestvalidloss -1326.27064  last_update 6\n",
      "train: iter 273  trainloss -1294.89298  validloss -1284.91927±0.00000  bestvalidloss -1326.27064  last_update 7\n",
      "train: iter 274  trainloss -1370.84952  validloss -1319.93836±0.00000  bestvalidloss -1326.27064  last_update 8\n",
      "train: iter 275  trainloss -1347.09665  validloss -1282.33845±0.00000  bestvalidloss -1326.27064  last_update 9\n",
      "train: iter 276  trainloss -1352.57050  validloss -1292.68075±0.00000  bestvalidloss -1326.27064  last_update 10\n",
      "train: iter 277  trainloss -1366.92866  validloss -1341.95234±0.00000  bestvalidloss -1341.95234  last_update 0\n",
      "train: iter 278  trainloss -1069.38141  validloss -1292.34605±0.00000  bestvalidloss -1341.95234  last_update 1\n",
      "train: iter 279  trainloss -1101.82047  validloss -903.68258±0.00000  bestvalidloss -1341.95234  last_update 2\n",
      "train: iter 280  trainloss -1242.34065  validloss -968.69468±0.00000  bestvalidloss -1341.95234  last_update 3\n",
      "train: iter 281  trainloss -1330.31839  validloss -1240.31292±0.00000  bestvalidloss -1341.95234  last_update 4\n",
      "train: iter 282  trainloss -1354.23930  validloss -1299.83230±0.00000  bestvalidloss -1341.95234  last_update 5\n",
      "train: iter 283  trainloss -1329.63319  validloss -1284.00783±0.00000  bestvalidloss -1341.95234  last_update 6\n",
      "train: iter 284  trainloss -1333.45429  validloss -1215.72413±0.00000  bestvalidloss -1341.95234  last_update 7\n",
      "train: iter 285  trainloss -1394.21634  validloss -1336.39949±0.00000  bestvalidloss -1341.95234  last_update 8\n",
      "train: iter 286  trainloss -1213.62692  validloss -1352.94751±0.00000  bestvalidloss -1352.94751  last_update 0\n",
      "train: iter 287  trainloss -1152.84014  validloss -1031.79288±0.00000  bestvalidloss -1352.94751  last_update 1\n",
      "train: iter 288  trainloss -1280.90138  validloss -1259.93766±0.00000  bestvalidloss -1352.94751  last_update 2\n",
      "train: iter 289  trainloss -1378.17792  validloss -1148.82136±0.00000  bestvalidloss -1352.94751  last_update 3\n",
      "train: iter 290  trainloss -1399.29238  validloss -1370.37202±0.00000  bestvalidloss -1370.37202  last_update 0\n",
      "train: iter 291  trainloss -1375.11223  validloss -1388.17607±0.00000  bestvalidloss -1388.17607  last_update 0\n",
      "train: iter 292  trainloss -1320.28403  validloss -1078.75511±0.00000  bestvalidloss -1388.17607  last_update 1\n",
      "train: iter 293  trainloss -1376.94763  validloss -1329.25797±0.00000  bestvalidloss -1388.17607  last_update 2\n",
      "train: iter 294  trainloss -1381.54985  validloss -1369.29285±0.00000  bestvalidloss -1388.17607  last_update 3\n",
      "train: iter 295  trainloss -1373.60526  validloss -1384.41675±0.00000  bestvalidloss -1388.17607  last_update 4\n",
      "train: iter 296  trainloss -1327.49224  validloss -1344.57290±0.00000  bestvalidloss -1388.17607  last_update 5\n",
      "train: iter 297  trainloss -1440.39087  validloss -1316.22016±0.00000  bestvalidloss -1388.17607  last_update 6\n",
      "train: iter 298  trainloss -1297.70935  validloss -1355.57558±0.00000  bestvalidloss -1388.17607  last_update 7\n",
      "train: iter 299  trainloss -1364.48897  validloss -1278.92344±0.00000  bestvalidloss -1388.17607  last_update 8\n",
      "train: iter 300  trainloss -1326.69997  validloss -1312.89720±0.00000  bestvalidloss -1388.17607  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 301  trainloss -1276.61858  validloss -929.02429±0.00000  bestvalidloss -1388.17607  last_update 10\n",
      "train: iter 302  trainloss -1390.89900  validloss -1339.49233±0.00000  bestvalidloss -1388.17607  last_update 11\n",
      "train: iter 303  trainloss -1174.69213  validloss -1226.35614±0.00000  bestvalidloss -1388.17607  last_update 12\n",
      "train: iter 304  trainloss -1387.45459  validloss -1318.47112±0.00000  bestvalidloss -1388.17607  last_update 13\n",
      "train: iter 305  trainloss -1411.38744  validloss -1371.19371±0.00000  bestvalidloss -1388.17607  last_update 14\n",
      "train: iter 306  trainloss -1244.40435  validloss -1390.94641±0.00000  bestvalidloss -1390.94641  last_update 0\n",
      "train: iter 307  trainloss -1307.53243  validloss -1353.02233±0.00000  bestvalidloss -1390.94641  last_update 1\n",
      "train: iter 308  trainloss -1361.70063  validloss -1284.65811±0.00000  bestvalidloss -1390.94641  last_update 2\n",
      "train: iter 309  trainloss -1383.91832  validloss -1361.94177±0.00000  bestvalidloss -1390.94641  last_update 3\n",
      "train: iter 310  trainloss -1242.22861  validloss -1360.10658±0.00000  bestvalidloss -1390.94641  last_update 4\n",
      "train: iter 311  trainloss -1376.07108  validloss -1278.22784±0.00000  bestvalidloss -1390.94641  last_update 5\n",
      "train: iter 312  trainloss -1287.68414  validloss -1312.55544±0.00000  bestvalidloss -1390.94641  last_update 6\n",
      "train: iter 313  trainloss -1254.16167  validloss -1298.98852±0.00000  bestvalidloss -1390.94641  last_update 7\n",
      "train: iter 314  trainloss -1243.56164  validloss -1160.52738±0.00000  bestvalidloss -1390.94641  last_update 8\n",
      "train: iter 315  trainloss -1364.24715  validloss -1213.60315±0.00000  bestvalidloss -1390.94641  last_update 9\n",
      "train: iter 316  trainloss -1438.08074  validloss -1361.87743±0.00000  bestvalidloss -1390.94641  last_update 10\n",
      "train: iter 317  trainloss -1483.35043  validloss -1409.86702±0.00000  bestvalidloss -1409.86702  last_update 0\n",
      "train: iter 318  trainloss -1430.35406  validloss -1431.97701±0.00000  bestvalidloss -1431.97701  last_update 0\n",
      "train: iter 319  trainloss -1241.68470  validloss -1333.22488±0.00000  bestvalidloss -1431.97701  last_update 1\n",
      "train: iter 320  trainloss -1455.31583  validloss -1324.24708±0.00000  bestvalidloss -1431.97701  last_update 2\n",
      "train: iter 321  trainloss -1427.05336  validloss -1359.98399±0.00000  bestvalidloss -1431.97701  last_update 3\n",
      "train: iter 322  trainloss -1413.53831  validloss -1399.47308±0.00000  bestvalidloss -1431.97701  last_update 4\n",
      "train: iter 323  trainloss -1470.87113  validloss -1431.15752±0.00000  bestvalidloss -1431.97701  last_update 5\n",
      "train: iter 324  trainloss -1458.81936  validloss -1452.17251±0.00000  bestvalidloss -1452.17251  last_update 0\n",
      "train: iter 325  trainloss -1376.81169  validloss -1409.85956±0.00000  bestvalidloss -1452.17251  last_update 1\n",
      "train: iter 326  trainloss -1445.40237  validloss -1331.80658±0.00000  bestvalidloss -1452.17251  last_update 2\n",
      "train: iter 327  trainloss -1500.66500  validloss -1328.73416±0.00000  bestvalidloss -1452.17251  last_update 3\n",
      "train: iter 328  trainloss -1178.26167  validloss -1410.86664±0.00000  bestvalidloss -1452.17251  last_update 4\n",
      "train: iter 329  trainloss -1262.40156  validloss -1225.76666±0.00000  bestvalidloss -1452.17251  last_update 5\n",
      "train: iter 330  trainloss -1384.75565  validloss -1269.53375±0.00000  bestvalidloss -1452.17251  last_update 6\n",
      "train: iter 331  trainloss -1444.88699  validloss -1400.94040±0.00000  bestvalidloss -1452.17251  last_update 7\n",
      "train: iter 332  trainloss -1449.46963  validloss -1423.96143±0.00000  bestvalidloss -1452.17251  last_update 8\n",
      "train: iter 333  trainloss -1407.13410  validloss -1328.89640±0.00000  bestvalidloss -1452.17251  last_update 9\n",
      "train: iter 334  trainloss -1444.23695  validloss -1241.26125±0.00000  bestvalidloss -1452.17251  last_update 10\n",
      "train: iter 335  trainloss -1477.94191  validloss -1430.08936±0.00000  bestvalidloss -1452.17251  last_update 11\n",
      "train: iter 336  trainloss -1352.09821  validloss -1388.69508±0.00000  bestvalidloss -1452.17251  last_update 12\n",
      "train: iter 337  trainloss -1473.20325  validloss -1399.68398±0.00000  bestvalidloss -1452.17251  last_update 13\n",
      "train: iter 338  trainloss -1497.14478  validloss -1404.35939±0.00000  bestvalidloss -1452.17251  last_update 14\n",
      "train: iter 339  trainloss -1291.48344  validloss -1396.86628±0.00000  bestvalidloss -1452.17251  last_update 15\n",
      "train: iter 340  trainloss -1471.95150  validloss -1332.77513±0.00000  bestvalidloss -1452.17251  last_update 16\n",
      "train: iter 341  trainloss -1505.39561  validloss -1467.77122±0.00000  bestvalidloss -1467.77122  last_update 0\n",
      "train: iter 342  trainloss -1387.86164  validloss -1378.63813±0.00000  bestvalidloss -1467.77122  last_update 1\n",
      "train: iter 343  trainloss -1399.04061  validloss -1429.04449±0.00000  bestvalidloss -1467.77122  last_update 2\n",
      "train: iter 344  trainloss -1435.50950  validloss -1378.67377±0.00000  bestvalidloss -1467.77122  last_update 3\n",
      "train: iter 345  trainloss -1454.30968  validloss -1459.75985±0.00000  bestvalidloss -1467.77122  last_update 4\n",
      "train: iter 346  trainloss -1467.84513  validloss -1448.33141±0.00000  bestvalidloss -1467.77122  last_update 5\n",
      "train: iter 347  trainloss -1190.20875  validloss -1325.14427±0.00000  bestvalidloss -1467.77122  last_update 6\n",
      "train: iter 348  trainloss -1429.07185  validloss -1293.66249±0.00000  bestvalidloss -1467.77122  last_update 7\n",
      "train: iter 349  trainloss -1367.55789  validloss -1392.98846±0.00000  bestvalidloss -1467.77122  last_update 8\n",
      "train: iter 350  trainloss -1460.84613  validloss -1348.03037±0.00000  bestvalidloss -1467.77122  last_update 9\n",
      "train: iter 351  trainloss -1403.92253  validloss -1303.84350±0.00000  bestvalidloss -1467.77122  last_update 10\n",
      "train: iter 352  trainloss -1493.23647  validloss -1396.71251±0.00000  bestvalidloss -1467.77122  last_update 11\n",
      "train: iter 353  trainloss -1536.06650  validloss -1488.76362±0.00000  bestvalidloss -1488.76362  last_update 0\n",
      "train: iter 354  trainloss -1321.31314  validloss -1430.29366±0.00000  bestvalidloss -1488.76362  last_update 1\n",
      "train: iter 355  trainloss -1484.46864  validloss -1381.72743±0.00000  bestvalidloss -1488.76362  last_update 2\n",
      "train: iter 356  trainloss -1517.70472  validloss -1439.02710±0.00000  bestvalidloss -1488.76362  last_update 3\n",
      "train: iter 357  trainloss -1521.80019  validloss -1446.79843±0.00000  bestvalidloss -1488.76362  last_update 4\n",
      "train: iter 358  trainloss -1225.20708  validloss -1409.73431±0.00000  bestvalidloss -1488.76362  last_update 5\n",
      "train: iter 359  trainloss -1416.03795  validloss -1389.68825±0.00000  bestvalidloss -1488.76362  last_update 6\n",
      "train: iter 360  trainloss -1346.53341  validloss -1044.10616±0.00000  bestvalidloss -1488.76362  last_update 7\n",
      "train: iter 361  trainloss -1558.06911  validloss -1483.53563±0.00000  bestvalidloss -1488.76362  last_update 8\n",
      "train: iter 362  trainloss -1436.04293  validloss -1468.35616±0.00000  bestvalidloss -1488.76362  last_update 9\n",
      "train: iter 363  trainloss -1478.30941  validloss -1435.53754±0.00000  bestvalidloss -1488.76362  last_update 10\n",
      "train: iter 364  trainloss -1544.48803  validloss -1430.70757±0.00000  bestvalidloss -1488.76362  last_update 11\n",
      "train: iter 365  trainloss -1526.91519  validloss -1508.26104±0.00000  bestvalidloss -1508.26104  last_update 0\n",
      "train: iter 366  trainloss -1511.63859  validloss -1432.42484±0.00000  bestvalidloss -1508.26104  last_update 1\n",
      "train: iter 367  trainloss -1472.97042  validloss -1487.86841±0.00000  bestvalidloss -1508.26104  last_update 2\n",
      "train: iter 368  trainloss -1450.27523  validloss -1392.71998±0.00000  bestvalidloss -1508.26104  last_update 3\n",
      "train: iter 369  trainloss -1286.55992  validloss -1463.41642±0.00000  bestvalidloss -1508.26104  last_update 4\n",
      "train: iter 370  trainloss -1410.51030  validloss -1192.31591±0.00000  bestvalidloss -1508.26104  last_update 5\n",
      "train: iter 371  trainloss -1436.45470  validloss -1260.27419±0.00000  bestvalidloss -1508.26104  last_update 6\n",
      "train: iter 372  trainloss -1513.96081  validloss -1405.85000±0.00000  bestvalidloss -1508.26104  last_update 7\n",
      "train: iter 373  trainloss -1260.95763  validloss -1406.06904±0.00000  bestvalidloss -1508.26104  last_update 8\n",
      "train: iter 374  trainloss -1386.71339  validloss -1126.91594±0.00000  bestvalidloss -1508.26104  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 375  trainloss -1535.11624  validloss -1442.41621±0.00000  bestvalidloss -1508.26104  last_update 10\n",
      "train: iter 376  trainloss -1525.26035  validloss -1469.18745±0.00000  bestvalidloss -1508.26104  last_update 11\n",
      "train: iter 377  trainloss -1416.06228  validloss -1520.48298±0.00000  bestvalidloss -1520.48298  last_update 0\n",
      "train: iter 378  trainloss -1458.81197  validloss -1347.67050±0.00000  bestvalidloss -1520.48298  last_update 1\n",
      "train: iter 379  trainloss -1390.14422  validloss -1474.41425±0.00000  bestvalidloss -1520.48298  last_update 2\n",
      "train: iter 380  trainloss -1513.74353  validloss -1463.43217±0.00000  bestvalidloss -1520.48298  last_update 3\n",
      "train: iter 381  trainloss -1525.74631  validloss -1504.98348±0.00000  bestvalidloss -1520.48298  last_update 4\n",
      "train: iter 382  trainloss -1536.55518  validloss -1484.40366±0.00000  bestvalidloss -1520.48298  last_update 5\n",
      "train: iter 383  trainloss -1355.77686  validloss -1347.68488±0.00000  bestvalidloss -1520.48298  last_update 6\n",
      "train: iter 384  trainloss -1492.41089  validloss -1398.32019±0.00000  bestvalidloss -1520.48298  last_update 7\n",
      "train: iter 385  trainloss -1538.53041  validloss -1508.55985±0.00000  bestvalidloss -1520.48298  last_update 8\n",
      "train: iter 386  trainloss -875.86266  validloss -1056.48291±0.00000  bestvalidloss -1520.48298  last_update 9\n",
      "train: iter 387  trainloss -1447.11107  validloss -1300.72347±0.00000  bestvalidloss -1520.48298  last_update 10\n",
      "train: iter 388  trainloss -1506.03003  validloss -1452.84232±0.00000  bestvalidloss -1520.48298  last_update 11\n",
      "train: iter 389  trainloss -1550.18114  validloss -1469.35275±0.00000  bestvalidloss -1520.48298  last_update 12\n",
      "train: iter 390  trainloss -1520.55605  validloss -1493.54937±0.00000  bestvalidloss -1520.48298  last_update 13\n",
      "train: iter 391  trainloss -1487.30159  validloss -1424.08804±0.00000  bestvalidloss -1520.48298  last_update 14\n",
      "train: iter 392  trainloss -1442.00903  validloss -1348.49146±0.00000  bestvalidloss -1520.48298  last_update 15\n",
      "train: iter 393  trainloss -1523.48755  validloss -1479.93154±0.00000  bestvalidloss -1520.48298  last_update 16\n",
      "train: iter 394  trainloss -1441.86537  validloss -1414.14227±0.00000  bestvalidloss -1520.48298  last_update 17\n",
      "train: iter 395  trainloss -1480.66761  validloss -1498.52134±0.00000  bestvalidloss -1520.48298  last_update 18\n",
      "train: iter 396  trainloss -1433.40123  validloss -1383.26376±0.00000  bestvalidloss -1520.48298  last_update 19\n",
      "train: iter 397  trainloss -1473.62054  validloss -1454.15231±0.00000  bestvalidloss -1520.48298  last_update 20\n",
      "train: iter 398  trainloss -1541.49695  validloss -1503.37082±0.00000  bestvalidloss -1520.48298  last_update 21\n",
      "train: iter 399  trainloss -1549.52690  validloss -1469.90194±0.00000  bestvalidloss -1520.48298  last_update 22\n",
      "train: iter 400  trainloss -1382.29211  validloss -1222.53915±0.00000  bestvalidloss -1520.48298  last_update 23\n",
      "train: iter 401  trainloss -1525.10412  validloss -1389.26179±0.00000  bestvalidloss -1520.48298  last_update 24\n",
      "train: iter 402  trainloss -1534.06739  validloss -1513.65218±0.00000  bestvalidloss -1520.48298  last_update 25\n",
      "train: iter 403  trainloss -1487.66149  validloss -1495.69025±0.00000  bestvalidloss -1520.48298  last_update 26\n",
      "train: iter 404  trainloss -1514.70660  validloss -1240.13304±0.00000  bestvalidloss -1520.48298  last_update 27\n",
      "train: iter 405  trainloss -1498.90237  validloss -1472.45676±0.00000  bestvalidloss -1520.48298  last_update 28\n",
      "train: iter 406  trainloss -1506.02269  validloss -1526.62117±0.00000  bestvalidloss -1526.62117  last_update 0\n",
      "train: iter 407  trainloss -1538.68416  validloss -1489.79193±0.00000  bestvalidloss -1526.62117  last_update 1\n",
      "train: iter 408  trainloss -1483.56764  validloss -1503.14339±0.00000  bestvalidloss -1526.62117  last_update 2\n",
      "train: iter 409  trainloss -1565.76644  validloss -1491.85058±0.00000  bestvalidloss -1526.62117  last_update 3\n",
      "train: iter 410  trainloss -1572.87311  validloss -1522.42095±0.00000  bestvalidloss -1526.62117  last_update 4\n",
      "train: iter 411  trainloss -1505.34250  validloss -1523.18450±0.00000  bestvalidloss -1526.62117  last_update 5\n",
      "train: iter 412  trainloss -1504.11801  validloss -1338.84486±0.00000  bestvalidloss -1526.62117  last_update 6\n",
      "train: iter 413  trainloss -1481.36835  validloss -1543.76076±0.00000  bestvalidloss -1543.76076  last_update 0\n",
      "train: iter 414  trainloss -1464.95726  validloss -1470.61943±0.00000  bestvalidloss -1543.76076  last_update 1\n",
      "train: iter 415  trainloss -1522.06055  validloss -1493.86694±0.00000  bestvalidloss -1543.76076  last_update 2\n",
      "train: iter 416  trainloss -1529.18886  validloss -1491.21709±0.00000  bestvalidloss -1543.76076  last_update 3\n",
      "train: iter 417  trainloss -1594.58697  validloss -1537.28735±0.00000  bestvalidloss -1543.76076  last_update 4\n",
      "train: iter 418  trainloss -1447.51899  validloss -1546.14307±0.00000  bestvalidloss -1546.14307  last_update 0\n",
      "train: iter 419  trainloss -1534.63589  validloss -1398.75676±0.00000  bestvalidloss -1546.14307  last_update 1\n",
      "train: iter 420  trainloss -1450.70500  validloss -1538.04840±0.00000  bestvalidloss -1546.14307  last_update 2\n",
      "train: iter 421  trainloss -1543.19722  validloss -1431.06451±0.00000  bestvalidloss -1546.14307  last_update 3\n",
      "train: iter 422  trainloss -1487.61374  validloss -1521.02277±0.00000  bestvalidloss -1546.14307  last_update 4\n",
      "train: iter 423  trainloss -1484.70315  validloss -1424.47904±0.00000  bestvalidloss -1546.14307  last_update 5\n",
      "train: iter 424  trainloss -1577.67032  validloss -1473.76705±0.00000  bestvalidloss -1546.14307  last_update 6\n",
      "train: iter 425  trainloss -1606.90017  validloss -1535.10571±0.00000  bestvalidloss -1546.14307  last_update 7\n",
      "train: iter 426  trainloss -1014.15250  validloss -1542.05493±0.00000  bestvalidloss -1546.14307  last_update 8\n",
      "train: iter 427  trainloss -1263.25542  validloss -1104.68660±0.00000  bestvalidloss -1546.14307  last_update 9\n",
      "train: iter 428  trainloss -1397.56123  validloss -1203.46049±0.00000  bestvalidloss -1546.14307  last_update 10\n",
      "train: iter 429  trainloss -1529.47868  validloss -1402.84352±0.00000  bestvalidloss -1546.14307  last_update 11\n",
      "train: iter 430  trainloss -1540.18262  validloss -1483.79348±0.00000  bestvalidloss -1546.14307  last_update 12\n",
      "train: iter 431  trainloss -1539.67439  validloss -1481.73718±0.00000  bestvalidloss -1546.14307  last_update 13\n",
      "train: iter 432  trainloss -1536.00021  validloss -1507.73064±0.00000  bestvalidloss -1546.14307  last_update 14\n",
      "train: iter 433  trainloss -1491.76021  validloss -1468.60754±0.00000  bestvalidloss -1546.14307  last_update 15\n",
      "train: iter 434  trainloss -1547.67678  validloss -1427.61611±0.00000  bestvalidloss -1546.14307  last_update 16\n",
      "train: iter 435  trainloss -1459.52284  validloss -1487.63973±0.00000  bestvalidloss -1546.14307  last_update 17\n",
      "train: iter 436  trainloss -1544.81366  validloss -1523.78528±0.00000  bestvalidloss -1546.14307  last_update 18\n",
      "train: iter 437  trainloss -1581.58779  validloss -1526.54195±0.00000  bestvalidloss -1546.14307  last_update 19\n",
      "train: iter 438  trainloss -1552.94644  validloss -1543.41978±0.00000  bestvalidloss -1546.14307  last_update 20\n",
      "train: iter 439  trainloss -1436.98305  validloss -1436.97880±0.00000  bestvalidloss -1546.14307  last_update 21\n",
      "train: iter 440  trainloss -1516.04109  validloss -1524.60978±0.00000  bestvalidloss -1546.14307  last_update 22\n",
      "train: iter 441  trainloss -1484.56864  validloss -1436.89269±0.00000  bestvalidloss -1546.14307  last_update 23\n",
      "train: iter 442  trainloss -1516.54120  validloss -1500.71353±0.00000  bestvalidloss -1546.14307  last_update 24\n",
      "train: iter 443  trainloss -1565.06636  validloss -1457.82890±0.00000  bestvalidloss -1546.14307  last_update 25\n",
      "train: iter 444  trainloss -1514.19401  validloss -1504.04674±0.00000  bestvalidloss -1546.14307  last_update 26\n",
      "train: iter 445  trainloss -1467.96485  validloss -1510.66232±0.00000  bestvalidloss -1546.14307  last_update 27\n",
      "train: iter 446  trainloss -1548.42755  validloss -1451.71565±0.00000  bestvalidloss -1546.14307  last_update 28\n",
      "train: iter 447  trainloss -1558.62909  validloss -1468.48278±0.00000  bestvalidloss -1546.14307  last_update 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 448  trainloss -1584.38944  validloss -1508.67223±0.00000  bestvalidloss -1546.14307  last_update 30\n",
      "train: iter 449  trainloss -1384.02169  validloss -1478.95190±0.00000  bestvalidloss -1546.14307  last_update 31\n",
      "train: iter 450  trainloss -1516.01860  validloss -1297.72803±0.00000  bestvalidloss -1546.14307  last_update 32\n",
      "train: iter 451  trainloss -1609.99011  validloss -1558.81552±0.00000  bestvalidloss -1558.81552  last_update 0\n",
      "train: iter 452  trainloss -1634.50649  validloss -1581.73737±0.00000  bestvalidloss -1581.73737  last_update 0\n",
      "train: iter 453  trainloss -1165.00519  validloss -1365.38703±0.00000  bestvalidloss -1581.73737  last_update 1\n",
      "train: iter 454  trainloss -1137.53953  validloss -1384.69094±0.00000  bestvalidloss -1581.73737  last_update 2\n",
      "train: iter 455  trainloss -1198.44268  validloss -868.92381±0.00000  bestvalidloss -1581.73737  last_update 3\n",
      "train: iter 456  trainloss -1375.14048  validloss -1300.19933±0.00000  bestvalidloss -1581.73737  last_update 4\n",
      "train: iter 457  trainloss -1471.23514  validloss -1393.79107±0.00000  bestvalidloss -1581.73737  last_update 5\n",
      "train: iter 458  trainloss -1528.43276  validloss -1463.81905±0.00000  bestvalidloss -1581.73737  last_update 6\n",
      "train: iter 459  trainloss -1244.70676  validloss -1401.98357±0.00000  bestvalidloss -1581.73737  last_update 7\n",
      "train: iter 460  trainloss -1477.21693  validloss -1228.99374±0.00000  bestvalidloss -1581.73737  last_update 8\n",
      "train: iter 461  trainloss -1524.85136  validloss -1465.37734±0.00000  bestvalidloss -1581.73737  last_update 9\n",
      "train: iter 462  trainloss -1493.93929  validloss -1422.58392±0.00000  bestvalidloss -1581.73737  last_update 10\n",
      "train: iter 463  trainloss -1568.36157  validloss -1505.87570±0.00000  bestvalidloss -1581.73737  last_update 11\n",
      "train: iter 464  trainloss -1520.28595  validloss -1521.03013±0.00000  bestvalidloss -1581.73737  last_update 12\n",
      "train: iter 465  trainloss -1548.81497  validloss -1469.60470±0.00000  bestvalidloss -1581.73737  last_update 13\n",
      "train: iter 466  trainloss -1569.63232  validloss -1543.07149±0.00000  bestvalidloss -1581.73737  last_update 14\n",
      "train: iter 467  trainloss -1592.19011  validloss -1478.78398±0.00000  bestvalidloss -1581.73737  last_update 15\n",
      "train: iter 468  trainloss -1602.70172  validloss -1553.99332±0.00000  bestvalidloss -1581.73737  last_update 16\n",
      "train: iter 469  trainloss -1440.53301  validloss -1407.66327±0.00000  bestvalidloss -1581.73737  last_update 17\n",
      "train: iter 470  trainloss -1564.51575  validloss -1392.76725±0.00000  bestvalidloss -1581.73737  last_update 18\n",
      "train: iter 471  trainloss -1597.19677  validloss -1541.05608±0.00000  bestvalidloss -1581.73737  last_update 19\n",
      "train: iter 472  trainloss -1555.94788  validloss -1560.45687±0.00000  bestvalidloss -1581.73737  last_update 20\n",
      "train: iter 473  trainloss -1372.97564  validloss -1382.49037±0.00000  bestvalidloss -1581.73737  last_update 21\n",
      "train: iter 474  trainloss -1581.71331  validloss -1497.54552±0.00000  bestvalidloss -1581.73737  last_update 22\n",
      "train: iter 475  trainloss -1587.42609  validloss -1555.10786±0.00000  bestvalidloss -1581.73737  last_update 23\n",
      "train: iter 476  trainloss -1589.43042  validloss -1559.13589±0.00000  bestvalidloss -1581.73737  last_update 24\n",
      "train: iter 477  trainloss -1588.04996  validloss -1476.19849±0.00000  bestvalidloss -1581.73737  last_update 25\n",
      "train: iter 478  trainloss -1464.19723  validloss -1559.55071±0.00000  bestvalidloss -1581.73737  last_update 26\n",
      "train: iter 479  trainloss -1618.39216  validloss -1553.02383±0.00000  bestvalidloss -1581.73737  last_update 27\n",
      "train: iter 480  trainloss -1520.63682  validloss -1545.27981±0.00000  bestvalidloss -1581.73737  last_update 28\n",
      "train: iter 481  trainloss -1562.05624  validloss -1432.40338±0.00000  bestvalidloss -1581.73737  last_update 29\n",
      "train: iter 482  trainloss -1423.90247  validloss -1573.32592±0.00000  bestvalidloss -1581.73737  last_update 30\n",
      "train: iter 483  trainloss -1508.77107  validloss -1465.85255±0.00000  bestvalidloss -1581.73737  last_update 31\n",
      "train: iter 484  trainloss -1582.36616  validloss -1487.38318±0.00000  bestvalidloss -1581.73737  last_update 32\n",
      "train: iter 485  trainloss -1544.73044  validloss -1536.26351±0.00000  bestvalidloss -1581.73737  last_update 33\n",
      "train: iter 486  trainloss -1384.26637  validloss -1461.01037±0.00000  bestvalidloss -1581.73737  last_update 34\n",
      "train: iter 487  trainloss -1507.73399  validloss -1426.91156±0.00000  bestvalidloss -1581.73737  last_update 35\n",
      "train: iter 488  trainloss -1475.79245  validloss -1505.36721±0.00000  bestvalidloss -1581.73737  last_update 36\n",
      "train: iter 489  trainloss -1459.43824  validloss -1409.17897±0.00000  bestvalidloss -1581.73737  last_update 37\n",
      "train: iter 490  trainloss -1522.15569  validloss -1359.85881±0.00000  bestvalidloss -1581.73737  last_update 38\n",
      "train: iter 491  trainloss -1587.44347  validloss -1501.17455±0.00000  bestvalidloss -1581.73737  last_update 39\n",
      "train: iter 492  trainloss -1566.85521  validloss -1482.12834±0.00000  bestvalidloss -1581.73737  last_update 40\n",
      "train: iter 493  trainloss -1571.37268  validloss -1546.96361±0.00000  bestvalidloss -1581.73737  last_update 41\n",
      "train: iter 494  trainloss -1573.68007  validloss -1427.28279±0.00000  bestvalidloss -1581.73737  last_update 42\n",
      "train: iter 495  trainloss -1564.30403  validloss -1561.02097±0.00000  bestvalidloss -1581.73737  last_update 43\n",
      "train: iter 496  trainloss -1509.56578  validloss -1443.42818±0.00000  bestvalidloss -1581.73737  last_update 44\n",
      "train: iter 497  trainloss -1537.99748  validloss -1507.01733±0.00000  bestvalidloss -1581.73737  last_update 45\n",
      "train: iter 498  trainloss -1566.27443  validloss -1474.96308±0.00000  bestvalidloss -1581.73737  last_update 46\n",
      "train: iter 499  trainloss -1615.41515  validloss -1500.56062±0.00000  bestvalidloss -1581.73737  last_update 47\n",
      "train: iter 500  trainloss -1608.85338  validloss -1574.68634±0.00000  bestvalidloss -1581.73737  last_update 48\n",
      "train: iter 501  trainloss -1298.03198  validloss -1531.37105±0.00000  bestvalidloss -1581.73737  last_update 49\n",
      "train: iter 502  trainloss -1537.89485  validloss -1389.45880±0.00000  bestvalidloss -1581.73737  last_update 50\n",
      "train: iter 503  trainloss -1568.39432  validloss -1521.41646±0.00000  bestvalidloss -1581.73737  last_update 51\n",
      "train: iter 504  trainloss -1555.30283  validloss -1531.48305±0.00000  bestvalidloss -1581.73737  last_update 52\n",
      "train: iter 505  trainloss -1635.85439  validloss -1568.15547±0.00000  bestvalidloss -1581.73737  last_update 53\n",
      "train: iter 506  trainloss -1508.99651  validloss -1534.42077±0.00000  bestvalidloss -1581.73737  last_update 54\n",
      "train: iter 507  trainloss -1516.78521  validloss -1335.33361±0.00000  bestvalidloss -1581.73737  last_update 55\n",
      "train: iter 508  trainloss -1630.26158  validloss -1562.93665±0.00000  bestvalidloss -1581.73737  last_update 56\n",
      "train: iter 509  trainloss -1627.24392  validloss -1550.81270±0.00000  bestvalidloss -1581.73737  last_update 57\n",
      "train: iter 510  trainloss -1506.62178  validloss -1544.83896±0.00000  bestvalidloss -1581.73737  last_update 58\n",
      "train: iter 511  trainloss -1529.19305  validloss -1438.39660±0.00000  bestvalidloss -1581.73737  last_update 59\n",
      "train: iter 512  trainloss -1608.35459  validloss -1563.74466±0.00000  bestvalidloss -1581.73737  last_update 60\n",
      "train: iter 513  trainloss -1510.08918  validloss -1480.94943±0.00000  bestvalidloss -1581.73737  last_update 61\n",
      "train: iter 514  trainloss -1573.76869  validloss -1357.61670±0.00000  bestvalidloss -1581.73737  last_update 62\n",
      "train: iter 515  trainloss -1565.37956  validloss -1566.84592±0.00000  bestvalidloss -1581.73737  last_update 63\n",
      "train: iter 516  trainloss -1609.46977  validloss -1546.70092±0.00000  bestvalidloss -1581.73737  last_update 64\n",
      "train: iter 517  trainloss -1385.97110  validloss -1465.77788±0.00000  bestvalidloss -1581.73737  last_update 65\n",
      "train: iter 518  trainloss -1411.20505  validloss -1516.14958±0.00000  bestvalidloss -1581.73737  last_update 66\n",
      "train: iter 519  trainloss -1522.68409  validloss -1424.04955±0.00000  bestvalidloss -1581.73737  last_update 67\n",
      "train: iter 520  trainloss -1593.82895  validloss -1490.56182±0.00000  bestvalidloss -1581.73737  last_update 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 521  trainloss -1603.39745  validloss -1307.32456±0.00000  bestvalidloss -1581.73737  last_update 69\n",
      "train: iter 522  trainloss -1609.32806  validloss -1558.77585±0.00000  bestvalidloss -1581.73737  last_update 70\n",
      "train: iter 523  trainloss -1570.50996  validloss -1441.19163±0.00000  bestvalidloss -1581.73737  last_update 71\n",
      "train: iter 524  trainloss -1532.94949  validloss -1536.15614±0.00000  bestvalidloss -1581.73737  last_update 72\n",
      "train: iter 525  trainloss -1501.29975  validloss -1518.30818±0.00000  bestvalidloss -1581.73737  last_update 73\n",
      "train: iter 526  trainloss -1555.46399  validloss -1333.95991±0.00000  bestvalidloss -1581.73737  last_update 74\n",
      "train: iter 527  trainloss -1639.70131  validloss -1538.74412±0.00000  bestvalidloss -1581.73737  last_update 75\n",
      "train: iter 528  trainloss -1595.35965  validloss -1570.06972±0.00000  bestvalidloss -1581.73737  last_update 76\n",
      "train: iter 529  trainloss -1437.96778  validloss -1567.77242±0.00000  bestvalidloss -1581.73737  last_update 77\n",
      "train: iter 530  trainloss -1616.42636  validloss -1392.93255±0.00000  bestvalidloss -1581.73737  last_update 78\n",
      "train: iter 531  trainloss -1468.79100  validloss -1566.67436±0.00000  bestvalidloss -1581.73737  last_update 79\n",
      "train: iter 532  trainloss -1299.11077  validloss -1436.58426±0.00000  bestvalidloss -1581.73737  last_update 80\n",
      "train: iter 533  trainloss -1516.24275  validloss -1409.18564±0.00000  bestvalidloss -1581.73737  last_update 81\n",
      "train: iter 534  trainloss -1588.53248  validloss -1521.81316±0.00000  bestvalidloss -1581.73737  last_update 82\n",
      "train: iter 535  trainloss -1596.47639  validloss -1549.23862±0.00000  bestvalidloss -1581.73737  last_update 83\n",
      "train: iter 536  trainloss -1541.40265  validloss -1560.74358±0.00000  bestvalidloss -1581.73737  last_update 84\n",
      "train: iter 537  trainloss -1609.80980  validloss -1588.33731±0.00000  bestvalidloss -1588.33731  last_update 0\n",
      "train: iter 538  trainloss -1580.20049  validloss -1531.57144±0.00000  bestvalidloss -1588.33731  last_update 1\n",
      "train: iter 539  trainloss -1612.54649  validloss -1560.97508±0.00000  bestvalidloss -1588.33731  last_update 2\n",
      "train: iter 540  trainloss -1600.17476  validloss -1544.97359±0.00000  bestvalidloss -1588.33731  last_update 3\n",
      "train: iter 541  trainloss -1533.37935  validloss -1496.96026±0.00000  bestvalidloss -1588.33731  last_update 4\n",
      "train: iter 542  trainloss -1621.80059  validloss -1559.63259±0.00000  bestvalidloss -1588.33731  last_update 5\n",
      "train: iter 543  trainloss -1631.38024  validloss -1577.04961±0.00000  bestvalidloss -1588.33731  last_update 6\n",
      "train: iter 544  trainloss -1553.19600  validloss -1468.26773±0.00000  bestvalidloss -1588.33731  last_update 7\n",
      "train: iter 545  trainloss -1629.31699  validloss -1536.71160±0.00000  bestvalidloss -1588.33731  last_update 8\n",
      "train: iter 546  trainloss -1609.42402  validloss -1580.67568±0.00000  bestvalidloss -1588.33731  last_update 9\n",
      "train: iter 547  trainloss -1452.96626  validloss -1500.14987±0.00000  bestvalidloss -1588.33731  last_update 10\n",
      "train: iter 548  trainloss -1532.68653  validloss -1374.65118±0.00000  bestvalidloss -1588.33731  last_update 11\n",
      "train: iter 549  trainloss -1606.03828  validloss -1535.11856±0.00000  bestvalidloss -1588.33731  last_update 12\n",
      "train: iter 550  trainloss -1504.97528  validloss -1560.71461±0.00000  bestvalidloss -1588.33731  last_update 13\n",
      "train: iter 551  trainloss -1445.98145  validloss -963.45073±0.00000  bestvalidloss -1588.33731  last_update 14\n",
      "train: iter 552  trainloss -1591.95860  validloss -1525.96007±0.00000  bestvalidloss -1588.33731  last_update 15\n",
      "train: iter 553  trainloss -1629.81099  validloss -1568.27909±0.00000  bestvalidloss -1588.33731  last_update 16\n",
      "train: iter 554  trainloss -1633.48922  validloss -1599.02084±0.00000  bestvalidloss -1599.02084  last_update 0\n",
      "train: iter 555  trainloss -1630.81920  validloss -1552.96431±0.00000  bestvalidloss -1599.02084  last_update 1\n",
      "train: iter 556  trainloss -1594.90725  validloss -1595.51358±0.00000  bestvalidloss -1599.02084  last_update 2\n",
      "train: iter 557  trainloss -1664.06663  validloss -1534.00526±0.00000  bestvalidloss -1599.02084  last_update 3\n",
      "train: iter 558  trainloss -1602.20065  validloss -1577.47206±0.00000  bestvalidloss -1599.02084  last_update 4\n",
      "train: iter 559  trainloss -1605.41979  validloss -1491.68572±0.00000  bestvalidloss -1599.02084  last_update 5\n",
      "train: iter 560  trainloss -1606.25985  validloss -1596.28307±0.00000  bestvalidloss -1599.02084  last_update 6\n",
      "train: iter 561  trainloss -1633.85213  validloss -1490.95046±0.00000  bestvalidloss -1599.02084  last_update 7\n",
      "train: iter 562  trainloss -1618.65650  validloss -1596.49422±0.00000  bestvalidloss -1599.02084  last_update 8\n",
      "train: iter 563  trainloss -1506.40974  validloss -1485.90674±0.00000  bestvalidloss -1599.02084  last_update 9\n",
      "train: iter 564  trainloss -1492.45966  validloss -1535.34740±0.00000  bestvalidloss -1599.02084  last_update 10\n",
      "train: iter 565  trainloss -1508.86374  validloss -1124.70815±0.00000  bestvalidloss -1599.02084  last_update 11\n",
      "train: iter 566  trainloss -1648.99402  validloss -1580.30193±0.00000  bestvalidloss -1599.02084  last_update 12\n",
      "train: iter 567  trainloss -1532.77932  validloss -1550.48582±0.00000  bestvalidloss -1599.02084  last_update 13\n",
      "train: iter 568  trainloss -1601.63897  validloss -1505.14967±0.00000  bestvalidloss -1599.02084  last_update 14\n",
      "train: iter 569  trainloss -1626.27466  validloss -1554.31055±0.00000  bestvalidloss -1599.02084  last_update 15\n",
      "train: iter 570  trainloss -1326.36679  validloss -1588.69924±0.00000  bestvalidloss -1599.02084  last_update 16\n",
      "train: iter 571  trainloss -1491.15113  validloss -1331.09065±0.00000  bestvalidloss -1599.02084  last_update 17\n",
      "train: iter 572  trainloss -1592.59111  validloss -1526.59754±0.00000  bestvalidloss -1599.02084  last_update 18\n",
      "train: iter 573  trainloss -1619.12934  validloss -1539.87283±0.00000  bestvalidloss -1599.02084  last_update 19\n",
      "train: iter 574  trainloss -1607.52050  validloss -1587.74261±0.00000  bestvalidloss -1599.02084  last_update 20\n",
      "train: iter 575  trainloss -1600.50844  validloss -1310.00616±0.00000  bestvalidloss -1599.02084  last_update 21\n",
      "train: iter 576  trainloss -1634.95747  validloss -1537.14358±0.00000  bestvalidloss -1599.02084  last_update 22\n",
      "train: iter 577  trainloss -1571.17245  validloss -1608.05811±0.00000  bestvalidloss -1608.05811  last_update 0\n",
      "train: iter 578  trainloss -1575.16694  validloss -1425.29854±0.00000  bestvalidloss -1608.05811  last_update 1\n",
      "train: iter 579  trainloss -1588.84719  validloss -1486.33081±0.00000  bestvalidloss -1608.05811  last_update 2\n",
      "train: iter 580  trainloss -1625.82134  validloss -1589.91572±0.00000  bestvalidloss -1608.05811  last_update 3\n",
      "train: iter 581  trainloss -1428.19270  validloss -1604.99919±0.00000  bestvalidloss -1608.05811  last_update 4\n",
      "train: iter 582  trainloss -1535.26152  validloss -1425.34096±0.00000  bestvalidloss -1608.05811  last_update 5\n",
      "train: iter 583  trainloss -1611.90946  validloss -1441.91311±0.00000  bestvalidloss -1608.05811  last_update 6\n",
      "train: iter 584  trainloss -1587.48921  validloss -1585.52545±0.00000  bestvalidloss -1608.05811  last_update 7\n",
      "train: iter 585  trainloss -1669.88254  validloss -1597.76823±0.00000  bestvalidloss -1608.05811  last_update 8\n",
      "train: iter 586  trainloss -1524.39457  validloss -1581.47878±0.00000  bestvalidloss -1608.05811  last_update 9\n",
      "train: iter 587  trainloss -1628.00369  validloss -1501.92143±0.00000  bestvalidloss -1608.05811  last_update 10\n",
      "train: iter 588  trainloss -1347.08745  validloss -1493.98451±0.00000  bestvalidloss -1608.05811  last_update 11\n",
      "train: iter 589  trainloss -1435.33085  validloss -967.16444±0.00000  bestvalidloss -1608.05811  last_update 12\n",
      "train: iter 590  trainloss -1581.83218  validloss -1471.00662±0.00000  bestvalidloss -1608.05811  last_update 13\n",
      "train: iter 591  trainloss -1620.37671  validloss -1544.79910±0.00000  bestvalidloss -1608.05811  last_update 14\n",
      "train: iter 592  trainloss -1581.82740  validloss -1482.68223±0.00000  bestvalidloss -1608.05811  last_update 15\n",
      "train: iter 593  trainloss -1628.14299  validloss -1544.18188±0.00000  bestvalidloss -1608.05811  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 594  trainloss -1492.56599  validloss -1002.90189±0.00000  bestvalidloss -1608.05811  last_update 17\n",
      "train: iter 595  trainloss -1592.91139  validloss -1485.41125±0.00000  bestvalidloss -1608.05811  last_update 18\n",
      "train: iter 596  trainloss -1473.78823  validloss -1474.16417±0.00000  bestvalidloss -1608.05811  last_update 19\n",
      "train: iter 597  trainloss -1484.96624  validloss -1287.54766±0.00000  bestvalidloss -1608.05811  last_update 20\n",
      "train: iter 598  trainloss -1654.89174  validloss -1561.15212±0.00000  bestvalidloss -1608.05811  last_update 21\n",
      "train: iter 599  trainloss -1611.10097  validloss -1563.46480±0.00000  bestvalidloss -1608.05811  last_update 22\n",
      "train: iter 600  trainloss -1555.75324  validloss -1580.52094±0.00000  bestvalidloss -1608.05811  last_update 23\n",
      "train: iter 601  trainloss -1368.40466  validloss -1584.63467±0.00000  bestvalidloss -1608.05811  last_update 24\n",
      "train: iter 602  trainloss -1599.37994  validloss -1510.70138±0.00000  bestvalidloss -1608.05811  last_update 25\n",
      "train: iter 603  trainloss -1664.51679  validloss -1597.46528±0.00000  bestvalidloss -1608.05811  last_update 26\n",
      "train: iter 604  trainloss -1559.15238  validloss -1602.72633±0.00000  bestvalidloss -1608.05811  last_update 27\n",
      "train: iter 605  trainloss -1628.66292  validloss -1535.23027±0.00000  bestvalidloss -1608.05811  last_update 28\n",
      "train: iter 606  trainloss -1572.33500  validloss -1401.64954±0.00000  bestvalidloss -1608.05811  last_update 29\n",
      "train: iter 607  trainloss -1642.81094  validloss -1588.23189±0.00000  bestvalidloss -1608.05811  last_update 30\n",
      "train: iter 608  trainloss -1509.11082  validloss -1553.43909±0.00000  bestvalidloss -1608.05811  last_update 31\n",
      "train: iter 609  trainloss -1642.67807  validloss -1548.75330±0.00000  bestvalidloss -1608.05811  last_update 32\n",
      "train: iter 610  trainloss -1624.56018  validloss -1593.10424±0.00000  bestvalidloss -1608.05811  last_update 33\n",
      "train: iter 611  trainloss -1618.34467  validloss -1490.99790±0.00000  bestvalidloss -1608.05811  last_update 34\n",
      "train: iter 612  trainloss -1639.56091  validloss -1575.20912±0.00000  bestvalidloss -1608.05811  last_update 35\n",
      "train: iter 613  trainloss -1572.47330  validloss -1579.21610±0.00000  bestvalidloss -1608.05811  last_update 36\n",
      "train: iter 614  trainloss -1667.44718  validloss -1585.90112±0.00000  bestvalidloss -1608.05811  last_update 37\n",
      "train: iter 615  trainloss -1610.25843  validloss -1580.20227±0.00000  bestvalidloss -1608.05811  last_update 38\n",
      "train: iter 616  trainloss -1570.41548  validloss -1308.94191±0.00000  bestvalidloss -1608.05811  last_update 39\n",
      "train: iter 617  trainloss -1541.94784  validloss -1560.35975±0.00000  bestvalidloss -1608.05811  last_update 40\n",
      "train: iter 618  trainloss -1535.32534  validloss -1481.18360±0.00000  bestvalidloss -1608.05811  last_update 41\n",
      "train: iter 619  trainloss -1648.65732  validloss -1594.51666±0.00000  bestvalidloss -1608.05811  last_update 42\n",
      "train: iter 620  trainloss -1643.50055  validloss -1624.07838±0.00000  bestvalidloss -1624.07838  last_update 0\n",
      "train: iter 621  trainloss -1370.22602  validloss -1599.83016±0.00000  bestvalidloss -1624.07838  last_update 1\n",
      "train: iter 622  trainloss -1608.26850  validloss -1501.68468±0.00000  bestvalidloss -1624.07838  last_update 2\n",
      "train: iter 623  trainloss -1661.48110  validloss -1508.33182±0.00000  bestvalidloss -1624.07838  last_update 3\n",
      "train: iter 624  trainloss -1672.76602  validloss -1583.38952±0.00000  bestvalidloss -1624.07838  last_update 4\n",
      "train: iter 625  trainloss -1614.14836  validloss -1588.53963±0.00000  bestvalidloss -1624.07838  last_update 5\n",
      "train: iter 626  trainloss -1605.67355  validloss -1517.15703±0.00000  bestvalidloss -1624.07838  last_update 6\n",
      "train: iter 627  trainloss -1575.39712  validloss -1456.96127±0.00000  bestvalidloss -1624.07838  last_update 7\n",
      "train: iter 628  trainloss -1672.28047  validloss -1581.85366±0.00000  bestvalidloss -1624.07838  last_update 8\n",
      "train: iter 629  trainloss -1628.40656  validloss -1619.08804±0.00000  bestvalidloss -1624.07838  last_update 9\n",
      "train: iter 630  trainloss -1632.72029  validloss -1536.86302±0.00000  bestvalidloss -1624.07838  last_update 10\n",
      "train: iter 631  trainloss -1582.06445  validloss -1546.99767±0.00000  bestvalidloss -1624.07838  last_update 11\n",
      "train: iter 632  trainloss -1633.46102  validloss -1548.38830±0.00000  bestvalidloss -1624.07838  last_update 12\n",
      "train: iter 633  trainloss -1547.94468  validloss -1373.97500±0.00000  bestvalidloss -1624.07838  last_update 13\n",
      "train: iter 634  trainloss -1624.92010  validloss -1585.50005±0.00000  bestvalidloss -1624.07838  last_update 14\n",
      "train: iter 635  trainloss -1405.20860  validloss -1598.30152±0.00000  bestvalidloss -1624.07838  last_update 15\n",
      "train: iter 636  trainloss -1621.57912  validloss -1523.54722±0.00000  bestvalidloss -1624.07838  last_update 16\n",
      "train: iter 637  trainloss -1643.52826  validloss -1596.70021±0.00000  bestvalidloss -1624.07838  last_update 17\n",
      "train: iter 638  trainloss -1587.25319  validloss -1268.52651±0.00000  bestvalidloss -1624.07838  last_update 18\n",
      "train: iter 639  trainloss -1623.57769  validloss -1615.04377±0.00000  bestvalidloss -1624.07838  last_update 19\n",
      "train: iter 640  trainloss -1632.02676  validloss -1549.26102±0.00000  bestvalidloss -1624.07838  last_update 20\n",
      "train: iter 641  trainloss -1563.68899  validloss -1364.31882±0.00000  bestvalidloss -1624.07838  last_update 21\n",
      "train: iter 642  trainloss -1676.61047  validloss -1536.41546±0.00000  bestvalidloss -1624.07838  last_update 22\n",
      "train: iter 643  trainloss -1650.94754  validloss -1531.16293±0.00000  bestvalidloss -1624.07838  last_update 23\n",
      "train: iter 644  trainloss -1602.88988  validloss -1490.80176±0.00000  bestvalidloss -1624.07838  last_update 24\n",
      "train: iter 645  trainloss -1680.73280  validloss -1592.82423±0.00000  bestvalidloss -1624.07838  last_update 25\n",
      "train: iter 646  trainloss -1479.04112  validloss -1604.22334±0.00000  bestvalidloss -1624.07838  last_update 26\n",
      "train: iter 647  trainloss -1680.40694  validloss -1493.55504±0.00000  bestvalidloss -1624.07838  last_update 27\n",
      "train: iter 648  trainloss -1655.02471  validloss -1610.33554±0.00000  bestvalidloss -1624.07838  last_update 28\n",
      "train: iter 649  trainloss -1605.33110  validloss -1381.60255±0.00000  bestvalidloss -1624.07838  last_update 29\n",
      "train: iter 650  trainloss -1560.06303  validloss -1573.10222±0.00000  bestvalidloss -1624.07838  last_update 30\n",
      "train: iter 651  trainloss -1633.01925  validloss -1443.00714±0.00000  bestvalidloss -1624.07838  last_update 31\n",
      "train: iter 652  trainloss -1621.06468  validloss -1598.25372±0.00000  bestvalidloss -1624.07838  last_update 32\n",
      "train: iter 653  trainloss -971.17945  validloss -1256.96282±0.00000  bestvalidloss -1624.07838  last_update 33\n",
      "train: iter 654  trainloss -1440.42026  validloss -1314.31045±0.00000  bestvalidloss -1624.07838  last_update 34\n",
      "train: iter 655  trainloss -1370.15144  validloss -1486.78407±0.00000  bestvalidloss -1624.07838  last_update 35\n",
      "train: iter 656  trainloss -1539.34898  validloss -1400.31836±0.00000  bestvalidloss -1624.07838  last_update 36\n",
      "train: iter 657  trainloss -1586.07554  validloss -1508.80256±0.00000  bestvalidloss -1624.07838  last_update 37\n",
      "train: iter 658  trainloss -1585.65685  validloss -1543.61618±0.00000  bestvalidloss -1624.07838  last_update 38\n",
      "train: iter 659  trainloss -1590.38063  validloss -1467.65394±0.00000  bestvalidloss -1624.07838  last_update 39\n",
      "train: iter 660  trainloss -1614.09974  validloss -1507.85869±0.00000  bestvalidloss -1624.07838  last_update 40\n",
      "train: iter 661  trainloss -1631.97328  validloss -1489.20079±0.00000  bestvalidloss -1624.07838  last_update 41\n",
      "train: iter 662  trainloss -1643.25396  validloss -1543.50899±0.00000  bestvalidloss -1624.07838  last_update 42\n",
      "train: iter 663  trainloss -1654.80677  validloss -1600.82858±0.00000  bestvalidloss -1624.07838  last_update 43\n",
      "train: iter 664  trainloss -1679.15245  validloss -1559.45112±0.00000  bestvalidloss -1624.07838  last_update 44\n",
      "train: iter 665  trainloss -1525.31014  validloss -1582.99774±0.00000  bestvalidloss -1624.07838  last_update 45\n",
      "train: iter 666  trainloss -1338.86302  validloss -1380.89505±0.00000  bestvalidloss -1624.07838  last_update 46\n",
      "train: iter 667  trainloss -1521.60114  validloss -1382.76868±0.00000  bestvalidloss -1624.07838  last_update 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 668  trainloss -1598.58581  validloss -1431.70253±0.00000  bestvalidloss -1624.07838  last_update 48\n",
      "train: iter 669  trainloss -1585.56333  validloss -1547.44373±0.00000  bestvalidloss -1624.07838  last_update 49\n",
      "train: iter 670  trainloss -1417.13464  validloss -1161.87293±0.00000  bestvalidloss -1624.07838  last_update 50\n",
      "train: iter 671  trainloss -1658.47343  validloss -1549.76625±0.00000  bestvalidloss -1624.07838  last_update 51\n",
      "train: iter 672  trainloss -1665.71521  validloss -1580.08807±0.00000  bestvalidloss -1624.07838  last_update 52\n",
      "train: iter 673  trainloss -1625.07437  validloss -1551.32353±0.00000  bestvalidloss -1624.07838  last_update 53\n",
      "train: iter 674  trainloss -1625.39252  validloss -1527.64852±0.00000  bestvalidloss -1624.07838  last_update 54\n",
      "train: iter 675  trainloss -1595.41447  validloss -1533.95605±0.00000  bestvalidloss -1624.07838  last_update 55\n",
      "train: iter 676  trainloss -1633.30388  validloss -1436.74462±0.00000  bestvalidloss -1624.07838  last_update 56\n",
      "train: iter 677  trainloss -1653.00393  validloss -1611.63818±0.00000  bestvalidloss -1624.07838  last_update 57\n",
      "train: iter 678  trainloss -1641.06470  validloss -1600.24303±0.00000  bestvalidloss -1624.07838  last_update 58\n",
      "train: iter 679  trainloss -1471.75793  validloss -1397.44872±0.00000  bestvalidloss -1624.07838  last_update 59\n",
      "train: iter 680  trainloss -1629.69995  validloss -1554.50919±0.00000  bestvalidloss -1624.07838  last_update 60\n",
      "train: iter 681  trainloss -1690.77711  validloss -1570.90843±0.00000  bestvalidloss -1624.07838  last_update 61\n",
      "train: iter 682  trainloss -1660.81903  validloss -1595.82345±0.00000  bestvalidloss -1624.07838  last_update 62\n",
      "train: iter 683  trainloss -1639.05300  validloss -1599.75339±0.00000  bestvalidloss -1624.07838  last_update 63\n",
      "train: iter 684  trainloss -1637.43815  validloss -1564.39269±0.00000  bestvalidloss -1624.07838  last_update 64\n",
      "train: iter 685  trainloss -1510.27722  validloss -1488.40567±0.00000  bestvalidloss -1624.07838  last_update 65\n",
      "train: iter 686  trainloss -1580.05870  validloss -1470.59252±0.00000  bestvalidloss -1624.07838  last_update 66\n",
      "train: iter 687  trainloss -1655.86425  validloss -1526.80423±0.00000  bestvalidloss -1624.07838  last_update 67\n",
      "train: iter 688  trainloss -1648.19383  validloss -1579.14249±0.00000  bestvalidloss -1624.07838  last_update 68\n",
      "train: iter 689  trainloss -1560.36212  validloss -1187.24149±0.00000  bestvalidloss -1624.07838  last_update 69\n",
      "train: iter 690  trainloss -1633.18538  validloss -1437.49458±0.00000  bestvalidloss -1624.07838  last_update 70\n",
      "train: iter 691  trainloss -1623.90159  validloss -1487.84697±0.00000  bestvalidloss -1624.07838  last_update 71\n",
      "train: iter 692  trainloss -1623.28553  validloss -1528.69512±0.00000  bestvalidloss -1624.07838  last_update 72\n",
      "train: iter 693  trainloss -1682.67447  validloss -1449.72769±0.00000  bestvalidloss -1624.07838  last_update 73\n",
      "train: iter 694  trainloss -1656.51474  validloss -1465.48683±0.00000  bestvalidloss -1624.07838  last_update 74\n",
      "train: iter 695  trainloss -1624.98221  validloss -1502.06514±0.00000  bestvalidloss -1624.07838  last_update 75\n",
      "train: iter 696  trainloss -1713.99999  validloss -1537.40756±0.00000  bestvalidloss -1624.07838  last_update 76\n",
      "train: iter 697  trainloss -1440.67111  validloss -1507.02748±0.00000  bestvalidloss -1624.07838  last_update 77\n",
      "train: iter 698  trainloss -1440.69087  validloss -1306.69434±0.00000  bestvalidloss -1624.07838  last_update 78\n",
      "train: iter 699  trainloss -1634.33349  validloss -1518.63174±0.00000  bestvalidloss -1624.07838  last_update 79\n",
      "train: iter 700  trainloss -1619.62582  validloss -1568.35624±0.00000  bestvalidloss -1624.07838  last_update 80\n",
      "train: iter 701  trainloss -1638.43401  validloss -1529.91295±0.00000  bestvalidloss -1624.07838  last_update 81\n",
      "train: iter 702  trainloss -1648.02801  validloss -1558.94532±0.00000  bestvalidloss -1624.07838  last_update 82\n",
      "train: iter 703  trainloss -1478.86613  validloss -1540.57619±0.00000  bestvalidloss -1624.07838  last_update 83\n",
      "train: iter 704  trainloss -1603.54034  validloss -1530.85951±0.00000  bestvalidloss -1624.07838  last_update 84\n",
      "train: iter 705  trainloss -1576.18330  validloss -1468.11502±0.00000  bestvalidloss -1624.07838  last_update 85\n",
      "train: iter 706  trainloss -1494.93184  validloss -1356.07582±0.00000  bestvalidloss -1624.07838  last_update 86\n",
      "train: iter 707  trainloss -1616.10364  validloss -1489.26549±0.00000  bestvalidloss -1624.07838  last_update 87\n",
      "train: iter 708  trainloss -1683.82216  validloss -1580.02068±0.00000  bestvalidloss -1624.07838  last_update 88\n",
      "train: iter 709  trainloss -1610.76817  validloss -1402.87464±0.00000  bestvalidloss -1624.07838  last_update 89\n",
      "train: iter 710  trainloss -1678.04664  validloss -1515.30506±0.00000  bestvalidloss -1624.07838  last_update 90\n",
      "train: iter 711  trainloss -1671.58845  validloss -1558.93390±0.00000  bestvalidloss -1624.07838  last_update 91\n",
      "train: iter 712  trainloss -1662.54680  validloss -1525.23752±0.00000  bestvalidloss -1624.07838  last_update 92\n",
      "train: iter 713  trainloss -1557.82590  validloss -1531.20090±0.00000  bestvalidloss -1624.07838  last_update 93\n",
      "train: iter 714  trainloss -1617.31811  validloss -1582.43484±0.00000  bestvalidloss -1624.07838  last_update 94\n",
      "train: iter 715  trainloss -1502.59048  validloss -1356.27733±0.00000  bestvalidloss -1624.07838  last_update 95\n",
      "train: iter 716  trainloss -1662.86505  validloss -1503.15520±0.00000  bestvalidloss -1624.07838  last_update 96\n",
      "train: iter 717  trainloss -1715.23586  validloss -1594.54528±0.00000  bestvalidloss -1624.07838  last_update 97\n",
      "train: iter 718  trainloss -1601.23513  validloss -1527.64467±0.00000  bestvalidloss -1624.07838  last_update 98\n",
      "train: iter 719  trainloss -1670.14245  validloss -1561.26806±0.00000  bestvalidloss -1624.07838  last_update 99\n",
      "train: iter 720  trainloss -1440.71491  validloss -1466.98053±0.00000  bestvalidloss -1624.07838  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.6716) penalty_target_max tensor(5.3178)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.06906  validloss 9.43641±0.00000  bestvalidloss 9.43641  last_update 0\n",
      "train: iter 1  trainloss 8.27585  validloss 8.61592±0.00000  bestvalidloss 8.61592  last_update 0\n",
      "train: iter 2  trainloss 7.62311  validloss 7.88254±0.00000  bestvalidloss 7.88254  last_update 0\n",
      "train: iter 3  trainloss 7.07153  validloss 7.30516±0.00000  bestvalidloss 7.30516  last_update 0\n",
      "train: iter 4  trainloss 6.61364  validloss 6.78842±0.00000  bestvalidloss 6.78842  last_update 0\n",
      "train: iter 5  trainloss 6.20297  validloss 6.35972±0.00000  bestvalidloss 6.35972  last_update 0\n",
      "train: iter 6  trainloss 5.87493  validloss 5.99271±0.00000  bestvalidloss 5.99271  last_update 0\n",
      "train: iter 7  trainloss 5.56247  validloss 5.67944±0.00000  bestvalidloss 5.67944  last_update 0\n",
      "train: iter 8  trainloss 5.31155  validloss 5.40417±0.00000  bestvalidloss 5.40417  last_update 0\n",
      "train: iter 9  trainloss 5.07535  validloss 5.15574±0.00000  bestvalidloss 5.15574  last_update 0\n",
      "train: iter 10  trainloss 4.85944  validloss 4.94507±0.00000  bestvalidloss 4.94507  last_update 0\n",
      "train: iter 11  trainloss 4.66696  validloss 4.73453±0.00000  bestvalidloss 4.73453  last_update 0\n",
      "train: iter 12  trainloss 4.49619  validloss 4.55188±0.00000  bestvalidloss 4.55188  last_update 0\n",
      "train: iter 13  trainloss 4.33280  validloss 4.39013±0.00000  bestvalidloss 4.39013  last_update 0\n",
      "train: iter 14  trainloss 4.18941  validloss 4.24688±0.00000  bestvalidloss 4.24688  last_update 0\n",
      "train: iter 15  trainloss 4.05258  validloss 4.10396±0.00000  bestvalidloss 4.10396  last_update 0\n",
      "train: iter 16  trainloss 3.92074  validloss 3.97285±0.00000  bestvalidloss 3.97285  last_update 0\n",
      "train: iter 17  trainloss 3.78996  validloss 3.82940±0.00000  bestvalidloss 3.82940  last_update 0\n",
      "train: iter 18  trainloss 3.66414  validloss 3.71008±0.00000  bestvalidloss 3.71008  last_update 0\n",
      "train: iter 19  trainloss 3.55202  validloss 3.59923±0.00000  bestvalidloss 3.59923  last_update 0\n",
      "train: iter 20  trainloss 3.43835  validloss 3.49043±0.00000  bestvalidloss 3.49043  last_update 0\n",
      "train: iter 21  trainloss 3.33446  validloss 3.36841±0.00000  bestvalidloss 3.36841  last_update 0\n",
      "train: iter 22  trainloss 3.23170  validloss 3.26847±0.00000  bestvalidloss 3.26847  last_update 0\n",
      "train: iter 23  trainloss 3.12772  validloss 3.17011±0.00000  bestvalidloss 3.17011  last_update 0\n",
      "train: iter 24  trainloss 3.03846  validloss 3.07269±0.00000  bestvalidloss 3.07269  last_update 0\n",
      "train: iter 25  trainloss 2.94521  validloss 2.97600±0.00000  bestvalidloss 2.97600  last_update 0\n",
      "train: iter 26  trainloss 2.85690  validloss 2.89718±0.00000  bestvalidloss 2.89718  last_update 0\n",
      "train: iter 27  trainloss 2.77870  validloss 2.81389±0.00000  bestvalidloss 2.81389  last_update 0\n",
      "train: iter 28  trainloss 2.70728  validloss 2.73399±0.00000  bestvalidloss 2.73399  last_update 0\n",
      "train: iter 29  trainloss 2.63156  validloss 2.67293±0.00000  bestvalidloss 2.67293  last_update 0\n",
      "train: iter 30  trainloss 2.56351  validloss 2.59870±0.00000  bestvalidloss 2.59870  last_update 0\n",
      "train: iter 31  trainloss 2.50290  validloss 2.53773±0.00000  bestvalidloss 2.53773  last_update 0\n",
      "train: iter 32  trainloss 2.44487  validloss 2.48132±0.00000  bestvalidloss 2.48132  last_update 0\n",
      "train: iter 33  trainloss 2.38213  validloss 2.43392±0.00000  bestvalidloss 2.43392  last_update 0\n",
      "train: iter 34  trainloss 2.33605  validloss 2.35996±0.00000  bestvalidloss 2.35996  last_update 0\n",
      "train: iter 35  trainloss 2.27620  validloss 2.30951±0.00000  bestvalidloss 2.30951  last_update 0\n",
      "train: iter 36  trainloss 2.23089  validloss 2.26235±0.00000  bestvalidloss 2.26235  last_update 0\n",
      "train: iter 37  trainloss 2.17879  validloss 2.21663±0.00000  bestvalidloss 2.21663  last_update 0\n",
      "train: iter 38  trainloss 2.12860  validloss 2.17512±0.00000  bestvalidloss 2.17512  last_update 0\n",
      "train: iter 39  trainloss 2.09095  validloss 2.12498±0.00000  bestvalidloss 2.12498  last_update 0\n",
      "train: iter 40  trainloss 2.04093  validloss 2.07990±0.00000  bestvalidloss 2.07990  last_update 0\n",
      "train: iter 41  trainloss 2.00527  validloss 2.04478±0.00000  bestvalidloss 2.04478  last_update 0\n",
      "train: iter 42  trainloss 1.94910  validloss 2.00037±0.00000  bestvalidloss 2.00037  last_update 0\n",
      "train: iter 43  trainloss 1.91283  validloss 1.97173±0.00000  bestvalidloss 1.97173  last_update 0\n",
      "train: iter 44  trainloss 1.87871  validloss 1.91019±0.00000  bestvalidloss 1.91019  last_update 0\n",
      "train: iter 45  trainloss 1.83591  validloss 1.87363±0.00000  bestvalidloss 1.87363  last_update 0\n",
      "train: iter 46  trainloss 1.79120  validloss 1.84997±0.00000  bestvalidloss 1.84997  last_update 0\n",
      "train: iter 47  trainloss 1.74925  validloss 1.78351±0.00000  bestvalidloss 1.78351  last_update 0\n",
      "train: iter 48  trainloss 1.71581  validloss 1.73530±0.00000  bestvalidloss 1.73530  last_update 0\n",
      "train: iter 49  trainloss 1.66854  validloss 1.72287±0.00000  bestvalidloss 1.72287  last_update 0\n",
      "train: iter 50  trainloss 1.63652  validloss 1.70663±0.00000  bestvalidloss 1.70663  last_update 0\n",
      "train: iter 51  trainloss 1.60694  validloss 1.63825±0.00000  bestvalidloss 1.63825  last_update 0\n",
      "train: iter 52  trainloss 1.55078  validloss 1.60513±0.00000  bestvalidloss 1.60513  last_update 0\n",
      "train: iter 53  trainloss 1.51627  validloss 1.55079±0.00000  bestvalidloss 1.55079  last_update 0\n",
      "train: iter 54  trainloss 1.46896  validloss 1.55915±0.00000  bestvalidloss 1.55079  last_update 1\n",
      "train: iter 55  trainloss 1.42708  validloss 1.47269±0.00000  bestvalidloss 1.47269  last_update 0\n",
      "train: iter 56  trainloss 1.37922  validloss 1.45075±0.00000  bestvalidloss 1.45075  last_update 0\n",
      "train: iter 57  trainloss 1.33072  validloss 1.38452±0.00000  bestvalidloss 1.38452  last_update 0\n",
      "train: iter 58  trainloss 1.27850  validloss 1.36348±0.00000  bestvalidloss 1.36348  last_update 0\n",
      "train: iter 59  trainloss 1.23209  validloss 1.30796±0.00000  bestvalidloss 1.30796  last_update 0\n",
      "train: iter 60  trainloss 1.17876  validloss 1.26753±0.00000  bestvalidloss 1.26753  last_update 0\n",
      "train: iter 61  trainloss 1.14825  validloss 1.20536±0.00000  bestvalidloss 1.20536  last_update 0\n",
      "train: iter 62  trainloss 1.06996  validloss 1.17469±0.00000  bestvalidloss 1.17469  last_update 0\n",
      "train: iter 63  trainloss 1.04344  validloss 1.08705±0.00000  bestvalidloss 1.08705  last_update 0\n",
      "train: iter 64  trainloss 0.98356  validloss 1.06831±0.00000  bestvalidloss 1.06831  last_update 0\n",
      "train: iter 65  trainloss 0.94000  validloss 0.97690±0.00000  bestvalidloss 0.97690  last_update 0\n",
      "train: iter 66  trainloss 0.88608  validloss 0.94550±0.00000  bestvalidloss 0.94550  last_update 0\n",
      "train: iter 67  trainloss 0.84961  validloss 0.96118±0.00000  bestvalidloss 0.94550  last_update 1\n",
      "train: iter 68  trainloss 0.80551  validloss 0.89081±0.00000  bestvalidloss 0.89081  last_update 0\n",
      "train: iter 69  trainloss 0.76979  validloss 0.83080±0.00000  bestvalidloss 0.83080  last_update 0\n",
      "train: iter 70  trainloss 0.71083  validloss 0.77445±0.00000  bestvalidloss 0.77445  last_update 0\n",
      "train: iter 71  trainloss 0.68102  validloss 0.73731±0.00000  bestvalidloss 0.73731  last_update 0\n",
      "train: iter 72  trainloss 0.62805  validloss 0.75972±0.00000  bestvalidloss 0.73731  last_update 1\n",
      "train: iter 73  trainloss 0.58240  validloss 0.67030±0.00000  bestvalidloss 0.67030  last_update 0\n",
      "train: iter 74  trainloss 0.53940  validloss 0.62470±0.00000  bestvalidloss 0.62470  last_update 0\n",
      "train: iter 75  trainloss 0.49261  validloss 0.60619±0.00000  bestvalidloss 0.60619  last_update 0\n",
      "train: iter 76  trainloss 0.47606  validloss 0.52797±0.00000  bestvalidloss 0.52797  last_update 0\n",
      "train: iter 77  trainloss 0.43573  validloss 0.54462±0.00000  bestvalidloss 0.52797  last_update 1\n",
      "train: iter 78  trainloss 0.39644  validloss 0.43990±0.00000  bestvalidloss 0.43990  last_update 0\n",
      "train: iter 79  trainloss 0.35317  validloss 0.45781±0.00000  bestvalidloss 0.43990  last_update 1\n",
      "train: iter 80  trainloss 0.32348  validloss 0.44265±0.00000  bestvalidloss 0.43990  last_update 2\n",
      "train: iter 81  trainloss 0.26683  validloss 0.35967±0.00000  bestvalidloss 0.35967  last_update 0\n",
      "train: iter 82  trainloss 0.22552  validloss 0.38274±0.00000  bestvalidloss 0.35967  last_update 1\n",
      "train: iter 83  trainloss 0.20561  validloss 0.25853±0.00000  bestvalidloss 0.25853  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 0.14001  validloss 0.18641±0.00000  bestvalidloss 0.18641  last_update 0\n",
      "train: iter 85  trainloss 0.10825  validloss 0.15332±0.00000  bestvalidloss 0.15332  last_update 0\n",
      "train: iter 86  trainloss 0.08037  validloss 0.14507±0.00000  bestvalidloss 0.14507  last_update 0\n",
      "train: iter 87  trainloss 0.02793  validloss 0.14458±0.00000  bestvalidloss 0.14458  last_update 0\n",
      "train: iter 88  trainloss -0.00145  validloss 0.09941±0.00000  bestvalidloss 0.09941  last_update 0\n",
      "train: iter 89  trainloss -0.04359  validloss 0.04118±0.00000  bestvalidloss 0.04118  last_update 0\n",
      "train: iter 90  trainloss -0.08038  validloss 0.00070±0.00000  bestvalidloss 0.00070  last_update 0\n",
      "train: iter 91  trainloss -0.11349  validloss -0.02401±0.00000  bestvalidloss -0.02401  last_update 0\n",
      "train: iter 92  trainloss -0.13128  validloss -0.08569±0.00000  bestvalidloss -0.08569  last_update 0\n",
      "train: iter 93  trainloss -0.18728  validloss -0.17766±0.00000  bestvalidloss -0.17766  last_update 0\n",
      "train: iter 94  trainloss -0.21707  validloss -0.15599±0.00000  bestvalidloss -0.17766  last_update 1\n",
      "train: iter 95  trainloss -0.25401  validloss -0.20957±0.00000  bestvalidloss -0.20957  last_update 0\n",
      "train: iter 96  trainloss -0.26867  validloss -0.22845±0.00000  bestvalidloss -0.22845  last_update 0\n",
      "train: iter 97  trainloss -0.32376  validloss -0.23168±0.00000  bestvalidloss -0.23168  last_update 0\n",
      "train: iter 98  trainloss -0.35347  validloss -0.29175±0.00000  bestvalidloss -0.29175  last_update 0\n",
      "train: iter 99  trainloss -0.39159  validloss -0.33325±0.00000  bestvalidloss -0.33325  last_update 0\n",
      "train: iter 100  trainloss -0.41677  validloss -0.38612±0.00000  bestvalidloss -0.38612  last_update 0\n",
      "train: iter 101  trainloss -0.45883  validloss -0.42036±0.00000  bestvalidloss -0.42036  last_update 0\n",
      "train: iter 102  trainloss -0.46955  validloss -0.45187±0.00000  bestvalidloss -0.45187  last_update 0\n",
      "train: iter 103  trainloss -0.52039  validloss -0.43943±0.00000  bestvalidloss -0.45187  last_update 1\n",
      "train: iter 104  trainloss -0.54140  validloss -0.48965±0.00000  bestvalidloss -0.48965  last_update 0\n",
      "train: iter 105  trainloss -0.59854  validloss -0.52141±0.00000  bestvalidloss -0.52141  last_update 0\n",
      "train: iter 106  trainloss -0.57936  validloss -0.56902±0.00000  bestvalidloss -0.56902  last_update 0\n",
      "train: iter 107  trainloss -0.63517  validloss -0.64298±0.00000  bestvalidloss -0.64298  last_update 0\n",
      "train: iter 108  trainloss -0.64842  validloss -0.64701±0.00000  bestvalidloss -0.64701  last_update 0\n",
      "train: iter 109  trainloss -0.69176  validloss -0.64394±0.00000  bestvalidloss -0.64701  last_update 1\n",
      "train: iter 110  trainloss -0.71813  validloss -0.67329±0.00000  bestvalidloss -0.67329  last_update 0\n",
      "train: iter 111  trainloss -0.75354  validloss -0.63884±0.00000  bestvalidloss -0.67329  last_update 1\n",
      "train: iter 112  trainloss -0.75905  validloss -0.75007±0.00000  bestvalidloss -0.75007  last_update 0\n",
      "train: iter 113  trainloss -0.76705  validloss -0.71871±0.00000  bestvalidloss -0.75007  last_update 1\n",
      "train: iter 114  trainloss -0.80138  validloss -0.73452±0.00000  bestvalidloss -0.75007  last_update 2\n",
      "train: iter 115  trainloss -0.84106  validloss -0.80527±0.00000  bestvalidloss -0.80527  last_update 0\n",
      "train: iter 116  trainloss -0.82936  validloss -0.80524±0.00000  bestvalidloss -0.80527  last_update 1\n",
      "train: iter 117  trainloss -0.85196  validloss -0.84754±0.00000  bestvalidloss -0.84754  last_update 0\n",
      "train: iter 118  trainloss -0.87458  validloss -0.86707±0.00000  bestvalidloss -0.86707  last_update 0\n",
      "train: iter 119  trainloss -0.89943  validloss -0.92562±0.00000  bestvalidloss -0.92562  last_update 0\n",
      "train: iter 120  trainloss -0.91671  validloss -0.92465±0.00000  bestvalidloss -0.92562  last_update 1\n",
      "train: iter 121  trainloss -0.90542  validloss -0.96686±0.00000  bestvalidloss -0.96686  last_update 0\n",
      "train: iter 122  trainloss -0.90819  validloss -0.97020±0.00000  bestvalidloss -0.97020  last_update 0\n",
      "train: iter 123  trainloss -0.93867  validloss -0.95898±0.00000  bestvalidloss -0.97020  last_update 1\n",
      "train: iter 124  trainloss -0.95274  validloss -0.97638±0.00000  bestvalidloss -0.97638  last_update 0\n",
      "train: iter 125  trainloss -0.96697  validloss -1.03976±0.00000  bestvalidloss -1.03976  last_update 0\n",
      "train: iter 126  trainloss -0.98132  validloss -1.02195±0.00000  bestvalidloss -1.03976  last_update 1\n",
      "train: iter 127  trainloss -0.97466  validloss -1.00979±0.00000  bestvalidloss -1.03976  last_update 2\n",
      "train: iter 128  trainloss -1.02475  validloss -1.00437±0.00000  bestvalidloss -1.03976  last_update 3\n",
      "train: iter 129  trainloss -0.96919  validloss -1.00948±0.00000  bestvalidloss -1.03976  last_update 4\n",
      "train: iter 130  trainloss -0.99995  validloss -0.94600±0.00000  bestvalidloss -1.03976  last_update 5\n",
      "train: iter 131  trainloss -1.04381  validloss -1.08358±0.00000  bestvalidloss -1.08358  last_update 0\n",
      "train: iter 132  trainloss -0.99380  validloss -1.04240±0.00000  bestvalidloss -1.08358  last_update 1\n",
      "train: iter 133  trainloss -1.03303  validloss -1.07123±0.00000  bestvalidloss -1.08358  last_update 2\n",
      "train: iter 134  trainloss -1.01957  validloss -1.05272±0.00000  bestvalidloss -1.08358  last_update 3\n",
      "train: iter 135  trainloss -0.98345  validloss -1.07860±0.00000  bestvalidloss -1.08358  last_update 4\n",
      "train: iter 136  trainloss -1.01137  validloss -1.14457±0.00000  bestvalidloss -1.14457  last_update 0\n",
      "train: iter 137  trainloss -1.01338  validloss -1.13468±0.00000  bestvalidloss -1.14457  last_update 1\n",
      "train: iter 138  trainloss -0.98835  validloss -1.09008±0.00000  bestvalidloss -1.14457  last_update 2\n",
      "train: iter 139  trainloss -0.97459  validloss -1.06681±0.00000  bestvalidloss -1.14457  last_update 3\n",
      "train: iter 140  trainloss -0.97504  validloss -1.11501±0.00000  bestvalidloss -1.14457  last_update 4\n",
      "train: iter 141  trainloss -1.01269  validloss -1.09725±0.00000  bestvalidloss -1.14457  last_update 5\n",
      "train: iter 142  trainloss -0.98803  validloss -1.02137±0.00000  bestvalidloss -1.14457  last_update 6\n",
      "train: iter 143  trainloss -0.99773  validloss -1.06754±0.00000  bestvalidloss -1.14457  last_update 7\n",
      "train: iter 144  trainloss -0.99124  validloss -1.00449±0.00000  bestvalidloss -1.14457  last_update 8\n",
      "train: iter 145  trainloss -1.04291  validloss -0.99002±0.00000  bestvalidloss -1.14457  last_update 9\n",
      "train: iter 146  trainloss -1.03725  validloss -1.08776±0.00000  bestvalidloss -1.14457  last_update 10\n",
      "train: iter 147  trainloss -1.02161  validloss -1.01682±0.00000  bestvalidloss -1.14457  last_update 11\n",
      "train: iter 148  trainloss -0.99759  validloss -1.14414±0.00000  bestvalidloss -1.14457  last_update 12\n",
      "train: iter 149  trainloss -1.05312  validloss -1.06184±0.00000  bestvalidloss -1.14457  last_update 13\n",
      "train: iter 150  trainloss -1.02789  validloss -1.04214±0.00000  bestvalidloss -1.14457  last_update 14\n",
      "train: iter 151  trainloss -0.96466  validloss -1.12622±0.00000  bestvalidloss -1.14457  last_update 15\n",
      "train: iter 152  trainloss -0.99980  validloss -1.10875±0.00000  bestvalidloss -1.14457  last_update 16\n",
      "train: iter 153  trainloss -1.01331  validloss -1.13078±0.00000  bestvalidloss -1.14457  last_update 17\n",
      "train: iter 154  trainloss -1.03280  validloss -1.12951±0.00000  bestvalidloss -1.14457  last_update 18\n",
      "train: iter 155  trainloss -1.00771  validloss -1.10275±0.00000  bestvalidloss -1.14457  last_update 19\n",
      "train: iter 156  trainloss -1.03390  validloss -1.07942±0.00000  bestvalidloss -1.14457  last_update 20\n",
      "train: iter 157  trainloss -1.01106  validloss -1.07649±0.00000  bestvalidloss -1.14457  last_update 21\n",
      "train: iter 158  trainloss -1.02440  validloss -1.08527±0.00000  bestvalidloss -1.14457  last_update 22\n",
      "train: iter 159  trainloss -0.98013  validloss -1.07135±0.00000  bestvalidloss -1.14457  last_update 23\n",
      "train: iter 160  trainloss -0.96798  validloss -1.05758±0.00000  bestvalidloss -1.14457  last_update 24\n",
      "train: iter 161  trainloss -1.04660  validloss -1.03558±0.00000  bestvalidloss -1.14457  last_update 25\n",
      "train: iter 162  trainloss -0.98416  validloss -1.09197±0.00000  bestvalidloss -1.14457  last_update 26\n",
      "train: iter 163  trainloss -1.01019  validloss -1.02948±0.00000  bestvalidloss -1.14457  last_update 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 164  trainloss -1.01498  validloss -1.09601±0.00000  bestvalidloss -1.14457  last_update 28\n",
      "train: iter 165  trainloss -1.04478  validloss -1.01182±0.00000  bestvalidloss -1.14457  last_update 29\n",
      "train: iter 166  trainloss -1.03272  validloss -1.15321±0.00000  bestvalidloss -1.15321  last_update 0\n",
      "train: iter 167  trainloss -1.01816  validloss -1.07862±0.00000  bestvalidloss -1.15321  last_update 1\n",
      "train: iter 168  trainloss -0.98275  validloss -1.03740±0.00000  bestvalidloss -1.15321  last_update 2\n",
      "train: iter 169  trainloss -1.03969  validloss -1.09579±0.00000  bestvalidloss -1.15321  last_update 3\n",
      "train: iter 170  trainloss -1.02002  validloss -1.10513±0.00000  bestvalidloss -1.15321  last_update 4\n",
      "train: iter 171  trainloss -0.98375  validloss -1.13007±0.00000  bestvalidloss -1.15321  last_update 5\n",
      "train: iter 172  trainloss -0.98746  validloss -1.02271±0.00000  bestvalidloss -1.15321  last_update 6\n",
      "train: iter 173  trainloss -1.02627  validloss -1.12823±0.00000  bestvalidloss -1.15321  last_update 7\n",
      "train: iter 174  trainloss -1.06877  validloss -1.03593±0.00000  bestvalidloss -1.15321  last_update 8\n",
      "train: iter 175  trainloss -1.01713  validloss -1.11098±0.00000  bestvalidloss -1.15321  last_update 9\n",
      "train: iter 176  trainloss -1.02866  validloss -1.08491±0.00000  bestvalidloss -1.15321  last_update 10\n",
      "train: iter 177  trainloss -0.95576  validloss -1.13592±0.00000  bestvalidloss -1.15321  last_update 11\n",
      "train: iter 178  trainloss -1.00040  validloss -1.10935±0.00000  bestvalidloss -1.15321  last_update 12\n",
      "train: iter 179  trainloss -1.05998  validloss -1.08950±0.00000  bestvalidloss -1.15321  last_update 13\n",
      "train: iter 180  trainloss -1.01015  validloss -1.11965±0.00000  bestvalidloss -1.15321  last_update 14\n",
      "train: iter 181  trainloss -1.01067  validloss -1.08814±0.00000  bestvalidloss -1.15321  last_update 15\n",
      "train: iter 182  trainloss -1.00223  validloss -1.04431±0.00000  bestvalidloss -1.15321  last_update 16\n",
      "train: iter 183  trainloss -1.02776  validloss -1.09287±0.00000  bestvalidloss -1.15321  last_update 17\n",
      "train: iter 184  trainloss -1.03520  validloss -1.08053±0.00000  bestvalidloss -1.15321  last_update 18\n",
      "train: iter 185  trainloss -0.99189  validloss -1.02213±0.00000  bestvalidloss -1.15321  last_update 19\n",
      "train: iter 186  trainloss -1.01683  validloss -1.09495±0.00000  bestvalidloss -1.15321  last_update 20\n",
      "train: iter 187  trainloss -1.01786  validloss -1.01981±0.00000  bestvalidloss -1.15321  last_update 21\n",
      "train: iter 188  trainloss -0.99476  validloss -1.06976±0.00000  bestvalidloss -1.15321  last_update 22\n",
      "train: iter 189  trainloss -1.01751  validloss -1.07156±0.00000  bestvalidloss -1.15321  last_update 23\n",
      "train: iter 190  trainloss -1.00503  validloss -1.06634±0.00000  bestvalidloss -1.15321  last_update 24\n",
      "train: iter 191  trainloss -0.98600  validloss -1.14153±0.00000  bestvalidloss -1.15321  last_update 25\n",
      "train: iter 192  trainloss -1.06252  validloss -1.09256±0.00000  bestvalidloss -1.15321  last_update 26\n",
      "train: iter 193  trainloss -1.06039  validloss -1.07801±0.00000  bestvalidloss -1.15321  last_update 27\n",
      "train: iter 194  trainloss -0.99972  validloss -1.19116±0.00000  bestvalidloss -1.19116  last_update 0\n",
      "train: iter 195  trainloss -0.99741  validloss -1.11046±0.00000  bestvalidloss -1.19116  last_update 1\n",
      "train: iter 196  trainloss -0.97200  validloss -1.15723±0.00000  bestvalidloss -1.19116  last_update 2\n",
      "train: iter 197  trainloss -1.02903  validloss -1.21999±0.00000  bestvalidloss -1.21999  last_update 0\n",
      "train: iter 198  trainloss -1.03377  validloss -1.15452±0.00000  bestvalidloss -1.21999  last_update 1\n",
      "train: iter 199  trainloss -0.94168  validloss -1.05369±0.00000  bestvalidloss -1.21999  last_update 2\n",
      "train: iter 200  trainloss -1.06331  validloss -1.07355±0.00000  bestvalidloss -1.21999  last_update 3\n",
      "train: iter 201  trainloss -1.02382  validloss -1.05072±0.00000  bestvalidloss -1.21999  last_update 4\n",
      "train: iter 202  trainloss -1.01074  validloss -1.12617±0.00000  bestvalidloss -1.21999  last_update 5\n",
      "train: iter 203  trainloss -0.97394  validloss -1.09025±0.00000  bestvalidloss -1.21999  last_update 6\n",
      "train: iter 204  trainloss -0.99342  validloss -1.07493±0.00000  bestvalidloss -1.21999  last_update 7\n",
      "train: iter 205  trainloss -0.96783  validloss -1.13120±0.00000  bestvalidloss -1.21999  last_update 8\n",
      "train: iter 206  trainloss -1.00719  validloss -1.12915±0.00000  bestvalidloss -1.21999  last_update 9\n",
      "train: iter 207  trainloss -1.02027  validloss -1.08976±0.00000  bestvalidloss -1.21999  last_update 10\n",
      "train: iter 208  trainloss -1.00527  validloss -1.05671±0.00000  bestvalidloss -1.21999  last_update 11\n",
      "train: iter 209  trainloss -0.99112  validloss -1.07767±0.00000  bestvalidloss -1.21999  last_update 12\n",
      "train: iter 210  trainloss -1.02249  validloss -1.12076±0.00000  bestvalidloss -1.21999  last_update 13\n",
      "train: iter 211  trainloss -1.02286  validloss -1.12346±0.00000  bestvalidloss -1.21999  last_update 14\n",
      "train: iter 212  trainloss -0.96360  validloss -1.12209±0.00000  bestvalidloss -1.21999  last_update 15\n",
      "train: iter 213  trainloss -1.02545  validloss -1.12783±0.00000  bestvalidloss -1.21999  last_update 16\n",
      "train: iter 214  trainloss -1.02741  validloss -0.98758±0.00000  bestvalidloss -1.21999  last_update 17\n",
      "train: iter 215  trainloss -1.00282  validloss -1.10130±0.00000  bestvalidloss -1.21999  last_update 18\n",
      "train: iter 216  trainloss -1.01671  validloss -0.99028±0.00000  bestvalidloss -1.21999  last_update 19\n",
      "train: iter 217  trainloss -1.01455  validloss -0.97995±0.00000  bestvalidloss -1.21999  last_update 20\n",
      "train: iter 218  trainloss -1.02235  validloss -1.15885±0.00000  bestvalidloss -1.21999  last_update 21\n",
      "train: iter 219  trainloss -0.98664  validloss -1.11468±0.00000  bestvalidloss -1.21999  last_update 22\n",
      "train: iter 220  trainloss -1.06954  validloss -1.10635±0.00000  bestvalidloss -1.21999  last_update 23\n",
      "train: iter 221  trainloss -0.98204  validloss -1.07415±0.00000  bestvalidloss -1.21999  last_update 24\n",
      "train: iter 222  trainloss -1.01222  validloss -1.11786±0.00000  bestvalidloss -1.21999  last_update 25\n",
      "train: iter 223  trainloss -1.04832  validloss -1.15220±0.00000  bestvalidloss -1.21999  last_update 26\n",
      "train: iter 224  trainloss -1.02171  validloss -1.04963±0.00000  bestvalidloss -1.21999  last_update 27\n",
      "train: iter 225  trainloss -0.99425  validloss -1.10211±0.00000  bestvalidloss -1.21999  last_update 28\n",
      "train: iter 226  trainloss -1.03753  validloss -1.01329±0.00000  bestvalidloss -1.21999  last_update 29\n",
      "train: iter 227  trainloss -1.01469  validloss -1.09898±0.00000  bestvalidloss -1.21999  last_update 30\n",
      "train: iter 228  trainloss -1.06534  validloss -1.16944±0.00000  bestvalidloss -1.21999  last_update 31\n",
      "train: iter 229  trainloss -1.00006  validloss -1.09746±0.00000  bestvalidloss -1.21999  last_update 32\n",
      "train: iter 230  trainloss -1.05273  validloss -1.15077±0.00000  bestvalidloss -1.21999  last_update 33\n",
      "train: iter 231  trainloss -0.99997  validloss -1.17060±0.00000  bestvalidloss -1.21999  last_update 34\n",
      "train: iter 232  trainloss -1.02987  validloss -1.13978±0.00000  bestvalidloss -1.21999  last_update 35\n",
      "train: iter 233  trainloss -1.00006  validloss -1.10386±0.00000  bestvalidloss -1.21999  last_update 36\n",
      "train: iter 234  trainloss -1.00633  validloss -1.07696±0.00000  bestvalidloss -1.21999  last_update 37\n",
      "train: iter 235  trainloss -1.05448  validloss -1.16104±0.00000  bestvalidloss -1.21999  last_update 38\n",
      "train: iter 236  trainloss -1.00250  validloss -1.18336±0.00000  bestvalidloss -1.21999  last_update 39\n",
      "train: iter 237  trainloss -1.01935  validloss -1.15090±0.00000  bestvalidloss -1.21999  last_update 40\n",
      "train: iter 238  trainloss -1.00242  validloss -1.09075±0.00000  bestvalidloss -1.21999  last_update 41\n",
      "train: iter 239  trainloss -1.03673  validloss -1.14632±0.00000  bestvalidloss -1.21999  last_update 42\n",
      "train: iter 240  trainloss -1.02735  validloss -1.03664±0.00000  bestvalidloss -1.21999  last_update 43\n",
      "train: iter 241  trainloss -0.99025  validloss -1.17774±0.00000  bestvalidloss -1.21999  last_update 44\n",
      "train: iter 242  trainloss -1.00070  validloss -1.13561±0.00000  bestvalidloss -1.21999  last_update 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 243  trainloss -1.00570  validloss -1.18178±0.00000  bestvalidloss -1.21999  last_update 46\n",
      "train: iter 244  trainloss -1.01102  validloss -1.04039±0.00000  bestvalidloss -1.21999  last_update 47\n",
      "train: iter 245  trainloss -1.01538  validloss -1.11874±0.00000  bestvalidloss -1.21999  last_update 48\n",
      "train: iter 246  trainloss -1.05685  validloss -1.07913±0.00000  bestvalidloss -1.21999  last_update 49\n",
      "train: iter 247  trainloss -1.05301  validloss -0.96647±0.00000  bestvalidloss -1.21999  last_update 50\n",
      "train: iter 248  trainloss -1.01099  validloss -0.99322±0.00000  bestvalidloss -1.21999  last_update 51\n",
      "train: iter 249  trainloss -1.01873  validloss -1.17338±0.00000  bestvalidloss -1.21999  last_update 52\n",
      "train: iter 250  trainloss -1.00335  validloss -1.15564±0.00000  bestvalidloss -1.21999  last_update 53\n",
      "train: iter 251  trainloss -1.00489  validloss -1.01951±0.00000  bestvalidloss -1.21999  last_update 54\n",
      "train: iter 252  trainloss -1.03295  validloss -0.98441±0.00000  bestvalidloss -1.21999  last_update 55\n",
      "train: iter 253  trainloss -1.05282  validloss -1.12871±0.00000  bestvalidloss -1.21999  last_update 56\n",
      "train: iter 254  trainloss -1.02628  validloss -0.99995±0.00000  bestvalidloss -1.21999  last_update 57\n",
      "train: iter 255  trainloss -1.02383  validloss -1.15402±0.00000  bestvalidloss -1.21999  last_update 58\n",
      "train: iter 256  trainloss -1.00970  validloss -1.06918±0.00000  bestvalidloss -1.21999  last_update 59\n",
      "train: iter 257  trainloss -1.06215  validloss -1.05908±0.00000  bestvalidloss -1.21999  last_update 60\n",
      "train: iter 258  trainloss -1.01635  validloss -1.07502±0.00000  bestvalidloss -1.21999  last_update 61\n",
      "train: iter 259  trainloss -1.00698  validloss -1.00965±0.00000  bestvalidloss -1.21999  last_update 62\n",
      "train: iter 260  trainloss -1.00321  validloss -1.09617±0.00000  bestvalidloss -1.21999  last_update 63\n",
      "train: iter 261  trainloss -1.02305  validloss -1.10809±0.00000  bestvalidloss -1.21999  last_update 64\n",
      "train: iter 262  trainloss -1.02315  validloss -1.11754±0.00000  bestvalidloss -1.21999  last_update 65\n",
      "train: iter 263  trainloss -1.01064  validloss -1.12985±0.00000  bestvalidloss -1.21999  last_update 66\n",
      "train: iter 264  trainloss -0.98995  validloss -1.13691±0.00000  bestvalidloss -1.21999  last_update 67\n",
      "train: iter 265  trainloss -1.00186  validloss -1.11254±0.00000  bestvalidloss -1.21999  last_update 68\n",
      "train: iter 266  trainloss -1.01714  validloss -1.14164±0.00000  bestvalidloss -1.21999  last_update 69\n",
      "train: iter 267  trainloss -1.03723  validloss -1.11351±0.00000  bestvalidloss -1.21999  last_update 70\n",
      "train: iter 268  trainloss -0.99345  validloss -1.15537±0.00000  bestvalidloss -1.21999  last_update 71\n",
      "train: iter 269  trainloss -1.01105  validloss -1.07770±0.00000  bestvalidloss -1.21999  last_update 72\n",
      "train: iter 270  trainloss -1.02487  validloss -1.11992±0.00000  bestvalidloss -1.21999  last_update 73\n",
      "train: iter 271  trainloss -1.01542  validloss -1.13045±0.00000  bestvalidloss -1.21999  last_update 74\n",
      "train: iter 272  trainloss -1.03432  validloss -1.06637±0.00000  bestvalidloss -1.21999  last_update 75\n",
      "train: iter 273  trainloss -1.02156  validloss -1.18275±0.00000  bestvalidloss -1.21999  last_update 76\n",
      "train: iter 274  trainloss -1.04845  validloss -1.12900±0.00000  bestvalidloss -1.21999  last_update 77\n",
      "train: iter 275  trainloss -1.01132  validloss -1.08459±0.00000  bestvalidloss -1.21999  last_update 78\n",
      "train: iter 276  trainloss -1.01194  validloss -1.09855±0.00000  bestvalidloss -1.21999  last_update 79\n",
      "train: iter 277  trainloss -0.98253  validloss -1.15831±0.00000  bestvalidloss -1.21999  last_update 80\n",
      "train: iter 278  trainloss -1.04819  validloss -1.08316±0.00000  bestvalidloss -1.21999  last_update 81\n",
      "train: iter 279  trainloss -1.02292  validloss -1.08149±0.00000  bestvalidloss -1.21999  last_update 82\n",
      "train: iter 280  trainloss -1.03028  validloss -1.04056±0.00000  bestvalidloss -1.21999  last_update 83\n",
      "train: iter 281  trainloss -1.02244  validloss -1.15588±0.00000  bestvalidloss -1.21999  last_update 84\n",
      "train: iter 282  trainloss -0.99678  validloss -1.11274±0.00000  bestvalidloss -1.21999  last_update 85\n",
      "train: iter 283  trainloss -1.02321  validloss -1.09222±0.00000  bestvalidloss -1.21999  last_update 86\n",
      "train: iter 284  trainloss -0.98698  validloss -1.07751±0.00000  bestvalidloss -1.21999  last_update 87\n",
      "train: iter 285  trainloss -1.03541  validloss -1.10207±0.00000  bestvalidloss -1.21999  last_update 88\n",
      "train: iter 286  trainloss -1.01399  validloss -1.10803±0.00000  bestvalidloss -1.21999  last_update 89\n",
      "train: iter 287  trainloss -1.00094  validloss -1.01660±0.00000  bestvalidloss -1.21999  last_update 90\n",
      "train: iter 288  trainloss -0.96940  validloss -1.01907±0.00000  bestvalidloss -1.21999  last_update 91\n",
      "train: iter 289  trainloss -1.03652  validloss -1.18796±0.00000  bestvalidloss -1.21999  last_update 92\n",
      "train: iter 290  trainloss -1.02306  validloss -1.14446±0.00000  bestvalidloss -1.21999  last_update 93\n",
      "train: iter 291  trainloss -1.00706  validloss -1.09607±0.00000  bestvalidloss -1.21999  last_update 94\n",
      "train: iter 292  trainloss -0.98626  validloss -1.11134±0.00000  bestvalidloss -1.21999  last_update 95\n",
      "train: iter 293  trainloss -1.03403  validloss -1.07085±0.00000  bestvalidloss -1.21999  last_update 96\n",
      "train: iter 294  trainloss -0.99024  validloss -1.12244±0.00000  bestvalidloss -1.21999  last_update 97\n",
      "train: iter 295  trainloss -1.06994  validloss -1.11158±0.00000  bestvalidloss -1.21999  last_update 98\n",
      "train: iter 296  trainloss -1.05277  validloss -1.10389±0.00000  bestvalidloss -1.21999  last_update 99\n",
      "train: iter 297  trainloss -1.00589  validloss -1.11425±0.00000  bestvalidloss -1.21999  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.6967, -3.5203, -2.6963, -5.0048], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 72.59647  validloss 75.94363±0.00000  bestvalidloss 75.94363  last_update 0\n",
      "train: iter 1  trainloss 53.85311  validloss 59.98156±0.00000  bestvalidloss 59.98156  last_update 0\n",
      "train: iter 2  trainloss 38.12986  validloss 41.57259±0.00000  bestvalidloss 41.57259  last_update 0\n",
      "train: iter 3  trainloss 29.13618  validloss 31.04668±0.00000  bestvalidloss 31.04668  last_update 0\n",
      "train: iter 4  trainloss 23.40203  validloss 24.28565±0.00000  bestvalidloss 24.28565  last_update 0\n",
      "train: iter 5  trainloss 19.34425  validloss 20.21054±0.00000  bestvalidloss 20.21054  last_update 0\n",
      "train: iter 6  trainloss 16.38047  validloss 17.17107±0.00000  bestvalidloss 17.17107  last_update 0\n",
      "train: iter 7  trainloss 14.08745  validloss 14.72715±0.00000  bestvalidloss 14.72715  last_update 0\n",
      "train: iter 8  trainloss 12.41216  validloss 13.23228±0.00000  bestvalidloss 13.23228  last_update 0\n",
      "train: iter 9  trainloss 11.13069  validloss 12.03227±0.00000  bestvalidloss 12.03227  last_update 0\n",
      "train: iter 10  trainloss 10.15481  validloss 11.11933±0.00000  bestvalidloss 11.11933  last_update 0\n",
      "train: iter 11  trainloss 9.31669  validloss 10.56670±0.00000  bestvalidloss 10.56670  last_update 0\n",
      "train: iter 12  trainloss 8.68157  validloss 9.95285±0.00000  bestvalidloss 9.95285  last_update 0\n",
      "train: iter 13  trainloss 8.11402  validloss 9.58514±0.00000  bestvalidloss 9.58514  last_update 0\n",
      "train: iter 14  trainloss 7.53375  validloss 9.05498±0.00000  bestvalidloss 9.05498  last_update 0\n",
      "train: iter 15  trainloss 7.04708  validloss 8.61200±0.00000  bestvalidloss 8.61200  last_update 0\n",
      "train: iter 16  trainloss 6.54605  validloss 8.35039±0.00000  bestvalidloss 8.35039  last_update 0\n",
      "train: iter 17  trainloss 6.18701  validloss 8.09052±0.00000  bestvalidloss 8.09052  last_update 0\n",
      "train: iter 18  trainloss 6.00710  validloss 7.84725±0.00000  bestvalidloss 7.84725  last_update 0\n",
      "train: iter 19  trainloss 5.82362  validloss 7.79934±0.00000  bestvalidloss 7.79934  last_update 0\n",
      "train: iter 20  trainloss 5.66526  validloss 7.58374±0.00000  bestvalidloss 7.58374  last_update 0\n",
      "train: iter 21  trainloss 5.59576  validloss 7.54575±0.00000  bestvalidloss 7.54575  last_update 0\n",
      "train: iter 22  trainloss 5.44170  validloss 7.40607±0.00000  bestvalidloss 7.40607  last_update 0\n",
      "train: iter 23  trainloss 5.39157  validloss 7.46652±0.00000  bestvalidloss 7.40607  last_update 1\n",
      "train: iter 24  trainloss 5.33794  validloss 7.24840±0.00000  bestvalidloss 7.24840  last_update 0\n",
      "train: iter 25  trainloss 5.26204  validloss 7.06619±0.00000  bestvalidloss 7.06619  last_update 0\n",
      "train: iter 26  trainloss 5.15838  validloss 7.06542±0.00000  bestvalidloss 7.06542  last_update 0\n",
      "train: iter 27  trainloss 5.15942  validloss 7.01876±0.00000  bestvalidloss 7.01876  last_update 0\n",
      "train: iter 28  trainloss 5.07604  validloss 6.81041±0.00000  bestvalidloss 6.81041  last_update 0\n",
      "train: iter 29  trainloss 5.06568  validloss 6.79586±0.00000  bestvalidloss 6.79586  last_update 0\n",
      "train: iter 30  trainloss 4.99908  validloss 6.86258±0.00000  bestvalidloss 6.79586  last_update 1\n",
      "train: iter 31  trainloss 4.97565  validloss 6.67849±0.00000  bestvalidloss 6.67849  last_update 0\n",
      "train: iter 32  trainloss 4.88920  validloss 6.51171±0.00000  bestvalidloss 6.51171  last_update 0\n",
      "train: iter 33  trainloss 4.85154  validloss 6.61045±0.00000  bestvalidloss 6.51171  last_update 1\n",
      "train: iter 34  trainloss 4.91117  validloss 6.49060±0.00000  bestvalidloss 6.49060  last_update 0\n",
      "train: iter 35  trainloss 4.77868  validloss 6.33815±0.00000  bestvalidloss 6.33815  last_update 0\n",
      "train: iter 36  trainloss 4.84369  validloss 6.57117±0.00000  bestvalidloss 6.33815  last_update 1\n",
      "train: iter 37  trainloss 4.81911  validloss 6.29519±0.00000  bestvalidloss 6.29519  last_update 0\n",
      "train: iter 38  trainloss 4.70847  validloss 6.38328±0.00000  bestvalidloss 6.29519  last_update 1\n",
      "train: iter 39  trainloss 4.72131  validloss 6.35218±0.00000  bestvalidloss 6.29519  last_update 2\n",
      "train: iter 40  trainloss 4.65718  validloss 6.32751±0.00000  bestvalidloss 6.29519  last_update 3\n",
      "train: iter 41  trainloss 4.66713  validloss 6.24182±0.00000  bestvalidloss 6.24182  last_update 0\n",
      "train: iter 42  trainloss 4.64334  validloss 6.11767±0.00000  bestvalidloss 6.11767  last_update 0\n",
      "train: iter 43  trainloss 4.56913  validloss 6.37398±0.00000  bestvalidloss 6.11767  last_update 1\n",
      "train: iter 44  trainloss 4.58040  validloss 5.97036±0.00000  bestvalidloss 5.97036  last_update 0\n",
      "train: iter 45  trainloss 4.48462  validloss 6.02300±0.00000  bestvalidloss 5.97036  last_update 1\n",
      "train: iter 46  trainloss 4.58606  validloss 6.07402±0.00000  bestvalidloss 5.97036  last_update 2\n",
      "train: iter 47  trainloss 4.51177  validloss 6.08921±0.00000  bestvalidloss 5.97036  last_update 3\n",
      "train: iter 48  trainloss 4.45543  validloss 5.89041±0.00000  bestvalidloss 5.89041  last_update 0\n",
      "train: iter 49  trainloss 4.47832  validloss 5.95597±0.00000  bestvalidloss 5.89041  last_update 1\n",
      "train: iter 50  trainloss 4.41083  validloss 6.07375±0.00000  bestvalidloss 5.89041  last_update 2\n",
      "train: iter 51  trainloss 4.40291  validloss 5.89931±0.00000  bestvalidloss 5.89041  last_update 3\n",
      "train: iter 52  trainloss 4.38563  validloss 6.13055±0.00000  bestvalidloss 5.89041  last_update 4\n",
      "train: iter 53  trainloss 4.36551  validloss 5.87956±0.00000  bestvalidloss 5.87956  last_update 0\n",
      "train: iter 54  trainloss 4.33593  validloss 5.76179±0.00000  bestvalidloss 5.76179  last_update 0\n",
      "train: iter 55  trainloss 4.25646  validloss 5.85107±0.00000  bestvalidloss 5.76179  last_update 1\n",
      "train: iter 56  trainloss 4.25367  validloss 5.82182±0.00000  bestvalidloss 5.76179  last_update 2\n",
      "train: iter 57  trainloss 4.19674  validloss 5.71892±0.00000  bestvalidloss 5.71892  last_update 0\n",
      "train: iter 58  trainloss 4.21569  validloss 5.72638±0.00000  bestvalidloss 5.71892  last_update 1\n",
      "train: iter 59  trainloss 4.19995  validloss 5.81463±0.00000  bestvalidloss 5.71892  last_update 2\n",
      "train: iter 60  trainloss 4.19523  validloss 5.87034±0.00000  bestvalidloss 5.71892  last_update 3\n",
      "train: iter 61  trainloss 4.17347  validloss 5.77898±0.00000  bestvalidloss 5.71892  last_update 4\n",
      "train: iter 62  trainloss 4.16340  validloss 5.83902±0.00000  bestvalidloss 5.71892  last_update 5\n",
      "train: iter 63  trainloss 4.22991  validloss 5.79756±0.00000  bestvalidloss 5.71892  last_update 6\n",
      "train: iter 64  trainloss 4.04334  validloss 5.77495±0.00000  bestvalidloss 5.71892  last_update 7\n",
      "train: iter 65  trainloss 4.15825  validloss 5.66945±0.00000  bestvalidloss 5.66945  last_update 0\n",
      "train: iter 66  trainloss 4.10487  validloss 5.77984±0.00000  bestvalidloss 5.66945  last_update 1\n",
      "train: iter 67  trainloss 4.12583  validloss 5.74619±0.00000  bestvalidloss 5.66945  last_update 2\n",
      "train: iter 68  trainloss 4.04373  validloss 5.78682±0.00000  bestvalidloss 5.66945  last_update 3\n",
      "train: iter 69  trainloss 4.07861  validloss 5.65754±0.00000  bestvalidloss 5.65754  last_update 0\n",
      "train: iter 70  trainloss 4.08941  validloss 5.71426±0.00000  bestvalidloss 5.65754  last_update 1\n",
      "train: iter 71  trainloss 4.09057  validloss 5.77862±0.00000  bestvalidloss 5.65754  last_update 2\n",
      "train: iter 72  trainloss 4.11991  validloss 5.81185±0.00000  bestvalidloss 5.65754  last_update 3\n",
      "train: iter 73  trainloss 4.06114  validloss 5.66924±0.00000  bestvalidloss 5.65754  last_update 4\n",
      "train: iter 74  trainloss 4.03514  validloss 5.64936±0.00000  bestvalidloss 5.64936  last_update 0\n",
      "train: iter 75  trainloss 4.03397  validloss 5.79238±0.00000  bestvalidloss 5.64936  last_update 1\n",
      "train: iter 76  trainloss 4.03582  validloss 5.75112±0.00000  bestvalidloss 5.64936  last_update 2\n",
      "train: iter 77  trainloss 4.05141  validloss 5.80899±0.00000  bestvalidloss 5.64936  last_update 3\n",
      "train: iter 78  trainloss 3.98318  validloss 5.74515±0.00000  bestvalidloss 5.64936  last_update 4\n",
      "train: iter 79  trainloss 4.00955  validloss 5.67759±0.00000  bestvalidloss 5.64936  last_update 5\n",
      "train: iter 80  trainloss 4.07373  validloss 5.82707±0.00000  bestvalidloss 5.64936  last_update 6\n",
      "train: iter 81  trainloss 4.01437  validloss 5.66436±0.00000  bestvalidloss 5.64936  last_update 7\n",
      "train: iter 82  trainloss 4.01045  validloss 5.65215±0.00000  bestvalidloss 5.64936  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 4.01382  validloss 5.54500±0.00000  bestvalidloss 5.54500  last_update 0\n",
      "train: iter 84  trainloss 4.02261  validloss 5.70381±0.00000  bestvalidloss 5.54500  last_update 1\n",
      "train: iter 85  trainloss 3.98222  validloss 5.52451±0.00000  bestvalidloss 5.52451  last_update 0\n",
      "train: iter 86  trainloss 4.02555  validloss 5.79789±0.00000  bestvalidloss 5.52451  last_update 1\n",
      "train: iter 87  trainloss 3.99560  validloss 5.72679±0.00000  bestvalidloss 5.52451  last_update 2\n",
      "train: iter 88  trainloss 4.03406  validloss 5.60791±0.00000  bestvalidloss 5.52451  last_update 3\n",
      "train: iter 89  trainloss 4.01298  validloss 5.57816±0.00000  bestvalidloss 5.52451  last_update 4\n",
      "train: iter 90  trainloss 4.01612  validloss 5.71379±0.00000  bestvalidloss 5.52451  last_update 5\n",
      "train: iter 91  trainloss 4.03272  validloss 5.61010±0.00000  bestvalidloss 5.52451  last_update 6\n",
      "train: iter 92  trainloss 3.97114  validloss 5.57794±0.00000  bestvalidloss 5.52451  last_update 7\n",
      "train: iter 93  trainloss 3.94270  validloss 5.72489±0.00000  bestvalidloss 5.52451  last_update 8\n",
      "train: iter 94  trainloss 3.98209  validloss 5.59799±0.00000  bestvalidloss 5.52451  last_update 9\n",
      "train: iter 95  trainloss 4.02542  validloss 5.60049±0.00000  bestvalidloss 5.52451  last_update 10\n",
      "train: iter 96  trainloss 4.00487  validloss 5.44400±0.00000  bestvalidloss 5.44400  last_update 0\n",
      "train: iter 97  trainloss 4.00370  validloss 5.88860±0.00000  bestvalidloss 5.44400  last_update 1\n",
      "train: iter 98  trainloss 4.00144  validloss 5.67787±0.00000  bestvalidloss 5.44400  last_update 2\n",
      "train: iter 99  trainloss 4.00148  validloss 5.64921±0.00000  bestvalidloss 5.44400  last_update 3\n",
      "train: iter 100  trainloss 3.98180  validloss 5.65589±0.00000  bestvalidloss 5.44400  last_update 4\n",
      "train: iter 101  trainloss 3.98360  validloss 5.76140±0.00000  bestvalidloss 5.44400  last_update 5\n",
      "train: iter 102  trainloss 3.97490  validloss 5.62941±0.00000  bestvalidloss 5.44400  last_update 6\n",
      "train: iter 103  trainloss 3.94840  validloss 5.65388±0.00000  bestvalidloss 5.44400  last_update 7\n",
      "train: iter 104  trainloss 4.01008  validloss 5.98414±0.00000  bestvalidloss 5.44400  last_update 8\n",
      "train: iter 105  trainloss 3.98503  validloss 5.53425±0.00000  bestvalidloss 5.44400  last_update 9\n",
      "train: iter 106  trainloss 3.98543  validloss 5.56928±0.00000  bestvalidloss 5.44400  last_update 10\n",
      "train: iter 107  trainloss 3.95461  validloss 5.78817±0.00000  bestvalidloss 5.44400  last_update 11\n",
      "train: iter 108  trainloss 4.01276  validloss 5.72126±0.00000  bestvalidloss 5.44400  last_update 12\n",
      "train: iter 109  trainloss 3.96161  validloss 5.87616±0.00000  bestvalidloss 5.44400  last_update 13\n",
      "train: iter 110  trainloss 3.93310  validloss 5.59191±0.00000  bestvalidloss 5.44400  last_update 14\n",
      "train: iter 111  trainloss 3.96551  validloss 5.65634±0.00000  bestvalidloss 5.44400  last_update 15\n",
      "train: iter 112  trainloss 4.04491  validloss 5.69090±0.00000  bestvalidloss 5.44400  last_update 16\n",
      "train: iter 113  trainloss 3.95318  validloss 5.63328±0.00000  bestvalidloss 5.44400  last_update 17\n",
      "train: iter 114  trainloss 3.96574  validloss 5.51067±0.00000  bestvalidloss 5.44400  last_update 18\n",
      "train: iter 115  trainloss 3.98707  validloss 5.65778±0.00000  bestvalidloss 5.44400  last_update 19\n",
      "train: iter 116  trainloss 3.99294  validloss 5.80129±0.00000  bestvalidloss 5.44400  last_update 20\n",
      "train: iter 117  trainloss 3.95430  validloss 5.63669±0.00000  bestvalidloss 5.44400  last_update 21\n",
      "train: iter 118  trainloss 3.94133  validloss 5.70144±0.00000  bestvalidloss 5.44400  last_update 22\n",
      "train: iter 119  trainloss 3.93328  validloss 5.68015±0.00000  bestvalidloss 5.44400  last_update 23\n",
      "train: iter 120  trainloss 3.95927  validloss 5.84438±0.00000  bestvalidloss 5.44400  last_update 24\n",
      "train: iter 121  trainloss 3.92623  validloss 5.58561±0.00000  bestvalidloss 5.44400  last_update 25\n",
      "train: iter 122  trainloss 3.89503  validloss 5.69962±0.00000  bestvalidloss 5.44400  last_update 26\n",
      "train: iter 123  trainloss 3.95723  validloss 5.87664±0.00000  bestvalidloss 5.44400  last_update 27\n",
      "train: iter 124  trainloss 3.94243  validloss 5.66583±0.00000  bestvalidloss 5.44400  last_update 28\n",
      "train: iter 125  trainloss 3.95008  validloss 5.75138±0.00000  bestvalidloss 5.44400  last_update 29\n",
      "train: iter 126  trainloss 3.96711  validloss 5.63585±0.00000  bestvalidloss 5.44400  last_update 30\n",
      "train: iter 127  trainloss 3.92680  validloss 5.66915±0.00000  bestvalidloss 5.44400  last_update 31\n",
      "train: iter 128  trainloss 3.94780  validloss 5.63778±0.00000  bestvalidloss 5.44400  last_update 32\n",
      "train: iter 129  trainloss 3.97800  validloss 5.61545±0.00000  bestvalidloss 5.44400  last_update 33\n",
      "train: iter 130  trainloss 3.93390  validloss 5.64781±0.00000  bestvalidloss 5.44400  last_update 34\n",
      "train: iter 131  trainloss 3.94266  validloss 6.02914±0.00000  bestvalidloss 5.44400  last_update 35\n",
      "train: iter 132  trainloss 3.93630  validloss 5.50946±0.00000  bestvalidloss 5.44400  last_update 36\n",
      "train: iter 133  trainloss 3.94815  validloss 5.58227±0.00000  bestvalidloss 5.44400  last_update 37\n",
      "train: iter 134  trainloss 3.93328  validloss 5.67342±0.00000  bestvalidloss 5.44400  last_update 38\n",
      "train: iter 135  trainloss 3.98934  validloss 5.59202±0.00000  bestvalidloss 5.44400  last_update 39\n",
      "train: iter 136  trainloss 3.90539  validloss 5.82282±0.00000  bestvalidloss 5.44400  last_update 40\n",
      "train: iter 137  trainloss 3.90515  validloss 5.68544±0.00000  bestvalidloss 5.44400  last_update 41\n",
      "train: iter 138  trainloss 3.96900  validloss 5.69465±0.00000  bestvalidloss 5.44400  last_update 42\n",
      "train: iter 139  trainloss 3.93986  validloss 5.63345±0.00000  bestvalidloss 5.44400  last_update 43\n",
      "train: iter 140  trainloss 3.93743  validloss 5.58466±0.00000  bestvalidloss 5.44400  last_update 44\n",
      "train: iter 141  trainloss 3.93847  validloss 5.53140±0.00000  bestvalidloss 5.44400  last_update 45\n",
      "train: iter 142  trainloss 3.94504  validloss 5.57436±0.00000  bestvalidloss 5.44400  last_update 46\n",
      "train: iter 143  trainloss 3.92320  validloss 5.56916±0.00000  bestvalidloss 5.44400  last_update 47\n",
      "train: iter 144  trainloss 3.94610  validloss 5.55822±0.00000  bestvalidloss 5.44400  last_update 48\n",
      "train: iter 145  trainloss 3.91838  validloss 5.61062±0.00000  bestvalidloss 5.44400  last_update 49\n",
      "train: iter 146  trainloss 3.95300  validloss 5.73386±0.00000  bestvalidloss 5.44400  last_update 50\n",
      "train: iter 147  trainloss 3.92398  validloss 5.66147±0.00000  bestvalidloss 5.44400  last_update 51\n",
      "train: iter 148  trainloss 3.92665  validloss 5.51487±0.00000  bestvalidloss 5.44400  last_update 52\n",
      "train: iter 149  trainloss 3.89163  validloss 5.72210±0.00000  bestvalidloss 5.44400  last_update 53\n",
      "train: iter 150  trainloss 3.94169  validloss 5.69331±0.00000  bestvalidloss 5.44400  last_update 54\n",
      "train: iter 151  trainloss 3.91227  validloss 5.62259±0.00000  bestvalidloss 5.44400  last_update 55\n",
      "train: iter 152  trainloss 3.96021  validloss 5.71489±0.00000  bestvalidloss 5.44400  last_update 56\n",
      "train: iter 153  trainloss 3.90728  validloss 5.74188±0.00000  bestvalidloss 5.44400  last_update 57\n",
      "train: iter 154  trainloss 3.94655  validloss 5.55725±0.00000  bestvalidloss 5.44400  last_update 58\n",
      "train: iter 155  trainloss 3.90128  validloss 5.60493±0.00000  bestvalidloss 5.44400  last_update 59\n",
      "train: iter 156  trainloss 3.91816  validloss 5.63627±0.00000  bestvalidloss 5.44400  last_update 60\n",
      "train: iter 157  trainloss 3.99657  validloss 5.70899±0.00000  bestvalidloss 5.44400  last_update 61\n",
      "train: iter 158  trainloss 3.86950  validloss 5.54222±0.00000  bestvalidloss 5.44400  last_update 62\n",
      "train: iter 159  trainloss 3.92580  validloss 5.62761±0.00000  bestvalidloss 5.44400  last_update 63\n",
      "train: iter 160  trainloss 4.01089  validloss 5.61055±0.00000  bestvalidloss 5.44400  last_update 64\n",
      "train: iter 161  trainloss 3.89966  validloss 5.63669±0.00000  bestvalidloss 5.44400  last_update 65\n",
      "train: iter 162  trainloss 3.91198  validloss 5.73090±0.00000  bestvalidloss 5.44400  last_update 66\n",
      "train: iter 163  trainloss 3.96181  validloss 5.75104±0.00000  bestvalidloss 5.44400  last_update 67\n",
      "train: iter 164  trainloss 3.92662  validloss 5.64612±0.00000  bestvalidloss 5.44400  last_update 68\n",
      "train: iter 165  trainloss 3.88109  validloss 5.67742±0.00000  bestvalidloss 5.44400  last_update 69\n",
      "train: iter 166  trainloss 3.88455  validloss 5.51228±0.00000  bestvalidloss 5.44400  last_update 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 4.01112  validloss 5.79500±0.00000  bestvalidloss 5.44400  last_update 71\n",
      "train: iter 168  trainloss 3.91704  validloss 5.74537±0.00000  bestvalidloss 5.44400  last_update 72\n",
      "train: iter 169  trainloss 3.89557  validloss 5.74345±0.00000  bestvalidloss 5.44400  last_update 73\n",
      "train: iter 170  trainloss 3.89397  validloss 5.55257±0.00000  bestvalidloss 5.44400  last_update 74\n",
      "train: iter 171  trainloss 3.89908  validloss 5.56228±0.00000  bestvalidloss 5.44400  last_update 75\n",
      "train: iter 172  trainloss 3.90697  validloss 5.52669±0.00000  bestvalidloss 5.44400  last_update 76\n",
      "train: iter 173  trainloss 3.91182  validloss 5.61052±0.00000  bestvalidloss 5.44400  last_update 77\n",
      "train: iter 174  trainloss 3.96022  validloss 5.51277±0.00000  bestvalidloss 5.44400  last_update 78\n",
      "train: iter 175  trainloss 3.93901  validloss 5.61847±0.00000  bestvalidloss 5.44400  last_update 79\n",
      "train: iter 176  trainloss 3.90544  validloss 5.59007±0.00000  bestvalidloss 5.44400  last_update 80\n",
      "train: iter 177  trainloss 3.98293  validloss 5.62320±0.00000  bestvalidloss 5.44400  last_update 81\n",
      "train: iter 178  trainloss 3.88810  validloss 5.63279±0.00000  bestvalidloss 5.44400  last_update 82\n",
      "train: iter 179  trainloss 3.87906  validloss 5.55306±0.00000  bestvalidloss 5.44400  last_update 83\n",
      "train: iter 180  trainloss 3.96611  validloss 5.58822±0.00000  bestvalidloss 5.44400  last_update 84\n",
      "train: iter 181  trainloss 3.92436  validloss 5.59784±0.00000  bestvalidloss 5.44400  last_update 85\n",
      "train: iter 182  trainloss 3.90071  validloss 5.53436±0.00000  bestvalidloss 5.44400  last_update 86\n",
      "train: iter 183  trainloss 3.87360  validloss 5.57391±0.00000  bestvalidloss 5.44400  last_update 87\n",
      "train: iter 184  trainloss 3.88795  validloss 5.57345±0.00000  bestvalidloss 5.44400  last_update 88\n",
      "train: iter 185  trainloss 3.88932  validloss 5.55659±0.00000  bestvalidloss 5.44400  last_update 89\n",
      "train: iter 186  trainloss 3.88398  validloss 5.65527±0.00000  bestvalidloss 5.44400  last_update 90\n",
      "train: iter 187  trainloss 3.85576  validloss 5.55904±0.00000  bestvalidloss 5.44400  last_update 91\n",
      "train: iter 188  trainloss 3.92831  validloss 5.68345±0.00000  bestvalidloss 5.44400  last_update 92\n",
      "train: iter 189  trainloss 3.89170  validloss 5.74525±0.00000  bestvalidloss 5.44400  last_update 93\n",
      "train: iter 190  trainloss 3.88645  validloss 5.53595±0.00000  bestvalidloss 5.44400  last_update 94\n",
      "train: iter 191  trainloss 3.88804  validloss 5.55512±0.00000  bestvalidloss 5.44400  last_update 95\n",
      "train: iter 192  trainloss 3.86019  validloss 5.63272±0.00000  bestvalidloss 5.44400  last_update 96\n",
      "train: iter 193  trainloss 3.87594  validloss 5.56257±0.00000  bestvalidloss 5.44400  last_update 97\n",
      "train: iter 194  trainloss 3.89663  validloss 5.82239±0.00000  bestvalidloss 5.44400  last_update 98\n",
      "train: iter 195  trainloss 3.87984  validloss 5.57932±0.00000  bestvalidloss 5.44400  last_update 99\n",
      "train: iter 196  trainloss 3.88844  validloss 5.59629±0.00000  bestvalidloss 5.44400  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-12.9182)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(8.5986)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.33380855681015925\n",
      "tensor([2.6833])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76489c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d299c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b22b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1d25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be9781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
