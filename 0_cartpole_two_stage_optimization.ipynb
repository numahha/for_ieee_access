{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)\n",
    "print(\"cfg_env\",cfg_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(6026.6948)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 48\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 474.14897  validloss 560.74474±0.00000  bestvalidloss 560.74474  last_update 0\n",
      "train: iter 1  trainloss 376.29080  validloss 324.25260±0.00000  bestvalidloss 324.25260  last_update 0\n",
      "train: iter 2  trainloss 253.38211  validloss 278.54825±0.00000  bestvalidloss 278.54825  last_update 0\n",
      "train: iter 3  trainloss 171.48385  validloss 205.30947±0.00000  bestvalidloss 205.30947  last_update 0\n",
      "train: iter 4  trainloss 165.27092  validloss 95.97467±0.00000  bestvalidloss 95.97467  last_update 0\n",
      "train: iter 5  trainloss 42.45579  validloss 26.57388±0.00000  bestvalidloss 26.57388  last_update 0\n",
      "train: iter 6  trainloss -16.79553  validloss -41.87044±0.00000  bestvalidloss -41.87044  last_update 0\n",
      "train: iter 7  trainloss -47.86424  validloss -45.53763±0.00000  bestvalidloss -45.53763  last_update 0\n",
      "train: iter 8  trainloss -98.23907  validloss -100.55161±0.00000  bestvalidloss -100.55161  last_update 0\n",
      "train: iter 9  trainloss -90.27027  validloss -155.33358±0.00000  bestvalidloss -155.33358  last_update 0\n",
      "train: iter 10  trainloss -129.68398  validloss -129.96455±0.00000  bestvalidloss -155.33358  last_update 1\n",
      "train: iter 11  trainloss -135.20720  validloss -192.03309±0.00000  bestvalidloss -192.03309  last_update 0\n",
      "train: iter 12  trainloss -143.64902  validloss 7.83874±0.00000  bestvalidloss -192.03309  last_update 1\n",
      "train: iter 13  trainloss -138.01533  validloss -54.68106±0.00000  bestvalidloss -192.03309  last_update 2\n",
      "train: iter 14  trainloss -204.68150  validloss -207.10032±0.00000  bestvalidloss -207.10032  last_update 0\n",
      "train: iter 15  trainloss -177.59919  validloss -143.73562±0.00000  bestvalidloss -207.10032  last_update 1\n",
      "train: iter 16  trainloss -221.91517  validloss -263.19347±0.00000  bestvalidloss -263.19347  last_update 0\n",
      "train: iter 17  trainloss -209.33588  validloss -273.46063±0.00000  bestvalidloss -273.46063  last_update 0\n",
      "train: iter 18  trainloss -204.16274  validloss -237.95932±0.00000  bestvalidloss -273.46063  last_update 1\n",
      "train: iter 19  trainloss -246.36349  validloss -309.94822±0.00000  bestvalidloss -309.94822  last_update 0\n",
      "train: iter 20  trainloss -275.41706  validloss -317.77489±0.00000  bestvalidloss -317.77489  last_update 0\n",
      "train: iter 21  trainloss -264.35277  validloss -350.09663±0.00000  bestvalidloss -350.09663  last_update 0\n",
      "train: iter 22  trainloss -284.85988  validloss -295.92981±0.00000  bestvalidloss -350.09663  last_update 1\n",
      "train: iter 23  trainloss -288.95853  validloss -300.59802±0.00000  bestvalidloss -350.09663  last_update 2\n",
      "train: iter 24  trainloss -302.56370  validloss -308.65211±0.00000  bestvalidloss -350.09663  last_update 3\n",
      "train: iter 25  trainloss -325.39404  validloss -348.20591±0.00000  bestvalidloss -350.09663  last_update 4\n",
      "train: iter 26  trainloss -313.69579  validloss -433.00148±0.00000  bestvalidloss -433.00148  last_update 0\n",
      "train: iter 27  trainloss -334.17899  validloss -409.48295±0.00000  bestvalidloss -433.00148  last_update 1\n",
      "train: iter 28  trainloss -344.99163  validloss -370.75255±0.00000  bestvalidloss -433.00148  last_update 2\n",
      "train: iter 29  trainloss -364.84039  validloss -315.13335±0.00000  bestvalidloss -433.00148  last_update 3\n",
      "train: iter 30  trainloss -364.83893  validloss -471.03992±0.00000  bestvalidloss -471.03992  last_update 0\n",
      "train: iter 31  trainloss -364.95148  validloss -301.02680±0.00000  bestvalidloss -471.03992  last_update 1\n",
      "train: iter 32  trainloss -392.57702  validloss -477.04253±0.00000  bestvalidloss -477.04253  last_update 0\n",
      "train: iter 33  trainloss -389.15630  validloss -487.99153±0.00000  bestvalidloss -487.99153  last_update 0\n",
      "train: iter 34  trainloss -330.01291  validloss -494.42828±0.00000  bestvalidloss -494.42828  last_update 0\n",
      "train: iter 35  trainloss -369.20090  validloss -161.38905±0.00000  bestvalidloss -494.42828  last_update 1\n",
      "train: iter 36  trainloss -396.31652  validloss -412.87136±0.00000  bestvalidloss -494.42828  last_update 2\n",
      "train: iter 37  trainloss -424.31350  validloss -465.99818±0.00000  bestvalidloss -494.42828  last_update 3\n",
      "train: iter 38  trainloss -332.90591  validloss -500.35137±0.00000  bestvalidloss -500.35137  last_update 0\n",
      "train: iter 39  trainloss -363.30796  validloss -290.06747±0.00000  bestvalidloss -500.35137  last_update 1\n",
      "train: iter 40  trainloss -433.04816  validloss -495.21380±0.00000  bestvalidloss -500.35137  last_update 2\n",
      "train: iter 41  trainloss -430.96393  validloss -505.79449±0.00000  bestvalidloss -505.79449  last_update 0\n",
      "train: iter 42  trainloss -429.05482  validloss -480.44471±0.00000  bestvalidloss -505.79449  last_update 1\n",
      "train: iter 43  trainloss -441.61946  validloss -480.01042±0.00000  bestvalidloss -505.79449  last_update 2\n",
      "train: iter 44  trainloss -429.95668  validloss -494.08110±0.00000  bestvalidloss -505.79449  last_update 3\n",
      "train: iter 45  trainloss -444.65346  validloss -479.36631±0.00000  bestvalidloss -505.79449  last_update 4\n",
      "train: iter 46  trainloss -452.14608  validloss -543.00860±0.00000  bestvalidloss -543.00860  last_update 0\n",
      "train: iter 47  trainloss -455.51400  validloss -505.48304±0.00000  bestvalidloss -543.00860  last_update 1\n",
      "train: iter 48  trainloss -427.50749  validloss -513.22068±0.00000  bestvalidloss -543.00860  last_update 2\n",
      "train: iter 49  trainloss -451.54592  validloss -524.54364±0.00000  bestvalidloss -543.00860  last_update 3\n",
      "train: iter 50  trainloss -447.40188  validloss -551.37735±0.00000  bestvalidloss -551.37735  last_update 0\n",
      "train: iter 51  trainloss -452.82698  validloss -519.92048±0.00000  bestvalidloss -551.37735  last_update 1\n",
      "train: iter 52  trainloss -475.06711  validloss -548.57956±0.00000  bestvalidloss -551.37735  last_update 2\n",
      "train: iter 53  trainloss -450.68256  validloss -563.87700±0.00000  bestvalidloss -563.87700  last_update 0\n",
      "train: iter 54  trainloss -435.87291  validloss -512.17891±0.00000  bestvalidloss -563.87700  last_update 1\n",
      "train: iter 55  trainloss -473.31786  validloss -547.05100±0.00000  bestvalidloss -563.87700  last_update 2\n",
      "train: iter 56  trainloss -477.54532  validloss -505.59839±0.00000  bestvalidloss -563.87700  last_update 3\n",
      "train: iter 57  trainloss -485.09564  validloss -573.06503±0.00000  bestvalidloss -573.06503  last_update 0\n",
      "train: iter 58  trainloss -483.79124  validloss -566.88678±0.00000  bestvalidloss -573.06503  last_update 1\n",
      "train: iter 59  trainloss -472.17490  validloss -567.64120±0.00000  bestvalidloss -573.06503  last_update 2\n",
      "train: iter 60  trainloss -488.64880  validloss -545.65315±0.00000  bestvalidloss -573.06503  last_update 3\n",
      "train: iter 61  trainloss -494.66372  validloss -549.33260±0.00000  bestvalidloss -573.06503  last_update 4\n",
      "train: iter 62  trainloss -496.02807  validloss -579.71306±0.00000  bestvalidloss -579.71306  last_update 0\n",
      "train: iter 63  trainloss -498.17173  validloss -548.03564±0.00000  bestvalidloss -579.71306  last_update 1\n",
      "train: iter 64  trainloss -507.08271  validloss -570.94660±0.00000  bestvalidloss -579.71306  last_update 2\n",
      "train: iter 65  trainloss -517.39824  validloss -576.04909±0.00000  bestvalidloss -579.71306  last_update 3\n",
      "train: iter 66  trainloss -501.74142  validloss -598.79417±0.00000  bestvalidloss -598.79417  last_update 0\n",
      "train: iter 67  trainloss -519.62451  validloss -591.14068±0.00000  bestvalidloss -598.79417  last_update 1\n",
      "train: iter 68  trainloss -539.58766  validloss -620.12808±0.00000  bestvalidloss -620.12808  last_update 0\n",
      "train: iter 69  trainloss -529.88450  validloss -617.05071±0.00000  bestvalidloss -620.12808  last_update 1\n",
      "train: iter 70  trainloss -526.26571  validloss -580.40228±0.00000  bestvalidloss -620.12808  last_update 2\n",
      "train: iter 71  trainloss -551.51697  validloss -630.76006±0.00000  bestvalidloss -630.76006  last_update 0\n",
      "train: iter 72  trainloss -549.81603  validloss -610.59342±0.00000  bestvalidloss -630.76006  last_update 1\n",
      "train: iter 73  trainloss -564.56022  validloss -621.22025±0.00000  bestvalidloss -630.76006  last_update 2\n",
      "train: iter 74  trainloss -566.07710  validloss -630.15228±0.00000  bestvalidloss -630.76006  last_update 3\n",
      "train: iter 75  trainloss -551.18979  validloss -624.86442±0.00000  bestvalidloss -630.76006  last_update 4\n",
      "train: iter 76  trainloss -543.34615  validloss -639.79967±0.00000  bestvalidloss -639.79967  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -558.19969  validloss -457.33210±0.00000  bestvalidloss -639.79967  last_update 1\n",
      "train: iter 78  trainloss -559.16608  validloss -636.02401±0.00000  bestvalidloss -639.79967  last_update 2\n",
      "train: iter 79  trainloss -516.00439  validloss -612.51650±0.00000  bestvalidloss -639.79967  last_update 3\n",
      "train: iter 80  trainloss -566.15657  validloss -504.12751±0.00000  bestvalidloss -639.79967  last_update 4\n",
      "train: iter 81  trainloss -570.55839  validloss -617.12020±0.00000  bestvalidloss -639.79967  last_update 5\n",
      "train: iter 82  trainloss -551.09998  validloss -622.49608±0.00000  bestvalidloss -639.79967  last_update 6\n",
      "train: iter 83  trainloss -567.96779  validloss -620.15903±0.00000  bestvalidloss -639.79967  last_update 7\n",
      "train: iter 84  trainloss -585.24704  validloss -670.53786±0.00000  bestvalidloss -670.53786  last_update 0\n",
      "train: iter 85  trainloss -579.77685  validloss -656.91339±0.00000  bestvalidloss -670.53786  last_update 1\n",
      "train: iter 86  trainloss -585.34636  validloss -631.49158±0.00000  bestvalidloss -670.53786  last_update 2\n",
      "train: iter 87  trainloss -573.13456  validloss -358.81025±0.00000  bestvalidloss -670.53786  last_update 3\n",
      "train: iter 88  trainloss -598.19627  validloss -554.22816±0.00000  bestvalidloss -670.53786  last_update 4\n",
      "train: iter 89  trainloss -566.95292  validloss -552.68711±0.00000  bestvalidloss -670.53786  last_update 5\n",
      "train: iter 90  trainloss -597.13790  validloss -619.38749±0.00000  bestvalidloss -670.53786  last_update 6\n",
      "train: iter 91  trainloss -588.17359  validloss -406.08486±0.00000  bestvalidloss -670.53786  last_update 7\n",
      "train: iter 92  trainloss -584.04050  validloss -676.96642±0.00000  bestvalidloss -676.96642  last_update 0\n",
      "train: iter 93  trainloss -591.84618  validloss -625.02601±0.00000  bestvalidloss -676.96642  last_update 1\n",
      "train: iter 94  trainloss -585.19575  validloss -583.14325±0.00000  bestvalidloss -676.96642  last_update 2\n",
      "train: iter 95  trainloss -607.10530  validloss -463.43740±0.00000  bestvalidloss -676.96642  last_update 3\n",
      "train: iter 96  trainloss -605.53724  validloss -568.78864±0.00000  bestvalidloss -676.96642  last_update 4\n",
      "train: iter 97  trainloss -613.63842  validloss -626.24186±0.00000  bestvalidloss -676.96642  last_update 5\n",
      "train: iter 98  trainloss -604.94605  validloss -504.12857±0.00000  bestvalidloss -676.96642  last_update 6\n",
      "train: iter 99  trainloss -598.43776  validloss -582.43366±0.00000  bestvalidloss -676.96642  last_update 7\n",
      "train: iter 100  trainloss -597.26410  validloss -597.91717±0.00000  bestvalidloss -676.96642  last_update 8\n",
      "train: iter 101  trainloss -611.04076  validloss -628.53784±0.00000  bestvalidloss -676.96642  last_update 9\n",
      "train: iter 102  trainloss -614.76718  validloss -666.02786±0.00000  bestvalidloss -676.96642  last_update 10\n",
      "train: iter 103  trainloss -616.28442  validloss -656.81216±0.00000  bestvalidloss -676.96642  last_update 11\n",
      "train: iter 104  trainloss -527.23991  validloss -634.80757±0.00000  bestvalidloss -676.96642  last_update 12\n",
      "train: iter 105  trainloss -536.54868  validloss -195.08579±0.00000  bestvalidloss -676.96642  last_update 13\n",
      "train: iter 106  trainloss -616.62731  validloss -628.37772±0.00000  bestvalidloss -676.96642  last_update 14\n",
      "train: iter 107  trainloss -618.44808  validloss -648.87699±0.00000  bestvalidloss -676.96642  last_update 15\n",
      "train: iter 108  trainloss -621.60168  validloss -593.27336±0.00000  bestvalidloss -676.96642  last_update 16\n",
      "train: iter 109  trainloss -620.61256  validloss -689.09630±0.00000  bestvalidloss -689.09630  last_update 0\n",
      "train: iter 110  trainloss -591.90976  validloss -692.36104±0.00000  bestvalidloss -692.36104  last_update 0\n",
      "train: iter 111  trainloss -625.56327  validloss -611.52235±0.00000  bestvalidloss -692.36104  last_update 1\n",
      "train: iter 112  trainloss -624.95942  validloss -643.35092±0.00000  bestvalidloss -692.36104  last_update 2\n",
      "train: iter 113  trainloss -611.57492  validloss -633.42897±0.00000  bestvalidloss -692.36104  last_update 3\n",
      "train: iter 114  trainloss -607.63300  validloss -568.83686±0.00000  bestvalidloss -692.36104  last_update 4\n",
      "train: iter 115  trainloss -628.43885  validloss -631.23674±0.00000  bestvalidloss -692.36104  last_update 5\n",
      "train: iter 116  trainloss -620.86329  validloss -513.58031±0.00000  bestvalidloss -692.36104  last_update 6\n",
      "train: iter 117  trainloss -619.26240  validloss -666.01897±0.00000  bestvalidloss -692.36104  last_update 7\n",
      "train: iter 118  trainloss -558.47596  validloss -665.46121±0.00000  bestvalidloss -692.36104  last_update 8\n",
      "train: iter 119  trainloss -620.06326  validloss -659.60664±0.00000  bestvalidloss -692.36104  last_update 9\n",
      "train: iter 120  trainloss -620.46261  validloss -687.37661±0.00000  bestvalidloss -692.36104  last_update 10\n",
      "train: iter 121  trainloss -607.08784  validloss -545.11476±0.00000  bestvalidloss -692.36104  last_update 11\n",
      "train: iter 122  trainloss -626.87976  validloss -650.81927±0.00000  bestvalidloss -692.36104  last_update 12\n",
      "train: iter 123  trainloss -637.81904  validloss -689.42583±0.00000  bestvalidloss -692.36104  last_update 13\n",
      "train: iter 124  trainloss -619.86932  validloss -681.85848±0.00000  bestvalidloss -692.36104  last_update 14\n",
      "train: iter 125  trainloss -607.50350  validloss -677.77015±0.00000  bestvalidloss -692.36104  last_update 15\n",
      "train: iter 126  trainloss -626.60480  validloss -649.44078±0.00000  bestvalidloss -692.36104  last_update 16\n",
      "train: iter 127  trainloss -566.96358  validloss -398.31551±0.00000  bestvalidloss -692.36104  last_update 17\n",
      "train: iter 128  trainloss -607.57929  validloss -647.09966±0.00000  bestvalidloss -692.36104  last_update 18\n",
      "train: iter 129  trainloss -624.66716  validloss -257.15926±0.00000  bestvalidloss -692.36104  last_update 19\n",
      "train: iter 130  trainloss -637.03534  validloss -687.97368±0.00000  bestvalidloss -692.36104  last_update 20\n",
      "train: iter 131  trainloss -611.01775  validloss -704.22819±0.00000  bestvalidloss -704.22819  last_update 0\n",
      "train: iter 132  trainloss -631.12980  validloss -644.96230±0.00000  bestvalidloss -704.22819  last_update 1\n",
      "train: iter 133  trainloss -643.07275  validloss -692.77249±0.00000  bestvalidloss -704.22819  last_update 2\n",
      "train: iter 134  trainloss -641.30504  validloss -701.41242±0.00000  bestvalidloss -704.22819  last_update 3\n",
      "train: iter 135  trainloss -589.79315  validloss -655.74911±0.00000  bestvalidloss -704.22819  last_update 4\n",
      "train: iter 136  trainloss -641.71802  validloss -622.26448±0.00000  bestvalidloss -704.22819  last_update 5\n",
      "train: iter 137  trainloss -628.37342  validloss -657.40605±0.00000  bestvalidloss -704.22819  last_update 6\n",
      "train: iter 138  trainloss -574.74391  validloss -587.89260±0.00000  bestvalidloss -704.22819  last_update 7\n",
      "train: iter 139  trainloss -643.97948  validloss -640.90265±0.00000  bestvalidloss -704.22819  last_update 8\n",
      "train: iter 140  trainloss -606.56554  validloss -678.95352±0.00000  bestvalidloss -704.22819  last_update 9\n",
      "train: iter 141  trainloss -615.85268  validloss -619.79555±0.00000  bestvalidloss -704.22819  last_update 10\n",
      "train: iter 142  trainloss -634.37422  validloss -619.55827±0.00000  bestvalidloss -704.22819  last_update 11\n",
      "train: iter 143  trainloss -635.39690  validloss -504.31730±0.00000  bestvalidloss -704.22819  last_update 12\n",
      "train: iter 144  trainloss -651.09365  validloss -692.60015±0.00000  bestvalidloss -704.22819  last_update 13\n",
      "train: iter 145  trainloss -641.97138  validloss -615.30611±0.00000  bestvalidloss -704.22819  last_update 14\n",
      "train: iter 146  trainloss -646.19521  validloss -513.91892±0.00000  bestvalidloss -704.22819  last_update 15\n",
      "train: iter 147  trainloss -646.27655  validloss -620.83407±0.00000  bestvalidloss -704.22819  last_update 16\n",
      "train: iter 148  trainloss -637.03186  validloss -645.60686±0.00000  bestvalidloss -704.22819  last_update 17\n",
      "train: iter 149  trainloss -633.95958  validloss -528.51747±0.00000  bestvalidloss -704.22819  last_update 18\n",
      "train: iter 150  trainloss -632.53774  validloss -579.89145±0.00000  bestvalidloss -704.22819  last_update 19\n",
      "train: iter 151  trainloss -644.07477  validloss -638.66073±0.00000  bestvalidloss -704.22819  last_update 20\n",
      "train: iter 152  trainloss -651.51342  validloss -668.86052±0.00000  bestvalidloss -704.22819  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -646.71854  validloss -575.57371±0.00000  bestvalidloss -704.22819  last_update 22\n",
      "train: iter 154  trainloss -613.71099  validloss -677.44623±0.00000  bestvalidloss -704.22819  last_update 23\n",
      "train: iter 155  trainloss -609.69886  validloss -210.74376±0.00000  bestvalidloss -704.22819  last_update 24\n",
      "train: iter 156  trainloss -637.36167  validloss 210.53202±0.00000  bestvalidloss -704.22819  last_update 25\n",
      "train: iter 157  trainloss -630.45952  validloss -684.68681±0.00000  bestvalidloss -704.22819  last_update 26\n",
      "train: iter 158  trainloss -650.98472  validloss -630.26542±0.00000  bestvalidloss -704.22819  last_update 27\n",
      "train: iter 159  trainloss -630.21019  validloss -609.37931±0.00000  bestvalidloss -704.22819  last_update 28\n",
      "train: iter 160  trainloss -645.44161  validloss -648.09337±0.00000  bestvalidloss -704.22819  last_update 29\n",
      "train: iter 161  trainloss -640.06622  validloss -632.43619±0.00000  bestvalidloss -704.22819  last_update 30\n",
      "train: iter 162  trainloss -653.93862  validloss -699.37761±0.00000  bestvalidloss -704.22819  last_update 31\n",
      "train: iter 163  trainloss -629.47088  validloss -666.88016±0.00000  bestvalidloss -704.22819  last_update 32\n",
      "train: iter 164  trainloss -644.19083  validloss -541.64579±0.00000  bestvalidloss -704.22819  last_update 33\n",
      "train: iter 165  trainloss -658.48413  validloss -691.35893±0.00000  bestvalidloss -704.22819  last_update 34\n",
      "train: iter 166  trainloss -615.89477  validloss -627.59914±0.00000  bestvalidloss -704.22819  last_update 35\n",
      "train: iter 167  trainloss -638.07305  validloss -604.78179±0.00000  bestvalidloss -704.22819  last_update 36\n",
      "train: iter 168  trainloss -635.07339  validloss -552.23414±0.00000  bestvalidloss -704.22819  last_update 37\n",
      "train: iter 169  trainloss -646.55648  validloss -666.08567±0.00000  bestvalidloss -704.22819  last_update 38\n",
      "train: iter 170  trainloss -648.54359  validloss -604.56578±0.00000  bestvalidloss -704.22819  last_update 39\n",
      "train: iter 171  trainloss -656.79667  validloss -689.45339±0.00000  bestvalidloss -704.22819  last_update 40\n",
      "train: iter 172  trainloss -611.47139  validloss -678.65306±0.00000  bestvalidloss -704.22819  last_update 41\n",
      "train: iter 173  trainloss -652.75124  validloss -623.66363±0.00000  bestvalidloss -704.22819  last_update 42\n",
      "train: iter 174  trainloss -659.20689  validloss -691.25981±0.00000  bestvalidloss -704.22819  last_update 43\n",
      "train: iter 175  trainloss -653.98082  validloss 235.98523±0.00000  bestvalidloss -704.22819  last_update 44\n",
      "train: iter 176  trainloss -641.14576  validloss -673.00751±0.00000  bestvalidloss -704.22819  last_update 45\n",
      "train: iter 177  trainloss -628.41448  validloss -598.42112±0.00000  bestvalidloss -704.22819  last_update 46\n",
      "train: iter 178  trainloss -651.46154  validloss -611.50323±0.00000  bestvalidloss -704.22819  last_update 47\n",
      "train: iter 179  trainloss -655.03385  validloss -535.67628±0.00000  bestvalidloss -704.22819  last_update 48\n",
      "train: iter 180  trainloss -654.61129  validloss -574.39684±0.00000  bestvalidloss -704.22819  last_update 49\n",
      "train: iter 181  trainloss -660.30604  validloss -556.63844±0.00000  bestvalidloss -704.22819  last_update 50\n",
      "train: iter 182  trainloss -653.40918  validloss -708.72472±0.00000  bestvalidloss -708.72472  last_update 0\n",
      "train: iter 183  trainloss -655.36460  validloss -628.33195±0.00000  bestvalidloss -708.72472  last_update 1\n",
      "train: iter 184  trainloss -626.19280  validloss -572.54494±0.00000  bestvalidloss -708.72472  last_update 2\n",
      "train: iter 185  trainloss -629.10184  validloss -676.43945±0.00000  bestvalidloss -708.72472  last_update 3\n",
      "train: iter 186  trainloss -630.95530  validloss -577.49800±0.00000  bestvalidloss -708.72472  last_update 4\n",
      "train: iter 187  trainloss -640.27300  validloss -625.82203±0.00000  bestvalidloss -708.72472  last_update 5\n",
      "train: iter 188  trainloss -661.28054  validloss -617.57450±0.00000  bestvalidloss -708.72472  last_update 6\n",
      "train: iter 189  trainloss -656.16535  validloss -474.44107±0.00000  bestvalidloss -708.72472  last_update 7\n",
      "train: iter 190  trainloss -650.48773  validloss -555.66869±0.00000  bestvalidloss -708.72472  last_update 8\n",
      "train: iter 191  trainloss -663.37373  validloss -425.25652±0.00000  bestvalidloss -708.72472  last_update 9\n",
      "train: iter 192  trainloss -672.13145  validloss -635.07108±0.00000  bestvalidloss -708.72472  last_update 10\n",
      "train: iter 193  trainloss -668.63161  validloss -694.46346±0.00000  bestvalidloss -708.72472  last_update 11\n",
      "train: iter 194  trainloss -606.65391  validloss -532.11998±0.00000  bestvalidloss -708.72472  last_update 12\n",
      "train: iter 195  trainloss -626.44041  validloss -687.79340±0.00000  bestvalidloss -708.72472  last_update 13\n",
      "train: iter 196  trainloss -639.31954  validloss -579.12080±0.00000  bestvalidloss -708.72472  last_update 14\n",
      "train: iter 197  trainloss -649.72678  validloss -686.22650±0.00000  bestvalidloss -708.72472  last_update 15\n",
      "train: iter 198  trainloss -634.85859  validloss -490.79173±0.00000  bestvalidloss -708.72472  last_update 16\n",
      "train: iter 199  trainloss -664.79279  validloss -693.53612±0.00000  bestvalidloss -708.72472  last_update 17\n",
      "train: iter 200  trainloss -664.71039  validloss -609.88688±0.00000  bestvalidloss -708.72472  last_update 18\n",
      "train: iter 201  trainloss -645.59526  validloss -607.01558±0.00000  bestvalidloss -708.72472  last_update 19\n",
      "train: iter 202  trainloss -648.62711  validloss -710.98047±0.00000  bestvalidloss -710.98047  last_update 0\n",
      "train: iter 203  trainloss -661.65327  validloss -520.18431±0.00000  bestvalidloss -710.98047  last_update 1\n",
      "train: iter 204  trainloss -657.53170  validloss -666.81416±0.00000  bestvalidloss -710.98047  last_update 2\n",
      "train: iter 205  trainloss -617.82224  validloss -661.94505±0.00000  bestvalidloss -710.98047  last_update 3\n",
      "train: iter 206  trainloss -665.46022  validloss -689.55952±0.00000  bestvalidloss -710.98047  last_update 4\n",
      "train: iter 207  trainloss -642.49550  validloss -508.36625±0.00000  bestvalidloss -710.98047  last_update 5\n",
      "train: iter 208  trainloss -633.39224  validloss -678.46009±0.00000  bestvalidloss -710.98047  last_update 6\n",
      "train: iter 209  trainloss -628.51917  validloss -702.34676±0.00000  bestvalidloss -710.98047  last_update 7\n",
      "train: iter 210  trainloss -672.36673  validloss -617.58000±0.00000  bestvalidloss -710.98047  last_update 8\n",
      "train: iter 211  trainloss -652.34615  validloss -564.38165±0.00000  bestvalidloss -710.98047  last_update 9\n",
      "train: iter 212  trainloss -662.50734  validloss -636.50330±0.00000  bestvalidloss -710.98047  last_update 10\n",
      "train: iter 213  trainloss -667.10375  validloss -547.63844±0.00000  bestvalidloss -710.98047  last_update 11\n",
      "train: iter 214  trainloss -651.21474  validloss -632.21274±0.00000  bestvalidloss -710.98047  last_update 12\n",
      "train: iter 215  trainloss -658.30021  validloss -712.24837±0.00000  bestvalidloss -712.24837  last_update 0\n",
      "train: iter 216  trainloss -639.80625  validloss -709.12753±0.00000  bestvalidloss -712.24837  last_update 1\n",
      "train: iter 217  trainloss -662.74106  validloss -701.34215±0.00000  bestvalidloss -712.24837  last_update 2\n",
      "train: iter 218  trainloss -636.56223  validloss -452.63187±0.00000  bestvalidloss -712.24837  last_update 3\n",
      "train: iter 219  trainloss -658.51794  validloss -724.55922±0.00000  bestvalidloss -724.55922  last_update 0\n",
      "train: iter 220  trainloss -639.66032  validloss -659.72095±0.00000  bestvalidloss -724.55922  last_update 1\n",
      "train: iter 221  trainloss -643.48552  validloss -637.75630±0.00000  bestvalidloss -724.55922  last_update 2\n",
      "train: iter 222  trainloss -667.08962  validloss -734.71136±0.00000  bestvalidloss -734.71136  last_update 0\n",
      "train: iter 223  trainloss -666.79819  validloss -721.82947±0.00000  bestvalidloss -734.71136  last_update 1\n",
      "train: iter 224  trainloss -664.19784  validloss -736.36295±0.00000  bestvalidloss -736.36295  last_update 0\n",
      "train: iter 225  trainloss -668.71840  validloss -724.24265±0.00000  bestvalidloss -736.36295  last_update 1\n",
      "train: iter 226  trainloss -618.17528  validloss -726.63831±0.00000  bestvalidloss -736.36295  last_update 2\n",
      "train: iter 227  trainloss -669.38796  validloss -714.58761±0.00000  bestvalidloss -736.36295  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -677.28154  validloss -732.22001±0.00000  bestvalidloss -736.36295  last_update 4\n",
      "train: iter 229  trainloss -646.82007  validloss -730.31190±0.00000  bestvalidloss -736.36295  last_update 5\n",
      "train: iter 230  trainloss -669.30791  validloss -702.79380±0.00000  bestvalidloss -736.36295  last_update 6\n",
      "train: iter 231  trainloss -669.06467  validloss -710.93931±0.00000  bestvalidloss -736.36295  last_update 7\n",
      "train: iter 232  trainloss -664.54010  validloss -723.96755±0.00000  bestvalidloss -736.36295  last_update 8\n",
      "train: iter 233  trainloss -661.12741  validloss -712.54719±0.00000  bestvalidloss -736.36295  last_update 9\n",
      "train: iter 234  trainloss -621.81423  validloss -703.14107±0.00000  bestvalidloss -736.36295  last_update 10\n",
      "train: iter 235  trainloss -642.03377  validloss -613.51723±0.00000  bestvalidloss -736.36295  last_update 11\n",
      "train: iter 236  trainloss -650.63494  validloss -690.35701±0.00000  bestvalidloss -736.36295  last_update 12\n",
      "train: iter 237  trainloss -664.90521  validloss -664.28084±0.00000  bestvalidloss -736.36295  last_update 13\n",
      "train: iter 238  trainloss -674.86614  validloss -684.32953±0.00000  bestvalidloss -736.36295  last_update 14\n",
      "train: iter 239  trainloss -674.76608  validloss -741.79123±0.00000  bestvalidloss -741.79123  last_update 0\n",
      "train: iter 240  trainloss -633.53697  validloss -737.85544±0.00000  bestvalidloss -741.79123  last_update 1\n",
      "train: iter 241  trainloss -675.02672  validloss -656.40466±0.00000  bestvalidloss -741.79123  last_update 2\n",
      "train: iter 242  trainloss -647.74670  validloss -725.23523±0.00000  bestvalidloss -741.79123  last_update 3\n",
      "train: iter 243  trainloss -642.94680  validloss -626.65474±0.00000  bestvalidloss -741.79123  last_update 4\n",
      "train: iter 244  trainloss -664.91772  validloss -730.15302±0.00000  bestvalidloss -741.79123  last_update 5\n",
      "train: iter 245  trainloss -661.59009  validloss -734.22690±0.00000  bestvalidloss -741.79123  last_update 6\n",
      "train: iter 246  trainloss -666.71756  validloss -721.04104±0.00000  bestvalidloss -741.79123  last_update 7\n",
      "train: iter 247  trainloss -670.90683  validloss -713.71163±0.00000  bestvalidloss -741.79123  last_update 8\n",
      "train: iter 248  trainloss -658.48726  validloss -632.08573±0.00000  bestvalidloss -741.79123  last_update 9\n",
      "train: iter 249  trainloss -654.84767  validloss -678.03790±0.00000  bestvalidloss -741.79123  last_update 10\n",
      "train: iter 250  trainloss -585.78732  validloss -618.11210±0.00000  bestvalidloss -741.79123  last_update 11\n",
      "train: iter 251  trainloss -672.77942  validloss -677.94927±0.00000  bestvalidloss -741.79123  last_update 12\n",
      "train: iter 252  trainloss -674.15700  validloss -725.00678±0.00000  bestvalidloss -741.79123  last_update 13\n",
      "train: iter 253  trainloss -653.47434  validloss -484.65008±0.00000  bestvalidloss -741.79123  last_update 14\n",
      "train: iter 254  trainloss -673.19783  validloss -694.02264±0.00000  bestvalidloss -741.79123  last_update 15\n",
      "train: iter 255  trainloss -681.31905  validloss -729.80547±0.00000  bestvalidloss -741.79123  last_update 16\n",
      "train: iter 256  trainloss -643.02583  validloss -723.34179±0.00000  bestvalidloss -741.79123  last_update 17\n",
      "train: iter 257  trainloss -660.14480  validloss -725.92901±0.00000  bestvalidloss -741.79123  last_update 18\n",
      "train: iter 258  trainloss -674.26247  validloss -723.15701±0.00000  bestvalidloss -741.79123  last_update 19\n",
      "train: iter 259  trainloss -677.43674  validloss -695.80259±0.00000  bestvalidloss -741.79123  last_update 20\n",
      "train: iter 260  trainloss -607.07270  validloss -709.10032±0.00000  bestvalidloss -741.79123  last_update 21\n",
      "train: iter 261  trainloss -656.14830  validloss -671.42687±0.00000  bestvalidloss -741.79123  last_update 22\n",
      "train: iter 262  trainloss -677.79619  validloss -729.75700±0.00000  bestvalidloss -741.79123  last_update 23\n",
      "train: iter 263  trainloss -680.15108  validloss -730.94331±0.00000  bestvalidloss -741.79123  last_update 24\n",
      "train: iter 264  trainloss -654.78868  validloss -722.21384±0.00000  bestvalidloss -741.79123  last_update 25\n",
      "train: iter 265  trainloss -628.11703  validloss -591.05821±0.00000  bestvalidloss -741.79123  last_update 26\n",
      "train: iter 266  trainloss -637.90054  validloss -634.27343±0.00000  bestvalidloss -741.79123  last_update 27\n",
      "train: iter 267  trainloss -659.54677  validloss -673.06547±0.00000  bestvalidloss -741.79123  last_update 28\n",
      "train: iter 268  trainloss -639.63308  validloss -697.25331±0.00000  bestvalidloss -741.79123  last_update 29\n",
      "train: iter 269  trainloss -634.88463  validloss -662.47691±0.00000  bestvalidloss -741.79123  last_update 30\n",
      "train: iter 270  trainloss -664.23049  validloss -644.42059±0.00000  bestvalidloss -741.79123  last_update 31\n",
      "train: iter 271  trainloss -666.76565  validloss -650.92091±0.00000  bestvalidloss -741.79123  last_update 32\n",
      "train: iter 272  trainloss -667.37777  validloss -654.82025±0.00000  bestvalidloss -741.79123  last_update 33\n",
      "train: iter 273  trainloss -678.82768  validloss -708.91343±0.00000  bestvalidloss -741.79123  last_update 34\n",
      "train: iter 274  trainloss -648.01602  validloss -741.94702±0.00000  bestvalidloss -741.94702  last_update 0\n",
      "train: iter 275  trainloss -682.83841  validloss -728.49090±0.00000  bestvalidloss -741.94702  last_update 1\n",
      "train: iter 276  trainloss -672.14955  validloss -690.54126±0.00000  bestvalidloss -741.94702  last_update 2\n",
      "train: iter 277  trainloss -677.33123  validloss -737.80894±0.00000  bestvalidloss -741.94702  last_update 3\n",
      "train: iter 278  trainloss -656.42345  validloss -692.60522±0.00000  bestvalidloss -741.94702  last_update 4\n",
      "train: iter 279  trainloss -646.52573  validloss -717.55150±0.00000  bestvalidloss -741.94702  last_update 5\n",
      "train: iter 280  trainloss -672.02612  validloss -580.17003±0.00000  bestvalidloss -741.94702  last_update 6\n",
      "train: iter 281  trainloss -667.60793  validloss -730.69062±0.00000  bestvalidloss -741.94702  last_update 7\n",
      "train: iter 282  trainloss -661.51660  validloss -702.14336±0.00000  bestvalidloss -741.94702  last_update 8\n",
      "train: iter 283  trainloss -670.21906  validloss -653.46635±0.00000  bestvalidloss -741.94702  last_update 9\n",
      "train: iter 284  trainloss -677.30895  validloss -662.68500±0.00000  bestvalidloss -741.94702  last_update 10\n",
      "train: iter 285  trainloss -673.51986  validloss -742.69287±0.00000  bestvalidloss -742.69287  last_update 0\n",
      "train: iter 286  trainloss -658.61957  validloss -722.15830±0.00000  bestvalidloss -742.69287  last_update 1\n",
      "train: iter 287  trainloss -667.16124  validloss -695.33668±0.00000  bestvalidloss -742.69287  last_update 2\n",
      "train: iter 288  trainloss -665.24103  validloss -733.55457±0.00000  bestvalidloss -742.69287  last_update 3\n",
      "train: iter 289  trainloss -675.53494  validloss -713.45815±0.00000  bestvalidloss -742.69287  last_update 4\n",
      "train: iter 290  trainloss -666.76089  validloss -725.60784±0.00000  bestvalidloss -742.69287  last_update 5\n",
      "train: iter 291  trainloss -680.67376  validloss -693.04909±0.00000  bestvalidloss -742.69287  last_update 6\n",
      "train: iter 292  trainloss -676.38450  validloss -696.68622±0.00000  bestvalidloss -742.69287  last_update 7\n",
      "train: iter 293  trainloss -666.81330  validloss -739.72820±0.00000  bestvalidloss -742.69287  last_update 8\n",
      "train: iter 294  trainloss -678.79601  validloss -667.26765±0.00000  bestvalidloss -742.69287  last_update 9\n",
      "train: iter 295  trainloss -664.81214  validloss -684.44695±0.00000  bestvalidloss -742.69287  last_update 10\n",
      "train: iter 296  trainloss -679.87458  validloss -744.50490±0.00000  bestvalidloss -744.50490  last_update 0\n",
      "train: iter 297  trainloss -672.51906  validloss -738.65998±0.00000  bestvalidloss -744.50490  last_update 1\n",
      "train: iter 298  trainloss -606.05884  validloss -602.62349±0.00000  bestvalidloss -744.50490  last_update 2\n",
      "train: iter 299  trainloss -653.02983  validloss -476.32360±0.00000  bestvalidloss -744.50490  last_update 3\n",
      "train: iter 300  trainloss -674.90404  validloss -705.40642±0.00000  bestvalidloss -744.50490  last_update 4\n",
      "train: iter 301  trainloss -684.18803  validloss -700.26273±0.00000  bestvalidloss -744.50490  last_update 5\n",
      "train: iter 302  trainloss -661.30010  validloss -688.29805±0.00000  bestvalidloss -744.50490  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 303  trainloss -685.68935  validloss -688.77150±0.00000  bestvalidloss -744.50490  last_update 7\n",
      "train: iter 304  trainloss -675.48520  validloss -628.98736±0.00000  bestvalidloss -744.50490  last_update 8\n",
      "train: iter 305  trainloss -651.26471  validloss -695.98087±0.00000  bestvalidloss -744.50490  last_update 9\n",
      "train: iter 306  trainloss -672.54858  validloss -735.19574±0.00000  bestvalidloss -744.50490  last_update 10\n",
      "train: iter 307  trainloss -608.20431  validloss -740.82621±0.00000  bestvalidloss -744.50490  last_update 11\n",
      "train: iter 308  trainloss -672.78499  validloss -722.52387±0.00000  bestvalidloss -744.50490  last_update 12\n",
      "train: iter 309  trainloss -681.06489  validloss -681.25760±0.00000  bestvalidloss -744.50490  last_update 13\n",
      "train: iter 310  trainloss -690.60796  validloss -703.26740±0.00000  bestvalidloss -744.50490  last_update 14\n",
      "train: iter 311  trainloss -636.16743  validloss -734.13727±0.00000  bestvalidloss -744.50490  last_update 15\n",
      "train: iter 312  trainloss -640.15680  validloss -636.58531±0.00000  bestvalidloss -744.50490  last_update 16\n",
      "train: iter 313  trainloss -661.53560  validloss -721.28148±0.00000  bestvalidloss -744.50490  last_update 17\n",
      "train: iter 314  trainloss -669.64383  validloss -541.49785±0.00000  bestvalidloss -744.50490  last_update 18\n",
      "train: iter 315  trainloss -682.87121  validloss -727.38969±0.00000  bestvalidloss -744.50490  last_update 19\n",
      "train: iter 316  trainloss -671.38742  validloss -715.00878±0.00000  bestvalidloss -744.50490  last_update 20\n",
      "train: iter 317  trainloss -679.91400  validloss -740.99918±0.00000  bestvalidloss -744.50490  last_update 21\n",
      "train: iter 318  trainloss -678.84245  validloss -718.51501±0.00000  bestvalidloss -744.50490  last_update 22\n",
      "train: iter 319  trainloss -673.34796  validloss -614.07876±0.00000  bestvalidloss -744.50490  last_update 23\n",
      "train: iter 320  trainloss -672.91387  validloss -742.25756±0.00000  bestvalidloss -744.50490  last_update 24\n",
      "train: iter 321  trainloss -679.39829  validloss -692.36735±0.00000  bestvalidloss -744.50490  last_update 25\n",
      "train: iter 322  trainloss -679.60322  validloss -720.54779±0.00000  bestvalidloss -744.50490  last_update 26\n",
      "train: iter 323  trainloss -644.30164  validloss -726.11719±0.00000  bestvalidloss -744.50490  last_update 27\n",
      "train: iter 324  trainloss -666.55467  validloss -510.39208±0.00000  bestvalidloss -744.50490  last_update 28\n",
      "train: iter 325  trainloss -662.18236  validloss -645.23940±0.00000  bestvalidloss -744.50490  last_update 29\n",
      "train: iter 326  trainloss -674.42973  validloss -714.89741±0.00000  bestvalidloss -744.50490  last_update 30\n",
      "train: iter 327  trainloss -671.46190  validloss -744.88948±0.00000  bestvalidloss -744.88948  last_update 0\n",
      "train: iter 328  trainloss -686.30323  validloss -695.72825±0.00000  bestvalidloss -744.88948  last_update 1\n",
      "train: iter 329  trainloss -678.61194  validloss -750.10365±0.00000  bestvalidloss -750.10365  last_update 0\n",
      "train: iter 330  trainloss -641.00005  validloss -637.73853±0.00000  bestvalidloss -750.10365  last_update 1\n",
      "train: iter 331  trainloss -663.79364  validloss -734.31970±0.00000  bestvalidloss -750.10365  last_update 2\n",
      "train: iter 332  trainloss -653.92044  validloss -731.41353±0.00000  bestvalidloss -750.10365  last_update 3\n",
      "train: iter 333  trainloss -677.85886  validloss -731.54559±0.00000  bestvalidloss -750.10365  last_update 4\n",
      "train: iter 334  trainloss -681.32162  validloss -736.11502±0.00000  bestvalidloss -750.10365  last_update 5\n",
      "train: iter 335  trainloss -633.96029  validloss -733.39464±0.00000  bestvalidloss -750.10365  last_update 6\n",
      "train: iter 336  trainloss -666.61942  validloss -732.07347±0.00000  bestvalidloss -750.10365  last_update 7\n",
      "train: iter 337  trainloss -685.88427  validloss -734.39344±0.00000  bestvalidloss -750.10365  last_update 8\n",
      "train: iter 338  trainloss -668.35155  validloss -714.91700±0.00000  bestvalidloss -750.10365  last_update 9\n",
      "train: iter 339  trainloss -686.75524  validloss -669.77187±0.00000  bestvalidloss -750.10365  last_update 10\n",
      "train: iter 340  trainloss -647.82395  validloss -726.02043±0.00000  bestvalidloss -750.10365  last_update 11\n",
      "train: iter 341  trainloss -652.67390  validloss -646.87313±0.00000  bestvalidloss -750.10365  last_update 12\n",
      "train: iter 342  trainloss -674.18206  validloss -643.47085±0.00000  bestvalidloss -750.10365  last_update 13\n",
      "train: iter 343  trainloss -665.40059  validloss -701.51939±0.00000  bestvalidloss -750.10365  last_update 14\n",
      "train: iter 344  trainloss -662.02574  validloss -471.23260±0.00000  bestvalidloss -750.10365  last_update 15\n",
      "train: iter 345  trainloss -677.70925  validloss -716.42165±0.00000  bestvalidloss -750.10365  last_update 16\n",
      "train: iter 346  trainloss -679.57399  validloss -729.34306±0.00000  bestvalidloss -750.10365  last_update 17\n",
      "train: iter 347  trainloss -590.78962  validloss -724.52171±0.00000  bestvalidloss -750.10365  last_update 18\n",
      "train: iter 348  trainloss -659.97182  validloss -642.45445±0.00000  bestvalidloss -750.10365  last_update 19\n",
      "train: iter 349  trainloss -676.38768  validloss -747.05852±0.00000  bestvalidloss -750.10365  last_update 20\n",
      "train: iter 350  trainloss -646.34647  validloss -727.75260±0.00000  bestvalidloss -750.10365  last_update 21\n",
      "train: iter 351  trainloss -684.10310  validloss -708.51858±0.00000  bestvalidloss -750.10365  last_update 22\n",
      "train: iter 352  trainloss -688.03305  validloss -754.01975±0.00000  bestvalidloss -754.01975  last_update 0\n",
      "train: iter 353  trainloss -675.79756  validloss -617.49477±0.00000  bestvalidloss -754.01975  last_update 1\n",
      "train: iter 354  trainloss -674.11802  validloss -719.70441±0.00000  bestvalidloss -754.01975  last_update 2\n",
      "train: iter 355  trainloss -677.08828  validloss -684.34913±0.00000  bestvalidloss -754.01975  last_update 3\n",
      "train: iter 356  trainloss -677.27637  validloss -728.57412±0.00000  bestvalidloss -754.01975  last_update 4\n",
      "train: iter 357  trainloss -686.59512  validloss -735.11054±0.00000  bestvalidloss -754.01975  last_update 5\n",
      "train: iter 358  trainloss -687.50529  validloss -733.21029±0.00000  bestvalidloss -754.01975  last_update 6\n",
      "train: iter 359  trainloss -680.01979  validloss -731.75653±0.00000  bestvalidloss -754.01975  last_update 7\n",
      "train: iter 360  trainloss -686.01241  validloss -733.31795±0.00000  bestvalidloss -754.01975  last_update 8\n",
      "train: iter 361  trainloss -692.00652  validloss -676.91599±0.00000  bestvalidloss -754.01975  last_update 9\n",
      "train: iter 362  trainloss -691.42978  validloss -746.09945±0.00000  bestvalidloss -754.01975  last_update 10\n",
      "train: iter 363  trainloss -645.55133  validloss -697.43832±0.00000  bestvalidloss -754.01975  last_update 11\n",
      "train: iter 364  trainloss -682.42704  validloss -664.43260±0.00000  bestvalidloss -754.01975  last_update 12\n",
      "train: iter 365  trainloss -688.46075  validloss -728.81291±0.00000  bestvalidloss -754.01975  last_update 13\n",
      "train: iter 366  trainloss -683.81313  validloss -681.86172±0.00000  bestvalidloss -754.01975  last_update 14\n",
      "train: iter 367  trainloss -689.15439  validloss -744.87450±0.00000  bestvalidloss -754.01975  last_update 15\n",
      "train: iter 368  trainloss -668.68869  validloss -716.05601±0.00000  bestvalidloss -754.01975  last_update 16\n",
      "train: iter 369  trainloss -650.97078  validloss -729.28989±0.00000  bestvalidloss -754.01975  last_update 17\n",
      "train: iter 370  trainloss -691.41439  validloss -746.80673±0.00000  bestvalidloss -754.01975  last_update 18\n",
      "train: iter 371  trainloss -684.26138  validloss -740.33361±0.00000  bestvalidloss -754.01975  last_update 19\n",
      "train: iter 372  trainloss -663.69167  validloss -732.25814±0.00000  bestvalidloss -754.01975  last_update 20\n",
      "train: iter 373  trainloss -638.16983  validloss -565.03426±0.00000  bestvalidloss -754.01975  last_update 21\n",
      "train: iter 374  trainloss -680.63151  validloss -720.48886±0.00000  bestvalidloss -754.01975  last_update 22\n",
      "train: iter 375  trainloss -686.32254  validloss -703.98798±0.00000  bestvalidloss -754.01975  last_update 23\n",
      "train: iter 376  trainloss -680.36324  validloss -733.21309±0.00000  bestvalidloss -754.01975  last_update 24\n",
      "train: iter 377  trainloss -678.51257  validloss -742.77415±0.00000  bestvalidloss -754.01975  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 378  trainloss -698.70955  validloss -746.97565±0.00000  bestvalidloss -754.01975  last_update 26\n",
      "train: iter 379  trainloss -669.63816  validloss -735.94209±0.00000  bestvalidloss -754.01975  last_update 27\n",
      "train: iter 380  trainloss -655.65509  validloss -756.83919±0.00000  bestvalidloss -756.83919  last_update 0\n",
      "train: iter 381  trainloss -692.77580  validloss -753.10919±0.00000  bestvalidloss -756.83919  last_update 1\n",
      "train: iter 382  trainloss -689.92015  validloss -728.82586±0.00000  bestvalidloss -756.83919  last_update 2\n",
      "train: iter 383  trainloss -688.14800  validloss -690.30788±0.00000  bestvalidloss -756.83919  last_update 3\n",
      "train: iter 384  trainloss -687.99031  validloss -726.68165±0.00000  bestvalidloss -756.83919  last_update 4\n",
      "train: iter 385  trainloss -688.67640  validloss -731.16019±0.00000  bestvalidloss -756.83919  last_update 5\n",
      "train: iter 386  trainloss -691.83731  validloss -746.37243±0.00000  bestvalidloss -756.83919  last_update 6\n",
      "train: iter 387  trainloss -676.08666  validloss -738.71009±0.00000  bestvalidloss -756.83919  last_update 7\n",
      "train: iter 388  trainloss -680.27757  validloss -712.04167±0.00000  bestvalidloss -756.83919  last_update 8\n",
      "train: iter 389  trainloss -691.34618  validloss -705.27851±0.00000  bestvalidloss -756.83919  last_update 9\n",
      "train: iter 390  trainloss -696.79643  validloss -744.08878±0.00000  bestvalidloss -756.83919  last_update 10\n",
      "train: iter 391  trainloss -697.31109  validloss -752.24404±0.00000  bestvalidloss -756.83919  last_update 11\n",
      "train: iter 392  trainloss -688.13971  validloss -735.61023±0.00000  bestvalidloss -756.83919  last_update 12\n",
      "train: iter 393  trainloss -693.64741  validloss -700.70021±0.00000  bestvalidloss -756.83919  last_update 13\n",
      "train: iter 394  trainloss -693.42164  validloss -699.12088±0.00000  bestvalidloss -756.83919  last_update 14\n",
      "train: iter 395  trainloss -677.79955  validloss -756.40549±0.00000  bestvalidloss -756.83919  last_update 15\n",
      "train: iter 396  trainloss -699.35177  validloss -753.11467±0.00000  bestvalidloss -756.83919  last_update 16\n",
      "train: iter 397  trainloss -669.01911  validloss -749.71326±0.00000  bestvalidloss -756.83919  last_update 17\n",
      "train: iter 398  trainloss -674.48849  validloss -703.83024±0.00000  bestvalidloss -756.83919  last_update 18\n",
      "train: iter 399  trainloss -692.61905  validloss -682.71484±0.00000  bestvalidloss -756.83919  last_update 19\n",
      "train: iter 400  trainloss -694.74526  validloss -732.36087±0.00000  bestvalidloss -756.83919  last_update 20\n",
      "train: iter 401  trainloss -690.25237  validloss -710.19802±0.00000  bestvalidloss -756.83919  last_update 21\n",
      "train: iter 402  trainloss -701.43046  validloss -763.36525±0.00000  bestvalidloss -763.36525  last_update 0\n",
      "train: iter 403  trainloss -683.37414  validloss -747.01455±0.00000  bestvalidloss -763.36525  last_update 1\n",
      "train: iter 404  trainloss -699.21326  validloss -725.15127±0.00000  bestvalidloss -763.36525  last_update 2\n",
      "train: iter 405  trainloss -684.66796  validloss -755.51913±0.00000  bestvalidloss -763.36525  last_update 3\n",
      "train: iter 406  trainloss -686.24719  validloss -639.61440±0.00000  bestvalidloss -763.36525  last_update 4\n",
      "train: iter 407  trainloss -692.55628  validloss -750.55237±0.00000  bestvalidloss -763.36525  last_update 5\n",
      "train: iter 408  trainloss -696.76204  validloss -727.32421±0.00000  bestvalidloss -763.36525  last_update 6\n",
      "train: iter 409  trainloss -667.73626  validloss -704.04701±0.00000  bestvalidloss -763.36525  last_update 7\n",
      "train: iter 410  trainloss -667.87361  validloss -713.03016±0.00000  bestvalidloss -763.36525  last_update 8\n",
      "train: iter 411  trainloss -686.16058  validloss -675.92912±0.00000  bestvalidloss -763.36525  last_update 9\n",
      "train: iter 412  trainloss -664.88446  validloss -745.98044±0.00000  bestvalidloss -763.36525  last_update 10\n",
      "train: iter 413  trainloss -685.11182  validloss -678.25431±0.00000  bestvalidloss -763.36525  last_update 11\n",
      "train: iter 414  trainloss -693.34051  validloss -727.84618±0.00000  bestvalidloss -763.36525  last_update 12\n",
      "train: iter 415  trainloss -694.25303  validloss -738.96060±0.00000  bestvalidloss -763.36525  last_update 13\n",
      "train: iter 416  trainloss -691.56366  validloss -702.25006±0.00000  bestvalidloss -763.36525  last_update 14\n",
      "train: iter 417  trainloss -692.33714  validloss -742.93498±0.00000  bestvalidloss -763.36525  last_update 15\n",
      "train: iter 418  trainloss -644.95054  validloss -711.43612±0.00000  bestvalidloss -763.36525  last_update 16\n",
      "train: iter 419  trainloss -692.16101  validloss -721.63362±0.00000  bestvalidloss -763.36525  last_update 17\n",
      "train: iter 420  trainloss -691.16799  validloss -734.03803±0.00000  bestvalidloss -763.36525  last_update 18\n",
      "train: iter 421  trainloss -683.61631  validloss -753.60133±0.00000  bestvalidloss -763.36525  last_update 19\n",
      "train: iter 422  trainloss -686.95480  validloss -743.79251±0.00000  bestvalidloss -763.36525  last_update 20\n",
      "train: iter 423  trainloss -708.04640  validloss -745.75503±0.00000  bestvalidloss -763.36525  last_update 21\n",
      "train: iter 424  trainloss -688.16524  validloss -736.10512±0.00000  bestvalidloss -763.36525  last_update 22\n",
      "train: iter 425  trainloss -663.04069  validloss -746.57956±0.00000  bestvalidloss -763.36525  last_update 23\n",
      "train: iter 426  trainloss -704.89578  validloss -712.60824±0.00000  bestvalidloss -763.36525  last_update 24\n",
      "train: iter 427  trainloss -700.21863  validloss -747.70623±0.00000  bestvalidloss -763.36525  last_update 25\n",
      "train: iter 428  trainloss -669.84505  validloss -760.88365±0.00000  bestvalidloss -763.36525  last_update 26\n",
      "train: iter 429  trainloss -678.91015  validloss -526.38625±0.00000  bestvalidloss -763.36525  last_update 27\n",
      "train: iter 430  trainloss -711.38595  validloss -718.66853±0.00000  bestvalidloss -763.36525  last_update 28\n",
      "train: iter 431  trainloss -689.82191  validloss -733.48651±0.00000  bestvalidloss -763.36525  last_update 29\n",
      "train: iter 432  trainloss -657.02094  validloss -764.65598±0.00000  bestvalidloss -764.65598  last_update 0\n",
      "train: iter 433  trainloss -706.72507  validloss -729.12616±0.00000  bestvalidloss -764.65598  last_update 1\n",
      "train: iter 434  trainloss -681.95167  validloss -750.26590±0.00000  bestvalidloss -764.65598  last_update 2\n",
      "train: iter 435  trainloss -692.60436  validloss -698.74935±0.00000  bestvalidloss -764.65598  last_update 3\n",
      "train: iter 436  trainloss -701.61697  validloss -740.96598±0.00000  bestvalidloss -764.65598  last_update 4\n",
      "train: iter 437  trainloss -696.80796  validloss -715.03628±0.00000  bestvalidloss -764.65598  last_update 5\n",
      "train: iter 438  trainloss -702.22792  validloss -687.52506±0.00000  bestvalidloss -764.65598  last_update 6\n",
      "train: iter 439  trainloss -703.03082  validloss -764.17481±0.00000  bestvalidloss -764.65598  last_update 7\n",
      "train: iter 440  trainloss -707.42750  validloss -719.46347±0.00000  bestvalidloss -764.65598  last_update 8\n",
      "train: iter 441  trainloss -708.79416  validloss -737.10395±0.00000  bestvalidloss -764.65598  last_update 9\n",
      "train: iter 442  trainloss -710.18725  validloss -689.53342±0.00000  bestvalidloss -764.65598  last_update 10\n",
      "train: iter 443  trainloss -670.97763  validloss -765.90751±0.00000  bestvalidloss -765.90751  last_update 0\n",
      "train: iter 444  trainloss -692.92258  validloss -730.22025±0.00000  bestvalidloss -765.90751  last_update 1\n",
      "train: iter 445  trainloss -687.26087  validloss -730.25638±0.00000  bestvalidloss -765.90751  last_update 2\n",
      "train: iter 446  trainloss -714.41475  validloss -762.14442±0.00000  bestvalidloss -765.90751  last_update 3\n",
      "train: iter 447  trainloss -684.01048  validloss -727.92748±0.00000  bestvalidloss -765.90751  last_update 4\n",
      "train: iter 448  trainloss -698.79662  validloss -708.27115±0.00000  bestvalidloss -765.90751  last_update 5\n",
      "train: iter 449  trainloss -705.83370  validloss -721.63486±0.00000  bestvalidloss -765.90751  last_update 6\n",
      "train: iter 450  trainloss -706.91331  validloss -696.25815±0.00000  bestvalidloss -765.90751  last_update 7\n",
      "train: iter 451  trainloss -694.33583  validloss -741.85766±0.00000  bestvalidloss -765.90751  last_update 8\n",
      "train: iter 452  trainloss -679.28248  validloss -673.61496±0.00000  bestvalidloss -765.90751  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 453  trainloss -695.35978  validloss -764.91608±0.00000  bestvalidloss -765.90751  last_update 10\n",
      "train: iter 454  trainloss -654.27354  validloss -719.15514±0.00000  bestvalidloss -765.90751  last_update 11\n",
      "train: iter 455  trainloss -705.15932  validloss -663.81964±0.00000  bestvalidloss -765.90751  last_update 12\n",
      "train: iter 456  trainloss -706.28587  validloss -749.27537±0.00000  bestvalidloss -765.90751  last_update 13\n",
      "train: iter 457  trainloss -711.57053  validloss -762.37776±0.00000  bestvalidloss -765.90751  last_update 14\n",
      "train: iter 458  trainloss -706.82555  validloss -733.96803±0.00000  bestvalidloss -765.90751  last_update 15\n",
      "train: iter 459  trainloss -678.45624  validloss -761.41843±0.00000  bestvalidloss -765.90751  last_update 16\n",
      "train: iter 460  trainloss -710.89188  validloss -711.73984±0.00000  bestvalidloss -765.90751  last_update 17\n",
      "train: iter 461  trainloss -682.88260  validloss -772.27873±0.00000  bestvalidloss -772.27873  last_update 0\n",
      "train: iter 462  trainloss -699.84170  validloss -752.44614±0.00000  bestvalidloss -772.27873  last_update 1\n",
      "train: iter 463  trainloss -698.49677  validloss -720.13706±0.00000  bestvalidloss -772.27873  last_update 2\n",
      "train: iter 464  trainloss -709.46421  validloss -762.21245±0.00000  bestvalidloss -772.27873  last_update 3\n",
      "train: iter 465  trainloss -713.16680  validloss -764.23088±0.00000  bestvalidloss -772.27873  last_update 4\n",
      "train: iter 466  trainloss -698.90728  validloss -727.15811±0.00000  bestvalidloss -772.27873  last_update 5\n",
      "train: iter 467  trainloss -707.71548  validloss -659.46736±0.00000  bestvalidloss -772.27873  last_update 6\n",
      "train: iter 468  trainloss -685.85724  validloss -713.13047±0.00000  bestvalidloss -772.27873  last_update 7\n",
      "train: iter 469  trainloss -697.30478  validloss -760.67749±0.00000  bestvalidloss -772.27873  last_update 8\n",
      "train: iter 470  trainloss -715.62562  validloss -750.76266±0.00000  bestvalidloss -772.27873  last_update 9\n",
      "train: iter 471  trainloss -696.83510  validloss -720.39746±0.00000  bestvalidloss -772.27873  last_update 10\n",
      "train: iter 472  trainloss -707.90535  validloss -762.07762±0.00000  bestvalidloss -772.27873  last_update 11\n",
      "train: iter 473  trainloss -687.81775  validloss -740.32974±0.00000  bestvalidloss -772.27873  last_update 12\n",
      "train: iter 474  trainloss -716.45256  validloss -733.63824±0.00000  bestvalidloss -772.27873  last_update 13\n",
      "train: iter 475  trainloss -697.76565  validloss -770.95103±0.00000  bestvalidloss -772.27873  last_update 14\n",
      "train: iter 476  trainloss -705.01812  validloss -748.56028±0.00000  bestvalidloss -772.27873  last_update 15\n",
      "train: iter 477  trainloss -712.38300  validloss -653.96131±0.00000  bestvalidloss -772.27873  last_update 16\n",
      "train: iter 478  trainloss -712.62130  validloss -751.41373±0.00000  bestvalidloss -772.27873  last_update 17\n",
      "train: iter 479  trainloss -680.17025  validloss -725.08037±0.00000  bestvalidloss -772.27873  last_update 18\n",
      "train: iter 480  trainloss -703.22312  validloss -735.75564±0.00000  bestvalidloss -772.27873  last_update 19\n",
      "train: iter 481  trainloss -666.95320  validloss -705.67054±0.00000  bestvalidloss -772.27873  last_update 20\n",
      "train: iter 482  trainloss -717.05100  validloss -679.42365±0.00000  bestvalidloss -772.27873  last_update 21\n",
      "train: iter 483  trainloss -691.09463  validloss -764.50612±0.00000  bestvalidloss -772.27873  last_update 22\n",
      "train: iter 484  trainloss -693.41473  validloss -732.95584±0.00000  bestvalidloss -772.27873  last_update 23\n",
      "train: iter 485  trainloss -684.28112  validloss -705.69696±0.00000  bestvalidloss -772.27873  last_update 24\n",
      "train: iter 486  trainloss -694.90117  validloss -749.13237±0.00000  bestvalidloss -772.27873  last_update 25\n",
      "train: iter 487  trainloss -701.08971  validloss -744.02935±0.00000  bestvalidloss -772.27873  last_update 26\n",
      "train: iter 488  trainloss -704.59146  validloss -752.52896±0.00000  bestvalidloss -772.27873  last_update 27\n",
      "train: iter 489  trainloss -724.97854  validloss -736.48627±0.00000  bestvalidloss -772.27873  last_update 28\n",
      "train: iter 490  trainloss -709.15937  validloss -750.20317±0.00000  bestvalidloss -772.27873  last_update 29\n",
      "train: iter 491  trainloss -692.68272  validloss -721.00988±0.00000  bestvalidloss -772.27873  last_update 30\n",
      "train: iter 492  trainloss -719.81753  validloss -760.00565±0.00000  bestvalidloss -772.27873  last_update 31\n",
      "train: iter 493  trainloss -696.99400  validloss -705.59461±0.00000  bestvalidloss -772.27873  last_update 32\n",
      "train: iter 494  trainloss -718.29816  validloss -729.00404±0.00000  bestvalidloss -772.27873  last_update 33\n",
      "train: iter 495  trainloss -714.84077  validloss -712.19417±0.00000  bestvalidloss -772.27873  last_update 34\n",
      "train: iter 496  trainloss -711.10717  validloss -751.50069±0.00000  bestvalidloss -772.27873  last_update 35\n",
      "train: iter 497  trainloss -700.22604  validloss -703.03012±0.00000  bestvalidloss -772.27873  last_update 36\n",
      "train: iter 498  trainloss -702.09297  validloss -743.54780±0.00000  bestvalidloss -772.27873  last_update 37\n",
      "train: iter 499  trainloss -668.84713  validloss -768.88316±0.00000  bestvalidloss -772.27873  last_update 38\n",
      "train: iter 500  trainloss -699.70585  validloss -708.23460±0.00000  bestvalidloss -772.27873  last_update 39\n",
      "train: iter 501  trainloss -667.24200  validloss -755.86568±0.00000  bestvalidloss -772.27873  last_update 40\n",
      "train: iter 502  trainloss -708.77978  validloss -762.34306±0.00000  bestvalidloss -772.27873  last_update 41\n",
      "train: iter 503  trainloss -708.37738  validloss -758.08671±0.00000  bestvalidloss -772.27873  last_update 42\n",
      "train: iter 504  trainloss -664.77444  validloss -695.27489±0.00000  bestvalidloss -772.27873  last_update 43\n",
      "train: iter 505  trainloss -692.75582  validloss -768.55171±0.00000  bestvalidloss -772.27873  last_update 44\n",
      "train: iter 506  trainloss -710.48181  validloss -736.05614±0.00000  bestvalidloss -772.27873  last_update 45\n",
      "train: iter 507  trainloss -719.72770  validloss -733.26689±0.00000  bestvalidloss -772.27873  last_update 46\n",
      "train: iter 508  trainloss -709.51899  validloss -724.38885±0.00000  bestvalidloss -772.27873  last_update 47\n",
      "train: iter 509  trainloss -676.49485  validloss -627.96183±0.00000  bestvalidloss -772.27873  last_update 48\n",
      "train: iter 510  trainloss -698.40321  validloss -750.52992±0.00000  bestvalidloss -772.27873  last_update 49\n",
      "train: iter 511  trainloss -697.45852  validloss -734.71957±0.00000  bestvalidloss -772.27873  last_update 50\n",
      "train: iter 512  trainloss -668.14477  validloss -730.33125±0.00000  bestvalidloss -772.27873  last_update 51\n",
      "train: iter 513  trainloss -712.52501  validloss -699.00070±0.00000  bestvalidloss -772.27873  last_update 52\n",
      "train: iter 514  trainloss -716.43722  validloss -689.96935±0.00000  bestvalidloss -772.27873  last_update 53\n",
      "train: iter 515  trainloss -712.91273  validloss -738.90722±0.00000  bestvalidloss -772.27873  last_update 54\n",
      "train: iter 516  trainloss -714.91905  validloss -764.96846±0.00000  bestvalidloss -772.27873  last_update 55\n",
      "train: iter 517  trainloss -712.13380  validloss -755.77467±0.00000  bestvalidloss -772.27873  last_update 56\n",
      "train: iter 518  trainloss -698.65957  validloss -759.46028±0.00000  bestvalidloss -772.27873  last_update 57\n",
      "train: iter 519  trainloss -704.08866  validloss -750.66582±0.00000  bestvalidloss -772.27873  last_update 58\n",
      "train: iter 520  trainloss -683.65330  validloss -757.17090±0.00000  bestvalidloss -772.27873  last_update 59\n",
      "train: iter 521  trainloss -717.98676  validloss -750.14269±0.00000  bestvalidloss -772.27873  last_update 60\n",
      "train: iter 522  trainloss -703.92089  validloss -719.59182±0.00000  bestvalidloss -772.27873  last_update 61\n",
      "train: iter 523  trainloss -698.64809  validloss -762.22059±0.00000  bestvalidloss -772.27873  last_update 62\n",
      "train: iter 524  trainloss -686.58457  validloss -761.24585±0.00000  bestvalidloss -772.27873  last_update 63\n",
      "train: iter 525  trainloss -719.33189  validloss -730.37648±0.00000  bestvalidloss -772.27873  last_update 64\n",
      "train: iter 526  trainloss -700.50167  validloss -724.59680±0.00000  bestvalidloss -772.27873  last_update 65\n",
      "train: iter 527  trainloss -691.25529  validloss -719.50794±0.00000  bestvalidloss -772.27873  last_update 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 528  trainloss -716.41137  validloss -754.05332±0.00000  bestvalidloss -772.27873  last_update 67\n",
      "train: iter 529  trainloss -699.53545  validloss -740.52914±0.00000  bestvalidloss -772.27873  last_update 68\n",
      "train: iter 530  trainloss -719.06986  validloss -763.18870±0.00000  bestvalidloss -772.27873  last_update 69\n",
      "train: iter 531  trainloss -721.42579  validloss -748.33515±0.00000  bestvalidloss -772.27873  last_update 70\n",
      "train: iter 532  trainloss -719.03552  validloss -777.87813±0.00000  bestvalidloss -777.87813  last_update 0\n",
      "train: iter 533  trainloss -693.38642  validloss -748.51390±0.00000  bestvalidloss -777.87813  last_update 1\n",
      "train: iter 534  trainloss -702.20183  validloss -750.59684±0.00000  bestvalidloss -777.87813  last_update 2\n",
      "train: iter 535  trainloss -722.96937  validloss -761.13260±0.00000  bestvalidloss -777.87813  last_update 3\n",
      "train: iter 536  trainloss -700.48406  validloss -757.40558±0.00000  bestvalidloss -777.87813  last_update 4\n",
      "train: iter 537  trainloss -687.49313  validloss -711.99895±0.00000  bestvalidloss -777.87813  last_update 5\n",
      "train: iter 538  trainloss -705.98022  validloss -638.00575±0.00000  bestvalidloss -777.87813  last_update 6\n",
      "train: iter 539  trainloss -720.24373  validloss -763.31689±0.00000  bestvalidloss -777.87813  last_update 7\n",
      "train: iter 540  trainloss -708.82829  validloss -755.72208±0.00000  bestvalidloss -777.87813  last_update 8\n",
      "train: iter 541  trainloss -721.91637  validloss -759.29505±0.00000  bestvalidloss -777.87813  last_update 9\n",
      "train: iter 542  trainloss -719.32856  validloss -760.36252±0.00000  bestvalidloss -777.87813  last_update 10\n",
      "train: iter 543  trainloss -713.94678  validloss -776.56495±0.00000  bestvalidloss -777.87813  last_update 11\n",
      "train: iter 544  trainloss -700.69055  validloss -742.17189±0.00000  bestvalidloss -777.87813  last_update 12\n",
      "train: iter 545  trainloss -680.72809  validloss -659.46570±0.00000  bestvalidloss -777.87813  last_update 13\n",
      "train: iter 546  trainloss -696.13070  validloss -712.85353±0.00000  bestvalidloss -777.87813  last_update 14\n",
      "train: iter 547  trainloss -703.28221  validloss -737.92779±0.00000  bestvalidloss -777.87813  last_update 15\n",
      "train: iter 548  trainloss -718.72779  validloss -730.17948±0.00000  bestvalidloss -777.87813  last_update 16\n",
      "train: iter 549  trainloss -680.22860  validloss -737.74556±0.00000  bestvalidloss -777.87813  last_update 17\n",
      "train: iter 550  trainloss -713.96338  validloss -760.56875±0.00000  bestvalidloss -777.87813  last_update 18\n",
      "train: iter 551  trainloss -698.20763  validloss -752.29534±0.00000  bestvalidloss -777.87813  last_update 19\n",
      "train: iter 552  trainloss -701.79107  validloss -719.49358±0.00000  bestvalidloss -777.87813  last_update 20\n",
      "train: iter 553  trainloss -694.62305  validloss -701.17986±0.00000  bestvalidloss -777.87813  last_update 21\n",
      "train: iter 554  trainloss -722.40782  validloss -756.21621±0.00000  bestvalidloss -777.87813  last_update 22\n",
      "train: iter 555  trainloss -709.77292  validloss -761.45895±0.00000  bestvalidloss -777.87813  last_update 23\n",
      "train: iter 556  trainloss -711.39762  validloss -770.40698±0.00000  bestvalidloss -777.87813  last_update 24\n",
      "train: iter 557  trainloss -710.62477  validloss -773.48480±0.00000  bestvalidloss -777.87813  last_update 25\n",
      "train: iter 558  trainloss -707.28624  validloss -744.00887±0.00000  bestvalidloss -777.87813  last_update 26\n",
      "train: iter 559  trainloss -715.27489  validloss -722.00056±0.00000  bestvalidloss -777.87813  last_update 27\n",
      "train: iter 560  trainloss -709.76817  validloss -777.82643±0.00000  bestvalidloss -777.87813  last_update 28\n",
      "train: iter 561  trainloss -707.57438  validloss -757.25943±0.00000  bestvalidloss -777.87813  last_update 29\n",
      "train: iter 562  trainloss -713.26193  validloss -698.24823±0.00000  bestvalidloss -777.87813  last_update 30\n",
      "train: iter 563  trainloss -715.54938  validloss -744.99613±0.00000  bestvalidloss -777.87813  last_update 31\n",
      "train: iter 564  trainloss -706.98890  validloss -755.70423±0.00000  bestvalidloss -777.87813  last_update 32\n",
      "train: iter 565  trainloss -727.72079  validloss -745.25449±0.00000  bestvalidloss -777.87813  last_update 33\n",
      "train: iter 566  trainloss -706.30097  validloss -771.71626±0.00000  bestvalidloss -777.87813  last_update 34\n",
      "train: iter 567  trainloss -722.67712  validloss -718.95060±0.00000  bestvalidloss -777.87813  last_update 35\n",
      "train: iter 568  trainloss -718.79498  validloss -769.62918±0.00000  bestvalidloss -777.87813  last_update 36\n",
      "train: iter 569  trainloss -726.25049  validloss -779.15869±0.00000  bestvalidloss -779.15869  last_update 0\n",
      "train: iter 570  trainloss -701.60583  validloss -756.56754±0.00000  bestvalidloss -779.15869  last_update 1\n",
      "train: iter 571  trainloss -693.53734  validloss -752.07905±0.00000  bestvalidloss -779.15869  last_update 2\n",
      "train: iter 572  trainloss -718.82697  validloss -655.16556±0.00000  bestvalidloss -779.15869  last_update 3\n",
      "train: iter 573  trainloss -701.20037  validloss -754.72425±0.00000  bestvalidloss -779.15869  last_update 4\n",
      "train: iter 574  trainloss -717.30085  validloss -750.01698±0.00000  bestvalidloss -779.15869  last_update 5\n",
      "train: iter 575  trainloss -725.34297  validloss -745.06980±0.00000  bestvalidloss -779.15869  last_update 6\n",
      "train: iter 576  trainloss -722.71738  validloss -738.18999±0.00000  bestvalidloss -779.15869  last_update 7\n",
      "train: iter 577  trainloss -719.02115  validloss -756.18770±0.00000  bestvalidloss -779.15869  last_update 8\n",
      "train: iter 578  trainloss -709.16352  validloss -768.81871±0.00000  bestvalidloss -779.15869  last_update 9\n",
      "train: iter 579  trainloss -725.71253  validloss -703.83881±0.00000  bestvalidloss -779.15869  last_update 10\n",
      "train: iter 580  trainloss -704.61918  validloss -754.98551±0.00000  bestvalidloss -779.15869  last_update 11\n",
      "train: iter 581  trainloss -700.88349  validloss -671.67032±0.00000  bestvalidloss -779.15869  last_update 12\n",
      "train: iter 582  trainloss -722.73425  validloss -769.86681±0.00000  bestvalidloss -779.15869  last_update 13\n",
      "train: iter 583  trainloss -702.71031  validloss -757.76200±0.00000  bestvalidloss -779.15869  last_update 14\n",
      "train: iter 584  trainloss -720.66258  validloss -700.54590±0.00000  bestvalidloss -779.15869  last_update 15\n",
      "train: iter 585  trainloss -722.54030  validloss -773.08303±0.00000  bestvalidloss -779.15869  last_update 16\n",
      "train: iter 586  trainloss -697.87341  validloss -768.75752±0.00000  bestvalidloss -779.15869  last_update 17\n",
      "train: iter 587  trainloss -684.10843  validloss -763.27952±0.00000  bestvalidloss -779.15869  last_update 18\n",
      "train: iter 588  trainloss -697.07095  validloss -733.92072±0.00000  bestvalidloss -779.15869  last_update 19\n",
      "train: iter 589  trainloss -720.77937  validloss -692.76783±0.00000  bestvalidloss -779.15869  last_update 20\n",
      "train: iter 590  trainloss -714.65930  validloss -773.33299±0.00000  bestvalidloss -779.15869  last_update 21\n",
      "train: iter 591  trainloss -695.94640  validloss -622.21976±0.00000  bestvalidloss -779.15869  last_update 22\n",
      "train: iter 592  trainloss -716.47276  validloss -754.87859±0.00000  bestvalidloss -779.15869  last_update 23\n",
      "train: iter 593  trainloss -702.45797  validloss -770.99305±0.00000  bestvalidloss -779.15869  last_update 24\n",
      "train: iter 594  trainloss -716.70365  validloss -754.64470±0.00000  bestvalidloss -779.15869  last_update 25\n",
      "train: iter 595  trainloss -702.31102  validloss -718.47494±0.00000  bestvalidloss -779.15869  last_update 26\n",
      "train: iter 596  trainloss -706.97612  validloss -720.58322±0.00000  bestvalidloss -779.15869  last_update 27\n",
      "train: iter 597  trainloss -724.83018  validloss -749.37680±0.00000  bestvalidloss -779.15869  last_update 28\n",
      "train: iter 598  trainloss -722.39189  validloss -737.78519±0.00000  bestvalidloss -779.15869  last_update 29\n",
      "train: iter 599  trainloss -717.80706  validloss -750.22751±0.00000  bestvalidloss -779.15869  last_update 30\n",
      "train: iter 600  trainloss -709.93766  validloss -739.71903±0.00000  bestvalidloss -779.15869  last_update 31\n",
      "train: iter 601  trainloss -691.42495  validloss -726.20010±0.00000  bestvalidloss -779.15869  last_update 32\n",
      "train: iter 602  trainloss -722.78908  validloss -745.70458±0.00000  bestvalidloss -779.15869  last_update 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 603  trainloss -688.73783  validloss -754.75396±0.00000  bestvalidloss -779.15869  last_update 34\n",
      "train: iter 604  trainloss -723.66045  validloss -755.33140±0.00000  bestvalidloss -779.15869  last_update 35\n",
      "train: iter 605  trainloss -666.65830  validloss -754.12496±0.00000  bestvalidloss -779.15869  last_update 36\n",
      "train: iter 606  trainloss -667.54781  validloss -665.90946±0.00000  bestvalidloss -779.15869  last_update 37\n",
      "train: iter 607  trainloss -727.02060  validloss -761.51690±0.00000  bestvalidloss -779.15869  last_update 38\n",
      "train: iter 608  trainloss -730.43441  validloss -761.42521±0.00000  bestvalidloss -779.15869  last_update 39\n",
      "train: iter 609  trainloss -715.74137  validloss -708.42343±0.00000  bestvalidloss -779.15869  last_update 40\n",
      "train: iter 610  trainloss -718.06142  validloss -739.72831±0.00000  bestvalidloss -779.15869  last_update 41\n",
      "train: iter 611  trainloss -724.24125  validloss -752.34191±0.00000  bestvalidloss -779.15869  last_update 42\n",
      "train: iter 612  trainloss -707.70455  validloss -778.44188±0.00000  bestvalidloss -779.15869  last_update 43\n",
      "train: iter 613  trainloss -713.84303  validloss -752.05336±0.00000  bestvalidloss -779.15869  last_update 44\n",
      "train: iter 614  trainloss -695.24008  validloss -699.94991±0.00000  bestvalidloss -779.15869  last_update 45\n",
      "train: iter 615  trainloss -722.00644  validloss -757.50837±0.00000  bestvalidloss -779.15869  last_update 46\n",
      "train: iter 616  trainloss -707.27715  validloss -759.68174±0.00000  bestvalidloss -779.15869  last_update 47\n",
      "train: iter 617  trainloss -708.91157  validloss -764.71809±0.00000  bestvalidloss -779.15869  last_update 48\n",
      "train: iter 618  trainloss -725.33072  validloss -652.54047±0.00000  bestvalidloss -779.15869  last_update 49\n",
      "train: iter 619  trainloss -719.40127  validloss -726.92975±0.00000  bestvalidloss -779.15869  last_update 50\n",
      "train: iter 620  trainloss -718.67700  validloss -758.31831±0.00000  bestvalidloss -779.15869  last_update 51\n",
      "train: iter 621  trainloss -725.57620  validloss -782.07424±0.00000  bestvalidloss -782.07424  last_update 0\n",
      "train: iter 622  trainloss -721.71837  validloss -753.99781±0.00000  bestvalidloss -782.07424  last_update 1\n",
      "train: iter 623  trainloss -698.58474  validloss -748.25469±0.00000  bestvalidloss -782.07424  last_update 2\n",
      "train: iter 624  trainloss -738.92148  validloss -763.24792±0.00000  bestvalidloss -782.07424  last_update 3\n",
      "train: iter 625  trainloss -716.59731  validloss -792.76800±0.00000  bestvalidloss -792.76800  last_update 0\n",
      "train: iter 626  trainloss -710.36407  validloss -740.58536±0.00000  bestvalidloss -792.76800  last_update 1\n",
      "train: iter 627  trainloss -698.55933  validloss -756.12049±0.00000  bestvalidloss -792.76800  last_update 2\n",
      "train: iter 628  trainloss -707.78385  validloss -759.20046±0.00000  bestvalidloss -792.76800  last_update 3\n",
      "train: iter 629  trainloss -697.46224  validloss -714.08571±0.00000  bestvalidloss -792.76800  last_update 4\n",
      "train: iter 630  trainloss -737.21036  validloss -723.39677±0.00000  bestvalidloss -792.76800  last_update 5\n",
      "train: iter 631  trainloss -727.69815  validloss -769.89502±0.00000  bestvalidloss -792.76800  last_update 6\n",
      "train: iter 632  trainloss -685.02208  validloss -761.85798±0.00000  bestvalidloss -792.76800  last_update 7\n",
      "train: iter 633  trainloss -733.94775  validloss -761.98643±0.00000  bestvalidloss -792.76800  last_update 8\n",
      "train: iter 634  trainloss -723.65513  validloss -743.40175±0.00000  bestvalidloss -792.76800  last_update 9\n",
      "train: iter 635  trainloss -714.23562  validloss -767.94895±0.00000  bestvalidloss -792.76800  last_update 10\n",
      "train: iter 636  trainloss -714.35705  validloss -774.26356±0.00000  bestvalidloss -792.76800  last_update 11\n",
      "train: iter 637  trainloss -717.37518  validloss -756.33211±0.00000  bestvalidloss -792.76800  last_update 12\n",
      "train: iter 638  trainloss -709.35475  validloss -766.39377±0.00000  bestvalidloss -792.76800  last_update 13\n",
      "train: iter 639  trainloss -731.46011  validloss -751.09750±0.00000  bestvalidloss -792.76800  last_update 14\n",
      "train: iter 640  trainloss -717.47209  validloss -664.44500±0.00000  bestvalidloss -792.76800  last_update 15\n",
      "train: iter 641  trainloss -722.22574  validloss -730.25733±0.00000  bestvalidloss -792.76800  last_update 16\n",
      "train: iter 642  trainloss -726.78898  validloss -762.52944±0.00000  bestvalidloss -792.76800  last_update 17\n",
      "train: iter 643  trainloss -708.71928  validloss -784.59950±0.00000  bestvalidloss -792.76800  last_update 18\n",
      "train: iter 644  trainloss -710.68699  validloss -747.48470±0.00000  bestvalidloss -792.76800  last_update 19\n",
      "train: iter 645  trainloss -732.10914  validloss -750.95312±0.00000  bestvalidloss -792.76800  last_update 20\n",
      "train: iter 646  trainloss -709.03008  validloss -752.22533±0.00000  bestvalidloss -792.76800  last_update 21\n",
      "train: iter 647  trainloss -721.26795  validloss -741.69273±0.00000  bestvalidloss -792.76800  last_update 22\n",
      "train: iter 648  trainloss -711.33493  validloss -741.47809±0.00000  bestvalidloss -792.76800  last_update 23\n",
      "train: iter 649  trainloss -719.84646  validloss -728.02819±0.00000  bestvalidloss -792.76800  last_update 24\n",
      "train: iter 650  trainloss -730.17090  validloss -770.28294±0.00000  bestvalidloss -792.76800  last_update 25\n",
      "train: iter 651  trainloss -699.61355  validloss -740.34718±0.00000  bestvalidloss -792.76800  last_update 26\n",
      "train: iter 652  trainloss -706.24085  validloss -702.22823±0.00000  bestvalidloss -792.76800  last_update 27\n",
      "train: iter 653  trainloss -716.25040  validloss -741.42169±0.00000  bestvalidloss -792.76800  last_update 28\n",
      "train: iter 654  trainloss -733.59676  validloss -773.36559±0.00000  bestvalidloss -792.76800  last_update 29\n",
      "train: iter 655  trainloss -711.50377  validloss -752.71046±0.00000  bestvalidloss -792.76800  last_update 30\n",
      "train: iter 656  trainloss -733.47290  validloss -730.29941±0.00000  bestvalidloss -792.76800  last_update 31\n",
      "train: iter 657  trainloss -725.15170  validloss -782.04458±0.00000  bestvalidloss -792.76800  last_update 32\n",
      "train: iter 658  trainloss -738.10468  validloss -767.82689±0.00000  bestvalidloss -792.76800  last_update 33\n",
      "train: iter 659  trainloss -706.92199  validloss -766.45812±0.00000  bestvalidloss -792.76800  last_update 34\n",
      "train: iter 660  trainloss -721.86002  validloss -774.09011±0.00000  bestvalidloss -792.76800  last_update 35\n",
      "train: iter 661  trainloss -702.50785  validloss -738.71685±0.00000  bestvalidloss -792.76800  last_update 36\n",
      "train: iter 662  trainloss -708.79939  validloss -711.90746±0.00000  bestvalidloss -792.76800  last_update 37\n",
      "train: iter 663  trainloss -727.79933  validloss -761.70770±0.00000  bestvalidloss -792.76800  last_update 38\n",
      "train: iter 664  trainloss -726.60355  validloss -726.52964±0.00000  bestvalidloss -792.76800  last_update 39\n",
      "train: iter 665  trainloss -713.08805  validloss -710.66204±0.00000  bestvalidloss -792.76800  last_update 40\n",
      "train: iter 666  trainloss -727.62981  validloss -724.19987±0.00000  bestvalidloss -792.76800  last_update 41\n",
      "train: iter 667  trainloss -719.52358  validloss -773.27144±0.00000  bestvalidloss -792.76800  last_update 42\n",
      "train: iter 668  trainloss -712.63646  validloss -552.14865±0.00000  bestvalidloss -792.76800  last_update 43\n",
      "train: iter 669  trainloss -706.43623  validloss -754.55422±0.00000  bestvalidloss -792.76800  last_update 44\n",
      "train: iter 670  trainloss -718.40741  validloss -765.31904±0.00000  bestvalidloss -792.76800  last_update 45\n",
      "train: iter 671  trainloss -692.68647  validloss -780.18168±0.00000  bestvalidloss -792.76800  last_update 46\n",
      "train: iter 672  trainloss -691.02146  validloss 17.30507±0.00000  bestvalidloss -792.76800  last_update 47\n",
      "train: iter 673  trainloss -700.78838  validloss -726.82626±0.00000  bestvalidloss -792.76800  last_update 48\n",
      "train: iter 674  trainloss -709.71918  validloss -731.46181±0.00000  bestvalidloss -792.76800  last_update 49\n",
      "train: iter 675  trainloss -740.76762  validloss -749.78823±0.00000  bestvalidloss -792.76800  last_update 50\n",
      "train: iter 676  trainloss -716.93113  validloss -751.12085±0.00000  bestvalidloss -792.76800  last_update 51\n",
      "train: iter 677  trainloss -712.47626  validloss -727.88899±0.00000  bestvalidloss -792.76800  last_update 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 678  trainloss -729.12144  validloss -765.03954±0.00000  bestvalidloss -792.76800  last_update 53\n",
      "train: iter 679  trainloss -725.09863  validloss -758.23689±0.00000  bestvalidloss -792.76800  last_update 54\n",
      "train: iter 680  trainloss -724.95024  validloss -757.34036±0.00000  bestvalidloss -792.76800  last_update 55\n",
      "train: iter 681  trainloss -729.56122  validloss -773.99229±0.00000  bestvalidloss -792.76800  last_update 56\n",
      "train: iter 682  trainloss -704.17336  validloss -767.74312±0.00000  bestvalidloss -792.76800  last_update 57\n",
      "train: iter 683  trainloss -693.24761  validloss -718.09701±0.00000  bestvalidloss -792.76800  last_update 58\n",
      "train: iter 684  trainloss -702.57488  validloss -682.94143±0.00000  bestvalidloss -792.76800  last_update 59\n",
      "train: iter 685  trainloss -685.59975  validloss -723.46327±0.00000  bestvalidloss -792.76800  last_update 60\n",
      "train: iter 686  trainloss -735.29301  validloss -762.17051±0.00000  bestvalidloss -792.76800  last_update 61\n",
      "train: iter 687  trainloss -715.62579  validloss -772.74316±0.00000  bestvalidloss -792.76800  last_update 62\n",
      "train: iter 688  trainloss -696.02696  validloss -735.56837±0.00000  bestvalidloss -792.76800  last_update 63\n",
      "train: iter 689  trainloss -712.77732  validloss -707.29312±0.00000  bestvalidloss -792.76800  last_update 64\n",
      "train: iter 690  trainloss -722.94043  validloss -754.50762±0.00000  bestvalidloss -792.76800  last_update 65\n",
      "train: iter 691  trainloss -732.08425  validloss -754.59137±0.00000  bestvalidloss -792.76800  last_update 66\n",
      "train: iter 692  trainloss -729.22221  validloss -772.26896±0.00000  bestvalidloss -792.76800  last_update 67\n",
      "train: iter 693  trainloss -724.70026  validloss -765.01234±0.00000  bestvalidloss -792.76800  last_update 68\n",
      "train: iter 694  trainloss -717.77821  validloss -761.39814±0.00000  bestvalidloss -792.76800  last_update 69\n",
      "train: iter 695  trainloss -715.36581  validloss -723.03722±0.00000  bestvalidloss -792.76800  last_update 70\n",
      "train: iter 696  trainloss -723.76420  validloss -636.99973±0.00000  bestvalidloss -792.76800  last_update 71\n",
      "train: iter 697  trainloss -702.83708  validloss -758.01730±0.00000  bestvalidloss -792.76800  last_update 72\n",
      "train: iter 698  trainloss -725.38191  validloss -756.48736±0.00000  bestvalidloss -792.76800  last_update 73\n",
      "train: iter 699  trainloss -722.45232  validloss -755.46288±0.00000  bestvalidloss -792.76800  last_update 74\n",
      "train: iter 700  trainloss -717.21448  validloss -764.64156±0.00000  bestvalidloss -792.76800  last_update 75\n",
      "train: iter 701  trainloss -730.43440  validloss -753.44259±0.00000  bestvalidloss -792.76800  last_update 76\n",
      "train: iter 702  trainloss -703.39516  validloss -770.37137±0.00000  bestvalidloss -792.76800  last_update 77\n",
      "train: iter 703  trainloss -728.58817  validloss -751.76304±0.00000  bestvalidloss -792.76800  last_update 78\n",
      "train: iter 704  trainloss -719.11042  validloss -750.73008±0.00000  bestvalidloss -792.76800  last_update 79\n",
      "train: iter 705  trainloss -733.32648  validloss -754.32861±0.00000  bestvalidloss -792.76800  last_update 80\n",
      "train: iter 706  trainloss -712.49687  validloss -740.83225±0.00000  bestvalidloss -792.76800  last_update 81\n",
      "train: iter 707  trainloss -738.32559  validloss -743.53197±0.00000  bestvalidloss -792.76800  last_update 82\n",
      "train: iter 708  trainloss -723.83282  validloss -773.85929±0.00000  bestvalidloss -792.76800  last_update 83\n",
      "train: iter 709  trainloss -716.92805  validloss -758.14698±0.00000  bestvalidloss -792.76800  last_update 84\n",
      "train: iter 710  trainloss -741.75009  validloss -753.71448±0.00000  bestvalidloss -792.76800  last_update 85\n",
      "train: iter 711  trainloss -723.04252  validloss -761.93797±0.00000  bestvalidloss -792.76800  last_update 86\n",
      "train: iter 712  trainloss -721.94936  validloss -740.47532±0.00000  bestvalidloss -792.76800  last_update 87\n",
      "train: iter 713  trainloss -724.23021  validloss -759.85206±0.00000  bestvalidloss -792.76800  last_update 88\n",
      "train: iter 714  trainloss -727.56486  validloss -733.89365±0.00000  bestvalidloss -792.76800  last_update 89\n",
      "train: iter 715  trainloss -716.02495  validloss -721.56037±0.00000  bestvalidloss -792.76800  last_update 90\n",
      "train: iter 716  trainloss -721.90914  validloss -735.17414±0.00000  bestvalidloss -792.76800  last_update 91\n",
      "train: iter 717  trainloss -734.70980  validloss -705.00616±0.00000  bestvalidloss -792.76800  last_update 92\n",
      "train: iter 718  trainloss -713.66863  validloss -773.93117±0.00000  bestvalidloss -792.76800  last_update 93\n",
      "train: iter 719  trainloss -720.26220  validloss -689.49295±0.00000  bestvalidloss -792.76800  last_update 94\n",
      "train: iter 720  trainloss -701.99471  validloss -771.65860±0.00000  bestvalidloss -792.76800  last_update 95\n",
      "train: iter 721  trainloss -736.81174  validloss -607.56272±0.00000  bestvalidloss -792.76800  last_update 96\n",
      "train: iter 722  trainloss -721.00113  validloss -768.06129±0.00000  bestvalidloss -792.76800  last_update 97\n",
      "train: iter 723  trainloss -723.48010  validloss -754.21366±0.00000  bestvalidloss -792.76800  last_update 98\n",
      "train: iter 724  trainloss -735.79946  validloss -734.73294±0.00000  bestvalidloss -792.76800  last_update 99\n",
      "train: iter 725  trainloss -730.78482  validloss -760.85366±0.00000  bestvalidloss -792.76800  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-5.7347) penalty_target_max tensor(11.6834)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.41217  validloss 9.75002±0.00000  bestvalidloss 9.75002  last_update 0\n",
      "train: iter 1  trainloss 8.55211  validloss 8.85270±0.00000  bestvalidloss 8.85270  last_update 0\n",
      "train: iter 2  trainloss 7.82587  validloss 8.07907±0.00000  bestvalidloss 8.07907  last_update 0\n",
      "train: iter 3  trainloss 7.22752  validloss 7.43017±0.00000  bestvalidloss 7.43017  last_update 0\n",
      "train: iter 4  trainloss 6.66921  validloss 6.87376±0.00000  bestvalidloss 6.87376  last_update 0\n",
      "train: iter 5  trainloss 6.22339  validloss 6.36615±0.00000  bestvalidloss 6.36615  last_update 0\n",
      "train: iter 6  trainloss 5.81452  validloss 5.93669±0.00000  bestvalidloss 5.93669  last_update 0\n",
      "train: iter 7  trainloss 5.45400  validloss 5.57120±0.00000  bestvalidloss 5.57120  last_update 0\n",
      "train: iter 8  trainloss 5.13708  validloss 5.24705±0.00000  bestvalidloss 5.24705  last_update 0\n",
      "train: iter 9  trainloss 4.85251  validloss 4.94235±0.00000  bestvalidloss 4.94235  last_update 0\n",
      "train: iter 10  trainloss 4.61069  validloss 4.66784±0.00000  bestvalidloss 4.66784  last_update 0\n",
      "train: iter 11  trainloss 4.38678  validloss 4.45700±0.00000  bestvalidloss 4.45700  last_update 0\n",
      "train: iter 12  trainloss 4.18651  validloss 4.26287±0.00000  bestvalidloss 4.26287  last_update 0\n",
      "train: iter 13  trainloss 4.01135  validloss 4.06356±0.00000  bestvalidloss 4.06356  last_update 0\n",
      "train: iter 14  trainloss 3.85358  validloss 3.90319±0.00000  bestvalidloss 3.90319  last_update 0\n",
      "train: iter 15  trainloss 3.70564  validloss 3.74676±0.00000  bestvalidloss 3.74676  last_update 0\n",
      "train: iter 16  trainloss 3.56788  validloss 3.60762±0.00000  bestvalidloss 3.60762  last_update 0\n",
      "train: iter 17  trainloss 3.45111  validloss 3.48524±0.00000  bestvalidloss 3.48524  last_update 0\n",
      "train: iter 18  trainloss 3.34315  validloss 3.37563±0.00000  bestvalidloss 3.37563  last_update 0\n",
      "train: iter 19  trainloss 3.24313  validloss 3.26988±0.00000  bestvalidloss 3.26988  last_update 0\n",
      "train: iter 20  trainloss 3.15077  validloss 3.16435±0.00000  bestvalidloss 3.16435  last_update 0\n",
      "train: iter 21  trainloss 3.06418  validloss 3.08193±0.00000  bestvalidloss 3.08193  last_update 0\n",
      "train: iter 22  trainloss 2.99014  validloss 3.00974±0.00000  bestvalidloss 3.00974  last_update 0\n",
      "train: iter 23  trainloss 2.91710  validloss 2.93786±0.00000  bestvalidloss 2.93786  last_update 0\n",
      "train: iter 24  trainloss 2.85097  validloss 2.86641±0.00000  bestvalidloss 2.86641  last_update 0\n",
      "train: iter 25  trainloss 2.79539  validloss 2.80937±0.00000  bestvalidloss 2.80937  last_update 0\n",
      "train: iter 26  trainloss 2.73638  validloss 2.74973±0.00000  bestvalidloss 2.74973  last_update 0\n",
      "train: iter 27  trainloss 2.68513  validloss 2.69742±0.00000  bestvalidloss 2.69742  last_update 0\n",
      "train: iter 28  trainloss 2.63817  validloss 2.64197±0.00000  bestvalidloss 2.64197  last_update 0\n",
      "train: iter 29  trainloss 2.59283  validloss 2.60141±0.00000  bestvalidloss 2.60141  last_update 0\n",
      "train: iter 30  trainloss 2.55174  validloss 2.55184±0.00000  bestvalidloss 2.55184  last_update 0\n",
      "train: iter 31  trainloss 2.51187  validloss 2.52159±0.00000  bestvalidloss 2.52159  last_update 0\n",
      "train: iter 32  trainloss 2.47412  validloss 2.48067±0.00000  bestvalidloss 2.48067  last_update 0\n",
      "train: iter 33  trainloss 2.44038  validloss 2.44270±0.00000  bestvalidloss 2.44270  last_update 0\n",
      "train: iter 34  trainloss 2.40351  validloss 2.41726±0.00000  bestvalidloss 2.41726  last_update 0\n",
      "train: iter 35  trainloss 2.37500  validloss 2.38485±0.00000  bestvalidloss 2.38485  last_update 0\n",
      "train: iter 36  trainloss 2.34659  validloss 2.35232±0.00000  bestvalidloss 2.35232  last_update 0\n",
      "train: iter 37  trainloss 2.31644  validloss 2.32247±0.00000  bestvalidloss 2.32247  last_update 0\n",
      "train: iter 38  trainloss 2.29241  validloss 2.30388±0.00000  bestvalidloss 2.30388  last_update 0\n",
      "train: iter 39  trainloss 2.26521  validloss 2.27349±0.00000  bestvalidloss 2.27349  last_update 0\n",
      "train: iter 40  trainloss 2.24247  validloss 2.24577±0.00000  bestvalidloss 2.24577  last_update 0\n",
      "train: iter 41  trainloss 2.21896  validloss 2.22639±0.00000  bestvalidloss 2.22639  last_update 0\n",
      "train: iter 42  trainloss 2.19697  validloss 2.20379±0.00000  bestvalidloss 2.20379  last_update 0\n",
      "train: iter 43  trainloss 2.17525  validloss 2.18329±0.00000  bestvalidloss 2.18329  last_update 0\n",
      "train: iter 44  trainloss 2.15503  validloss 2.16499±0.00000  bestvalidloss 2.16499  last_update 0\n",
      "train: iter 45  trainloss 2.13244  validloss 2.14025±0.00000  bestvalidloss 2.14025  last_update 0\n",
      "train: iter 46  trainloss 2.11354  validloss 2.12064±0.00000  bestvalidloss 2.12064  last_update 0\n",
      "train: iter 47  trainloss 2.09315  validloss 2.09938±0.00000  bestvalidloss 2.09938  last_update 0\n",
      "train: iter 48  trainloss 2.07442  validloss 2.08104±0.00000  bestvalidloss 2.08104  last_update 0\n",
      "train: iter 49  trainloss 2.05366  validloss 2.06191±0.00000  bestvalidloss 2.06191  last_update 0\n",
      "train: iter 50  trainloss 2.03632  validloss 2.04293±0.00000  bestvalidloss 2.04293  last_update 0\n",
      "train: iter 51  trainloss 2.01801  validloss 2.02604±0.00000  bestvalidloss 2.02604  last_update 0\n",
      "train: iter 52  trainloss 1.99695  validloss 2.00386±0.00000  bestvalidloss 2.00386  last_update 0\n",
      "train: iter 53  trainloss 1.97764  validloss 1.98440±0.00000  bestvalidloss 1.98440  last_update 0\n",
      "train: iter 54  trainloss 1.95690  validloss 1.96818±0.00000  bestvalidloss 1.96818  last_update 0\n",
      "train: iter 55  trainloss 1.93564  validloss 1.94663±0.00000  bestvalidloss 1.94663  last_update 0\n",
      "train: iter 56  trainloss 1.91637  validloss 1.92749±0.00000  bestvalidloss 1.92749  last_update 0\n",
      "train: iter 57  trainloss 1.89740  validloss 1.90561±0.00000  bestvalidloss 1.90561  last_update 0\n",
      "train: iter 58  trainloss 1.87270  validloss 1.88496±0.00000  bestvalidloss 1.88496  last_update 0\n",
      "train: iter 59  trainloss 1.85127  validloss 1.86462±0.00000  bestvalidloss 1.86462  last_update 0\n",
      "train: iter 60  trainloss 1.82867  validloss 1.84457±0.00000  bestvalidloss 1.84457  last_update 0\n",
      "train: iter 61  trainloss 1.80607  validloss 1.82200±0.00000  bestvalidloss 1.82200  last_update 0\n",
      "train: iter 62  trainloss 1.78418  validloss 1.79981±0.00000  bestvalidloss 1.79981  last_update 0\n",
      "train: iter 63  trainloss 1.75941  validloss 1.77535±0.00000  bestvalidloss 1.77535  last_update 0\n",
      "train: iter 64  trainloss 1.73322  validloss 1.75401±0.00000  bestvalidloss 1.75401  last_update 0\n",
      "train: iter 65  trainloss 1.70535  validloss 1.72632±0.00000  bestvalidloss 1.72632  last_update 0\n",
      "train: iter 66  trainloss 1.67774  validloss 1.70135±0.00000  bestvalidloss 1.70135  last_update 0\n",
      "train: iter 67  trainloss 1.65143  validloss 1.67304±0.00000  bestvalidloss 1.67304  last_update 0\n",
      "train: iter 68  trainloss 1.62277  validloss 1.64639±0.00000  bestvalidloss 1.64639  last_update 0\n",
      "train: iter 69  trainloss 1.59368  validloss 1.62311±0.00000  bestvalidloss 1.62311  last_update 0\n",
      "train: iter 70  trainloss 1.56475  validloss 1.59241±0.00000  bestvalidloss 1.59241  last_update 0\n",
      "train: iter 71  trainloss 1.53278  validloss 1.56281±0.00000  bestvalidloss 1.56281  last_update 0\n",
      "train: iter 72  trainloss 1.50414  validloss 1.53166±0.00000  bestvalidloss 1.53166  last_update 0\n",
      "train: iter 73  trainloss 1.47386  validloss 1.49615±0.00000  bestvalidloss 1.49615  last_update 0\n",
      "train: iter 74  trainloss 1.44072  validloss 1.47383±0.00000  bestvalidloss 1.47383  last_update 0\n",
      "train: iter 75  trainloss 1.40938  validloss 1.44856±0.00000  bestvalidloss 1.44856  last_update 0\n",
      "train: iter 76  trainloss 1.38100  validloss 1.41966±0.00000  bestvalidloss 1.41966  last_update 0\n",
      "train: iter 77  trainloss 1.34879  validloss 1.38325±0.00000  bestvalidloss 1.38325  last_update 0\n",
      "train: iter 78  trainloss 1.31434  validloss 1.36665±0.00000  bestvalidloss 1.36665  last_update 0\n",
      "train: iter 79  trainloss 1.29334  validloss 1.33609±0.00000  bestvalidloss 1.33609  last_update 0\n",
      "train: iter 80  trainloss 1.26057  validloss 1.30163±0.00000  bestvalidloss 1.30163  last_update 0\n",
      "train: iter 81  trainloss 1.23530  validloss 1.28259±0.00000  bestvalidloss 1.28259  last_update 0\n",
      "train: iter 82  trainloss 1.21194  validloss 1.26271±0.00000  bestvalidloss 1.26271  last_update 0\n",
      "train: iter 83  trainloss 1.18752  validloss 1.23411±0.00000  bestvalidloss 1.23411  last_update 0\n",
      "train: iter 84  trainloss 1.17010  validloss 1.19934±0.00000  bestvalidloss 1.19934  last_update 0\n",
      "train: iter 85  trainloss 1.14730  validloss 1.20589±0.00000  bestvalidloss 1.19934  last_update 1\n",
      "train: iter 86  trainloss 1.12679  validloss 1.19890±0.00000  bestvalidloss 1.19890  last_update 0\n",
      "train: iter 87  trainloss 1.11566  validloss 1.17632±0.00000  bestvalidloss 1.17632  last_update 0\n",
      "train: iter 88  trainloss 1.09322  validloss 1.13800±0.00000  bestvalidloss 1.13800  last_update 0\n",
      "train: iter 89  trainloss 1.09934  validloss 1.15674±0.00000  bestvalidloss 1.13800  last_update 1\n",
      "train: iter 90  trainloss 1.06675  validloss 1.14361±0.00000  bestvalidloss 1.13800  last_update 2\n",
      "train: iter 91  trainloss 1.07358  validloss 1.14315±0.00000  bestvalidloss 1.13800  last_update 3\n",
      "train: iter 92  trainloss 1.06677  validloss 1.14700±0.00000  bestvalidloss 1.13800  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 93  trainloss 1.04481  validloss 1.11821±0.00000  bestvalidloss 1.11821  last_update 0\n",
      "train: iter 94  trainloss 1.04659  validloss 1.11212±0.00000  bestvalidloss 1.11212  last_update 0\n",
      "train: iter 95  trainloss 1.04365  validloss 1.10817±0.00000  bestvalidloss 1.10817  last_update 0\n",
      "train: iter 96  trainloss 1.03212  validloss 1.11960±0.00000  bestvalidloss 1.10817  last_update 1\n",
      "train: iter 97  trainloss 1.01765  validloss 1.09459±0.00000  bestvalidloss 1.09459  last_update 0\n",
      "train: iter 98  trainloss 1.03505  validloss 1.10799±0.00000  bestvalidloss 1.09459  last_update 1\n",
      "train: iter 99  trainloss 1.01343  validloss 1.08877±0.00000  bestvalidloss 1.08877  last_update 0\n",
      "train: iter 100  trainloss 1.02081  validloss 1.07820±0.00000  bestvalidloss 1.07820  last_update 0\n",
      "train: iter 101  trainloss 1.02168  validloss 1.10754±0.00000  bestvalidloss 1.07820  last_update 1\n",
      "train: iter 102  trainloss 1.02487  validloss 1.11206±0.00000  bestvalidloss 1.07820  last_update 2\n",
      "train: iter 103  trainloss 1.01211  validloss 1.09815±0.00000  bestvalidloss 1.07820  last_update 3\n",
      "train: iter 104  trainloss 0.99606  validloss 1.11751±0.00000  bestvalidloss 1.07820  last_update 4\n",
      "train: iter 105  trainloss 1.00634  validloss 1.09497±0.00000  bestvalidloss 1.07820  last_update 5\n",
      "train: iter 106  trainloss 0.99631  validloss 1.09977±0.00000  bestvalidloss 1.07820  last_update 6\n",
      "train: iter 107  trainloss 1.00026  validloss 1.10573±0.00000  bestvalidloss 1.07820  last_update 7\n",
      "train: iter 108  trainloss 1.00928  validloss 1.11974±0.00000  bestvalidloss 1.07820  last_update 8\n",
      "train: iter 109  trainloss 1.00272  validloss 1.08114±0.00000  bestvalidloss 1.07820  last_update 9\n",
      "train: iter 110  trainloss 1.00328  validloss 1.07941±0.00000  bestvalidloss 1.07820  last_update 10\n",
      "train: iter 111  trainloss 1.00199  validloss 1.09128±0.00000  bestvalidloss 1.07820  last_update 11\n",
      "train: iter 112  trainloss 0.99393  validloss 1.10607±0.00000  bestvalidloss 1.07820  last_update 12\n",
      "train: iter 113  trainloss 0.99289  validloss 1.13398±0.00000  bestvalidloss 1.07820  last_update 13\n",
      "train: iter 114  trainloss 0.99254  validloss 1.10849±0.00000  bestvalidloss 1.07820  last_update 14\n",
      "train: iter 115  trainloss 0.98510  validloss 1.07469±0.00000  bestvalidloss 1.07469  last_update 0\n",
      "train: iter 116  trainloss 0.98078  validloss 1.11365±0.00000  bestvalidloss 1.07469  last_update 1\n",
      "train: iter 117  trainloss 0.98242  validloss 1.14581±0.00000  bestvalidloss 1.07469  last_update 2\n",
      "train: iter 118  trainloss 0.99650  validloss 1.07275±0.00000  bestvalidloss 1.07275  last_update 0\n",
      "train: iter 119  trainloss 0.99188  validloss 1.10163±0.00000  bestvalidloss 1.07275  last_update 1\n",
      "train: iter 120  trainloss 0.97760  validloss 1.06809±0.00000  bestvalidloss 1.06809  last_update 0\n",
      "train: iter 121  trainloss 0.96839  validloss 1.14006±0.00000  bestvalidloss 1.06809  last_update 1\n",
      "train: iter 122  trainloss 0.97487  validloss 1.09692±0.00000  bestvalidloss 1.06809  last_update 2\n",
      "train: iter 123  trainloss 0.97837  validloss 1.09061±0.00000  bestvalidloss 1.06809  last_update 3\n",
      "train: iter 124  trainloss 0.98950  validloss 1.11120±0.00000  bestvalidloss 1.06809  last_update 4\n",
      "train: iter 125  trainloss 0.97333  validloss 1.08727±0.00000  bestvalidloss 1.06809  last_update 5\n",
      "train: iter 126  trainloss 0.98857  validloss 1.08624±0.00000  bestvalidloss 1.06809  last_update 6\n",
      "train: iter 127  trainloss 0.99899  validloss 1.09617±0.00000  bestvalidloss 1.06809  last_update 7\n",
      "train: iter 128  trainloss 0.96399  validloss 1.12537±0.00000  bestvalidloss 1.06809  last_update 8\n",
      "train: iter 129  trainloss 0.98961  validloss 1.10025±0.00000  bestvalidloss 1.06809  last_update 9\n",
      "train: iter 130  trainloss 0.97513  validloss 1.09213±0.00000  bestvalidloss 1.06809  last_update 10\n",
      "train: iter 131  trainloss 0.97644  validloss 1.11728±0.00000  bestvalidloss 1.06809  last_update 11\n",
      "train: iter 132  trainloss 0.98819  validloss 1.06903±0.00000  bestvalidloss 1.06809  last_update 12\n",
      "train: iter 133  trainloss 0.96167  validloss 1.12415±0.00000  bestvalidloss 1.06809  last_update 13\n",
      "train: iter 134  trainloss 0.98161  validloss 1.12410±0.00000  bestvalidloss 1.06809  last_update 14\n",
      "train: iter 135  trainloss 0.96775  validloss 1.11881±0.00000  bestvalidloss 1.06809  last_update 15\n",
      "train: iter 136  trainloss 0.97843  validloss 1.14416±0.00000  bestvalidloss 1.06809  last_update 16\n",
      "train: iter 137  trainloss 0.96672  validloss 1.10818±0.00000  bestvalidloss 1.06809  last_update 17\n",
      "train: iter 138  trainloss 0.96524  validloss 1.09638±0.00000  bestvalidloss 1.06809  last_update 18\n",
      "train: iter 139  trainloss 0.98078  validloss 1.11695±0.00000  bestvalidloss 1.06809  last_update 19\n",
      "train: iter 140  trainloss 0.95349  validloss 1.10635±0.00000  bestvalidloss 1.06809  last_update 20\n",
      "train: iter 141  trainloss 0.98484  validloss 1.09619±0.00000  bestvalidloss 1.06809  last_update 21\n",
      "train: iter 142  trainloss 0.97545  validloss 1.09785±0.00000  bestvalidloss 1.06809  last_update 22\n",
      "train: iter 143  trainloss 0.97472  validloss 1.13051±0.00000  bestvalidloss 1.06809  last_update 23\n",
      "train: iter 144  trainloss 0.97493  validloss 1.11902±0.00000  bestvalidloss 1.06809  last_update 24\n",
      "train: iter 145  trainloss 0.97466  validloss 1.09194±0.00000  bestvalidloss 1.06809  last_update 25\n",
      "train: iter 146  trainloss 0.98113  validloss 1.09475±0.00000  bestvalidloss 1.06809  last_update 26\n",
      "train: iter 147  trainloss 0.98462  validloss 1.09890±0.00000  bestvalidloss 1.06809  last_update 27\n",
      "train: iter 148  trainloss 0.97031  validloss 1.10370±0.00000  bestvalidloss 1.06809  last_update 28\n",
      "train: iter 149  trainloss 0.97325  validloss 1.10634±0.00000  bestvalidloss 1.06809  last_update 29\n",
      "train: iter 150  trainloss 0.98732  validloss 1.11257±0.00000  bestvalidloss 1.06809  last_update 30\n",
      "train: iter 151  trainloss 0.98025  validloss 1.05595±0.00000  bestvalidloss 1.05595  last_update 0\n",
      "train: iter 152  trainloss 0.96923  validloss 1.15305±0.00000  bestvalidloss 1.05595  last_update 1\n",
      "train: iter 153  trainloss 0.97694  validloss 1.05875±0.00000  bestvalidloss 1.05595  last_update 2\n",
      "train: iter 154  trainloss 0.99772  validloss 1.07771±0.00000  bestvalidloss 1.05595  last_update 3\n",
      "train: iter 155  trainloss 0.97417  validloss 1.11333±0.00000  bestvalidloss 1.05595  last_update 4\n",
      "train: iter 156  trainloss 0.97848  validloss 1.14964±0.00000  bestvalidloss 1.05595  last_update 5\n",
      "train: iter 157  trainloss 0.96722  validloss 1.09488±0.00000  bestvalidloss 1.05595  last_update 6\n",
      "train: iter 158  trainloss 0.95746  validloss 1.08202±0.00000  bestvalidloss 1.05595  last_update 7\n",
      "train: iter 159  trainloss 0.97030  validloss 1.07840±0.00000  bestvalidloss 1.05595  last_update 8\n",
      "train: iter 160  trainloss 0.97886  validloss 1.11862±0.00000  bestvalidloss 1.05595  last_update 9\n",
      "train: iter 161  trainloss 0.98132  validloss 1.07366±0.00000  bestvalidloss 1.05595  last_update 10\n",
      "train: iter 162  trainloss 0.97648  validloss 1.07738±0.00000  bestvalidloss 1.05595  last_update 11\n",
      "train: iter 163  trainloss 0.96223  validloss 1.12625±0.00000  bestvalidloss 1.05595  last_update 12\n",
      "train: iter 164  trainloss 0.98524  validloss 1.10264±0.00000  bestvalidloss 1.05595  last_update 13\n",
      "train: iter 165  trainloss 0.97704  validloss 1.11625±0.00000  bestvalidloss 1.05595  last_update 14\n",
      "train: iter 166  trainloss 0.99666  validloss 1.08534±0.00000  bestvalidloss 1.05595  last_update 15\n",
      "train: iter 167  trainloss 0.97800  validloss 1.07191±0.00000  bestvalidloss 1.05595  last_update 16\n",
      "train: iter 168  trainloss 0.98326  validloss 1.06528±0.00000  bestvalidloss 1.05595  last_update 17\n",
      "train: iter 169  trainloss 0.96923  validloss 1.09196±0.00000  bestvalidloss 1.05595  last_update 18\n",
      "train: iter 170  trainloss 0.96149  validloss 1.15274±0.00000  bestvalidloss 1.05595  last_update 19\n",
      "train: iter 171  trainloss 0.97798  validloss 1.06303±0.00000  bestvalidloss 1.05595  last_update 20\n",
      "train: iter 172  trainloss 0.95871  validloss 1.09265±0.00000  bestvalidloss 1.05595  last_update 21\n",
      "train: iter 173  trainloss 0.99671  validloss 1.09595±0.00000  bestvalidloss 1.05595  last_update 22\n",
      "train: iter 174  trainloss 0.99120  validloss 1.09371±0.00000  bestvalidloss 1.05595  last_update 23\n",
      "train: iter 175  trainloss 0.98641  validloss 1.10215±0.00000  bestvalidloss 1.05595  last_update 24\n",
      "train: iter 176  trainloss 0.97549  validloss 1.09128±0.00000  bestvalidloss 1.05595  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 177  trainloss 0.98956  validloss 1.06999±0.00000  bestvalidloss 1.05595  last_update 26\n",
      "train: iter 178  trainloss 0.99328  validloss 1.10566±0.00000  bestvalidloss 1.05595  last_update 27\n",
      "train: iter 179  trainloss 0.98071  validloss 1.09031±0.00000  bestvalidloss 1.05595  last_update 28\n",
      "train: iter 180  trainloss 0.95983  validloss 1.10411±0.00000  bestvalidloss 1.05595  last_update 29\n",
      "train: iter 181  trainloss 0.98209  validloss 1.14214±0.00000  bestvalidloss 1.05595  last_update 30\n",
      "train: iter 182  trainloss 0.99250  validloss 1.13251±0.00000  bestvalidloss 1.05595  last_update 31\n",
      "train: iter 183  trainloss 0.97474  validloss 1.09084±0.00000  bestvalidloss 1.05595  last_update 32\n",
      "train: iter 184  trainloss 0.96909  validloss 1.10242±0.00000  bestvalidloss 1.05595  last_update 33\n",
      "train: iter 185  trainloss 0.95421  validloss 1.12035±0.00000  bestvalidloss 1.05595  last_update 34\n",
      "train: iter 186  trainloss 0.99239  validloss 1.15338±0.00000  bestvalidloss 1.05595  last_update 35\n",
      "train: iter 187  trainloss 0.98646  validloss 1.09757±0.00000  bestvalidloss 1.05595  last_update 36\n",
      "train: iter 188  trainloss 0.99232  validloss 1.10683±0.00000  bestvalidloss 1.05595  last_update 37\n",
      "train: iter 189  trainloss 0.98397  validloss 1.15572±0.00000  bestvalidloss 1.05595  last_update 38\n",
      "train: iter 190  trainloss 0.96860  validloss 1.10513±0.00000  bestvalidloss 1.05595  last_update 39\n",
      "train: iter 191  trainloss 0.95663  validloss 1.10188±0.00000  bestvalidloss 1.05595  last_update 40\n",
      "train: iter 192  trainloss 0.96910  validloss 1.07358±0.00000  bestvalidloss 1.05595  last_update 41\n",
      "train: iter 193  trainloss 0.98701  validloss 1.14120±0.00000  bestvalidloss 1.05595  last_update 42\n",
      "train: iter 194  trainloss 0.95379  validloss 1.10134±0.00000  bestvalidloss 1.05595  last_update 43\n",
      "train: iter 195  trainloss 0.97346  validloss 1.10221±0.00000  bestvalidloss 1.05595  last_update 44\n",
      "train: iter 196  trainloss 0.97537  validloss 1.10701±0.00000  bestvalidloss 1.05595  last_update 45\n",
      "train: iter 197  trainloss 0.98348  validloss 1.06691±0.00000  bestvalidloss 1.05595  last_update 46\n",
      "train: iter 198  trainloss 0.97687  validloss 1.15639±0.00000  bestvalidloss 1.05595  last_update 47\n",
      "train: iter 199  trainloss 0.97901  validloss 1.14354±0.00000  bestvalidloss 1.05595  last_update 48\n",
      "train: iter 200  trainloss 0.96528  validloss 1.10813±0.00000  bestvalidloss 1.05595  last_update 49\n",
      "train: iter 201  trainloss 0.97764  validloss 1.10372±0.00000  bestvalidloss 1.05595  last_update 50\n",
      "train: iter 202  trainloss 0.96694  validloss 1.10524±0.00000  bestvalidloss 1.05595  last_update 51\n",
      "train: iter 203  trainloss 0.98695  validloss 1.09661±0.00000  bestvalidloss 1.05595  last_update 52\n",
      "train: iter 204  trainloss 1.00227  validloss 1.10133±0.00000  bestvalidloss 1.05595  last_update 53\n",
      "train: iter 205  trainloss 0.97520  validloss 1.18500±0.00000  bestvalidloss 1.05595  last_update 54\n",
      "train: iter 206  trainloss 0.97144  validloss 1.08730±0.00000  bestvalidloss 1.05595  last_update 55\n",
      "train: iter 207  trainloss 0.97147  validloss 1.13316±0.00000  bestvalidloss 1.05595  last_update 56\n",
      "train: iter 208  trainloss 0.98425  validloss 1.10215±0.00000  bestvalidloss 1.05595  last_update 57\n",
      "train: iter 209  trainloss 0.96665  validloss 1.13015±0.00000  bestvalidloss 1.05595  last_update 58\n",
      "train: iter 210  trainloss 0.98553  validloss 1.11215±0.00000  bestvalidloss 1.05595  last_update 59\n",
      "train: iter 211  trainloss 0.97270  validloss 1.10944±0.00000  bestvalidloss 1.05595  last_update 60\n",
      "train: iter 212  trainloss 0.97318  validloss 1.14334±0.00000  bestvalidloss 1.05595  last_update 61\n",
      "train: iter 213  trainloss 0.97560  validloss 1.15440±0.00000  bestvalidloss 1.05595  last_update 62\n",
      "train: iter 214  trainloss 0.98796  validloss 1.12175±0.00000  bestvalidloss 1.05595  last_update 63\n",
      "train: iter 215  trainloss 0.95149  validloss 1.12761±0.00000  bestvalidloss 1.05595  last_update 64\n",
      "train: iter 216  trainloss 0.96822  validloss 1.12650±0.00000  bestvalidloss 1.05595  last_update 65\n",
      "train: iter 217  trainloss 0.95261  validloss 1.10239±0.00000  bestvalidloss 1.05595  last_update 66\n",
      "train: iter 218  trainloss 0.97191  validloss 1.08239±0.00000  bestvalidloss 1.05595  last_update 67\n",
      "train: iter 219  trainloss 0.97756  validloss 1.07849±0.00000  bestvalidloss 1.05595  last_update 68\n",
      "train: iter 220  trainloss 1.00246  validloss 1.07624±0.00000  bestvalidloss 1.05595  last_update 69\n",
      "train: iter 221  trainloss 0.98336  validloss 1.08772±0.00000  bestvalidloss 1.05595  last_update 70\n",
      "train: iter 222  trainloss 0.99679  validloss 1.12560±0.00000  bestvalidloss 1.05595  last_update 71\n",
      "train: iter 223  trainloss 0.98003  validloss 1.08986±0.00000  bestvalidloss 1.05595  last_update 72\n",
      "train: iter 224  trainloss 0.96923  validloss 1.13291±0.00000  bestvalidloss 1.05595  last_update 73\n",
      "train: iter 225  trainloss 0.98228  validloss 1.09601±0.00000  bestvalidloss 1.05595  last_update 74\n",
      "train: iter 226  trainloss 0.97066  validloss 1.09922±0.00000  bestvalidloss 1.05595  last_update 75\n",
      "train: iter 227  trainloss 0.98602  validloss 1.09162±0.00000  bestvalidloss 1.05595  last_update 76\n",
      "train: iter 228  trainloss 0.96427  validloss 1.11952±0.00000  bestvalidloss 1.05595  last_update 77\n",
      "train: iter 229  trainloss 0.95658  validloss 1.07154±0.00000  bestvalidloss 1.05595  last_update 78\n",
      "train: iter 230  trainloss 0.98420  validloss 1.10919±0.00000  bestvalidloss 1.05595  last_update 79\n",
      "train: iter 231  trainloss 0.98793  validloss 1.10150±0.00000  bestvalidloss 1.05595  last_update 80\n",
      "train: iter 232  trainloss 0.97609  validloss 1.12637±0.00000  bestvalidloss 1.05595  last_update 81\n",
      "train: iter 233  trainloss 0.96093  validloss 1.12001±0.00000  bestvalidloss 1.05595  last_update 82\n",
      "train: iter 234  trainloss 0.98692  validloss 1.06235±0.00000  bestvalidloss 1.05595  last_update 83\n",
      "train: iter 235  trainloss 0.96647  validloss 1.12527±0.00000  bestvalidloss 1.05595  last_update 84\n",
      "train: iter 236  trainloss 0.95480  validloss 1.11569±0.00000  bestvalidloss 1.05595  last_update 85\n",
      "train: iter 237  trainloss 0.95937  validloss 1.15000±0.00000  bestvalidloss 1.05595  last_update 86\n",
      "train: iter 238  trainloss 0.98235  validloss 1.06978±0.00000  bestvalidloss 1.05595  last_update 87\n",
      "train: iter 239  trainloss 0.98767  validloss 1.11518±0.00000  bestvalidloss 1.05595  last_update 88\n",
      "train: iter 240  trainloss 0.96348  validloss 1.12621±0.00000  bestvalidloss 1.05595  last_update 89\n",
      "train: iter 241  trainloss 1.00875  validloss 1.08919±0.00000  bestvalidloss 1.05595  last_update 90\n",
      "train: iter 242  trainloss 0.97048  validloss 1.11041±0.00000  bestvalidloss 1.05595  last_update 91\n",
      "train: iter 243  trainloss 0.97269  validloss 1.08531±0.00000  bestvalidloss 1.05595  last_update 92\n",
      "train: iter 244  trainloss 0.99904  validloss 1.08891±0.00000  bestvalidloss 1.05595  last_update 93\n",
      "train: iter 245  trainloss 0.96658  validloss 1.12573±0.00000  bestvalidloss 1.05595  last_update 94\n",
      "train: iter 246  trainloss 0.94357  validloss 1.10782±0.00000  bestvalidloss 1.05595  last_update 95\n",
      "train: iter 247  trainloss 0.97932  validloss 1.13617±0.00000  bestvalidloss 1.05595  last_update 96\n",
      "train: iter 248  trainloss 0.96041  validloss 1.11941±0.00000  bestvalidloss 1.05595  last_update 97\n",
      "train: iter 249  trainloss 0.96213  validloss 1.12142±0.00000  bestvalidloss 1.05595  last_update 98\n",
      "train: iter 250  trainloss 0.99236  validloss 1.08653±0.00000  bestvalidloss 1.05595  last_update 99\n",
      "train: iter 251  trainloss 0.97861  validloss 1.10026±0.00000  bestvalidloss 1.05595  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 4.1829, -0.8126], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 13.56270  validloss 19.05753±0.00000  bestvalidloss 19.05753  last_update 0\n",
      "train: iter 1  trainloss 7.38508  validloss 10.75205±0.00000  bestvalidloss 10.75205  last_update 0\n",
      "train: iter 2  trainloss 4.64278  validloss 5.65550±0.00000  bestvalidloss 5.65550  last_update 0\n",
      "train: iter 3  trainloss 3.58096  validloss 3.60660±0.00000  bestvalidloss 3.60660  last_update 0\n",
      "train: iter 4  trainloss 3.13072  validloss 2.43010±0.00000  bestvalidloss 2.43010  last_update 0\n",
      "train: iter 5  trainloss 2.85322  validloss 1.84143±0.00000  bestvalidloss 1.84143  last_update 0\n",
      "train: iter 6  trainloss 2.71012  validloss 1.52654±0.00000  bestvalidloss 1.52654  last_update 0\n",
      "train: iter 7  trainloss 2.62996  validloss 1.36657±0.00000  bestvalidloss 1.36657  last_update 0\n",
      "train: iter 8  trainloss 2.56638  validloss 1.26664±0.00000  bestvalidloss 1.26664  last_update 0\n",
      "train: iter 9  trainloss 2.53720  validloss 1.19561±0.00000  bestvalidloss 1.19561  last_update 0\n",
      "train: iter 10  trainloss 2.43124  validloss 1.18050±0.00000  bestvalidloss 1.18050  last_update 0\n",
      "train: iter 11  trainloss 2.36004  validloss 1.16169±0.00000  bestvalidloss 1.16169  last_update 0\n",
      "train: iter 12  trainloss 2.29078  validloss 1.12135±0.00000  bestvalidloss 1.12135  last_update 0\n",
      "train: iter 13  trainloss 2.22717  validloss 1.13847±0.00000  bestvalidloss 1.12135  last_update 1\n",
      "train: iter 14  trainloss 2.11047  validloss 1.07267±0.00000  bestvalidloss 1.07267  last_update 0\n",
      "train: iter 15  trainloss 1.98882  validloss 0.99746±0.00000  bestvalidloss 0.99746  last_update 0\n",
      "train: iter 16  trainloss 1.88547  validloss 1.15471±0.00000  bestvalidloss 0.99746  last_update 1\n",
      "train: iter 17  trainloss 1.80020  validloss 0.94659±0.00000  bestvalidloss 0.94659  last_update 0\n",
      "train: iter 18  trainloss 1.75523  validloss 0.95447±0.00000  bestvalidloss 0.94659  last_update 1\n",
      "train: iter 19  trainloss 1.71548  validloss 1.03529±0.00000  bestvalidloss 0.94659  last_update 2\n",
      "train: iter 20  trainloss 1.66179  validloss 0.88744±0.00000  bestvalidloss 0.88744  last_update 0\n",
      "train: iter 21  trainloss 1.67618  validloss 1.10530±0.00000  bestvalidloss 0.88744  last_update 1\n",
      "train: iter 22  trainloss 1.67361  validloss 0.90547±0.00000  bestvalidloss 0.88744  last_update 2\n",
      "train: iter 23  trainloss 1.65035  validloss 0.92552±0.00000  bestvalidloss 0.88744  last_update 3\n",
      "train: iter 24  trainloss 1.64231  validloss 0.99104±0.00000  bestvalidloss 0.88744  last_update 4\n",
      "train: iter 25  trainloss 1.63037  validloss 0.86499±0.00000  bestvalidloss 0.86499  last_update 0\n",
      "train: iter 26  trainloss 1.61908  validloss 0.83223±0.00000  bestvalidloss 0.83223  last_update 0\n",
      "train: iter 27  trainloss 1.60688  validloss 0.83890±0.00000  bestvalidloss 0.83223  last_update 1\n",
      "train: iter 28  trainloss 1.62205  validloss 0.94003±0.00000  bestvalidloss 0.83223  last_update 2\n",
      "train: iter 29  trainloss 1.62760  validloss 0.83286±0.00000  bestvalidloss 0.83223  last_update 3\n",
      "train: iter 30  trainloss 1.59028  validloss 0.87276±0.00000  bestvalidloss 0.83223  last_update 4\n",
      "train: iter 31  trainloss 1.59701  validloss 0.84355±0.00000  bestvalidloss 0.83223  last_update 5\n",
      "train: iter 32  trainloss 1.62685  validloss 0.89496±0.00000  bestvalidloss 0.83223  last_update 6\n",
      "train: iter 33  trainloss 1.58294  validloss 0.93250±0.00000  bestvalidloss 0.83223  last_update 7\n",
      "train: iter 34  trainloss 1.63210  validloss 0.88763±0.00000  bestvalidloss 0.83223  last_update 8\n",
      "train: iter 35  trainloss 1.61489  validloss 0.96272±0.00000  bestvalidloss 0.83223  last_update 9\n",
      "train: iter 36  trainloss 1.60010  validloss 0.95801±0.00000  bestvalidloss 0.83223  last_update 10\n",
      "train: iter 37  trainloss 1.61056  validloss 0.88388±0.00000  bestvalidloss 0.83223  last_update 11\n",
      "train: iter 38  trainloss 1.60432  validloss 0.83081±0.00000  bestvalidloss 0.83081  last_update 0\n",
      "train: iter 39  trainloss 1.61026  validloss 0.85393±0.00000  bestvalidloss 0.83081  last_update 1\n",
      "train: iter 40  trainloss 1.59965  validloss 0.81984±0.00000  bestvalidloss 0.81984  last_update 0\n",
      "train: iter 41  trainloss 1.61854  validloss 0.92572±0.00000  bestvalidloss 0.81984  last_update 1\n",
      "train: iter 42  trainloss 1.59221  validloss 0.82739±0.00000  bestvalidloss 0.81984  last_update 2\n",
      "train: iter 43  trainloss 1.60880  validloss 0.96664±0.00000  bestvalidloss 0.81984  last_update 3\n",
      "train: iter 44  trainloss 1.59636  validloss 0.81363±0.00000  bestvalidloss 0.81363  last_update 0\n",
      "train: iter 45  trainloss 1.58276  validloss 0.82539±0.00000  bestvalidloss 0.81363  last_update 1\n",
      "train: iter 46  trainloss 1.60818  validloss 0.81072±0.00000  bestvalidloss 0.81072  last_update 0\n",
      "train: iter 47  trainloss 1.59854  validloss 0.85079±0.00000  bestvalidloss 0.81072  last_update 1\n",
      "train: iter 48  trainloss 1.61508  validloss 0.81910±0.00000  bestvalidloss 0.81072  last_update 2\n",
      "train: iter 49  trainloss 1.60150  validloss 0.87081±0.00000  bestvalidloss 0.81072  last_update 3\n",
      "train: iter 50  trainloss 1.57358  validloss 0.82280±0.00000  bestvalidloss 0.81072  last_update 4\n",
      "train: iter 51  trainloss 1.58999  validloss 1.00061±0.00000  bestvalidloss 0.81072  last_update 5\n",
      "train: iter 52  trainloss 1.62455  validloss 0.96529±0.00000  bestvalidloss 0.81072  last_update 6\n",
      "train: iter 53  trainloss 1.61700  validloss 0.89512±0.00000  bestvalidloss 0.81072  last_update 7\n",
      "train: iter 54  trainloss 1.59354  validloss 0.92518±0.00000  bestvalidloss 0.81072  last_update 8\n",
      "train: iter 55  trainloss 1.59959  validloss 1.00930±0.00000  bestvalidloss 0.81072  last_update 9\n",
      "train: iter 56  trainloss 1.59670  validloss 0.86654±0.00000  bestvalidloss 0.81072  last_update 10\n",
      "train: iter 57  trainloss 1.61826  validloss 0.85463±0.00000  bestvalidloss 0.81072  last_update 11\n",
      "train: iter 58  trainloss 1.61097  validloss 1.03495±0.00000  bestvalidloss 0.81072  last_update 12\n",
      "train: iter 59  trainloss 1.56696  validloss 0.94243±0.00000  bestvalidloss 0.81072  last_update 13\n",
      "train: iter 60  trainloss 1.61758  validloss 0.87038±0.00000  bestvalidloss 0.81072  last_update 14\n",
      "train: iter 61  trainloss 1.61124  validloss 0.80287±0.00000  bestvalidloss 0.80287  last_update 0\n",
      "train: iter 62  trainloss 1.65284  validloss 0.83554±0.00000  bestvalidloss 0.80287  last_update 1\n",
      "train: iter 63  trainloss 1.57512  validloss 0.86314±0.00000  bestvalidloss 0.80287  last_update 2\n",
      "train: iter 64  trainloss 1.56451  validloss 0.81394±0.00000  bestvalidloss 0.80287  last_update 3\n",
      "train: iter 65  trainloss 1.61746  validloss 0.86868±0.00000  bestvalidloss 0.80287  last_update 4\n",
      "train: iter 66  trainloss 1.60146  validloss 0.80284±0.00000  bestvalidloss 0.80284  last_update 0\n",
      "train: iter 67  trainloss 1.59892  validloss 0.81237±0.00000  bestvalidloss 0.80284  last_update 1\n",
      "train: iter 68  trainloss 1.61730  validloss 0.90637±0.00000  bestvalidloss 0.80284  last_update 2\n",
      "train: iter 69  trainloss 1.59995  validloss 0.83873±0.00000  bestvalidloss 0.80284  last_update 3\n",
      "train: iter 70  trainloss 1.58194  validloss 0.85430±0.00000  bestvalidloss 0.80284  last_update 4\n",
      "train: iter 71  trainloss 1.58969  validloss 0.87326±0.00000  bestvalidloss 0.80284  last_update 5\n",
      "train: iter 72  trainloss 1.65282  validloss 0.91371±0.00000  bestvalidloss 0.80284  last_update 6\n",
      "train: iter 73  trainloss 1.63155  validloss 0.92082±0.00000  bestvalidloss 0.80284  last_update 7\n",
      "train: iter 74  trainloss 1.60185  validloss 0.81872±0.00000  bestvalidloss 0.80284  last_update 8\n",
      "train: iter 75  trainloss 1.58805  validloss 0.82038±0.00000  bestvalidloss 0.80284  last_update 9\n",
      "train: iter 76  trainloss 1.59958  validloss 0.90670±0.00000  bestvalidloss 0.80284  last_update 10\n",
      "train: iter 77  trainloss 1.59038  validloss 0.85514±0.00000  bestvalidloss 0.80284  last_update 11\n",
      "train: iter 78  trainloss 1.57618  validloss 0.95940±0.00000  bestvalidloss 0.80284  last_update 12\n",
      "train: iter 79  trainloss 1.62476  validloss 0.78758±0.00000  bestvalidloss 0.78758  last_update 0\n",
      "train: iter 80  trainloss 1.65914  validloss 0.85057±0.00000  bestvalidloss 0.78758  last_update 1\n",
      "train: iter 81  trainloss 1.58059  validloss 0.92265±0.00000  bestvalidloss 0.78758  last_update 2\n",
      "train: iter 82  trainloss 1.62199  validloss 0.96276±0.00000  bestvalidloss 0.78758  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.59801  validloss 0.92366±0.00000  bestvalidloss 0.78758  last_update 4\n",
      "train: iter 84  trainloss 1.60626  validloss 0.83681±0.00000  bestvalidloss 0.78758  last_update 5\n",
      "train: iter 85  trainloss 1.58826  validloss 0.94214±0.00000  bestvalidloss 0.78758  last_update 6\n",
      "train: iter 86  trainloss 1.63547  validloss 0.87971±0.00000  bestvalidloss 0.78758  last_update 7\n",
      "train: iter 87  trainloss 1.58966  validloss 0.88017±0.00000  bestvalidloss 0.78758  last_update 8\n",
      "train: iter 88  trainloss 1.59765  validloss 0.88559±0.00000  bestvalidloss 0.78758  last_update 9\n",
      "train: iter 89  trainloss 1.60323  validloss 0.80695±0.00000  bestvalidloss 0.78758  last_update 10\n",
      "train: iter 90  trainloss 1.59855  validloss 0.80078±0.00000  bestvalidloss 0.78758  last_update 11\n",
      "train: iter 91  trainloss 1.56869  validloss 0.85230±0.00000  bestvalidloss 0.78758  last_update 12\n",
      "train: iter 92  trainloss 1.61320  validloss 0.86395±0.00000  bestvalidloss 0.78758  last_update 13\n",
      "train: iter 93  trainloss 1.60099  validloss 0.79185±0.00000  bestvalidloss 0.78758  last_update 14\n",
      "train: iter 94  trainloss 1.60621  validloss 0.80599±0.00000  bestvalidloss 0.78758  last_update 15\n",
      "train: iter 95  trainloss 1.59732  validloss 0.87541±0.00000  bestvalidloss 0.78758  last_update 16\n",
      "train: iter 96  trainloss 1.58828  validloss 0.83649±0.00000  bestvalidloss 0.78758  last_update 17\n",
      "train: iter 97  trainloss 1.56024  validloss 0.83059±0.00000  bestvalidloss 0.78758  last_update 18\n",
      "train: iter 98  trainloss 1.62562  validloss 0.93523±0.00000  bestvalidloss 0.78758  last_update 19\n",
      "train: iter 99  trainloss 1.57346  validloss 0.83929±0.00000  bestvalidloss 0.78758  last_update 20\n",
      "train: iter 100  trainloss 1.57089  validloss 1.11083±0.00000  bestvalidloss 0.78758  last_update 21\n",
      "train: iter 101  trainloss 1.63264  validloss 0.87621±0.00000  bestvalidloss 0.78758  last_update 22\n",
      "train: iter 102  trainloss 1.57430  validloss 0.87281±0.00000  bestvalidloss 0.78758  last_update 23\n",
      "train: iter 103  trainloss 1.61176  validloss 0.88390±0.00000  bestvalidloss 0.78758  last_update 24\n",
      "train: iter 104  trainloss 1.60703  validloss 0.83937±0.00000  bestvalidloss 0.78758  last_update 25\n",
      "train: iter 105  trainloss 1.61517  validloss 0.79886±0.00000  bestvalidloss 0.78758  last_update 26\n",
      "train: iter 106  trainloss 1.61616  validloss 0.80265±0.00000  bestvalidloss 0.78758  last_update 27\n",
      "train: iter 107  trainloss 1.59516  validloss 0.89055±0.00000  bestvalidloss 0.78758  last_update 28\n",
      "train: iter 108  trainloss 1.57148  validloss 0.83287±0.00000  bestvalidloss 0.78758  last_update 29\n",
      "train: iter 109  trainloss 1.58286  validloss 0.83847±0.00000  bestvalidloss 0.78758  last_update 30\n",
      "train: iter 110  trainloss 1.61937  validloss 0.92693±0.00000  bestvalidloss 0.78758  last_update 31\n",
      "train: iter 111  trainloss 1.60405  validloss 0.87407±0.00000  bestvalidloss 0.78758  last_update 32\n",
      "train: iter 112  trainloss 1.60918  validloss 0.83202±0.00000  bestvalidloss 0.78758  last_update 33\n",
      "train: iter 113  trainloss 1.62071  validloss 0.92654±0.00000  bestvalidloss 0.78758  last_update 34\n",
      "train: iter 114  trainloss 1.60565  validloss 0.86130±0.00000  bestvalidloss 0.78758  last_update 35\n",
      "train: iter 115  trainloss 1.59701  validloss 0.94339±0.00000  bestvalidloss 0.78758  last_update 36\n",
      "train: iter 116  trainloss 1.58664  validloss 0.91113±0.00000  bestvalidloss 0.78758  last_update 37\n",
      "train: iter 117  trainloss 1.57738  validloss 0.82726±0.00000  bestvalidloss 0.78758  last_update 38\n",
      "train: iter 118  trainloss 1.61612  validloss 0.86355±0.00000  bestvalidloss 0.78758  last_update 39\n",
      "train: iter 119  trainloss 1.61791  validloss 0.92055±0.00000  bestvalidloss 0.78758  last_update 40\n",
      "train: iter 120  trainloss 1.58206  validloss 0.83817±0.00000  bestvalidloss 0.78758  last_update 41\n",
      "train: iter 121  trainloss 1.63394  validloss 0.82490±0.00000  bestvalidloss 0.78758  last_update 42\n",
      "train: iter 122  trainloss 1.61080  validloss 0.81412±0.00000  bestvalidloss 0.78758  last_update 43\n",
      "train: iter 123  trainloss 1.58680  validloss 0.80901±0.00000  bestvalidloss 0.78758  last_update 44\n",
      "train: iter 124  trainloss 1.58055  validloss 0.87590±0.00000  bestvalidloss 0.78758  last_update 45\n",
      "train: iter 125  trainloss 1.58200  validloss 0.95166±0.00000  bestvalidloss 0.78758  last_update 46\n",
      "train: iter 126  trainloss 1.57286  validloss 0.86156±0.00000  bestvalidloss 0.78758  last_update 47\n",
      "train: iter 127  trainloss 1.58053  validloss 1.04156±0.00000  bestvalidloss 0.78758  last_update 48\n",
      "train: iter 128  trainloss 1.57512  validloss 0.87611±0.00000  bestvalidloss 0.78758  last_update 49\n",
      "train: iter 129  trainloss 1.56892  validloss 0.82728±0.00000  bestvalidloss 0.78758  last_update 50\n",
      "train: iter 130  trainloss 1.58252  validloss 0.89870±0.00000  bestvalidloss 0.78758  last_update 51\n",
      "train: iter 131  trainloss 1.58233  validloss 0.84523±0.00000  bestvalidloss 0.78758  last_update 52\n",
      "train: iter 132  trainloss 1.58085  validloss 0.83110±0.00000  bestvalidloss 0.78758  last_update 53\n",
      "train: iter 133  trainloss 1.58275  validloss 0.87187±0.00000  bestvalidloss 0.78758  last_update 54\n",
      "train: iter 134  trainloss 1.59871  validloss 0.89287±0.00000  bestvalidloss 0.78758  last_update 55\n",
      "train: iter 135  trainloss 1.59442  validloss 0.81733±0.00000  bestvalidloss 0.78758  last_update 56\n",
      "train: iter 136  trainloss 1.57697  validloss 0.82753±0.00000  bestvalidloss 0.78758  last_update 57\n",
      "train: iter 137  trainloss 1.60817  validloss 0.81123±0.00000  bestvalidloss 0.78758  last_update 58\n",
      "train: iter 138  trainloss 1.58877  validloss 0.83850±0.00000  bestvalidloss 0.78758  last_update 59\n",
      "train: iter 139  trainloss 1.60825  validloss 0.83072±0.00000  bestvalidloss 0.78758  last_update 60\n",
      "train: iter 140  trainloss 1.57320  validloss 0.89754±0.00000  bestvalidloss 0.78758  last_update 61\n",
      "train: iter 141  trainloss 1.58948  validloss 0.90545±0.00000  bestvalidloss 0.78758  last_update 62\n",
      "train: iter 142  trainloss 1.60286  validloss 0.83205±0.00000  bestvalidloss 0.78758  last_update 63\n",
      "train: iter 143  trainloss 1.58668  validloss 0.89357±0.00000  bestvalidloss 0.78758  last_update 64\n",
      "train: iter 144  trainloss 1.60577  validloss 0.85366±0.00000  bestvalidloss 0.78758  last_update 65\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
