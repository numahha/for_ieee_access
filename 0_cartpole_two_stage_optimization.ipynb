{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-982.5344)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 677.04364  validloss 1447.06972±0.00000  bestvalidloss 1447.06972  last_update 0\n",
      "train: iter 1  trainloss 275.00991  validloss 611.47583±0.00000  bestvalidloss 611.47583  last_update 0\n",
      "train: iter 2  trainloss 230.53609  validloss 319.63634±0.00000  bestvalidloss 319.63634  last_update 0\n",
      "train: iter 3  trainloss 189.48451  validloss 382.02607±0.00000  bestvalidloss 319.63634  last_update 1\n",
      "train: iter 4  trainloss -24.66916  validloss 779.00643±0.00000  bestvalidloss 319.63634  last_update 2\n",
      "train: iter 5  trainloss -215.59346  validloss 213.92780±0.00000  bestvalidloss 213.92780  last_update 0\n",
      "train: iter 6  trainloss -138.66976  validloss -102.31381±0.00000  bestvalidloss -102.31381  last_update 0\n",
      "train: iter 7  trainloss -351.18372  validloss 148.99628±0.00000  bestvalidloss -102.31381  last_update 1\n",
      "train: iter 8  trainloss -436.71993  validloss -168.79200±0.00000  bestvalidloss -168.79200  last_update 0\n",
      "train: iter 9  trainloss -513.42676  validloss -284.63752±0.00000  bestvalidloss -284.63752  last_update 0\n",
      "train: iter 10  trainloss -609.54496  validloss -418.63991±0.00000  bestvalidloss -418.63991  last_update 0\n",
      "train: iter 11  trainloss -633.88550  validloss -514.07439±0.00000  bestvalidloss -514.07439  last_update 0\n",
      "train: iter 12  trainloss -583.12116  validloss -510.21330±0.00000  bestvalidloss -514.07439  last_update 1\n",
      "train: iter 13  trainloss -762.06264  validloss -535.64303±0.00000  bestvalidloss -535.64303  last_update 0\n",
      "train: iter 14  trainloss -805.33742  validloss -670.52970±0.00000  bestvalidloss -670.52970  last_update 0\n",
      "train: iter 15  trainloss -842.51015  validloss -705.58584±0.00000  bestvalidloss -705.58584  last_update 0\n",
      "train: iter 16  trainloss -868.82657  validloss -678.62575±0.00000  bestvalidloss -705.58584  last_update 1\n",
      "train: iter 17  trainloss -905.26279  validloss -704.85680±0.00000  bestvalidloss -705.58584  last_update 2\n",
      "train: iter 18  trainloss -896.62943  validloss -727.68282±0.00000  bestvalidloss -727.68282  last_update 0\n",
      "train: iter 19  trainloss -947.05819  validloss -699.35690±0.00000  bestvalidloss -727.68282  last_update 1\n",
      "train: iter 20  trainloss -976.13000  validloss -795.26688±0.00000  bestvalidloss -795.26688  last_update 0\n",
      "train: iter 21  trainloss -867.97604  validloss -736.75952±0.00000  bestvalidloss -795.26688  last_update 1\n",
      "train: iter 22  trainloss -1038.21671  validloss -773.12959±0.00000  bestvalidloss -795.26688  last_update 2\n",
      "train: iter 23  trainloss -979.89639  validloss -830.08276±0.00000  bestvalidloss -830.08276  last_update 0\n",
      "train: iter 24  trainloss -1089.43599  validloss -866.25158±0.00000  bestvalidloss -866.25158  last_update 0\n",
      "train: iter 25  trainloss -1041.86557  validloss -925.74802±0.00000  bestvalidloss -925.74802  last_update 0\n",
      "train: iter 26  trainloss -1150.13116  validloss -935.09125±0.00000  bestvalidloss -935.09125  last_update 0\n",
      "train: iter 27  trainloss -1160.15762  validloss -993.30054±0.00000  bestvalidloss -993.30054  last_update 0\n",
      "train: iter 28  trainloss -1077.79431  validloss -1039.79444±0.00000  bestvalidloss -1039.79444  last_update 0\n",
      "train: iter 29  trainloss -1163.49113  validloss -777.37990±0.00000  bestvalidloss -1039.79444  last_update 1\n",
      "train: iter 30  trainloss -1113.68157  validloss -1055.69216±0.00000  bestvalidloss -1055.69216  last_update 0\n",
      "train: iter 31  trainloss -1224.31432  validloss -1075.45397±0.00000  bestvalidloss -1075.45397  last_update 0\n",
      "train: iter 32  trainloss -1163.52603  validloss -962.95741±0.00000  bestvalidloss -1075.45397  last_update 1\n",
      "train: iter 33  trainloss -1219.80398  validloss -1095.38676±0.00000  bestvalidloss -1095.38676  last_update 0\n",
      "train: iter 34  trainloss -1233.40134  validloss -954.43037±0.00000  bestvalidloss -1095.38676  last_update 1\n",
      "train: iter 35  trainloss -1240.46721  validloss -1065.97028±0.00000  bestvalidloss -1095.38676  last_update 2\n",
      "train: iter 36  trainloss -1206.69246  validloss -1121.96840±0.00000  bestvalidloss -1121.96840  last_update 0\n",
      "train: iter 37  trainloss -1298.55529  validloss -1163.08782±0.00000  bestvalidloss -1163.08782  last_update 0\n",
      "train: iter 38  trainloss -1300.45081  validloss -1139.48262±0.00000  bestvalidloss -1163.08782  last_update 1\n",
      "train: iter 39  trainloss -1334.70576  validloss -1166.52476±0.00000  bestvalidloss -1166.52476  last_update 0\n",
      "train: iter 40  trainloss -1307.70002  validloss -1175.66330±0.00000  bestvalidloss -1175.66330  last_update 0\n",
      "train: iter 41  trainloss -1371.43156  validloss -1190.25142±0.00000  bestvalidloss -1190.25142  last_update 0\n",
      "train: iter 42  trainloss -1397.49378  validloss -1233.17414±0.00000  bestvalidloss -1233.17414  last_update 0\n",
      "train: iter 43  trainloss -1403.16378  validloss -1188.95160±0.00000  bestvalidloss -1233.17414  last_update 1\n",
      "train: iter 44  trainloss -1398.63213  validloss -1178.04179±0.00000  bestvalidloss -1233.17414  last_update 2\n",
      "train: iter 45  trainloss -1406.24401  validloss -1171.17130±0.00000  bestvalidloss -1233.17414  last_update 3\n",
      "train: iter 46  trainloss -1344.68977  validloss -1287.07915±0.00000  bestvalidloss -1287.07915  last_update 0\n",
      "train: iter 47  trainloss -1359.36809  validloss -1296.50139±0.00000  bestvalidloss -1296.50139  last_update 0\n",
      "train: iter 48  trainloss -1321.34110  validloss -1157.97161±0.00000  bestvalidloss -1296.50139  last_update 1\n",
      "train: iter 49  trainloss -1441.88211  validloss -1288.83099±0.00000  bestvalidloss -1296.50139  last_update 2\n",
      "train: iter 50  trainloss -1479.10961  validloss -1267.44495±0.00000  bestvalidloss -1296.50139  last_update 3\n",
      "train: iter 51  trainloss -1410.13637  validloss -1269.69291±0.00000  bestvalidloss -1296.50139  last_update 4\n",
      "train: iter 52  trainloss -1278.01297  validloss -1112.99081±0.00000  bestvalidloss -1296.50139  last_update 5\n",
      "train: iter 53  trainloss -1341.53241  validloss -1058.83752±0.00000  bestvalidloss -1296.50139  last_update 6\n",
      "train: iter 54  trainloss -1503.86738  validloss -1336.62850±0.00000  bestvalidloss -1336.62850  last_update 0\n",
      "train: iter 55  trainloss -1474.07822  validloss -1362.80305±0.00000  bestvalidloss -1362.80305  last_update 0\n",
      "train: iter 56  trainloss -1497.78867  validloss -1357.40938±0.00000  bestvalidloss -1362.80305  last_update 1\n",
      "train: iter 57  trainloss -1516.76289  validloss -1278.69766±0.00000  bestvalidloss -1362.80305  last_update 2\n",
      "train: iter 58  trainloss -1509.70271  validloss -1388.64021±0.00000  bestvalidloss -1388.64021  last_update 0\n",
      "train: iter 59  trainloss -1460.13028  validloss -1316.63299±0.00000  bestvalidloss -1388.64021  last_update 1\n",
      "train: iter 60  trainloss -1444.81118  validloss -1367.64284±0.00000  bestvalidloss -1388.64021  last_update 2\n",
      "train: iter 61  trainloss -1494.90886  validloss -1341.92689±0.00000  bestvalidloss -1388.64021  last_update 3\n",
      "train: iter 62  trainloss -1534.83197  validloss -1100.19250±0.00000  bestvalidloss -1388.64021  last_update 4\n",
      "train: iter 63  trainloss -1572.00764  validloss -1378.56130±0.00000  bestvalidloss -1388.64021  last_update 5\n",
      "train: iter 64  trainloss -1575.12743  validloss -1355.86111±0.00000  bestvalidloss -1388.64021  last_update 6\n",
      "train: iter 65  trainloss -1534.16445  validloss -1424.92798±0.00000  bestvalidloss -1424.92798  last_update 0\n",
      "train: iter 66  trainloss -1524.48017  validloss -1164.98257±0.00000  bestvalidloss -1424.92798  last_update 1\n",
      "train: iter 67  trainloss -1586.79553  validloss -1474.67574±0.00000  bestvalidloss -1474.67574  last_update 0\n",
      "train: iter 68  trainloss -1581.25185  validloss -1461.21875±0.00000  bestvalidloss -1474.67574  last_update 1\n",
      "train: iter 69  trainloss -1583.53402  validloss -1420.59198±0.00000  bestvalidloss -1474.67574  last_update 2\n",
      "train: iter 70  trainloss -1632.44406  validloss -1431.80567±0.00000  bestvalidloss -1474.67574  last_update 3\n",
      "train: iter 71  trainloss -1578.52515  validloss -1484.97588±0.00000  bestvalidloss -1484.97588  last_update 0\n",
      "train: iter 72  trainloss -1598.00648  validloss -1385.64519±0.00000  bestvalidloss -1484.97588  last_update 1\n",
      "train: iter 73  trainloss -1626.57889  validloss -1509.43587±0.00000  bestvalidloss -1509.43587  last_update 0\n",
      "train: iter 74  trainloss -1620.04078  validloss -1447.45561±0.00000  bestvalidloss -1509.43587  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1607.98417  validloss -1508.33909±0.00000  bestvalidloss -1509.43587  last_update 2\n",
      "train: iter 76  trainloss -1612.54191  validloss -1521.76674±0.00000  bestvalidloss -1521.76674  last_update 0\n",
      "train: iter 77  trainloss -1665.83600  validloss -1526.54995±0.00000  bestvalidloss -1526.54995  last_update 0\n",
      "train: iter 78  trainloss -1485.51722  validloss -1476.76448±0.00000  bestvalidloss -1526.54995  last_update 1\n",
      "train: iter 79  trainloss -1692.38349  validloss -1415.80595±0.00000  bestvalidloss -1526.54995  last_update 2\n",
      "train: iter 80  trainloss -1683.73759  validloss -1570.79718±0.00000  bestvalidloss -1570.79718  last_update 0\n",
      "train: iter 81  trainloss -1705.82208  validloss -1582.18178±0.00000  bestvalidloss -1582.18178  last_update 0\n",
      "train: iter 82  trainloss -1662.18519  validloss -1541.12486±0.00000  bestvalidloss -1582.18178  last_update 1\n",
      "train: iter 83  trainloss -1713.27349  validloss -1587.67801±0.00000  bestvalidloss -1587.67801  last_update 0\n",
      "train: iter 84  trainloss -1704.67028  validloss -1581.35750±0.00000  bestvalidloss -1587.67801  last_update 1\n",
      "train: iter 85  trainloss -1691.01714  validloss -1603.58415±0.00000  bestvalidloss -1603.58415  last_update 0\n",
      "train: iter 86  trainloss -1644.72827  validloss -1539.91916±0.00000  bestvalidloss -1603.58415  last_update 1\n",
      "train: iter 87  trainloss -1717.57298  validloss -1466.12841±0.00000  bestvalidloss -1603.58415  last_update 2\n",
      "train: iter 88  trainloss -1693.87981  validloss -1522.13313±0.00000  bestvalidloss -1603.58415  last_update 3\n",
      "train: iter 89  trainloss -1712.01836  validloss -1570.47188±0.00000  bestvalidloss -1603.58415  last_update 4\n",
      "train: iter 90  trainloss -1725.45293  validloss -1610.53350±0.00000  bestvalidloss -1610.53350  last_update 0\n",
      "train: iter 91  trainloss -1725.76637  validloss -1593.34574±0.00000  bestvalidloss -1610.53350  last_update 1\n",
      "train: iter 92  trainloss -1701.97250  validloss -1598.99101±0.00000  bestvalidloss -1610.53350  last_update 2\n",
      "train: iter 93  trainloss -1743.31404  validloss -1610.77745±0.00000  bestvalidloss -1610.77745  last_update 0\n",
      "train: iter 94  trainloss -1752.22941  validloss -1594.23455±0.00000  bestvalidloss -1610.77745  last_update 1\n",
      "train: iter 95  trainloss -1722.78111  validloss -1585.83854±0.00000  bestvalidloss -1610.77745  last_update 2\n",
      "train: iter 96  trainloss -1756.41053  validloss -1617.84750±0.00000  bestvalidloss -1617.84750  last_update 0\n",
      "train: iter 97  trainloss -1613.73826  validloss -1559.26734±0.00000  bestvalidloss -1617.84750  last_update 1\n",
      "train: iter 98  trainloss -1709.54688  validloss -1471.56981±0.00000  bestvalidloss -1617.84750  last_update 2\n",
      "train: iter 99  trainloss -1762.08115  validloss -1617.95081±0.00000  bestvalidloss -1617.95081  last_update 0\n",
      "train: iter 100  trainloss -1798.55598  validloss -1638.78949±0.00000  bestvalidloss -1638.78949  last_update 0\n",
      "train: iter 101  trainloss -1784.00769  validloss -1569.39801±0.00000  bestvalidloss -1638.78949  last_update 1\n",
      "train: iter 102  trainloss -1775.48253  validloss -1640.48595±0.00000  bestvalidloss -1640.48595  last_update 0\n",
      "train: iter 103  trainloss -1752.34711  validloss -1527.75258±0.00000  bestvalidloss -1640.48595  last_update 1\n",
      "train: iter 104  trainloss -1729.76439  validloss -1642.05974±0.00000  bestvalidloss -1642.05974  last_update 0\n",
      "train: iter 105  trainloss -1631.19629  validloss -1350.26749±0.00000  bestvalidloss -1642.05974  last_update 1\n",
      "train: iter 106  trainloss -1780.40366  validloss -1627.35042±0.00000  bestvalidloss -1642.05974  last_update 2\n",
      "train: iter 107  trainloss -1754.88190  validloss -1569.01253±0.00000  bestvalidloss -1642.05974  last_update 3\n",
      "train: iter 108  trainloss -1697.90352  validloss -1594.93329±0.00000  bestvalidloss -1642.05974  last_update 4\n",
      "train: iter 109  trainloss -1817.86439  validloss -1628.54936±0.00000  bestvalidloss -1642.05974  last_update 5\n",
      "train: iter 110  trainloss -1798.93022  validloss -1663.70364±0.00000  bestvalidloss -1663.70364  last_update 0\n",
      "train: iter 111  trainloss -1776.53961  validloss -1655.55666±0.00000  bestvalidloss -1663.70364  last_update 1\n",
      "train: iter 112  trainloss -1830.04467  validloss -1651.44255±0.00000  bestvalidloss -1663.70364  last_update 2\n",
      "train: iter 113  trainloss -1801.80296  validloss -1647.54159±0.00000  bestvalidloss -1663.70364  last_update 3\n",
      "train: iter 114  trainloss -1806.13816  validloss -1675.34419±0.00000  bestvalidloss -1675.34419  last_update 0\n",
      "train: iter 115  trainloss -1733.88950  validloss -1659.11840±0.00000  bestvalidloss -1675.34419  last_update 1\n",
      "train: iter 116  trainloss -1742.29313  validloss -1595.18732±0.00000  bestvalidloss -1675.34419  last_update 2\n",
      "train: iter 117  trainloss -1758.88046  validloss -1605.64056±0.00000  bestvalidloss -1675.34419  last_update 3\n",
      "train: iter 118  trainloss -1827.03848  validloss -1628.87989±0.00000  bestvalidloss -1675.34419  last_update 4\n",
      "train: iter 119  trainloss -1764.44294  validloss -1673.06875±0.00000  bestvalidloss -1675.34419  last_update 5\n",
      "train: iter 120  trainloss -1697.25112  validloss -1500.47672±0.00000  bestvalidloss -1675.34419  last_update 6\n",
      "train: iter 121  trainloss -1778.04266  validloss -1597.31017±0.00000  bestvalidloss -1675.34419  last_update 7\n",
      "train: iter 122  trainloss -1824.28524  validloss -1644.00538±0.00000  bestvalidloss -1675.34419  last_update 8\n",
      "train: iter 123  trainloss -1829.69848  validloss -1691.30601±0.00000  bestvalidloss -1691.30601  last_update 0\n",
      "train: iter 124  trainloss -1845.55926  validloss -1688.28219±0.00000  bestvalidloss -1691.30601  last_update 1\n",
      "train: iter 125  trainloss -1767.34536  validloss -1676.38973±0.00000  bestvalidloss -1691.30601  last_update 2\n",
      "train: iter 126  trainloss -1837.23633  validloss -1602.25009±0.00000  bestvalidloss -1691.30601  last_update 3\n",
      "train: iter 127  trainloss -1791.35559  validloss -1708.10203±0.00000  bestvalidloss -1708.10203  last_update 0\n",
      "train: iter 128  trainloss -1704.06989  validloss -1665.51286±0.00000  bestvalidloss -1708.10203  last_update 1\n",
      "train: iter 129  trainloss -1799.94045  validloss -1476.59798±0.00000  bestvalidloss -1708.10203  last_update 2\n",
      "train: iter 130  trainloss -1834.10709  validloss -1667.34536±0.00000  bestvalidloss -1708.10203  last_update 3\n",
      "train: iter 131  trainloss -1825.94713  validloss -1618.09757±0.00000  bestvalidloss -1708.10203  last_update 4\n",
      "train: iter 132  trainloss -1793.79828  validloss -1686.61296±0.00000  bestvalidloss -1708.10203  last_update 5\n",
      "train: iter 133  trainloss -1814.78309  validloss -1663.14676±0.00000  bestvalidloss -1708.10203  last_update 6\n",
      "train: iter 134  trainloss -1733.63456  validloss -1476.25439±0.00000  bestvalidloss -1708.10203  last_update 7\n",
      "train: iter 135  trainloss -1818.76174  validloss -1609.94720±0.00000  bestvalidloss -1708.10203  last_update 8\n",
      "train: iter 136  trainloss -1844.20785  validloss -1689.32355±0.00000  bestvalidloss -1708.10203  last_update 9\n",
      "train: iter 137  trainloss -1835.23963  validloss -1705.03856±0.00000  bestvalidloss -1708.10203  last_update 10\n",
      "train: iter 138  trainloss -1812.03525  validloss -1602.65607±0.00000  bestvalidloss -1708.10203  last_update 11\n",
      "train: iter 139  trainloss -1761.32312  validloss -1683.98647±0.00000  bestvalidloss -1708.10203  last_update 12\n",
      "train: iter 140  trainloss -1817.67789  validloss -1674.85171±0.00000  bestvalidloss -1708.10203  last_update 13\n",
      "train: iter 141  trainloss -1847.76566  validloss -1626.88126±0.00000  bestvalidloss -1708.10203  last_update 14\n",
      "train: iter 142  trainloss -1820.47986  validloss -1728.29920±0.00000  bestvalidloss -1728.29920  last_update 0\n",
      "train: iter 143  trainloss -1841.48142  validloss -1698.21696±0.00000  bestvalidloss -1728.29920  last_update 1\n",
      "train: iter 144  trainloss -1696.62435  validloss -1701.16777±0.00000  bestvalidloss -1728.29920  last_update 2\n",
      "train: iter 145  trainloss -1796.07793  validloss -1615.90629±0.00000  bestvalidloss -1728.29920  last_update 3\n",
      "train: iter 146  trainloss -1793.12047  validloss -1645.23424±0.00000  bestvalidloss -1728.29920  last_update 4\n",
      "train: iter 147  trainloss -1821.29006  validloss -1672.05019±0.00000  bestvalidloss -1728.29920  last_update 5\n",
      "train: iter 148  trainloss -1844.09836  validloss -1665.60244±0.00000  bestvalidloss -1728.29920  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -1796.82203  validloss -1675.07465±0.00000  bestvalidloss -1728.29920  last_update 7\n",
      "train: iter 150  trainloss -1868.24734  validloss -1657.36304±0.00000  bestvalidloss -1728.29920  last_update 8\n",
      "train: iter 151  trainloss -1872.75004  validloss -1696.09545±0.00000  bestvalidloss -1728.29920  last_update 9\n",
      "train: iter 152  trainloss -1861.18594  validloss -1729.63794±0.00000  bestvalidloss -1729.63794  last_update 0\n",
      "train: iter 153  trainloss -1849.89587  validloss -1735.84848±0.00000  bestvalidloss -1735.84848  last_update 0\n",
      "train: iter 154  trainloss -1777.11701  validloss -1683.28731±0.00000  bestvalidloss -1735.84848  last_update 1\n",
      "train: iter 155  trainloss -1736.50468  validloss -1045.31522±0.00000  bestvalidloss -1735.84848  last_update 2\n",
      "train: iter 156  trainloss -1834.38413  validloss -1675.32987±0.00000  bestvalidloss -1735.84848  last_update 3\n",
      "train: iter 157  trainloss -1866.02990  validloss -1685.31329±0.00000  bestvalidloss -1735.84848  last_update 4\n",
      "train: iter 158  trainloss -1845.82286  validloss -1714.57816±0.00000  bestvalidloss -1735.84848  last_update 5\n",
      "train: iter 159  trainloss -1881.06217  validloss -1739.14727±0.00000  bestvalidloss -1739.14727  last_update 0\n",
      "train: iter 160  trainloss -1837.59879  validloss -1720.64534±0.00000  bestvalidloss -1739.14727  last_update 1\n",
      "train: iter 161  trainloss -1821.19923  validloss -1568.29634±0.00000  bestvalidloss -1739.14727  last_update 2\n",
      "train: iter 162  trainloss -1883.82902  validloss -1722.06760±0.00000  bestvalidloss -1739.14727  last_update 3\n",
      "train: iter 163  trainloss -1853.14965  validloss -1731.63741±0.00000  bestvalidloss -1739.14727  last_update 4\n",
      "train: iter 164  trainloss -1857.02069  validloss -1715.98860±0.00000  bestvalidloss -1739.14727  last_update 5\n",
      "train: iter 165  trainloss -1798.89807  validloss -1696.16467±0.00000  bestvalidloss -1739.14727  last_update 6\n",
      "train: iter 166  trainloss -1780.74361  validloss -1533.13350±0.00000  bestvalidloss -1739.14727  last_update 7\n",
      "train: iter 167  trainloss -1822.96337  validloss -1670.98218±0.00000  bestvalidloss -1739.14727  last_update 8\n",
      "train: iter 168  trainloss -1745.71362  validloss -1616.11922±0.00000  bestvalidloss -1739.14727  last_update 9\n",
      "train: iter 169  trainloss -1856.62577  validloss -1644.27887±0.00000  bestvalidloss -1739.14727  last_update 10\n",
      "train: iter 170  trainloss -1887.59179  validloss -1748.85626±0.00000  bestvalidloss -1748.85626  last_update 0\n",
      "train: iter 171  trainloss -1874.02022  validloss -1737.14393±0.00000  bestvalidloss -1748.85626  last_update 1\n",
      "train: iter 172  trainloss -1876.09893  validloss -1665.83773±0.00000  bestvalidloss -1748.85626  last_update 2\n",
      "train: iter 173  trainloss -1825.19633  validloss -1712.41807±0.00000  bestvalidloss -1748.85626  last_update 3\n",
      "train: iter 174  trainloss -1827.99037  validloss -1554.71685±0.00000  bestvalidloss -1748.85626  last_update 4\n",
      "train: iter 175  trainloss -1881.98074  validloss -1712.44420±0.00000  bestvalidloss -1748.85626  last_update 5\n",
      "train: iter 176  trainloss -1901.49920  validloss -1734.46282±0.00000  bestvalidloss -1748.85626  last_update 6\n",
      "train: iter 177  trainloss -1891.05770  validloss -1747.59923±0.00000  bestvalidloss -1748.85626  last_update 7\n",
      "train: iter 178  trainloss -1800.52466  validloss -1658.60728±0.00000  bestvalidloss -1748.85626  last_update 8\n",
      "train: iter 179  trainloss -1870.84226  validloss -1668.25237±0.00000  bestvalidloss -1748.85626  last_update 9\n",
      "train: iter 180  trainloss -1854.78074  validloss -1750.15148±0.00000  bestvalidloss -1750.15148  last_update 0\n",
      "train: iter 181  trainloss -1714.54484  validloss -1699.92831±0.00000  bestvalidloss -1750.15148  last_update 1\n",
      "train: iter 182  trainloss -1752.39444  validloss -1490.99183±0.00000  bestvalidloss -1750.15148  last_update 2\n",
      "train: iter 183  trainloss -1888.74223  validloss -1700.25739±0.00000  bestvalidloss -1750.15148  last_update 3\n",
      "train: iter 184  trainloss -1883.23111  validloss -1754.53829±0.00000  bestvalidloss -1754.53829  last_update 0\n",
      "train: iter 185  trainloss -1869.51845  validloss -1716.72705±0.00000  bestvalidloss -1754.53829  last_update 1\n",
      "train: iter 186  trainloss -1870.99373  validloss -1732.72874±0.00000  bestvalidloss -1754.53829  last_update 2\n",
      "train: iter 187  trainloss -1862.55680  validloss -1600.22168±0.00000  bestvalidloss -1754.53829  last_update 3\n",
      "train: iter 188  trainloss -1856.22464  validloss -1750.28049±0.00000  bestvalidloss -1754.53829  last_update 4\n",
      "train: iter 189  trainloss -1856.66564  validloss -1679.66601±0.00000  bestvalidloss -1754.53829  last_update 5\n",
      "train: iter 190  trainloss -1866.40138  validloss -1736.00371±0.00000  bestvalidloss -1754.53829  last_update 6\n",
      "train: iter 191  trainloss -1867.90528  validloss -1730.71292±0.00000  bestvalidloss -1754.53829  last_update 7\n",
      "train: iter 192  trainloss -1866.79325  validloss -1692.29801±0.00000  bestvalidloss -1754.53829  last_update 8\n",
      "train: iter 193  trainloss -1894.05276  validloss -1733.14975±0.00000  bestvalidloss -1754.53829  last_update 9\n",
      "train: iter 194  trainloss -1785.67812  validloss -1685.76287±0.00000  bestvalidloss -1754.53829  last_update 10\n",
      "train: iter 195  trainloss -1837.83075  validloss -1652.21067±0.00000  bestvalidloss -1754.53829  last_update 11\n",
      "train: iter 196  trainloss -1893.61868  validloss -1715.32470±0.00000  bestvalidloss -1754.53829  last_update 12\n",
      "train: iter 197  trainloss -1883.69671  validloss -1769.03778±0.00000  bestvalidloss -1769.03778  last_update 0\n",
      "train: iter 198  trainloss -1880.45620  validloss -1724.99428±0.00000  bestvalidloss -1769.03778  last_update 1\n",
      "train: iter 199  trainloss -1891.91494  validloss -1668.13470±0.00000  bestvalidloss -1769.03778  last_update 2\n",
      "train: iter 200  trainloss -1822.60922  validloss -1638.06712±0.00000  bestvalidloss -1769.03778  last_update 3\n",
      "train: iter 201  trainloss -1799.11957  validloss -1667.19191±0.00000  bestvalidloss -1769.03778  last_update 4\n",
      "train: iter 202  trainloss -1866.66621  validloss -1704.17824±0.00000  bestvalidloss -1769.03778  last_update 5\n",
      "train: iter 203  trainloss -1853.32603  validloss -1701.57352±0.00000  bestvalidloss -1769.03778  last_update 6\n",
      "train: iter 204  trainloss -1899.63358  validloss -1691.13813±0.00000  bestvalidloss -1769.03778  last_update 7\n",
      "train: iter 205  trainloss -1921.05021  validloss -1769.65043±0.00000  bestvalidloss -1769.65043  last_update 0\n",
      "train: iter 206  trainloss -1873.39875  validloss -1740.92757±0.00000  bestvalidloss -1769.65043  last_update 1\n",
      "train: iter 207  trainloss -1813.65082  validloss -1653.07612±0.00000  bestvalidloss -1769.65043  last_update 2\n",
      "train: iter 208  trainloss -1869.84650  validloss -1583.50889±0.00000  bestvalidloss -1769.65043  last_update 3\n",
      "train: iter 209  trainloss -1889.21597  validloss -1758.18765±0.00000  bestvalidloss -1769.65043  last_update 4\n",
      "train: iter 210  trainloss -1859.09042  validloss -1602.31637±0.00000  bestvalidloss -1769.65043  last_update 5\n",
      "train: iter 211  trainloss -1885.18896  validloss -1755.42155±0.00000  bestvalidloss -1769.65043  last_update 6\n",
      "train: iter 212  trainloss -1876.15059  validloss -1776.12962±0.00000  bestvalidloss -1776.12962  last_update 0\n",
      "train: iter 213  trainloss -1856.72973  validloss -1603.73929±0.00000  bestvalidloss -1776.12962  last_update 1\n",
      "train: iter 214  trainloss -1896.39362  validloss -1685.17564±0.00000  bestvalidloss -1776.12962  last_update 2\n",
      "train: iter 215  trainloss -1821.77338  validloss -1738.53002±0.00000  bestvalidloss -1776.12962  last_update 3\n",
      "train: iter 216  trainloss -1892.18727  validloss -1708.57317±0.00000  bestvalidloss -1776.12962  last_update 4\n",
      "train: iter 217  trainloss -1889.90034  validloss -1558.91001±0.00000  bestvalidloss -1776.12962  last_update 5\n",
      "train: iter 218  trainloss -1777.86551  validloss -1653.98769±0.00000  bestvalidloss -1776.12962  last_update 6\n",
      "train: iter 219  trainloss -1891.59922  validloss -1735.13917±0.00000  bestvalidloss -1776.12962  last_update 7\n",
      "train: iter 220  trainloss -1911.41999  validloss -1705.99480±0.00000  bestvalidloss -1776.12962  last_update 8\n",
      "train: iter 221  trainloss -1859.69424  validloss -1747.53159±0.00000  bestvalidloss -1776.12962  last_update 9\n",
      "train: iter 222  trainloss -1862.72757  validloss -1693.66350±0.00000  bestvalidloss -1776.12962  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1877.38618  validloss -1740.99157±0.00000  bestvalidloss -1776.12962  last_update 11\n",
      "train: iter 224  trainloss -1847.50880  validloss -1769.39780±0.00000  bestvalidloss -1776.12962  last_update 12\n",
      "train: iter 225  trainloss -1904.98547  validloss -1757.98750±0.00000  bestvalidloss -1776.12962  last_update 13\n",
      "train: iter 226  trainloss -1774.39503  validloss -1773.51976±0.00000  bestvalidloss -1776.12962  last_update 14\n",
      "train: iter 227  trainloss -1845.20996  validloss -1337.31783±0.00000  bestvalidloss -1776.12962  last_update 15\n",
      "train: iter 228  trainloss -1863.35242  validloss -1757.78675±0.00000  bestvalidloss -1776.12962  last_update 16\n",
      "train: iter 229  trainloss -1852.69210  validloss -1697.91856±0.00000  bestvalidloss -1776.12962  last_update 17\n",
      "train: iter 230  trainloss -1898.41853  validloss -1762.24056±0.00000  bestvalidloss -1776.12962  last_update 18\n",
      "train: iter 231  trainloss -1907.46113  validloss -1775.09198±0.00000  bestvalidloss -1776.12962  last_update 19\n",
      "train: iter 232  trainloss -1901.02991  validloss -1762.93206±0.00000  bestvalidloss -1776.12962  last_update 20\n",
      "train: iter 233  trainloss -1852.67606  validloss -1721.22829±0.00000  bestvalidloss -1776.12962  last_update 21\n",
      "train: iter 234  trainloss -1870.27558  validloss -1694.22383±0.00000  bestvalidloss -1776.12962  last_update 22\n",
      "train: iter 235  trainloss -1902.94307  validloss -1715.03784±0.00000  bestvalidloss -1776.12962  last_update 23\n",
      "train: iter 236  trainloss -1868.73259  validloss -1765.19420±0.00000  bestvalidloss -1776.12962  last_update 24\n",
      "train: iter 237  trainloss -1897.79930  validloss -1735.45790±0.00000  bestvalidloss -1776.12962  last_update 25\n",
      "train: iter 238  trainloss -1769.62563  validloss -1680.23530±0.00000  bestvalidloss -1776.12962  last_update 26\n",
      "train: iter 239  trainloss -1864.25281  validloss -1423.73733±0.00000  bestvalidloss -1776.12962  last_update 27\n",
      "train: iter 240  trainloss -1913.76868  validloss -1771.35118±0.00000  bestvalidloss -1776.12962  last_update 28\n",
      "train: iter 241  trainloss -1883.86267  validloss -1793.28380±0.00000  bestvalidloss -1793.28380  last_update 0\n",
      "train: iter 242  trainloss -1842.88463  validloss -1534.44068±0.00000  bestvalidloss -1793.28380  last_update 1\n",
      "train: iter 243  trainloss -1910.12793  validloss -1798.49701±0.00000  bestvalidloss -1798.49701  last_update 0\n",
      "train: iter 244  trainloss -1821.50322  validloss -1724.86214±0.00000  bestvalidloss -1798.49701  last_update 1\n",
      "train: iter 245  trainloss -1893.28809  validloss -1672.94821±0.00000  bestvalidloss -1798.49701  last_update 2\n",
      "train: iter 246  trainloss -1895.14794  validloss -1734.13325±0.00000  bestvalidloss -1798.49701  last_update 3\n",
      "train: iter 247  trainloss -1860.75203  validloss -1740.80479±0.00000  bestvalidloss -1798.49701  last_update 4\n",
      "train: iter 248  trainloss -1873.66016  validloss -1669.39601±0.00000  bestvalidloss -1798.49701  last_update 5\n",
      "train: iter 249  trainloss -1915.24395  validloss -1763.79063±0.00000  bestvalidloss -1798.49701  last_update 6\n",
      "train: iter 250  trainloss -1932.64149  validloss -1789.93372±0.00000  bestvalidloss -1798.49701  last_update 7\n",
      "train: iter 251  trainloss -1898.07149  validloss -1736.93372±0.00000  bestvalidloss -1798.49701  last_update 8\n",
      "train: iter 252  trainloss -1796.93121  validloss -1709.00879±0.00000  bestvalidloss -1798.49701  last_update 9\n",
      "train: iter 253  trainloss -1869.23856  validloss -1703.87746±0.00000  bestvalidloss -1798.49701  last_update 10\n",
      "train: iter 254  trainloss -1890.18238  validloss -1693.92827±0.00000  bestvalidloss -1798.49701  last_update 11\n",
      "train: iter 255  trainloss -1919.69662  validloss -1766.77231±0.00000  bestvalidloss -1798.49701  last_update 12\n",
      "train: iter 256  trainloss -1864.22352  validloss -1744.67246±0.00000  bestvalidloss -1798.49701  last_update 13\n",
      "train: iter 257  trainloss -1889.76050  validloss -1767.05796±0.00000  bestvalidloss -1798.49701  last_update 14\n",
      "train: iter 258  trainloss -1911.43286  validloss -1745.90683±0.00000  bestvalidloss -1798.49701  last_update 15\n",
      "train: iter 259  trainloss -1888.96676  validloss -1784.57767±0.00000  bestvalidloss -1798.49701  last_update 16\n",
      "train: iter 260  trainloss -1904.64639  validloss -1795.51602±0.00000  bestvalidloss -1798.49701  last_update 17\n",
      "train: iter 261  trainloss -1824.71895  validloss -1716.91373±0.00000  bestvalidloss -1798.49701  last_update 18\n",
      "train: iter 262  trainloss -1871.48562  validloss -1718.36953±0.00000  bestvalidloss -1798.49701  last_update 19\n",
      "train: iter 263  trainloss -1912.10820  validloss -1760.60717±0.00000  bestvalidloss -1798.49701  last_update 20\n",
      "train: iter 264  trainloss -1908.64626  validloss -1790.92868±0.00000  bestvalidloss -1798.49701  last_update 21\n",
      "train: iter 265  trainloss -1687.28243  validloss -1764.22845±0.00000  bestvalidloss -1798.49701  last_update 22\n",
      "train: iter 266  trainloss -1861.45067  validloss -1558.41461±0.00000  bestvalidloss -1798.49701  last_update 23\n",
      "train: iter 267  trainloss -1913.81681  validloss -1753.27707±0.00000  bestvalidloss -1798.49701  last_update 24\n",
      "train: iter 268  trainloss -1893.69836  validloss -1766.49447±0.00000  bestvalidloss -1798.49701  last_update 25\n",
      "train: iter 269  trainloss -1917.58529  validloss -1740.85054±0.00000  bestvalidloss -1798.49701  last_update 26\n",
      "train: iter 270  trainloss -1927.55392  validloss -1745.41328±0.00000  bestvalidloss -1798.49701  last_update 27\n",
      "train: iter 271  trainloss -1935.52063  validloss -1802.59799±0.00000  bestvalidloss -1802.59799  last_update 0\n",
      "train: iter 272  trainloss -1891.60576  validloss -1791.18847±0.00000  bestvalidloss -1802.59799  last_update 1\n",
      "train: iter 273  trainloss -1875.46305  validloss -1795.71013±0.00000  bestvalidloss -1802.59799  last_update 2\n",
      "train: iter 274  trainloss -1877.05964  validloss -1779.91635±0.00000  bestvalidloss -1802.59799  last_update 3\n",
      "train: iter 275  trainloss -1862.73853  validloss -1691.05543±0.00000  bestvalidloss -1802.59799  last_update 4\n",
      "train: iter 276  trainloss -1904.33795  validloss -1750.60710±0.00000  bestvalidloss -1802.59799  last_update 5\n",
      "train: iter 277  trainloss -1915.25348  validloss -1794.77427±0.00000  bestvalidloss -1802.59799  last_update 6\n",
      "train: iter 278  trainloss -1919.03279  validloss -1807.90739±0.00000  bestvalidloss -1807.90739  last_update 0\n",
      "train: iter 279  trainloss -1825.31923  validloss -1710.09275±0.00000  bestvalidloss -1807.90739  last_update 1\n",
      "train: iter 280  trainloss -1916.61324  validloss -1752.17444±0.00000  bestvalidloss -1807.90739  last_update 2\n",
      "train: iter 281  trainloss -1912.46841  validloss -1773.23239±0.00000  bestvalidloss -1807.90739  last_update 3\n",
      "train: iter 282  trainloss -1930.89787  validloss -1741.95202±0.00000  bestvalidloss -1807.90739  last_update 4\n",
      "train: iter 283  trainloss -1859.86902  validloss -1783.79963±0.00000  bestvalidloss -1807.90739  last_update 5\n",
      "train: iter 284  trainloss -1883.24766  validloss -1683.49360±0.00000  bestvalidloss -1807.90739  last_update 6\n",
      "train: iter 285  trainloss -1911.36720  validloss -1740.22420±0.00000  bestvalidloss -1807.90739  last_update 7\n",
      "train: iter 286  trainloss -1940.58595  validloss -1808.57384±0.00000  bestvalidloss -1808.57384  last_update 0\n",
      "train: iter 287  trainloss -1921.25402  validloss -1800.56056±0.00000  bestvalidloss -1808.57384  last_update 1\n",
      "train: iter 288  trainloss -1751.42504  validloss -1745.81798±0.00000  bestvalidloss -1808.57384  last_update 2\n",
      "train: iter 289  trainloss -1844.66618  validloss -1608.67414±0.00000  bestvalidloss -1808.57384  last_update 3\n",
      "train: iter 290  trainloss -1888.51102  validloss -1733.08514±0.00000  bestvalidloss -1808.57384  last_update 4\n",
      "train: iter 291  trainloss -1932.63917  validloss -1789.10356±0.00000  bestvalidloss -1808.57384  last_update 5\n",
      "train: iter 292  trainloss -1936.17484  validloss -1797.75337±0.00000  bestvalidloss -1808.57384  last_update 6\n",
      "train: iter 293  trainloss -1879.60317  validloss -1722.34654±0.00000  bestvalidloss -1808.57384  last_update 7\n",
      "train: iter 294  trainloss -1900.48770  validloss -1757.48004±0.00000  bestvalidloss -1808.57384  last_update 8\n",
      "train: iter 295  trainloss -1935.06828  validloss -1783.35387±0.00000  bestvalidloss -1808.57384  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -1911.43870  validloss -1813.41641±0.00000  bestvalidloss -1813.41641  last_update 0\n",
      "train: iter 297  trainloss -1717.24353  validloss -1690.12466±0.00000  bestvalidloss -1813.41641  last_update 1\n",
      "train: iter 298  trainloss -1899.12653  validloss -1722.59868±0.00000  bestvalidloss -1813.41641  last_update 2\n",
      "train: iter 299  trainloss -1919.02148  validloss -1782.39592±0.00000  bestvalidloss -1813.41641  last_update 3\n",
      "train: iter 300  trainloss -1920.51145  validloss -1799.34608±0.00000  bestvalidloss -1813.41641  last_update 4\n",
      "train: iter 301  trainloss -1931.65940  validloss -1778.04760±0.00000  bestvalidloss -1813.41641  last_update 5\n",
      "train: iter 302  trainloss -1924.28331  validloss -1793.20123±0.00000  bestvalidloss -1813.41641  last_update 6\n",
      "train: iter 303  trainloss -1911.28409  validloss -1775.74150±0.00000  bestvalidloss -1813.41641  last_update 7\n",
      "train: iter 304  trainloss -1870.10788  validloss -1779.22245±0.00000  bestvalidloss -1813.41641  last_update 8\n",
      "train: iter 305  trainloss -1933.94442  validloss -1757.92180±0.00000  bestvalidloss -1813.41641  last_update 9\n",
      "train: iter 306  trainloss -1933.26461  validloss -1771.53045±0.00000  bestvalidloss -1813.41641  last_update 10\n",
      "train: iter 307  trainloss -1869.08328  validloss -1764.37621±0.00000  bestvalidloss -1813.41641  last_update 11\n",
      "train: iter 308  trainloss -1916.06866  validloss -1789.08070±0.00000  bestvalidloss -1813.41641  last_update 12\n",
      "train: iter 309  trainloss -1847.26956  validloss -1766.29276±0.00000  bestvalidloss -1813.41641  last_update 13\n",
      "train: iter 310  trainloss -1895.50550  validloss -1645.12356±0.00000  bestvalidloss -1813.41641  last_update 14\n",
      "train: iter 311  trainloss -1891.73189  validloss -1774.97227±0.00000  bestvalidloss -1813.41641  last_update 15\n",
      "train: iter 312  trainloss -1908.65103  validloss -1820.48463±0.00000  bestvalidloss -1820.48463  last_update 0\n",
      "train: iter 313  trainloss -1891.81321  validloss -1663.34480±0.00000  bestvalidloss -1820.48463  last_update 1\n",
      "train: iter 314  trainloss -1916.94390  validloss -1774.52370±0.00000  bestvalidloss -1820.48463  last_update 2\n",
      "train: iter 315  trainloss -1929.74207  validloss -1795.24262±0.00000  bestvalidloss -1820.48463  last_update 3\n",
      "train: iter 316  trainloss -1938.23549  validloss -1784.09890±0.00000  bestvalidloss -1820.48463  last_update 4\n",
      "train: iter 317  trainloss -1810.67603  validloss -1813.27582±0.00000  bestvalidloss -1820.48463  last_update 5\n",
      "train: iter 318  trainloss -1827.00463  validloss -1601.96248±0.00000  bestvalidloss -1820.48463  last_update 6\n",
      "train: iter 319  trainloss -1934.45898  validloss -1790.39353±0.00000  bestvalidloss -1820.48463  last_update 7\n",
      "train: iter 320  trainloss -1935.15313  validloss -1813.47761±0.00000  bestvalidloss -1820.48463  last_update 8\n",
      "train: iter 321  trainloss -1879.11245  validloss -1712.02872±0.00000  bestvalidloss -1820.48463  last_update 9\n",
      "train: iter 322  trainloss -1797.16220  validloss -1750.44148±0.00000  bestvalidloss -1820.48463  last_update 10\n",
      "train: iter 323  trainloss -1841.82454  validloss -1457.97193±0.00000  bestvalidloss -1820.48463  last_update 11\n",
      "train: iter 324  trainloss -1919.90366  validloss -1764.54631±0.00000  bestvalidloss -1820.48463  last_update 12\n",
      "train: iter 325  trainloss -1942.80785  validloss -1777.76324±0.00000  bestvalidloss -1820.48463  last_update 13\n",
      "train: iter 326  trainloss -1942.73991  validloss -1814.99003±0.00000  bestvalidloss -1820.48463  last_update 14\n",
      "train: iter 327  trainloss -1942.14324  validloss -1791.14530±0.00000  bestvalidloss -1820.48463  last_update 15\n",
      "train: iter 328  trainloss -1951.53864  validloss -1718.01925±0.00000  bestvalidloss -1820.48463  last_update 16\n",
      "train: iter 329  trainloss -1751.00454  validloss -1749.41783±0.00000  bestvalidloss -1820.48463  last_update 17\n",
      "train: iter 330  trainloss -1872.53699  validloss -1556.98260±0.00000  bestvalidloss -1820.48463  last_update 18\n",
      "train: iter 331  trainloss -1932.51584  validloss -1787.75948±0.00000  bestvalidloss -1820.48463  last_update 19\n",
      "train: iter 332  trainloss -1900.26679  validloss -1811.45670±0.00000  bestvalidloss -1820.48463  last_update 20\n",
      "train: iter 333  trainloss -1907.88867  validloss -1750.01877±0.00000  bestvalidloss -1820.48463  last_update 21\n",
      "train: iter 334  trainloss -1949.59011  validloss -1802.79664±0.00000  bestvalidloss -1820.48463  last_update 22\n",
      "train: iter 335  trainloss -1938.22043  validloss -1830.80945±0.00000  bestvalidloss -1830.80945  last_update 0\n",
      "train: iter 336  trainloss -1887.13435  validloss -1752.32014±0.00000  bestvalidloss -1830.80945  last_update 1\n",
      "train: iter 337  trainloss -1860.97664  validloss -1705.31143±0.00000  bestvalidloss -1830.80945  last_update 2\n",
      "train: iter 338  trainloss -1939.49249  validloss -1793.29172±0.00000  bestvalidloss -1830.80945  last_update 3\n",
      "train: iter 339  trainloss -1954.74301  validloss -1808.16159±0.00000  bestvalidloss -1830.80945  last_update 4\n",
      "train: iter 340  trainloss -1935.00020  validloss -1830.21324±0.00000  bestvalidloss -1830.80945  last_update 5\n",
      "train: iter 341  trainloss -1759.54703  validloss -1807.39525±0.00000  bestvalidloss -1830.80945  last_update 6\n",
      "train: iter 342  trainloss -1871.08590  validloss -1645.12599±0.00000  bestvalidloss -1830.80945  last_update 7\n",
      "train: iter 343  trainloss -1942.01395  validloss -1766.79908±0.00000  bestvalidloss -1830.80945  last_update 8\n",
      "train: iter 344  trainloss -1926.55587  validloss -1795.51642±0.00000  bestvalidloss -1830.80945  last_update 9\n",
      "train: iter 345  trainloss -1916.42041  validloss -1780.75211±0.00000  bestvalidloss -1830.80945  last_update 10\n",
      "train: iter 346  trainloss -1904.27757  validloss -1710.95414±0.00000  bestvalidloss -1830.80945  last_update 11\n",
      "train: iter 347  trainloss -1942.87877  validloss -1780.80490±0.00000  bestvalidloss -1830.80945  last_update 12\n",
      "train: iter 348  trainloss -1928.06388  validloss -1799.18066±0.00000  bestvalidloss -1830.80945  last_update 13\n",
      "train: iter 349  trainloss -1944.92842  validloss -1805.63807±0.00000  bestvalidloss -1830.80945  last_update 14\n",
      "train: iter 350  trainloss -1956.91654  validloss -1819.84174±0.00000  bestvalidloss -1830.80945  last_update 15\n",
      "train: iter 351  trainloss -1920.74206  validloss -1827.55885±0.00000  bestvalidloss -1830.80945  last_update 16\n",
      "train: iter 352  trainloss -1910.99919  validloss -1794.36401±0.00000  bestvalidloss -1830.80945  last_update 17\n",
      "train: iter 353  trainloss -1910.94236  validloss -1720.38501±0.00000  bestvalidloss -1830.80945  last_update 18\n",
      "train: iter 354  trainloss -1940.08684  validloss -1778.83630±0.00000  bestvalidloss -1830.80945  last_update 19\n",
      "train: iter 355  trainloss -1920.14414  validloss -1774.61476±0.00000  bestvalidloss -1830.80945  last_update 20\n",
      "train: iter 356  trainloss -1938.53563  validloss -1813.30536±0.00000  bestvalidloss -1830.80945  last_update 21\n",
      "train: iter 357  trainloss -1924.98069  validloss -1832.82888±0.00000  bestvalidloss -1832.82888  last_update 0\n",
      "train: iter 358  trainloss -1904.75045  validloss -1755.71283±0.00000  bestvalidloss -1832.82888  last_update 1\n",
      "train: iter 359  trainloss -1865.09791  validloss -1743.18960±0.00000  bestvalidloss -1832.82888  last_update 2\n",
      "train: iter 360  trainloss -1942.07652  validloss -1761.12749±0.00000  bestvalidloss -1832.82888  last_update 3\n",
      "train: iter 361  trainloss -1882.81198  validloss -1771.45103±0.00000  bestvalidloss -1832.82888  last_update 4\n",
      "train: iter 362  trainloss -1933.01198  validloss -1811.60949±0.00000  bestvalidloss -1832.82888  last_update 5\n",
      "train: iter 363  trainloss -1943.30733  validloss -1750.11859±0.00000  bestvalidloss -1832.82888  last_update 6\n",
      "train: iter 364  trainloss -1954.53655  validloss -1825.59785±0.00000  bestvalidloss -1832.82888  last_update 7\n",
      "train: iter 365  trainloss -1924.56126  validloss -1778.01841±0.00000  bestvalidloss -1832.82888  last_update 8\n",
      "train: iter 366  trainloss -1944.75122  validloss -1736.89203±0.00000  bestvalidloss -1832.82888  last_update 9\n",
      "train: iter 367  trainloss -1904.01103  validloss -1782.67744±0.00000  bestvalidloss -1832.82888  last_update 10\n",
      "train: iter 368  trainloss -1918.31077  validloss -1786.01585±0.00000  bestvalidloss -1832.82888  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -1958.40684  validloss -1798.03915±0.00000  bestvalidloss -1832.82888  last_update 12\n",
      "train: iter 370  trainloss -1841.57526  validloss -1801.24444±0.00000  bestvalidloss -1832.82888  last_update 13\n",
      "train: iter 371  trainloss -1899.40341  validloss -1713.09264±0.00000  bestvalidloss -1832.82888  last_update 14\n",
      "train: iter 372  trainloss -1934.60218  validloss -1796.22649±0.00000  bestvalidloss -1832.82888  last_update 15\n",
      "train: iter 373  trainloss -1935.12653  validloss -1843.55375±0.00000  bestvalidloss -1843.55375  last_update 0\n",
      "train: iter 374  trainloss -1943.92389  validloss -1767.46668±0.00000  bestvalidloss -1843.55375  last_update 1\n",
      "train: iter 375  trainloss -1839.74577  validloss -1731.46958±0.00000  bestvalidloss -1843.55375  last_update 2\n",
      "train: iter 376  trainloss -1930.32077  validloss -1702.39333±0.00000  bestvalidloss -1843.55375  last_update 3\n",
      "train: iter 377  trainloss -1956.01720  validloss -1780.46672±0.00000  bestvalidloss -1843.55375  last_update 4\n",
      "train: iter 378  trainloss -1937.61638  validloss -1823.89374±0.00000  bestvalidloss -1843.55375  last_update 5\n",
      "train: iter 379  trainloss -1877.82085  validloss -1678.07795±0.00000  bestvalidloss -1843.55375  last_update 6\n",
      "train: iter 380  trainloss -1921.56199  validloss -1633.33954±0.00000  bestvalidloss -1843.55375  last_update 7\n",
      "train: iter 381  trainloss -1933.31283  validloss -1799.26314±0.00000  bestvalidloss -1843.55375  last_update 8\n",
      "train: iter 382  trainloss -1953.09619  validloss -1779.14159±0.00000  bestvalidloss -1843.55375  last_update 9\n",
      "train: iter 383  trainloss -1944.29457  validloss -1805.31936±0.00000  bestvalidloss -1843.55375  last_update 10\n",
      "train: iter 384  trainloss -1944.76538  validloss -1766.69321±0.00000  bestvalidloss -1843.55375  last_update 11\n",
      "train: iter 385  trainloss -1896.55635  validloss -1824.79571±0.00000  bestvalidloss -1843.55375  last_update 12\n",
      "train: iter 386  trainloss -1935.11062  validloss -1793.77347±0.00000  bestvalidloss -1843.55375  last_update 13\n",
      "train: iter 387  trainloss -1935.43855  validloss -1832.21332±0.00000  bestvalidloss -1843.55375  last_update 14\n",
      "train: iter 388  trainloss -1920.65792  validloss -1634.21756±0.00000  bestvalidloss -1843.55375  last_update 15\n",
      "train: iter 389  trainloss -1847.77009  validloss -1827.71998±0.00000  bestvalidloss -1843.55375  last_update 16\n",
      "train: iter 390  trainloss -1887.17508  validloss -1675.26573±0.00000  bestvalidloss -1843.55375  last_update 17\n",
      "train: iter 391  trainloss -1909.02525  validloss -1791.67191±0.00000  bestvalidloss -1843.55375  last_update 18\n",
      "train: iter 392  trainloss -1902.43734  validloss -1769.14591±0.00000  bestvalidloss -1843.55375  last_update 19\n",
      "train: iter 393  trainloss -1945.52905  validloss -1794.92917±0.00000  bestvalidloss -1843.55375  last_update 20\n",
      "train: iter 394  trainloss -1950.40814  validloss -1797.18661±0.00000  bestvalidloss -1843.55375  last_update 21\n",
      "train: iter 395  trainloss -1955.04105  validloss -1809.19171±0.00000  bestvalidloss -1843.55375  last_update 22\n",
      "train: iter 396  trainloss -1860.32499  validloss -1806.92956±0.00000  bestvalidloss -1843.55375  last_update 23\n",
      "train: iter 397  trainloss -1955.11177  validloss -1764.56089±0.00000  bestvalidloss -1843.55375  last_update 24\n",
      "train: iter 398  trainloss -1950.39137  validloss -1812.20609±0.00000  bestvalidloss -1843.55375  last_update 25\n",
      "train: iter 399  trainloss -1947.88319  validloss -1780.93075±0.00000  bestvalidloss -1843.55375  last_update 26\n",
      "train: iter 400  trainloss -1954.58275  validloss -1831.56695±0.00000  bestvalidloss -1843.55375  last_update 27\n",
      "train: iter 401  trainloss -1780.99639  validloss -1785.78095±0.00000  bestvalidloss -1843.55375  last_update 28\n",
      "train: iter 402  trainloss -1871.62531  validloss -1662.50177±0.00000  bestvalidloss -1843.55375  last_update 29\n",
      "train: iter 403  trainloss -1953.88321  validloss -1786.89247±0.00000  bestvalidloss -1843.55375  last_update 30\n",
      "train: iter 404  trainloss -1948.00112  validloss -1801.50266±0.00000  bestvalidloss -1843.55375  last_update 31\n",
      "train: iter 405  trainloss -1956.62769  validloss -1830.46500±0.00000  bestvalidloss -1843.55375  last_update 32\n",
      "train: iter 406  trainloss -1978.40840  validloss -1836.50773±0.00000  bestvalidloss -1843.55375  last_update 33\n",
      "train: iter 407  trainloss -1941.53395  validloss -1803.43630±0.00000  bestvalidloss -1843.55375  last_update 34\n",
      "train: iter 408  trainloss -1729.76333  validloss -1729.85050±0.00000  bestvalidloss -1843.55375  last_update 35\n",
      "train: iter 409  trainloss -1941.40672  validloss -1745.58219±0.00000  bestvalidloss -1843.55375  last_update 36\n",
      "train: iter 410  trainloss -1920.74262  validloss -1723.69621±0.00000  bestvalidloss -1843.55375  last_update 37\n",
      "train: iter 411  trainloss -1911.60260  validloss -1797.18265±0.00000  bestvalidloss -1843.55375  last_update 38\n",
      "train: iter 412  trainloss -1864.39625  validloss -1650.08905±0.00000  bestvalidloss -1843.55375  last_update 39\n",
      "train: iter 413  trainloss -1920.27940  validloss -1761.56658±0.00000  bestvalidloss -1843.55375  last_update 40\n",
      "train: iter 414  trainloss -1904.84909  validloss -1767.50287±0.00000  bestvalidloss -1843.55375  last_update 41\n",
      "train: iter 415  trainloss -1966.28952  validloss -1837.28319±0.00000  bestvalidloss -1843.55375  last_update 42\n",
      "train: iter 416  trainloss -1946.40242  validloss -1836.82975±0.00000  bestvalidloss -1843.55375  last_update 43\n",
      "train: iter 417  trainloss -1872.76863  validloss -1789.43031±0.00000  bestvalidloss -1843.55375  last_update 44\n",
      "train: iter 418  trainloss -1934.57146  validloss -1735.23560±0.00000  bestvalidloss -1843.55375  last_update 45\n",
      "train: iter 419  trainloss -1953.51262  validloss -1802.04788±0.00000  bestvalidloss -1843.55375  last_update 46\n",
      "train: iter 420  trainloss -1961.19229  validloss -1830.76407±0.00000  bestvalidloss -1843.55375  last_update 47\n",
      "train: iter 421  trainloss -1927.04557  validloss -1799.91478±0.00000  bestvalidloss -1843.55375  last_update 48\n",
      "train: iter 422  trainloss -1885.62632  validloss -1711.69892±0.00000  bestvalidloss -1843.55375  last_update 49\n",
      "train: iter 423  trainloss -1931.76653  validloss -1773.19686±0.00000  bestvalidloss -1843.55375  last_update 50\n",
      "train: iter 424  trainloss -1952.36583  validloss -1788.31443±0.00000  bestvalidloss -1843.55375  last_update 51\n",
      "train: iter 425  trainloss -1892.43602  validloss -1813.66335±0.00000  bestvalidloss -1843.55375  last_update 52\n",
      "train: iter 426  trainloss -1884.13737  validloss -1716.77806±0.00000  bestvalidloss -1843.55375  last_update 53\n",
      "train: iter 427  trainloss -1911.19082  validloss -1703.02020±0.00000  bestvalidloss -1843.55375  last_update 54\n",
      "train: iter 428  trainloss -1941.88331  validloss -1762.99570±0.00000  bestvalidloss -1843.55375  last_update 55\n",
      "train: iter 429  trainloss -1962.88310  validloss -1836.07295±0.00000  bestvalidloss -1843.55375  last_update 56\n",
      "train: iter 430  trainloss -1866.87051  validloss -1804.47208±0.00000  bestvalidloss -1843.55375  last_update 57\n",
      "train: iter 431  trainloss -1860.82974  validloss -1622.82666±0.00000  bestvalidloss -1843.55375  last_update 58\n",
      "train: iter 432  trainloss -1925.58776  validloss -1801.29565±0.00000  bestvalidloss -1843.55375  last_update 59\n",
      "train: iter 433  trainloss -1891.04278  validloss -1654.55654±0.00000  bestvalidloss -1843.55375  last_update 60\n",
      "train: iter 434  trainloss -1912.66921  validloss -1777.02975±0.00000  bestvalidloss -1843.55375  last_update 61\n",
      "train: iter 435  trainloss -1964.83252  validloss -1824.71108±0.00000  bestvalidloss -1843.55375  last_update 62\n",
      "train: iter 436  trainloss -1958.69680  validloss -1831.81442±0.00000  bestvalidloss -1843.55375  last_update 63\n",
      "train: iter 437  trainloss -1944.48539  validloss -1817.50559±0.00000  bestvalidloss -1843.55375  last_update 64\n",
      "train: iter 438  trainloss -1851.90454  validloss -1683.24867±0.00000  bestvalidloss -1843.55375  last_update 65\n",
      "train: iter 439  trainloss -1966.01456  validloss -1803.53842±0.00000  bestvalidloss -1843.55375  last_update 66\n",
      "train: iter 440  trainloss -1960.46985  validloss -1825.81205±0.00000  bestvalidloss -1843.55375  last_update 67\n",
      "train: iter 441  trainloss -1917.75567  validloss -1676.55977±0.00000  bestvalidloss -1843.55375  last_update 68\n",
      "train: iter 442  trainloss -1901.97138  validloss -1709.74348±0.00000  bestvalidloss -1843.55375  last_update 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 443  trainloss -1956.32568  validloss -1828.92078±0.00000  bestvalidloss -1843.55375  last_update 70\n",
      "train: iter 444  trainloss -1926.91187  validloss -1806.57946±0.00000  bestvalidloss -1843.55375  last_update 71\n",
      "train: iter 445  trainloss -1859.51275  validloss -1668.59873±0.00000  bestvalidloss -1843.55375  last_update 72\n",
      "train: iter 446  trainloss -1940.90051  validloss -1777.59062±0.00000  bestvalidloss -1843.55375  last_update 73\n",
      "train: iter 447  trainloss -1955.96956  validloss -1795.88755±0.00000  bestvalidloss -1843.55375  last_update 74\n",
      "train: iter 448  trainloss -1948.03351  validloss -1809.75701±0.00000  bestvalidloss -1843.55375  last_update 75\n",
      "train: iter 449  trainloss -1949.62592  validloss -1806.48812±0.00000  bestvalidloss -1843.55375  last_update 76\n",
      "train: iter 450  trainloss -1942.52292  validloss -1808.06403±0.00000  bestvalidloss -1843.55375  last_update 77\n",
      "train: iter 451  trainloss -1965.65858  validloss -1840.15898±0.00000  bestvalidloss -1843.55375  last_update 78\n",
      "train: iter 452  trainloss -1953.78111  validloss -1834.51897±0.00000  bestvalidloss -1843.55375  last_update 79\n",
      "train: iter 453  trainloss -1847.54626  validloss -1652.48978±0.00000  bestvalidloss -1843.55375  last_update 80\n",
      "train: iter 454  trainloss -1939.82202  validloss -1749.95683±0.00000  bestvalidloss -1843.55375  last_update 81\n",
      "train: iter 455  trainloss -1975.53881  validloss -1793.18337±0.00000  bestvalidloss -1843.55375  last_update 82\n",
      "train: iter 456  trainloss -1936.20609  validloss -1839.02903±0.00000  bestvalidloss -1843.55375  last_update 83\n",
      "train: iter 457  trainloss -1884.20384  validloss -1797.68462±0.00000  bestvalidloss -1843.55375  last_update 84\n",
      "train: iter 458  trainloss -1922.59190  validloss -1712.16591±0.00000  bestvalidloss -1843.55375  last_update 85\n",
      "train: iter 459  trainloss -1963.73532  validloss -1821.77613±0.00000  bestvalidloss -1843.55375  last_update 86\n",
      "train: iter 460  trainloss -1963.91125  validloss -1816.79008±0.00000  bestvalidloss -1843.55375  last_update 87\n",
      "train: iter 461  trainloss -1971.30220  validloss -1816.85790±0.00000  bestvalidloss -1843.55375  last_update 88\n",
      "train: iter 462  trainloss -1929.68465  validloss -1835.81804±0.00000  bestvalidloss -1843.55375  last_update 89\n",
      "train: iter 463  trainloss -1921.63512  validloss -1760.04286±0.00000  bestvalidloss -1843.55375  last_update 90\n",
      "train: iter 464  trainloss -1963.82462  validloss -1764.61260±0.00000  bestvalidloss -1843.55375  last_update 91\n",
      "train: iter 465  trainloss -1956.33399  validloss -1824.95980±0.00000  bestvalidloss -1843.55375  last_update 92\n",
      "train: iter 466  trainloss -1960.92962  validloss -1834.75167±0.00000  bestvalidloss -1843.55375  last_update 93\n",
      "train: iter 467  trainloss -1843.25572  validloss -1762.53386±0.00000  bestvalidloss -1843.55375  last_update 94\n",
      "train: iter 468  trainloss -1944.34697  validloss -1800.60191±0.00000  bestvalidloss -1843.55375  last_update 95\n",
      "train: iter 469  trainloss -1951.37261  validloss -1818.22161±0.00000  bestvalidloss -1843.55375  last_update 96\n",
      "train: iter 470  trainloss -1979.89305  validloss -1824.29627±0.00000  bestvalidloss -1843.55375  last_update 97\n",
      "train: iter 471  trainloss -1947.66998  validloss -1793.38574±0.00000  bestvalidloss -1843.55375  last_update 98\n",
      "train: iter 472  trainloss -1885.72035  validloss -1812.50476±0.00000  bestvalidloss -1843.55375  last_update 99\n",
      "train: iter 473  trainloss -1903.67217  validloss -1799.47996±0.00000  bestvalidloss -1843.55375  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.9764) penalty_target_max tensor(3.1129)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGdCAYAAAAWp6lMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACKSElEQVR4nO3dd3hTZf8G8Dtpm3QvuqFA2XuvoqhIpSAO3AivoqIogoo4AF8Ffy4U3Ip74OsCXKgsLVugbMres9Dd0qYzTZPz++PJSc5J0kKRNG25P9fVq8k5J8lJKMmd77M0kiRJICIiImrEtJ4+ASIiIiJ3Y+AhIiKiRo+Bh4iIiBo9Bh4iIiJq9Bh4iIiIqNFj4CEiIqJGj4GHiIiIGj0GHiIiImr0vD19AvWBxWJBRkYGgoKCoNFoPH06REREdAEkSUJxcTHi4uKg1dZcw2HgAZCRkYH4+HhPnwYRERFdhPT0dDRr1qzGYxh4AAQFBQEQL1hwcLCHz4aIiIguhMFgQHx8vO1zvCYMPICtGSs4OJiBh4iIqIG5kO4o7LRMREREjR4DDxERETV6DDxERETU6DHwEBERUaPn1sCzbt063HjjjYiLi4NGo8GiRYtU+++77z5oNBrVz7Bhw1THFBQUYMyYMQgODkZoaCjGjRuHkpIS1TG7d+/GoEGD4Ovri/j4eMyePdudT4uIiIgaGLcGntLSUnTv3h1z586t9phhw4YhMzPT9vPjjz+q9o8ZMwb79u1DSkoKFi9ejHXr1mH8+PG2/QaDAUOHDkWLFi2wfft2zJkzBy+++CI+++wztz0vIiIialjcOix9+PDhGD58eI3H6PV6xMTEuNx34MABLF++HFu3bkWfPn0AAB988AGuv/56vPnmm4iLi8P333+PyspKfPXVV9DpdOjcuTPS0tLw9ttvq4IRERERXb483odnzZo1iIqKQvv27TFhwgTk5+fb9qWmpiI0NNQWdgAgKSkJWq0Wmzdvth1z1VVXQafT2Y5JTk7GoUOHcO7cOZePaTQaYTAYVD9ERETUeHk08AwbNgz/+9//sHLlSrzxxhtYu3Ythg8fDrPZDADIyspCVFSU6jbe3t4IDw9HVlaW7Zjo6GjVMfJ1+RhHs2bNQkhIiO2Hy0oQERE1bh6daXnUqFG2y127dkW3bt3QunVrrFmzBkOGDHHb406fPh1TpkyxXZenpiYiIqLGyeNNWkqtWrVCREQEjh49CgCIiYlBTk6O6piqqioUFBTY+v3ExMQgOztbdYx8vbq+QXq93raMBJeTICIiavzqVeA5c+YM8vPzERsbCwBITExEYWEhtm/fbjtm1apVsFgs6N+/v+2YdevWwWQy2Y5JSUlB+/btERYWVrdPgIiIiOoltwaekpISpKWlIS0tDQBw4sQJpKWl4fTp0ygpKcEzzzyDTZs24eTJk1i5ciVuvvlmtGnTBsnJyQCAjh07YtiwYXjooYewZcsWbNiwAZMmTcKoUaMQFxcHABg9ejR0Oh3GjRuHffv2YcGCBXjvvfdUTVYeYzYBy6cDS58FTBWePhsiIqLLlkaSJMldd75mzRoMHjzYafvYsWPx8ccfY+TIkdi5cycKCwsRFxeHoUOH4uWXX1Z1Qi4oKMCkSZPw559/QqvV4rbbbsP777+PwMBA2zG7d+/GxIkTsXXrVkREROCxxx7D1KlTL/g8DQYDQkJCUFRUdGmbt6qMwCvWTtfTTgO+IZfuvomIiC5ztfn8dmvgaSjcFnjMVcDLTcTlZ08A/uGX7r6JiIguc7X5/K5XfXgaHa2X/bJk8dx5EBERXeYYeNxJowGgEZctZo+eChER0eWMgcfd5CqPxMBDRETkKQw87qaxBh5WeIiIiDyGgcfdWOEhIiLyOAYed2OFh4iIyOMYeNxNa32JOUqLiIjIYxh43I0VHiIiIo9j4HE39uEhIiLyOAYed2OFh4iIyOMYeNyNFR4iIiKPY+BxN1uFh52WiYiIPIWBx91so7RY4SEiIvIUBh53Yx8eIiIij2PgcTf24SEiIvI4Bh53Y4WHiIjI4xh43I0VHiIiIo9j4HE3jfUl5igtIiIij2HgcTdWeIiIiDyOgcfd2IeHiIjI4xh43I0VHiIiIo9j4HE3VniIiIg8joHH3VjhISIi8jgGHnfjKC0iIiKPY+BxN1Z4iIiIPI6Bx93Yh4eIiMjjGHjcTcPV0omIiDyNgcfdtKzwEBEReRoDj7uxwkNERORxDDzuZuu0LHn2PIiIiC5jDDzuxk7LREREHsfA424clk5ERORxDDzuxgoPERGRxzHwuBsrPERERB7HwONutqUlGHiIiIg8hYHH3WwVHq6lRURE5CkMPO7GPjxEREQex8DjbuzDQ0RE5HFuDTzr1q3DjTfeiLi4OGg0GixatEi1X5IkzJgxA7GxsfDz80NSUhKOHDmiOqagoABjxoxBcHAwQkNDMW7cOJSUlKiO2b17NwYNGgRfX1/Ex8dj9uzZ7nxatcMKDxERkce5NfCUlpaie/fumDt3rsv9s2fPxvvvv49PPvkEmzdvRkBAAJKTk1FRUWE7ZsyYMdi3bx9SUlKwePFirFu3DuPHj7ftNxgMGDp0KFq0aIHt27djzpw5ePHFF/HZZ5+586ldOFZ4iIiIPE+qIwCk3377zXbdYrFIMTEx0pw5c2zbCgsLJb1eL/3444+SJEnS/v37JQDS1q1bbccsW7ZM0mg00tmzZyVJkqSPPvpICgsLk4xGo+2YqVOnSu3bt7/gcysqKpIASEVFRRf79Kr31/OSNDNYkpY/d+nvm4iI6DJWm89vj/XhOXHiBLKyspCUlGTbFhISgv79+yM1NRUAkJqaitDQUPTp08d2TFJSErRaLTZv3mw75qqrroJOp7Mdk5ycjEOHDuHcuXMuH9toNMJgMKh+3IajtIiIiDzOY4EnKysLABAdHa3aHh0dbduXlZWFqKgo1X5vb2+Eh4erjnF1H8rHcDRr1iyEhITYfuLj4//9E6oO+/AQERF53GU5Smv69OkoKiqy/aSnp7vvwdiHh4iIyOM8FnhiYmIAANnZ2art2dnZtn0xMTHIyclR7a+qqkJBQYHqGFf3oXwMR3q9HsHBwaoft2GFh4iIyOM8FngSEhIQExODlStX2rYZDAZs3rwZiYmJAIDExEQUFhZi+/bttmNWrVoFi8WC/v37245Zt24dTCaT7ZiUlBS0b98eYWFhdfRsaqC1vsSs8BAREXmMWwNPSUkJ0tLSkJaWBkB0VE5LS8Pp06eh0WgwefJkvPLKK/jjjz+wZ88e3HvvvYiLi8PIkSMBAB07dsSwYcPw0EMPYcuWLdiwYQMmTZqEUaNGIS4uDgAwevRo6HQ6jBs3Dvv27cOCBQvw3nvvYcqUKe58ahfOVuFhp2UiIiJP8XbnnW/btg2DBw+2XZdDyNixYzFv3jw8++yzKC0txfjx41FYWIgrr7wSy5cvh6+vr+0233//PSZNmoQhQ4ZAq9Xitttuw/vvv2/bHxISgr///hsTJ05E7969ERERgRkzZqjm6vEo9uEhIiLyOI0kSZKnT8LTDAYDQkJCUFRUdOn782z8EPj7v0DXO4HbPr+0901ERHQZq83n92U5SqtOscJDRETkcQw87sZRWkRERB7HwONuHKVFRETkcQw87sZRWkRERB7HwONu7MNDRETkcQw87sY+PERERB7HwONurPAQERF5HAOPu7HCQ0RE5HEMPO5mG6XFTstERESewsDjbqzwEBEReRwDj7uxDw8REZHHMfC4Gys8REREHsfA426s8BAREXkcA4+7OVZ4WOkhIiKqcww87qYcpVVeCLzdEVj0qEdPiYiI6HLDwONuygrPrvlASTaQ9r1nz4mIiOgyw8Djbso+PJyLh4iIyCMYeNxNWeFh4CEiIvIIBh53Y4WHiIjI4xh43M1W4bEw8BAREXkIA4+7aTTit2QGIHn0VIiIiC5XDDzuplX04eEcPERERB7BwONuGmUfHkWFR2K1h4iIqK4w8LiRJEkoNYlgI1kcmrRY7SEiIqozDDxuVGGy4KaPUsUVyaHTssXkmZMiIiK6DDHwuJGPlwZm+SV2nIfHUuWZkyIiIroMMfC4kZdWA4v1JZYc5+Exs8JDRERUVxh43Eij0UDr5S0uWyzqfjvsw0NERFRnGHjczNsaeCCZAXOlfQebtIiIiOoMA4+baVWBR9GMxU7LREREdYaBx820XmIeHo1kAcxG+w5WeIiIiOoMA4+baeQKDwCYyu2XzQw8REREdYWBx928fO2XjcX2y6zwEBER1RkGHnfz1tsvVxjslxl4iIiI6gwDj5t5e3vDKFmbtYzKwMNOy0RERHWFgcfNfLw0MEInrqgCD+fhISIiqisMPG7m46WFET7iirJJizMtExER1RkGHjfTeWtRIbmq8LAPDxERUV3xeOB58cUXodFoVD8dOnSw7a+oqMDEiRPRpEkTBAYG4rbbbkN2drbqPk6fPo0RI0bA398fUVFReOaZZ1BVVT8Chc5Liwq5SUsZchh4iIiI6oz3+Q9xv86dO2PFihW2697e9tN68sknsWTJEvz0008ICQnBpEmTcOutt2LDhg0AALPZjBEjRiAmJgYbN25EZmYm7r33Xvj4+OC1116r8+fiSNWkpcTAQ0REVGfqReDx9vZGTEyM0/aioiJ8+eWX+OGHH3DttdcCAL7++mt07NgRmzZtwoABA/D3339j//79WLFiBaKjo9GjRw+8/PLLmDp1Kl588UXodLq6fjoqPt6KCo8SAw8REVGd8XiTFgAcOXIEcXFxaNWqFcaMGYPTp08DALZv3w6TyYSkpCTbsR06dEDz5s2RmpoKAEhNTUXXrl0RHR1tOyY5ORkGgwH79u1z+XhGoxEGg0H14y4+XhoYJRcVHnZaJiIiqjMeDzz9+/fHvHnzsHz5cnz88cc4ceIEBg0ahOLiYmRlZUGn0yE0NFR1m+joaGRlZQEAsrKyVGFH3i/vc2XWrFkICQmx/cTHx1/6J2al6sOjxAoPERFRnfF4k9bw4cNtl7t164b+/fujRYsWWLhwIfz8/NzymNOnT8eUKVNs1w0Gg9tCj867uj48nIeHiIiorni8wuMoNDQU7dq1w9GjRxETE4PKykoUFhaqjsnOzrb1+YmJiXEatSVfd9UvCAD0ej2Cg4NVP+7iU22Fh01aREREdaXeBZ6SkhIcO3YMsbGx6N27N3x8fLBy5Urb/kOHDuH06dNITEwEACQmJmLPnj3IycmxHZOSkoLg4GB06tSpzs/fkY+X1nUfHjZpERER1RmPN2k9/fTTuPHGG9GiRQtkZGRg5syZ8PLywt13342QkBCMGzcOU6ZMQXh4OIKDg/HYY48hMTERAwYMAAAMHToUnTp1wj333IPZs2cjKysLzz//PCZOnAi9Xn+eR3c/nZfGdYWHnZaJiIjqjMcDz5kzZ3D33XcjPz8fkZGRuPLKK7Fp0yZERkYCAN555x1otVrcdtttMBqNSE5OxkcffWS7vZeXFxYvXowJEyYgMTERAQEBGDt2LF566SVPPSWV6ufhYR8eIiKiuuLxwDN//vwa9/v6+mLu3LmYO3dutce0aNECS5cuvdSndknoOA8PERGRx9W7PjyNTfV9eNikRUREVFcYeNyMMy0TERF5HgOPm+m8NK778JgZeIiIiOoKA4+b+XhpUSGxwkNERORJDDxuVv1Myww8REREdYWBx82qn2mZgYeIiKiuMPC4ma7aeXgYeIiIiOoKA4+bVduHhzMtExER1RkGHjfzcRylFd5a/GaFh4iIqM4w8LiZ00zLUR3Fby4tQUREVGcYeNzMx0sLDST7hijrCu6caZmIiKjOMPC4mc5bi+NSHE4hFmg1GPBvInawSYuIiKjOMPC4mY+XFiZ44ybpHeCe3wCtl9jBTstERER1hoHHzXy8NACAcjMAjQbQWheoZx8eIiKiOsPA42Y6b/ESm8wWSJIEeFlHbLFJi4iIqM4w8LiZv05UdCQJKCwzKSo8bNIiIiKqKww8bhao90ariAAAQFp6oSLwsMJDRERUVxh46kCvFmEAgG2nCuyBx8zAQ0REVFcYeOpAb2vg2X7qHPvwEBEReQADTx3oYw08u9KLUCW/5OzDQ0REVGcYeOpA68hABPt6o9xkRnqhNeiwwkNERFRnGHjqgFarsfXjOZRbLjZy4kEiIqI6w8BTR3o3F4FnX45RbKgyevBsiIiILi8MPHVE7rhsCzzmSg+eDRER0eWFgaeONA3zAwDkloulJlBV4cGzISIiurww8NSRAL2Yf6fQZH3J2aRFRERUZxh46kiAdYkJo6QTG0zlQNZe8ZuIiIjcioGnjvj6aKHVAJWwzrQsmYFPrgC+ucmzJ0ZERHQZYOCpIxqNBgE6bxjho95xZotnToiIiOgywsBTh/z1Xqh0DDxERETkdgw8dShA5w0zvGDReHv6VIiIiC4rDDx1yF/vBQCweOk9fCZERESXFwaeOiSP1DJrdR4+EyIiossLA08dkufiYeAhIiKqWww8dchfJ5q0qjQMPERERHWJgacOBVorPCYNR2oRERHVJQaeOuRv7cNT6VjhkSQPnA0REdHlg4GnDgVYR2lVwiHwcOV0IiIit2pUgWfu3Llo2bIlfH190b9/f2zZUr9mMZY7LTvNtsyV04mIiNyq0QSeBQsWYMqUKZg5cyZ27NiB7t27Izk5GTk5OZ4+NZsAa6dlo+QYeLhyOhERkTs1msDz9ttv46GHHsL999+PTp064ZNPPoG/vz+++uorT5+ajdyHp1xymGmZFR4iIiK3ahSBp7KyEtu3b0dSUpJtm1arRVJSElJTU52ONxqNMBgMqp+6IPfhKWeFh4iIqE41isCTl5cHs9mM6Oho1fbo6GhkZWU5HT9r1iyEhITYfuLj4+vkPOU+PBUWxwoPAw8REZE7NYrAU1vTp09HUVGR7Sc9Pb1OHldu0iq1eKl3MPAQERG5VaNYtjsiIgJeXl7Izs5Wbc/OzkZMTIzT8Xq9Hnp93S/gaWvSMjsGHvbhISIicqdGUeHR6XTo3bs3Vq5cadtmsViwcuVKJCYmevDM1OTFQ6vMFvUOBh4iIiK3ahQVHgCYMmUKxo4diz59+qBfv3549913UVpaivvvv9/Tp2Yj9+GxWCzqqMkmLSIiIrdqNIHnrrvuQm5uLmbMmIGsrCz06NEDy5cvd+rI7Eny4qFasMJDRERUlxpN4AGASZMmYdKkSZ4+jWrpvbXw0mqgcdzBpSWIiIjcqlH04WkoNBoNAnRe8GKFh4iIqE4x8NSxAL03NE6Bh314iIiI3ImBp47567yghaTeyAoPERGRWzHw1LFAvTfWW7qqN7LCQ0RE5FYMPHXMX+eNxZYB2NL/Q6DjjWIjKzxERERuxcBTx8RsyxocCh0EhLcSG1nhISIicisGnjomr6f1wu/7sO54sdjIwENERORWDDx1TJ5tGQA2nS4VF9ikRURE5FYMPHUsQGdfONQIH3GBFR4iIiK3YuCpY/6KCo898JR76GyIiIguDww8dSxQb6/wGCR/caGiyENnQ0REdHlg4KljcqdlAChAsLhQmu+hsyEiIro8MPDUMR8v+9Kh+ZIceHI9dDZERESXBwaeOlZUbrJdtgWesnzAYqnmFkRERPRvMfDUsYSIQNvlcwgSFyQzUFHomRMiIiK6DDDw1LGkjlF49ZYuAAATvGHWhYgdpXkePCsiIqLGjYGnjmk0Gozp3wLNwvwAACbfcLGD/XiIiIjchoHHQwKso7Uq9dbAU8YKDxERkbsw8HiIn3XG5XKfMLGBFR4iIiK3YeDxkADrBITlOjnwcC4eIiIid2Hg8RB5AsISr1CxgRUeIiIit2Hg8RB5EdFibajYwD48REREbsPA4yF+1gpPkcY6F0/5OQ+eDRERUePGwOMhcoXHoLFORFhW4MGzISIiatwYeDzEXy8qPOcs1sBTXui5kyEiImrkGHg8RK7w5FsCxIZyVniIiIjchYHHQ/wdA09lCVBV6cEzIiIiarwYeDxEHpaea9ID0IiN7LhMRETkFgw8HtIkUAcAyCmpAvxCxUY2axEREbkFA4+HxIWKxUMzCssBP+t6WqzwEBERuQUDj4fEhvgCAAwVVTD7hoqNHJpORETkFgw8HhLk64Mg69D0Cu8QsZFNWkRERG7BwONBsaGiylOi5WzLRERE7sTA40GxIaIfTxGsgYdNWkRERG7BwONBcdYKT548F09ZvgfPhoiIqPFi4PGgmGDrSK2qULGhJNtzJ0NERNSIMfB4kNyH50SltUmrONODZ0NERNR4MfB4UJy1D8+RcjnwZHnwbIiIiBovjwaeli1bQqPRqH5ef/111TG7d+/GoEGD4Ovri/j4eMyePdvpfn766Sd06NABvr6+6Nq1K5YuXVpXT+FfkSs8+4v9xYbSXMBs8uAZERERNU4er/C89NJLyMzMtP089thjtn0GgwFDhw5FixYtsH37dsyZMwcvvvgiPvvsM9sxGzduxN13341x48Zh586dGDlyJEaOHIm9e/d64unUilzhOVvpB0nrIzayHw8REdEl5/HAExQUhJiYGNtPQECAbd/333+PyspKfPXVV+jcuTNGjRqFxx9/HG+//bbtmPfeew/Dhg3DM888g44dO+Lll19Gr1698OGHH3ri6dSKn84Lof4+kKBFlX+U2MhmLSIiokvO44Hn9ddfR5MmTdCzZ0/MmTMHVVVVtn2pqam46qqroNPpbNuSk5Nx6NAhnDt3znZMUlKS6j6Tk5ORmppa7WMajUYYDAbVj6fIc/GU6eXAw47LREREl5pHA8/jjz+O+fPnY/Xq1Xj44Yfx2muv4dlnn7Xtz8rKQnR0tOo28vWsrKwaj5H3uzJr1iyEhITYfuLj4y/VU6q1OOuaWkXeEWLDwnuBYjZrERERXUqXPPBMmzbNqSOy48/BgwcBAFOmTME111yDbt264ZFHHsFbb72FDz74AEaj8VKflsr06dNRVFRk+0lPT3fr49VE7ricp7WumC5ZgJUveex8iIiIGiPvS32HTz31FO67774aj2nVqpXL7f3790dVVRVOnjyJ9u3bIyYmBtnZ6mqHfD0mJsb229Ux8n5X9Ho99Hr9+Z5KnZCbtFL8R6CXX4pYQHTfb8DwNwB9oIfPjoiIqHG45IEnMjISkZGRF3XbtLQ0aLVaREWJ/iyJiYn473//C5PJBB8fMYopJSUF7du3R1hYmO2YlStXYvLkybb7SUlJQWJi4r97InUk1tqktasiGnj2OPBhHyD/KHBwCdD9Lg+fHRERUePgsT48qampePfdd7Fr1y4cP34c33//PZ588kn85z//sYWZ0aNHQ6fTYdy4cdi3bx8WLFiA9957D1OmTLHdzxNPPIHly5fjrbfewsGDB/Hiiy9i27ZtmDRpkqeeWq3IFZ7MogpAowFaDhI7Co578KyIiIgal0te4blQer0e8+fPx4svvgij0YiEhAQ8+eSTqjATEhKCv//+GxMnTkTv3r0RERGBGTNmYPz48bZjBg4ciB9++AHPP/88nnvuObRt2xaLFi1Cly5dPPG0ak1eQDSjsBySJEHjb+3LU37Og2dFRETUuHgs8PTq1QubNm0673HdunXDP//8U+Mxd9xxB+64445LdWp1KsbapGWssuBcmQnhfqK6hfICD54VERFR4+LxeXgud3pvL0QEinmG9pwtwoYMi9jBCg8REdElw8BTD8j9eMZ+tQVf7ygSGxl4iIiILhkGnnpAHqkFAOck61D0MjZpERERXSoMPPVAXKif7XIhrIGHFR4iIqJLhoGnHmgXHWS7XChXeCqKAIvZQ2dERETUuDDw1AMjusXaLhdBXi1eEqGHiIiI/jUGnnogxM8HfVuK4ehV8Eapxl/sYD8eIiKiS4KBp574YmxfDG4vluQo1rAfDxER0aXEwFNPhPj5YHJSOwCKfjwMPERERJcEA089EugrJr62DU0vzQWMxR48IyIiosaBgaceCdSLwHPKHCE2/P4oMLs1kLnLg2dFRETU8DHw1CNy4FlnVix8ajYCa14HzFWAxeKhMyMiImrYGHjqEX+dFzQaYL3FYaX3k+uB/90MvN0RqDB45uSIiIgaMAaeekSj0SBQ7w0DAlEVEGPfYTQAp9YDJVlAxk7PnSAREVED5e3pEyC1IL03iiuqcGzYt2hfvBmoLAPWvGY/oCzfcydHRETUQLHCU8/II7Xy/VoBAx8D+j6oPuDI38CZbR44MyIiooaLgaeekTsuFxurxIaAJsDIT+wH7PoR+GIIYMj0wNkRERE1TAw89Uygrw8AoKSiyr6xx93AdS+pDzyxrg7PioiIqGFj4KlnguQKT4XJYUes+vrxNXVzQkRERI0AA089Ex3sCwA4kVeq3hEUo75+fA0gSeptZhOweyFgyHDfCRIRETVADDz1TM/moQCAHacL1TscKzzFGUBxlnpb6ofArw8Bnwxy2/kRERE1RAw89UzvFmEAgP2ZBpRVKvrxOFZ4ACBnv/r6oeXid1mem86OiIioYWLgqWfiQv0QE+wLs0XC7jNF9h36IPvlpn3E75wDDrd2aOIiIiIiAAw89VLvlqLKs+VEgXrHYzuAh1YDba8T13MdAw8RERG5wsBTDyW2agIA2HDUoWmqSWugaS8gsoO47ljhcezETERERAAYeOqlK9pEAAB2ni5EeaXZ+YCoTuJ3zgGxijoRERHViIGnHmrZxB+xIb6oNFuw+YSLtbOatAb8wgBTGZCxQ7GDFR4iIiJXGHjqIY1Gg8EdogAAf+5ysYSE1gtIuEpcPra6Ds+MiIioYWLgqadu7dkUALBsbyZKjfZmq+V7s/DbzjNAq8Fiw3FF4GEfHiIiIpcYeOqp3i3C0LKJP8oqzVh9KAcAYDJb8Mh32/Hkgl3IjxogDjy7XdGPRxF42LeHiIjIhoGnntJoNBjSMRqAfbRWfkmlbb/Brxng4w+YK4FzJ8VGZYWnqryuTpWIiKjeY+Cpx65sK0Zr/bglHVMWpiGzyB5iSowWIKKtuJJ70LpVEXhMFXV0lkRERPUfA0891q9luO3yrzvO4vc0+6KgxUaTfT4eOfBUGe03ZoWHiIjIhoGnHgvQe2N4F/saWusO59ouF1dUAZHtxZW8w+K3qcx+Y1Z4iIiIbBh46rkPR/fCxMGtAQDH80pt20sqqoAIa+A5u0NUd5QhhxUeIiIiGwaees5Lq8HA1hFO24srTECzvoC3H5B/BFgyBTApQg4rPERERDYMPA1A57hgp23FFVVAUDRw2xdiw/4/1U1aVQw/REREMgaeBiDUX4cWTfxV20rkyQjbXgdovABjEWAx2Q+oLAOy9wFbPgdmNQWOrKjDMyYiIqpf3BZ4Xn31VQwcOBD+/v4IDQ11eczp06cxYsQI+Pv7IyoqCs888wyqqtQT5q1Zswa9evWCXq9HmzZtMG/ePKf7mTt3Llq2bAlfX1/0798fW7ZsccMz8qxhnWNU1w0V1tfJWw+Et3K+wepXgY8HAkufBixVwMJ76+AsiYiI6ie3BZ7KykrccccdmDBhgsv9ZrMZI0aMQGVlJTZu3IhvvvkG8+bNw4wZM2zHnDhxAiNGjMDgwYORlpaGyZMn48EHH8Rff/1lO2bBggWYMmUKZs6ciR07dqB79+5ITk5GTk6Ou56aR4zoFqu6/uOW01i82zpMPaqD8w2y96qvmyudjyEiIrpMaCTJvQswzZs3D5MnT0ZhYaFq+7Jly3DDDTcgIyMD0dFiRuFPPvkEU6dORW5uLnQ6HaZOnYolS5Zg7177h/eoUaNQWFiI5cuXAwD69++Pvn374sMPPwQAWCwWxMfH47HHHsO0adMu6BwNBgNCQkJQVFSE4GDn/jL1gSRJGPXZJmw+UaDafuy16+G15lVg3Zzz38mLRe45OSIiIg+ozee3x/rwpKamomvXrrawAwDJyckwGAzYt2+f7ZikpCTV7ZKTk5GamgpAVJG2b9+uOkar1SIpKcl2jCtGoxEGg0H1U99pNBr88NAAfDyml2p7YVmlfQJCIiIicsljgScrK0sVdgDYrmdlZdV4jMFgQHl5OfLy8mA2m10eI9+HK7NmzUJISIjtJz4+/lI8Jbfz0moQ5Ouj2pZXUgnEdvfQGRERETUMtQo806ZNg0ajqfHn4MGD578jD5s+fTqKiopsP+np6Z4+pQsW5Outup5XYgTCW1/Yjd3beklERFRveZ//ELunnnoK9913X43HtGrlYsSQCzExMU6jqbKzs2375N/yNuUxwcHB8PPzg5eXF7y8vFweI9+HK3q9Hnq9/oLOs74JdBV4tBeYWytLAX2gG86KiIiofqtV4ImMjERkZOQleeDExES8+uqryMnJQVRUFAAgJSUFwcHB6NSpk+2YpUuXqm6XkpKCxMREAIBOp0Pv3r2xcuVKjBw5EoDotLxy5UpMmjTpkpxnfROoV/+Tfbr2OJqF+aF3ZEcg90DNNy7NZeBp6ErzAN9QwKtW/3WJiC57buvDc/r0aaSlpeH06dMwm81IS0tDWloaSkpKAABDhw5Fp06dcM8992DXrl3466+/8Pzzz2PixIm26ssjjzyC48eP49lnn8XBgwfx0UcfYeHChXjyySdtjzNlyhR8/vnn+Oabb3DgwAFMmDABpaWluP/++9311DyqSYAOUUH26tT+TANu+zgVuOrp89+4NPf8x1D9lXMQmNMa+Hq4p8+EiKjBcdvXxBkzZuCbb76xXe/ZsycAYPXq1bjmmmvg5eWFxYsXY8KECUhMTERAQADGjh2Ll156yXabhIQELFmyBE8++STee+89NGvWDF988QWSk5Ntx9x1113Izc3FjBkzkJWVhR49emD58uVOHZkbC28vLVY+dTU+XnMMH605Zttu6XQrtEGxwIm1wNo3XN/43wSejDQxiWHSi0DLKy/+fuji7Z4vfp9pfBNrEhG5m9vn4WkIGsI8PI7mbzmNab/usV3f+cJ1CPX3gebMNuDLJNc3uuEdoM8DF/eAr8aKtbp8Q4Fppy7uPujfWfEisP4dcZlzKhERNYx5eOjfiQhUd7recfoc+r22EnOPhlV/o/xj1e87H3lhUmP9n7OIiIjIEQNPAxXg0Hn5hUV7kVtsxJy/DgGPbgJaDXa+Uc7+i3swZRHwQofAExER1SMMPA1Up7hg+Pl42a5nFFXYd0Z1BO5dBPgEqG+Uc55RXNUpOmO/HFrDJI0b3gd+eQiwWC7ucYiIiNyEgaeBCvHzwfqpg3FthyinfV+uP4Gsogrg/iVAu2HAuBViR3EmUFbgdPx5Ze+zX7aYqz8u5QVgz0Lg+KraPwYREZEbMfA0YE0C9Wge7u+0/eXF+/HId9uBuJ7A6AVAfF8gpLnYeTFVnvwj9stVFdUfJ6ssrf1jEBERuREDTwMXEahzuT0tvVC9IaaL+J2ZVvsHKT9nv2wqd32Mucp+WcM/KyIiql/4ydTAOY7WqlZ8P/H7r+eAjwYChswLf5AKxRDo6io88iguAIDmwu+baoGvKxHRxWLgaeAuOPA0T7RfztkHbPyg5uMrDPbOx8rAY6ou8CgrP5f91E5ERFTPMPA0cJ3iqp9o6fVlB3G20BpE4nqqdx5aWv3q6QUngNfjgZ/vE9crFHPvVFXTpGVS9NupMorfx1YDZ7dXf/JUSwySREQXi4GngYsL9cPc0b2g83b+p/xk7TE8+v0OccVbDyRcZd957gTwz5v26/nHgB9GASkzgW1fiW37fxe/a1vhMZUDhgzg25HA59fW/knR+XGCdCKiWuGSy43AiG6xuKpdBPTeXvhjVwae/mmXbd8uZeflWz4FMncDeYeAlBnAqleAiPZAeCvgkyvEMYeXAQMfVz+Aqg9PdRUexfaqCvXcPRYLoGW2vqQkC6DxOv9xREQEgIGn0Qjy9QEA3N67Gb745zgOZhXb9kmSBI1GAwTHiZ/2w8RCohs/AP58AtA6fHAql48wm9SBx1IlRmR5OfzpKIeim8rVFQizEdD6/dunSEqWKud/NyIiqha/djdCgQ7LTmQbjCiuMGHT8XzY1oq99gUgKA4oLxDhRxdkv0GJYlX18nPqwAO4rvI4Vngki/o6XVqWqvMfQ0RENgw8jZChwqS6fjDLgP98sRmjPtuElQdyxEZvPdDySvtBzXrb18kqUCwyWpKj7pAMuO7HoxyWbioHzJX263InZrp0GHiIiGqFgacRKixTB56Nx/Kx64yo0vyxK8O+Q56bBwCa9QMCIsTlPMXMyudO2C9rrZUjlxUeReCpqlBXdVjhufRqWuKDiIicMPA0Qrf3bqa6/tm647bLIX4+9h3x/e2Xm/YG/K2BR1J8mJ47KX7rAgGddTFSlxUeh1FaqgDECs8loWwmZIWHiKhWGHgaoceHtMUHd/dE2ozrMMRhcdFsg3JV9U6AfxPASy+qPXKFR6nAWuHxDQG8rR2PL6TCY2KF55JTVnUYeIiIaoWBpxHy9fHCjd3jEOqvw/t398QdioqPKvB4eQMTNgKPbQP8w10HnnOKwOPjKy6zwuMZDDxERBeNgaeRC9B7Y84d3fHHJDHPTpbBIawExQCh1pXUAyKd7+DYKvH7fBUe5bB09uFxD2XIYeAhIqoVBp7LREywqM7kFhtRZba4PsjfRYXHKq/KF2Yv67pdpgoRcM5st8+3U1OFp7rZmal2VIGHnZaJiGqDgecy0SRQDy+tBhYJyCupdH2QqyYtq+kne+LIOeuHbFU5sPBe4Itrgd0LxTbHeXgcr9O/xwoPEdFFY+C5THhpNYgKEhWaHafPuT4ouKnLzcP9f0SKpQ9y5KKNqQI4ukJc3vq5dZvDTMuqTsvsw3NJsA8PEdFFY+C5jMSGiGatR7/fgT92ZWDNoRz1AZHtgHbDxeWwBKD7aGDUj/ANDAEAVEAn9in78HjLHZkdKzwOo7bo32OFh4joonEtrcvIE0ntMParLQCAx3/cCQBIefIqtI1WLCsx6ntg9wKUh7WHPr4XtFoNQlPFbWyBpyzffnz2PmDdHMBoX7sLJnZadgv24SEiumis8FxGrm4XiTm3d1Nt25vhsE6W1gsnm92MHp/n2FZdrzCJTs4VkjXwKGdiLi8Qq66f2mDf5lThYZPWJcEKDxHRRWPgucxc3U499PxUfpnTMa8vOwhjlQW/7jwLADhXJjo52yo8eYdrfhB2WnYP9uFxVngaWP8OUF7o6TMhonqOgecyExXsi8RWTWzXj+XaOxubzBZM+mEHlu/LUt1GXpurCNalJTJ21vwgpnKHwFOPKjyleUD+sfMfVx+xwuPsi+uAFS8CS5/29JkQUT3HwHMZ+uze3njxxk4AgOO5JbbtO08XYvHuTNWxFSazrcKz0tzrwh7AYgJO/mO/Xp8qPHNaAx/0AorOevpMak9ihcdJiTWcH1vt2fMgonqPgecyFOTrgyvbiqatE3mlkKyTBx5ThB9ZZlEFjFWiD0+a1BqZPs2rv+Oozq6316cKj+x8Var6SFXhqWbySCIicomB5zLVook/vLQalFWakV4gmp+O5TgHnuOqEKTBwsAxYsHRvg863+kVT7h+sPpS4ZFnhRZXPHYaF419eIiILhoDz2XKx0uL3s3DAACL92QAAI5aw82rt3RBhxgxVN2x6pOivQJ49jgw4i37Rv8I4M7/Ad3vcv1gygqPIQP430jg0LJL80Rqw2yq+8e8lNiHh4joojHwXMZut66i/vHqY/hw1RGsOZQLAGgTGYjwADEi67iiUzMAFFcoPmi9rKO2EicCnW4Wl+/9AwiMVj+QssKzbCpwfDXw46hL90QulPI8pIZY4WHgISK6WAw8l7Hru8UiUO+NYmMV3vzbPtS8dVQgwqyBR67whPj5AAAM5YoqySPrgaGvAgMfs29rdTVw5ZPqB1JWeApOXNonURuqwNMA+8Bw4kEioovGwHMZC9R745sH+qJzXDC0GrGtRRN/NAnQoYk18Byx9utp0cQfgKjwyJ2cEdkeGDgJ8PJR33FYS/X1qgoxiqYwXYzgqs6en4Evk903gqqqga/vxQpPDS6wYldV2TCre0T0r3Fpictc7xbhWPL4IABAekEZ/HVe0Gg0CPMXgUeeg6djTDB2nylClUVChckCP51X9XcaFKu+fmqjaMbSBakXGXX0yzjxe90c4MZ3L/YpVU+1oGl59cfVV+y0/O+UFwLvdQdaXAHc/YOnz4aI6hgrPGQTH+6PJoFiRfUmgTrVvo6xQfCyloEMFeoqjSRJ9qoPAER3BsJb26+brdWUymJ1U1KlYpZn5e3NlRf/JGqirPCY6snIsdpgheffOfAnUFEIHFri6TMhIg9g4CGX5E7LspYRAQjUi4JgsSLwSJKEqb/sxhWvr0JusTXYePkAE7cAY36p+UHmjQDObBeXixWzO/uH/+vzd6mqoVd4GHiqdSHNVBL7PRFdzhh4yKVOscGq6y2bBCDYTwQeg2Kk1rK9WVi47Qwyiiqw+lCO/QZe3oA+sOYHydgBfHODuJx3yL7dXdWXRlXh4Yd3rfE1+/dW/B+w+TNPnwXRRXFb4Hn11VcxcOBA+Pv7IzQ01OUxGo3G6Wf+/PmqY9asWYNevXpBr9ejTZs2mDdvntP9zJ07Fy1btoSvry/69++PLVu2uOEZXV4SIgKg0divNwvzQ5BedE4+c85eHfl0rX1dqgOZBvWdeOvtl31DAN9Q5weSV1XPVSxIWlHkfJzFDHx7K/DLQ+c/+QoDcHCJc8fkBt+HR9EcyApP7SmbU9lxufay9wPr3waWPePpMyG6KG4LPJWVlbjjjjswYcKEGo/7+uuvkZmZafsZOXKkbd+JEycwYsQIDB48GGlpaZg8eTIefPBB/PXXX7ZjFixYgClTpmDmzJnYsWMHunfvjuTkZOTk5Lh4NLpQGo0GTUP9bNe9vbQI8hUVnsd/3Inf086issqC/YqQs++sY+DxtV9OnAQExbh+MItZXeFxFXjyDgPHVgJ7FooFQGvyyzhg/mhgzSz1dndWeCQJ+Hkc8Ot4+7bSfODjK4D1716ax2CT1r+jDDzu6ifWmBmL7ZdZLaMGyG2B5//+7//w5JNPomvXrjUeFxoaipiYGNuPr6/9Q/KTTz5BQkIC3nrrLXTs2BGTJk3C7bffjnfeecd2zNtvv42HHnoI999/Pzp16oRPPvkE/v7++Oqrr9z11C4bj17TBgAwoJXoUxPkax9+/sT8NBzOLobJbP+mvC+jCBaL4ptzeGugaW+g00jgyilAWILrBypKR/bRHfbrrgKPcqh6zv6aT/zI3+L3Noe/AXf24SnJAfb+DOxeIEYDAcCmj4DsvcCKmZfmMeoq8JQXiteurMB9j3HJXUgfHkXgaYjTEnic4jWuL8vFENWCx/vwTJw4EREREejXrx+++uor1Wif1NRUJCUlqY5PTk5GamoqAFFF2r59u+oYrVaLpKQk2zGuGI1GGAwG1Q85u7tfPL55oB8+HC1WSc8sUoeErzecBAD0SwiH3luL0kozTuQrhp1764CHVgF3fiP69Ax7DQhu6vxAOQcRUKAIMRWFzsecU0xYmHPgwp6AT4D6+r+p8Jw7Cfzzlj3MOFLdd5nztkuhrvrwLHoUWPwk8NN97nsMT1C+Zqzw1J6yGZCBkRogjwael156CQsXLkRKSgpuu+02PProo/jggw9s+7OyshAdrV6mIDo6GgaDAeXl5cjLy4PZbHZ5TFZWFqoza9YshISE2H7i4+Mv7RNrJDQaDa5uF4kI61B1Hy/1n8svO84AAHrEh6JbsxAAwLaTNVQFwlsBU/Y7r6p+aAkCNYpw4KrCc+6k/XL2vgt7AjqHwPNv+vD8bySw8iVgaTX9FyoVa44ZrZeVEzJeij4jdTUPjzxs+8Ra9z2GJ5gVH9L8wK495aShrPBQA1SrwDNt2jSXHY2VPwcPHrzg+3vhhRdwxRVXoGfPnpg6dSqeffZZzJkzp9ZPoramT5+OoqIi2096errbH7MxePWWLriyTQQ++U9v1fY+LcIwoFUTAEDqsXzb9oLSSpQYXXww9xitvr7jfwCAPMk6Mux8gaemCo9ybh+dv3rfv6rwWCtMB/50vd+oCDyV1r4OXoqh/ZXOK9HXGvvwqNW2ymVShFwzA0+tKUMiAw81QLWaafmpp57CfffdV+MxrVq1uuiT6d+/P15++WUYjUbo9XrExMQgOztbdUx2djaCg4Ph5+cHLy8veHl5uTwmJqaaDrIA9Ho99Hp9tfvJtc5xIfjuwf4AgEmD2+CTtcfw0FWtcF2naATqvfHBqqNIPZ4PSZKQeiwf477ZhtgQX6x86mpolEO++j8MRLQFYruLykmuCDCplk640WuTaBKqqhRNYrLCU/bLOfvFiCWti7xuyLBfVvbZ2PA+kPKC/frFvmFXVxmqVHTolMOPMpSUnwP0QRf3mLLaBJ7SPBEMW14J1XC7xsRcwzIlrigDT1UlcO4UEBznvDQKuaZ6/RgYqeGpVeCJjIxEZGSku84FaWlpCAsLs4WRxMRELF26VHVMSkoKEhMTAQA6nQ69e/fGypUrbaO7LBYLVq5ciUmTJrntPAl4Ork9Hh/SFjpvETp6tQiDzkuLbIMR+zMNuH/eVhirLDieV4rcEiOighQjtrx8gHbJ4vLdPwB/PoHS45vxvTlJBB5AjMgqzgJ63yeun1MEnsoSoOCYCE2ODIrOzeWKSpEy7ADqN+9LQVXhKXHeVlYAhDb/d49Rmz48n14lXotRPwIdrv93j1tf1bQumysmRfXv2Ergr+eAloOA+xZf2vNqrFjhoQbObWtpnT59GgUFBTh9+jTMZjPS0tIAAG3atEFgYCD+/PNPZGdnY8CAAfD19UVKSgpee+01PP3007b7eOSRR/Dhhx/i2WefxQMPPIBVq1Zh4cKFWLLEPjX8lClTMHbsWPTp0wf9+vXDu+++i9LSUtx///3uempkJYcdAPD18UKP5qHYcqIAH605BmOVvbpyLKdUHXiUwlsBY/9E52ni37RM4wd/qRz4cZTYHxwnRnoZrR3Lo7sC2XuAjJ3VBB5FhcdV52fZpX7DNrqo8Cibscr/5YgniwWqUTLnmzVYDn4H/nQdeAwZgC4Q8A123tdQKCs8F9JHStmMuelj8fvkP5f2nBozZXXTVZOwJDXeaiI1Cm7rtDxjxgz07NkTM2fORElJCXr27ImePXti27ZtAAAfHx/MnTsXiYmJ6NGjBz799FO8/fbbmDnTPoQ3ISEBS5YsQUpKCrp374633noLX3zxBZKTk23H3HXXXXjzzTcxY8YM9OjRA2lpaVi+fLlTR2ZyP7kfz5Ldmartx3Jr7r9SqQhHpRqH2ZnPbgfyjojLIc2BFqK6h4w013dmOGO/bDSISkiliwVL/02Fx9WHa6WLPjzKEFR+7uIfD3BuwrrQPjyuglFJDvB2R+Cdzs776guLWYwSW1dDnz7lSCtl82V1lBUedzbJ5BwEPr8WOPzX+Y9tSGqq8JzZDsxOsPXHI6qP3BZ45s2bZ1tUUvlzzTXXAACGDRuGnTt3ori4GCUlJUhLS8PDDz8MrUO/jGuuuQY7d+6E0WjEsWPHXPYhmjRpEk6dOgWj0YjNmzejf//+7npaVINEa+CR+VtXVD9f4ClVdGwu1TiMrMrZD+RbA09EGyCup7icmeb6zpSdmwHxBvzZYOfjCo6JodeWC/igdOSqU7XRxSgtZeD5t3PaOAYXZeA5uR74aCBwcoPz7Vw1fZ3Zaj0/Q/2dcfjkP8C+34BVr1R/jsoKz4UMM6+rTsu/jRdB/Yc73fcYnlBTH55fHxSh/o/H6vaciGrB4/PwUOPRs3ko/Hy8bNdH9RV9Vr7ecBKzlx/EpuP5uPGD9fg29aTqdsqRXNlahz5iB/4Elj4rLjdpaw88GTudO60WnRHT3ystnqyexVlp21fAqfXnf2KOb+7FLqY8UHZarnTVpOXGCs+8EUDOPuCbG8V1s2Lf+Sofl7ov04UyZIp/2+r6Iimfg7GaebKUIeeCAo+ywuPGeXhKGuks7zVVeBri2nR02WHgoUvG18cLH/2nF4Z0iMLYxBYY1sU+Uu6jNccw6rNN2HO2CC/8vg85xfY3SGXg+cR7jPMdy30HItoCEe0BvzDx4bXqFSBzl/hw/ONx0USTscP59jXZNd/1dosFyNwtQlWFwwducabz8S4rPO4MPC6CglwFUgYEV01algsIE+72yRXAgv8Ae352vV/5gWpw8XoDDn14LOfvyK28Tw5Lr72qGio8F9KkSORhDDx0SQ1uH4Uv7+uL/7u5C7o1C0Gn2GDVmlyyL/6xz5ysDDx7TPHAw/8AN7wLdLhBfaMmbcRQ9OYDxfUN74rRSK9EATu+sR+n9QYi2l3YCe9b5Prb6f7fgE8HiapJqcM3dmXgObpSrB6tmnjQRR+esgIxS/OG90QlqrYcP8xr6sOjDDFGF82JygDn2Dzn2HwkV0IO/CkCiqvmvItRZp2vae0bwMYPRcDMSANOrLOeV6H9WFcBE3Cu6pyvyqOsZrn1A7qRdNw9uhJY/479b6KmCg8DDzUAbhulReTr44WlTwwCAPR/bQWyDfY3zN92nkVCRABeWbwfVYr1t8oqq4DYbuKn931A/jHgQ+tEh5Htxe/m/e2zAQMu+7dU+UXAG4dxXqZS4NQGoM0Q9faT1qau06nAsqnqfcq1vL67VfwOiLJvk/vGKJu5yguAv/4LpH0H7PwemLRFfZ+VZeKYkGauz7M2nZaVgcZwFijOBoIUnfiVocUxwDg2cZlKxXxIC/4jroclAENfrv6xL4Tyg7PgGPD3f8VovJ+tIysn71Wfl6smRMB5WLq5EvBxDtc2yiYt1f1UM6dTfXPiH+CPScD1bwFtk85//L8l/21HdQbaDa25Dw8DDzUADeB/OTUGnWLVw59zi42Y/uselFaaVUPYyyrN9gVINRrRUfmOecDNH4kPRQBoNwzQeIkqzpVTxLaWg2z3YZR8sLegFn/aR1c6b1N2fnYcuiyPEFN+KCurQAf+AOaPUVdXSrKBg9b5XvIOiUBUkmvf//tE4L0eorOrK7UJPMoKT+5B4P2eIjjKagw8DqHAcYRbddWW2ig87bxN2Qk954B6zbJqKzyOgec88/JU11/pUi8k666h2d/dJv4uv7/NPfdfHfn/Ais89dv2b4Bjqzx9FvUaAw/VCeVK63f0rqaKYVVucqjYdL4F6Kno2xPZHng0FXjgL2DIDPF71A/Avb8jTwrGY6ZJWFMUhfPqNVb8PrrCeV/eUedt8mKkGWmiKqCcDNHRoSXqylNhunqpiX/eAt5sA+z/Q1xP3ywqFju+dX1/F9KHR+YUYkqB9W+73u94rOMSGI6BR3MJ3jIKjjtvUzb/VRQ6NGlVU+H5N01aqu0NpMOtp/odyWFG1YfHMfC4cTHbupC9D9j8qbqzvNLRFaJPX32VkQb8+Tjw7S2ePpN6jYGH6sSIbrEAgMggPR4d3Ab9E8Lx9NB2WPhwotOxpZXObzr7MoqwL0Px4RzZHvAPF9+mmw8QE+i1ugZ9jJ/gb0tffFd1XbXnYpE0MMQkAkNmikpR3iF71cFYLCozRdb11fpPsN+wWR/Ax180VeUfcR4CX5PyAnVoWWVtFvrrv+JNVq5i7P/ddaWiNn14HDtZA8Cpjfa+GMYa+vA4BpzKEvVjX2jgydwNvBoLrH7Ned/5Ao/hrEOTVobz8cClq/BU19R10RQVHneuav9vmSrEXEGu5qlSjWK7kD48tZzeIOdg9XNpecLHA4Flz4qpEBzlHRXVtU8HOe+rL+T3K6D+TjVRDzDwUJ1I7hyDr+7rg98eHYiEiAAseDgRk65ti85xzjP9lhrVHxLFFSaMeH89Rry/HuWVF/YBkocQYPB/RUDxDVXtu75yFnZe+y0Q0ASI7yc2Ln1WrOs1qxkw73oAkrhdhxH2G/qFifW/AODsjgsLPLpAQC9Wknc527J/OFCSZf8WXV4AHF8jLsvhC6i+SctxeLW5yvXIq4Lj9mYtVxUe+YPZKfCUOoQiF801kgSsfxfY/ZN929/PiyCx9g3nc3QVeJRNWIXpDk1a1VV4ahF4LObqKySXetZtZZOWqzBRX6x4UcwV9LuLZXhMivOWP0Br7MOj+JA939xWFgvwUX/gs6v//fxUl4LyeZ074bw/X1HtvdRhoqII+HIokDr3X96R4m9u13z7ZK3/hiQBq2fZq9CNAAMP1ZlrO0SjWZh6BfMAvXO/+VJjFf7el4XXlx2E2SJhz1n7B+7pgpq/jWuVn8dXPwtMPws8dQh4YhdO3ZOKO40v4KDUHCa535DcWfnwMuD4anE5c5f43aQN0LSX/f4qS4A46/WMHeoFTaujC6x5DS3fYOdRW6tfA46sAD5KBD4aIL6JVxd4HMON0eC6wgOISkn+MfU364oi8eb4Rkvg53HOw+crS9UfSiYXH+An1gErZorJ58xVIlxk71XsX6s+3lVQVK6BVnRG3aRlqK7CU4smrZpCjWPl599+qCn/rRybCOuTzdblNfb9KqoYq1+zB01lUJNfuwvtw3O+ipnyNVFWJjxF/v8OAPrzLLVSm3B8dCWwfHrNcz5t/UI0Z//13IXfryvKJsVFjwAf9rnw21b3ReHkemDt68DCe/7dudUjDDxU75QaqzD+2+34ZO0xLNmTid1nLjzw6L3tEx9WmMxi9I2PLxDWEmcRhS1SRwBAUbn1P3lb+zIlGPComNxQ1vIKQKeY+Tn3kD0AXWiFx78JEBpf/f7SPHvgkStBGTtEx9SidPFzdlv1fXiUlRBABJjq1hArOAF80EvdRFRRJAKL0QDs/dn5jbeyVF2Zcnw8wD6UHBAh8MxW+7BzANi/SH28qwBTqPjgK0p3aNLKdN23wtUorerUNMFicZaoSBUcF/MCzWnjetbqC1Wp+Bt1NS3ApXAxM4TX5KtkUY2TRyQqA4/c3FhTHx7lv8X5JrNUhvT6UAGTZx4HqpmXShGA9/7qukLpyne3Aps+EhOcVqfyEjWnXujfWZURyNpjD/VLngJmt3I9VYbyy487l2KpQww85HF/TroSt/ZqiiYBolPvw9/ZRyqdyC3FrvRC2/XzBR6L4tt5jkH9nzS32H7dUGF9g47tBtz6BTD2T2DYLKDHaPsN5BFgCVeL311vt8/0fHYbkO4wtNw/QnSw1gXZt3W+BQipIfAUZ9mrG22vAyI7OB9z4h/nviDZ+0QAc+yDU1Hk/KYt32f6Zuf7NhrUo6CU5XtAfBtXvvGdWAu8111d9TmaYr+cd0SEQcDeyfvYanXVxNWbq3IIf9EZdbCSLK778dSmSaumqsPP9wMbPwC+uQn4ZRxQlgf89kj1x9dEkiCp1lW7yMBjNomKy6lU2/2qGC/RfEiysjzx+5h1xKKr56Cq8Cgum03qsOmqCqikrEAqg7GnKEdGuppnShnKfn9UjHqsjZoCkpd9MMe/ChWu/s7kUFycLfoK5h0V8yp9cqX4ewdEhcloEHNh1XRuJdkXf271CAMPeVzXZiF4+84eCPEX/8EKy+wfXAezDNh5utB2/fVlB/DXPtd9OipM6iHu2cXqb6HKAFRUbkJRmUkEn253AAlXiR39HwESJ4mRX36hYttd36Lqli9woN0ESGEJ9j5BjsGi+QAxhH60YvbmXvfW3KRVXgDTiY0AACmkmQheEzYCt35u7y90cr39sUKaAzHdRBVnyVPO1ZyKIvsHynUvizltWl8rrrsKPBVF1TcZAeIbqGM/i3MnxUSPGz8U56BsEsg/Yp+nqM/9YmSa4ax4g/0iSVSDalrFHhDPtcT6b6yxVuwK00XT3prXRdADnCs6jhW3oyuBtB/F5Rqfo/XDQtm84vgBcvgv0c/iPM1dS9NOQqNsXqgu8Kx7U0xqWd03/F3zRcXl62HiurJTN+C678tf/xX9Qapr0rwQcvOLqyqVqZoKj+O5na9qoQwV9SHwFCmaU11VeC6mCnWhzaLK40pzqz/ufFydt/z/7PeJQOqHwNfDgTWzxLaUF9THuqqOKqtGxQw8RJdU7+ZhTtuW7c1ClsH+5moyS3j42+04kVeKc6WVeOTb7bbV2Q3l6m/42QaHwKMIQNkGI/q+ugLXvb3WPu8PAOj8geRXRXiR+YbgrcyuGP7RNvyxO1PMAwQA4a2Bcfbqxh6plbjQfKAITje+Jyb8k1d4l414S/Qr0oqA53N0OQBgf1kwEBgFRHcGut0J3GYthZ/ZYi+7x3YD7vpOXD653rlzYkWh/RtlYLRoTguwrk/mWL0BrIHnrPN2WWWJ687WOQfFhIFbv1Bvzzsi5tEBgKa9gXjrQr4pL4jnsOrV6h/LlZgu4vfOb8XClGtmiW+ogPOb9K8PitFogKgQfXer6M9wfI2oiNWGPIGh2SSCzg93iuY+Zbhz4ft1Dmu5VdfUsOplEf52/SCuO35AKjvPmk3OfatcBYXUD0Wo3fxJjedYI/k1VX7Iy9U3ZQVCOZTfMdQ5VtPyj4nJNuUqpfLDuTTv4s/138jaCywcK6aWUAZwV2HRZfXkPIMnLrSyp5rLq5aBZ/NnwJo3xGXH0AnYQ7E8iWppDhAUp3hsxXN1bB4G1P9OJa6/ZDY0DDxUb8y8qTN+eMj1Sve39mqquj57+UG8tHg/lu/LwsQfRBNKoUPgySpSBx7lTM+bjuej0mxBtsFo789Tg+2nxAfOnjNFwE3vA4+nAY9tB5raOwe+s0cnQpZWCwx/Q8wUDYgP/mZ9xeXOtwJ9HwSCYuwVJKufchzmJ2rSWlR0zJXAJmsH05huQFgL6+NKIggo7f8DyNoNePsCra4R2wKjUa3zVXhy9ovlNxztdliDTB6unndYTHYIAFGdgDYOMwLLzQf+Tap/TPudivsAgF0/AnsWisvmShEQXPXrkYfB7//dvm3D+/aqk4+/821ckcv5fzyu7tfkKjRm7BShylQBfzj0X3H1wacMC0VnRdPDV8nA19fbmyG0iuaE/GPnDzzK5jz5A64m1a5Ab3Q+b2OJeF0NiqZIZYVHrrjJHCsiH/YVTUHykG9Vk1aBqBx9OVRUqGpzrheqoghYNNE++hEQa7ntXyT6LCmbTy+0wnO+0WXKIFdTc6oybNUU/nb/JP4+5ErL/t+BZc8Aa14TXzJcBWv5b0Q5lURAhP3ygT/tl139X1L+DcgjJQvTxRB9V5O1NgAMPFRvBOq9MbB1BH58aAAmJ7VFyybiw+nhq1vhyST12ljL9mbht532ysSu9EKM+ULdZHMsV/1GpazwnMiz7ysoO//K2fLxZwvLAW89EJ4ghh9rtTD0ehRLzf2w1tJd1U9I5Z5FoolpyAz7NsU3up4Vn+CYtqX6NhqN6NcD2N+85IpH55Hit3I0FCA6HgMibMnLSdQUePKPiZAiHtC2eaXGWuHa95uoMJ1Pt7vE79Op4o1S6yMCW/9HgBveAQY+JvbL3yRd9VVyFNURCG3hel/BcddlePnNffdC+7ZjK+0z0MZdYP+LsgLxAbR7gXq747Dl/GPA59cC/7sZWHgPAjQOnXldffNW9pkqzRH9k9I3iyVO5LCo7DORs9914DmyQszoXZqn2m85s+38q8FXt2isPNpK+SFfnCWa15Tkas/Z7cD3t6v3KZu+zCb7CCK5z5vyQ74sDzi0VDz/1A+dw83RlcCc1uoAW1trZ4slXf53s/UxFWHFcPb8FR5X/4bnq8YoH8MhHFVVmWExVQJr54ggLytxWLNP6dcHxd/HihfF9RTF+0juwWoqPNYApQw8yueq7Kztqu+S8j7lwLNkipiEUV52pIFh4KF6J7F1E0xOaodvx/XHT48kYvrwjmgW5oeHr2qFyUlt8cSQtk63uXnuBqewcSBT/eaV6VDxkRWUqj8cispMeH7RHvxzRLypFVeYbPd9ttB5BMqBLk/jUdNkmOGlClXGKjOeX7QHqw5mA/pA4IrHRVCSeekBAMcssTiHYBhNLkbetB2quvpPcSzSC8qArneqj/MLt1/WBdk7XAOimUzp5o9Ek1qLK9XDWRVD8L83Xul8LjXpdpf6jTWiraiS+PgCfR4Aet2nPj4sAS41VzT/dbxJ/Y1UKWOn68BTWSq+7Z62dvaVKzpyM9+FBh6jAUj7Qbw+sd2Ba6xVHsd+Qtl77SHh+BqESo79WVxUB5QVtdzD6v4Rcj8rVeA54DrwfH+bWK7kj8dU1QGtqRTIOU8TXk19ZyRJXZVwVdWSKzyuZgZXdlpWrjvnbZ1pXBm2yvJrnnPp5wfEMQvvrf58HWXuVi+l4liBkpd4AazzMyn+ji64wnOepjjl66u4XFVpRPprPaB9NRJY/Yr6NsoQVZIjOhiXOASr/CMiRCpnea828Lio8CiDjfLf1VWAcxV4cg46H9eAMPBQvRUf7o++LcUHuUajwfTrO2JyUjs8dm0bvDyyC+4Z0ALto4OcbieP9jqUVQyztX/OrvRCnMp3XVrOL1F/cP6+6yy+23Qa93y5BX/sylBVgzJcBB5lHyNls9l3m07ju02n8cC8ba6f4Oj5sLQajLGmaQBEQHLS6mogrCUAoFIXint+ycBtH28U1Ztm/ezHPbYd6HijeHO7fraturMrvRB/HHO439bXiia1xIkOD2av8KyzdHN9zkre1n4u3r6ir054a/s+5fxFgPOiqCHqJkobZeDpdFP1laCzO1zPNp1/VIygk8xAcDPxmsi03kBMV9f358rWz8XvLrfb/g2w8ztg65ei8nByg3pdMHMlOpv2qO8j7XsxzH3RRPsHuyrwHFJXfI6vBr6/U1Q9ZK4qPMqOtkf+huT4AZx7noVzS2sIPBVF6uYMV/075AqP1st5n7LTsjxiDwAM1ueprKKU5qk7izuOaKqug3vaDyIMya+LxSKCQNEZMSPyB73s/WyUH/gWs+iALnMMhhfah+e8FR7XgefM8X1IsLhYS87xPn99SFRz/nxc3dxkLLFWghSVsNzDrs9RflxtNYFH2f+v1EV1SbUWoDXweGp5k0uEq6VTg+PtpcU9A0RTx9/7sjD+W/WCm8XGKvj6aFFuMuNkfilaRwbim40nAQBtowJxJEf95nDOoUlLGXBm/L5X1ZyWV1KJCpMZvj72N/qMQmXgsV8+nnuejoutr0VhzJU487Lo+FzhqsLj4ydGbW39Ah/v8QYMGuTIlawRbwG/PSwmWPQPF52Zy8+JGaGtbp67AVpYcJOvdUPC1UCwWOYD7YeLQJF7UKz27u1ru12V41vDhI1i+n1AfPj3+A/Qd5z9jVbnL5rb8q1vosowBohKT2C0vXJRXZCJ7Q70fUhUh6I6iWa9Wz8XwUHZB+PgYhHaHFUUAgeXiMvNB4j7k5ulEq4G9M4BGQCQ/JroyLr3Z/s3fjnMJAxS95FZoqie9VCs8Qagu3GH6rqtiSrtO7EcyhWPqzuJG4vUC6e6arrJP4pM39aIBWDReEMrVYl+WjJLFUy5x6FT3ibPoaoBiPAR1lL8rdRU4SnNO//IJLnC42o9uR3fiKrTmJ/EnFIya9AzlxfC9r+nrEAdcs6dEPNfybz97PP/mE3i7+L4WmCRdcmXgChg+OtiNFtxFjDoKftt844AUR3UwbjojJjmoTquKjyu+sfUFBiBagOPj6GasAOoA4/8t35oqTqMlJ9zroLlHnS9YK1c9atuYVdlR2THShKgfi3ksKqshkmS/XGNxdX/36pHWOGhBu26TtF4+KpWqm1XtolAhxgxY+r+DAPySoxYbB3J9ZiL5jDHJq10xVw/hWUmzPxD/S1QbtZKLyjDhqN5yCqyV32UFR7l4K9i67w/W04UYOCslVhzSLyJKTtM55dW0+9CFwBc8QSWlHexbTKZLWLE1qOpYq4fmSLsmMzijc4CLfa1GieqHaO+tx+r0QD3LxND5298Dxj6Mgq0TfCs6SEAQFqYtTlt0NNi5Nigp0XV5IG/gKufER+coc3tw+4jO9rvW+6kraSsUjg01dn4BgMj3hRzIslvpt3uFIvD9r4fuHuBaAosPOV6mD0AbPlM/G4+QHTylh++3Q2o1FTzHS+yA3DLx8BzGUBLxZpJGi/xvOQKjyO5r5C1utXOdMD1cYB9pJhjJ/FDy6u/DQAUnMDhPeK5Lq6yvq5yk51sz0L1dcdmnONrgM8Hi/4wiyYCh2t4zNKc6gOPr3VyTLnCo2jiK5GsgfnMVgCS6NujPA9rp+d1exTNTWV5YkJMmTL8WCzqJle5meqft+zbtn4h+pSkbxZ/E9u+tO87a62sKgPCgT9EyPQNVXdgl5uETWUiWGXutgcjV9WTzF3qUWuFp8XyNHLzpDLwlJ+zVZs0NU1WemCxqN449mNSVvNKsuxNUfK/Rd4R131wygrE417INAWmUud/c2WTVv4R8XyVwV9+Xf55WyzJ8/2d4jG3fA78cJfrZjYPY+ChBk1u6to0fQjSZlyHJ5PaYdatXdGtmXgz2H7qHL7bdAqVZgt6xIdiUBvnPiH5JZVYvjcT+zPEG4Pc9DW0k+vOvmfPiYBz1ZzVGPPFZixXzAuUo6jwFCoqR3L/oXu/2oyMogrc97XoMKgOPEZUmV1/G6ussuCkokmu2s7RVpIk2c4TAHZ3mCwqQI7fwvzDgZs+ADpcDzTthbsCv8ZC82AAwPdNnhBBY7C1/8qQF4An97qurADqZitXFRz5DdpLL/o03TFPhLUBiqY1nfr8tp8qEM2IugDgxneB9sOA1oNVx1QFtwC63mGfIFLWarAIhVbX/BGA6YtcVD4Ae6Dx8lGHm4i2ojolD+13JDf39FRXepaY+6EqqJn6Ocn9WRynAch2aAZzZDaiv1lUShabB8DVema6dDEzdLrFep65h0Tfn7yjIhTIHXYli6g2bf+6+scrzXUdePo/Ajwq9zHKEk1D1uVVrqh4Dz+br3K+jXIGbUMmJMcPYFOZulqlDD/FmeqKwrzrRSVCDkX+TcTr/91t9mOU0wbIIwKVr/cuudp3lbofmXI29Kw9olnsmxvE+bsKPGnfAYsetV///g5gy6di4krAoYIm2ZozNYUnAQCfVY1AcWtFcysgQsfy6eomTgAocqgKydWf5olicEBVuetZ38vyrEHoAke5OXaaVgYWc6UIssrXQj5ePp8jfwF7fwGWPi0C9b9eH+zSY+ChRiEmxBeh/jo8kdQW0cG+GNhaBJt5G0/i/ZWimeW+gS0R7Gcf7iuPAvt+8yk88t0O3P35JkiSZJvN+Zr26s6+Oi/x3+V0QRksFsn2RUxZ1VFOdqjs7yNXhRybrZSBR5Kqr/IcyDSgUjGpYs55As9zv+3BNW+usV3PL7mwtnfl0P4so49YPFXZT8NF6Xz+ltNiLqSut4th99e/qe43ILvtC9Fp+MEV4nrnW0ToGaRoIgqyh8z9GQbc9nEqBr6+Sn0/10wHYnvYrr5XdYu471s/E00cAHDt80BEGxGyxqVg59CfkG0OxMZzoa6fuHI2bHkEHABEtLM/79ELxXO78X3nJrv2I1T38ad5IE6P/BW46hnRtAOI0XBVRvuoOOWyJoDoaC7PTi1r0gYA4Avxd7HT0gYIb+W0X7ZFsgbN/CNiHbYPe4vJIasT0d552++TRBOio8Bo0Rzab7y4vuAewFyJKnghE01QAb3zbZQzZFtMKC/MRrCmhmHauQftFQ7HD/GyfOCfN+0B5oG/q+/8DoglHQ4sVvcDksNldBf1hKD+EfYm3c8VgTp7X/XVrr0/26tHctPlyX+AV2JQvHep+lhrAPK2NmmdlqJg9FaE+xveFb8zdjrPGXXaoZIpz90U0qzmZWuKM537fgG2wRJOshyCt625OlD8dmxulZvMlGsKKptnlWv21RMMPNQoJbayz/NikYBRfeNxU/c4eGk1uLtfPAa1jcD4q0QzhDw7c1G5CUdySmCsskCrAa5oo54r5ur24tvzvoyiagNHtsEIY5UZTy3chV2KNcAyCyucOiUbq8xOcwANe3cdDBUmbDyWh+V77ZWjk/kOQ+wdJlVU2nH6HH7col6UMa+kmuYyK0OFCZIkoUgxy7Vyxuvq5JcYMe3XPZi8YCfKLd7AHV8D/R6y7T+cXSzWNAPEvEDj16iqLgDESKwH/hbhR/EhtOVENf0k4noAD69FQsV3SDa+jrkF1rmQgmLE/Y/5RTS/yeL7oThCjM7KRBNYHKpIAOwjiABRGbIq9ArDwq3pkCQJaJcsnlvvscCd36hvH9pczLdktcrSE+e8o0Twiu8nPkyrKoBXokTg0QU6dxpvngg8tg24xzpfTbO+qo7gBVIgchEKKUrRdNhqsH1yRwAHLM1RpKumAnfdS8ALeSKcya5+1n5ZDlvVDFk/VBaATcfzgSEzRWXB2oE13ycGFmjtTVqOvP2AQHFO5bknEQQReLIiFSMBm7QVH8Q5++1TCMgfpAGKLx67fhRVKm9fMe2BPAmokk+A/bksGOO8HxBzWUUqwp5fqOuFQX+8yx5mXPnxbtH8pVRVjqBKhz4x1oWJ9cXi/2W6FIUKb8VCpfL0E4Wn1KEBECEKEIMNtIom2aCY6ptaATGiyrG/DyBeN1fWvqGeUFGu8MjzecnzKMlKc8TxyqVijiiWmcneK8Lr0mdFiN77q3r0nAcw8FCjFOLvg/hwMYqoVUQAZt3aFVrrUuqzbu2Gb8f1R2yI8xv00HfEQpixIX6Id1jZ/cbuYpbSXelFOHPO9bfUvBIjlu7JxC871OtFZRaV43CWujR+Iq/UKfCcKzNh4dZ0jP58Mx75brutE/RphxFm2TVUeD5b67x2T7X9gyACXM+XUjD1l92oVDSpFZaff34iuanOZJZwJEfdZr9wazqGvrMOc/6qphlJqXl/dV8kB+WVziPYJGhxSGoOi/JtLKQp0DbJqRKl7Jh+dMjn6pE7jrRewG1fAs36Yvi2Pnj2l91YlObQDBUcJz74ATFXkM4fuPYFnNVE41XTaFTCByXGKvv9eTv8rV0zXfQVUk7AGBQt7rf1tcCjm4AxP6umMThoaQ5Ag5Ju99tv06Q10Gmk7WqBFIRlUQ+qHyssAXguE7jiCdFkN/wN0YdqzM/qvlZtr1NNpOno1bX5GPXZJpTCF2hmPy7dVwSwDZYurm8Y2tw2f5R+07u2Cs/umJHiA1yjFc2tfa3n/cuDol9Oxk5xvdNNwBRr6JD7qoTEi3/jFgOdH6/tdcCkrUDrIdU+F4S2EEFUJi8Xc6HkQJWxQzR/VWN77N3iwor/A0py4FcqAs9pKQr5IZ3tBwbFicBnqRJVKSW5KbRNEtDzP/btgTUEHt9Q0dx3ysUiuCHx6oktk14UCxdn7wXe7yEmmUzfYg888tI0jiPTSnJEtU3ZKVw5nUJROrDvV9HUt/NbsWbdp1c7zw5fhxh4qNGafVt33NqrKX4cPwAaF00x4QE6F7cSOsYG2wKSrG9L0SH4UHYxjjqM9GoTFYioID0kCZi93PkD/mxhOfacVXcsPJBpwNFs8abSr2U4WkWKN1FlQDhpHTHmuGhqrkOFx1ZFAZweBwDyaghIH60+BrNFwsJt6pBWWHoBFR5FkFLOeyRJEp79RXzz/XK9erK+JbszcfvHG1Wdw5UsFgkWi4QKRRNefqnz+Xsr/n2k88zGq6xWHQ/oIT5AnzoMdB8N03/+cL5B19uBB1cgEyKQ/HPExbwrg6YA//kVGG3tFxLRBjdq5+Jz8w0A7B3VAYj+L1pv8aF++9fAgEdFs98wxYR+wYqh+lEdRdVB0WQl95E5E9YPuH850H+CmP+o4w22Yyrhgw1+g4F+D4ufp48CD68VgUwWGi+a2dpep27WKTwlOrVf/6ZtU1ELe7NbrhQKwPr3pQhK60NExWinpG5eUz1e0v8BWm8EnvgLMRrRzHJU2woYuxh4aJUYTXXV02LagPIC4Kf77auMt75WNKUpm+/CrBNSugo8TXuJ4Hvn/0RACIxWV7Xk2yubJTVaMRpQER6r9XwOMD0duOXT6vt2AciXgjA/7GHRcd5UCqyZBR9zOSokH5yVInAy8lrxutz7h/hbkMOLXOFp6RCk4noBPRXzEfmHq5v0tD6iItjnAft8U65mRPYLUw1uQEQ7INk6J1DhaVHpmXeDvdKXcDVc9RvDkinAr9bmzeomN/35AfX1hEFOzbB1iYGHGq3E1k3w9p09EB3sutSu3H59V3szwJAOUXjp5s5Ox8cE+yIqSA+zRcKrS9SjcXrGh+LqduLNz9UEh8dyS/HbTnWgeHLBLnyTKsr2PZqH4ocHB0CjgWoB1FPWUCAHHjkUKfsNfZt6Eh1nLMfvaWdRaqxyOTmiHBgkScK7Kw5j2i+7sfO0+ODx9lK/mck5othYZRvpVR1lkDqQaa/wpClWuJcfVzbxhx3Yduqc02sIAFVmC65//x/c8vFG1X07zpUEAIG+9vJ+TRUsQF3hySqqENWUoGhs7fkqOn9dhk/XOpfazYphdspAqWRKGIwpq434cYvom1FWaf+2W1Kh+OY7eDow9ZSYSqDLrfY+Tt3uAG54F2vaTsNn212MtOlyG9BjDGb6TsOvFhF4sgwVYn224a/bRsplRSSiXNJhi6UDiistYi6m62cDgZH2zuKuKL8IeOlFM0m/h7Da3B0Vkg9GHL4eUpM2MOqb4KQkPtR2ni4UzwEaILIjdmnl/ysaHLvua1F5kCdqBET/mJgu9qVWABy0xONYZRPxPOQPZ/9w4MFVIkwZDfbKgdwZXblMiRzUAiJE6NMrnqPcv0sfCNw8F3j6MHD7V+rnHRgjXhtZwXExGvDOb4DHdwIja1iPzFsvqnbdR4kZ1FsPAfqMAwb/F8pgkCuFIsNgtM9Cbg1wGy2dUQkflFZagCsni7m2AHXfLMBeQQREmInvJ8Jc0z5ihFnT3uoKT6ebxXxcN7xjnwcrfZP4LVdpANG/SznUvdU1QM97xKLJ8mutnG8nONa+xAugnstKHi0Y1UmM4JS1G+ZcRW3SVvx7uBpCX0cYeOiyFRPii9du6Yq5o3vhmnb2fgIfju6FuFDRHHaddaTW4PaR0Gg0uLaDOK7YWKW6rzZRgbY+PoCoHi1+7EosfXwQtBoxAeDWk+fgrdXg/25yDlPBvt6ICfHFwNbqfkNyFUT+3beFGD4rz+icWVSOF37fB0kCvtpw0jbHUESgHrf1sr8ByX14juWW4N0VRzB/azoe+t82SJLk9N2tebi9GuC4IKujPEVn6INZ9gqPvPaY7Jy1wqIMPsr5jmQn88twMKsYu9ILcUBxf44VHkmSUGa0h5DqJpW0Pb4iECmbA2f+vg+VZgtmLXPup6EMSaVG14Fnxf5s/LrzLKb/ugdVZouqU3qJw98I9IEu7yO/w2jct6cbXlt6UF0VAkQIGPkRllTZKyqu+m8t6/IO+hk/Qg7C1EHrQvznFxEShturTeNNT6GX8VOckSJx4MY/8fMVf6Ic4gvCztPnREgZvxoY+ydKFc/5VJMrgKcPqfsGyeuS9Z9g2/SdOQl5rkKqt05UTuQmo9ZD7K/bAMWoKOWQ8ls/A55RzBoc2111l2WVVZC81R11084axIjIHtYmokTFfYe3EqP+gmKdz89RTBfgnl+BG94Wz/nFQtuuDKmJ+PLT6WbVTVZZetrOS8WxM3q8ormxWR8RsjQaYOwfwOS9zn14OlxvDxOOIxavnmqvGHW9016RaXWNGAGp0YhFk8f+oZ6lXaMVr7VyhvhrposmM+VITEsV0Mzehw3tkkWl0NtXVJOeOiSm0PBXzAjvAQw8dFkb3b85RnSLxU094jCiWyxm3doVfjr7qKQ3buuGF27ohDfvEG+iM27shFF9nUdG9GkZjkFtIxHi54NgX298OLonujQNQae4YAxqaw9Cw7vG4s4+zrc3mUUQuDexpWr7qfwyGKvMyLR+yF3ZVow+W3ckD9N/3Y1nf7Z3mDRbLDhsbSJrFx2I2bd3w+bnRD+Gc2WVqDJbsPesPUTklVQis6gCuQ4juJoE6hFsrZ6cO0/HZXXgKbYFGscAIne6VlZiTBbn6pFyZNuOU4Wqc5WVV5oxd/VRVX+jU/mlTs1ayuvK55FtqMDZwnJc++Ya7HdYfkQpR1FFczXDNqAe1XYwS92HyXCBwUM1yq+azuglRsXouSLn5j1DlTeK4W899vyPW2Ey4/N1x8XjtUkSzV5xPWz7TPBGmTXgnC3zwukS+0eFrXoX1xMIjFR9cNsqcRoNcOe3ohnmqmfEtog22NP+MSw2D8BP5qtdNlMCEP2SHt8pPliHvW7fHtZCTCzopRPVGCVvHfDIeuDhdapFeY/nlqDHSyl47re9qpA0cu4GzPn7kJh/6ondzovcenmLprZJ20X1otVgHOg+HSeudzF6zUFZ8ts4ZonFi1VjkVlYASmkmZhME4BZ441VZjnwOIRoZSdquSP6qB/F63zje/Z9ugAgwPrFSBmSlM+h1dXAiLdFJWvITFTE9hXBdtSPotJ25/9E8+odDp3vATEhqVWxfzy2nTqnGhWJDiOAaaeAiZvtIarzLeLfKkRU3iauAYo63wtMOSD6owXF2IOvB3GmZSIAvj5emDu6l9P28AAdxl1p/3bjr/PG/93cGSn7s5FfWonXb+2KUH8f9G4h2sRXTLkaOm8tQhTD3++7oiXWHs5Fz+ahePnmzvDTeaFfy3BsOSkWFWwbFYg7+ohqTFLHaHSMDbb1hzlVUIYV+3MgSYC/zgtDO0cjUO+NEmOV00isvWcNtgDULjoIXloNmgTooNGIwRLnykzYl6FuNjmYZXBaVT7Uzweh/joYKqpQZO24bLFIWLAtHf8cyUVCRAAmDW4LP52XKogUlpmQbTAiJsTXaVTZrR9txOf39kGg3v6Wc+ZcOdILynDmXDkSWzfBH7sy8NFq+zf1ckUzUn5JJbafKkCYvw5z/jqEZYoRbAAwZeEuvPjHPvw8YSDaRQdh8vydSEsvxMJHEhEV5Kuq1mQbKvDK4v047lBhKq8042xhOVpHBkCj0ajWRZOnInDs16V87TYdV48qq6nSIocxjUajCjlZRUa0iQrCgUwDooN9ER6gg8mhcnTUxQzeqqa0Cwg8s5YewDepp/DDltNY/fQ1qn2OM4/nlRhVzaQ5xUaUGKts/5bK6pfqtp1uAjrdJEYjGioQFeyLrfHj8NIusXxIXnENzZBB0cA105y3D5khmsu8XHx0uVg25PvNp1FZZcGPW05j1gPfAD/cgdkm0cT06drjmD68o70/kKNgMUgBEzZi79ki3PCh6AB8oq+k6hNotkg4kGlAh5ggeHtpUdDhbgz53dpEbhIjMUNHvAl0uRWfrjmGjAOiylHqWOHpdqcYQm822Tsnd7he/FRHHyhCntYbmUYdAmBCsK/1vafvOKDvOKw6mI2HZv6F/7upM/4zwHpfzQcAzQcgp7gCx4/nY4BiVCua9gH6T0DeuQLctPsKZHySipMvPyaG1ndw6As15mfgxDpRKfLWAY+mYuiL3+FwRTQ6bzmFR6/xXH8dVxh4iGpJ7+2FlU9djZP5ZegRH6raFxnkPMfF4PZR+OfZwYgN8YW3dS6fD0b3xK87zuLexBYIUIQAL60GPz+SiD1nizDqs03YlV6Ix+eL0Sqj+zWH3tsLPeJDsf5ozYsXyhMventpERWkR7bBiCM5xU4VjQOZxU6Bp3kTf+SWGHG6ADiZV4ZjuaX4aVs6tp60N1Ot2J+DXi1CVSvWA8CBLANiQnxtfY6igvS2IfwfrjqC23vbm9kqqywY/OYaVFkkvHRzZ8z4vfoFL39PO4s3lte8cKGhogpLdmei2dV+WJQm5n956c/9uP+KBFWn46yiClX1RvbiH/uwYFs6HrwyAc/f0Ek1uaOxyoLcEiM+XnMMOcUVeG9UT/h4aVVBIPWYOvAYHJunrCwWCRO+347dZ4qw5PFBqsCTWVSOozklGP7eP4gN8cXGadei2CE4yX2vlJQhx1XgOZJdjPAAHcIDdFh9KAc/bhVh2VWzouPM43nFRqd+YWfPlaN9jBjeX6p4PFd9qaYs3IVlezKx5PFBqnPLLzWKJtXa9unw8sbvaWfx9/5svHl7d1VF1pEyYBfFD0bI1JP46P821u7xNBocUYTMozklaKtYw2/u6qN4O+UwHr6qFaZf39Hp9c8orECovw5oMRD7fHwBiIkFy4xmFFeYMOmHnRjSMUpUd694AoDoy3bBH86x3fHuisN4f+UqtIsOwvLJ6gkgH/52O8wWCc8v2ov/DFCHuxs/WI9sgxE/PjQAiXJzulYLDH8d63acQcZuMZFjpUYH3fDX4cTHF2inmDVdH4jDkqhg17pptQ6wSYvoIoT665zCTk3iw/1tYQcQHaYnXNNaFXZkAXpvdG0aAi9rNcFskXBVu0hMGy7azO9JrOYbqdXLN3fGzT3sI37kJrXRn2/GhqPiQ3lEN9E/YdvJApQ6lNYfubq1eIMG8NRPu/Dsz7ux9eQ5+PpocXvvZvDXeeFQdrGqwhTmL75V7jlThI3H8mxNWqP62UcBnTlX7jS6rcraMbimsAM4NxfJ2kUH4tFr7POK7DlbZJsxGwAW784Ui60qnC4ocxr1BgALtonn88X6E/jnSK7TXEvrDudi3saTWLonC39ZZ9dWzma90SHwuAoTC7elo9PM5fhrXzYyiyqw5lCOw+KzFdhqrfxlFlUg9Vi+6oNDoxGvY05xBQpKK/HPkVxIkqQKHaXGKlVz3r6MIlz3zjrc8+UW/LbzLB6Yt001iaXj1AiO8y/llRidmvSU0zIoH7vAoXN5tqECS3ZnwiIBy/ZmqcKAySzBUF77D0VJkvDE/DQs2Z2J7ze7WMtLQdnseTSnWD06yepYbgm+Wn+i2lnOAfVAhE0nClT73k4RE0l+uk5MB+EYUDMVS8+UKZ5/WaUZX60/ibWHc1V//6sOZqPzzL/wy3b1IIfqz60c7644Aosk/p+UOgQuubnckSRJtubUVQeznfYrO+0rq501UVYazecZOekJDDxE9VCA3huv39oV8eF+6Nk8FB+O7mkLTMmdY7Dw4US0jXLdCfaexJa2sCQfrxQeoMPN1jmFVh+yz61xVbtIfPKf3ogO9lU1yQFAv4RwLBifiDfv6I4ljw+yhS/ZQOuSHW+nHMboz+0zw04c3Brv3tUDgPj2v+KAGB3SIebSLDRYbjLj2WEdsGD8AACif8nuM0U13sZkllQj4VxZsjvTafkOeZg9ACzaeRZrDuUgVdGMVe4wkutgpgEWxYfGybxSPL9or6p5atupc+omLUOFquL27aZTtkpRVJAe7aLE67bzdCH+7899uOfLLfj8n+MoUTQrOT6/X3eIKtz+TIPtstKyPZmwWCTbB7NjhedsYbkt/MlTM5yxBj2LRUKZ4nk7BkllBdBYZXYKA+nVzGdVE+VjvLLkAK54fZVqGRclZQA7nO3cFChJEm79aCNeWrwfH6+pflI85RQKmx2aLh05VjaUYUnZb6esskr1XORJPx/7YSeMVRY89ZN9mYwV+7Px6PfbUVRmQlGZCeP/tw03z92AUmOVUxhdcyi32uqikrIa5+ViZnTl/mxDBc6cK8Owd9dhwdbqF0BVjqaUBxVIkoRZyw5g9vKD550+wt0YeIjqqTv6xOOfZ6/Fb49eYW+Xt+qXEI6v7uuLq9tFYv74AXjzju7w0mrw5VjnieMGtY1AkLWSdN/Allj06BUY0LqJqtzfPjoI/3ugH4Z1EeEoWtE099GYXlj4cCK6WytaCREBeOTq1vj0HvuoDFdrlAXpvaH39sLInk3RMVbMKis3jcy+XT3bslYDVXNXdX54qD/eusM+CkcOJT2ah8LHS4OC0kos3SOaDHTezm9vnWKDnba5svVkge2+H76qFXy8NKo1HVccyLGth+aobVQg9N5alFaa0eq5pbZq0DsrDqOyygJ/nRdu7SkqcNtOFqg6LWcVGVUfgisP5tg+MIN8vdGrRSgAMZv279Zmu9eWHnT6gFNWUpQf1q6+qU/7dQ9aPbcUibNWYemeTKfwsPl4ASQJCPX3Qbdm4vHlCk9FlVn1uuzPMGD1wRzbN/1VB+zDn8+cK3caheaq0nY+m4+rKyxnC8vxx64Ml8cqP7QPZxerqhYArP3UxDktdegX9s3Gk5i7+qhquRlABIp0a58uVxxHcKoqPIrAU1ppxvE8ewg7ZB1w4BicAeDB/23D0j1ZeGfFYTyxYCf+3p+NXemFWLonU/X3A4hpH+79cku14UKSJGQVVdjm+ALUgw9kysCfbTDiz12ZOJhVjE9dTGwqU4Zl+fZnC8vx6drj+GjNMaw6mFPdTesEAw9RAxUf7o9vHuiHAa2a4PbezXDkleEY0tF5AjBfHy9892B/fPNAP7x4U2c0b+KPYF8f3H9FS9sxdzqMPBs3KAGPD2mLv5+8Ctd3dT08d3D7KHSMDUbnuGAM6xKDuBBf9EsIx6+PDkSfFmF4boR9CYQe8fZ5UgJ0XugcF4KfHknEk0ntsGvGUKyfei1eGWmfqXdQ2wh0ig3GdIdKUrdmobhNEYzkaone2wtdm4rH2GYdEj85qa3TOas6ZyroreFo4mDRPHYst9Q2tL5HfCiGdKhmYjWr4V3sVbRAX2+0jrRX3x79fgckSbI1J867vx/+a31tDmeX2JqwxPViHFI031VWWWzzNwX5+qBnvKiwrHeYCHGLQzPLEWs1Q5Ik7FD0+XFV5VCa89chFFgnnGwVIYaGyx/g7aKDEB8mpmuQKzyO/VWKjVW4f95W3PThBmQWlas6yZ85V+50/Kn8MmQUlmPYu+vw3G/qtZwsFgkbj+Vh9cEc1bIsjp3DAXXn8VJjFYa/9w8e+Xa7agTivgyDU4ds5WutnIKhsKwSM//Yhzl/HcKRnBJV4CkxVmHQ7NVO5wuI19sx1GUWKs5N0eRTVG5SNb/e+WkqFm5NVwV1k9miCqCHs4uxQdF/b1HaWZcj+9LSC7HhaL5T6LFYJEz7ZQ8GzFqJbzfZmwOVTbMyZQjKKqqw9f87nldabROXMvDIxxzLtQerN5YfdAqddYmdlokaCccRRErdXfQ3enBQK+zLMKBX81A8oAg/gFhaY8p17Wp8PJ23FosfuxJajRht9M/Ua22Xf56gngH3pu5NbX1+mob5wUurQd+W4ejbUoxYCbH2AVo/dTAkSYQ5WVp6oW1UllyVemVkFzy/aC9ev9U+Muf5Gzph7FdbUFxRhf4J4XjwylbYe7YIxRVVmHBNawTpfbDrTKHt+Bu7x+FPa2Vg54zrkGMwonm4P/7el40jOSW2vjV9Woaj0mzBcmul5qbucaqKwpVtIpDYuontHMP9daqmG7NFwq87ziKvxAgfLw26NQuBr48X+rQIw7ZT51THKj9YkzpGYcWBHCzdI+5XWeHZl+F6OH1CRABO5JXiifk78dV9fVFQWlnjOmqrnroaT/20S0wmCNHvaMtJESjaRgeqRrJ1iAlCU+tyK3LgkZstgvTeCPbzsVXwjuaU4IVF+1T9w86eK4eP9W+0bVQgjuSU4ECmAT9tT8fx3FIczCrG9OEdEOTrgyqzBU8sEP10AODexBbolxCOPi3CsXSvw2rigKoz/oajeTiQaVDN/A2Izt6O0yWsP2Jv0j1bWI6iMhNC/H1Us5VvOJqHDGtoeWJIW7xnXYx4UdpZvHSzejmNEmOVrUlL56VFpdmCDFUfHvvrscthck4AmP7bHij/G58uKFNVYhz7iW08ll/txKrzNp5E5zh1RXPp3kxbXzW5QghAdY4ydYWnAvsV4XXLiQLc0E00ixurzDiaU4JOscGqiprcDKrst2essiCjsFz1/7suMfAQXaZC/Hzw1X19z39gDZR9hbxqCFwDWtknHOsQU32zUrMw5zdCeR20YYq+SP8Z0ALDusQgItDe9NareRiWPj4IBzINGNIxGl5aDT4a01t1X03D/PD5P8dxZZsITBveAeH+PripR1P467zRMkK8HQ5qG2mbwLFzXDAig/SqytkjV7dGeIAOfjovPH5tW+i9tSgqN+GvfVkI9dNhclJb5BYb8fC321FmMsNskWz9MTrFBsPXR4wq+mB0T9z+carLmbEBYMI1bWx9ngAg2NcHrSICEezr7XKOHz8fL3xwd0/cPHcDcoqNuOGD9dW+zgDw0KAEtIoMxKf39Lb2ScrFxmP5tkpUu+gg/LXP3pm1XXSQbX26Y7klKKusslVs/PVe0PuoGwxWHBC3bdHEH6fyy5BXYkSgXjz3Lk1DcCSnxKkp6q5PN2Ha8A7IKqqwhR0A+F/qKfwv1V6RCPP3Uc2ttC/DAJPZgnu/3KLqV6VkMku2gCv7x2G04y87zuCBKxNU/cDeW3kEZosEXx8tHru2DYJ8vfHKkgOoMFmw7ZS6spZtMNpek9ZRgTiQaXDow+P879Y83N8WdM0WCcoGrWM5JdjpIhh1aRoMb60WaemFtn5Z7aODbM1iALD9VIGqQzwAvLvC9TpWmYUVTtMuKCs8J/NLVZ3w5cCTY6jAfV9vxf5MA94b1QP5itvkFotReMesI9yu7RCFT/7T22VTc11hkxYRuZ1Go8Hix67Ejd3jMNWhmep8Qv11mDu6l23xVpky7Mjiw/0xtHNMteErPECHtc8Mxqu3dEWQrw/+7+YutjmUZI9cY5/MTd4XqPfG1/f1xWu3dEWnuGC8eFNnTB3WAX46L2i1GoQF6PD9gwMwd0wvtI0OwsA2Edjzf8nY+t8ktFcMYe7Z3P5YsSF+WDZ5EF6/tSu+HNsH66cOxsgecarHbtHEHgCvahcBrVaDHor7uFsxCm5Aq3B0aRqCj8b0sk1LAIjQNktRCWsVGYB1zwzG08lioruoIF+Mv6o13ritm6qzevNwf+gUIws7xAShXVQQWjTxR1mlGZ+sPY41h0QgC9B5I9LFvwcADFT0FztprbAoKw8BOi9bJ/b9mQY8+L9tWGitQjxyteuVvV+/Td0HLLfYiLmrj1YbduS/nXkbT6q2y5UteWT8q0sPYH+GAdsUzYzyqLXbejWDt5cWDw5qZfu7kPuLybINFbaKXbto0ayZWVQBSZLE7OAOIyJHdItFypSrcN/Ali7P+1BWMTa6mIKibVSQ02CEW3s1RZDeG31bhsFLq8G5MpNTFclxlKSs0myxNf8VV5hQWFapqvCsPZwLZUuU3I/qnRWHbdW1NYdyVU1axioLDBVVOGZ9zBu7x3o07AAMPERUR7o0DcEHd/dEU+uyHfVVVJAv3r6zO3rEh+KhQfbwM7hDFEb3b17DLZ2FB+jw4/gB6J8gKlzyUiWyYF8fjOrXHEM6RqNZmD9m394dj1zdGh+OFrPx3tDN3n/qVutSIfcMaGELEMmdo3FH72YI1Hvjues7WrfF4OdHBuI/A5rj/itaYuHDiRjSMQoxwb7w9dFiVN94NG/iD723ev6a+HB/VUf05uH+tuVSooP16BQnFtS9xzqXy/srj+DNv8WQ7GJjFV69RYTH+eMHqJplesSHqpYr8fHSqGYf/++ITnj4avvrXFllsfXDSu4cjaSO9mVfAOCO3s2cPuwB5+qF8sN1bGIL+HhVX4Gcc3t3XNcpGmaLhOvf/0c1elF+LZQjE+XAs3i3OvBM/WW3LVS1sfbjqqyy4KmFu5BbYrRNwyB7Ykhb6L298OJNndHauk6e0tw1R7HLWm26pad9qok2UYFI7qz+W+rSNAQbpl+Lb8f1t92XY0dsV+QvDo9+vwMPzNuK3q+sQNLb61QVNLmvnBykD2UXo6C0EpsUHci3nzrnNA/Tiv3Ztj48yn5tnsImLSIiB7f2amYLGP9WeIAO88cPwLkyE8IDdDUeq/PWqj5YJ1zTBmWVZtzcoyl8rNWW6zpFY+t/k5BXYkR8uD+uahuJV27pogowOm8tXhlpr+oE6L2ROv3a807yN6BVE/zz7GDsyzCgX0I4+iWEI7fEiBA/H9v939U3HisOiHmE5D4xCREBaBMVhF+sfbdu7B6H39MykBARgJt7NIVGo7HNAn5772ZoHxOECde0htFkwai+8SgzmXFFmzPQQKOaVLNbs1C8ektXtI0+iZu6x2Hv2SLcZK2Czbq1K9YcysGsW7vh/q+32IIBAFzRpgn8fLxtzWp9WoYjbcZQ/LjlND7/5zieu74jnpifZjv+hm6x6NYsBCn77U148eF++HPSlSgorURsiJ9qgsPru8biy/UnnOYsOqPo/BsWoLPNiv7rzrP41TpEv2moH27t1RQRgXq0U1T/WkcG2sLBPQNa4O/9WbYRWJ1igzFteAfbMP/4cH+0igxEr+ah2GGtUkUH622jOTvFBuNwdgnWHVYHN0AEUHl5kKggPe7u1xzvrTyiWv9O2ZzlrdXYgtqwLjEoqxR9dr7ZeFLVzOVqfiu5KddLq0GrehB43FbhOXnyJMaNG4eEhAT4+fmhdevWmDlzJior1Qlw9+7dGDRoEHx9fREfH4/Zs2c73ddPP/2EDh06wNfXF127dsXSpUtV+yVJwowZMxAbGws/Pz8kJSXhyBHXbZVERHVNo9GcN+y4Eqj3xswbOztNcumn87J1/NRqNU7VmurO4ULEh/tjWJcYaDQaaDQaRAX5qu4/yNcH88cnYu0zg7Fh2rW4vXczPHategmBqcM64L/Xd8SiR6+Ar48X7ujdDMM6xyAySI+Jg9vYjplxYydotRoE6r3x/YMD8N2D/fG8dQTbHb2bwUurQXSwL6YO64COscG4o0+87Vzu7tccn97TB+EBOnx1X190aRqMbs1CcPiV4fj+wQEY3V+MPIwLEZ16A/TeeHBQK2x+Lgk392iKJ4aIUXzv3NUdvj5eaBcdhKeHtsOgthFY8viVWPP0YIT669AqMtBpNuce8aH4feIVGNY5BloN0Kt5KDQaMbqwb8swhPiJ5WbGDGiuahYERBh7amh7jHVoxgpSTD0x/qpWeH6EfYXya9pHIjpYLHY8omsshlorhQ8qKpCRQfbOyx0V0y+0jw7CnX3s4b1fQjjuv6IltBrgvVE98ejg1ujaNAQ6by1u7dkU3RXNode0j0SflvYm1P4JTWzVSrnzdrvoQLRsou579+k9vW3HAUCfFmGqaTA8RnKTZcuWSffdd5/0119/SceOHZN+//13KSoqSnrqqadsxxQVFUnR0dHSmDFjpL1790o//vij5OfnJ3366ae2YzZs2CB5eXlJs2fPlvbv3y89//zzko+Pj7Rnzx7bMa+//roUEhIiLVq0SNq1a5d00003SQkJCVJ5efkFnWtRUZEEQCoqKrp0LwAREdlYLJYLPvZIdrFUXln1r+9/1cFsKb2g1OXxZrNFyi2uqNVjuGI0mVW/XZ3Lx2uOSi2mLpZaTF0sLdp5xuX9bDyaJ7WYulia+fte27YNR3Klab/skrINrj/LzGaLNO2X3dKrS/arth/JNkhdZi6X7vlys3TmXJn087Z0qcXUxdIdn2yU8kuMUmWVWcox2J+70WSWSipMkiRJkqG8Uhrw2grpmjmrpdziCun53/bYzr2yyiylnT4nJb62wrbtv7/tln7YfEq6avYq6YGvt0ivLtkvlVdWST9ZH7PF1MXSZ2uP1eIVrZ3afH67LfC4Mnv2bCkhIcF2/aOPPpLCwsIko9Fo2zZ16lSpffv2tut33nmnNGLECNX99O/fX3r44YclSRJ/WDExMdKcOXNs+wsLCyW9Xi/9+OOPF3ReDDxEROQuhWWVUofnl0ntn1+qChqO8oorahUMa2I2q+8nv8R4wfdtNJltAe50fqnU7cW/pOd+3a06ZsepAum5X3dLp/NdB8qi8kpb4DmWU3wRz+DC1Obzu05rTEVFRQgPt5e5UlNTcdVVV0Gns5d6k5OT8cYbb+DcuXMICwtDamoqpkyZorqf5ORkLFq0CABw4sQJZGVlISkpybY/JCQE/fv3R2pqKkaNGuV0HkajEUajvY3SYHA9pwUREdG/FeLng6VPDIKxyuxygWFZk2pGul0Mx3m5atOkquzwHR/uj10zhzod07N5mGrUoaNgXx8sfDgRJUZTvei/A9ThKK2jR4/igw8+wMMPP2zblpWVhehodU9z+XpWVlaNxyj3K2/n6hhHs2bNQkhIiO0nPj7e5XFERESXQkJEQI1zUDVG/RLCce15ZimvS7UOPNOmTbN1Zqvu5+DBg6rbnD17FsOGDcMdd9yBhx566JKd/MWaPn06ioqKbD/p6ennvxERERE1WLVu0nrqqadw33331XhMq1b2nuMZGRkYPHgwBg4ciM8++0x1XExMDLKz1cvSy9djYmJqPEa5X94WGxurOqZHjx4uz0+v10Ovv3SlQyIiIqrfah14IiMjERkZef4DISo7gwcPRu/evfH1119D67AEfWJiIv773//CZDLBx0cMyUtJSUH79u0RFhZmO2blypWYPHmy7XYpKSlITEwEACQkJCAmJgYrV660BRyDwYDNmzdjwoQJtX16RERE1Ai5rQ/P2bNncc0116B58+Z48803kZubi6ysLFW/mtGjR0On02HcuHHYt28fFixYgPfee0/VSfmJJ57A8uXL8dZbb+HgwYN48cUXsW3bNkyaNAmAmFti8uTJeOWVV/DHH39gz549uPfeexEXF4eRI0e66+kRERFRA+K2UVopKSk4evQojh49imbN1DOWStYl60NCQvD3339j4sSJ6N27NyIiIjBjxgyMHz/eduzAgQPxww8/4Pnnn8dzzz2Htm3bYtGiRejSxb5K7bPPPovS0lKMHz8ehYWFuPLKK7F8+XL4+rpeRZaIiIguLxpJTh+XMYPBgJCQEBQVFSE4+PLqRU9ERNRQ1ebzm4uHEhERUaPHwENERESNHgMPERERNXoMPERERNToMfAQERFRo8fAQ0RERI0eAw8RERE1em6beLAhkaciMhgMHj4TIiIiulDy5/aFTCnIwAOguLgYABAfH+/hMyEiIqLaKi4uRkhISI3HcKZlABaLBRkZGQgKCoJGo7mk920wGBAfH4/09HTO4lzH+Np7Fl9/z+Fr7zl87euWJEkoLi5GXFyc0wLljljhAaDVap3W+7rUgoOD+cfvIXztPYuvv+fwtfccvvZ153yVHRk7LRMREVGjx8BDREREjR4Dj5vp9XrMnDkTer3e06dy2eFr71l8/T2Hr73n8LWvv9hpmYiIiBo9VniIiIio0WPgISIiokaPgYeIiIgaPQYeIiIiavQYeNxs7ty5aNmyJXx9fdG/f39s2bLF06fU4K1btw433ngj4uLioNFosGjRItV+SZIwY8YMxMbGws/PD0lJSThy5IjqmIKCAowZMwbBwcEIDQ3FuHHjUFJSUofPomGaNWsW+vbti6CgIERFRWHkyJE4dOiQ6piKigpMnDgRTZo0QWBgIG677TZkZ2erjjl9+jRGjBgBf39/REVF4ZlnnkFVVVVdPpUG5+OPP0a3bt1sE9olJiZi2bJltv183evO66+/Do1Gg8mTJ9u28fWv/xh43GjBggWYMmUKZs6ciR07dqB79+5ITk5GTk6Op0+tQSstLUX37t0xd+5cl/tnz56N999/H5988gk2b96MgIAAJCcno6KiwnbMmDFjsG/fPqSkpGDx4sVYt24dxo8fX1dPocFau3YtJk6ciE2bNiElJQUmkwlDhw5FaWmp7Zgnn3wSf/75J3766SesXbsWGRkZuPXWW237zWYzRowYgcrKSmzcuBHffPMN5s2bhxkzZnjiKTUYzZo1w+uvv47t27dj27ZtuPbaa3HzzTdj3759APi615WtW7fi008/Rbdu3VTb+fo3ABK5Tb9+/aSJEyfarpvNZikuLk6aNWuWB8+qcQEg/fbbb7brFotFiomJkebMmWPbVlhYKOn1eunHH3+UJEmS9u/fLwGQtm7dajtm2bJlkkajkc6ePVtn594Y5OTkSACktWvXSpIkXmsfHx/pp59+sh1z4MABCYCUmpoqSZIkLV26VNJqtVJWVpbtmI8//lgKDg6WjEZj3T6BBi4sLEz64osv+LrXkeLiYqlt27ZSSkqKdPXVV0tPPPGEJEn8u28oWOFxk8rKSmzfvh1JSUm2bVqtFklJSUhNTfXgmTVuJ06cQFZWlup1DwkJQf/+/W2ve2pqKkJDQ9GnTx/bMUlJSdBqtdi8eXOdn3NDVlRUBAAIDw8HAGzfvh0mk0n1+nfo0AHNmzdXvf5du3ZFdHS07Zjk5GQYDAZbtYJqZjabMX/+fJSWliIxMZGvex2ZOHEiRowYoXqdAf7dNxRcPNRN8vLyYDabVX/cABAdHY2DBw966Kwav6ysLABw+brL+7KyshAVFaXa7+3tjfDwcNsxdH4WiwWTJ0/GFVdcgS5dugAQr61Op0NoaKjqWMfX39W/j7yPqrdnzx4kJiaioqICgYGB+O2339CpUyekpaXxdXez+fPnY8eOHdi6davTPv7dNwwMPER0USZOnIi9e/di/fr1nj6Vy0b79u2RlpaGoqIi/Pzzzxg7dizWrl3r6dNq9NLT0/HEE08gJSUFvr6+nj4dukhs0nKTiIgIeHl5OfXSz87ORkxMjIfOqvGTX9uaXveYmBinjuNVVVUoKCjgv80FmjRpEhYvXozVq1ejWbNmtu0xMTGorKxEYWGh6njH19/Vv4+8j6qn0+nQpk0b9O7dG7NmzUL37t3x3nvv8XV3s+3btyMnJwe9evWCt7c3vL29sXbtWrz//vvw9vZGdHQ0X/8GgIHHTXQ6HXr37o2VK1fatlksFqxcuRKJiYkePLPGLSEhATExMarX3WAwYPPmzbbXPTExEYWFhdi+fbvtmFWrVsFisaB///51fs4NiSRJmDRpEn777TesWrUKCQkJqv29e/eGj4+P6vU/dOgQTp8+rXr99+zZowqdKSkpCA4ORqdOnermiTQSFosFRqORr7ubDRkyBHv27EFaWprtp0+fPhgzZoztMl//BsDTvaYbs/nz50t6vV6aN2+etH//fmn8+PFSaGioqpc+1V5xcbG0c+dOaefOnRIA6e2335Z27twpnTp1SpIkSXr99del0NBQ6ffff5d2794t3XzzzVJCQoJUXl5uu49hw4ZJPXv2lDZv3iytX79eatu2rXT33Xd76ik1GBMmTJBCQkKkNWvWSJmZmbafsrIy2zGPPPKI1Lx5c2nVqlXStm3bpMTERCkxMdG2v6qqSurSpYs0dOhQKS0tTVq+fLkUGRkpTZ8+3RNPqcGYNm2atHbtWunEiRPS7t27pWnTpkkajUb6+++/JUni617XlKO0JImvf0PAwONmH3zwgdS8eXNJp9NJ/fr1kzZt2uTpU2rwVq9eLQFw+hk7dqwkSWJo+gsvvCBFR0dLer1eGjJkiHTo0CHVfeTn50t33323FBgYKAUHB0v333+/VFxc7IFn07C4et0BSF9//bXtmPLycunRRx+VwsLCJH9/f+mWW26RMjMzVfdz8uRJafjw4ZKfn58UEREhPfXUU5LJZKrjZ9OwPPDAA1KLFi0knU4nRUZGSkOGDLGFHUni617XHAMPX//6TyNJkuSZ2hIRERFR3WAfHiIiImr0GHiIiIio0WPgISIiokaPgYeIiIgaPQYeIiIiavQYeIiIiKjRY+AhIiKiRo+Bh4iIiBo9Bh4iIiJq9Bh4iIiIqNFj4CEiIqJGj4GHiIiIGr3/B9Y3Mz19NXX1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 11.92679  validloss 12.45789±0.00000  bestvalidloss 12.45789  last_update 0\n",
      "train: iter 1  trainloss 10.85442  validloss 11.30235±0.00000  bestvalidloss 11.30235  last_update 0\n",
      "train: iter 2  trainloss 9.96373  validloss 10.31591±0.00000  bestvalidloss 10.31591  last_update 0\n",
      "train: iter 3  trainloss 9.19820  validloss 9.51584±0.00000  bestvalidloss 9.51584  last_update 0\n",
      "train: iter 4  trainloss 8.56765  validloss 8.82021±0.00000  bestvalidloss 8.82021  last_update 0\n",
      "train: iter 5  trainloss 8.00600  validloss 8.21799±0.00000  bestvalidloss 8.21799  last_update 0\n",
      "train: iter 6  trainloss 7.52245  validloss 7.74376±0.00000  bestvalidloss 7.74376  last_update 0\n",
      "train: iter 7  trainloss 7.11374  validloss 7.28196±0.00000  bestvalidloss 7.28196  last_update 0\n",
      "train: iter 8  trainloss 6.73435  validloss 6.88182±0.00000  bestvalidloss 6.88182  last_update 0\n",
      "train: iter 9  trainloss 6.41466  validloss 6.54457±0.00000  bestvalidloss 6.54457  last_update 0\n",
      "train: iter 10  trainloss 6.13022  validloss 6.25703±0.00000  bestvalidloss 6.25703  last_update 0\n",
      "train: iter 11  trainloss 5.86206  validloss 5.95103±0.00000  bestvalidloss 5.95103  last_update 0\n",
      "train: iter 12  trainloss 5.63229  validloss 5.71918±0.00000  bestvalidloss 5.71918  last_update 0\n",
      "train: iter 13  trainloss 5.41664  validloss 5.48745±0.00000  bestvalidloss 5.48745  last_update 0\n",
      "train: iter 14  trainloss 5.22438  validloss 5.29418±0.00000  bestvalidloss 5.29418  last_update 0\n",
      "train: iter 15  trainloss 5.03705  validloss 5.11106±0.00000  bestvalidloss 5.11106  last_update 0\n",
      "train: iter 16  trainloss 4.86958  validloss 4.94199±0.00000  bestvalidloss 4.94199  last_update 0\n",
      "train: iter 17  trainloss 4.71141  validloss 4.78419±0.00000  bestvalidloss 4.78419  last_update 0\n",
      "train: iter 18  trainloss 4.56320  validloss 4.61494±0.00000  bestvalidloss 4.61494  last_update 0\n",
      "train: iter 19  trainloss 4.42198  validloss 4.48308±0.00000  bestvalidloss 4.48308  last_update 0\n",
      "train: iter 20  trainloss 4.28435  validloss 4.33523±0.00000  bestvalidloss 4.33523  last_update 0\n",
      "train: iter 21  trainloss 4.15485  validloss 4.20974±0.00000  bestvalidloss 4.20974  last_update 0\n",
      "train: iter 22  trainloss 4.02941  validloss 4.07566±0.00000  bestvalidloss 4.07566  last_update 0\n",
      "train: iter 23  trainloss 3.90231  validloss 3.95607±0.00000  bestvalidloss 3.95607  last_update 0\n",
      "train: iter 24  trainloss 3.78581  validloss 3.83165±0.00000  bestvalidloss 3.83165  last_update 0\n",
      "train: iter 25  trainloss 3.66571  validloss 3.72287±0.00000  bestvalidloss 3.72287  last_update 0\n",
      "train: iter 26  trainloss 3.55028  validloss 3.60186±0.00000  bestvalidloss 3.60186  last_update 0\n",
      "train: iter 27  trainloss 3.43840  validloss 3.48968±0.00000  bestvalidloss 3.48968  last_update 0\n",
      "train: iter 28  trainloss 3.33133  validloss 3.37406±0.00000  bestvalidloss 3.37406  last_update 0\n",
      "train: iter 29  trainloss 3.22893  validloss 3.27868±0.00000  bestvalidloss 3.27868  last_update 0\n",
      "train: iter 30  trainloss 3.13153  validloss 3.17278±0.00000  bestvalidloss 3.17278  last_update 0\n",
      "train: iter 31  trainloss 3.03534  validloss 3.07352±0.00000  bestvalidloss 3.07352  last_update 0\n",
      "train: iter 32  trainloss 2.94705  validloss 2.98552±0.00000  bestvalidloss 2.98552  last_update 0\n",
      "train: iter 33  trainloss 2.86185  validloss 2.90217±0.00000  bestvalidloss 2.90217  last_update 0\n",
      "train: iter 34  trainloss 2.78065  validloss 2.81540±0.00000  bestvalidloss 2.81540  last_update 0\n",
      "train: iter 35  trainloss 2.70369  validloss 2.74801±0.00000  bestvalidloss 2.74801  last_update 0\n",
      "train: iter 36  trainloss 2.63129  validloss 2.66483±0.00000  bestvalidloss 2.66483  last_update 0\n",
      "train: iter 37  trainloss 2.56289  validloss 2.59420±0.00000  bestvalidloss 2.59420  last_update 0\n",
      "train: iter 38  trainloss 2.49509  validloss 2.52539±0.00000  bestvalidloss 2.52539  last_update 0\n",
      "train: iter 39  trainloss 2.42766  validloss 2.45985±0.00000  bestvalidloss 2.45985  last_update 0\n",
      "train: iter 40  trainloss 2.36353  validloss 2.39737±0.00000  bestvalidloss 2.39737  last_update 0\n",
      "train: iter 41  trainloss 2.30230  validloss 2.33598±0.00000  bestvalidloss 2.33598  last_update 0\n",
      "train: iter 42  trainloss 2.24099  validloss 2.27519±0.00000  bestvalidloss 2.27519  last_update 0\n",
      "train: iter 43  trainloss 2.18286  validloss 2.22086±0.00000  bestvalidloss 2.22086  last_update 0\n",
      "train: iter 44  trainloss 2.12311  validloss 2.16386±0.00000  bestvalidloss 2.16386  last_update 0\n",
      "train: iter 45  trainloss 2.06178  validloss 2.10982±0.00000  bestvalidloss 2.10982  last_update 0\n",
      "train: iter 46  trainloss 2.01074  validloss 2.04606±0.00000  bestvalidloss 2.04606  last_update 0\n",
      "train: iter 47  trainloss 1.95244  validloss 2.00550±0.00000  bestvalidloss 2.00550  last_update 0\n",
      "train: iter 48  trainloss 1.90081  validloss 1.94670±0.00000  bestvalidloss 1.94670  last_update 0\n",
      "train: iter 49  trainloss 1.83935  validloss 1.89292±0.00000  bestvalidloss 1.89292  last_update 0\n",
      "train: iter 50  trainloss 1.79082  validloss 1.84039±0.00000  bestvalidloss 1.84039  last_update 0\n",
      "train: iter 51  trainloss 1.74599  validloss 1.78834±0.00000  bestvalidloss 1.78834  last_update 0\n",
      "train: iter 52  trainloss 1.68511  validloss 1.74616±0.00000  bestvalidloss 1.74616  last_update 0\n",
      "train: iter 53  trainloss 1.63577  validloss 1.67996±0.00000  bestvalidloss 1.67996  last_update 0\n",
      "train: iter 54  trainloss 1.58394  validloss 1.65223±0.00000  bestvalidloss 1.65223  last_update 0\n",
      "train: iter 55  trainloss 1.53144  validloss 1.61277±0.00000  bestvalidloss 1.61277  last_update 0\n",
      "train: iter 56  trainloss 1.48152  validloss 1.52491±0.00000  bestvalidloss 1.52491  last_update 0\n",
      "train: iter 57  trainloss 1.43542  validloss 1.49838±0.00000  bestvalidloss 1.49838  last_update 0\n",
      "train: iter 58  trainloss 1.37218  validloss 1.45925±0.00000  bestvalidloss 1.45925  last_update 0\n",
      "train: iter 59  trainloss 1.32628  validloss 1.39365±0.00000  bestvalidloss 1.39365  last_update 0\n",
      "train: iter 60  trainloss 1.26791  validloss 1.35472±0.00000  bestvalidloss 1.35472  last_update 0\n",
      "train: iter 61  trainloss 1.22889  validloss 1.31034±0.00000  bestvalidloss 1.31034  last_update 0\n",
      "train: iter 62  trainloss 1.18603  validloss 1.26855±0.00000  bestvalidloss 1.26855  last_update 0\n",
      "train: iter 63  trainloss 1.13251  validloss 1.22154±0.00000  bestvalidloss 1.22154  last_update 0\n",
      "train: iter 64  trainloss 1.07773  validloss 1.19460±0.00000  bestvalidloss 1.19460  last_update 0\n",
      "train: iter 65  trainloss 1.03785  validloss 1.12506±0.00000  bestvalidloss 1.12506  last_update 0\n",
      "train: iter 66  trainloss 0.96584  validloss 1.05066±0.00000  bestvalidloss 1.05066  last_update 0\n",
      "train: iter 67  trainloss 0.92389  validloss 1.04184±0.00000  bestvalidloss 1.04184  last_update 0\n",
      "train: iter 68  trainloss 0.86447  validloss 0.96528±0.00000  bestvalidloss 0.96528  last_update 0\n",
      "train: iter 69  trainloss 0.81275  validloss 0.96509±0.00000  bestvalidloss 0.96509  last_update 0\n",
      "train: iter 70  trainloss 0.76370  validloss 0.88497±0.00000  bestvalidloss 0.88497  last_update 0\n",
      "train: iter 71  trainloss 0.70894  validloss 0.86391±0.00000  bestvalidloss 0.86391  last_update 0\n",
      "train: iter 72  trainloss 0.65857  validloss 0.78195±0.00000  bestvalidloss 0.78195  last_update 0\n",
      "train: iter 73  trainloss 0.61299  validloss 0.73769±0.00000  bestvalidloss 0.73769  last_update 0\n",
      "train: iter 74  trainloss 0.53610  validloss 0.67193±0.00000  bestvalidloss 0.67193  last_update 0\n",
      "train: iter 75  trainloss 0.50250  validloss 0.64095±0.00000  bestvalidloss 0.64095  last_update 0\n",
      "train: iter 76  trainloss 0.42162  validloss 0.60464±0.00000  bestvalidloss 0.60464  last_update 0\n",
      "train: iter 77  trainloss 0.38639  validloss 0.56637±0.00000  bestvalidloss 0.56637  last_update 0\n",
      "train: iter 78  trainloss 0.34354  validloss 0.49739±0.00000  bestvalidloss 0.49739  last_update 0\n",
      "train: iter 79  trainloss 0.30209  validloss 0.43703±0.00000  bestvalidloss 0.43703  last_update 0\n",
      "train: iter 80  trainloss 0.22856  validloss 0.36134±0.00000  bestvalidloss 0.36134  last_update 0\n",
      "train: iter 81  trainloss 0.17997  validloss 0.36949±0.00000  bestvalidloss 0.36134  last_update 1\n",
      "train: iter 82  trainloss 0.15526  validloss 0.30536±0.00000  bestvalidloss 0.30536  last_update 0\n",
      "train: iter 83  trainloss 0.05224  validloss 0.31272±0.00000  bestvalidloss 0.30536  last_update 1\n",
      "train: iter 84  trainloss 0.06448  validloss 0.22752±0.00000  bestvalidloss 0.22752  last_update 0\n",
      "train: iter 85  trainloss 0.02448  validloss 0.21468±0.00000  bestvalidloss 0.21468  last_update 0\n",
      "train: iter 86  trainloss -0.05166  validloss 0.14289±0.00000  bestvalidloss 0.14289  last_update 0\n",
      "train: iter 87  trainloss -0.04836  validloss 0.18338±0.00000  bestvalidloss 0.14289  last_update 1\n",
      "train: iter 88  trainloss -0.12144  validloss 0.12311±0.00000  bestvalidloss 0.12311  last_update 0\n",
      "train: iter 89  trainloss -0.16848  validloss 0.05767±0.00000  bestvalidloss 0.05767  last_update 0\n",
      "train: iter 90  trainloss -0.19632  validloss 0.03372±0.00000  bestvalidloss 0.03372  last_update 0\n",
      "train: iter 91  trainloss -0.21968  validloss -0.03971±0.00000  bestvalidloss -0.03971  last_update 0\n",
      "train: iter 92  trainloss -0.26495  validloss -0.10787±0.00000  bestvalidloss -0.10787  last_update 0\n",
      "train: iter 93  trainloss -0.30185  validloss -0.15459±0.00000  bestvalidloss -0.15459  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 94  trainloss -0.34921  validloss -0.15802±0.00000  bestvalidloss -0.15802  last_update 0\n",
      "train: iter 95  trainloss -0.37500  validloss -0.15575±0.00000  bestvalidloss -0.15802  last_update 1\n",
      "train: iter 96  trainloss -0.41801  validloss -0.21218±0.00000  bestvalidloss -0.21218  last_update 0\n",
      "train: iter 97  trainloss -0.46555  validloss -0.32665±0.00000  bestvalidloss -0.32665  last_update 0\n",
      "train: iter 98  trainloss -0.49763  validloss -0.30513±0.00000  bestvalidloss -0.32665  last_update 1\n",
      "train: iter 99  trainloss -0.54767  validloss -0.27305±0.00000  bestvalidloss -0.32665  last_update 2\n",
      "train: iter 100  trainloss -0.56954  validloss -0.34501±0.00000  bestvalidloss -0.34501  last_update 0\n",
      "train: iter 101  trainloss -0.62626  validloss -0.40311±0.00000  bestvalidloss -0.40311  last_update 0\n",
      "train: iter 102  trainloss -0.64638  validloss -0.47887±0.00000  bestvalidloss -0.47887  last_update 0\n",
      "train: iter 103  trainloss -0.68846  validloss -0.48459±0.00000  bestvalidloss -0.48459  last_update 0\n",
      "train: iter 104  trainloss -0.73906  validloss -0.47626±0.00000  bestvalidloss -0.48459  last_update 1\n",
      "train: iter 105  trainloss -0.76463  validloss -0.55643±0.00000  bestvalidloss -0.55643  last_update 0\n",
      "train: iter 106  trainloss -0.82117  validloss -0.53778±0.00000  bestvalidloss -0.55643  last_update 1\n",
      "train: iter 107  trainloss -0.83652  validloss -0.63649±0.00000  bestvalidloss -0.63649  last_update 0\n",
      "train: iter 108  trainloss -0.88117  validloss -0.65471±0.00000  bestvalidloss -0.65471  last_update 0\n",
      "train: iter 109  trainloss -0.90729  validloss -0.73170±0.00000  bestvalidloss -0.73170  last_update 0\n",
      "train: iter 110  trainloss -0.94442  validloss -0.75987±0.00000  bestvalidloss -0.75987  last_update 0\n",
      "train: iter 111  trainloss -0.98531  validloss -0.72558±0.00000  bestvalidloss -0.75987  last_update 1\n",
      "train: iter 112  trainloss -1.02576  validloss -0.81938±0.00000  bestvalidloss -0.81938  last_update 0\n",
      "train: iter 113  trainloss -1.07125  validloss -0.80338±0.00000  bestvalidloss -0.81938  last_update 1\n",
      "train: iter 114  trainloss -1.08331  validloss -0.89054±0.00000  bestvalidloss -0.89054  last_update 0\n",
      "train: iter 115  trainloss -1.10338  validloss -0.93833±0.00000  bestvalidloss -0.93833  last_update 0\n",
      "train: iter 116  trainloss -1.15952  validloss -0.91043±0.00000  bestvalidloss -0.93833  last_update 1\n",
      "train: iter 117  trainloss -1.17567  validloss -0.95860±0.00000  bestvalidloss -0.95860  last_update 0\n",
      "train: iter 118  trainloss -1.20528  validloss -1.01511±0.00000  bestvalidloss -1.01511  last_update 0\n",
      "train: iter 119  trainloss -1.23519  validloss -1.05795±0.00000  bestvalidloss -1.05795  last_update 0\n",
      "train: iter 120  trainloss -1.28856  validloss -1.10229±0.00000  bestvalidloss -1.10229  last_update 0\n",
      "train: iter 121  trainloss -1.26850  validloss -1.20319±0.00000  bestvalidloss -1.20319  last_update 0\n",
      "train: iter 122  trainloss -1.32760  validloss -1.13255±0.00000  bestvalidloss -1.20319  last_update 1\n",
      "train: iter 123  trainloss -1.38997  validloss -1.16903±0.00000  bestvalidloss -1.20319  last_update 2\n",
      "train: iter 124  trainloss -1.39250  validloss -1.22185±0.00000  bestvalidloss -1.22185  last_update 0\n",
      "train: iter 125  trainloss -1.41909  validloss -1.18758±0.00000  bestvalidloss -1.22185  last_update 1\n",
      "train: iter 126  trainloss -1.42830  validloss -1.22464±0.00000  bestvalidloss -1.22464  last_update 0\n",
      "train: iter 127  trainloss -1.46568  validloss -1.28100±0.00000  bestvalidloss -1.28100  last_update 0\n",
      "train: iter 128  trainloss -1.46528  validloss -1.36834±0.00000  bestvalidloss -1.36834  last_update 0\n",
      "train: iter 129  trainloss -1.52094  validloss -1.38350±0.00000  bestvalidloss -1.38350  last_update 0\n",
      "train: iter 130  trainloss -1.53393  validloss -1.34623±0.00000  bestvalidloss -1.38350  last_update 1\n",
      "train: iter 131  trainloss -1.55298  validloss -1.33979±0.00000  bestvalidloss -1.38350  last_update 2\n",
      "train: iter 132  trainloss -1.56313  validloss -1.34632±0.00000  bestvalidloss -1.38350  last_update 3\n",
      "train: iter 133  trainloss -1.58886  validloss -1.34713±0.00000  bestvalidloss -1.38350  last_update 4\n",
      "train: iter 134  trainloss -1.60158  validloss -1.45211±0.00000  bestvalidloss -1.45211  last_update 0\n",
      "train: iter 135  trainloss -1.62961  validloss -1.43188±0.00000  bestvalidloss -1.45211  last_update 1\n",
      "train: iter 136  trainloss -1.63719  validloss -1.47941±0.00000  bestvalidloss -1.47941  last_update 0\n",
      "train: iter 137  trainloss -1.60936  validloss -1.38959±0.00000  bestvalidloss -1.47941  last_update 1\n",
      "train: iter 138  trainloss -1.63037  validloss -1.46583±0.00000  bestvalidloss -1.47941  last_update 2\n",
      "train: iter 139  trainloss -1.64192  validloss -1.36631±0.00000  bestvalidloss -1.47941  last_update 3\n",
      "train: iter 140  trainloss -1.70879  validloss -1.48986±0.00000  bestvalidloss -1.48986  last_update 0\n",
      "train: iter 141  trainloss -1.68534  validloss -1.40535±0.00000  bestvalidloss -1.48986  last_update 1\n",
      "train: iter 142  trainloss -1.68924  validloss -1.55528±0.00000  bestvalidloss -1.55528  last_update 0\n",
      "train: iter 143  trainloss -1.70715  validloss -1.49251±0.00000  bestvalidloss -1.55528  last_update 1\n",
      "train: iter 144  trainloss -1.67234  validloss -1.56450±0.00000  bestvalidloss -1.56450  last_update 0\n",
      "train: iter 145  trainloss -1.68282  validloss -1.61021±0.00000  bestvalidloss -1.61021  last_update 0\n",
      "train: iter 146  trainloss -1.67653  validloss -1.50051±0.00000  bestvalidloss -1.61021  last_update 1\n",
      "train: iter 147  trainloss -1.70952  validloss -1.48474±0.00000  bestvalidloss -1.61021  last_update 2\n",
      "train: iter 148  trainloss -1.71538  validloss -1.50843±0.00000  bestvalidloss -1.61021  last_update 3\n",
      "train: iter 149  trainloss -1.70278  validloss -1.48849±0.00000  bestvalidloss -1.61021  last_update 4\n",
      "train: iter 150  trainloss -1.72536  validloss -1.57697±0.00000  bestvalidloss -1.61021  last_update 5\n",
      "train: iter 151  trainloss -1.72168  validloss -1.52350±0.00000  bestvalidloss -1.61021  last_update 6\n",
      "train: iter 152  trainloss -1.69999  validloss -1.58232±0.00000  bestvalidloss -1.61021  last_update 7\n",
      "train: iter 153  trainloss -1.75895  validloss -1.58092±0.00000  bestvalidloss -1.61021  last_update 8\n",
      "train: iter 154  trainloss -1.68781  validloss -1.53866±0.00000  bestvalidloss -1.61021  last_update 9\n",
      "train: iter 155  trainloss -1.72342  validloss -1.53832±0.00000  bestvalidloss -1.61021  last_update 10\n",
      "train: iter 156  trainloss -1.69670  validloss -1.55001±0.00000  bestvalidloss -1.61021  last_update 11\n",
      "train: iter 157  trainloss -1.76928  validloss -1.52504±0.00000  bestvalidloss -1.61021  last_update 12\n",
      "train: iter 158  trainloss -1.74033  validloss -1.52956±0.00000  bestvalidloss -1.61021  last_update 13\n",
      "train: iter 159  trainloss -1.71567  validloss -1.62741±0.00000  bestvalidloss -1.62741  last_update 0\n",
      "train: iter 160  trainloss -1.76548  validloss -1.55774±0.00000  bestvalidloss -1.62741  last_update 1\n",
      "train: iter 161  trainloss -1.77551  validloss -1.58011±0.00000  bestvalidloss -1.62741  last_update 2\n",
      "train: iter 162  trainloss -1.72527  validloss -1.61775±0.00000  bestvalidloss -1.62741  last_update 3\n",
      "train: iter 163  trainloss -1.72189  validloss -1.53675±0.00000  bestvalidloss -1.62741  last_update 4\n",
      "train: iter 164  trainloss -1.73493  validloss -1.49920±0.00000  bestvalidloss -1.62741  last_update 5\n",
      "train: iter 165  trainloss -1.72075  validloss -1.57830±0.00000  bestvalidloss -1.62741  last_update 6\n",
      "train: iter 166  trainloss -1.74567  validloss -1.46305±0.00000  bestvalidloss -1.62741  last_update 7\n",
      "train: iter 167  trainloss -1.74582  validloss -1.52770±0.00000  bestvalidloss -1.62741  last_update 8\n",
      "train: iter 168  trainloss -1.70598  validloss -1.59996±0.00000  bestvalidloss -1.62741  last_update 9\n",
      "train: iter 169  trainloss -1.72245  validloss -1.53776±0.00000  bestvalidloss -1.62741  last_update 10\n",
      "train: iter 170  trainloss -1.72860  validloss -1.47280±0.00000  bestvalidloss -1.62741  last_update 11\n",
      "train: iter 171  trainloss -1.75015  validloss -1.52138±0.00000  bestvalidloss -1.62741  last_update 12\n",
      "train: iter 172  trainloss -1.71702  validloss -1.56981±0.00000  bestvalidloss -1.62741  last_update 13\n",
      "train: iter 173  trainloss -1.78470  validloss -1.52726±0.00000  bestvalidloss -1.62741  last_update 14\n",
      "train: iter 174  trainloss -1.76726  validloss -1.53742±0.00000  bestvalidloss -1.62741  last_update 15\n",
      "train: iter 175  trainloss -1.74042  validloss -1.66216±0.00000  bestvalidloss -1.66216  last_update 0\n",
      "train: iter 176  trainloss -1.76288  validloss -1.60494±0.00000  bestvalidloss -1.66216  last_update 1\n",
      "train: iter 177  trainloss -1.76475  validloss -1.56131±0.00000  bestvalidloss -1.66216  last_update 2\n",
      "train: iter 178  trainloss -1.73074  validloss -1.54344±0.00000  bestvalidloss -1.66216  last_update 3\n",
      "train: iter 179  trainloss -1.70985  validloss -1.63583±0.00000  bestvalidloss -1.66216  last_update 4\n",
      "train: iter 180  trainloss -1.76111  validloss -1.56764±0.00000  bestvalidloss -1.66216  last_update 5\n",
      "train: iter 181  trainloss -1.72212  validloss -1.50442±0.00000  bestvalidloss -1.66216  last_update 6\n",
      "train: iter 182  trainloss -1.76211  validloss -1.47715±0.00000  bestvalidloss -1.66216  last_update 7\n",
      "train: iter 183  trainloss -1.74913  validloss -1.64495±0.00000  bestvalidloss -1.66216  last_update 8\n",
      "train: iter 184  trainloss -1.78111  validloss -1.55618±0.00000  bestvalidloss -1.66216  last_update 9\n",
      "train: iter 185  trainloss -1.74546  validloss -1.57641±0.00000  bestvalidloss -1.66216  last_update 10\n",
      "train: iter 186  trainloss -1.71327  validloss -1.53039±0.00000  bestvalidloss -1.66216  last_update 11\n",
      "train: iter 187  trainloss -1.74032  validloss -1.47855±0.00000  bestvalidloss -1.66216  last_update 12\n",
      "train: iter 188  trainloss -1.73882  validloss -1.54183±0.00000  bestvalidloss -1.66216  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 189  trainloss -1.78067  validloss -1.51595±0.00000  bestvalidloss -1.66216  last_update 14\n",
      "train: iter 190  trainloss -1.72159  validloss -1.56603±0.00000  bestvalidloss -1.66216  last_update 15\n",
      "train: iter 191  trainloss -1.71751  validloss -1.62052±0.00000  bestvalidloss -1.66216  last_update 16\n",
      "train: iter 192  trainloss -1.74704  validloss -1.55345±0.00000  bestvalidloss -1.66216  last_update 17\n",
      "train: iter 193  trainloss -1.75516  validloss -1.58554±0.00000  bestvalidloss -1.66216  last_update 18\n",
      "train: iter 194  trainloss -1.73352  validloss -1.63732±0.00000  bestvalidloss -1.66216  last_update 19\n",
      "train: iter 195  trainloss -1.73575  validloss -1.57982±0.00000  bestvalidloss -1.66216  last_update 20\n",
      "train: iter 196  trainloss -1.78210  validloss -1.52869±0.00000  bestvalidloss -1.66216  last_update 21\n",
      "train: iter 197  trainloss -1.77578  validloss -1.55771±0.00000  bestvalidloss -1.66216  last_update 22\n",
      "train: iter 198  trainloss -1.75322  validloss -1.60311±0.00000  bestvalidloss -1.66216  last_update 23\n",
      "train: iter 199  trainloss -1.74923  validloss -1.51134±0.00000  bestvalidloss -1.66216  last_update 24\n",
      "train: iter 200  trainloss -1.75256  validloss -1.59433±0.00000  bestvalidloss -1.66216  last_update 25\n",
      "train: iter 201  trainloss -1.76557  validloss -1.54537±0.00000  bestvalidloss -1.66216  last_update 26\n",
      "train: iter 202  trainloss -1.78439  validloss -1.64081±0.00000  bestvalidloss -1.66216  last_update 27\n",
      "train: iter 203  trainloss -1.74710  validloss -1.51681±0.00000  bestvalidloss -1.66216  last_update 28\n",
      "train: iter 204  trainloss -1.72532  validloss -1.62579±0.00000  bestvalidloss -1.66216  last_update 29\n",
      "train: iter 205  trainloss -1.79607  validloss -1.66572±0.00000  bestvalidloss -1.66572  last_update 0\n",
      "train: iter 206  trainloss -1.79628  validloss -1.61646±0.00000  bestvalidloss -1.66572  last_update 1\n",
      "train: iter 207  trainloss -1.74615  validloss -1.64934±0.00000  bestvalidloss -1.66572  last_update 2\n",
      "train: iter 208  trainloss -1.76287  validloss -1.57781±0.00000  bestvalidloss -1.66572  last_update 3\n",
      "train: iter 209  trainloss -1.76281  validloss -1.51723±0.00000  bestvalidloss -1.66572  last_update 4\n",
      "train: iter 210  trainloss -1.75260  validloss -1.49283±0.00000  bestvalidloss -1.66572  last_update 5\n",
      "train: iter 211  trainloss -1.78743  validloss -1.62418±0.00000  bestvalidloss -1.66572  last_update 6\n",
      "train: iter 212  trainloss -1.75933  validloss -1.60240±0.00000  bestvalidloss -1.66572  last_update 7\n",
      "train: iter 213  trainloss -1.72992  validloss -1.60032±0.00000  bestvalidloss -1.66572  last_update 8\n",
      "train: iter 214  trainloss -1.72041  validloss -1.59573±0.00000  bestvalidloss -1.66572  last_update 9\n",
      "train: iter 215  trainloss -1.75728  validloss -1.52816±0.00000  bestvalidloss -1.66572  last_update 10\n",
      "train: iter 216  trainloss -1.70314  validloss -1.55033±0.00000  bestvalidloss -1.66572  last_update 11\n",
      "train: iter 217  trainloss -1.79356  validloss -1.56404±0.00000  bestvalidloss -1.66572  last_update 12\n",
      "train: iter 218  trainloss -1.75151  validloss -1.54841±0.00000  bestvalidloss -1.66572  last_update 13\n",
      "train: iter 219  trainloss -1.75434  validloss -1.52754±0.00000  bestvalidloss -1.66572  last_update 14\n",
      "train: iter 220  trainloss -1.75433  validloss -1.61645±0.00000  bestvalidloss -1.66572  last_update 15\n",
      "train: iter 221  trainloss -1.69421  validloss -1.63181±0.00000  bestvalidloss -1.66572  last_update 16\n",
      "train: iter 222  trainloss -1.73283  validloss -1.51157±0.00000  bestvalidloss -1.66572  last_update 17\n",
      "train: iter 223  trainloss -1.74806  validloss -1.64760±0.00000  bestvalidloss -1.66572  last_update 18\n",
      "train: iter 224  trainloss -1.76877  validloss -1.65487±0.00000  bestvalidloss -1.66572  last_update 19\n",
      "train: iter 225  trainloss -1.70934  validloss -1.55109±0.00000  bestvalidloss -1.66572  last_update 20\n",
      "train: iter 226  trainloss -1.76837  validloss -1.58013±0.00000  bestvalidloss -1.66572  last_update 21\n",
      "train: iter 227  trainloss -1.79161  validloss -1.44086±0.00000  bestvalidloss -1.66572  last_update 22\n",
      "train: iter 228  trainloss -1.79297  validloss -1.50138±0.00000  bestvalidloss -1.66572  last_update 23\n",
      "train: iter 229  trainloss -1.73868  validloss -1.66689±0.00000  bestvalidloss -1.66689  last_update 0\n",
      "train: iter 230  trainloss -1.74498  validloss -1.61444±0.00000  bestvalidloss -1.66689  last_update 1\n",
      "train: iter 231  trainloss -1.76252  validloss -1.63031±0.00000  bestvalidloss -1.66689  last_update 2\n",
      "train: iter 232  trainloss -1.73228  validloss -1.63570±0.00000  bestvalidloss -1.66689  last_update 3\n",
      "train: iter 233  trainloss -1.72017  validloss -1.51704±0.00000  bestvalidloss -1.66689  last_update 4\n",
      "train: iter 234  trainloss -1.74455  validloss -1.53305±0.00000  bestvalidloss -1.66689  last_update 5\n",
      "train: iter 235  trainloss -1.77058  validloss -1.69370±0.00000  bestvalidloss -1.69370  last_update 0\n",
      "train: iter 236  trainloss -1.66364  validloss -1.60355±0.00000  bestvalidloss -1.69370  last_update 1\n",
      "train: iter 237  trainloss -1.71947  validloss -1.55708±0.00000  bestvalidloss -1.69370  last_update 2\n",
      "train: iter 238  trainloss -1.75367  validloss -1.51382±0.00000  bestvalidloss -1.69370  last_update 3\n",
      "train: iter 239  trainloss -1.69923  validloss -1.69364±0.00000  bestvalidloss -1.69370  last_update 4\n",
      "train: iter 240  trainloss -1.75067  validloss -1.71311±0.00000  bestvalidloss -1.71311  last_update 0\n",
      "train: iter 241  trainloss -1.76710  validloss -1.52319±0.00000  bestvalidloss -1.71311  last_update 1\n",
      "train: iter 242  trainloss -1.74768  validloss -1.60131±0.00000  bestvalidloss -1.71311  last_update 2\n",
      "train: iter 243  trainloss -1.71241  validloss -1.71429±0.00000  bestvalidloss -1.71429  last_update 0\n",
      "train: iter 244  trainloss -1.74727  validloss -1.67546±0.00000  bestvalidloss -1.71429  last_update 1\n",
      "train: iter 245  trainloss -1.80528  validloss -1.57038±0.00000  bestvalidloss -1.71429  last_update 2\n",
      "train: iter 246  trainloss -1.76980  validloss -1.59299±0.00000  bestvalidloss -1.71429  last_update 3\n",
      "train: iter 247  trainloss -1.77328  validloss -1.61893±0.00000  bestvalidloss -1.71429  last_update 4\n",
      "train: iter 248  trainloss -1.76926  validloss -1.62583±0.00000  bestvalidloss -1.71429  last_update 5\n",
      "train: iter 249  trainloss -1.75997  validloss -1.69720±0.00000  bestvalidloss -1.71429  last_update 6\n",
      "train: iter 250  trainloss -1.72664  validloss -1.52071±0.00000  bestvalidloss -1.71429  last_update 7\n",
      "train: iter 251  trainloss -1.78774  validloss -1.52257±0.00000  bestvalidloss -1.71429  last_update 8\n",
      "train: iter 252  trainloss -1.75231  validloss -1.61200±0.00000  bestvalidloss -1.71429  last_update 9\n",
      "train: iter 253  trainloss -1.77382  validloss -1.46833±0.00000  bestvalidloss -1.71429  last_update 10\n",
      "train: iter 254  trainloss -1.75386  validloss -1.55391±0.00000  bestvalidloss -1.71429  last_update 11\n",
      "train: iter 255  trainloss -1.83535  validloss -1.61625±0.00000  bestvalidloss -1.71429  last_update 12\n",
      "train: iter 256  trainloss -1.74584  validloss -1.63184±0.00000  bestvalidloss -1.71429  last_update 13\n",
      "train: iter 257  trainloss -1.74900  validloss -1.55861±0.00000  bestvalidloss -1.71429  last_update 14\n",
      "train: iter 258  trainloss -1.75418  validloss -1.50676±0.00000  bestvalidloss -1.71429  last_update 15\n",
      "train: iter 259  trainloss -1.75238  validloss -1.52755±0.00000  bestvalidloss -1.71429  last_update 16\n",
      "train: iter 260  trainloss -1.75225  validloss -1.63647±0.00000  bestvalidloss -1.71429  last_update 17\n",
      "train: iter 261  trainloss -1.77828  validloss -1.53012±0.00000  bestvalidloss -1.71429  last_update 18\n",
      "train: iter 262  trainloss -1.78523  validloss -1.58224±0.00000  bestvalidloss -1.71429  last_update 19\n",
      "train: iter 263  trainloss -1.79914  validloss -1.56564±0.00000  bestvalidloss -1.71429  last_update 20\n",
      "train: iter 264  trainloss -1.71685  validloss -1.61016±0.00000  bestvalidloss -1.71429  last_update 21\n",
      "train: iter 265  trainloss -1.77329  validloss -1.44565±0.00000  bestvalidloss -1.71429  last_update 22\n",
      "train: iter 266  trainloss -1.73697  validloss -1.56816±0.00000  bestvalidloss -1.71429  last_update 23\n",
      "train: iter 267  trainloss -1.74716  validloss -1.62123±0.00000  bestvalidloss -1.71429  last_update 24\n",
      "train: iter 268  trainloss -1.78803  validloss -1.50816±0.00000  bestvalidloss -1.71429  last_update 25\n",
      "train: iter 269  trainloss -1.79668  validloss -1.67769±0.00000  bestvalidloss -1.71429  last_update 26\n",
      "train: iter 270  trainloss -1.78260  validloss -1.60921±0.00000  bestvalidloss -1.71429  last_update 27\n",
      "train: iter 271  trainloss -1.77095  validloss -1.63662±0.00000  bestvalidloss -1.71429  last_update 28\n",
      "train: iter 272  trainloss -1.76525  validloss -1.54890±0.00000  bestvalidloss -1.71429  last_update 29\n",
      "train: iter 273  trainloss -1.76554  validloss -1.64241±0.00000  bestvalidloss -1.71429  last_update 30\n",
      "train: iter 274  trainloss -1.78577  validloss -1.61867±0.00000  bestvalidloss -1.71429  last_update 31\n",
      "train: iter 275  trainloss -1.76608  validloss -1.51837±0.00000  bestvalidloss -1.71429  last_update 32\n",
      "train: iter 276  trainloss -1.74914  validloss -1.64074±0.00000  bestvalidloss -1.71429  last_update 33\n",
      "train: iter 277  trainloss -1.75480  validloss -1.65615±0.00000  bestvalidloss -1.71429  last_update 34\n",
      "train: iter 278  trainloss -1.72547  validloss -1.56055±0.00000  bestvalidloss -1.71429  last_update 35\n",
      "train: iter 279  trainloss -1.80012  validloss -1.59834±0.00000  bestvalidloss -1.71429  last_update 36\n",
      "train: iter 280  trainloss -1.77283  validloss -1.45309±0.00000  bestvalidloss -1.71429  last_update 37\n",
      "train: iter 281  trainloss -1.72420  validloss -1.59299±0.00000  bestvalidloss -1.71429  last_update 38\n",
      "train: iter 282  trainloss -1.71592  validloss -1.61006±0.00000  bestvalidloss -1.71429  last_update 39\n",
      "train: iter 283  trainloss -1.75408  validloss -1.53257±0.00000  bestvalidloss -1.71429  last_update 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 284  trainloss -1.77424  validloss -1.65067±0.00000  bestvalidloss -1.71429  last_update 41\n",
      "train: iter 285  trainloss -1.75642  validloss -1.62075±0.00000  bestvalidloss -1.71429  last_update 42\n",
      "train: iter 286  trainloss -1.69966  validloss -1.47154±0.00000  bestvalidloss -1.71429  last_update 43\n",
      "train: iter 287  trainloss -1.75257  validloss -1.53253±0.00000  bestvalidloss -1.71429  last_update 44\n",
      "train: iter 288  trainloss -1.77497  validloss -1.57125±0.00000  bestvalidloss -1.71429  last_update 45\n",
      "train: iter 289  trainloss -1.82199  validloss -1.68358±0.00000  bestvalidloss -1.71429  last_update 46\n",
      "train: iter 290  trainloss -1.82356  validloss -1.67484±0.00000  bestvalidloss -1.71429  last_update 47\n",
      "train: iter 291  trainloss -1.76834  validloss -1.57392±0.00000  bestvalidloss -1.71429  last_update 48\n",
      "train: iter 292  trainloss -1.69518  validloss -1.63610±0.00000  bestvalidloss -1.71429  last_update 49\n",
      "train: iter 293  trainloss -1.76827  validloss -1.60726±0.00000  bestvalidloss -1.71429  last_update 50\n",
      "train: iter 294  trainloss -1.71681  validloss -1.52659±0.00000  bestvalidloss -1.71429  last_update 51\n",
      "train: iter 295  trainloss -1.80406  validloss -1.58187±0.00000  bestvalidloss -1.71429  last_update 52\n",
      "train: iter 296  trainloss -1.71454  validloss -1.50908±0.00000  bestvalidloss -1.71429  last_update 53\n",
      "train: iter 297  trainloss -1.79517  validloss -1.52407±0.00000  bestvalidloss -1.71429  last_update 54\n",
      "train: iter 298  trainloss -1.79745  validloss -1.60785±0.00000  bestvalidloss -1.71429  last_update 55\n",
      "train: iter 299  trainloss -1.77480  validloss -1.62101±0.00000  bestvalidloss -1.71429  last_update 56\n",
      "train: iter 300  trainloss -1.79743  validloss -1.54227±0.00000  bestvalidloss -1.71429  last_update 57\n",
      "train: iter 301  trainloss -1.72218  validloss -1.48802±0.00000  bestvalidloss -1.71429  last_update 58\n",
      "train: iter 302  trainloss -1.74501  validloss -1.49166±0.00000  bestvalidloss -1.71429  last_update 59\n",
      "train: iter 303  trainloss -1.75753  validloss -1.51622±0.00000  bestvalidloss -1.71429  last_update 60\n",
      "train: iter 304  trainloss -1.76112  validloss -1.66599±0.00000  bestvalidloss -1.71429  last_update 61\n",
      "train: iter 305  trainloss -1.75006  validloss -1.50558±0.00000  bestvalidloss -1.71429  last_update 62\n",
      "train: iter 306  trainloss -1.77592  validloss -1.60062±0.00000  bestvalidloss -1.71429  last_update 63\n",
      "train: iter 307  trainloss -1.80986  validloss -1.59461±0.00000  bestvalidloss -1.71429  last_update 64\n",
      "train: iter 308  trainloss -1.76791  validloss -1.62355±0.00000  bestvalidloss -1.71429  last_update 65\n",
      "train: iter 309  trainloss -1.78392  validloss -1.66969±0.00000  bestvalidloss -1.71429  last_update 66\n",
      "train: iter 310  trainloss -1.75933  validloss -1.65682±0.00000  bestvalidloss -1.71429  last_update 67\n",
      "train: iter 311  trainloss -1.73148  validloss -1.64009±0.00000  bestvalidloss -1.71429  last_update 68\n",
      "train: iter 312  trainloss -1.74701  validloss -1.52597±0.00000  bestvalidloss -1.71429  last_update 69\n",
      "train: iter 313  trainloss -1.76054  validloss -1.54397±0.00000  bestvalidloss -1.71429  last_update 70\n",
      "train: iter 314  trainloss -1.76406  validloss -1.65589±0.00000  bestvalidloss -1.71429  last_update 71\n",
      "train: iter 315  trainloss -1.81258  validloss -1.61890±0.00000  bestvalidloss -1.71429  last_update 72\n",
      "train: iter 316  trainloss -1.69668  validloss -1.50134±0.00000  bestvalidloss -1.71429  last_update 73\n",
      "train: iter 317  trainloss -1.76766  validloss -1.62469±0.00000  bestvalidloss -1.71429  last_update 74\n",
      "train: iter 318  trainloss -1.73337  validloss -1.55210±0.00000  bestvalidloss -1.71429  last_update 75\n",
      "train: iter 319  trainloss -1.74648  validloss -1.73185±0.00000  bestvalidloss -1.73185  last_update 0\n",
      "train: iter 320  trainloss -1.79212  validloss -1.58611±0.00000  bestvalidloss -1.73185  last_update 1\n",
      "train: iter 321  trainloss -1.67431  validloss -1.54219±0.00000  bestvalidloss -1.73185  last_update 2\n",
      "train: iter 322  trainloss -1.74848  validloss -1.51469±0.00000  bestvalidloss -1.73185  last_update 3\n",
      "train: iter 323  trainloss -1.72280  validloss -1.56192±0.00000  bestvalidloss -1.73185  last_update 4\n",
      "train: iter 324  trainloss -1.69589  validloss -1.52644±0.00000  bestvalidloss -1.73185  last_update 5\n",
      "train: iter 325  trainloss -1.72915  validloss -1.54907±0.00000  bestvalidloss -1.73185  last_update 6\n",
      "train: iter 326  trainloss -1.72054  validloss -1.63443±0.00000  bestvalidloss -1.73185  last_update 7\n",
      "train: iter 327  trainloss -1.71918  validloss -1.57279±0.00000  bestvalidloss -1.73185  last_update 8\n",
      "train: iter 328  trainloss -1.76845  validloss -1.48972±0.00000  bestvalidloss -1.73185  last_update 9\n",
      "train: iter 329  trainloss -1.73226  validloss -1.56183±0.00000  bestvalidloss -1.73185  last_update 10\n",
      "train: iter 330  trainloss -1.79343  validloss -1.59549±0.00000  bestvalidloss -1.73185  last_update 11\n",
      "train: iter 331  trainloss -1.78877  validloss -1.59376±0.00000  bestvalidloss -1.73185  last_update 12\n",
      "train: iter 332  trainloss -1.78439  validloss -1.65408±0.00000  bestvalidloss -1.73185  last_update 13\n",
      "train: iter 333  trainloss -1.73401  validloss -1.55169±0.00000  bestvalidloss -1.73185  last_update 14\n",
      "train: iter 334  trainloss -1.74962  validloss -1.62247±0.00000  bestvalidloss -1.73185  last_update 15\n",
      "train: iter 335  trainloss -1.79001  validloss -1.55469±0.00000  bestvalidloss -1.73185  last_update 16\n",
      "train: iter 336  trainloss -1.79947  validloss -1.49038±0.00000  bestvalidloss -1.73185  last_update 17\n",
      "train: iter 337  trainloss -1.72891  validloss -1.57246±0.00000  bestvalidloss -1.73185  last_update 18\n",
      "train: iter 338  trainloss -1.71936  validloss -1.57005±0.00000  bestvalidloss -1.73185  last_update 19\n",
      "train: iter 339  trainloss -1.73917  validloss -1.59980±0.00000  bestvalidloss -1.73185  last_update 20\n",
      "train: iter 340  trainloss -1.77311  validloss -1.41930±0.00000  bestvalidloss -1.73185  last_update 21\n",
      "train: iter 341  trainloss -1.75694  validloss -1.58458±0.00000  bestvalidloss -1.73185  last_update 22\n",
      "train: iter 342  trainloss -1.75854  validloss -1.60420±0.00000  bestvalidloss -1.73185  last_update 23\n",
      "train: iter 343  trainloss -1.72474  validloss -1.55346±0.00000  bestvalidloss -1.73185  last_update 24\n",
      "train: iter 344  trainloss -1.79534  validloss -1.50000±0.00000  bestvalidloss -1.73185  last_update 25\n",
      "train: iter 345  trainloss -1.71895  validloss -1.56932±0.00000  bestvalidloss -1.73185  last_update 26\n",
      "train: iter 346  trainloss -1.77938  validloss -1.52016±0.00000  bestvalidloss -1.73185  last_update 27\n",
      "train: iter 347  trainloss -1.75476  validloss -1.45647±0.00000  bestvalidloss -1.73185  last_update 28\n",
      "train: iter 348  trainloss -1.80169  validloss -1.58349±0.00000  bestvalidloss -1.73185  last_update 29\n",
      "train: iter 349  trainloss -1.75448  validloss -1.59002±0.00000  bestvalidloss -1.73185  last_update 30\n",
      "train: iter 350  trainloss -1.75711  validloss -1.66502±0.00000  bestvalidloss -1.73185  last_update 31\n",
      "train: iter 351  trainloss -1.74790  validloss -1.61785±0.00000  bestvalidloss -1.73185  last_update 32\n",
      "train: iter 352  trainloss -1.73631  validloss -1.43851±0.00000  bestvalidloss -1.73185  last_update 33\n",
      "train: iter 353  trainloss -1.80833  validloss -1.59887±0.00000  bestvalidloss -1.73185  last_update 34\n",
      "train: iter 354  trainloss -1.75372  validloss -1.52316±0.00000  bestvalidloss -1.73185  last_update 35\n",
      "train: iter 355  trainloss -1.75403  validloss -1.53661±0.00000  bestvalidloss -1.73185  last_update 36\n",
      "train: iter 356  trainloss -1.72523  validloss -1.66079±0.00000  bestvalidloss -1.73185  last_update 37\n",
      "train: iter 357  trainloss -1.70439  validloss -1.61731±0.00000  bestvalidloss -1.73185  last_update 38\n",
      "train: iter 358  trainloss -1.80186  validloss -1.54201±0.00000  bestvalidloss -1.73185  last_update 39\n",
      "train: iter 359  trainloss -1.74328  validloss -1.68987±0.00000  bestvalidloss -1.73185  last_update 40\n",
      "train: iter 360  trainloss -1.69842  validloss -1.50187±0.00000  bestvalidloss -1.73185  last_update 41\n",
      "train: iter 361  trainloss -1.73038  validloss -1.55276±0.00000  bestvalidloss -1.73185  last_update 42\n",
      "train: iter 362  trainloss -1.73079  validloss -1.55905±0.00000  bestvalidloss -1.73185  last_update 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 363  trainloss -1.72520  validloss -1.51014±0.00000  bestvalidloss -1.73185  last_update 44\n",
      "train: iter 364  trainloss -1.70067  validloss -1.53959±0.00000  bestvalidloss -1.73185  last_update 45\n",
      "train: iter 365  trainloss -1.70975  validloss -1.74375±0.00000  bestvalidloss -1.74375  last_update 0\n",
      "train: iter 366  trainloss -1.70345  validloss -1.53769±0.00000  bestvalidloss -1.74375  last_update 1\n",
      "train: iter 367  trainloss -1.77156  validloss -1.44371±0.00000  bestvalidloss -1.74375  last_update 2\n",
      "train: iter 368  trainloss -1.76231  validloss -1.52308±0.00000  bestvalidloss -1.74375  last_update 3\n",
      "train: iter 369  trainloss -1.74945  validloss -1.56791±0.00000  bestvalidloss -1.74375  last_update 4\n",
      "train: iter 370  trainloss -1.71906  validloss -1.56510±0.00000  bestvalidloss -1.74375  last_update 5\n",
      "train: iter 371  trainloss -1.80512  validloss -1.49650±0.00000  bestvalidloss -1.74375  last_update 6\n",
      "train: iter 372  trainloss -1.77402  validloss -1.65328±0.00000  bestvalidloss -1.74375  last_update 7\n",
      "train: iter 373  trainloss -1.76147  validloss -1.51557±0.00000  bestvalidloss -1.74375  last_update 8\n",
      "train: iter 374  trainloss -1.72198  validloss -1.51043±0.00000  bestvalidloss -1.74375  last_update 9\n",
      "train: iter 375  trainloss -1.77273  validloss -1.53893±0.00000  bestvalidloss -1.74375  last_update 10\n",
      "train: iter 376  trainloss -1.77939  validloss -1.49396±0.00000  bestvalidloss -1.74375  last_update 11\n",
      "train: iter 377  trainloss -1.75668  validloss -1.59027±0.00000  bestvalidloss -1.74375  last_update 12\n",
      "train: iter 378  trainloss -1.73482  validloss -1.52057±0.00000  bestvalidloss -1.74375  last_update 13\n",
      "train: iter 379  trainloss -1.73937  validloss -1.60469±0.00000  bestvalidloss -1.74375  last_update 14\n",
      "train: iter 380  trainloss -1.73692  validloss -1.61160±0.00000  bestvalidloss -1.74375  last_update 15\n",
      "train: iter 381  trainloss -1.72900  validloss -1.61246±0.00000  bestvalidloss -1.74375  last_update 16\n",
      "train: iter 382  trainloss -1.76065  validloss -1.68145±0.00000  bestvalidloss -1.74375  last_update 17\n",
      "train: iter 383  trainloss -1.73683  validloss -1.56408±0.00000  bestvalidloss -1.74375  last_update 18\n",
      "train: iter 384  trainloss -1.74471  validloss -1.65067±0.00000  bestvalidloss -1.74375  last_update 19\n",
      "train: iter 385  trainloss -1.77044  validloss -1.57822±0.00000  bestvalidloss -1.74375  last_update 20\n",
      "train: iter 386  trainloss -1.81979  validloss -1.63012±0.00000  bestvalidloss -1.74375  last_update 21\n",
      "train: iter 387  trainloss -1.74365  validloss -1.59874±0.00000  bestvalidloss -1.74375  last_update 22\n",
      "train: iter 388  trainloss -1.76096  validloss -1.31767±0.00000  bestvalidloss -1.74375  last_update 23\n",
      "train: iter 389  trainloss -1.77290  validloss -1.66823±0.00000  bestvalidloss -1.74375  last_update 24\n",
      "train: iter 390  trainloss -1.74788  validloss -1.61230±0.00000  bestvalidloss -1.74375  last_update 25\n",
      "train: iter 391  trainloss -1.70728  validloss -1.63394±0.00000  bestvalidloss -1.74375  last_update 26\n",
      "train: iter 392  trainloss -1.72440  validloss -1.52254±0.00000  bestvalidloss -1.74375  last_update 27\n",
      "train: iter 393  trainloss -1.74095  validloss -1.63913±0.00000  bestvalidloss -1.74375  last_update 28\n",
      "train: iter 394  trainloss -1.78783  validloss -1.59399±0.00000  bestvalidloss -1.74375  last_update 29\n",
      "train: iter 395  trainloss -1.79002  validloss -1.59513±0.00000  bestvalidloss -1.74375  last_update 30\n",
      "train: iter 396  trainloss -1.74923  validloss -1.73986±0.00000  bestvalidloss -1.74375  last_update 31\n",
      "train: iter 397  trainloss -1.74735  validloss -1.48649±0.00000  bestvalidloss -1.74375  last_update 32\n",
      "train: iter 398  trainloss -1.83688  validloss -1.55612±0.00000  bestvalidloss -1.74375  last_update 33\n",
      "train: iter 399  trainloss -1.71520  validloss -1.60988±0.00000  bestvalidloss -1.74375  last_update 34\n",
      "train: iter 400  trainloss -1.78900  validloss -1.66180±0.00000  bestvalidloss -1.74375  last_update 35\n",
      "train: iter 401  trainloss -1.80528  validloss -1.56497±0.00000  bestvalidloss -1.74375  last_update 36\n",
      "train: iter 402  trainloss -1.78588  validloss -1.56642±0.00000  bestvalidloss -1.74375  last_update 37\n",
      "train: iter 403  trainloss -1.80447  validloss -1.59901±0.00000  bestvalidloss -1.74375  last_update 38\n",
      "train: iter 404  trainloss -1.74328  validloss -1.65208±0.00000  bestvalidloss -1.74375  last_update 39\n",
      "train: iter 405  trainloss -1.75376  validloss -1.59836±0.00000  bestvalidloss -1.74375  last_update 40\n",
      "train: iter 406  trainloss -1.74037  validloss -1.55189±0.00000  bestvalidloss -1.74375  last_update 41\n",
      "train: iter 407  trainloss -1.72084  validloss -1.56154±0.00000  bestvalidloss -1.74375  last_update 42\n",
      "train: iter 408  trainloss -1.75431  validloss -1.60502±0.00000  bestvalidloss -1.74375  last_update 43\n",
      "train: iter 409  trainloss -1.79257  validloss -1.47396±0.00000  bestvalidloss -1.74375  last_update 44\n",
      "train: iter 410  trainloss -1.74563  validloss -1.51394±0.00000  bestvalidloss -1.74375  last_update 45\n",
      "train: iter 411  trainloss -1.76377  validloss -1.63479±0.00000  bestvalidloss -1.74375  last_update 46\n",
      "train: iter 412  trainloss -1.76292  validloss -1.71671±0.00000  bestvalidloss -1.74375  last_update 47\n",
      "train: iter 413  trainloss -1.73676  validloss -1.52265±0.00000  bestvalidloss -1.74375  last_update 48\n",
      "train: iter 414  trainloss -1.79950  validloss -1.70788±0.00000  bestvalidloss -1.74375  last_update 49\n",
      "train: iter 415  trainloss -1.75919  validloss -1.54104±0.00000  bestvalidloss -1.74375  last_update 50\n",
      "train: iter 416  trainloss -1.76790  validloss -1.57655±0.00000  bestvalidloss -1.74375  last_update 51\n",
      "train: iter 417  trainloss -1.79661  validloss -1.56968±0.00000  bestvalidloss -1.74375  last_update 52\n",
      "train: iter 418  trainloss -1.74319  validloss -1.69339±0.00000  bestvalidloss -1.74375  last_update 53\n",
      "train: iter 419  trainloss -1.76244  validloss -1.57915±0.00000  bestvalidloss -1.74375  last_update 54\n",
      "train: iter 420  trainloss -1.75907  validloss -1.62614±0.00000  bestvalidloss -1.74375  last_update 55\n",
      "train: iter 421  trainloss -1.68602  validloss -1.66413±0.00000  bestvalidloss -1.74375  last_update 56\n",
      "train: iter 422  trainloss -1.79905  validloss -1.63911±0.00000  bestvalidloss -1.74375  last_update 57\n",
      "train: iter 423  trainloss -1.74172  validloss -1.48571±0.00000  bestvalidloss -1.74375  last_update 58\n",
      "train: iter 424  trainloss -1.80204  validloss -1.61156±0.00000  bestvalidloss -1.74375  last_update 59\n",
      "train: iter 425  trainloss -1.69039  validloss -1.58117±0.00000  bestvalidloss -1.74375  last_update 60\n",
      "train: iter 426  trainloss -1.79306  validloss -1.60977±0.00000  bestvalidloss -1.74375  last_update 61\n",
      "train: iter 427  trainloss -1.74098  validloss -1.61428±0.00000  bestvalidloss -1.74375  last_update 62\n",
      "train: iter 428  trainloss -1.73200  validloss -1.57465±0.00000  bestvalidloss -1.74375  last_update 63\n",
      "train: iter 429  trainloss -1.74279  validloss -1.59567±0.00000  bestvalidloss -1.74375  last_update 64\n",
      "train: iter 430  trainloss -1.78221  validloss -1.63403±0.00000  bestvalidloss -1.74375  last_update 65\n",
      "train: iter 431  trainloss -1.71064  validloss -1.60321±0.00000  bestvalidloss -1.74375  last_update 66\n",
      "train: iter 432  trainloss -1.78045  validloss -1.65500±0.00000  bestvalidloss -1.74375  last_update 67\n",
      "train: iter 433  trainloss -1.76976  validloss -1.55499±0.00000  bestvalidloss -1.74375  last_update 68\n",
      "train: iter 434  trainloss -1.78740  validloss -1.55461±0.00000  bestvalidloss -1.74375  last_update 69\n",
      "train: iter 435  trainloss -1.71535  validloss -1.51243±0.00000  bestvalidloss -1.74375  last_update 70\n",
      "train: iter 436  trainloss -1.72346  validloss -1.45556±0.00000  bestvalidloss -1.74375  last_update 71\n",
      "train: iter 437  trainloss -1.79211  validloss -1.57152±0.00000  bestvalidloss -1.74375  last_update 72\n",
      "train: iter 438  trainloss -1.76554  validloss -1.57155±0.00000  bestvalidloss -1.74375  last_update 73\n",
      "train: iter 439  trainloss -1.76566  validloss -1.53677±0.00000  bestvalidloss -1.74375  last_update 74\n",
      "train: iter 440  trainloss -1.77720  validloss -1.65630±0.00000  bestvalidloss -1.74375  last_update 75\n",
      "train: iter 441  trainloss -1.79557  validloss -1.56500±0.00000  bestvalidloss -1.74375  last_update 76\n",
      "train: iter 442  trainloss -1.69464  validloss -1.52597±0.00000  bestvalidloss -1.74375  last_update 77\n",
      "train: iter 443  trainloss -1.75809  validloss -1.57427±0.00000  bestvalidloss -1.74375  last_update 78\n",
      "train: iter 444  trainloss -1.74488  validloss -1.57113±0.00000  bestvalidloss -1.74375  last_update 79\n",
      "train: iter 445  trainloss -1.71444  validloss -1.53902±0.00000  bestvalidloss -1.74375  last_update 80\n",
      "train: iter 446  trainloss -1.78869  validloss -1.58715±0.00000  bestvalidloss -1.74375  last_update 81\n",
      "train: iter 447  trainloss -1.76712  validloss -1.56700±0.00000  bestvalidloss -1.74375  last_update 82\n",
      "train: iter 448  trainloss -1.75321  validloss -1.62890±0.00000  bestvalidloss -1.74375  last_update 83\n",
      "train: iter 449  trainloss -1.75567  validloss -1.55472±0.00000  bestvalidloss -1.74375  last_update 84\n",
      "train: iter 450  trainloss -1.76640  validloss -1.51880±0.00000  bestvalidloss -1.74375  last_update 85\n",
      "train: iter 451  trainloss -1.76832  validloss -1.58748±0.00000  bestvalidloss -1.74375  last_update 86\n",
      "train: iter 452  trainloss -1.75720  validloss -1.46296±0.00000  bestvalidloss -1.74375  last_update 87\n",
      "train: iter 453  trainloss -1.70860  validloss -1.61912±0.00000  bestvalidloss -1.74375  last_update 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 454  trainloss -1.76792  validloss -1.67855±0.00000  bestvalidloss -1.74375  last_update 89\n",
      "train: iter 455  trainloss -1.83564  validloss -1.49544±0.00000  bestvalidloss -1.74375  last_update 90\n",
      "train: iter 456  trainloss -1.72753  validloss -1.52691±0.00000  bestvalidloss -1.74375  last_update 91\n",
      "train: iter 457  trainloss -1.73365  validloss -1.63344±0.00000  bestvalidloss -1.74375  last_update 92\n",
      "train: iter 458  trainloss -1.75240  validloss -1.66368±0.00000  bestvalidloss -1.74375  last_update 93\n",
      "train: iter 459  trainloss -1.76876  validloss -1.61751±0.00000  bestvalidloss -1.74375  last_update 94\n",
      "train: iter 460  trainloss -1.74290  validloss -1.61159±0.00000  bestvalidloss -1.74375  last_update 95\n",
      "train: iter 461  trainloss -1.74500  validloss -1.65246±0.00000  bestvalidloss -1.74375  last_update 96\n",
      "train: iter 462  trainloss -1.74444  validloss -1.54743±0.00000  bestvalidloss -1.74375  last_update 97\n",
      "train: iter 463  trainloss -1.72697  validloss -1.60709±0.00000  bestvalidloss -1.74375  last_update 98\n",
      "train: iter 464  trainloss -1.78721  validloss -1.57323±0.00000  bestvalidloss -1.74375  last_update 99\n",
      "train: iter 465  trainloss -1.74722  validloss -1.60079±0.00000  bestvalidloss -1.74375  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 4.1881,  1.9563, -5.0988, -4.0715], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 87.76701  validloss 89.89538±0.00000  bestvalidloss 89.89538  last_update 0\n",
      "train: iter 1  trainloss 65.70480  validloss 68.10659±0.00000  bestvalidloss 68.10659  last_update 0\n",
      "train: iter 2  trainloss 49.31558  validloss 50.30543±0.00000  bestvalidloss 50.30543  last_update 0\n",
      "train: iter 3  trainloss 38.04820  validloss 38.01680±0.00000  bestvalidloss 38.01680  last_update 0\n",
      "train: iter 4  trainloss 30.15182  validloss 29.76530±0.00000  bestvalidloss 29.76530  last_update 0\n",
      "train: iter 5  trainloss 24.10346  validloss 23.55395±0.00000  bestvalidloss 23.55395  last_update 0\n",
      "train: iter 6  trainloss 19.27410  validloss 18.93159±0.00000  bestvalidloss 18.93159  last_update 0\n",
      "train: iter 7  trainloss 15.53422  validloss 15.42753±0.00000  bestvalidloss 15.42753  last_update 0\n",
      "train: iter 8  trainloss 12.52430  validloss 12.60825±0.00000  bestvalidloss 12.60825  last_update 0\n",
      "train: iter 9  trainloss 10.14679  validloss 10.52906±0.00000  bestvalidloss 10.52906  last_update 0\n",
      "train: iter 10  trainloss 8.40706  validloss 8.90479±0.00000  bestvalidloss 8.90479  last_update 0\n",
      "train: iter 11  trainloss 6.97315  validloss 7.85682±0.00000  bestvalidloss 7.85682  last_update 0\n",
      "train: iter 12  trainloss 5.96958  validloss 6.96501±0.00000  bestvalidloss 6.96501  last_update 0\n",
      "train: iter 13  trainloss 5.19476  validloss 6.47099±0.00000  bestvalidloss 6.47099  last_update 0\n",
      "train: iter 14  trainloss 4.63603  validloss 6.10747±0.00000  bestvalidloss 6.10747  last_update 0\n",
      "train: iter 15  trainloss 4.21275  validloss 5.85862±0.00000  bestvalidloss 5.85862  last_update 0\n",
      "train: iter 16  trainloss 3.92248  validloss 5.72732±0.00000  bestvalidloss 5.72732  last_update 0\n",
      "train: iter 17  trainloss 3.67863  validloss 5.60010±0.00000  bestvalidloss 5.60010  last_update 0\n",
      "train: iter 18  trainloss 3.46218  validloss 5.53205±0.00000  bestvalidloss 5.53205  last_update 0\n",
      "train: iter 19  trainloss 3.29376  validloss 5.39606±0.00000  bestvalidloss 5.39606  last_update 0\n",
      "train: iter 20  trainloss 3.16433  validloss 5.35680±0.00000  bestvalidloss 5.35680  last_update 0\n",
      "train: iter 21  trainloss 3.05736  validloss 5.12148±0.00000  bestvalidloss 5.12148  last_update 0\n",
      "train: iter 22  trainloss 3.00135  validloss 5.13715±0.00000  bestvalidloss 5.12148  last_update 1\n",
      "train: iter 23  trainloss 2.94509  validloss 5.05207±0.00000  bestvalidloss 5.05207  last_update 0\n",
      "train: iter 24  trainloss 2.91303  validloss 5.07396±0.00000  bestvalidloss 5.05207  last_update 1\n",
      "train: iter 25  trainloss 2.90046  validloss 5.04603±0.00000  bestvalidloss 5.04603  last_update 0\n",
      "train: iter 26  trainloss 2.85305  validloss 5.02922±0.00000  bestvalidloss 5.02922  last_update 0\n",
      "train: iter 27  trainloss 2.83263  validloss 5.12127±0.00000  bestvalidloss 5.02922  last_update 1\n",
      "train: iter 28  trainloss 2.84323  validloss 5.01928±0.00000  bestvalidloss 5.01928  last_update 0\n",
      "train: iter 29  trainloss 2.81704  validloss 5.10429±0.00000  bestvalidloss 5.01928  last_update 1\n",
      "train: iter 30  trainloss 2.81259  validloss 5.04156±0.00000  bestvalidloss 5.01928  last_update 2\n",
      "train: iter 31  trainloss 2.80439  validloss 4.99449±0.00000  bestvalidloss 4.99449  last_update 0\n",
      "train: iter 32  trainloss 2.80855  validloss 4.99523±0.00000  bestvalidloss 4.99449  last_update 1\n",
      "train: iter 33  trainloss 2.78829  validloss 4.94441±0.00000  bestvalidloss 4.94441  last_update 0\n",
      "train: iter 34  trainloss 2.78247  validloss 5.08382±0.00000  bestvalidloss 4.94441  last_update 1\n",
      "train: iter 35  trainloss 2.77196  validloss 5.02722±0.00000  bestvalidloss 4.94441  last_update 2\n",
      "train: iter 36  trainloss 2.77243  validloss 5.01622±0.00000  bestvalidloss 4.94441  last_update 3\n",
      "train: iter 37  trainloss 2.76399  validloss 5.03012±0.00000  bestvalidloss 4.94441  last_update 4\n",
      "train: iter 38  trainloss 2.78969  validloss 5.03658±0.00000  bestvalidloss 4.94441  last_update 5\n",
      "train: iter 39  trainloss 2.76501  validloss 4.95926±0.00000  bestvalidloss 4.94441  last_update 6\n",
      "train: iter 40  trainloss 2.78768  validloss 5.00045±0.00000  bestvalidloss 4.94441  last_update 7\n",
      "train: iter 41  trainloss 2.74964  validloss 4.94263±0.00000  bestvalidloss 4.94263  last_update 0\n",
      "train: iter 42  trainloss 2.77037  validloss 5.02244±0.00000  bestvalidloss 4.94263  last_update 1\n",
      "train: iter 43  trainloss 2.76593  validloss 5.04963±0.00000  bestvalidloss 4.94263  last_update 2\n",
      "train: iter 44  trainloss 2.76450  validloss 5.05858±0.00000  bestvalidloss 4.94263  last_update 3\n",
      "train: iter 45  trainloss 2.74808  validloss 4.96105±0.00000  bestvalidloss 4.94263  last_update 4\n",
      "train: iter 46  trainloss 2.77460  validloss 4.95539±0.00000  bestvalidloss 4.94263  last_update 5\n",
      "train: iter 47  trainloss 2.73410  validloss 4.99353±0.00000  bestvalidloss 4.94263  last_update 6\n",
      "train: iter 48  trainloss 2.74160  validloss 4.98192±0.00000  bestvalidloss 4.94263  last_update 7\n",
      "train: iter 49  trainloss 2.74814  validloss 4.96083±0.00000  bestvalidloss 4.94263  last_update 8\n",
      "train: iter 50  trainloss 2.74235  validloss 5.02235±0.00000  bestvalidloss 4.94263  last_update 9\n",
      "train: iter 51  trainloss 2.77272  validloss 4.97468±0.00000  bestvalidloss 4.94263  last_update 10\n",
      "train: iter 52  trainloss 2.71985  validloss 4.99673±0.00000  bestvalidloss 4.94263  last_update 11\n",
      "train: iter 53  trainloss 2.74760  validloss 4.97761±0.00000  bestvalidloss 4.94263  last_update 12\n",
      "train: iter 54  trainloss 2.73258  validloss 4.96973±0.00000  bestvalidloss 4.94263  last_update 13\n",
      "train: iter 55  trainloss 2.75877  validloss 5.04047±0.00000  bestvalidloss 4.94263  last_update 14\n",
      "train: iter 56  trainloss 2.75108  validloss 4.96967±0.00000  bestvalidloss 4.94263  last_update 15\n",
      "train: iter 57  trainloss 2.73736  validloss 5.02634±0.00000  bestvalidloss 4.94263  last_update 16\n",
      "train: iter 58  trainloss 2.73276  validloss 4.99598±0.00000  bestvalidloss 4.94263  last_update 17\n",
      "train: iter 59  trainloss 2.75064  validloss 4.87251±0.00000  bestvalidloss 4.87251  last_update 0\n",
      "train: iter 60  trainloss 2.72473  validloss 4.93226±0.00000  bestvalidloss 4.87251  last_update 1\n",
      "train: iter 61  trainloss 2.74719  validloss 4.94507±0.00000  bestvalidloss 4.87251  last_update 2\n",
      "train: iter 62  trainloss 2.72856  validloss 4.91496±0.00000  bestvalidloss 4.87251  last_update 3\n",
      "train: iter 63  trainloss 2.72660  validloss 4.96692±0.00000  bestvalidloss 4.87251  last_update 4\n",
      "train: iter 64  trainloss 2.74136  validloss 5.01311±0.00000  bestvalidloss 4.87251  last_update 5\n",
      "train: iter 65  trainloss 2.74305  validloss 5.02848±0.00000  bestvalidloss 4.87251  last_update 6\n",
      "train: iter 66  trainloss 2.74111  validloss 4.99533±0.00000  bestvalidloss 4.87251  last_update 7\n",
      "train: iter 67  trainloss 2.71658  validloss 4.91770±0.00000  bestvalidloss 4.87251  last_update 8\n",
      "train: iter 68  trainloss 2.72298  validloss 4.99336±0.00000  bestvalidloss 4.87251  last_update 9\n",
      "train: iter 69  trainloss 2.72295  validloss 4.93836±0.00000  bestvalidloss 4.87251  last_update 10\n",
      "train: iter 70  trainloss 2.73003  validloss 4.95136±0.00000  bestvalidloss 4.87251  last_update 11\n",
      "train: iter 71  trainloss 2.74582  validloss 4.93914±0.00000  bestvalidloss 4.87251  last_update 12\n",
      "train: iter 72  trainloss 2.70595  validloss 5.00075±0.00000  bestvalidloss 4.87251  last_update 13\n",
      "train: iter 73  trainloss 2.72064  validloss 4.99520±0.00000  bestvalidloss 4.87251  last_update 14\n",
      "train: iter 74  trainloss 2.75111  validloss 4.91353±0.00000  bestvalidloss 4.87251  last_update 15\n",
      "train: iter 75  trainloss 2.73017  validloss 4.94391±0.00000  bestvalidloss 4.87251  last_update 16\n",
      "train: iter 76  trainloss 2.72062  validloss 4.92675±0.00000  bestvalidloss 4.87251  last_update 17\n",
      "train: iter 77  trainloss 2.71037  validloss 5.01198±0.00000  bestvalidloss 4.87251  last_update 18\n",
      "train: iter 78  trainloss 2.68548  validloss 4.92290±0.00000  bestvalidloss 4.87251  last_update 19\n",
      "train: iter 79  trainloss 2.71497  validloss 4.99512±0.00000  bestvalidloss 4.87251  last_update 20\n",
      "train: iter 80  trainloss 2.71242  validloss 4.87764±0.00000  bestvalidloss 4.87251  last_update 21\n",
      "train: iter 81  trainloss 2.69232  validloss 5.00697±0.00000  bestvalidloss 4.87251  last_update 22\n",
      "train: iter 82  trainloss 2.72105  validloss 4.94722±0.00000  bestvalidloss 4.87251  last_update 23\n",
      "train: iter 83  trainloss 2.70264  validloss 4.95959±0.00000  bestvalidloss 4.87251  last_update 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 2.71457  validloss 4.98390±0.00000  bestvalidloss 4.87251  last_update 25\n",
      "train: iter 85  trainloss 2.71121  validloss 4.96102±0.00000  bestvalidloss 4.87251  last_update 26\n",
      "train: iter 86  trainloss 2.72852  validloss 4.94894±0.00000  bestvalidloss 4.87251  last_update 27\n",
      "train: iter 87  trainloss 2.71405  validloss 5.02220±0.00000  bestvalidloss 4.87251  last_update 28\n",
      "train: iter 88  trainloss 2.73870  validloss 5.00990±0.00000  bestvalidloss 4.87251  last_update 29\n",
      "train: iter 89  trainloss 2.71625  validloss 4.94281±0.00000  bestvalidloss 4.87251  last_update 30\n",
      "train: iter 90  trainloss 2.70439  validloss 4.92209±0.00000  bestvalidloss 4.87251  last_update 31\n",
      "train: iter 91  trainloss 2.68419  validloss 4.88276±0.00000  bestvalidloss 4.87251  last_update 32\n",
      "train: iter 92  trainloss 2.70489  validloss 4.87449±0.00000  bestvalidloss 4.87251  last_update 33\n",
      "train: iter 93  trainloss 2.68994  validloss 5.00288±0.00000  bestvalidloss 4.87251  last_update 34\n",
      "train: iter 94  trainloss 2.68153  validloss 4.72871±0.00000  bestvalidloss 4.72871  last_update 0\n",
      "train: iter 95  trainloss 2.58736  validloss 4.82507±0.00000  bestvalidloss 4.72871  last_update 1\n",
      "train: iter 96  trainloss 2.52174  validloss 4.54277±0.00000  bestvalidloss 4.54277  last_update 0\n",
      "train: iter 97  trainloss 2.45889  validloss 4.23593±0.00000  bestvalidloss 4.23593  last_update 0\n",
      "train: iter 98  trainloss 2.41859  validloss 4.41053±0.00000  bestvalidloss 4.23593  last_update 1\n",
      "train: iter 99  trainloss 2.41226  validloss 4.11985±0.00000  bestvalidloss 4.11985  last_update 0\n",
      "train: iter 100  trainloss 2.40749  validloss 4.17995±0.00000  bestvalidloss 4.11985  last_update 1\n",
      "train: iter 101  trainloss 2.40139  validloss 4.42861±0.00000  bestvalidloss 4.11985  last_update 2\n",
      "train: iter 102  trainloss 2.40217  validloss 4.32876±0.00000  bestvalidloss 4.11985  last_update 3\n",
      "train: iter 103  trainloss 2.37502  validloss 4.11169±0.00000  bestvalidloss 4.11169  last_update 0\n",
      "train: iter 104  trainloss 2.37240  validloss 4.22555±0.00000  bestvalidloss 4.11169  last_update 1\n",
      "train: iter 105  trainloss 2.36777  validloss 4.18339±0.00000  bestvalidloss 4.11169  last_update 2\n",
      "train: iter 106  trainloss 2.36042  validloss 4.33612±0.00000  bestvalidloss 4.11169  last_update 3\n",
      "train: iter 107  trainloss 2.37988  validloss 4.23358±0.00000  bestvalidloss 4.11169  last_update 4\n",
      "train: iter 108  trainloss 2.38013  validloss 4.20190±0.00000  bestvalidloss 4.11169  last_update 5\n",
      "train: iter 109  trainloss 2.36199  validloss 4.26338±0.00000  bestvalidloss 4.11169  last_update 6\n",
      "train: iter 110  trainloss 2.35233  validloss 4.18594±0.00000  bestvalidloss 4.11169  last_update 7\n",
      "train: iter 111  trainloss 2.36481  validloss 4.31810±0.00000  bestvalidloss 4.11169  last_update 8\n",
      "train: iter 112  trainloss 2.35856  validloss 4.20549±0.00000  bestvalidloss 4.11169  last_update 9\n",
      "train: iter 113  trainloss 2.35463  validloss 4.16347±0.00000  bestvalidloss 4.11169  last_update 10\n",
      "train: iter 114  trainloss 2.38299  validloss 4.12389±0.00000  bestvalidloss 4.11169  last_update 11\n",
      "train: iter 115  trainloss 2.37241  validloss 4.18708±0.00000  bestvalidloss 4.11169  last_update 12\n",
      "train: iter 116  trainloss 2.35979  validloss 4.12612±0.00000  bestvalidloss 4.11169  last_update 13\n",
      "train: iter 117  trainloss 2.35647  validloss 4.31571±0.00000  bestvalidloss 4.11169  last_update 14\n",
      "train: iter 118  trainloss 2.35206  validloss 4.18088±0.00000  bestvalidloss 4.11169  last_update 15\n",
      "train: iter 119  trainloss 2.33788  validloss 4.16661±0.00000  bestvalidloss 4.11169  last_update 16\n",
      "train: iter 120  trainloss 2.35564  validloss 4.23788±0.00000  bestvalidloss 4.11169  last_update 17\n",
      "train: iter 121  trainloss 2.33555  validloss 4.24527±0.00000  bestvalidloss 4.11169  last_update 18\n",
      "train: iter 122  trainloss 2.36151  validloss 4.12347±0.00000  bestvalidloss 4.11169  last_update 19\n",
      "train: iter 123  trainloss 2.34058  validloss 4.10887±0.00000  bestvalidloss 4.10887  last_update 0\n",
      "train: iter 124  trainloss 2.35188  validloss 4.14150±0.00000  bestvalidloss 4.10887  last_update 1\n",
      "train: iter 125  trainloss 2.34397  validloss 4.32443±0.00000  bestvalidloss 4.10887  last_update 2\n",
      "train: iter 126  trainloss 2.35249  validloss 4.25077±0.00000  bestvalidloss 4.10887  last_update 3\n",
      "train: iter 127  trainloss 2.33481  validloss 4.10604±0.00000  bestvalidloss 4.10604  last_update 0\n",
      "train: iter 128  trainloss 2.35667  validloss 4.25533±0.00000  bestvalidloss 4.10604  last_update 1\n",
      "train: iter 129  trainloss 2.34593  validloss 4.08768±0.00000  bestvalidloss 4.08768  last_update 0\n",
      "train: iter 130  trainloss 2.32154  validloss 4.05629±0.00000  bestvalidloss 4.05629  last_update 0\n",
      "train: iter 131  trainloss 2.35053  validloss 4.23363±0.00000  bestvalidloss 4.05629  last_update 1\n",
      "train: iter 132  trainloss 2.31993  validloss 4.10206±0.00000  bestvalidloss 4.05629  last_update 2\n",
      "train: iter 133  trainloss 2.33428  validloss 4.09771±0.00000  bestvalidloss 4.05629  last_update 3\n",
      "train: iter 134  trainloss 2.32251  validloss 4.11296±0.00000  bestvalidloss 4.05629  last_update 4\n",
      "train: iter 135  trainloss 2.31077  validloss 4.16017±0.00000  bestvalidloss 4.05629  last_update 5\n",
      "train: iter 136  trainloss 2.30405  validloss 4.08560±0.00000  bestvalidloss 4.05629  last_update 6\n",
      "train: iter 137  trainloss 2.32329  validloss 4.10394±0.00000  bestvalidloss 4.05629  last_update 7\n",
      "train: iter 138  trainloss 2.29073  validloss 4.14987±0.00000  bestvalidloss 4.05629  last_update 8\n",
      "train: iter 139  trainloss 2.30199  validloss 4.09035±0.00000  bestvalidloss 4.05629  last_update 9\n",
      "train: iter 140  trainloss 2.31649  validloss 4.14889±0.00000  bestvalidloss 4.05629  last_update 10\n",
      "train: iter 141  trainloss 2.31033  validloss 4.08953±0.00000  bestvalidloss 4.05629  last_update 11\n",
      "train: iter 142  trainloss 2.29766  validloss 4.15855±0.00000  bestvalidloss 4.05629  last_update 12\n",
      "train: iter 143  trainloss 2.32827  validloss 4.06401±0.00000  bestvalidloss 4.05629  last_update 13\n",
      "train: iter 144  trainloss 2.28838  validloss 4.07483±0.00000  bestvalidloss 4.05629  last_update 14\n",
      "train: iter 145  trainloss 2.31042  validloss 4.01486±0.00000  bestvalidloss 4.01486  last_update 0\n",
      "train: iter 146  trainloss 2.29430  validloss 3.98414±0.00000  bestvalidloss 3.98414  last_update 0\n",
      "train: iter 147  trainloss 2.27974  validloss 4.11126±0.00000  bestvalidloss 3.98414  last_update 1\n",
      "train: iter 148  trainloss 2.29055  validloss 4.01303±0.00000  bestvalidloss 3.98414  last_update 2\n",
      "train: iter 149  trainloss 2.27700  validloss 4.12152±0.00000  bestvalidloss 3.98414  last_update 3\n",
      "train: iter 150  trainloss 2.29645  validloss 4.05590±0.00000  bestvalidloss 3.98414  last_update 4\n",
      "train: iter 151  trainloss 2.27635  validloss 4.02393±0.00000  bestvalidloss 3.98414  last_update 5\n",
      "train: iter 152  trainloss 2.26991  validloss 4.03093±0.00000  bestvalidloss 3.98414  last_update 6\n",
      "train: iter 153  trainloss 2.29881  validloss 3.95815±0.00000  bestvalidloss 3.95815  last_update 0\n",
      "train: iter 154  trainloss 2.26549  validloss 4.25968±0.00000  bestvalidloss 3.95815  last_update 1\n",
      "train: iter 155  trainloss 2.28350  validloss 4.14225±0.00000  bestvalidloss 3.95815  last_update 2\n",
      "train: iter 156  trainloss 2.29172  validloss 4.24431±0.00000  bestvalidloss 3.95815  last_update 3\n",
      "train: iter 157  trainloss 2.26509  validloss 3.95380±0.00000  bestvalidloss 3.95380  last_update 0\n",
      "train: iter 158  trainloss 2.24527  validloss 3.99005±0.00000  bestvalidloss 3.95380  last_update 1\n",
      "train: iter 159  trainloss 2.25086  validloss 4.00826±0.00000  bestvalidloss 3.95380  last_update 2\n",
      "train: iter 160  trainloss 2.25390  validloss 4.01303±0.00000  bestvalidloss 3.95380  last_update 3\n",
      "train: iter 161  trainloss 2.25858  validloss 3.94496±0.00000  bestvalidloss 3.94496  last_update 0\n",
      "train: iter 162  trainloss 2.26973  validloss 3.99580±0.00000  bestvalidloss 3.94496  last_update 1\n",
      "train: iter 163  trainloss 2.25104  validloss 4.16946±0.00000  bestvalidloss 3.94496  last_update 2\n",
      "train: iter 164  trainloss 2.25982  validloss 3.93926±0.00000  bestvalidloss 3.93926  last_update 0\n",
      "train: iter 165  trainloss 2.24251  validloss 4.01010±0.00000  bestvalidloss 3.93926  last_update 1\n",
      "train: iter 166  trainloss 2.24649  validloss 4.03678±0.00000  bestvalidloss 3.93926  last_update 2\n",
      "train: iter 167  trainloss 2.25927  validloss 4.17778±0.00000  bestvalidloss 3.93926  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 2.24673  validloss 3.95154±0.00000  bestvalidloss 3.93926  last_update 4\n",
      "train: iter 169  trainloss 2.24578  validloss 4.11231±0.00000  bestvalidloss 3.93926  last_update 5\n",
      "train: iter 170  trainloss 2.24122  validloss 3.94939±0.00000  bestvalidloss 3.93926  last_update 6\n",
      "train: iter 171  trainloss 2.22758  validloss 4.07338±0.00000  bestvalidloss 3.93926  last_update 7\n",
      "train: iter 172  trainloss 2.24692  validloss 3.91167±0.00000  bestvalidloss 3.91167  last_update 0\n",
      "train: iter 173  trainloss 2.22670  validloss 3.93663±0.00000  bestvalidloss 3.91167  last_update 1\n",
      "train: iter 174  trainloss 2.23267  validloss 3.91853±0.00000  bestvalidloss 3.91167  last_update 2\n",
      "train: iter 175  trainloss 2.23967  validloss 3.94045±0.00000  bestvalidloss 3.91167  last_update 3\n",
      "train: iter 176  trainloss 2.22872  validloss 3.84445±0.00000  bestvalidloss 3.84445  last_update 0\n",
      "train: iter 177  trainloss 2.19731  validloss 3.96055±0.00000  bestvalidloss 3.84445  last_update 1\n",
      "train: iter 178  trainloss 2.22474  validloss 3.96154±0.00000  bestvalidloss 3.84445  last_update 2\n",
      "train: iter 179  trainloss 2.21282  validloss 3.92858±0.00000  bestvalidloss 3.84445  last_update 3\n",
      "train: iter 180  trainloss 2.21603  validloss 4.03499±0.00000  bestvalidloss 3.84445  last_update 4\n",
      "train: iter 181  trainloss 2.21527  validloss 3.88629±0.00000  bestvalidloss 3.84445  last_update 5\n",
      "train: iter 182  trainloss 2.20803  validloss 3.83937±0.00000  bestvalidloss 3.83937  last_update 0\n",
      "train: iter 183  trainloss 2.21195  validloss 4.20799±0.00000  bestvalidloss 3.83937  last_update 1\n",
      "train: iter 184  trainloss 2.19775  validloss 3.92724±0.00000  bestvalidloss 3.83937  last_update 2\n",
      "train: iter 185  trainloss 2.20988  validloss 3.89402±0.00000  bestvalidloss 3.83937  last_update 3\n",
      "train: iter 186  trainloss 2.21251  validloss 3.99447±0.00000  bestvalidloss 3.83937  last_update 4\n",
      "train: iter 187  trainloss 2.16893  validloss 3.77556±0.00000  bestvalidloss 3.77556  last_update 0\n",
      "train: iter 188  trainloss 2.18202  validloss 4.07964±0.00000  bestvalidloss 3.77556  last_update 1\n",
      "train: iter 189  trainloss 2.18535  validloss 4.00348±0.00000  bestvalidloss 3.77556  last_update 2\n",
      "train: iter 190  trainloss 2.18770  validloss 3.83112±0.00000  bestvalidloss 3.77556  last_update 3\n",
      "train: iter 191  trainloss 2.18067  validloss 3.91433±0.00000  bestvalidloss 3.77556  last_update 4\n",
      "train: iter 192  trainloss 2.17494  validloss 3.81257±0.00000  bestvalidloss 3.77556  last_update 5\n",
      "train: iter 193  trainloss 2.16858  validloss 3.85609±0.00000  bestvalidloss 3.77556  last_update 6\n",
      "train: iter 194  trainloss 2.18917  validloss 3.84604±0.00000  bestvalidloss 3.77556  last_update 7\n",
      "train: iter 195  trainloss 2.21174  validloss 3.83511±0.00000  bestvalidloss 3.77556  last_update 8\n",
      "train: iter 196  trainloss 2.16593  validloss 3.85590±0.00000  bestvalidloss 3.77556  last_update 9\n",
      "train: iter 197  trainloss 2.19625  validloss 3.81110±0.00000  bestvalidloss 3.77556  last_update 10\n",
      "train: iter 198  trainloss 2.19209  validloss 3.84519±0.00000  bestvalidloss 3.77556  last_update 11\n",
      "train: iter 199  trainloss 2.18253  validloss 3.90081±0.00000  bestvalidloss 3.77556  last_update 12\n",
      "train: iter 200  trainloss 2.18172  validloss 3.92132±0.00000  bestvalidloss 3.77556  last_update 13\n",
      "train: iter 201  trainloss 2.21334  validloss 3.81856±0.00000  bestvalidloss 3.77556  last_update 14\n",
      "train: iter 202  trainloss 2.19389  validloss 3.79757±0.00000  bestvalidloss 3.77556  last_update 15\n",
      "train: iter 203  trainloss 2.17862  validloss 3.85992±0.00000  bestvalidloss 3.77556  last_update 16\n",
      "train: iter 204  trainloss 2.18670  validloss 3.90919±0.00000  bestvalidloss 3.77556  last_update 17\n",
      "train: iter 205  trainloss 2.18470  validloss 3.88507±0.00000  bestvalidloss 3.77556  last_update 18\n",
      "train: iter 206  trainloss 2.19584  validloss 3.89485±0.00000  bestvalidloss 3.77556  last_update 19\n",
      "train: iter 207  trainloss 2.17800  validloss 3.85939±0.00000  bestvalidloss 3.77556  last_update 20\n",
      "train: iter 208  trainloss 2.18517  validloss 3.88650±0.00000  bestvalidloss 3.77556  last_update 21\n",
      "train: iter 209  trainloss 2.17388  validloss 3.85610±0.00000  bestvalidloss 3.77556  last_update 22\n",
      "train: iter 210  trainloss 2.18959  validloss 3.87653±0.00000  bestvalidloss 3.77556  last_update 23\n",
      "train: iter 211  trainloss 2.19648  validloss 3.80479±0.00000  bestvalidloss 3.77556  last_update 24\n",
      "train: iter 212  trainloss 2.17371  validloss 3.86489±0.00000  bestvalidloss 3.77556  last_update 25\n",
      "train: iter 213  trainloss 2.13815  validloss 3.90117±0.00000  bestvalidloss 3.77556  last_update 26\n",
      "train: iter 214  trainloss 2.17405  validloss 3.81126±0.00000  bestvalidloss 3.77556  last_update 27\n",
      "train: iter 215  trainloss 2.19460  validloss 3.89540±0.00000  bestvalidloss 3.77556  last_update 28\n",
      "train: iter 216  trainloss 2.16621  validloss 3.84678±0.00000  bestvalidloss 3.77556  last_update 29\n",
      "train: iter 217  trainloss 2.17811  validloss 3.79168±0.00000  bestvalidloss 3.77556  last_update 30\n",
      "train: iter 218  trainloss 2.17900  validloss 3.86015±0.00000  bestvalidloss 3.77556  last_update 31\n",
      "train: iter 219  trainloss 2.17918  validloss 3.90394±0.00000  bestvalidloss 3.77556  last_update 32\n",
      "train: iter 220  trainloss 2.19779  validloss 3.76165±0.00000  bestvalidloss 3.76165  last_update 0\n",
      "train: iter 221  trainloss 2.18640  validloss 3.96831±0.00000  bestvalidloss 3.76165  last_update 1\n",
      "train: iter 222  trainloss 2.16333  validloss 3.93990±0.00000  bestvalidloss 3.76165  last_update 2\n",
      "train: iter 223  trainloss 2.19906  validloss 3.85048±0.00000  bestvalidloss 3.76165  last_update 3\n",
      "train: iter 224  trainloss 2.16288  validloss 3.90001±0.00000  bestvalidloss 3.76165  last_update 4\n",
      "train: iter 225  trainloss 2.16931  validloss 3.84785±0.00000  bestvalidloss 3.76165  last_update 5\n",
      "train: iter 226  trainloss 2.17567  validloss 3.80101±0.00000  bestvalidloss 3.76165  last_update 6\n",
      "train: iter 227  trainloss 2.17337  validloss 3.76967±0.00000  bestvalidloss 3.76165  last_update 7\n",
      "train: iter 228  trainloss 2.17421  validloss 3.73558±0.00000  bestvalidloss 3.73558  last_update 0\n",
      "train: iter 229  trainloss 2.17686  validloss 3.91086±0.00000  bestvalidloss 3.73558  last_update 1\n",
      "train: iter 230  trainloss 2.18171  validloss 3.86462±0.00000  bestvalidloss 3.73558  last_update 2\n",
      "train: iter 231  trainloss 2.15823  validloss 3.76692±0.00000  bestvalidloss 3.73558  last_update 3\n",
      "train: iter 232  trainloss 2.16144  validloss 3.85815±0.00000  bestvalidloss 3.73558  last_update 4\n",
      "train: iter 233  trainloss 2.16443  validloss 3.86744±0.00000  bestvalidloss 3.73558  last_update 5\n",
      "train: iter 234  trainloss 2.19391  validloss 3.82849±0.00000  bestvalidloss 3.73558  last_update 6\n",
      "train: iter 235  trainloss 2.18689  validloss 3.81776±0.00000  bestvalidloss 3.73558  last_update 7\n",
      "train: iter 236  trainloss 2.16068  validloss 3.87390±0.00000  bestvalidloss 3.73558  last_update 8\n",
      "train: iter 237  trainloss 2.14528  validloss 4.01978±0.00000  bestvalidloss 3.73558  last_update 9\n",
      "train: iter 238  trainloss 2.16220  validloss 3.87811±0.00000  bestvalidloss 3.73558  last_update 10\n",
      "train: iter 239  trainloss 2.17155  validloss 3.77044±0.00000  bestvalidloss 3.73558  last_update 11\n",
      "train: iter 240  trainloss 2.15313  validloss 3.79245±0.00000  bestvalidloss 3.73558  last_update 12\n",
      "train: iter 241  trainloss 2.20206  validloss 4.03014±0.00000  bestvalidloss 3.73558  last_update 13\n",
      "train: iter 242  trainloss 2.17696  validloss 3.79117±0.00000  bestvalidloss 3.73558  last_update 14\n",
      "train: iter 243  trainloss 2.14417  validloss 3.74936±0.00000  bestvalidloss 3.73558  last_update 15\n",
      "train: iter 244  trainloss 2.14979  validloss 3.83121±0.00000  bestvalidloss 3.73558  last_update 16\n",
      "train: iter 245  trainloss 2.16331  validloss 3.78619±0.00000  bestvalidloss 3.73558  last_update 17\n",
      "train: iter 246  trainloss 2.13951  validloss 3.78690±0.00000  bestvalidloss 3.73558  last_update 18\n",
      "train: iter 247  trainloss 2.18145  validloss 3.90483±0.00000  bestvalidloss 3.73558  last_update 19\n",
      "train: iter 248  trainloss 2.18259  validloss 3.83600±0.00000  bestvalidloss 3.73558  last_update 20\n",
      "train: iter 249  trainloss 2.13417  validloss 3.78709±0.00000  bestvalidloss 3.73558  last_update 21\n",
      "train: iter 250  trainloss 2.13700  validloss 4.05233±0.00000  bestvalidloss 3.73558  last_update 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 251  trainloss 2.16151  validloss 3.91990±0.00000  bestvalidloss 3.73558  last_update 23\n",
      "train: iter 252  trainloss 2.17177  validloss 3.79669±0.00000  bestvalidloss 3.73558  last_update 24\n",
      "train: iter 253  trainloss 2.14550  validloss 3.78707±0.00000  bestvalidloss 3.73558  last_update 25\n",
      "train: iter 254  trainloss 2.15605  validloss 3.79256±0.00000  bestvalidloss 3.73558  last_update 26\n",
      "train: iter 255  trainloss 2.15184  validloss 3.82599±0.00000  bestvalidloss 3.73558  last_update 27\n",
      "train: iter 256  trainloss 2.17583  validloss 3.83624±0.00000  bestvalidloss 3.73558  last_update 28\n",
      "train: iter 257  trainloss 2.14828  validloss 3.76063±0.00000  bestvalidloss 3.73558  last_update 29\n",
      "train: iter 258  trainloss 2.16603  validloss 3.83949±0.00000  bestvalidloss 3.73558  last_update 30\n",
      "train: iter 259  trainloss 2.16820  validloss 3.80498±0.00000  bestvalidloss 3.73558  last_update 31\n",
      "train: iter 260  trainloss 2.14452  validloss 3.76427±0.00000  bestvalidloss 3.73558  last_update 32\n",
      "train: iter 261  trainloss 2.14921  validloss 3.82039±0.00000  bestvalidloss 3.73558  last_update 33\n",
      "train: iter 262  trainloss 2.18552  validloss 3.84354±0.00000  bestvalidloss 3.73558  last_update 34\n",
      "train: iter 263  trainloss 2.17907  validloss 3.78970±0.00000  bestvalidloss 3.73558  last_update 35\n",
      "train: iter 264  trainloss 2.17882  validloss 3.74630±0.00000  bestvalidloss 3.73558  last_update 36\n",
      "train: iter 265  trainloss 2.14658  validloss 3.76433±0.00000  bestvalidloss 3.73558  last_update 37\n",
      "train: iter 266  trainloss 2.16591  validloss 3.76912±0.00000  bestvalidloss 3.73558  last_update 38\n",
      "train: iter 267  trainloss 2.17880  validloss 3.75202±0.00000  bestvalidloss 3.73558  last_update 39\n",
      "train: iter 268  trainloss 2.14123  validloss 3.91715±0.00000  bestvalidloss 3.73558  last_update 40\n",
      "train: iter 269  trainloss 2.18625  validloss 3.82291±0.00000  bestvalidloss 3.73558  last_update 41\n",
      "train: iter 270  trainloss 2.18408  validloss 3.80606±0.00000  bestvalidloss 3.73558  last_update 42\n",
      "train: iter 271  trainloss 2.17702  validloss 3.86860±0.00000  bestvalidloss 3.73558  last_update 43\n",
      "train: iter 272  trainloss 2.14950  validloss 3.78378±0.00000  bestvalidloss 3.73558  last_update 44\n",
      "train: iter 273  trainloss 2.16664  validloss 3.77724±0.00000  bestvalidloss 3.73558  last_update 45\n",
      "train: iter 274  trainloss 2.16816  validloss 3.76103±0.00000  bestvalidloss 3.73558  last_update 46\n",
      "train: iter 275  trainloss 2.13957  validloss 3.77464±0.00000  bestvalidloss 3.73558  last_update 47\n",
      "train: iter 276  trainloss 2.16905  validloss 3.73600±0.00000  bestvalidloss 3.73558  last_update 48\n",
      "train: iter 277  trainloss 2.17673  validloss 3.79948±0.00000  bestvalidloss 3.73558  last_update 49\n",
      "train: iter 278  trainloss 2.15503  validloss 3.72489±0.00000  bestvalidloss 3.72489  last_update 0\n",
      "train: iter 279  trainloss 2.17107  validloss 3.83783±0.00000  bestvalidloss 3.72489  last_update 1\n",
      "train: iter 280  trainloss 2.15864  validloss 3.77939±0.00000  bestvalidloss 3.72489  last_update 2\n",
      "train: iter 281  trainloss 2.16931  validloss 3.82500±0.00000  bestvalidloss 3.72489  last_update 3\n",
      "train: iter 282  trainloss 2.14081  validloss 3.92523±0.00000  bestvalidloss 3.72489  last_update 4\n",
      "train: iter 283  trainloss 2.16289  validloss 3.85151±0.00000  bestvalidloss 3.72489  last_update 5\n",
      "train: iter 284  trainloss 2.14638  validloss 3.76645±0.00000  bestvalidloss 3.72489  last_update 6\n",
      "train: iter 285  trainloss 2.13973  validloss 3.74462±0.00000  bestvalidloss 3.72489  last_update 7\n",
      "train: iter 286  trainloss 2.15048  validloss 3.80544±0.00000  bestvalidloss 3.72489  last_update 8\n",
      "train: iter 287  trainloss 2.13688  validloss 3.85529±0.00000  bestvalidloss 3.72489  last_update 9\n",
      "train: iter 288  trainloss 2.14759  validloss 3.77795±0.00000  bestvalidloss 3.72489  last_update 10\n",
      "train: iter 289  trainloss 2.16145  validloss 3.84414±0.00000  bestvalidloss 3.72489  last_update 11\n",
      "train: iter 290  trainloss 2.13300  validloss 3.75175±0.00000  bestvalidloss 3.72489  last_update 12\n",
      "train: iter 291  trainloss 2.16481  validloss 3.93304±0.00000  bestvalidloss 3.72489  last_update 13\n",
      "train: iter 292  trainloss 2.17731  validloss 3.73406±0.00000  bestvalidloss 3.72489  last_update 14\n",
      "train: iter 293  trainloss 2.18989  validloss 3.83649±0.00000  bestvalidloss 3.72489  last_update 15\n",
      "train: iter 294  trainloss 2.13007  validloss 3.88761±0.00000  bestvalidloss 3.72489  last_update 16\n",
      "train: iter 295  trainloss 2.16066  validloss 3.99315±0.00000  bestvalidloss 3.72489  last_update 17\n",
      "train: iter 296  trainloss 2.15436  validloss 3.82268±0.00000  bestvalidloss 3.72489  last_update 18\n",
      "train: iter 297  trainloss 2.16284  validloss 3.81817±0.00000  bestvalidloss 3.72489  last_update 19\n",
      "train: iter 298  trainloss 2.15653  validloss 3.84376±0.00000  bestvalidloss 3.72489  last_update 20\n",
      "train: iter 299  trainloss 2.15506  validloss 3.72627±0.00000  bestvalidloss 3.72489  last_update 21\n",
      "train: iter 300  trainloss 2.15780  validloss 3.74555±0.00000  bestvalidloss 3.72489  last_update 22\n",
      "train: iter 301  trainloss 2.17565  validloss 3.87786±0.00000  bestvalidloss 3.72489  last_update 23\n",
      "train: iter 302  trainloss 2.13114  validloss 3.73986±0.00000  bestvalidloss 3.72489  last_update 24\n",
      "train: iter 303  trainloss 2.16240  validloss 3.78321±0.00000  bestvalidloss 3.72489  last_update 25\n",
      "train: iter 304  trainloss 2.14933  validloss 3.79531±0.00000  bestvalidloss 3.72489  last_update 26\n",
      "train: iter 305  trainloss 2.15287  validloss 3.79633±0.00000  bestvalidloss 3.72489  last_update 27\n",
      "train: iter 306  trainloss 2.15158  validloss 3.85142±0.00000  bestvalidloss 3.72489  last_update 28\n",
      "train: iter 307  trainloss 2.19437  validloss 3.87192±0.00000  bestvalidloss 3.72489  last_update 29\n",
      "train: iter 308  trainloss 2.14074  validloss 3.86198±0.00000  bestvalidloss 3.72489  last_update 30\n",
      "train: iter 309  trainloss 2.14633  validloss 3.79705±0.00000  bestvalidloss 3.72489  last_update 31\n",
      "train: iter 310  trainloss 2.13189  validloss 3.84188±0.00000  bestvalidloss 3.72489  last_update 32\n",
      "train: iter 311  trainloss 2.15069  validloss 3.84650±0.00000  bestvalidloss 3.72489  last_update 33\n",
      "train: iter 312  trainloss 2.12379  validloss 3.81533±0.00000  bestvalidloss 3.72489  last_update 34\n",
      "train: iter 313  trainloss 2.14477  validloss 3.79702±0.00000  bestvalidloss 3.72489  last_update 35\n",
      "train: iter 314  trainloss 2.13224  validloss 3.86511±0.00000  bestvalidloss 3.72489  last_update 36\n",
      "train: iter 315  trainloss 2.14741  validloss 3.80691±0.00000  bestvalidloss 3.72489  last_update 37\n",
      "train: iter 316  trainloss 2.16880  validloss 3.79618±0.00000  bestvalidloss 3.72489  last_update 38\n",
      "train: iter 317  trainloss 2.14300  validloss 3.74930±0.00000  bestvalidloss 3.72489  last_update 39\n",
      "train: iter 318  trainloss 2.14832  validloss 3.82747±0.00000  bestvalidloss 3.72489  last_update 40\n",
      "train: iter 319  trainloss 2.15408  validloss 3.79131±0.00000  bestvalidloss 3.72489  last_update 41\n",
      "train: iter 320  trainloss 2.15596  validloss 3.87127±0.00000  bestvalidloss 3.72489  last_update 42\n",
      "train: iter 321  trainloss 2.13339  validloss 3.78009±0.00000  bestvalidloss 3.72489  last_update 43\n",
      "train: iter 322  trainloss 2.16363  validloss 3.81327±0.00000  bestvalidloss 3.72489  last_update 44\n",
      "train: iter 323  trainloss 2.13274  validloss 3.75118±0.00000  bestvalidloss 3.72489  last_update 45\n",
      "train: iter 324  trainloss 2.14772  validloss 3.86181±0.00000  bestvalidloss 3.72489  last_update 46\n",
      "train: iter 325  trainloss 2.14371  validloss 3.76981±0.00000  bestvalidloss 3.72489  last_update 47\n",
      "train: iter 326  trainloss 2.13465  validloss 3.76711±0.00000  bestvalidloss 3.72489  last_update 48\n",
      "train: iter 327  trainloss 2.11987  validloss 3.85956±0.00000  bestvalidloss 3.72489  last_update 49\n",
      "train: iter 328  trainloss 2.15237  validloss 3.72969±0.00000  bestvalidloss 3.72489  last_update 50\n",
      "train: iter 329  trainloss 2.13972  validloss 3.79147±0.00000  bestvalidloss 3.72489  last_update 51\n",
      "train: iter 330  trainloss 2.11217  validloss 3.75527±0.00000  bestvalidloss 3.72489  last_update 52\n",
      "train: iter 331  trainloss 2.15047  validloss 3.75407±0.00000  bestvalidloss 3.72489  last_update 53\n",
      "train: iter 332  trainloss 2.16229  validloss 3.84811±0.00000  bestvalidloss 3.72489  last_update 54\n",
      "train: iter 333  trainloss 2.12676  validloss 3.83870±0.00000  bestvalidloss 3.72489  last_update 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 334  trainloss 2.12841  validloss 3.74145±0.00000  bestvalidloss 3.72489  last_update 56\n",
      "train: iter 335  trainloss 2.14672  validloss 3.75064±0.00000  bestvalidloss 3.72489  last_update 57\n",
      "train: iter 336  trainloss 2.13354  validloss 3.72639±0.00000  bestvalidloss 3.72489  last_update 58\n",
      "train: iter 337  trainloss 2.13510  validloss 3.75851±0.00000  bestvalidloss 3.72489  last_update 59\n",
      "train: iter 338  trainloss 2.15098  validloss 3.76201±0.00000  bestvalidloss 3.72489  last_update 60\n",
      "train: iter 339  trainloss 2.13517  validloss 3.81662±0.00000  bestvalidloss 3.72489  last_update 61\n",
      "train: iter 340  trainloss 2.17247  validloss 3.77257±0.00000  bestvalidloss 3.72489  last_update 62\n",
      "train: iter 341  trainloss 2.16151  validloss 3.87303±0.00000  bestvalidloss 3.72489  last_update 63\n",
      "train: iter 342  trainloss 2.17690  validloss 3.84278±0.00000  bestvalidloss 3.72489  last_update 64\n",
      "train: iter 343  trainloss 2.14568  validloss 3.73642±0.00000  bestvalidloss 3.72489  last_update 65\n",
      "train: iter 344  trainloss 2.13408  validloss 3.77823±0.00000  bestvalidloss 3.72489  last_update 66\n",
      "train: iter 345  trainloss 2.15157  validloss 3.76845±0.00000  bestvalidloss 3.72489  last_update 67\n",
      "train: iter 346  trainloss 2.12820  validloss 3.86184±0.00000  bestvalidloss 3.72489  last_update 68\n",
      "train: iter 347  trainloss 2.12373  validloss 3.75512±0.00000  bestvalidloss 3.72489  last_update 69\n",
      "train: iter 348  trainloss 2.13820  validloss 3.84963±0.00000  bestvalidloss 3.72489  last_update 70\n",
      "train: iter 349  trainloss 2.13482  validloss 3.77354±0.00000  bestvalidloss 3.72489  last_update 71\n",
      "train: iter 350  trainloss 2.12594  validloss 3.71215±0.00000  bestvalidloss 3.71215  last_update 0\n",
      "train: iter 351  trainloss 2.12940  validloss 3.81802±0.00000  bestvalidloss 3.71215  last_update 1\n",
      "train: iter 352  trainloss 2.11668  validloss 3.83100±0.00000  bestvalidloss 3.71215  last_update 2\n",
      "train: iter 353  trainloss 2.15194  validloss 3.88072±0.00000  bestvalidloss 3.71215  last_update 3\n",
      "train: iter 354  trainloss 2.14319  validloss 3.80525±0.00000  bestvalidloss 3.71215  last_update 4\n",
      "train: iter 355  trainloss 2.15021  validloss 3.74669±0.00000  bestvalidloss 3.71215  last_update 5\n",
      "train: iter 356  trainloss 2.13129  validloss 3.79311±0.00000  bestvalidloss 3.71215  last_update 6\n",
      "train: iter 357  trainloss 2.14748  validloss 3.76243±0.00000  bestvalidloss 3.71215  last_update 7\n",
      "train: iter 358  trainloss 2.11435  validloss 3.74194±0.00000  bestvalidloss 3.71215  last_update 8\n",
      "train: iter 359  trainloss 2.11902  validloss 3.74622±0.00000  bestvalidloss 3.71215  last_update 9\n",
      "train: iter 360  trainloss 2.12883  validloss 3.89834±0.00000  bestvalidloss 3.71215  last_update 10\n",
      "train: iter 361  trainloss 2.14452  validloss 3.75705±0.00000  bestvalidloss 3.71215  last_update 11\n",
      "train: iter 362  trainloss 2.15469  validloss 3.82795±0.00000  bestvalidloss 3.71215  last_update 12\n",
      "train: iter 363  trainloss 2.13029  validloss 3.73895±0.00000  bestvalidloss 3.71215  last_update 13\n",
      "train: iter 364  trainloss 2.13775  validloss 3.75684±0.00000  bestvalidloss 3.71215  last_update 14\n",
      "train: iter 365  trainloss 2.14396  validloss 3.78536±0.00000  bestvalidloss 3.71215  last_update 15\n",
      "train: iter 366  trainloss 2.12972  validloss 3.86494±0.00000  bestvalidloss 3.71215  last_update 16\n",
      "train: iter 367  trainloss 2.13478  validloss 3.86261±0.00000  bestvalidloss 3.71215  last_update 17\n",
      "train: iter 368  trainloss 2.14012  validloss 3.78291±0.00000  bestvalidloss 3.71215  last_update 18\n",
      "train: iter 369  trainloss 2.13946  validloss 3.83653±0.00000  bestvalidloss 3.71215  last_update 19\n",
      "train: iter 370  trainloss 2.12908  validloss 3.75699±0.00000  bestvalidloss 3.71215  last_update 20\n",
      "train: iter 371  trainloss 2.17286  validloss 3.71878±0.00000  bestvalidloss 3.71215  last_update 21\n",
      "train: iter 372  trainloss 2.12359  validloss 3.82367±0.00000  bestvalidloss 3.71215  last_update 22\n",
      "train: iter 373  trainloss 2.14060  validloss 3.75687±0.00000  bestvalidloss 3.71215  last_update 23\n",
      "train: iter 374  trainloss 2.13452  validloss 3.75169±0.00000  bestvalidloss 3.71215  last_update 24\n",
      "train: iter 375  trainloss 2.11568  validloss 3.84563±0.00000  bestvalidloss 3.71215  last_update 25\n",
      "train: iter 376  trainloss 2.15153  validloss 3.73905±0.00000  bestvalidloss 3.71215  last_update 26\n",
      "train: iter 377  trainloss 2.11639  validloss 3.73555±0.00000  bestvalidloss 3.71215  last_update 27\n",
      "train: iter 378  trainloss 2.13924  validloss 3.76078±0.00000  bestvalidloss 3.71215  last_update 28\n",
      "train: iter 379  trainloss 2.13861  validloss 3.80491±0.00000  bestvalidloss 3.71215  last_update 29\n",
      "train: iter 380  trainloss 2.16173  validloss 3.94280±0.00000  bestvalidloss 3.71215  last_update 30\n",
      "train: iter 381  trainloss 2.14827  validloss 3.84429±0.00000  bestvalidloss 3.71215  last_update 31\n",
      "train: iter 382  trainloss 2.12182  validloss 3.77547±0.00000  bestvalidloss 3.71215  last_update 32\n",
      "train: iter 383  trainloss 2.13419  validloss 3.70017±0.00000  bestvalidloss 3.70017  last_update 0\n",
      "train: iter 384  trainloss 2.12000  validloss 3.75269±0.00000  bestvalidloss 3.70017  last_update 1\n",
      "train: iter 385  trainloss 2.12947  validloss 3.77274±0.00000  bestvalidloss 3.70017  last_update 2\n",
      "train: iter 386  trainloss 2.15606  validloss 3.71579±0.00000  bestvalidloss 3.70017  last_update 3\n",
      "train: iter 387  trainloss 2.15492  validloss 3.72404±0.00000  bestvalidloss 3.70017  last_update 4\n",
      "train: iter 388  trainloss 2.13606  validloss 3.72608±0.00000  bestvalidloss 3.70017  last_update 5\n",
      "train: iter 389  trainloss 2.14102  validloss 3.72247±0.00000  bestvalidloss 3.70017  last_update 6\n",
      "train: iter 390  trainloss 2.13995  validloss 3.94990±0.00000  bestvalidloss 3.70017  last_update 7\n",
      "train: iter 391  trainloss 2.13781  validloss 3.69316±0.00000  bestvalidloss 3.69316  last_update 0\n",
      "train: iter 392  trainloss 2.14570  validloss 3.72968±0.00000  bestvalidloss 3.69316  last_update 1\n",
      "train: iter 393  trainloss 2.12977  validloss 3.81720±0.00000  bestvalidloss 3.69316  last_update 2\n",
      "train: iter 394  trainloss 2.11501  validloss 3.77721±0.00000  bestvalidloss 3.69316  last_update 3\n",
      "train: iter 395  trainloss 2.11440  validloss 3.81235±0.00000  bestvalidloss 3.69316  last_update 4\n",
      "train: iter 396  trainloss 2.14083  validloss 3.77566±0.00000  bestvalidloss 3.69316  last_update 5\n",
      "train: iter 397  trainloss 2.10469  validloss 3.73208±0.00000  bestvalidloss 3.69316  last_update 6\n",
      "train: iter 398  trainloss 2.13941  validloss 3.76844±0.00000  bestvalidloss 3.69316  last_update 7\n",
      "train: iter 399  trainloss 2.11612  validloss 3.77707±0.00000  bestvalidloss 3.69316  last_update 8\n",
      "train: iter 400  trainloss 2.12885  validloss 3.77884±0.00000  bestvalidloss 3.69316  last_update 9\n",
      "train: iter 401  trainloss 2.13188  validloss 3.80831±0.00000  bestvalidloss 3.69316  last_update 10\n",
      "train: iter 402  trainloss 2.10283  validloss 3.78819±0.00000  bestvalidloss 3.69316  last_update 11\n",
      "train: iter 403  trainloss 2.14141  validloss 3.74825±0.00000  bestvalidloss 3.69316  last_update 12\n",
      "train: iter 404  trainloss 2.11944  validloss 3.73846±0.00000  bestvalidloss 3.69316  last_update 13\n",
      "train: iter 405  trainloss 2.13818  validloss 3.78956±0.00000  bestvalidloss 3.69316  last_update 14\n",
      "train: iter 406  trainloss 2.13561  validloss 3.75777±0.00000  bestvalidloss 3.69316  last_update 15\n",
      "train: iter 407  trainloss 2.11868  validloss 3.75840±0.00000  bestvalidloss 3.69316  last_update 16\n",
      "train: iter 408  trainloss 2.11765  validloss 3.77067±0.00000  bestvalidloss 3.69316  last_update 17\n",
      "train: iter 409  trainloss 2.14902  validloss 3.76247±0.00000  bestvalidloss 3.69316  last_update 18\n",
      "train: iter 410  trainloss 2.12874  validloss 3.82080±0.00000  bestvalidloss 3.69316  last_update 19\n",
      "train: iter 411  trainloss 2.11513  validloss 3.72782±0.00000  bestvalidloss 3.69316  last_update 20\n",
      "train: iter 412  trainloss 2.13160  validloss 3.75470±0.00000  bestvalidloss 3.69316  last_update 21\n",
      "train: iter 413  trainloss 2.09020  validloss 3.76766±0.00000  bestvalidloss 3.69316  last_update 22\n",
      "train: iter 414  trainloss 2.13670  validloss 3.82164±0.00000  bestvalidloss 3.69316  last_update 23\n",
      "train: iter 415  trainloss 2.11328  validloss 3.79785±0.00000  bestvalidloss 3.69316  last_update 24\n",
      "train: iter 416  trainloss 2.13569  validloss 3.74817±0.00000  bestvalidloss 3.69316  last_update 25\n",
      "train: iter 417  trainloss 2.14962  validloss 3.78245±0.00000  bestvalidloss 3.69316  last_update 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 418  trainloss 2.14959  validloss 3.74987±0.00000  bestvalidloss 3.69316  last_update 27\n",
      "train: iter 419  trainloss 2.12179  validloss 3.83728±0.00000  bestvalidloss 3.69316  last_update 28\n",
      "train: iter 420  trainloss 2.09649  validloss 3.80313±0.00000  bestvalidloss 3.69316  last_update 29\n",
      "train: iter 421  trainloss 2.11203  validloss 3.79198±0.00000  bestvalidloss 3.69316  last_update 30\n",
      "train: iter 422  trainloss 2.12955  validloss 3.84016±0.00000  bestvalidloss 3.69316  last_update 31\n",
      "train: iter 423  trainloss 2.12629  validloss 3.78614±0.00000  bestvalidloss 3.69316  last_update 32\n",
      "train: iter 424  trainloss 2.15193  validloss 3.77847±0.00000  bestvalidloss 3.69316  last_update 33\n",
      "train: iter 425  trainloss 2.16987  validloss 3.78461±0.00000  bestvalidloss 3.69316  last_update 34\n",
      "train: iter 426  trainloss 2.13665  validloss 3.75788±0.00000  bestvalidloss 3.69316  last_update 35\n",
      "train: iter 427  trainloss 2.10706  validloss 3.82560±0.00000  bestvalidloss 3.69316  last_update 36\n",
      "train: iter 428  trainloss 2.14401  validloss 3.79308±0.00000  bestvalidloss 3.69316  last_update 37\n",
      "train: iter 429  trainloss 2.12237  validloss 3.69998±0.00000  bestvalidloss 3.69316  last_update 38\n",
      "train: iter 430  trainloss 2.13582  validloss 3.78094±0.00000  bestvalidloss 3.69316  last_update 39\n",
      "train: iter 431  trainloss 2.13101  validloss 3.69690±0.00000  bestvalidloss 3.69316  last_update 40\n",
      "train: iter 432  trainloss 2.09939  validloss 3.74064±0.00000  bestvalidloss 3.69316  last_update 41\n",
      "train: iter 433  trainloss 2.11650  validloss 3.65778±0.00000  bestvalidloss 3.65778  last_update 0\n",
      "train: iter 434  trainloss 2.14881  validloss 3.74803±0.00000  bestvalidloss 3.65778  last_update 1\n",
      "train: iter 435  trainloss 2.13849  validloss 3.77516±0.00000  bestvalidloss 3.65778  last_update 2\n",
      "train: iter 436  trainloss 2.11044  validloss 3.71344±0.00000  bestvalidloss 3.65778  last_update 3\n",
      "train: iter 437  trainloss 2.11326  validloss 3.79801±0.00000  bestvalidloss 3.65778  last_update 4\n",
      "train: iter 438  trainloss 2.13537  validloss 3.71540±0.00000  bestvalidloss 3.65778  last_update 5\n",
      "train: iter 439  trainloss 2.12682  validloss 3.70864±0.00000  bestvalidloss 3.65778  last_update 6\n",
      "train: iter 440  trainloss 2.08012  validloss 3.74532±0.00000  bestvalidloss 3.65778  last_update 7\n",
      "train: iter 441  trainloss 2.13647  validloss 3.72306±0.00000  bestvalidloss 3.65778  last_update 8\n",
      "train: iter 442  trainloss 2.12515  validloss 3.85996±0.00000  bestvalidloss 3.65778  last_update 9\n",
      "train: iter 443  trainloss 2.12040  validloss 3.77379±0.00000  bestvalidloss 3.65778  last_update 10\n",
      "train: iter 444  trainloss 2.11501  validloss 3.77526±0.00000  bestvalidloss 3.65778  last_update 11\n",
      "train: iter 445  trainloss 2.12887  validloss 3.81867±0.00000  bestvalidloss 3.65778  last_update 12\n",
      "train: iter 446  trainloss 2.12155  validloss 3.75785±0.00000  bestvalidloss 3.65778  last_update 13\n",
      "train: iter 447  trainloss 2.12493  validloss 3.82144±0.00000  bestvalidloss 3.65778  last_update 14\n",
      "train: iter 448  trainloss 2.11716  validloss 3.82586±0.00000  bestvalidloss 3.65778  last_update 15\n",
      "train: iter 449  trainloss 2.09267  validloss 3.74472±0.00000  bestvalidloss 3.65778  last_update 16\n",
      "train: iter 450  trainloss 2.11900  validloss 3.75222±0.00000  bestvalidloss 3.65778  last_update 17\n",
      "train: iter 451  trainloss 2.13570  validloss 3.71903±0.00000  bestvalidloss 3.65778  last_update 18\n",
      "train: iter 452  trainloss 2.10945  validloss 3.73123±0.00000  bestvalidloss 3.65778  last_update 19\n",
      "train: iter 453  trainloss 2.09209  validloss 3.76397±0.00000  bestvalidloss 3.65778  last_update 20\n",
      "train: iter 454  trainloss 2.14134  validloss 3.75696±0.00000  bestvalidloss 3.65778  last_update 21\n",
      "train: iter 455  trainloss 2.10163  validloss 3.71877±0.00000  bestvalidloss 3.65778  last_update 22\n",
      "train: iter 456  trainloss 2.11625  validloss 3.77863±0.00000  bestvalidloss 3.65778  last_update 23\n",
      "train: iter 457  trainloss 2.12871  validloss 3.70574±0.00000  bestvalidloss 3.65778  last_update 24\n",
      "train: iter 458  trainloss 2.11893  validloss 3.67248±0.00000  bestvalidloss 3.65778  last_update 25\n",
      "train: iter 459  trainloss 2.11079  validloss 3.80425±0.00000  bestvalidloss 3.65778  last_update 26\n",
      "train: iter 460  trainloss 2.11064  validloss 3.82539±0.00000  bestvalidloss 3.65778  last_update 27\n",
      "train: iter 461  trainloss 2.13192  validloss 3.75124±0.00000  bestvalidloss 3.65778  last_update 28\n",
      "train: iter 462  trainloss 2.11842  validloss 3.69011±0.00000  bestvalidloss 3.65778  last_update 29\n",
      "train: iter 463  trainloss 2.11755  validloss 3.77292±0.00000  bestvalidloss 3.65778  last_update 30\n",
      "train: iter 464  trainloss 2.12645  validloss 3.71483±0.00000  bestvalidloss 3.65778  last_update 31\n",
      "train: iter 465  trainloss 2.13527  validloss 3.74844±0.00000  bestvalidloss 3.65778  last_update 32\n",
      "train: iter 466  trainloss 2.11824  validloss 3.85155±0.00000  bestvalidloss 3.65778  last_update 33\n",
      "train: iter 467  trainloss 2.12979  validloss 3.74512±0.00000  bestvalidloss 3.65778  last_update 34\n",
      "train: iter 468  trainloss 2.11495  validloss 3.72189±0.00000  bestvalidloss 3.65778  last_update 35\n",
      "train: iter 469  trainloss 2.14839  validloss 3.69161±0.00000  bestvalidloss 3.65778  last_update 36\n",
      "train: iter 470  trainloss 2.11738  validloss 3.71335±0.00000  bestvalidloss 3.65778  last_update 37\n",
      "train: iter 471  trainloss 2.13649  validloss 3.72740±0.00000  bestvalidloss 3.65778  last_update 38\n",
      "train: iter 472  trainloss 2.09559  validloss 3.75263±0.00000  bestvalidloss 3.65778  last_update 39\n",
      "train: iter 473  trainloss 2.09414  validloss 3.73098±0.00000  bestvalidloss 3.65778  last_update 40\n",
      "train: iter 474  trainloss 2.12546  validloss 3.75622±0.00000  bestvalidloss 3.65778  last_update 41\n",
      "train: iter 475  trainloss 2.13315  validloss 3.77788±0.00000  bestvalidloss 3.65778  last_update 42\n",
      "train: iter 476  trainloss 2.09579  validloss 3.76301±0.00000  bestvalidloss 3.65778  last_update 43\n",
      "train: iter 477  trainloss 2.09708  validloss 3.71880±0.00000  bestvalidloss 3.65778  last_update 44\n",
      "train: iter 478  trainloss 2.09576  validloss 3.77459±0.00000  bestvalidloss 3.65778  last_update 45\n",
      "train: iter 479  trainloss 2.11217  validloss 3.74475±0.00000  bestvalidloss 3.65778  last_update 46\n",
      "train: iter 480  trainloss 2.13068  validloss 3.78181±0.00000  bestvalidloss 3.65778  last_update 47\n",
      "train: iter 481  trainloss 2.12016  validloss 3.73020±0.00000  bestvalidloss 3.65778  last_update 48\n",
      "train: iter 482  trainloss 2.13250  validloss 3.71695±0.00000  bestvalidloss 3.65778  last_update 49\n",
      "train: iter 483  trainloss 2.13527  validloss 3.72112±0.00000  bestvalidloss 3.65778  last_update 50\n",
      "train: iter 484  trainloss 2.13001  validloss 3.77225±0.00000  bestvalidloss 3.65778  last_update 51\n",
      "train: iter 485  trainloss 2.14225  validloss 3.76487±0.00000  bestvalidloss 3.65778  last_update 52\n",
      "train: iter 486  trainloss 2.11824  validloss 3.77206±0.00000  bestvalidloss 3.65778  last_update 53\n",
      "train: iter 487  trainloss 2.12944  validloss 3.71883±0.00000  bestvalidloss 3.65778  last_update 54\n",
      "train: iter 488  trainloss 2.08835  validloss 3.70690±0.00000  bestvalidloss 3.65778  last_update 55\n",
      "train: iter 489  trainloss 2.12758  validloss 3.72747±0.00000  bestvalidloss 3.65778  last_update 56\n",
      "train: iter 490  trainloss 2.11282  validloss 3.68309±0.00000  bestvalidloss 3.65778  last_update 57\n",
      "train: iter 491  trainloss 2.15032  validloss 3.81042±0.00000  bestvalidloss 3.65778  last_update 58\n",
      "train: iter 492  trainloss 2.11917  validloss 3.74873±0.00000  bestvalidloss 3.65778  last_update 59\n",
      "train: iter 493  trainloss 2.13785  validloss 3.78489±0.00000  bestvalidloss 3.65778  last_update 60\n",
      "train: iter 494  trainloss 2.11821  validloss 3.72045±0.00000  bestvalidloss 3.65778  last_update 61\n",
      "train: iter 495  trainloss 2.10458  validloss 3.67503±0.00000  bestvalidloss 3.65778  last_update 62\n",
      "train: iter 496  trainloss 2.13182  validloss 3.70891±0.00000  bestvalidloss 3.65778  last_update 63\n",
      "train: iter 497  trainloss 2.10140  validloss 3.78953±0.00000  bestvalidloss 3.65778  last_update 64\n",
      "train: iter 498  trainloss 2.09074  validloss 3.75296±0.00000  bestvalidloss 3.65778  last_update 65\n",
      "train: iter 499  trainloss 2.10284  validloss 3.70138±0.00000  bestvalidloss 3.65778  last_update 66\n",
      "train: iter 500  trainloss 2.10806  validloss 3.71823±0.00000  bestvalidloss 3.65778  last_update 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 501  trainloss 2.12818  validloss 3.71275±0.00000  bestvalidloss 3.65778  last_update 68\n",
      "train: iter 502  trainloss 2.12978  validloss 3.71854±0.00000  bestvalidloss 3.65778  last_update 69\n",
      "train: iter 503  trainloss 2.11525  validloss 3.85771±0.00000  bestvalidloss 3.65778  last_update 70\n",
      "train: iter 504  trainloss 2.11038  validloss 3.72951±0.00000  bestvalidloss 3.65778  last_update 71\n",
      "train: iter 505  trainloss 2.11271  validloss 3.74519±0.00000  bestvalidloss 3.65778  last_update 72\n",
      "train: iter 506  trainloss 2.12504  validloss 3.75588±0.00000  bestvalidloss 3.65778  last_update 73\n",
      "train: iter 507  trainloss 2.10117  validloss 3.73660±0.00000  bestvalidloss 3.65778  last_update 74\n",
      "train: iter 508  trainloss 2.12465  validloss 3.77823±0.00000  bestvalidloss 3.65778  last_update 75\n",
      "train: iter 509  trainloss 2.13595  validloss 3.72883±0.00000  bestvalidloss 3.65778  last_update 76\n",
      "train: iter 510  trainloss 2.09073  validloss 3.64472±0.00000  bestvalidloss 3.64472  last_update 0\n",
      "train: iter 511  trainloss 2.13428  validloss 3.74156±0.00000  bestvalidloss 3.64472  last_update 1\n",
      "train: iter 512  trainloss 2.08788  validloss 3.79156±0.00000  bestvalidloss 3.64472  last_update 2\n",
      "train: iter 513  trainloss 2.06759  validloss 3.78096±0.00000  bestvalidloss 3.64472  last_update 3\n",
      "train: iter 514  trainloss 2.10696  validloss 3.81008±0.00000  bestvalidloss 3.64472  last_update 4\n",
      "train: iter 515  trainloss 2.11615  validloss 3.70584±0.00000  bestvalidloss 3.64472  last_update 5\n",
      "train: iter 516  trainloss 2.10024  validloss 3.74210±0.00000  bestvalidloss 3.64472  last_update 6\n",
      "train: iter 517  trainloss 2.11480  validloss 3.70272±0.00000  bestvalidloss 3.64472  last_update 7\n",
      "train: iter 518  trainloss 2.11013  validloss 3.78113±0.00000  bestvalidloss 3.64472  last_update 8\n",
      "train: iter 519  trainloss 2.13537  validloss 3.78803±0.00000  bestvalidloss 3.64472  last_update 9\n",
      "train: iter 520  trainloss 2.12089  validloss 3.81496±0.00000  bestvalidloss 3.64472  last_update 10\n",
      "train: iter 521  trainloss 2.14675  validloss 3.70703±0.00000  bestvalidloss 3.64472  last_update 11\n",
      "train: iter 522  trainloss 2.10760  validloss 3.74710±0.00000  bestvalidloss 3.64472  last_update 12\n",
      "train: iter 523  trainloss 2.12865  validloss 3.67257±0.00000  bestvalidloss 3.64472  last_update 13\n",
      "train: iter 524  trainloss 2.09390  validloss 3.68368±0.00000  bestvalidloss 3.64472  last_update 14\n",
      "train: iter 525  trainloss 2.11628  validloss 3.77469±0.00000  bestvalidloss 3.64472  last_update 15\n",
      "train: iter 526  trainloss 2.08035  validloss 3.81172±0.00000  bestvalidloss 3.64472  last_update 16\n",
      "train: iter 527  trainloss 2.07673  validloss 3.76305±0.00000  bestvalidloss 3.64472  last_update 17\n",
      "train: iter 528  trainloss 2.10557  validloss 3.70082±0.00000  bestvalidloss 3.64472  last_update 18\n",
      "train: iter 529  trainloss 2.10701  validloss 3.77635±0.00000  bestvalidloss 3.64472  last_update 19\n",
      "train: iter 530  trainloss 2.12567  validloss 3.85933±0.00000  bestvalidloss 3.64472  last_update 20\n",
      "train: iter 531  trainloss 2.12523  validloss 3.66323±0.00000  bestvalidloss 3.64472  last_update 21\n",
      "train: iter 532  trainloss 2.10356  validloss 3.73852±0.00000  bestvalidloss 3.64472  last_update 22\n",
      "train: iter 533  trainloss 2.14143  validloss 3.70894±0.00000  bestvalidloss 3.64472  last_update 23\n",
      "train: iter 534  trainloss 2.12397  validloss 3.69530±0.00000  bestvalidloss 3.64472  last_update 24\n",
      "train: iter 535  trainloss 2.10273  validloss 3.71437±0.00000  bestvalidloss 3.64472  last_update 25\n",
      "train: iter 536  trainloss 2.09798  validloss 3.78949±0.00000  bestvalidloss 3.64472  last_update 26\n",
      "train: iter 537  trainloss 2.12605  validloss 3.67500±0.00000  bestvalidloss 3.64472  last_update 27\n",
      "train: iter 538  trainloss 2.11624  validloss 3.76247±0.00000  bestvalidloss 3.64472  last_update 28\n",
      "train: iter 539  trainloss 2.10993  validloss 3.70638±0.00000  bestvalidloss 3.64472  last_update 29\n",
      "train: iter 540  trainloss 2.08737  validloss 3.67453±0.00000  bestvalidloss 3.64472  last_update 30\n",
      "train: iter 541  trainloss 2.14311  validloss 3.86077±0.00000  bestvalidloss 3.64472  last_update 31\n",
      "train: iter 542  trainloss 2.11018  validloss 3.79404±0.00000  bestvalidloss 3.64472  last_update 32\n",
      "train: iter 543  trainloss 2.12354  validloss 3.71345±0.00000  bestvalidloss 3.64472  last_update 33\n",
      "train: iter 544  trainloss 2.10806  validloss 3.74849±0.00000  bestvalidloss 3.64472  last_update 34\n",
      "train: iter 545  trainloss 2.10850  validloss 3.77878±0.00000  bestvalidloss 3.64472  last_update 35\n",
      "train: iter 546  trainloss 2.09378  validloss 3.70970±0.00000  bestvalidloss 3.64472  last_update 36\n",
      "train: iter 547  trainloss 2.09904  validloss 3.73607±0.00000  bestvalidloss 3.64472  last_update 37\n",
      "train: iter 548  trainloss 2.12698  validloss 3.72075±0.00000  bestvalidloss 3.64472  last_update 38\n",
      "train: iter 549  trainloss 2.12721  validloss 3.66725±0.00000  bestvalidloss 3.64472  last_update 39\n",
      "train: iter 550  trainloss 2.10815  validloss 3.66250±0.00000  bestvalidloss 3.64472  last_update 40\n",
      "train: iter 551  trainloss 2.10496  validloss 3.77473±0.00000  bestvalidloss 3.64472  last_update 41\n",
      "train: iter 552  trainloss 2.10105  validloss 3.70331±0.00000  bestvalidloss 3.64472  last_update 42\n",
      "train: iter 553  trainloss 2.10740  validloss 3.75116±0.00000  bestvalidloss 3.64472  last_update 43\n",
      "train: iter 554  trainloss 2.11658  validloss 3.78661±0.00000  bestvalidloss 3.64472  last_update 44\n",
      "train: iter 555  trainloss 2.10249  validloss 3.77096±0.00000  bestvalidloss 3.64472  last_update 45\n",
      "train: iter 556  trainloss 2.12573  validloss 3.81433±0.00000  bestvalidloss 3.64472  last_update 46\n",
      "train: iter 557  trainloss 2.09666  validloss 3.73259±0.00000  bestvalidloss 3.64472  last_update 47\n",
      "train: iter 558  trainloss 2.10505  validloss 3.75017±0.00000  bestvalidloss 3.64472  last_update 48\n",
      "train: iter 559  trainloss 2.10068  validloss 3.71784±0.00000  bestvalidloss 3.64472  last_update 49\n",
      "train: iter 560  trainloss 2.12274  validloss 3.77831±0.00000  bestvalidloss 3.64472  last_update 50\n",
      "train: iter 561  trainloss 2.10520  validloss 3.74027±0.00000  bestvalidloss 3.64472  last_update 51\n",
      "train: iter 562  trainloss 2.06976  validloss 3.71129±0.00000  bestvalidloss 3.64472  last_update 52\n",
      "train: iter 563  trainloss 2.11847  validloss 3.70264±0.00000  bestvalidloss 3.64472  last_update 53\n",
      "train: iter 564  trainloss 2.09744  validloss 3.72811±0.00000  bestvalidloss 3.64472  last_update 54\n",
      "train: iter 565  trainloss 2.12465  validloss 3.73774±0.00000  bestvalidloss 3.64472  last_update 55\n",
      "train: iter 566  trainloss 2.10322  validloss 3.69432±0.00000  bestvalidloss 3.64472  last_update 56\n",
      "train: iter 567  trainloss 2.10646  validloss 3.71963±0.00000  bestvalidloss 3.64472  last_update 57\n",
      "train: iter 568  trainloss 2.11663  validloss 3.80834±0.00000  bestvalidloss 3.64472  last_update 58\n",
      "train: iter 569  trainloss 2.09436  validloss 3.75981±0.00000  bestvalidloss 3.64472  last_update 59\n",
      "train: iter 570  trainloss 2.07738  validloss 3.73694±0.00000  bestvalidloss 3.64472  last_update 60\n",
      "train: iter 571  trainloss 2.10920  validloss 3.72853±0.00000  bestvalidloss 3.64472  last_update 61\n",
      "train: iter 572  trainloss 2.11805  validloss 3.78850±0.00000  bestvalidloss 3.64472  last_update 62\n",
      "train: iter 573  trainloss 2.09666  validloss 3.72000±0.00000  bestvalidloss 3.64472  last_update 63\n",
      "train: iter 574  trainloss 2.09357  validloss 3.71766±0.00000  bestvalidloss 3.64472  last_update 64\n",
      "train: iter 575  trainloss 2.08879  validloss 3.71405±0.00000  bestvalidloss 3.64472  last_update 65\n",
      "train: iter 576  trainloss 2.09765  validloss 3.74682±0.00000  bestvalidloss 3.64472  last_update 66\n",
      "train: iter 577  trainloss 2.10604  validloss 3.80517±0.00000  bestvalidloss 3.64472  last_update 67\n",
      "train: iter 578  trainloss 2.09289  validloss 3.70592±0.00000  bestvalidloss 3.64472  last_update 68\n",
      "train: iter 579  trainloss 2.09454  validloss 3.75321±0.00000  bestvalidloss 3.64472  last_update 69\n",
      "train: iter 580  trainloss 2.09739  validloss 3.89758±0.00000  bestvalidloss 3.64472  last_update 70\n",
      "train: iter 581  trainloss 2.11801  validloss 3.76541±0.00000  bestvalidloss 3.64472  last_update 71\n",
      "train: iter 582  trainloss 2.11604  validloss 3.69958±0.00000  bestvalidloss 3.64472  last_update 72\n",
      "train: iter 583  trainloss 2.10748  validloss 3.79002±0.00000  bestvalidloss 3.64472  last_update 73\n",
      "train: iter 584  trainloss 2.10653  validloss 3.68899±0.00000  bestvalidloss 3.64472  last_update 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 585  trainloss 2.10329  validloss 3.67724±0.00000  bestvalidloss 3.64472  last_update 75\n",
      "train: iter 586  trainloss 2.11106  validloss 3.76058±0.00000  bestvalidloss 3.64472  last_update 76\n",
      "train: iter 587  trainloss 2.09901  validloss 3.79984±0.00000  bestvalidloss 3.64472  last_update 77\n",
      "train: iter 588  trainloss 2.08478  validloss 3.76108±0.00000  bestvalidloss 3.64472  last_update 78\n",
      "train: iter 589  trainloss 2.09371  validloss 3.72864±0.00000  bestvalidloss 3.64472  last_update 79\n",
      "train: iter 590  trainloss 2.11812  validloss 3.73054±0.00000  bestvalidloss 3.64472  last_update 80\n",
      "train: iter 591  trainloss 2.08316  validloss 3.72692±0.00000  bestvalidloss 3.64472  last_update 81\n",
      "train: iter 592  trainloss 2.12343  validloss 3.82096±0.00000  bestvalidloss 3.64472  last_update 82\n",
      "train: iter 593  trainloss 2.10435  validloss 3.73498±0.00000  bestvalidloss 3.64472  last_update 83\n",
      "train: iter 594  trainloss 2.09542  validloss 3.68464±0.00000  bestvalidloss 3.64472  last_update 84\n",
      "train: iter 595  trainloss 2.10479  validloss 3.69690±0.00000  bestvalidloss 3.64472  last_update 85\n",
      "train: iter 596  trainloss 2.12711  validloss 3.74594±0.00000  bestvalidloss 3.64472  last_update 86\n",
      "train: iter 597  trainloss 2.12228  validloss 3.78848±0.00000  bestvalidloss 3.64472  last_update 87\n",
      "train: iter 598  trainloss 2.10561  validloss 3.71479±0.00000  bestvalidloss 3.64472  last_update 88\n",
      "train: iter 599  trainloss 2.09538  validloss 3.69998±0.00000  bestvalidloss 3.64472  last_update 89\n",
      "train: iter 600  trainloss 2.09705  validloss 3.76542±0.00000  bestvalidloss 3.64472  last_update 90\n",
      "train: iter 601  trainloss 2.09241  validloss 3.80478±0.00000  bestvalidloss 3.64472  last_update 91\n",
      "train: iter 602  trainloss 2.10147  validloss 3.66230±0.00000  bestvalidloss 3.64472  last_update 92\n",
      "train: iter 603  trainloss 2.10376  validloss 3.75766±0.00000  bestvalidloss 3.64472  last_update 93\n",
      "train: iter 604  trainloss 2.11599  validloss 3.76464±0.00000  bestvalidloss 3.64472  last_update 94\n",
      "train: iter 605  trainloss 2.07711  validloss 3.80731±0.00000  bestvalidloss 3.64472  last_update 95\n",
      "train: iter 606  trainloss 2.09471  validloss 3.68476±0.00000  bestvalidloss 3.64472  last_update 96\n",
      "train: iter 607  trainloss 2.11657  validloss 3.66075±0.00000  bestvalidloss 3.64472  last_update 97\n",
      "train: iter 608  trainloss 2.10097  validloss 3.64991±0.00000  bestvalidloss 3.64472  last_update 98\n",
      "train: iter 609  trainloss 2.07991  validloss 3.78322±0.00000  bestvalidloss 3.64472  last_update 99\n",
      "train: iter 610  trainloss 2.12301  validloss 3.71501±0.00000  bestvalidloss 3.64472  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-3.0259)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-3.4609)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7605639575542602\n",
      "tensor([-0.2419])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
