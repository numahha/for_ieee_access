{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(6804.9561)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 48\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 811.99037  validloss 1884.70680±0.00000  bestvalidloss 1884.70680  last_update 0\n",
      "train: iter 1  trainloss 516.44943  validloss 1207.06611±0.00000  bestvalidloss 1207.06611  last_update 0\n",
      "train: iter 2  trainloss 251.27802  validloss 816.24252±0.00000  bestvalidloss 816.24252  last_update 0\n",
      "train: iter 3  trainloss -39.34919  validloss 576.29206±0.00000  bestvalidloss 576.29206  last_update 0\n",
      "train: iter 4  trainloss -233.59600  validloss 1047.71888±0.00000  bestvalidloss 576.29206  last_update 1\n",
      "train: iter 5  trainloss -380.13708  validloss 241.06332±0.00000  bestvalidloss 241.06332  last_update 0\n",
      "train: iter 6  trainloss -432.29498  validloss 576.52685±0.00000  bestvalidloss 241.06332  last_update 1\n",
      "train: iter 7  trainloss -551.00200  validloss 170.92963±0.00000  bestvalidloss 170.92963  last_update 0\n",
      "train: iter 8  trainloss -680.13999  validloss 482.37117±0.00000  bestvalidloss 170.92963  last_update 1\n",
      "train: iter 9  trainloss -681.32944  validloss 871.89637±0.00000  bestvalidloss 170.92963  last_update 2\n",
      "train: iter 10  trainloss -707.41693  validloss 263.69637±0.00000  bestvalidloss 170.92963  last_update 3\n",
      "train: iter 11  trainloss -711.30424  validloss 24.44949±0.00000  bestvalidloss 24.44949  last_update 0\n",
      "train: iter 12  trainloss -769.97101  validloss 406.56324±0.00000  bestvalidloss 24.44949  last_update 1\n",
      "train: iter 13  trainloss -724.26769  validloss 583.11655±0.00000  bestvalidloss 24.44949  last_update 2\n",
      "train: iter 14  trainloss -872.43158  validloss -7.33092±0.00000  bestvalidloss -7.33092  last_update 0\n",
      "train: iter 15  trainloss -947.46526  validloss 339.27943±0.00000  bestvalidloss -7.33092  last_update 1\n",
      "train: iter 16  trainloss -958.85295  validloss -59.22628±0.00000  bestvalidloss -59.22628  last_update 0\n",
      "train: iter 17  trainloss -998.15542  validloss -321.03191±0.00000  bestvalidloss -321.03191  last_update 0\n",
      "train: iter 18  trainloss -1041.73594  validloss -288.25966±0.00000  bestvalidloss -321.03191  last_update 1\n",
      "train: iter 19  trainloss -1032.23237  validloss -405.99236±0.00000  bestvalidloss -405.99236  last_update 0\n",
      "train: iter 20  trainloss -913.39172  validloss 16.63080±0.00000  bestvalidloss -405.99236  last_update 1\n",
      "train: iter 21  trainloss -1105.01762  validloss -255.62074±0.00000  bestvalidloss -405.99236  last_update 2\n",
      "train: iter 22  trainloss -1040.76959  validloss -351.08957±0.00000  bestvalidloss -405.99236  last_update 3\n",
      "train: iter 23  trainloss -1148.99987  validloss -577.59601±0.00000  bestvalidloss -577.59601  last_update 0\n",
      "train: iter 24  trainloss -1132.67024  validloss -145.53016±0.00000  bestvalidloss -577.59601  last_update 1\n",
      "train: iter 25  trainloss -1099.09747  validloss -498.99791±0.00000  bestvalidloss -577.59601  last_update 2\n",
      "train: iter 26  trainloss -1147.18280  validloss -482.47510±0.00000  bestvalidloss -577.59601  last_update 3\n",
      "train: iter 27  trainloss -1173.44505  validloss -664.49025±0.00000  bestvalidloss -664.49025  last_update 0\n",
      "train: iter 28  trainloss -967.84179  validloss -671.41994±0.00000  bestvalidloss -671.41994  last_update 0\n",
      "train: iter 29  trainloss -1004.80333  validloss -50.40160±0.00000  bestvalidloss -671.41994  last_update 1\n",
      "train: iter 30  trainloss -972.02345  validloss 65.17598±0.00000  bestvalidloss -671.41994  last_update 2\n",
      "train: iter 31  trainloss -1260.15602  validloss -853.40418±0.00000  bestvalidloss -853.40418  last_update 0\n",
      "train: iter 32  trainloss -1253.08651  validloss -868.47434±0.00000  bestvalidloss -868.47434  last_update 0\n",
      "train: iter 33  trainloss -1192.59381  validloss -925.59737±0.00000  bestvalidloss -925.59737  last_update 0\n",
      "train: iter 34  trainloss -1277.75275  validloss -750.80083±0.00000  bestvalidloss -925.59737  last_update 1\n",
      "train: iter 35  trainloss -1204.10654  validloss -916.83505±0.00000  bestvalidloss -925.59737  last_update 2\n",
      "train: iter 36  trainloss -1164.33608  validloss -267.33667±0.00000  bestvalidloss -925.59737  last_update 3\n",
      "train: iter 37  trainloss -1253.76778  validloss -906.58178±0.00000  bestvalidloss -925.59737  last_update 4\n",
      "train: iter 38  trainloss -1324.98371  validloss -891.65104±0.00000  bestvalidloss -925.59737  last_update 5\n",
      "train: iter 39  trainloss -1324.05789  validloss -1014.36402±0.00000  bestvalidloss -1014.36402  last_update 0\n",
      "train: iter 40  trainloss -1319.10469  validloss -982.56480±0.00000  bestvalidloss -1014.36402  last_update 1\n",
      "train: iter 41  trainloss -1314.51402  validloss -956.27198±0.00000  bestvalidloss -1014.36402  last_update 2\n",
      "train: iter 42  trainloss -1335.37560  validloss -1059.98464±0.00000  bestvalidloss -1059.98464  last_update 0\n",
      "train: iter 43  trainloss -1338.88133  validloss -1086.62917±0.00000  bestvalidloss -1086.62917  last_update 0\n",
      "train: iter 44  trainloss -1344.79358  validloss -1093.62215±0.00000  bestvalidloss -1093.62215  last_update 0\n",
      "train: iter 45  trainloss -1273.00400  validloss -1018.58428±0.00000  bestvalidloss -1093.62215  last_update 1\n",
      "train: iter 46  trainloss -1349.69175  validloss -1006.63766±0.00000  bestvalidloss -1093.62215  last_update 2\n",
      "train: iter 47  trainloss -1314.30846  validloss -987.35974±0.00000  bestvalidloss -1093.62215  last_update 3\n",
      "train: iter 48  trainloss -1374.41412  validloss -1047.76341±0.00000  bestvalidloss -1093.62215  last_update 4\n",
      "train: iter 49  trainloss -1364.55759  validloss -1026.34819±0.00000  bestvalidloss -1093.62215  last_update 5\n",
      "train: iter 50  trainloss -1360.48171  validloss -1016.97651±0.00000  bestvalidloss -1093.62215  last_update 6\n",
      "train: iter 51  trainloss -1176.69446  validloss -799.43218±0.00000  bestvalidloss -1093.62215  last_update 7\n",
      "train: iter 52  trainloss -1375.43751  validloss -971.69142±0.00000  bestvalidloss -1093.62215  last_update 8\n",
      "train: iter 53  trainloss -1331.68333  validloss -1064.32468±0.00000  bestvalidloss -1093.62215  last_update 9\n",
      "train: iter 54  trainloss -1080.10223  validloss -843.91827±0.00000  bestvalidloss -1093.62215  last_update 10\n",
      "train: iter 55  trainloss -1233.16230  validloss -723.36097±0.00000  bestvalidloss -1093.62215  last_update 11\n",
      "train: iter 56  trainloss -1368.94058  validloss -896.31197±0.00000  bestvalidloss -1093.62215  last_update 12\n",
      "train: iter 57  trainloss -1414.68241  validloss -1165.91834±0.00000  bestvalidloss -1165.91834  last_update 0\n",
      "train: iter 58  trainloss -1438.39274  validloss -1133.17460±0.00000  bestvalidloss -1165.91834  last_update 1\n",
      "train: iter 59  trainloss -1443.73912  validloss -1200.67014±0.00000  bestvalidloss -1200.67014  last_update 0\n",
      "train: iter 60  trainloss -1367.21298  validloss -1206.75493±0.00000  bestvalidloss -1206.75493  last_update 0\n",
      "train: iter 61  trainloss -1354.25497  validloss -1079.65002±0.00000  bestvalidloss -1206.75493  last_update 1\n",
      "train: iter 62  trainloss -1442.80354  validloss -1055.23890±0.00000  bestvalidloss -1206.75493  last_update 2\n",
      "train: iter 63  trainloss -1371.91425  validloss -1154.85954±0.00000  bestvalidloss -1206.75493  last_update 3\n",
      "train: iter 64  trainloss -1420.06868  validloss -941.67537±0.00000  bestvalidloss -1206.75493  last_update 4\n",
      "train: iter 65  trainloss -1459.47595  validloss -1108.83161±0.00000  bestvalidloss -1206.75493  last_update 5\n",
      "train: iter 66  trainloss -1437.63752  validloss -1112.85928±0.00000  bestvalidloss -1206.75493  last_update 6\n",
      "train: iter 67  trainloss -1366.70685  validloss -767.75535±0.00000  bestvalidloss -1206.75493  last_update 7\n",
      "train: iter 68  trainloss -1435.31673  validloss -1144.81929±0.00000  bestvalidloss -1206.75493  last_update 8\n",
      "train: iter 69  trainloss -1444.69216  validloss -1156.59267±0.00000  bestvalidloss -1206.75493  last_update 9\n",
      "train: iter 70  trainloss -1174.68427  validloss -813.94828±0.00000  bestvalidloss -1206.75493  last_update 10\n",
      "train: iter 71  trainloss -1431.92445  validloss -778.85585±0.00000  bestvalidloss -1206.75493  last_update 11\n",
      "train: iter 72  trainloss -1469.77456  validloss -1052.77918±0.00000  bestvalidloss -1206.75493  last_update 12\n",
      "train: iter 73  trainloss -1508.76315  validloss -1168.54612±0.00000  bestvalidloss -1206.75493  last_update 13\n",
      "train: iter 74  trainloss -1473.77902  validloss -1086.51768±0.00000  bestvalidloss -1206.75493  last_update 14\n",
      "train: iter 75  trainloss -1452.97874  validloss -1196.12190±0.00000  bestvalidloss -1206.75493  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 76  trainloss -1383.45000  validloss -1266.10024±0.00000  bestvalidloss -1266.10024  last_update 0\n",
      "train: iter 77  trainloss -1481.64525  validloss -892.68929±0.00000  bestvalidloss -1266.10024  last_update 1\n",
      "train: iter 78  trainloss -1516.79499  validloss -1123.37563±0.00000  bestvalidloss -1266.10024  last_update 2\n",
      "train: iter 79  trainloss -1485.45048  validloss -1043.54536±0.00000  bestvalidloss -1266.10024  last_update 3\n",
      "train: iter 80  trainloss -1507.88315  validloss -1090.72210±0.00000  bestvalidloss -1266.10024  last_update 4\n",
      "train: iter 81  trainloss -1486.22784  validloss -1191.99656±0.00000  bestvalidloss -1266.10024  last_update 5\n",
      "train: iter 82  trainloss -1497.08965  validloss -1228.57825±0.00000  bestvalidloss -1266.10024  last_update 6\n",
      "train: iter 83  trainloss -1493.02022  validloss -1239.15252±0.00000  bestvalidloss -1266.10024  last_update 7\n",
      "train: iter 84  trainloss -1526.45108  validloss -1132.69709±0.00000  bestvalidloss -1266.10024  last_update 8\n",
      "train: iter 85  trainloss -1558.80823  validloss -1271.78567±0.00000  bestvalidloss -1271.78567  last_update 0\n",
      "train: iter 86  trainloss -1517.78013  validloss -1090.57953±0.00000  bestvalidloss -1271.78567  last_update 1\n",
      "train: iter 87  trainloss -1432.63907  validloss -1282.50403±0.00000  bestvalidloss -1282.50403  last_update 0\n",
      "train: iter 88  trainloss -1546.72146  validloss -1192.09853±0.00000  bestvalidloss -1282.50403  last_update 1\n",
      "train: iter 89  trainloss -1562.66653  validloss -1056.95828±0.00000  bestvalidloss -1282.50403  last_update 2\n",
      "train: iter 90  trainloss -1537.77727  validloss -1330.98137±0.00000  bestvalidloss -1330.98137  last_update 0\n",
      "train: iter 91  trainloss -1517.87005  validloss -1281.33063±0.00000  bestvalidloss -1330.98137  last_update 1\n",
      "train: iter 92  trainloss -1553.52741  validloss -973.65776±0.00000  bestvalidloss -1330.98137  last_update 2\n",
      "train: iter 93  trainloss -1586.68392  validloss -1207.85646±0.00000  bestvalidloss -1330.98137  last_update 3\n",
      "train: iter 94  trainloss -1551.87403  validloss -1095.00166±0.00000  bestvalidloss -1330.98137  last_update 4\n",
      "train: iter 95  trainloss -1496.08942  validloss -829.50709±0.00000  bestvalidloss -1330.98137  last_update 5\n",
      "train: iter 96  trainloss -1534.37017  validloss -1137.93614±0.00000  bestvalidloss -1330.98137  last_update 6\n",
      "train: iter 97  trainloss -1503.32498  validloss -1154.52242±0.00000  bestvalidloss -1330.98137  last_update 7\n",
      "train: iter 98  trainloss -1552.55406  validloss -910.02576±0.00000  bestvalidloss -1330.98137  last_update 8\n",
      "train: iter 99  trainloss -1563.82972  validloss -1311.71120±0.00000  bestvalidloss -1330.98137  last_update 9\n",
      "train: iter 100  trainloss -1578.53563  validloss -1358.73623±0.00000  bestvalidloss -1358.73623  last_update 0\n",
      "train: iter 101  trainloss -1591.93027  validloss -1351.37932±0.00000  bestvalidloss -1358.73623  last_update 1\n",
      "train: iter 102  trainloss -1619.18461  validloss -1263.77029±0.00000  bestvalidloss -1358.73623  last_update 2\n",
      "train: iter 103  trainloss -1511.82986  validloss -1304.20755±0.00000  bestvalidloss -1358.73623  last_update 3\n",
      "train: iter 104  trainloss -1578.21008  validloss -1203.81375±0.00000  bestvalidloss -1358.73623  last_update 4\n",
      "train: iter 105  trainloss -1625.47143  validloss -1369.16926±0.00000  bestvalidloss -1369.16926  last_update 0\n",
      "train: iter 106  trainloss -1572.06247  validloss -1303.86729±0.00000  bestvalidloss -1369.16926  last_update 1\n",
      "train: iter 107  trainloss -1551.41418  validloss -1262.10704±0.00000  bestvalidloss -1369.16926  last_update 2\n",
      "train: iter 108  trainloss -1599.45147  validloss -1238.98216±0.00000  bestvalidloss -1369.16926  last_update 3\n",
      "train: iter 109  trainloss -1624.55996  validloss -1316.01765±0.00000  bestvalidloss -1369.16926  last_update 4\n",
      "train: iter 110  trainloss -1619.66132  validloss -1381.29642±0.00000  bestvalidloss -1381.29642  last_update 0\n",
      "train: iter 111  trainloss -1600.67781  validloss -1298.75232±0.00000  bestvalidloss -1381.29642  last_update 1\n",
      "train: iter 112  trainloss -1536.68322  validloss -1176.96607±0.00000  bestvalidloss -1381.29642  last_update 2\n",
      "train: iter 113  trainloss -1616.64811  validloss -1167.98661±0.00000  bestvalidloss -1381.29642  last_update 3\n",
      "train: iter 114  trainloss -1661.14314  validloss -1282.87993±0.00000  bestvalidloss -1381.29642  last_update 4\n",
      "train: iter 115  trainloss -1561.70398  validloss -1396.47120±0.00000  bestvalidloss -1396.47120  last_update 0\n",
      "train: iter 116  trainloss -1671.09509  validloss -1353.04100±0.00000  bestvalidloss -1396.47120  last_update 1\n",
      "train: iter 117  trainloss -1425.24092  validloss -1019.22614±0.00000  bestvalidloss -1396.47120  last_update 2\n",
      "train: iter 118  trainloss -1629.47457  validloss -1083.48898±0.00000  bestvalidloss -1396.47120  last_update 3\n",
      "train: iter 119  trainloss -1675.16129  validloss -1223.78793±0.00000  bestvalidloss -1396.47120  last_update 4\n",
      "train: iter 120  trainloss -1639.70480  validloss -1212.09824±0.00000  bestvalidloss -1396.47120  last_update 5\n",
      "train: iter 121  trainloss -1691.88424  validloss -1416.72607±0.00000  bestvalidloss -1416.72607  last_update 0\n",
      "train: iter 122  trainloss -1678.41373  validloss -1375.04144±0.00000  bestvalidloss -1416.72607  last_update 1\n",
      "train: iter 123  trainloss -1698.99769  validloss -1215.79634±0.00000  bestvalidloss -1416.72607  last_update 2\n",
      "train: iter 124  trainloss -1682.55983  validloss -1453.54556±0.00000  bestvalidloss -1453.54556  last_update 0\n",
      "train: iter 125  trainloss -1680.73683  validloss -1329.44530±0.00000  bestvalidloss -1453.54556  last_update 1\n",
      "train: iter 126  trainloss -1641.11277  validloss -1050.70421±0.00000  bestvalidloss -1453.54556  last_update 2\n",
      "train: iter 127  trainloss -1722.70651  validloss -1441.31071±0.00000  bestvalidloss -1453.54556  last_update 3\n",
      "train: iter 128  trainloss -1711.83097  validloss -1397.67382±0.00000  bestvalidloss -1453.54556  last_update 4\n",
      "train: iter 129  trainloss -1661.72811  validloss -1326.61194±0.00000  bestvalidloss -1453.54556  last_update 5\n",
      "train: iter 130  trainloss -1661.20174  validloss -1383.06604±0.00000  bestvalidloss -1453.54556  last_update 6\n",
      "train: iter 131  trainloss -1717.39017  validloss -1333.73537±0.00000  bestvalidloss -1453.54556  last_update 7\n",
      "train: iter 132  trainloss -1674.79484  validloss -1495.45185±0.00000  bestvalidloss -1495.45185  last_update 0\n",
      "train: iter 133  trainloss -1701.21870  validloss -1393.60237±0.00000  bestvalidloss -1495.45185  last_update 1\n",
      "train: iter 134  trainloss -1689.53421  validloss -1493.41884±0.00000  bestvalidloss -1495.45185  last_update 2\n",
      "train: iter 135  trainloss -1480.18832  validloss -1137.86314±0.00000  bestvalidloss -1495.45185  last_update 3\n",
      "train: iter 136  trainloss -1682.94894  validloss -1296.57125±0.00000  bestvalidloss -1495.45185  last_update 4\n",
      "train: iter 137  trainloss -1704.20685  validloss -1449.54317±0.00000  bestvalidloss -1495.45185  last_update 5\n",
      "train: iter 138  trainloss -1748.01549  validloss -1345.47603±0.00000  bestvalidloss -1495.45185  last_update 6\n",
      "train: iter 139  trainloss -1726.15987  validloss -1412.34667±0.00000  bestvalidloss -1495.45185  last_update 7\n",
      "train: iter 140  trainloss -1705.00622  validloss -1544.72606±0.00000  bestvalidloss -1544.72606  last_update 0\n",
      "train: iter 141  trainloss -1763.36442  validloss -1478.85157±0.00000  bestvalidloss -1544.72606  last_update 1\n",
      "train: iter 142  trainloss -1695.61560  validloss -1541.47267±0.00000  bestvalidloss -1544.72606  last_update 2\n",
      "train: iter 143  trainloss -1715.34525  validloss -1511.03383±0.00000  bestvalidloss -1544.72606  last_update 3\n",
      "train: iter 144  trainloss -1720.26294  validloss -1110.46251±0.00000  bestvalidloss -1544.72606  last_update 4\n",
      "train: iter 145  trainloss -1750.74724  validloss -1465.89009±0.00000  bestvalidloss -1544.72606  last_update 5\n",
      "train: iter 146  trainloss -1639.55393  validloss -1319.78673±0.00000  bestvalidloss -1544.72606  last_update 6\n",
      "train: iter 147  trainloss -1728.54445  validloss -1220.89108±0.00000  bestvalidloss -1544.72606  last_update 7\n",
      "train: iter 148  trainloss -1710.57648  validloss -1502.90137±0.00000  bestvalidloss -1544.72606  last_update 8\n",
      "train: iter 149  trainloss -1757.63857  validloss -1395.25821±0.00000  bestvalidloss -1544.72606  last_update 9\n",
      "train: iter 150  trainloss -1694.45345  validloss -1276.10855±0.00000  bestvalidloss -1544.72606  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 151  trainloss -1688.68805  validloss -954.79820±0.00000  bestvalidloss -1544.72606  last_update 11\n",
      "train: iter 152  trainloss -1757.50204  validloss -1457.66289±0.00000  bestvalidloss -1544.72606  last_update 12\n",
      "train: iter 153  trainloss -1747.95312  validloss -1552.83727±0.00000  bestvalidloss -1552.83727  last_update 0\n",
      "train: iter 154  trainloss -1751.63857  validloss -1424.05420±0.00000  bestvalidloss -1552.83727  last_update 1\n",
      "train: iter 155  trainloss -1773.81551  validloss -1580.03281±0.00000  bestvalidloss -1580.03281  last_update 0\n",
      "train: iter 156  trainloss -1749.78583  validloss -1577.13195±0.00000  bestvalidloss -1580.03281  last_update 1\n",
      "train: iter 157  trainloss -1745.47585  validloss -1517.39939±0.00000  bestvalidloss -1580.03281  last_update 2\n",
      "train: iter 158  trainloss -1758.87463  validloss -1538.20474±0.00000  bestvalidloss -1580.03281  last_update 3\n",
      "train: iter 159  trainloss -1773.11568  validloss -1519.85997±0.00000  bestvalidloss -1580.03281  last_update 4\n",
      "train: iter 160  trainloss -1787.38426  validloss -1478.22313±0.00000  bestvalidloss -1580.03281  last_update 5\n",
      "train: iter 161  trainloss -1772.77602  validloss -1355.74994±0.00000  bestvalidloss -1580.03281  last_update 6\n",
      "train: iter 162  trainloss -1677.06904  validloss -1548.03094±0.00000  bestvalidloss -1580.03281  last_update 7\n",
      "train: iter 163  trainloss -1764.20829  validloss -1581.96721±0.00000  bestvalidloss -1581.96721  last_update 0\n",
      "train: iter 164  trainloss -1747.85162  validloss -1582.68646±0.00000  bestvalidloss -1582.68646  last_update 0\n",
      "train: iter 165  trainloss -1777.68202  validloss -1348.17621±0.00000  bestvalidloss -1582.68646  last_update 1\n",
      "train: iter 166  trainloss -1655.71669  validloss -1494.65925±0.00000  bestvalidloss -1582.68646  last_update 2\n",
      "train: iter 167  trainloss -1774.26107  validloss -1429.48883±0.00000  bestvalidloss -1582.68646  last_update 3\n",
      "train: iter 168  trainloss -1792.89970  validloss -1590.71889±0.00000  bestvalidloss -1590.71889  last_update 0\n",
      "train: iter 169  trainloss -1804.36169  validloss -1515.81699±0.00000  bestvalidloss -1590.71889  last_update 1\n",
      "train: iter 170  trainloss -1747.42228  validloss -1538.20407±0.00000  bestvalidloss -1590.71889  last_update 2\n",
      "train: iter 171  trainloss -1785.37778  validloss -1182.77075±0.00000  bestvalidloss -1590.71889  last_update 3\n",
      "train: iter 172  trainloss -1786.63095  validloss -1543.76243±0.00000  bestvalidloss -1590.71889  last_update 4\n",
      "train: iter 173  trainloss -1726.89177  validloss -1256.67726±0.00000  bestvalidloss -1590.71889  last_update 5\n",
      "train: iter 174  trainloss -1810.51422  validloss -1535.52930±0.00000  bestvalidloss -1590.71889  last_update 6\n",
      "train: iter 175  trainloss -1819.69433  validloss -1580.01835±0.00000  bestvalidloss -1590.71889  last_update 7\n",
      "train: iter 176  trainloss -1638.42383  validloss -1544.97097±0.00000  bestvalidloss -1590.71889  last_update 8\n",
      "train: iter 177  trainloss -1776.19596  validloss -1347.47589±0.00000  bestvalidloss -1590.71889  last_update 9\n",
      "train: iter 178  trainloss -1829.74851  validloss -1556.10404±0.00000  bestvalidloss -1590.71889  last_update 10\n",
      "train: iter 179  trainloss -1815.21263  validloss -1463.80802±0.00000  bestvalidloss -1590.71889  last_update 11\n",
      "train: iter 180  trainloss -1823.47950  validloss -1623.23421±0.00000  bestvalidloss -1623.23421  last_update 0\n",
      "train: iter 181  trainloss -1642.75800  validloss -1476.79204±0.00000  bestvalidloss -1623.23421  last_update 1\n",
      "train: iter 182  trainloss -1747.72068  validloss -1520.97620±0.00000  bestvalidloss -1623.23421  last_update 2\n",
      "train: iter 183  trainloss -1738.96542  validloss -1289.25347±0.00000  bestvalidloss -1623.23421  last_update 3\n",
      "train: iter 184  trainloss -1826.97242  validloss -1521.91129±0.00000  bestvalidloss -1623.23421  last_update 4\n",
      "train: iter 185  trainloss -1810.38430  validloss -1547.75404±0.00000  bestvalidloss -1623.23421  last_update 5\n",
      "train: iter 186  trainloss -1701.18446  validloss -1555.89395±0.00000  bestvalidloss -1623.23421  last_update 6\n",
      "train: iter 187  trainloss -1792.30558  validloss -1504.92893±0.00000  bestvalidloss -1623.23421  last_update 7\n",
      "train: iter 188  trainloss -1810.60549  validloss -1516.08153±0.00000  bestvalidloss -1623.23421  last_update 8\n",
      "train: iter 189  trainloss -1826.93968  validloss -1563.13716±0.00000  bestvalidloss -1623.23421  last_update 9\n",
      "train: iter 190  trainloss -1816.65451  validloss -1545.42480±0.00000  bestvalidloss -1623.23421  last_update 10\n",
      "train: iter 191  trainloss -1773.65332  validloss -1555.43326±0.00000  bestvalidloss -1623.23421  last_update 11\n",
      "train: iter 192  trainloss -1764.13589  validloss -1454.77045±0.00000  bestvalidloss -1623.23421  last_update 12\n",
      "train: iter 193  trainloss -1835.24541  validloss -1447.91831±0.00000  bestvalidloss -1623.23421  last_update 13\n",
      "train: iter 194  trainloss -1771.72761  validloss -1510.39536±0.00000  bestvalidloss -1623.23421  last_update 14\n",
      "train: iter 195  trainloss -1829.69962  validloss -1503.72055±0.00000  bestvalidloss -1623.23421  last_update 15\n",
      "train: iter 196  trainloss -1843.34926  validloss -1550.41572±0.00000  bestvalidloss -1623.23421  last_update 16\n",
      "train: iter 197  trainloss -1755.40556  validloss -1607.45006±0.00000  bestvalidloss -1623.23421  last_update 17\n",
      "train: iter 198  trainloss -1691.56402  validloss -1339.32509±0.00000  bestvalidloss -1623.23421  last_update 18\n",
      "train: iter 199  trainloss -1804.84653  validloss -1626.83398±0.00000  bestvalidloss -1626.83398  last_update 0\n",
      "train: iter 200  trainloss -1814.58334  validloss -1548.53927±0.00000  bestvalidloss -1626.83398  last_update 1\n",
      "train: iter 201  trainloss -1836.88795  validloss -1535.80498±0.00000  bestvalidloss -1626.83398  last_update 2\n",
      "train: iter 202  trainloss -1822.36740  validloss -1545.66151±0.00000  bestvalidloss -1626.83398  last_update 3\n",
      "train: iter 203  trainloss -1800.73205  validloss -1618.62060±0.00000  bestvalidloss -1626.83398  last_update 4\n",
      "train: iter 204  trainloss -1841.98677  validloss -1546.47791±0.00000  bestvalidloss -1626.83398  last_update 5\n",
      "train: iter 205  trainloss -1799.64876  validloss -1539.62905±0.00000  bestvalidloss -1626.83398  last_update 6\n",
      "train: iter 206  trainloss -1804.92714  validloss -1548.19217±0.00000  bestvalidloss -1626.83398  last_update 7\n",
      "train: iter 207  trainloss -1835.63472  validloss -1571.03375±0.00000  bestvalidloss -1626.83398  last_update 8\n",
      "train: iter 208  trainloss -1857.02120  validloss -1647.22370±0.00000  bestvalidloss -1647.22370  last_update 0\n",
      "train: iter 209  trainloss -1774.97869  validloss -1484.76750±0.00000  bestvalidloss -1647.22370  last_update 1\n",
      "train: iter 210  trainloss -1823.79216  validloss -1516.85098±0.00000  bestvalidloss -1647.22370  last_update 2\n",
      "train: iter 211  trainloss -1803.48957  validloss -1413.25351±0.00000  bestvalidloss -1647.22370  last_update 3\n",
      "train: iter 212  trainloss -1852.15057  validloss -1582.29519±0.00000  bestvalidloss -1647.22370  last_update 4\n",
      "train: iter 213  trainloss -1836.83245  validloss -1504.66934±0.00000  bestvalidloss -1647.22370  last_update 5\n",
      "train: iter 214  trainloss -1747.05860  validloss -1569.39857±0.00000  bestvalidloss -1647.22370  last_update 6\n",
      "train: iter 215  trainloss -1841.98349  validloss -1575.52993±0.00000  bestvalidloss -1647.22370  last_update 7\n",
      "train: iter 216  trainloss -1857.91221  validloss -1300.57023±0.00000  bestvalidloss -1647.22370  last_update 8\n",
      "train: iter 217  trainloss -1797.45498  validloss -1589.81283±0.00000  bestvalidloss -1647.22370  last_update 9\n",
      "train: iter 218  trainloss -1753.94463  validloss -1204.22759±0.00000  bestvalidloss -1647.22370  last_update 10\n",
      "train: iter 219  trainloss -1851.30547  validloss -1594.17543±0.00000  bestvalidloss -1647.22370  last_update 11\n",
      "train: iter 220  trainloss -1840.52490  validloss -1362.12725±0.00000  bestvalidloss -1647.22370  last_update 12\n",
      "train: iter 221  trainloss -1800.27627  validloss -1593.02031±0.00000  bestvalidloss -1647.22370  last_update 13\n",
      "train: iter 222  trainloss -1790.90949  validloss -1537.55821±0.00000  bestvalidloss -1647.22370  last_update 14\n",
      "train: iter 223  trainloss -1850.43996  validloss -1552.61925±0.00000  bestvalidloss -1647.22370  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 224  trainloss -1869.00188  validloss -1565.22387±0.00000  bestvalidloss -1647.22370  last_update 16\n",
      "train: iter 225  trainloss -1847.40459  validloss -1437.21708±0.00000  bestvalidloss -1647.22370  last_update 17\n",
      "train: iter 226  trainloss -1755.89250  validloss -1306.76301±0.00000  bestvalidloss -1647.22370  last_update 18\n",
      "train: iter 227  trainloss -1866.20792  validloss -1556.80643±0.00000  bestvalidloss -1647.22370  last_update 19\n",
      "train: iter 228  trainloss -1683.99239  validloss -1637.41636±0.00000  bestvalidloss -1647.22370  last_update 20\n",
      "train: iter 229  trainloss -1715.61657  validloss 858.45632±0.00000  bestvalidloss -1647.22370  last_update 21\n",
      "train: iter 230  trainloss -1858.59643  validloss -1567.43748±0.00000  bestvalidloss -1647.22370  last_update 22\n",
      "train: iter 231  trainloss -1845.97216  validloss -1581.16841±0.00000  bestvalidloss -1647.22370  last_update 23\n",
      "train: iter 232  trainloss -1864.27672  validloss -1493.27715±0.00000  bestvalidloss -1647.22370  last_update 24\n",
      "train: iter 233  trainloss -1836.53557  validloss -1501.82720±0.00000  bestvalidloss -1647.22370  last_update 25\n",
      "train: iter 234  trainloss -1847.65742  validloss -1562.59373±0.00000  bestvalidloss -1647.22370  last_update 26\n",
      "train: iter 235  trainloss -1855.30400  validloss -1588.04433±0.00000  bestvalidloss -1647.22370  last_update 27\n",
      "train: iter 236  trainloss -1841.73994  validloss -1568.80845±0.00000  bestvalidloss -1647.22370  last_update 28\n",
      "train: iter 237  trainloss -1851.12131  validloss -1636.64258±0.00000  bestvalidloss -1647.22370  last_update 29\n",
      "train: iter 238  trainloss -1872.34524  validloss -1548.91545±0.00000  bestvalidloss -1647.22370  last_update 30\n",
      "train: iter 239  trainloss -1868.74843  validloss -1614.13534±0.00000  bestvalidloss -1647.22370  last_update 31\n",
      "train: iter 240  trainloss -1819.58544  validloss -1593.82916±0.00000  bestvalidloss -1647.22370  last_update 32\n",
      "train: iter 241  trainloss -1796.77755  validloss -1536.88044±0.00000  bestvalidloss -1647.22370  last_update 33\n",
      "train: iter 242  trainloss -1875.11361  validloss -1465.31609±0.00000  bestvalidloss -1647.22370  last_update 34\n",
      "train: iter 243  trainloss -1782.81734  validloss -1529.45784±0.00000  bestvalidloss -1647.22370  last_update 35\n",
      "train: iter 244  trainloss -1822.36795  validloss -1321.79459±0.00000  bestvalidloss -1647.22370  last_update 36\n",
      "train: iter 245  trainloss -1886.92804  validloss -1587.97210±0.00000  bestvalidloss -1647.22370  last_update 37\n",
      "train: iter 246  trainloss -1666.94180  validloss -1579.34708±0.00000  bestvalidloss -1647.22370  last_update 38\n",
      "train: iter 247  trainloss -1703.65583  validloss -1140.98739±0.00000  bestvalidloss -1647.22370  last_update 39\n",
      "train: iter 248  trainloss -1850.40201  validloss -1410.09521±0.00000  bestvalidloss -1647.22370  last_update 40\n",
      "train: iter 249  trainloss -1881.72092  validloss -1517.17569±0.00000  bestvalidloss -1647.22370  last_update 41\n",
      "train: iter 250  trainloss -1836.35794  validloss -1559.10860±0.00000  bestvalidloss -1647.22370  last_update 42\n",
      "train: iter 251  trainloss -1362.34952  validloss -1460.13193±0.00000  bestvalidloss -1647.22370  last_update 43\n",
      "train: iter 252  trainloss -1597.85043  validloss 99.33878±0.00000  bestvalidloss -1647.22370  last_update 44\n",
      "train: iter 253  trainloss -1880.66178  validloss -1624.65128±0.00000  bestvalidloss -1647.22370  last_update 45\n",
      "train: iter 254  trainloss -1881.72526  validloss -1650.24430±0.00000  bestvalidloss -1650.24430  last_update 0\n",
      "train: iter 255  trainloss -1883.74273  validloss -1619.63162±0.00000  bestvalidloss -1650.24430  last_update 1\n",
      "train: iter 256  trainloss -1898.59370  validloss -1618.22711±0.00000  bestvalidloss -1650.24430  last_update 2\n",
      "train: iter 257  trainloss -1889.40876  validloss -1589.81993±0.00000  bestvalidloss -1650.24430  last_update 3\n",
      "train: iter 258  trainloss -1671.22358  validloss -1555.79748±0.00000  bestvalidloss -1650.24430  last_update 4\n",
      "train: iter 259  trainloss -1851.74139  validloss -1259.88995±0.00000  bestvalidloss -1650.24430  last_update 5\n",
      "train: iter 260  trainloss -1882.74227  validloss -1576.68092±0.00000  bestvalidloss -1650.24430  last_update 6\n",
      "train: iter 261  trainloss -1895.00299  validloss -1620.39306±0.00000  bestvalidloss -1650.24430  last_update 7\n",
      "train: iter 262  trainloss -1674.61583  validloss -1596.53342±0.00000  bestvalidloss -1650.24430  last_update 8\n",
      "train: iter 263  trainloss -1837.45530  validloss -1513.63338±0.00000  bestvalidloss -1650.24430  last_update 9\n",
      "train: iter 264  trainloss -1896.25910  validloss -1634.29393±0.00000  bestvalidloss -1650.24430  last_update 10\n",
      "train: iter 265  trainloss -1831.86460  validloss -1544.83453±0.00000  bestvalidloss -1650.24430  last_update 11\n",
      "train: iter 266  trainloss -1886.68873  validloss -1620.10792±0.00000  bestvalidloss -1650.24430  last_update 12\n",
      "train: iter 267  trainloss -1903.21141  validloss -1609.23221±0.00000  bestvalidloss -1650.24430  last_update 13\n",
      "train: iter 268  trainloss -1864.44816  validloss -1564.17917±0.00000  bestvalidloss -1650.24430  last_update 14\n",
      "train: iter 269  trainloss -1894.75206  validloss -1591.10783±0.00000  bestvalidloss -1650.24430  last_update 15\n",
      "train: iter 270  trainloss -1837.23476  validloss -1525.26471±0.00000  bestvalidloss -1650.24430  last_update 16\n",
      "train: iter 271  trainloss -1854.20897  validloss -1504.02434±0.00000  bestvalidloss -1650.24430  last_update 17\n",
      "train: iter 272  trainloss -1875.90817  validloss -1439.69064±0.00000  bestvalidloss -1650.24430  last_update 18\n",
      "train: iter 273  trainloss -1848.67825  validloss -1522.73178±0.00000  bestvalidloss -1650.24430  last_update 19\n",
      "train: iter 274  trainloss -1883.48460  validloss -1435.27489±0.00000  bestvalidloss -1650.24430  last_update 20\n",
      "train: iter 275  trainloss -1861.18057  validloss -1478.92450±0.00000  bestvalidloss -1650.24430  last_update 21\n",
      "train: iter 276  trainloss -1830.14098  validloss -1656.81884±0.00000  bestvalidloss -1656.81884  last_update 0\n",
      "train: iter 277  trainloss -1867.62220  validloss -1425.32030±0.00000  bestvalidloss -1656.81884  last_update 1\n",
      "train: iter 278  trainloss -1896.55343  validloss -1588.23329±0.00000  bestvalidloss -1656.81884  last_update 2\n",
      "train: iter 279  trainloss -1888.74450  validloss -1551.18863±0.00000  bestvalidloss -1656.81884  last_update 3\n",
      "train: iter 280  trainloss -1836.62180  validloss -1516.40709±0.00000  bestvalidloss -1656.81884  last_update 4\n",
      "train: iter 281  trainloss -1858.49926  validloss -1496.52559±0.00000  bestvalidloss -1656.81884  last_update 5\n",
      "train: iter 282  trainloss -1798.84170  validloss -1611.36827±0.00000  bestvalidloss -1656.81884  last_update 6\n",
      "train: iter 283  trainloss -1904.51913  validloss -1593.64617±0.00000  bestvalidloss -1656.81884  last_update 7\n",
      "train: iter 284  trainloss -1899.89502  validloss -1618.77495±0.00000  bestvalidloss -1656.81884  last_update 8\n",
      "train: iter 285  trainloss -1857.60000  validloss -1579.93950±0.00000  bestvalidloss -1656.81884  last_update 9\n",
      "train: iter 286  trainloss -1783.08340  validloss -1165.68770±0.00000  bestvalidloss -1656.81884  last_update 10\n",
      "train: iter 287  trainloss -1827.65620  validloss -1398.67781±0.00000  bestvalidloss -1656.81884  last_update 11\n",
      "train: iter 288  trainloss -1792.06787  validloss -228.12635±0.00000  bestvalidloss -1656.81884  last_update 12\n",
      "train: iter 289  trainloss -1892.05985  validloss -1586.56418±0.00000  bestvalidloss -1656.81884  last_update 13\n",
      "train: iter 290  trainloss -1920.98216  validloss -1582.05334±0.00000  bestvalidloss -1656.81884  last_update 14\n",
      "train: iter 291  trainloss -1888.54091  validloss -1501.18331±0.00000  bestvalidloss -1656.81884  last_update 15\n",
      "train: iter 292  trainloss -1916.63220  validloss -1590.00861±0.00000  bestvalidloss -1656.81884  last_update 16\n",
      "train: iter 293  trainloss -1851.83346  validloss -1486.06530±0.00000  bestvalidloss -1656.81884  last_update 17\n",
      "train: iter 294  trainloss -1881.48658  validloss -1589.66628±0.00000  bestvalidloss -1656.81884  last_update 18\n",
      "train: iter 295  trainloss -1903.65668  validloss -1591.16398±0.00000  bestvalidloss -1656.81884  last_update 19\n",
      "train: iter 296  trainloss -1813.64368  validloss -1636.18452±0.00000  bestvalidloss -1656.81884  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 297  trainloss -1865.70897  validloss -1649.12667±0.00000  bestvalidloss -1656.81884  last_update 21\n",
      "train: iter 298  trainloss -1878.03377  validloss -1336.66782±0.00000  bestvalidloss -1656.81884  last_update 22\n",
      "train: iter 299  trainloss -1890.61904  validloss -1645.59721±0.00000  bestvalidloss -1656.81884  last_update 23\n",
      "train: iter 300  trainloss -1757.25515  validloss -1403.56330±0.00000  bestvalidloss -1656.81884  last_update 24\n",
      "train: iter 301  trainloss -1840.02513  validloss -1434.63659±0.00000  bestvalidloss -1656.81884  last_update 25\n",
      "train: iter 302  trainloss -1910.81600  validloss -1525.70471±0.00000  bestvalidloss -1656.81884  last_update 26\n",
      "train: iter 303  trainloss -1894.29229  validloss -1572.88419±0.00000  bestvalidloss -1656.81884  last_update 27\n",
      "train: iter 304  trainloss -1919.44054  validloss -1648.01320±0.00000  bestvalidloss -1656.81884  last_update 28\n",
      "train: iter 305  trainloss -1849.69548  validloss -1621.79391±0.00000  bestvalidloss -1656.81884  last_update 29\n",
      "train: iter 306  trainloss -1789.95610  validloss -1616.47454±0.00000  bestvalidloss -1656.81884  last_update 30\n",
      "train: iter 307  trainloss -1873.80831  validloss -1572.67661±0.00000  bestvalidloss -1656.81884  last_update 31\n",
      "train: iter 308  trainloss -1892.13177  validloss -1641.24989±0.00000  bestvalidloss -1656.81884  last_update 32\n",
      "train: iter 309  trainloss -1925.04987  validloss -1653.70318±0.00000  bestvalidloss -1656.81884  last_update 33\n",
      "train: iter 310  trainloss -1867.65684  validloss -1437.59529±0.00000  bestvalidloss -1656.81884  last_update 34\n",
      "train: iter 311  trainloss -1832.37551  validloss -1571.72597±0.00000  bestvalidloss -1656.81884  last_update 35\n",
      "train: iter 312  trainloss -1860.27231  validloss -1226.91644±0.00000  bestvalidloss -1656.81884  last_update 36\n",
      "train: iter 313  trainloss -1898.34701  validloss -1568.50885±0.00000  bestvalidloss -1656.81884  last_update 37\n",
      "train: iter 314  trainloss -1868.48456  validloss -1581.55818±0.00000  bestvalidloss -1656.81884  last_update 38\n",
      "train: iter 315  trainloss -1911.73242  validloss -1620.71339±0.00000  bestvalidloss -1656.81884  last_update 39\n",
      "train: iter 316  trainloss -1931.88443  validloss -1662.72332±0.00000  bestvalidloss -1662.72332  last_update 0\n",
      "train: iter 317  trainloss -1897.13445  validloss -1635.05592±0.00000  bestvalidloss -1662.72332  last_update 1\n",
      "train: iter 318  trainloss -1601.83886  validloss -1392.46725±0.00000  bestvalidloss -1662.72332  last_update 2\n",
      "train: iter 319  trainloss -1850.91751  validloss -1447.96140±0.00000  bestvalidloss -1662.72332  last_update 3\n",
      "train: iter 320  trainloss -1892.51238  validloss -1631.29241±0.00000  bestvalidloss -1662.72332  last_update 4\n",
      "train: iter 321  trainloss -1926.95675  validloss -1688.60905±0.00000  bestvalidloss -1688.60905  last_update 0\n",
      "train: iter 322  trainloss -1874.49596  validloss -1644.23571±0.00000  bestvalidloss -1688.60905  last_update 1\n",
      "train: iter 323  trainloss -1863.05367  validloss -1438.25894±0.00000  bestvalidloss -1688.60905  last_update 2\n",
      "train: iter 324  trainloss -1919.92828  validloss -1560.90334±0.00000  bestvalidloss -1688.60905  last_update 3\n",
      "train: iter 325  trainloss -1913.48783  validloss -1650.75103±0.00000  bestvalidloss -1688.60905  last_update 4\n",
      "train: iter 326  trainloss -1936.93183  validloss -1618.26950±0.00000  bestvalidloss -1688.60905  last_update 5\n",
      "train: iter 327  trainloss -1912.97104  validloss -1553.52382±0.00000  bestvalidloss -1688.60905  last_update 6\n",
      "train: iter 328  trainloss -1495.15160  validloss -941.39141±0.00000  bestvalidloss -1688.60905  last_update 7\n",
      "train: iter 329  trainloss -1888.81652  validloss -1514.64085±0.00000  bestvalidloss -1688.60905  last_update 8\n",
      "train: iter 330  trainloss -1898.00488  validloss -1612.92216±0.00000  bestvalidloss -1688.60905  last_update 9\n",
      "train: iter 331  trainloss -1924.46865  validloss -1676.28354±0.00000  bestvalidloss -1688.60905  last_update 10\n",
      "train: iter 332  trainloss -1900.31293  validloss -1671.46906±0.00000  bestvalidloss -1688.60905  last_update 11\n",
      "train: iter 333  trainloss -1839.37081  validloss -1605.00768±0.00000  bestvalidloss -1688.60905  last_update 12\n",
      "train: iter 334  trainloss -1915.26844  validloss -1603.38665±0.00000  bestvalidloss -1688.60905  last_update 13\n",
      "train: iter 335  trainloss -1873.23406  validloss -1595.35316±0.00000  bestvalidloss -1688.60905  last_update 14\n",
      "train: iter 336  trainloss -1862.47358  validloss -1379.28840±0.00000  bestvalidloss -1688.60905  last_update 15\n",
      "train: iter 337  trainloss -1938.47442  validloss -1652.66067±0.00000  bestvalidloss -1688.60905  last_update 16\n",
      "train: iter 338  trainloss -1914.07127  validloss -1622.22032±0.00000  bestvalidloss -1688.60905  last_update 17\n",
      "train: iter 339  trainloss -1878.47194  validloss -1527.36450±0.00000  bestvalidloss -1688.60905  last_update 18\n",
      "train: iter 340  trainloss -1923.95335  validloss -1662.85404±0.00000  bestvalidloss -1688.60905  last_update 19\n",
      "train: iter 341  trainloss -1877.71712  validloss -1649.50719±0.00000  bestvalidloss -1688.60905  last_update 20\n",
      "train: iter 342  trainloss -1935.74769  validloss -1712.62327±0.00000  bestvalidloss -1712.62327  last_update 0\n",
      "train: iter 343  trainloss -1824.17896  validloss -1705.68025±0.00000  bestvalidloss -1712.62327  last_update 1\n",
      "train: iter 344  trainloss -1828.83592  validloss -1160.75031±0.00000  bestvalidloss -1712.62327  last_update 2\n",
      "train: iter 345  trainloss -1931.96370  validloss -1639.70023±0.00000  bestvalidloss -1712.62327  last_update 3\n",
      "train: iter 346  trainloss -1909.03299  validloss -1668.25885±0.00000  bestvalidloss -1712.62327  last_update 4\n",
      "train: iter 347  trainloss -1926.48859  validloss -1688.51984±0.00000  bestvalidloss -1712.62327  last_update 5\n",
      "train: iter 348  trainloss -1912.25829  validloss -1687.35325±0.00000  bestvalidloss -1712.62327  last_update 6\n",
      "train: iter 349  trainloss -1925.30441  validloss -1609.42388±0.00000  bestvalidloss -1712.62327  last_update 7\n",
      "train: iter 350  trainloss -1817.94687  validloss -1630.37817±0.00000  bestvalidloss -1712.62327  last_update 8\n",
      "train: iter 351  trainloss -1868.79474  validloss -1565.12261±0.00000  bestvalidloss -1712.62327  last_update 9\n",
      "train: iter 352  trainloss -1797.63821  validloss -1532.83357±0.00000  bestvalidloss -1712.62327  last_update 10\n",
      "train: iter 353  trainloss -1929.95974  validloss -1647.12603±0.00000  bestvalidloss -1712.62327  last_update 11\n",
      "train: iter 354  trainloss -1937.38313  validloss -1660.70293±0.00000  bestvalidloss -1712.62327  last_update 12\n",
      "train: iter 355  trainloss -1767.87678  validloss -1634.87690±0.00000  bestvalidloss -1712.62327  last_update 13\n",
      "train: iter 356  trainloss -1935.80196  validloss -1618.41798±0.00000  bestvalidloss -1712.62327  last_update 14\n",
      "train: iter 357  trainloss -1897.06224  validloss -1672.24462±0.00000  bestvalidloss -1712.62327  last_update 15\n",
      "train: iter 358  trainloss -1902.36324  validloss -1644.85279±0.00000  bestvalidloss -1712.62327  last_update 16\n",
      "train: iter 359  trainloss -1947.60651  validloss -1694.15128±0.00000  bestvalidloss -1712.62327  last_update 17\n",
      "train: iter 360  trainloss -1807.36432  validloss -1594.81316±0.00000  bestvalidloss -1712.62327  last_update 18\n",
      "train: iter 361  trainloss -1921.08062  validloss -1641.55603±0.00000  bestvalidloss -1712.62327  last_update 19\n",
      "train: iter 362  trainloss -1915.93452  validloss -1646.85417±0.00000  bestvalidloss -1712.62327  last_update 20\n",
      "train: iter 363  trainloss -1896.31632  validloss -1694.89517±0.00000  bestvalidloss -1712.62327  last_update 21\n",
      "train: iter 364  trainloss -1941.87257  validloss -1714.76440±0.00000  bestvalidloss -1714.76440  last_update 0\n",
      "train: iter 365  trainloss -1899.29945  validloss -1659.67937±0.00000  bestvalidloss -1714.76440  last_update 1\n",
      "train: iter 366  trainloss -1950.41291  validloss -1706.26445±0.00000  bestvalidloss -1714.76440  last_update 2\n",
      "train: iter 367  trainloss -1930.15591  validloss -1642.56293±0.00000  bestvalidloss -1714.76440  last_update 3\n",
      "train: iter 368  trainloss -1913.39165  validloss -1613.99582±0.00000  bestvalidloss -1714.76440  last_update 4\n",
      "train: iter 369  trainloss -1873.77828  validloss -1594.79971±0.00000  bestvalidloss -1714.76440  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 370  trainloss -1817.01575  validloss -952.83616±0.00000  bestvalidloss -1714.76440  last_update 6\n",
      "train: iter 371  trainloss -1942.76421  validloss -1693.10745±0.00000  bestvalidloss -1714.76440  last_update 7\n",
      "train: iter 372  trainloss -1931.25977  validloss -1630.51868±0.00000  bestvalidloss -1714.76440  last_update 8\n",
      "train: iter 373  trainloss -1803.87529  validloss -1640.98632±0.00000  bestvalidloss -1714.76440  last_update 9\n",
      "train: iter 374  trainloss -1830.86079  validloss -103.16416±0.00000  bestvalidloss -1714.76440  last_update 10\n",
      "train: iter 375  trainloss -1932.47470  validloss -1709.07160±0.00000  bestvalidloss -1714.76440  last_update 11\n",
      "train: iter 376  trainloss -1917.22451  validloss -1680.09379±0.00000  bestvalidloss -1714.76440  last_update 12\n",
      "train: iter 377  trainloss -1912.00082  validloss -1685.53022±0.00000  bestvalidloss -1714.76440  last_update 13\n",
      "train: iter 378  trainloss -1845.70030  validloss -1471.83352±0.00000  bestvalidloss -1714.76440  last_update 14\n",
      "train: iter 379  trainloss -1877.92260  validloss -1625.33173±0.00000  bestvalidloss -1714.76440  last_update 15\n",
      "train: iter 380  trainloss -1942.41796  validloss -1666.10266±0.00000  bestvalidloss -1714.76440  last_update 16\n",
      "train: iter 381  trainloss -1910.10775  validloss -1649.34711±0.00000  bestvalidloss -1714.76440  last_update 17\n",
      "train: iter 382  trainloss -1962.06053  validloss -1760.11153±0.00000  bestvalidloss -1760.11153  last_update 0\n",
      "train: iter 383  trainloss -1909.32941  validloss -1731.77219±0.00000  bestvalidloss -1760.11153  last_update 1\n",
      "train: iter 384  trainloss -1922.67829  validloss -1738.75116±0.00000  bestvalidloss -1760.11153  last_update 2\n",
      "train: iter 385  trainloss -1961.43855  validloss -1724.10316±0.00000  bestvalidloss -1760.11153  last_update 3\n",
      "train: iter 386  trainloss -1909.77638  validloss -1699.68607±0.00000  bestvalidloss -1760.11153  last_update 4\n",
      "train: iter 387  trainloss -1852.63838  validloss -1647.20985±0.00000  bestvalidloss -1760.11153  last_update 5\n",
      "train: iter 388  trainloss -1901.26325  validloss -1683.74647±0.00000  bestvalidloss -1760.11153  last_update 6\n",
      "train: iter 389  trainloss -1944.29907  validloss -1565.29548±0.00000  bestvalidloss -1760.11153  last_update 7\n",
      "train: iter 390  trainloss -1928.40249  validloss -1715.94685±0.00000  bestvalidloss -1760.11153  last_update 8\n",
      "train: iter 391  trainloss -1962.34699  validloss -1659.83817±0.00000  bestvalidloss -1760.11153  last_update 9\n",
      "train: iter 392  trainloss -1826.15124  validloss -1650.55995±0.00000  bestvalidloss -1760.11153  last_update 10\n",
      "train: iter 393  trainloss -1942.36541  validloss -1682.96296±0.00000  bestvalidloss -1760.11153  last_update 11\n",
      "train: iter 394  trainloss -1953.61967  validloss -1681.59167±0.00000  bestvalidloss -1760.11153  last_update 12\n",
      "train: iter 395  trainloss -1845.99213  validloss -1683.30858±0.00000  bestvalidloss -1760.11153  last_update 13\n",
      "train: iter 396  trainloss -1938.02648  validloss -1680.76244±0.00000  bestvalidloss -1760.11153  last_update 14\n",
      "train: iter 397  trainloss -1950.60215  validloss -1696.04680±0.00000  bestvalidloss -1760.11153  last_update 15\n",
      "train: iter 398  trainloss -1886.90791  validloss -1689.75117±0.00000  bestvalidloss -1760.11153  last_update 16\n",
      "train: iter 399  trainloss -1792.84941  validloss -1435.20114±0.00000  bestvalidloss -1760.11153  last_update 17\n",
      "train: iter 400  trainloss -1952.83497  validloss -1692.61952±0.00000  bestvalidloss -1760.11153  last_update 18\n",
      "train: iter 401  trainloss -1946.00022  validloss -1688.37356±0.00000  bestvalidloss -1760.11153  last_update 19\n",
      "train: iter 402  trainloss -1954.03019  validloss -1526.95332±0.00000  bestvalidloss -1760.11153  last_update 20\n",
      "train: iter 403  trainloss -1963.50576  validloss -1732.80153±0.00000  bestvalidloss -1760.11153  last_update 21\n",
      "train: iter 404  trainloss -1849.15217  validloss -1731.43723±0.00000  bestvalidloss -1760.11153  last_update 22\n",
      "train: iter 405  trainloss -1879.00608  validloss -1469.66772±0.00000  bestvalidloss -1760.11153  last_update 23\n",
      "train: iter 406  trainloss -1823.30750  validloss -1667.07859±0.00000  bestvalidloss -1760.11153  last_update 24\n",
      "train: iter 407  trainloss -1942.61901  validloss -1743.12248±0.00000  bestvalidloss -1760.11153  last_update 25\n",
      "train: iter 408  trainloss -1953.34370  validloss -1766.95202±0.00000  bestvalidloss -1766.95202  last_update 0\n",
      "train: iter 409  trainloss -1934.24172  validloss -1680.43659±0.00000  bestvalidloss -1766.95202  last_update 1\n",
      "train: iter 410  trainloss -1961.84626  validloss -1736.59995±0.00000  bestvalidloss -1766.95202  last_update 2\n",
      "train: iter 411  trainloss -1921.93827  validloss -1672.05543±0.00000  bestvalidloss -1766.95202  last_update 3\n",
      "train: iter 412  trainloss -1968.28024  validloss -1712.54212±0.00000  bestvalidloss -1766.95202  last_update 4\n",
      "train: iter 413  trainloss -1924.30072  validloss -1736.73368±0.00000  bestvalidloss -1766.95202  last_update 5\n",
      "train: iter 414  trainloss -1890.21865  validloss -1706.68433±0.00000  bestvalidloss -1766.95202  last_update 6\n",
      "train: iter 415  trainloss -1923.10016  validloss -1732.64939±0.00000  bestvalidloss -1766.95202  last_update 7\n",
      "train: iter 416  trainloss -1934.10749  validloss -1744.26173±0.00000  bestvalidloss -1766.95202  last_update 8\n",
      "train: iter 417  trainloss -1921.21842  validloss -1709.15491±0.00000  bestvalidloss -1766.95202  last_update 9\n",
      "train: iter 418  trainloss -1921.88304  validloss -1741.84064±0.00000  bestvalidloss -1766.95202  last_update 10\n",
      "train: iter 419  trainloss -1950.80796  validloss -1591.18979±0.00000  bestvalidloss -1766.95202  last_update 11\n",
      "train: iter 420  trainloss -1971.31693  validloss -1760.62867±0.00000  bestvalidloss -1766.95202  last_update 12\n",
      "train: iter 421  trainloss -1873.91020  validloss -1693.40301±0.00000  bestvalidloss -1766.95202  last_update 13\n",
      "train: iter 422  trainloss -1919.02769  validloss -1605.75034±0.00000  bestvalidloss -1766.95202  last_update 14\n",
      "train: iter 423  trainloss -1911.39608  validloss -1684.70251±0.00000  bestvalidloss -1766.95202  last_update 15\n",
      "train: iter 424  trainloss -1887.11776  validloss -1312.19713±0.00000  bestvalidloss -1766.95202  last_update 16\n",
      "train: iter 425  trainloss -1918.15213  validloss -1392.16708±0.00000  bestvalidloss -1766.95202  last_update 17\n",
      "train: iter 426  trainloss -1905.51317  validloss -1706.40697±0.00000  bestvalidloss -1766.95202  last_update 18\n",
      "train: iter 427  trainloss -1834.59699  validloss -1486.13304±0.00000  bestvalidloss -1766.95202  last_update 19\n",
      "train: iter 428  trainloss -1955.50858  validloss -1740.87435±0.00000  bestvalidloss -1766.95202  last_update 20\n",
      "train: iter 429  trainloss -1939.64755  validloss -1717.62860±0.00000  bestvalidloss -1766.95202  last_update 21\n",
      "train: iter 430  trainloss -1973.45993  validloss -1712.94187±0.00000  bestvalidloss -1766.95202  last_update 22\n",
      "train: iter 431  trainloss -1928.17666  validloss -1760.07801±0.00000  bestvalidloss -1766.95202  last_update 23\n",
      "train: iter 432  trainloss -1848.34875  validloss -1677.57931±0.00000  bestvalidloss -1766.95202  last_update 24\n",
      "train: iter 433  trainloss -1952.19683  validloss -1752.24933±0.00000  bestvalidloss -1766.95202  last_update 25\n",
      "train: iter 434  trainloss -1978.79078  validloss -1735.81262±0.00000  bestvalidloss -1766.95202  last_update 26\n",
      "train: iter 435  trainloss -1727.01823  validloss -1762.91228±0.00000  bestvalidloss -1766.95202  last_update 27\n",
      "train: iter 436  trainloss -1770.93340  validloss -629.66489±0.00000  bestvalidloss -1766.95202  last_update 28\n",
      "train: iter 437  trainloss -1938.68064  validloss -1656.98431±0.00000  bestvalidloss -1766.95202  last_update 29\n",
      "train: iter 438  trainloss -1956.99391  validloss -1676.60436±0.00000  bestvalidloss -1766.95202  last_update 30\n",
      "train: iter 439  trainloss -1960.48567  validloss -1770.05460±0.00000  bestvalidloss -1770.05460  last_update 0\n",
      "train: iter 440  trainloss -1974.36025  validloss -1752.07758±0.00000  bestvalidloss -1770.05460  last_update 1\n",
      "train: iter 441  trainloss -1959.86329  validloss -1714.53513±0.00000  bestvalidloss -1770.05460  last_update 2\n",
      "train: iter 442  trainloss -1898.94975  validloss -1601.95041±0.00000  bestvalidloss -1770.05460  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 443  trainloss -1712.45355  validloss -1597.64471±0.00000  bestvalidloss -1770.05460  last_update 4\n",
      "train: iter 444  trainloss -1917.96922  validloss -1677.59630±0.00000  bestvalidloss -1770.05460  last_update 5\n",
      "train: iter 445  trainloss -1960.64836  validloss -1751.64859±0.00000  bestvalidloss -1770.05460  last_update 6\n",
      "train: iter 446  trainloss -1956.33789  validloss -1754.36875±0.00000  bestvalidloss -1770.05460  last_update 7\n",
      "train: iter 447  trainloss -1956.29289  validloss -1671.56680±0.00000  bestvalidloss -1770.05460  last_update 8\n",
      "train: iter 448  trainloss -1962.41346  validloss -1720.58911±0.00000  bestvalidloss -1770.05460  last_update 9\n",
      "train: iter 449  trainloss -1935.61548  validloss -1617.72348±0.00000  bestvalidloss -1770.05460  last_update 10\n",
      "train: iter 450  trainloss -1877.29270  validloss -1683.34752±0.00000  bestvalidloss -1770.05460  last_update 11\n",
      "train: iter 451  trainloss -1972.12254  validloss -1660.77722±0.00000  bestvalidloss -1770.05460  last_update 12\n",
      "train: iter 452  trainloss -1790.82446  validloss -1624.99467±0.00000  bestvalidloss -1770.05460  last_update 13\n",
      "train: iter 453  trainloss -1970.07410  validloss -1707.59191±0.00000  bestvalidloss -1770.05460  last_update 14\n",
      "train: iter 454  trainloss -1960.96367  validloss -1761.47195±0.00000  bestvalidloss -1770.05460  last_update 15\n",
      "train: iter 455  trainloss -1955.89799  validloss -1759.21323±0.00000  bestvalidloss -1770.05460  last_update 16\n",
      "train: iter 456  trainloss -1953.65148  validloss -1740.79524±0.00000  bestvalidloss -1770.05460  last_update 17\n",
      "train: iter 457  trainloss -1944.27928  validloss -1659.30061±0.00000  bestvalidloss -1770.05460  last_update 18\n",
      "train: iter 458  trainloss -1954.29163  validloss -1690.73447±0.00000  bestvalidloss -1770.05460  last_update 19\n",
      "train: iter 459  trainloss -1964.26516  validloss -1671.70603±0.00000  bestvalidloss -1770.05460  last_update 20\n",
      "train: iter 460  trainloss -1944.93859  validloss -1720.25887±0.00000  bestvalidloss -1770.05460  last_update 21\n",
      "train: iter 461  trainloss -1878.65302  validloss -1732.11248±0.00000  bestvalidloss -1770.05460  last_update 22\n",
      "train: iter 462  trainloss -1969.07818  validloss -1721.35779±0.00000  bestvalidloss -1770.05460  last_update 23\n",
      "train: iter 463  trainloss -1965.24467  validloss -1764.15492±0.00000  bestvalidloss -1770.05460  last_update 24\n",
      "train: iter 464  trainloss -1939.93183  validloss -1734.62445±0.00000  bestvalidloss -1770.05460  last_update 25\n",
      "train: iter 465  trainloss -1886.11049  validloss -1599.23142±0.00000  bestvalidloss -1770.05460  last_update 26\n",
      "train: iter 466  trainloss -1904.85673  validloss -1595.16258±0.00000  bestvalidloss -1770.05460  last_update 27\n",
      "train: iter 467  trainloss -1910.08107  validloss -1096.33271±0.00000  bestvalidloss -1770.05460  last_update 28\n",
      "train: iter 468  trainloss -1963.48091  validloss -1714.63516±0.00000  bestvalidloss -1770.05460  last_update 29\n",
      "train: iter 469  trainloss -1983.33835  validloss -1718.63768±0.00000  bestvalidloss -1770.05460  last_update 30\n",
      "train: iter 470  trainloss -1971.88648  validloss -1605.91737±0.00000  bestvalidloss -1770.05460  last_update 31\n",
      "train: iter 471  trainloss -1909.09295  validloss -1645.00307±0.00000  bestvalidloss -1770.05460  last_update 32\n",
      "train: iter 472  trainloss -1973.41392  validloss -1606.63078±0.00000  bestvalidloss -1770.05460  last_update 33\n",
      "train: iter 473  trainloss -1812.24096  validloss -1415.68070±0.00000  bestvalidloss -1770.05460  last_update 34\n",
      "train: iter 474  trainloss -1968.25875  validloss -1661.12229±0.00000  bestvalidloss -1770.05460  last_update 35\n",
      "train: iter 475  trainloss -1977.74641  validloss -1716.37079±0.00000  bestvalidloss -1770.05460  last_update 36\n",
      "train: iter 476  trainloss -1979.10886  validloss -1778.19224±0.00000  bestvalidloss -1778.19224  last_update 0\n",
      "train: iter 477  trainloss -1981.57905  validloss -1735.76845±0.00000  bestvalidloss -1778.19224  last_update 1\n",
      "train: iter 478  trainloss -1813.49594  validloss -1672.11379±0.00000  bestvalidloss -1778.19224  last_update 2\n",
      "train: iter 479  trainloss -1920.45193  validloss -1697.36182±0.00000  bestvalidloss -1778.19224  last_update 3\n",
      "train: iter 480  trainloss -1875.45183  validloss -1472.75744±0.00000  bestvalidloss -1778.19224  last_update 4\n",
      "train: iter 481  trainloss -1911.12278  validloss -1687.44677±0.00000  bestvalidloss -1778.19224  last_update 5\n",
      "train: iter 482  trainloss -1974.65701  validloss -1748.63689±0.00000  bestvalidloss -1778.19224  last_update 6\n",
      "train: iter 483  trainloss -1959.30337  validloss -1777.57019±0.00000  bestvalidloss -1778.19224  last_update 7\n",
      "train: iter 484  trainloss -1856.73608  validloss -1745.47327±0.00000  bestvalidloss -1778.19224  last_update 8\n",
      "train: iter 485  trainloss -1945.36521  validloss -1637.69789±0.00000  bestvalidloss -1778.19224  last_update 9\n",
      "train: iter 486  trainloss -1975.02170  validloss -1734.63456±0.00000  bestvalidloss -1778.19224  last_update 10\n",
      "train: iter 487  trainloss -1792.79097  validloss -1355.80936±0.00000  bestvalidloss -1778.19224  last_update 11\n",
      "train: iter 488  trainloss -1912.28258  validloss -1508.56146±0.00000  bestvalidloss -1778.19224  last_update 12\n",
      "train: iter 489  trainloss -1970.65901  validloss -1735.18749±0.00000  bestvalidloss -1778.19224  last_update 13\n",
      "train: iter 490  trainloss -1971.93053  validloss -1744.96889±0.00000  bestvalidloss -1778.19224  last_update 14\n",
      "train: iter 491  trainloss -1984.98116  validloss -1783.32492±0.00000  bestvalidloss -1783.32492  last_update 0\n",
      "train: iter 492  trainloss -1978.91278  validloss -1796.17793±0.00000  bestvalidloss -1796.17793  last_update 0\n",
      "train: iter 493  trainloss -1988.81161  validloss -1789.01298±0.00000  bestvalidloss -1796.17793  last_update 1\n",
      "train: iter 494  trainloss -1952.36148  validloss -1801.76362±0.00000  bestvalidloss -1801.76362  last_update 0\n",
      "train: iter 495  trainloss -1932.49074  validloss -1804.22429±0.00000  bestvalidloss -1804.22429  last_update 0\n",
      "train: iter 496  trainloss -1882.06875  validloss -1727.27518±0.00000  bestvalidloss -1804.22429  last_update 1\n",
      "train: iter 497  trainloss -1893.00242  validloss -1736.05952±0.00000  bestvalidloss -1804.22429  last_update 2\n",
      "train: iter 498  trainloss -1948.05645  validloss -1724.21801±0.00000  bestvalidloss -1804.22429  last_update 3\n",
      "train: iter 499  trainloss -1978.29121  validloss -1760.24231±0.00000  bestvalidloss -1804.22429  last_update 4\n",
      "train: iter 500  trainloss -1974.90331  validloss -1705.64744±0.00000  bestvalidloss -1804.22429  last_update 5\n",
      "train: iter 501  trainloss -1865.20674  validloss -1595.13874±0.00000  bestvalidloss -1804.22429  last_update 6\n",
      "train: iter 502  trainloss -1976.41737  validloss -1690.96442±0.00000  bestvalidloss -1804.22429  last_update 7\n",
      "train: iter 503  trainloss -1944.59529  validloss -1725.38014±0.00000  bestvalidloss -1804.22429  last_update 8\n",
      "train: iter 504  trainloss -1988.63211  validloss -1781.42170±0.00000  bestvalidloss -1804.22429  last_update 9\n",
      "train: iter 505  trainloss -1983.52984  validloss -1733.66688±0.00000  bestvalidloss -1804.22429  last_update 10\n",
      "train: iter 506  trainloss -1851.55998  validloss -1611.29713±0.00000  bestvalidloss -1804.22429  last_update 11\n",
      "train: iter 507  trainloss -1977.81137  validloss -1730.81534±0.00000  bestvalidloss -1804.22429  last_update 12\n",
      "train: iter 508  trainloss -1978.68103  validloss -1708.66281±0.00000  bestvalidloss -1804.22429  last_update 13\n",
      "train: iter 509  trainloss -1993.44598  validloss -1783.79658±0.00000  bestvalidloss -1804.22429  last_update 14\n",
      "train: iter 510  trainloss -1928.88036  validloss -1746.98422±0.00000  bestvalidloss -1804.22429  last_update 15\n",
      "train: iter 511  trainloss -1968.92116  validloss -1692.65340±0.00000  bestvalidloss -1804.22429  last_update 16\n",
      "train: iter 512  trainloss -1936.75316  validloss -1393.09950±0.00000  bestvalidloss -1804.22429  last_update 17\n",
      "train: iter 513  trainloss -1814.46925  validloss -1709.72972±0.00000  bestvalidloss -1804.22429  last_update 18\n",
      "train: iter 514  trainloss -1927.93387  validloss -1668.93879±0.00000  bestvalidloss -1804.22429  last_update 19\n",
      "train: iter 515  trainloss -1979.94377  validloss -1778.22685±0.00000  bestvalidloss -1804.22429  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 516  trainloss -1991.06281  validloss -1782.90362±0.00000  bestvalidloss -1804.22429  last_update 21\n",
      "train: iter 517  trainloss -1987.28576  validloss -1813.62032±0.00000  bestvalidloss -1813.62032  last_update 0\n",
      "train: iter 518  trainloss -1898.47065  validloss -1681.59947±0.00000  bestvalidloss -1813.62032  last_update 1\n",
      "train: iter 519  trainloss -1929.62637  validloss -1621.53121±0.00000  bestvalidloss -1813.62032  last_update 2\n",
      "train: iter 520  trainloss -1972.52572  validloss -1780.35853±0.00000  bestvalidloss -1813.62032  last_update 3\n",
      "train: iter 521  trainloss -1999.85418  validloss -1810.74110±0.00000  bestvalidloss -1813.62032  last_update 4\n",
      "train: iter 522  trainloss -1935.00235  validloss -1760.87183±0.00000  bestvalidloss -1813.62032  last_update 5\n",
      "train: iter 523  trainloss -1979.74477  validloss -1752.48845±0.00000  bestvalidloss -1813.62032  last_update 6\n",
      "train: iter 524  trainloss -1965.18168  validloss -1739.78820±0.00000  bestvalidloss -1813.62032  last_update 7\n",
      "train: iter 525  trainloss -1924.43292  validloss -1754.97150±0.00000  bestvalidloss -1813.62032  last_update 8\n",
      "train: iter 526  trainloss -1968.57456  validloss -1648.06216±0.00000  bestvalidloss -1813.62032  last_update 9\n",
      "train: iter 527  trainloss -1972.54831  validloss -1794.23749±0.00000  bestvalidloss -1813.62032  last_update 10\n",
      "train: iter 528  trainloss -1945.28278  validloss -1691.62244±0.00000  bestvalidloss -1813.62032  last_update 11\n",
      "train: iter 529  trainloss -1951.83591  validloss -1770.63988±0.00000  bestvalidloss -1813.62032  last_update 12\n",
      "train: iter 530  trainloss -1960.06844  validloss -1647.60804±0.00000  bestvalidloss -1813.62032  last_update 13\n",
      "train: iter 531  trainloss -1930.97297  validloss -1463.09494±0.00000  bestvalidloss -1813.62032  last_update 14\n",
      "train: iter 532  trainloss -1846.90911  validloss -1525.10750±0.00000  bestvalidloss -1813.62032  last_update 15\n",
      "train: iter 533  trainloss -1981.84726  validloss -1770.89567±0.00000  bestvalidloss -1813.62032  last_update 16\n",
      "train: iter 534  trainloss -1967.03563  validloss -1795.93165±0.00000  bestvalidloss -1813.62032  last_update 17\n",
      "train: iter 535  trainloss -1984.28807  validloss -1776.28880±0.00000  bestvalidloss -1813.62032  last_update 18\n",
      "train: iter 536  trainloss -1985.53899  validloss -1808.56495±0.00000  bestvalidloss -1813.62032  last_update 19\n",
      "train: iter 537  trainloss -1949.24529  validloss -1690.63340±0.00000  bestvalidloss -1813.62032  last_update 20\n",
      "train: iter 538  trainloss -1768.39499  validloss -1734.02975±0.00000  bestvalidloss -1813.62032  last_update 21\n",
      "train: iter 539  trainloss -1923.91955  validloss -1657.26400±0.00000  bestvalidloss -1813.62032  last_update 22\n",
      "train: iter 540  trainloss -1995.82348  validloss -1753.81143±0.00000  bestvalidloss -1813.62032  last_update 23\n",
      "train: iter 541  trainloss -1986.70745  validloss -1778.58797±0.00000  bestvalidloss -1813.62032  last_update 24\n",
      "train: iter 542  trainloss -1938.05918  validloss -1734.24096±0.00000  bestvalidloss -1813.62032  last_update 25\n",
      "train: iter 543  trainloss -1984.72440  validloss -1797.87069±0.00000  bestvalidloss -1813.62032  last_update 26\n",
      "train: iter 544  trainloss -1998.72639  validloss -1796.57045±0.00000  bestvalidloss -1813.62032  last_update 27\n",
      "train: iter 545  trainloss -1944.44612  validloss -1774.79529±0.00000  bestvalidloss -1813.62032  last_update 28\n",
      "train: iter 546  trainloss -1924.91352  validloss -1583.34681±0.00000  bestvalidloss -1813.62032  last_update 29\n",
      "train: iter 547  trainloss -1969.03256  validloss -1759.23054±0.00000  bestvalidloss -1813.62032  last_update 30\n",
      "train: iter 548  trainloss -1999.04521  validloss -1773.76752±0.00000  bestvalidloss -1813.62032  last_update 31\n",
      "train: iter 549  trainloss -1959.86782  validloss -1773.90059±0.00000  bestvalidloss -1813.62032  last_update 32\n",
      "train: iter 550  trainloss -1967.44975  validloss -1586.02449±0.00000  bestvalidloss -1813.62032  last_update 33\n",
      "train: iter 551  trainloss -1997.01758  validloss -1807.56528±0.00000  bestvalidloss -1813.62032  last_update 34\n",
      "train: iter 552  trainloss -1930.94200  validloss -1770.84380±0.00000  bestvalidloss -1813.62032  last_update 35\n",
      "train: iter 553  trainloss -1954.65461  validloss -1693.21081±0.00000  bestvalidloss -1813.62032  last_update 36\n",
      "train: iter 554  trainloss -1963.30289  validloss -1680.52228±0.00000  bestvalidloss -1813.62032  last_update 37\n",
      "train: iter 555  trainloss -1987.19124  validloss -1775.18908±0.00000  bestvalidloss -1813.62032  last_update 38\n",
      "train: iter 556  trainloss -1978.07231  validloss -1708.18810±0.00000  bestvalidloss -1813.62032  last_update 39\n",
      "train: iter 557  trainloss -1950.39739  validloss -1756.02609±0.00000  bestvalidloss -1813.62032  last_update 40\n",
      "train: iter 558  trainloss -1941.45081  validloss -1482.65412±0.00000  bestvalidloss -1813.62032  last_update 41\n",
      "train: iter 559  trainloss -1953.45071  validloss -1822.96875±0.00000  bestvalidloss -1822.96875  last_update 0\n",
      "train: iter 560  trainloss -1937.84647  validloss -1599.00288±0.00000  bestvalidloss -1822.96875  last_update 1\n",
      "train: iter 561  trainloss -1980.95411  validloss -1814.21969±0.00000  bestvalidloss -1822.96875  last_update 2\n",
      "train: iter 562  trainloss -1963.95109  validloss -1750.13042±0.00000  bestvalidloss -1822.96875  last_update 3\n",
      "train: iter 563  trainloss -1977.22722  validloss -1778.67598±0.00000  bestvalidloss -1822.96875  last_update 4\n",
      "train: iter 564  trainloss -1964.05067  validloss -1727.74968±0.00000  bestvalidloss -1822.96875  last_update 5\n",
      "train: iter 565  trainloss -1964.70083  validloss -1711.57187±0.00000  bestvalidloss -1822.96875  last_update 6\n",
      "train: iter 566  trainloss -1863.61993  validloss -1631.54054±0.00000  bestvalidloss -1822.96875  last_update 7\n",
      "train: iter 567  trainloss -1926.53865  validloss -1720.12249±0.00000  bestvalidloss -1822.96875  last_update 8\n",
      "train: iter 568  trainloss -1954.26497  validloss -1773.66908±0.00000  bestvalidloss -1822.96875  last_update 9\n",
      "train: iter 569  trainloss -1979.29834  validloss -1761.10031±0.00000  bestvalidloss -1822.96875  last_update 10\n",
      "train: iter 570  trainloss -1944.62523  validloss -1798.67816±0.00000  bestvalidloss -1822.96875  last_update 11\n",
      "train: iter 571  trainloss -1966.45325  validloss -1801.38933±0.00000  bestvalidloss -1822.96875  last_update 12\n",
      "train: iter 572  trainloss -1943.71678  validloss -1342.40314±0.00000  bestvalidloss -1822.96875  last_update 13\n",
      "train: iter 573  trainloss -2004.35497  validloss -1801.13872±0.00000  bestvalidloss -1822.96875  last_update 14\n",
      "train: iter 574  trainloss -1955.93588  validloss -1806.33458±0.00000  bestvalidloss -1822.96875  last_update 15\n",
      "train: iter 575  trainloss -1967.43336  validloss -1696.76058±0.00000  bestvalidloss -1822.96875  last_update 16\n",
      "train: iter 576  trainloss -2002.00979  validloss -1821.20249±0.00000  bestvalidloss -1822.96875  last_update 17\n",
      "train: iter 577  trainloss -1982.08120  validloss -1789.94479±0.00000  bestvalidloss -1822.96875  last_update 18\n",
      "train: iter 578  trainloss -1933.43159  validloss -1706.72612±0.00000  bestvalidloss -1822.96875  last_update 19\n",
      "train: iter 579  trainloss -1849.15135  validloss -1791.61732±0.00000  bestvalidloss -1822.96875  last_update 20\n",
      "train: iter 580  trainloss -1996.56783  validloss -1692.81732±0.00000  bestvalidloss -1822.96875  last_update 21\n",
      "train: iter 581  trainloss -1972.13176  validloss -1821.38904±0.00000  bestvalidloss -1822.96875  last_update 22\n",
      "train: iter 582  trainloss -1992.57366  validloss -1838.89886±0.00000  bestvalidloss -1838.89886  last_update 0\n",
      "train: iter 583  trainloss -1971.20474  validloss -1832.32026±0.00000  bestvalidloss -1838.89886  last_update 1\n",
      "train: iter 584  trainloss -1969.31459  validloss -1765.45990±0.00000  bestvalidloss -1838.89886  last_update 2\n",
      "train: iter 585  trainloss -1973.43897  validloss -1773.62815±0.00000  bestvalidloss -1838.89886  last_update 3\n",
      "train: iter 586  trainloss -1879.88717  validloss -1808.31177±0.00000  bestvalidloss -1838.89886  last_update 4\n",
      "train: iter 587  trainloss -1948.90603  validloss -1599.65047±0.00000  bestvalidloss -1838.89886  last_update 5\n",
      "train: iter 588  trainloss -1966.06530  validloss -1819.79093±0.00000  bestvalidloss -1838.89886  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 589  trainloss -1999.37451  validloss -1799.46912±0.00000  bestvalidloss -1838.89886  last_update 7\n",
      "train: iter 590  trainloss -1890.69570  validloss -1821.80405±0.00000  bestvalidloss -1838.89886  last_update 8\n",
      "train: iter 591  trainloss -1932.41736  validloss -1767.20932±0.00000  bestvalidloss -1838.89886  last_update 9\n",
      "train: iter 592  trainloss -1978.47389  validloss -1734.01624±0.00000  bestvalidloss -1838.89886  last_update 10\n",
      "train: iter 593  trainloss -2000.33584  validloss -1820.67987±0.00000  bestvalidloss -1838.89886  last_update 11\n",
      "train: iter 594  trainloss -2019.68934  validloss -1821.67666±0.00000  bestvalidloss -1838.89886  last_update 12\n",
      "train: iter 595  trainloss -1989.85455  validloss -1813.82244±0.00000  bestvalidloss -1838.89886  last_update 13\n",
      "train: iter 596  trainloss -1991.74089  validloss -1840.49807±0.00000  bestvalidloss -1840.49807  last_update 0\n",
      "train: iter 597  trainloss -1813.57659  validloss -1676.37827±0.00000  bestvalidloss -1840.49807  last_update 1\n",
      "train: iter 598  trainloss -1959.02551  validloss -1719.50597±0.00000  bestvalidloss -1840.49807  last_update 2\n",
      "train: iter 599  trainloss -1974.46567  validloss -1786.27366±0.00000  bestvalidloss -1840.49807  last_update 3\n",
      "train: iter 600  trainloss -1972.23448  validloss -1838.47938±0.00000  bestvalidloss -1840.49807  last_update 4\n",
      "train: iter 601  trainloss -1952.48018  validloss -1821.22370±0.00000  bestvalidloss -1840.49807  last_update 5\n",
      "train: iter 602  trainloss -1886.94454  validloss -1794.91247±0.00000  bestvalidloss -1840.49807  last_update 6\n",
      "train: iter 603  trainloss -1981.60072  validloss -1707.32359±0.00000  bestvalidloss -1840.49807  last_update 7\n",
      "train: iter 604  trainloss -1997.90382  validloss -1815.40010±0.00000  bestvalidloss -1840.49807  last_update 8\n",
      "train: iter 605  trainloss -1962.99792  validloss -1814.49263±0.00000  bestvalidloss -1840.49807  last_update 9\n",
      "train: iter 606  trainloss -1999.96024  validloss -1823.45515±0.00000  bestvalidloss -1840.49807  last_update 10\n",
      "train: iter 607  trainloss -1939.14786  validloss -1811.22833±0.00000  bestvalidloss -1840.49807  last_update 11\n",
      "train: iter 608  trainloss -1942.94175  validloss -1694.06637±0.00000  bestvalidloss -1840.49807  last_update 12\n",
      "train: iter 609  trainloss -2006.65931  validloss -1775.12415±0.00000  bestvalidloss -1840.49807  last_update 13\n",
      "train: iter 610  trainloss -2011.92404  validloss -1856.19417±0.00000  bestvalidloss -1856.19417  last_update 0\n",
      "train: iter 611  trainloss -1940.42565  validloss -1662.04196±0.00000  bestvalidloss -1856.19417  last_update 1\n",
      "train: iter 612  trainloss -1824.73284  validloss -1477.60772±0.00000  bestvalidloss -1856.19417  last_update 2\n",
      "train: iter 613  trainloss -1973.97775  validloss -1755.62395±0.00000  bestvalidloss -1856.19417  last_update 3\n",
      "train: iter 614  trainloss -1985.34554  validloss -1754.25208±0.00000  bestvalidloss -1856.19417  last_update 4\n",
      "train: iter 615  trainloss -1977.57912  validloss -1823.63454±0.00000  bestvalidloss -1856.19417  last_update 5\n",
      "train: iter 616  trainloss -1952.10092  validloss -1667.23637±0.00000  bestvalidloss -1856.19417  last_update 6\n",
      "train: iter 617  trainloss -1965.14389  validloss -1670.95467±0.00000  bestvalidloss -1856.19417  last_update 7\n",
      "train: iter 618  trainloss -1994.90214  validloss -1813.06214±0.00000  bestvalidloss -1856.19417  last_update 8\n",
      "train: iter 619  trainloss -1957.29000  validloss -1764.40918±0.00000  bestvalidloss -1856.19417  last_update 9\n",
      "train: iter 620  trainloss -2009.08129  validloss -1839.50686±0.00000  bestvalidloss -1856.19417  last_update 10\n",
      "train: iter 621  trainloss -1975.63608  validloss -1799.52065±0.00000  bestvalidloss -1856.19417  last_update 11\n",
      "train: iter 622  trainloss -1968.86123  validloss -1847.29933±0.00000  bestvalidloss -1856.19417  last_update 12\n",
      "train: iter 623  trainloss -1905.75972  validloss -1718.87809±0.00000  bestvalidloss -1856.19417  last_update 13\n",
      "train: iter 624  trainloss -1986.33794  validloss -1755.91384±0.00000  bestvalidloss -1856.19417  last_update 14\n",
      "train: iter 625  trainloss -2005.97592  validloss -1810.06467±0.00000  bestvalidloss -1856.19417  last_update 15\n",
      "train: iter 626  trainloss -1998.32664  validloss -1798.27565±0.00000  bestvalidloss -1856.19417  last_update 16\n",
      "train: iter 627  trainloss -1974.10752  validloss -1802.76579±0.00000  bestvalidloss -1856.19417  last_update 17\n",
      "train: iter 628  trainloss -1873.64028  validloss -1491.67584±0.00000  bestvalidloss -1856.19417  last_update 18\n",
      "train: iter 629  trainloss -1969.61140  validloss -1741.89250±0.00000  bestvalidloss -1856.19417  last_update 19\n",
      "train: iter 630  trainloss -2014.29722  validloss -1824.58167±0.00000  bestvalidloss -1856.19417  last_update 20\n",
      "train: iter 631  trainloss -2011.43502  validloss -1867.45165±0.00000  bestvalidloss -1867.45165  last_update 0\n",
      "train: iter 632  trainloss -1934.04729  validloss -1814.84886±0.00000  bestvalidloss -1867.45165  last_update 1\n",
      "train: iter 633  trainloss -1717.50642  validloss -1555.57725±0.00000  bestvalidloss -1867.45165  last_update 2\n",
      "train: iter 634  trainloss -1984.12729  validloss -1739.75026±0.00000  bestvalidloss -1867.45165  last_update 3\n",
      "train: iter 635  trainloss -1990.56581  validloss -1840.29133±0.00000  bestvalidloss -1867.45165  last_update 4\n",
      "train: iter 636  trainloss -1859.52276  validloss -1809.59118±0.00000  bestvalidloss -1867.45165  last_update 5\n",
      "train: iter 637  trainloss -1990.60570  validloss -1756.02703±0.00000  bestvalidloss -1867.45165  last_update 6\n",
      "train: iter 638  trainloss -2009.66585  validloss -1838.11216±0.00000  bestvalidloss -1867.45165  last_update 7\n",
      "train: iter 639  trainloss -1988.69356  validloss -1863.36066±0.00000  bestvalidloss -1867.45165  last_update 8\n",
      "train: iter 640  trainloss -2009.31629  validloss -1831.25193±0.00000  bestvalidloss -1867.45165  last_update 9\n",
      "train: iter 641  trainloss -2003.77505  validloss -1834.55828±0.00000  bestvalidloss -1867.45165  last_update 10\n",
      "train: iter 642  trainloss -2011.54441  validloss -1852.99496±0.00000  bestvalidloss -1867.45165  last_update 11\n",
      "train: iter 643  trainloss -1993.00854  validloss -1819.58283±0.00000  bestvalidloss -1867.45165  last_update 12\n",
      "train: iter 644  trainloss -1790.64428  validloss -1793.62916±0.00000  bestvalidloss -1867.45165  last_update 13\n",
      "train: iter 645  trainloss -1931.87159  validloss -1541.13629±0.00000  bestvalidloss -1867.45165  last_update 14\n",
      "train: iter 646  trainloss -2003.49753  validloss -1853.19469±0.00000  bestvalidloss -1867.45165  last_update 15\n",
      "train: iter 647  trainloss -1970.97368  validloss -1852.93363±0.00000  bestvalidloss -1867.45165  last_update 16\n",
      "train: iter 648  trainloss -2005.80831  validloss -1779.99651±0.00000  bestvalidloss -1867.45165  last_update 17\n",
      "train: iter 649  trainloss -1999.81454  validloss -1820.17629±0.00000  bestvalidloss -1867.45165  last_update 18\n",
      "train: iter 650  trainloss -1989.98029  validloss -1863.46689±0.00000  bestvalidloss -1867.45165  last_update 19\n",
      "train: iter 651  trainloss -1980.43689  validloss -1822.46117±0.00000  bestvalidloss -1867.45165  last_update 20\n",
      "train: iter 652  trainloss -1837.79270  validloss -1658.79841±0.00000  bestvalidloss -1867.45165  last_update 21\n",
      "train: iter 653  trainloss -1875.93084  validloss -1697.34411±0.00000  bestvalidloss -1867.45165  last_update 22\n",
      "train: iter 654  trainloss -1983.47494  validloss -1748.47152±0.00000  bestvalidloss -1867.45165  last_update 23\n",
      "train: iter 655  trainloss -2009.79354  validloss -1835.67311±0.00000  bestvalidloss -1867.45165  last_update 24\n",
      "train: iter 656  trainloss -2013.52947  validloss -1858.29205±0.00000  bestvalidloss -1867.45165  last_update 25\n",
      "train: iter 657  trainloss -1938.57737  validloss -1830.48575±0.00000  bestvalidloss -1867.45165  last_update 26\n",
      "train: iter 658  trainloss -1928.04069  validloss -1652.93333±0.00000  bestvalidloss -1867.45165  last_update 27\n",
      "train: iter 659  trainloss -1963.75433  validloss -1769.41044±0.00000  bestvalidloss -1867.45165  last_update 28\n",
      "train: iter 660  trainloss -2004.27503  validloss -1845.56752±0.00000  bestvalidloss -1867.45165  last_update 29\n",
      "train: iter 661  trainloss -2019.47868  validloss -1846.28403±0.00000  bestvalidloss -1867.45165  last_update 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 662  trainloss -1976.19968  validloss -1865.38686±0.00000  bestvalidloss -1867.45165  last_update 31\n",
      "train: iter 663  trainloss -1958.40486  validloss -1724.22510±0.00000  bestvalidloss -1867.45165  last_update 32\n",
      "train: iter 664  trainloss -1981.19821  validloss -1848.83749±0.00000  bestvalidloss -1867.45165  last_update 33\n",
      "train: iter 665  trainloss -1991.52058  validloss -1804.74811±0.00000  bestvalidloss -1867.45165  last_update 34\n",
      "train: iter 666  trainloss -1988.61923  validloss -1854.31772±0.00000  bestvalidloss -1867.45165  last_update 35\n",
      "train: iter 667  trainloss -1869.70571  validloss -1819.25240±0.00000  bestvalidloss -1867.45165  last_update 36\n",
      "train: iter 668  trainloss -1968.73548  validloss -1668.21290±0.00000  bestvalidloss -1867.45165  last_update 37\n",
      "train: iter 669  trainloss -2017.64059  validloss -1829.81370±0.00000  bestvalidloss -1867.45165  last_update 38\n",
      "train: iter 670  trainloss -2017.01628  validloss -1827.05736±0.00000  bestvalidloss -1867.45165  last_update 39\n",
      "train: iter 671  trainloss -2015.01112  validloss -1856.88899±0.00000  bestvalidloss -1867.45165  last_update 40\n",
      "train: iter 672  trainloss -2020.71141  validloss -1843.05740±0.00000  bestvalidloss -1867.45165  last_update 41\n",
      "train: iter 673  trainloss -1868.95111  validloss -1866.41585±0.00000  bestvalidloss -1867.45165  last_update 42\n",
      "train: iter 674  trainloss -1947.73585  validloss -1689.44960±0.00000  bestvalidloss -1867.45165  last_update 43\n",
      "train: iter 675  trainloss -1991.51786  validloss -1807.89036±0.00000  bestvalidloss -1867.45165  last_update 44\n",
      "train: iter 676  trainloss -1982.29635  validloss -1680.62628±0.00000  bestvalidloss -1867.45165  last_update 45\n",
      "train: iter 677  trainloss -2002.46691  validloss -1796.80804±0.00000  bestvalidloss -1867.45165  last_update 46\n",
      "train: iter 678  trainloss -1949.29110  validloss -1612.00108±0.00000  bestvalidloss -1867.45165  last_update 47\n",
      "train: iter 679  trainloss -1984.04480  validloss -1821.45274±0.00000  bestvalidloss -1867.45165  last_update 48\n",
      "train: iter 680  trainloss -1971.58722  validloss -1807.82653±0.00000  bestvalidloss -1867.45165  last_update 49\n",
      "train: iter 681  trainloss -2009.28090  validloss -1789.80287±0.00000  bestvalidloss -1867.45165  last_update 50\n",
      "train: iter 682  trainloss -2004.60802  validloss -1847.79236±0.00000  bestvalidloss -1867.45165  last_update 51\n",
      "train: iter 683  trainloss -1995.18472  validloss -1872.08709±0.00000  bestvalidloss -1872.08709  last_update 0\n",
      "train: iter 684  trainloss -1931.21684  validloss -1656.73306±0.00000  bestvalidloss -1872.08709  last_update 1\n",
      "train: iter 685  trainloss -1995.02316  validloss -1826.85530±0.00000  bestvalidloss -1872.08709  last_update 2\n",
      "train: iter 686  trainloss -1997.70178  validloss -1805.43886±0.00000  bestvalidloss -1872.08709  last_update 3\n",
      "train: iter 687  trainloss -2015.07603  validloss -1859.33589±0.00000  bestvalidloss -1872.08709  last_update 4\n",
      "train: iter 688  trainloss -2017.01041  validloss -1864.94653±0.00000  bestvalidloss -1872.08709  last_update 5\n",
      "train: iter 689  trainloss -2001.52003  validloss -1850.49948±0.00000  bestvalidloss -1872.08709  last_update 6\n",
      "train: iter 690  trainloss -1663.05647  validloss -1857.33037±0.00000  bestvalidloss -1872.08709  last_update 7\n",
      "train: iter 691  trainloss -1907.78920  validloss -1473.53718±0.00000  bestvalidloss -1872.08709  last_update 8\n",
      "train: iter 692  trainloss -1990.77011  validloss -1741.04427±0.00000  bestvalidloss -1872.08709  last_update 9\n",
      "train: iter 693  trainloss -2014.66577  validloss -1832.21902±0.00000  bestvalidloss -1872.08709  last_update 10\n",
      "train: iter 694  trainloss -2009.31388  validloss -1834.53747±0.00000  bestvalidloss -1872.08709  last_update 11\n",
      "train: iter 695  trainloss -1982.91435  validloss -1738.13420±0.00000  bestvalidloss -1872.08709  last_update 12\n",
      "train: iter 696  trainloss -1974.47376  validloss -1846.99387±0.00000  bestvalidloss -1872.08709  last_update 13\n",
      "train: iter 697  trainloss -1992.84863  validloss -1852.29489±0.00000  bestvalidloss -1872.08709  last_update 14\n",
      "train: iter 698  trainloss -2001.92179  validloss -1862.52318±0.00000  bestvalidloss -1872.08709  last_update 15\n",
      "train: iter 699  trainloss -2006.35930  validloss -1835.30956±0.00000  bestvalidloss -1872.08709  last_update 16\n",
      "train: iter 700  trainloss -2009.97361  validloss -1864.60164±0.00000  bestvalidloss -1872.08709  last_update 17\n",
      "train: iter 701  trainloss -1977.00517  validloss -1763.04458±0.00000  bestvalidloss -1872.08709  last_update 18\n",
      "train: iter 702  trainloss -2019.78205  validloss -1875.82433±0.00000  bestvalidloss -1875.82433  last_update 0\n",
      "train: iter 703  trainloss -1988.62617  validloss -1849.59800±0.00000  bestvalidloss -1875.82433  last_update 1\n",
      "train: iter 704  trainloss -1945.85646  validloss -1827.58927±0.00000  bestvalidloss -1875.82433  last_update 2\n",
      "train: iter 705  trainloss -2016.76301  validloss -1865.68973±0.00000  bestvalidloss -1875.82433  last_update 3\n",
      "train: iter 706  trainloss -2016.20883  validloss -1882.90172±0.00000  bestvalidloss -1882.90172  last_update 0\n",
      "train: iter 707  trainloss -2000.17048  validloss -1844.83575±0.00000  bestvalidloss -1882.90172  last_update 1\n",
      "train: iter 708  trainloss -1906.75343  validloss -1852.25200±0.00000  bestvalidloss -1882.90172  last_update 2\n",
      "train: iter 709  trainloss -1954.02508  validloss -913.10201±0.00000  bestvalidloss -1882.90172  last_update 3\n",
      "train: iter 710  trainloss -1805.96380  validloss -1812.57474±0.00000  bestvalidloss -1882.90172  last_update 4\n",
      "train: iter 711  trainloss -1951.25490  validloss -1634.21202±0.00000  bestvalidloss -1882.90172  last_update 5\n",
      "train: iter 712  trainloss -2008.81410  validloss -1826.60468±0.00000  bestvalidloss -1882.90172  last_update 6\n",
      "train: iter 713  trainloss -2012.29678  validloss -1861.19680±0.00000  bestvalidloss -1882.90172  last_update 7\n",
      "train: iter 714  trainloss -2014.90695  validloss -1851.91582±0.00000  bestvalidloss -1882.90172  last_update 8\n",
      "train: iter 715  trainloss -2007.22010  validloss -1881.82717±0.00000  bestvalidloss -1882.90172  last_update 9\n",
      "train: iter 716  trainloss -2012.63953  validloss -1869.12604±0.00000  bestvalidloss -1882.90172  last_update 10\n",
      "train: iter 717  trainloss -2008.28352  validloss -1836.67959±0.00000  bestvalidloss -1882.90172  last_update 11\n",
      "train: iter 718  trainloss -1838.14810  validloss -1774.78690±0.00000  bestvalidloss -1882.90172  last_update 12\n",
      "train: iter 719  trainloss -1900.75080  validloss -1372.94697±0.00000  bestvalidloss -1882.90172  last_update 13\n",
      "train: iter 720  trainloss -1990.68805  validloss -1793.29065±0.00000  bestvalidloss -1882.90172  last_update 14\n",
      "train: iter 721  trainloss -2018.75533  validloss -1852.85595±0.00000  bestvalidloss -1882.90172  last_update 15\n",
      "train: iter 722  trainloss -2011.33129  validloss -1853.78979±0.00000  bestvalidloss -1882.90172  last_update 16\n",
      "train: iter 723  trainloss -1989.86852  validloss -1870.30141±0.00000  bestvalidloss -1882.90172  last_update 17\n",
      "train: iter 724  trainloss -1830.58958  validloss -1801.51760±0.00000  bestvalidloss -1882.90172  last_update 18\n",
      "train: iter 725  trainloss -1988.55951  validloss -1747.30871±0.00000  bestvalidloss -1882.90172  last_update 19\n",
      "train: iter 726  trainloss -1992.67522  validloss -1846.35417±0.00000  bestvalidloss -1882.90172  last_update 20\n",
      "train: iter 727  trainloss -1984.59789  validloss -1798.98749±0.00000  bestvalidloss -1882.90172  last_update 21\n",
      "train: iter 728  trainloss -2010.52476  validloss -1873.31394±0.00000  bestvalidloss -1882.90172  last_update 22\n",
      "train: iter 729  trainloss -2018.93116  validloss -1883.65477±0.00000  bestvalidloss -1883.65477  last_update 0\n",
      "train: iter 730  trainloss -2016.98018  validloss -1815.46881±0.00000  bestvalidloss -1883.65477  last_update 1\n",
      "train: iter 731  trainloss -2004.18442  validloss -1851.27429±0.00000  bestvalidloss -1883.65477  last_update 2\n",
      "train: iter 732  trainloss -1992.48014  validloss -1841.95522±0.00000  bestvalidloss -1883.65477  last_update 3\n",
      "train: iter 733  trainloss -1995.44383  validloss -1874.17881±0.00000  bestvalidloss -1883.65477  last_update 4\n",
      "train: iter 734  trainloss -2025.61771  validloss -1751.49430±0.00000  bestvalidloss -1883.65477  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 735  trainloss -2026.54377  validloss -1885.83387±0.00000  bestvalidloss -1885.83387  last_update 0\n",
      "train: iter 736  trainloss -1999.35663  validloss -1854.14803±0.00000  bestvalidloss -1885.83387  last_update 1\n",
      "train: iter 737  trainloss -1941.84099  validloss -1585.97921±0.00000  bestvalidloss -1885.83387  last_update 2\n",
      "train: iter 738  trainloss -2022.92324  validloss -1821.10726±0.00000  bestvalidloss -1885.83387  last_update 3\n",
      "train: iter 739  trainloss -1897.05219  validloss -1861.60225±0.00000  bestvalidloss -1885.83387  last_update 4\n",
      "train: iter 740  trainloss -1904.55680  validloss -1632.22478±0.00000  bestvalidloss -1885.83387  last_update 5\n",
      "train: iter 741  trainloss -1985.78990  validloss -1779.59875±0.00000  bestvalidloss -1885.83387  last_update 6\n",
      "train: iter 742  trainloss -2006.05249  validloss -1853.74657±0.00000  bestvalidloss -1885.83387  last_update 7\n",
      "train: iter 743  trainloss -1989.98598  validloss -1838.39594±0.00000  bestvalidloss -1885.83387  last_update 8\n",
      "train: iter 744  trainloss -1984.47742  validloss -1840.73074±0.00000  bestvalidloss -1885.83387  last_update 9\n",
      "train: iter 745  trainloss -2011.90352  validloss -1881.80541±0.00000  bestvalidloss -1885.83387  last_update 10\n",
      "train: iter 746  trainloss -2031.03600  validloss -1870.21031±0.00000  bestvalidloss -1885.83387  last_update 11\n",
      "train: iter 747  trainloss -2032.42475  validloss -1854.73552±0.00000  bestvalidloss -1885.83387  last_update 12\n",
      "train: iter 748  trainloss -2011.29918  validloss -1886.88822±0.00000  bestvalidloss -1886.88822  last_update 0\n",
      "train: iter 749  trainloss -2012.36002  validloss -1833.61299±0.00000  bestvalidloss -1886.88822  last_update 1\n",
      "train: iter 750  trainloss -1971.81915  validloss -1858.44246±0.00000  bestvalidloss -1886.88822  last_update 2\n",
      "train: iter 751  trainloss -2008.33168  validloss -1709.76646±0.00000  bestvalidloss -1886.88822  last_update 3\n",
      "train: iter 752  trainloss -1890.49668  validloss -1832.36875±0.00000  bestvalidloss -1886.88822  last_update 4\n",
      "train: iter 753  trainloss -1892.95674  validloss -1127.42906±0.00000  bestvalidloss -1886.88822  last_update 5\n",
      "train: iter 754  trainloss -2007.15536  validloss -1837.76256±0.00000  bestvalidloss -1886.88822  last_update 6\n",
      "train: iter 755  trainloss -2024.05342  validloss -1869.20929±0.00000  bestvalidloss -1886.88822  last_update 7\n",
      "train: iter 756  trainloss -1905.45420  validloss -1879.84562±0.00000  bestvalidloss -1886.88822  last_update 8\n",
      "train: iter 757  trainloss -1985.67221  validloss -1662.11201±0.00000  bestvalidloss -1886.88822  last_update 9\n",
      "train: iter 758  trainloss -2011.99544  validloss -1860.64312±0.00000  bestvalidloss -1886.88822  last_update 10\n",
      "train: iter 759  trainloss -2016.14730  validloss -1869.55552±0.00000  bestvalidloss -1886.88822  last_update 11\n",
      "train: iter 760  trainloss -2021.39198  validloss -1859.34860±0.00000  bestvalidloss -1886.88822  last_update 12\n",
      "train: iter 761  trainloss -2001.55743  validloss -1827.13531±0.00000  bestvalidloss -1886.88822  last_update 13\n",
      "train: iter 762  trainloss -2005.28568  validloss -1889.05571±0.00000  bestvalidloss -1889.05571  last_update 0\n",
      "train: iter 763  trainloss -1970.12841  validloss -1791.32048±0.00000  bestvalidloss -1889.05571  last_update 1\n",
      "train: iter 764  trainloss -2004.15000  validloss -1813.42070±0.00000  bestvalidloss -1889.05571  last_update 2\n",
      "train: iter 765  trainloss -1999.50538  validloss -1837.93071±0.00000  bestvalidloss -1889.05571  last_update 3\n",
      "train: iter 766  trainloss -1819.53804  validloss -1549.31234±0.00000  bestvalidloss -1889.05571  last_update 4\n",
      "train: iter 767  trainloss -1973.13328  validloss -1634.86555±0.00000  bestvalidloss -1889.05571  last_update 5\n",
      "train: iter 768  trainloss -2019.64372  validloss -1834.03071±0.00000  bestvalidloss -1889.05571  last_update 6\n",
      "train: iter 769  trainloss -2020.13582  validloss -1839.56674±0.00000  bestvalidloss -1889.05571  last_update 7\n",
      "train: iter 770  trainloss -2019.76142  validloss -1887.49943±0.00000  bestvalidloss -1889.05571  last_update 8\n",
      "train: iter 771  trainloss -2014.07287  validloss -1683.32023±0.00000  bestvalidloss -1889.05571  last_update 9\n",
      "train: iter 772  trainloss -1914.83519  validloss -1799.21216±0.00000  bestvalidloss -1889.05571  last_update 10\n",
      "train: iter 773  trainloss -2005.71873  validloss -1763.75096±0.00000  bestvalidloss -1889.05571  last_update 11\n",
      "train: iter 774  trainloss -2026.49579  validloss -1879.98244±0.00000  bestvalidloss -1889.05571  last_update 12\n",
      "train: iter 775  trainloss -1988.63580  validloss -1874.05509±0.00000  bestvalidloss -1889.05571  last_update 13\n",
      "train: iter 776  trainloss -2033.62896  validloss -1881.47655±0.00000  bestvalidloss -1889.05571  last_update 14\n",
      "train: iter 777  trainloss -1891.58322  validloss -1784.77845±0.00000  bestvalidloss -1889.05571  last_update 15\n",
      "train: iter 778  trainloss -1939.40273  validloss -1758.83795±0.00000  bestvalidloss -1889.05571  last_update 16\n",
      "train: iter 779  trainloss -1979.72598  validloss -1766.67820±0.00000  bestvalidloss -1889.05571  last_update 17\n",
      "train: iter 780  trainloss -2002.44963  validloss -1799.20937±0.00000  bestvalidloss -1889.05571  last_update 18\n",
      "train: iter 781  trainloss -2003.85899  validloss -1851.18220±0.00000  bestvalidloss -1889.05571  last_update 19\n",
      "train: iter 782  trainloss -1882.48387  validloss -1806.48072±0.00000  bestvalidloss -1889.05571  last_update 20\n",
      "train: iter 783  trainloss -1984.69855  validloss -1783.05283±0.00000  bestvalidloss -1889.05571  last_update 21\n",
      "train: iter 784  trainloss -1990.37863  validloss -1844.33627±0.00000  bestvalidloss -1889.05571  last_update 22\n",
      "train: iter 785  trainloss -2013.62458  validloss -1869.85552±0.00000  bestvalidloss -1889.05571  last_update 23\n",
      "train: iter 786  trainloss -2025.79606  validloss -1786.25877±0.00000  bestvalidloss -1889.05571  last_update 24\n",
      "train: iter 787  trainloss -1944.10771  validloss -1898.26871±0.00000  bestvalidloss -1898.26871  last_update 0\n",
      "train: iter 788  trainloss -2008.70498  validloss -1768.57065±0.00000  bestvalidloss -1898.26871  last_update 1\n",
      "train: iter 789  trainloss -2017.03430  validloss -1852.99026±0.00000  bestvalidloss -1898.26871  last_update 2\n",
      "train: iter 790  trainloss -2008.31272  validloss -1852.18447±0.00000  bestvalidloss -1898.26871  last_update 3\n",
      "train: iter 791  trainloss -2021.91597  validloss -1880.17763±0.00000  bestvalidloss -1898.26871  last_update 4\n",
      "train: iter 792  trainloss -2020.50349  validloss -1862.72371±0.00000  bestvalidloss -1898.26871  last_update 5\n",
      "train: iter 793  trainloss -1985.53222  validloss -1898.72402±0.00000  bestvalidloss -1898.72402  last_update 0\n",
      "train: iter 794  trainloss -2001.07086  validloss -1792.07252±0.00000  bestvalidloss -1898.72402  last_update 1\n",
      "train: iter 795  trainloss -2037.73734  validloss -1903.35280±0.00000  bestvalidloss -1903.35280  last_update 0\n",
      "train: iter 796  trainloss -1967.18975  validloss -1897.86261±0.00000  bestvalidloss -1903.35280  last_update 1\n",
      "train: iter 797  trainloss -2009.29153  validloss -1822.96515±0.00000  bestvalidloss -1903.35280  last_update 2\n",
      "train: iter 798  trainloss -2010.82746  validloss -1879.19031±0.00000  bestvalidloss -1903.35280  last_update 3\n",
      "train: iter 799  trainloss -2031.92833  validloss -1883.28696±0.00000  bestvalidloss -1903.35280  last_update 4\n",
      "train: iter 800  trainloss -1924.32622  validloss -1854.39590±0.00000  bestvalidloss -1903.35280  last_update 5\n",
      "train: iter 801  trainloss -1910.61551  validloss -1667.72314±0.00000  bestvalidloss -1903.35280  last_update 6\n",
      "train: iter 802  trainloss -1955.01412  validloss -1795.92708±0.00000  bestvalidloss -1903.35280  last_update 7\n",
      "train: iter 803  trainloss -1874.15329  validloss -1867.62303±0.00000  bestvalidloss -1903.35280  last_update 8\n",
      "train: iter 804  trainloss -1953.31133  validloss -1700.25980±0.00000  bestvalidloss -1903.35280  last_update 9\n",
      "train: iter 805  trainloss -2011.36160  validloss -1811.87502±0.00000  bestvalidloss -1903.35280  last_update 10\n",
      "train: iter 806  trainloss -2002.32626  validloss -1877.99971±0.00000  bestvalidloss -1903.35280  last_update 11\n",
      "train: iter 807  trainloss -2002.92417  validloss -1865.28980±0.00000  bestvalidloss -1903.35280  last_update 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 808  trainloss -2027.72615  validloss -1810.93100±0.00000  bestvalidloss -1903.35280  last_update 13\n",
      "train: iter 809  trainloss -2012.20374  validloss -1864.53049±0.00000  bestvalidloss -1903.35280  last_update 14\n",
      "train: iter 810  trainloss -1924.21161  validloss -1845.41926±0.00000  bestvalidloss -1903.35280  last_update 15\n",
      "train: iter 811  trainloss -2007.61777  validloss -1732.49240±0.00000  bestvalidloss -1903.35280  last_update 16\n",
      "train: iter 812  trainloss -2016.47780  validloss -1887.15390±0.00000  bestvalidloss -1903.35280  last_update 17\n",
      "train: iter 813  trainloss -2021.04277  validloss -1835.47339±0.00000  bestvalidloss -1903.35280  last_update 18\n",
      "train: iter 814  trainloss -1869.10451  validloss -1853.69514±0.00000  bestvalidloss -1903.35280  last_update 19\n",
      "train: iter 815  trainloss -1985.26336  validloss -1768.04650±0.00000  bestvalidloss -1903.35280  last_update 20\n",
      "train: iter 816  trainloss -2021.81616  validloss -1859.07430±0.00000  bestvalidloss -1903.35280  last_update 21\n",
      "train: iter 817  trainloss -2004.84143  validloss -1791.64434±0.00000  bestvalidloss -1903.35280  last_update 22\n",
      "train: iter 818  trainloss -2017.56147  validloss -1829.87619±0.00000  bestvalidloss -1903.35280  last_update 23\n",
      "train: iter 819  trainloss -2016.51969  validloss -1837.98219±0.00000  bestvalidloss -1903.35280  last_update 24\n",
      "train: iter 820  trainloss -2001.81631  validloss -1854.07345±0.00000  bestvalidloss -1903.35280  last_update 25\n",
      "train: iter 821  trainloss -1861.16660  validloss -1880.74681±0.00000  bestvalidloss -1903.35280  last_update 26\n",
      "train: iter 822  trainloss -1892.69433  validloss -1243.03429±0.00000  bestvalidloss -1903.35280  last_update 27\n",
      "train: iter 823  trainloss -2017.39933  validloss -1844.79669±0.00000  bestvalidloss -1903.35280  last_update 28\n",
      "train: iter 824  trainloss -2019.92776  validloss -1852.58693±0.00000  bestvalidloss -1903.35280  last_update 29\n",
      "train: iter 825  trainloss -2023.64451  validloss -1869.54081±0.00000  bestvalidloss -1903.35280  last_update 30\n",
      "train: iter 826  trainloss -1900.09007  validloss -1818.72955±0.00000  bestvalidloss -1903.35280  last_update 31\n",
      "train: iter 827  trainloss -2022.18744  validloss -1849.43538±0.00000  bestvalidloss -1903.35280  last_update 32\n",
      "train: iter 828  trainloss -2026.36754  validloss -1887.39410±0.00000  bestvalidloss -1903.35280  last_update 33\n",
      "train: iter 829  trainloss -1998.05899  validloss -1878.87734±0.00000  bestvalidloss -1903.35280  last_update 34\n",
      "train: iter 830  trainloss -2030.65424  validloss -1881.26922±0.00000  bestvalidloss -1903.35280  last_update 35\n",
      "train: iter 831  trainloss -1865.94227  validloss -1879.07202±0.00000  bestvalidloss -1903.35280  last_update 36\n",
      "train: iter 832  trainloss -1993.12127  validloss -1739.30017±0.00000  bestvalidloss -1903.35280  last_update 37\n",
      "train: iter 833  trainloss -2036.24906  validloss -1868.41794±0.00000  bestvalidloss -1903.35280  last_update 38\n",
      "train: iter 834  trainloss -1968.81609  validloss -1873.63939±0.00000  bestvalidloss -1903.35280  last_update 39\n",
      "train: iter 835  trainloss -2025.13466  validloss -1836.30416±0.00000  bestvalidloss -1903.35280  last_update 40\n",
      "train: iter 836  trainloss -2004.82778  validloss -1877.60793±0.00000  bestvalidloss -1903.35280  last_update 41\n",
      "train: iter 837  trainloss -2037.45922  validloss -1894.01343±0.00000  bestvalidloss -1903.35280  last_update 42\n",
      "train: iter 838  trainloss -2029.34573  validloss -1877.45085±0.00000  bestvalidloss -1903.35280  last_update 43\n",
      "train: iter 839  trainloss -2001.75316  validloss -1842.73724±0.00000  bestvalidloss -1903.35280  last_update 44\n",
      "train: iter 840  trainloss -2006.76612  validloss -1842.78100±0.00000  bestvalidloss -1903.35280  last_update 45\n",
      "train: iter 841  trainloss -2029.43605  validloss -1881.68080±0.00000  bestvalidloss -1903.35280  last_update 46\n",
      "train: iter 842  trainloss -2016.37780  validloss -1863.57864±0.00000  bestvalidloss -1903.35280  last_update 47\n",
      "train: iter 843  trainloss -1983.61650  validloss -1459.70189±0.00000  bestvalidloss -1903.35280  last_update 48\n",
      "train: iter 844  trainloss -1993.29846  validloss -1862.24254±0.00000  bestvalidloss -1903.35280  last_update 49\n",
      "train: iter 845  trainloss -2025.37397  validloss -1853.59713±0.00000  bestvalidloss -1903.35280  last_update 50\n",
      "train: iter 846  trainloss -1995.25481  validloss -1880.24567±0.00000  bestvalidloss -1903.35280  last_update 51\n",
      "train: iter 847  trainloss -1664.19902  validloss -1481.38760±0.00000  bestvalidloss -1903.35280  last_update 52\n",
      "train: iter 848  trainloss -1944.96690  validloss -1695.36148±0.00000  bestvalidloss -1903.35280  last_update 53\n",
      "train: iter 849  trainloss -2010.80424  validloss -1832.11497±0.00000  bestvalidloss -1903.35280  last_update 54\n",
      "train: iter 850  trainloss -2025.13318  validloss -1821.60196±0.00000  bestvalidloss -1903.35280  last_update 55\n",
      "train: iter 851  trainloss -1932.62229  validloss -1846.98498±0.00000  bestvalidloss -1903.35280  last_update 56\n",
      "train: iter 852  trainloss -1981.79283  validloss -1603.13966±0.00000  bestvalidloss -1903.35280  last_update 57\n",
      "train: iter 853  trainloss -2034.13758  validloss -1859.36140±0.00000  bestvalidloss -1903.35280  last_update 58\n",
      "train: iter 854  trainloss -2018.14885  validloss -1859.55071±0.00000  bestvalidloss -1903.35280  last_update 59\n",
      "train: iter 855  trainloss -2030.30336  validloss -1890.42357±0.00000  bestvalidloss -1903.35280  last_update 60\n",
      "train: iter 856  trainloss -2009.46283  validloss -1855.32621±0.00000  bestvalidloss -1903.35280  last_update 61\n",
      "train: iter 857  trainloss -2010.15235  validloss -1835.39355±0.00000  bestvalidloss -1903.35280  last_update 62\n",
      "train: iter 858  trainloss -2022.23071  validloss -1887.80029±0.00000  bestvalidloss -1903.35280  last_update 63\n",
      "train: iter 859  trainloss -2023.38558  validloss -1833.18598±0.00000  bestvalidloss -1903.35280  last_update 64\n",
      "train: iter 860  trainloss -2042.67086  validloss -1879.93607±0.00000  bestvalidloss -1903.35280  last_update 65\n",
      "train: iter 861  trainloss -1980.03013  validloss -1844.46994±0.00000  bestvalidloss -1903.35280  last_update 66\n",
      "train: iter 862  trainloss -2026.45911  validloss -1780.06033±0.00000  bestvalidloss -1903.35280  last_update 67\n",
      "train: iter 863  trainloss -1969.92496  validloss -1890.37684±0.00000  bestvalidloss -1903.35280  last_update 68\n",
      "train: iter 864  trainloss -2020.39661  validloss -1810.72147±0.00000  bestvalidloss -1903.35280  last_update 69\n",
      "train: iter 865  trainloss -1938.33285  validloss -1874.50236±0.00000  bestvalidloss -1903.35280  last_update 70\n",
      "train: iter 866  trainloss -1970.54489  validloss -1798.00886±0.00000  bestvalidloss -1903.35280  last_update 71\n",
      "train: iter 867  trainloss -2030.61473  validloss -1823.36641±0.00000  bestvalidloss -1903.35280  last_update 72\n",
      "train: iter 868  trainloss -1999.75410  validloss -1859.55296±0.00000  bestvalidloss -1903.35280  last_update 73\n",
      "train: iter 869  trainloss -2028.85304  validloss -1861.34162±0.00000  bestvalidloss -1903.35280  last_update 74\n",
      "train: iter 870  trainloss -2025.30238  validloss -1885.75312±0.00000  bestvalidloss -1903.35280  last_update 75\n",
      "train: iter 871  trainloss -2025.92399  validloss -1884.44304±0.00000  bestvalidloss -1903.35280  last_update 76\n",
      "train: iter 872  trainloss -1827.37115  validloss -1846.57708±0.00000  bestvalidloss -1903.35280  last_update 77\n",
      "train: iter 873  trainloss -1998.12881  validloss -1790.99136±0.00000  bestvalidloss -1903.35280  last_update 78\n",
      "train: iter 874  trainloss -2025.32174  validloss -1876.63391±0.00000  bestvalidloss -1903.35280  last_update 79\n",
      "train: iter 875  trainloss -2027.28663  validloss -1896.61711±0.00000  bestvalidloss -1903.35280  last_update 80\n",
      "train: iter 876  trainloss -1914.03832  validloss -1826.90246±0.00000  bestvalidloss -1903.35280  last_update 81\n",
      "train: iter 877  trainloss -2013.50786  validloss -1737.73022±0.00000  bestvalidloss -1903.35280  last_update 82\n",
      "train: iter 878  trainloss -2020.96868  validloss -1840.50764±0.00000  bestvalidloss -1903.35280  last_update 83\n",
      "train: iter 879  trainloss -1975.72810  validloss -1857.21182±0.00000  bestvalidloss -1903.35280  last_update 84\n",
      "train: iter 880  trainloss -1917.91025  validloss -1770.50321±0.00000  bestvalidloss -1903.35280  last_update 85\n",
      "train: iter 881  trainloss -2033.18298  validloss -1857.27750±0.00000  bestvalidloss -1903.35280  last_update 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 882  trainloss -2022.60291  validloss -1863.87947±0.00000  bestvalidloss -1903.35280  last_update 87\n",
      "train: iter 883  trainloss -1864.15711  validloss -1659.08197±0.00000  bestvalidloss -1903.35280  last_update 88\n",
      "train: iter 884  trainloss -2020.03271  validloss -1829.13920±0.00000  bestvalidloss -1903.35280  last_update 89\n",
      "train: iter 885  trainloss -2044.50132  validloss -1868.60073±0.00000  bestvalidloss -1903.35280  last_update 90\n",
      "train: iter 886  trainloss -2048.69852  validloss -1899.85975±0.00000  bestvalidloss -1903.35280  last_update 91\n",
      "train: iter 887  trainloss -2004.18668  validloss -1879.93746±0.00000  bestvalidloss -1903.35280  last_update 92\n",
      "train: iter 888  trainloss -1991.35750  validloss -1861.25331±0.00000  bestvalidloss -1903.35280  last_update 93\n",
      "train: iter 889  trainloss -2016.51662  validloss -1874.26650±0.00000  bestvalidloss -1903.35280  last_update 94\n",
      "train: iter 890  trainloss -1933.23743  validloss -1817.96150±0.00000  bestvalidloss -1903.35280  last_update 95\n",
      "train: iter 891  trainloss -1964.07709  validloss -1826.15984±0.00000  bestvalidloss -1903.35280  last_update 96\n",
      "train: iter 892  trainloss -2018.60138  validloss -1800.35345±0.00000  bestvalidloss -1903.35280  last_update 97\n",
      "train: iter 893  trainloss -2029.82776  validloss -1868.07885±0.00000  bestvalidloss -1903.35280  last_update 98\n",
      "train: iter 894  trainloss -2048.97467  validloss -1883.91871±0.00000  bestvalidloss -1903.35280  last_update 99\n",
      "train: iter 895  trainloss -2040.93468  validloss -1904.43683±0.00000  bestvalidloss -1904.43683  last_update 0\n",
      "train: iter 896  trainloss -1993.90607  validloss -1882.52672±0.00000  bestvalidloss -1904.43683  last_update 1\n",
      "train: iter 897  trainloss -2027.46592  validloss -1849.05241±0.00000  bestvalidloss -1904.43683  last_update 2\n",
      "train: iter 898  trainloss -2022.08966  validloss -1849.54561±0.00000  bestvalidloss -1904.43683  last_update 3\n",
      "train: iter 899  trainloss -2000.73566  validloss -1877.72483±0.00000  bestvalidloss -1904.43683  last_update 4\n",
      "train: iter 900  trainloss -1998.77345  validloss -1834.72848±0.00000  bestvalidloss -1904.43683  last_update 5\n",
      "train: iter 901  trainloss -2010.48463  validloss -1819.82373±0.00000  bestvalidloss -1904.43683  last_update 6\n",
      "train: iter 902  trainloss -2044.02002  validloss -1875.63041±0.00000  bestvalidloss -1904.43683  last_update 7\n",
      "train: iter 903  trainloss -2007.82353  validloss -1906.83726±0.00000  bestvalidloss -1906.83726  last_update 0\n",
      "train: iter 904  trainloss -1966.71249  validloss -1857.16040±0.00000  bestvalidloss -1906.83726  last_update 1\n",
      "train: iter 905  trainloss -1780.69268  validloss -1485.48691±0.00000  bestvalidloss -1906.83726  last_update 2\n",
      "train: iter 906  trainloss -1951.21392  validloss -1270.39338±0.00000  bestvalidloss -1906.83726  last_update 3\n",
      "train: iter 907  trainloss -1978.23924  validloss -1834.87773±0.00000  bestvalidloss -1906.83726  last_update 4\n",
      "train: iter 908  trainloss -2011.30009  validloss -1826.81630±0.00000  bestvalidloss -1906.83726  last_update 5\n",
      "train: iter 909  trainloss -2019.02116  validloss -1848.67663±0.00000  bestvalidloss -1906.83726  last_update 6\n",
      "train: iter 910  trainloss -2020.99569  validloss -1806.47334±0.00000  bestvalidloss -1906.83726  last_update 7\n",
      "train: iter 911  trainloss -2031.63872  validloss -1877.53873±0.00000  bestvalidloss -1906.83726  last_update 8\n",
      "train: iter 912  trainloss -2010.06803  validloss -1879.03763±0.00000  bestvalidloss -1906.83726  last_update 9\n",
      "train: iter 913  trainloss -1949.23785  validloss -1887.39395±0.00000  bestvalidloss -1906.83726  last_update 10\n",
      "train: iter 914  trainloss -1969.36939  validloss -1715.64037±0.00000  bestvalidloss -1906.83726  last_update 11\n",
      "train: iter 915  trainloss -2032.73274  validloss -1845.70140±0.00000  bestvalidloss -1906.83726  last_update 12\n",
      "train: iter 916  trainloss -2032.63417  validloss -1855.93628±0.00000  bestvalidloss -1906.83726  last_update 13\n",
      "train: iter 917  trainloss -2016.05827  validloss -1878.46644±0.00000  bestvalidloss -1906.83726  last_update 14\n",
      "train: iter 918  trainloss -2022.33410  validloss -1816.34979±0.00000  bestvalidloss -1906.83726  last_update 15\n",
      "train: iter 919  trainloss -2028.58936  validloss -1898.92796±0.00000  bestvalidloss -1906.83726  last_update 16\n",
      "train: iter 920  trainloss -2037.37147  validloss -1868.46108±0.00000  bestvalidloss -1906.83726  last_update 17\n",
      "train: iter 921  trainloss -2021.52218  validloss -1916.00333±0.00000  bestvalidloss -1916.00333  last_update 0\n",
      "train: iter 922  trainloss -2009.80300  validloss -1876.26597±0.00000  bestvalidloss -1916.00333  last_update 1\n",
      "train: iter 923  trainloss -2021.54715  validloss -1844.33958±0.00000  bestvalidloss -1916.00333  last_update 2\n",
      "train: iter 924  trainloss -1993.03396  validloss -1886.43694±0.00000  bestvalidloss -1916.00333  last_update 3\n",
      "train: iter 925  trainloss -1985.37947  validloss -1722.03909±0.00000  bestvalidloss -1916.00333  last_update 4\n",
      "train: iter 926  trainloss -2032.13510  validloss -1892.51390±0.00000  bestvalidloss -1916.00333  last_update 5\n",
      "train: iter 927  trainloss -1981.77043  validloss -1870.87122±0.00000  bestvalidloss -1916.00333  last_update 6\n",
      "train: iter 928  trainloss -1995.73645  validloss -1829.52094±0.00000  bestvalidloss -1916.00333  last_update 7\n",
      "train: iter 929  trainloss -1921.63381  validloss -1793.62614±0.00000  bestvalidloss -1916.00333  last_update 8\n",
      "train: iter 930  trainloss -1964.79603  validloss -1614.72758±0.00000  bestvalidloss -1916.00333  last_update 9\n",
      "train: iter 931  trainloss -2027.20367  validloss -1798.32878±0.00000  bestvalidloss -1916.00333  last_update 10\n",
      "train: iter 932  trainloss -2013.95905  validloss -1862.15123±0.00000  bestvalidloss -1916.00333  last_update 11\n",
      "train: iter 933  trainloss -2027.64286  validloss -1834.63472±0.00000  bestvalidloss -1916.00333  last_update 12\n",
      "train: iter 934  trainloss -2032.26019  validloss -1866.73005±0.00000  bestvalidloss -1916.00333  last_update 13\n",
      "train: iter 935  trainloss -2049.30044  validloss -1890.88539±0.00000  bestvalidloss -1916.00333  last_update 14\n",
      "train: iter 936  trainloss -2005.20070  validloss -1871.91876±0.00000  bestvalidloss -1916.00333  last_update 15\n",
      "train: iter 937  trainloss -1951.04758  validloss -1793.14408±0.00000  bestvalidloss -1916.00333  last_update 16\n",
      "train: iter 938  trainloss -2020.06430  validloss -1832.19524±0.00000  bestvalidloss -1916.00333  last_update 17\n",
      "train: iter 939  trainloss -1991.24130  validloss -1873.10674±0.00000  bestvalidloss -1916.00333  last_update 18\n",
      "train: iter 940  trainloss -1979.93447  validloss -1562.93055±0.00000  bestvalidloss -1916.00333  last_update 19\n",
      "train: iter 941  trainloss -2014.91878  validloss -1896.82806±0.00000  bestvalidloss -1916.00333  last_update 20\n",
      "train: iter 942  trainloss -1999.47189  validloss -1744.49474±0.00000  bestvalidloss -1916.00333  last_update 21\n",
      "train: iter 943  trainloss -2014.41370  validloss -1830.87964±0.00000  bestvalidloss -1916.00333  last_update 22\n",
      "train: iter 944  trainloss -2042.44435  validloss -1864.76959±0.00000  bestvalidloss -1916.00333  last_update 23\n",
      "train: iter 945  trainloss -1991.89915  validloss -1798.52735±0.00000  bestvalidloss -1916.00333  last_update 24\n",
      "train: iter 946  trainloss -2001.02416  validloss -1832.77498±0.00000  bestvalidloss -1916.00333  last_update 25\n",
      "train: iter 947  trainloss -1875.77415  validloss -1829.54283±0.00000  bestvalidloss -1916.00333  last_update 26\n",
      "train: iter 948  trainloss -1969.08627  validloss -1653.51866±0.00000  bestvalidloss -1916.00333  last_update 27\n",
      "train: iter 949  trainloss -2025.18415  validloss -1868.07731±0.00000  bestvalidloss -1916.00333  last_update 28\n",
      "train: iter 950  trainloss -2007.68793  validloss -1873.52202±0.00000  bestvalidloss -1916.00333  last_update 29\n",
      "train: iter 951  trainloss -2009.07099  validloss -1891.12000±0.00000  bestvalidloss -1916.00333  last_update 30\n",
      "train: iter 952  trainloss -2040.71064  validloss -1893.88780±0.00000  bestvalidloss -1916.00333  last_update 31\n",
      "train: iter 953  trainloss -2028.17038  validloss -1894.76697±0.00000  bestvalidloss -1916.00333  last_update 32\n",
      "train: iter 954  trainloss -1976.11388  validloss -1843.51888±0.00000  bestvalidloss -1916.00333  last_update 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 955  trainloss -2035.53591  validloss -1894.38945±0.00000  bestvalidloss -1916.00333  last_update 34\n",
      "train: iter 956  trainloss -1991.79991  validloss -1888.03344±0.00000  bestvalidloss -1916.00333  last_update 35\n",
      "train: iter 957  trainloss -2032.00391  validloss -1864.39981±0.00000  bestvalidloss -1916.00333  last_update 36\n",
      "train: iter 958  trainloss -2008.81333  validloss -1891.39520±0.00000  bestvalidloss -1916.00333  last_update 37\n",
      "train: iter 959  trainloss -1820.53473  validloss -1607.45769±0.00000  bestvalidloss -1916.00333  last_update 38\n",
      "train: iter 960  trainloss -1937.00043  validloss -1627.90833±0.00000  bestvalidloss -1916.00333  last_update 39\n",
      "train: iter 961  trainloss -2019.43189  validloss -1839.63596±0.00000  bestvalidloss -1916.00333  last_update 40\n",
      "train: iter 962  trainloss -2035.77951  validloss -1862.05689±0.00000  bestvalidloss -1916.00333  last_update 41\n",
      "train: iter 963  trainloss -2008.08545  validloss -1858.73387±0.00000  bestvalidloss -1916.00333  last_update 42\n",
      "train: iter 964  trainloss -1999.99620  validloss -1849.92262±0.00000  bestvalidloss -1916.00333  last_update 43\n",
      "train: iter 965  trainloss -2033.41406  validloss -1845.75792±0.00000  bestvalidloss -1916.00333  last_update 44\n",
      "train: iter 966  trainloss -2056.81128  validloss -1866.45969±0.00000  bestvalidloss -1916.00333  last_update 45\n",
      "train: iter 967  trainloss -2019.08392  validloss -1907.96413±0.00000  bestvalidloss -1916.00333  last_update 46\n",
      "train: iter 968  trainloss -2003.16887  validloss -1872.71144±0.00000  bestvalidloss -1916.00333  last_update 47\n",
      "train: iter 969  trainloss -2003.16996  validloss -1359.40065±0.00000  bestvalidloss -1916.00333  last_update 48\n",
      "train: iter 970  trainloss -2043.06875  validloss -1905.71298±0.00000  bestvalidloss -1916.00333  last_update 49\n",
      "train: iter 971  trainloss -2037.01112  validloss -1844.39324±0.00000  bestvalidloss -1916.00333  last_update 50\n",
      "train: iter 972  trainloss -1936.55215  validloss -1911.87336±0.00000  bestvalidloss -1916.00333  last_update 51\n",
      "train: iter 973  trainloss -2022.08885  validloss -1831.52156±0.00000  bestvalidloss -1916.00333  last_update 52\n",
      "train: iter 974  trainloss -2020.99646  validloss -1890.96632±0.00000  bestvalidloss -1916.00333  last_update 53\n",
      "train: iter 975  trainloss -2036.49984  validloss -1913.78307±0.00000  bestvalidloss -1916.00333  last_update 54\n",
      "train: iter 976  trainloss -1893.13034  validloss -1431.69744±0.00000  bestvalidloss -1916.00333  last_update 55\n",
      "train: iter 977  trainloss -2017.53191  validloss -1788.20911±0.00000  bestvalidloss -1916.00333  last_update 56\n",
      "train: iter 978  trainloss -2014.40370  validloss -1846.14583±0.00000  bestvalidloss -1916.00333  last_update 57\n",
      "train: iter 979  trainloss -2039.64713  validloss -1882.57925±0.00000  bestvalidloss -1916.00333  last_update 58\n",
      "train: iter 980  trainloss -2026.48447  validloss -1889.03118±0.00000  bestvalidloss -1916.00333  last_update 59\n",
      "train: iter 981  trainloss -1904.77130  validloss -1888.06561±0.00000  bestvalidloss -1916.00333  last_update 60\n",
      "train: iter 982  trainloss -1968.64495  validloss -1482.87366±0.00000  bestvalidloss -1916.00333  last_update 61\n",
      "train: iter 983  trainloss -2038.24170  validloss -1887.01888±0.00000  bestvalidloss -1916.00333  last_update 62\n",
      "train: iter 984  trainloss -2047.13439  validloss -1906.38131±0.00000  bestvalidloss -1916.00333  last_update 63\n",
      "train: iter 985  trainloss -1987.06799  validloss -1874.89180±0.00000  bestvalidloss -1916.00333  last_update 64\n",
      "train: iter 986  trainloss -1998.55932  validloss -1755.55828±0.00000  bestvalidloss -1916.00333  last_update 65\n",
      "train: iter 987  trainloss -2030.09462  validloss -1857.22899±0.00000  bestvalidloss -1916.00333  last_update 66\n",
      "train: iter 988  trainloss -2032.73861  validloss -1843.37691±0.00000  bestvalidloss -1916.00333  last_update 67\n",
      "train: iter 989  trainloss -1965.43302  validloss -1885.00573±0.00000  bestvalidloss -1916.00333  last_update 68\n",
      "train: iter 990  trainloss -2037.86920  validloss -1883.31246±0.00000  bestvalidloss -1916.00333  last_update 69\n",
      "train: iter 991  trainloss -2043.96677  validloss -1876.05576±0.00000  bestvalidloss -1916.00333  last_update 70\n",
      "train: iter 992  trainloss -2026.29794  validloss -1890.81362±0.00000  bestvalidloss -1916.00333  last_update 71\n",
      "train: iter 993  trainloss -2010.57754  validloss -1875.12953±0.00000  bestvalidloss -1916.00333  last_update 72\n",
      "train: iter 994  trainloss -1904.85915  validloss -1746.41028±0.00000  bestvalidloss -1916.00333  last_update 73\n",
      "train: iter 995  trainloss -1995.41483  validloss -1853.66889±0.00000  bestvalidloss -1916.00333  last_update 74\n",
      "train: iter 996  trainloss -1936.51162  validloss -1834.72063±0.00000  bestvalidloss -1916.00333  last_update 75\n",
      "train: iter 997  trainloss -2022.71676  validloss -1732.79606±0.00000  bestvalidloss -1916.00333  last_update 76\n",
      "train: iter 998  trainloss -2017.80612  validloss -1892.88401±0.00000  bestvalidloss -1916.00333  last_update 77\n",
      "train: iter 999  trainloss -2038.17368  validloss -1860.15472±0.00000  bestvalidloss -1916.00333  last_update 78\n",
      "train: iter 1000  trainloss -1986.94277  validloss -1890.79961±0.00000  bestvalidloss -1916.00333  last_update 79\n",
      "train: iter 1001  trainloss -2027.59590  validloss -1827.63721±0.00000  bestvalidloss -1916.00333  last_update 80\n",
      "train: iter 1002  trainloss -2041.84148  validloss -1902.02545±0.00000  bestvalidloss -1916.00333  last_update 81\n",
      "train: iter 1003  trainloss -2050.27312  validloss -1887.07379±0.00000  bestvalidloss -1916.00333  last_update 82\n",
      "train: iter 1004  trainloss -1990.20611  validloss -1898.40352±0.00000  bestvalidloss -1916.00333  last_update 83\n",
      "train: iter 1005  trainloss -1791.70861  validloss -1243.60669±0.00000  bestvalidloss -1916.00333  last_update 84\n",
      "train: iter 1006  trainloss -2027.42857  validloss -1824.32810±0.00000  bestvalidloss -1916.00333  last_update 85\n",
      "train: iter 1007  trainloss -2005.81786  validloss -1870.65103±0.00000  bestvalidloss -1916.00333  last_update 86\n",
      "train: iter 1008  trainloss -2048.28362  validloss -1885.30322±0.00000  bestvalidloss -1916.00333  last_update 87\n",
      "train: iter 1009  trainloss -2038.04972  validloss -1899.55219±0.00000  bestvalidloss -1916.00333  last_update 88\n",
      "train: iter 1010  trainloss -2038.26469  validloss -1874.87380±0.00000  bestvalidloss -1916.00333  last_update 89\n",
      "train: iter 1011  trainloss -2013.44221  validloss -1859.78914±0.00000  bestvalidloss -1916.00333  last_update 90\n",
      "train: iter 1012  trainloss -1981.85075  validloss -1877.79576±0.00000  bestvalidloss -1916.00333  last_update 91\n",
      "train: iter 1013  trainloss -2002.87876  validloss -1807.20169±0.00000  bestvalidloss -1916.00333  last_update 92\n",
      "train: iter 1014  trainloss -2035.61497  validloss -1632.54924±0.00000  bestvalidloss -1916.00333  last_update 93\n",
      "train: iter 1015  trainloss -2050.10223  validloss -1887.21990±0.00000  bestvalidloss -1916.00333  last_update 94\n",
      "train: iter 1016  trainloss -1972.84322  validloss -1885.59565±0.00000  bestvalidloss -1916.00333  last_update 95\n",
      "train: iter 1017  trainloss -2042.76365  validloss -1869.43126±0.00000  bestvalidloss -1916.00333  last_update 96\n",
      "train: iter 1018  trainloss -2033.42162  validloss -1883.65586±0.00000  bestvalidloss -1916.00333  last_update 97\n",
      "train: iter 1019  trainloss -1936.36088  validloss -1880.64678±0.00000  bestvalidloss -1916.00333  last_update 98\n",
      "train: iter 1020  trainloss -2016.86405  validloss -1762.91949±0.00000  bestvalidloss -1916.00333  last_update 99\n",
      "train: iter 1021  trainloss -2037.44423  validloss -1881.09020±0.00000  bestvalidloss -1916.00333  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3193) penalty_target_max tensor(6.2573)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.81597  validloss 4.99343±0.00000  bestvalidloss 4.99343  last_update 0\n",
      "train: iter 1  trainloss 4.46352  validloss 4.59208±0.00000  bestvalidloss 4.59208  last_update 0\n",
      "train: iter 2  trainloss 4.16188  validloss 4.26168±0.00000  bestvalidloss 4.26168  last_update 0\n",
      "train: iter 3  trainloss 3.90544  validloss 4.00430±0.00000  bestvalidloss 4.00430  last_update 0\n",
      "train: iter 4  trainloss 3.68808  validloss 3.76584±0.00000  bestvalidloss 3.76584  last_update 0\n",
      "train: iter 5  trainloss 3.48101  validloss 3.55929±0.00000  bestvalidloss 3.55929  last_update 0\n",
      "train: iter 6  trainloss 3.29934  validloss 3.36996±0.00000  bestvalidloss 3.36996  last_update 0\n",
      "train: iter 7  trainloss 3.12175  validloss 3.19079±0.00000  bestvalidloss 3.19079  last_update 0\n",
      "train: iter 8  trainloss 2.95441  validloss 3.03139±0.00000  bestvalidloss 3.03139  last_update 0\n",
      "train: iter 9  trainloss 2.79840  validloss 2.86787±0.00000  bestvalidloss 2.86787  last_update 0\n",
      "train: iter 10  trainloss 2.65335  validloss 2.71516±0.00000  bestvalidloss 2.71516  last_update 0\n",
      "train: iter 11  trainloss 2.51330  validloss 2.56729±0.00000  bestvalidloss 2.56729  last_update 0\n",
      "train: iter 12  trainloss 2.38665  validloss 2.43943±0.00000  bestvalidloss 2.43943  last_update 0\n",
      "train: iter 13  trainloss 2.26836  validloss 2.30681±0.00000  bestvalidloss 2.30681  last_update 0\n",
      "train: iter 14  trainloss 2.15504  validloss 2.19195±0.00000  bestvalidloss 2.19195  last_update 0\n",
      "train: iter 15  trainloss 2.05102  validloss 2.08162±0.00000  bestvalidloss 2.08162  last_update 0\n",
      "train: iter 16  trainloss 1.95499  validloss 1.97767±0.00000  bestvalidloss 1.97767  last_update 0\n",
      "train: iter 17  trainloss 1.86534  validloss 1.89313±0.00000  bestvalidloss 1.89313  last_update 0\n",
      "train: iter 18  trainloss 1.78600  validloss 1.80692±0.00000  bestvalidloss 1.80692  last_update 0\n",
      "train: iter 19  trainloss 1.70215  validloss 1.72203±0.00000  bestvalidloss 1.72203  last_update 0\n",
      "train: iter 20  trainloss 1.62409  validloss 1.64320±0.00000  bestvalidloss 1.64320  last_update 0\n",
      "train: iter 21  trainloss 1.54584  validloss 1.56247±0.00000  bestvalidloss 1.56247  last_update 0\n",
      "train: iter 22  trainloss 1.47328  validloss 1.48422±0.00000  bestvalidloss 1.48422  last_update 0\n",
      "train: iter 23  trainloss 1.39136  validloss 1.40800±0.00000  bestvalidloss 1.40800  last_update 0\n",
      "train: iter 24  trainloss 1.31110  validloss 1.33029±0.00000  bestvalidloss 1.33029  last_update 0\n",
      "train: iter 25  trainloss 1.23324  validloss 1.24850±0.00000  bestvalidloss 1.24850  last_update 0\n",
      "train: iter 26  trainloss 1.15305  validloss 1.16803±0.00000  bestvalidloss 1.16803  last_update 0\n",
      "train: iter 27  trainloss 1.07090  validloss 1.08577±0.00000  bestvalidloss 1.08577  last_update 0\n",
      "train: iter 28  trainloss 0.98812  validloss 1.00964±0.00000  bestvalidloss 1.00964  last_update 0\n",
      "train: iter 29  trainloss 0.91198  validloss 0.92472±0.00000  bestvalidloss 0.92472  last_update 0\n",
      "train: iter 30  trainloss 0.82727  validloss 0.84970±0.00000  bestvalidloss 0.84970  last_update 0\n",
      "train: iter 31  trainloss 0.74222  validloss 0.75397±0.00000  bestvalidloss 0.75397  last_update 0\n",
      "train: iter 32  trainloss 0.64974  validloss 0.66803±0.00000  bestvalidloss 0.66803  last_update 0\n",
      "train: iter 33  trainloss 0.57617  validloss 0.58206±0.00000  bestvalidloss 0.58206  last_update 0\n",
      "train: iter 34  trainloss 0.49309  validloss 0.49851±0.00000  bestvalidloss 0.49851  last_update 0\n",
      "train: iter 35  trainloss 0.41142  validloss 0.42287±0.00000  bestvalidloss 0.42287  last_update 0\n",
      "train: iter 36  trainloss 0.33072  validloss 0.34159±0.00000  bestvalidloss 0.34159  last_update 0\n",
      "train: iter 37  trainloss 0.25757  validloss 0.24751±0.00000  bestvalidloss 0.24751  last_update 0\n",
      "train: iter 38  trainloss 0.18012  validloss 0.17735±0.00000  bestvalidloss 0.17735  last_update 0\n",
      "train: iter 39  trainloss 0.11441  validloss 0.10115±0.00000  bestvalidloss 0.10115  last_update 0\n",
      "train: iter 40  trainloss 0.04333  validloss 0.04429±0.00000  bestvalidloss 0.04429  last_update 0\n",
      "train: iter 41  trainloss -0.03044  validloss -0.02870±0.00000  bestvalidloss -0.02870  last_update 0\n",
      "train: iter 42  trainloss -0.08362  validloss -0.10328±0.00000  bestvalidloss -0.10328  last_update 0\n",
      "train: iter 43  trainloss -0.13480  validloss -0.17258±0.00000  bestvalidloss -0.17258  last_update 0\n",
      "train: iter 44  trainloss -0.18914  validloss -0.24302±0.00000  bestvalidloss -0.24302  last_update 0\n",
      "train: iter 45  trainloss -0.24864  validloss -0.27720±0.00000  bestvalidloss -0.27720  last_update 0\n",
      "train: iter 46  trainloss -0.29731  validloss -0.33927±0.00000  bestvalidloss -0.33927  last_update 0\n",
      "train: iter 47  trainloss -0.34332  validloss -0.39057±0.00000  bestvalidloss -0.39057  last_update 0\n",
      "train: iter 48  trainloss -0.39205  validloss -0.43412±0.00000  bestvalidloss -0.43412  last_update 0\n",
      "train: iter 49  trainloss -0.45294  validloss -0.46474±0.00000  bestvalidloss -0.46474  last_update 0\n",
      "train: iter 50  trainloss -0.48518  validloss -0.53229±0.00000  bestvalidloss -0.53229  last_update 0\n",
      "train: iter 51  trainloss -0.53075  validloss -0.57992±0.00000  bestvalidloss -0.57992  last_update 0\n",
      "train: iter 52  trainloss -0.56954  validloss -0.61322±0.00000  bestvalidloss -0.61322  last_update 0\n",
      "train: iter 53  trainloss -0.62053  validloss -0.66208±0.00000  bestvalidloss -0.66208  last_update 0\n",
      "train: iter 54  trainloss -0.67309  validloss -0.72446±0.00000  bestvalidloss -0.72446  last_update 0\n",
      "train: iter 55  trainloss -0.69837  validloss -0.76230±0.00000  bestvalidloss -0.76230  last_update 0\n",
      "train: iter 56  trainloss -0.73547  validloss -0.79561±0.00000  bestvalidloss -0.79561  last_update 0\n",
      "train: iter 57  trainloss -0.78514  validloss -0.82439±0.00000  bestvalidloss -0.82439  last_update 0\n",
      "train: iter 58  trainloss -0.83467  validloss -0.91447±0.00000  bestvalidloss -0.91447  last_update 0\n",
      "train: iter 59  trainloss -0.86594  validloss -0.91373±0.00000  bestvalidloss -0.91447  last_update 1\n",
      "train: iter 60  trainloss -0.91352  validloss -0.98582±0.00000  bestvalidloss -0.98582  last_update 0\n",
      "train: iter 61  trainloss -0.96304  validloss -0.97268±0.00000  bestvalidloss -0.98582  last_update 1\n",
      "train: iter 62  trainloss -1.03770  validloss -1.05835±0.00000  bestvalidloss -1.05835  last_update 0\n",
      "train: iter 63  trainloss -1.02280  validloss -1.05791±0.00000  bestvalidloss -1.05835  last_update 1\n",
      "train: iter 64  trainloss -1.07293  validloss -1.14255±0.00000  bestvalidloss -1.14255  last_update 0\n",
      "train: iter 65  trainloss -1.09509  validloss -1.16893±0.00000  bestvalidloss -1.16893  last_update 0\n",
      "train: iter 66  trainloss -1.15296  validloss -1.19809±0.00000  bestvalidloss -1.19809  last_update 0\n",
      "train: iter 67  trainloss -1.15738  validloss -1.21942±0.00000  bestvalidloss -1.21942  last_update 0\n",
      "train: iter 68  trainloss -1.20105  validloss -1.23072±0.00000  bestvalidloss -1.23072  last_update 0\n",
      "train: iter 69  trainloss -1.24157  validloss -1.29113±0.00000  bestvalidloss -1.29113  last_update 0\n",
      "train: iter 70  trainloss -1.24856  validloss -1.30931±0.00000  bestvalidloss -1.30931  last_update 0\n",
      "train: iter 71  trainloss -1.30834  validloss -1.33486±0.00000  bestvalidloss -1.33486  last_update 0\n",
      "train: iter 72  trainloss -1.32110  validloss -1.39551±0.00000  bestvalidloss -1.39551  last_update 0\n",
      "train: iter 73  trainloss -1.33896  validloss -1.42163±0.00000  bestvalidloss -1.42163  last_update 0\n",
      "train: iter 74  trainloss -1.37640  validloss -1.48698±0.00000  bestvalidloss -1.48698  last_update 0\n",
      "train: iter 75  trainloss -1.39265  validloss -1.43302±0.00000  bestvalidloss -1.48698  last_update 1\n",
      "train: iter 76  trainloss -1.44179  validloss -1.47675±0.00000  bestvalidloss -1.48698  last_update 2\n",
      "train: iter 77  trainloss -1.45557  validloss -1.43174±0.00000  bestvalidloss -1.48698  last_update 3\n",
      "train: iter 78  trainloss -1.47814  validloss -1.47027±0.00000  bestvalidloss -1.48698  last_update 4\n",
      "train: iter 79  trainloss -1.52516  validloss -1.56569±0.00000  bestvalidloss -1.56569  last_update 0\n",
      "train: iter 80  trainloss -1.54934  validloss -1.63037±0.00000  bestvalidloss -1.63037  last_update 0\n",
      "train: iter 81  trainloss -1.56457  validloss -1.57180±0.00000  bestvalidloss -1.63037  last_update 1\n",
      "train: iter 82  trainloss -1.60101  validloss -1.63499±0.00000  bestvalidloss -1.63499  last_update 0\n",
      "train: iter 83  trainloss -1.58031  validloss -1.63944±0.00000  bestvalidloss -1.63944  last_update 0\n",
      "train: iter 84  trainloss -1.64165  validloss -1.67194±0.00000  bestvalidloss -1.67194  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss -1.70205  validloss -1.61400±0.00000  bestvalidloss -1.67194  last_update 1\n",
      "train: iter 86  trainloss -1.68232  validloss -1.71885±0.00000  bestvalidloss -1.71885  last_update 0\n",
      "train: iter 87  trainloss -1.61882  validloss -1.62645±0.00000  bestvalidloss -1.71885  last_update 1\n",
      "train: iter 88  trainloss -1.67122  validloss -1.69736±0.00000  bestvalidloss -1.71885  last_update 2\n",
      "train: iter 89  trainloss -1.65179  validloss -1.59688±0.00000  bestvalidloss -1.71885  last_update 3\n",
      "train: iter 90  trainloss -1.71994  validloss -1.69417±0.00000  bestvalidloss -1.71885  last_update 4\n",
      "train: iter 91  trainloss -1.69232  validloss -1.68343±0.00000  bestvalidloss -1.71885  last_update 5\n",
      "train: iter 92  trainloss -1.72304  validloss -1.74119±0.00000  bestvalidloss -1.74119  last_update 0\n",
      "train: iter 93  trainloss -1.73122  validloss -1.81640±0.00000  bestvalidloss -1.81640  last_update 0\n",
      "train: iter 94  trainloss -1.75767  validloss -1.78059±0.00000  bestvalidloss -1.81640  last_update 1\n",
      "train: iter 95  trainloss -1.73444  validloss -1.61401±0.00000  bestvalidloss -1.81640  last_update 2\n",
      "train: iter 96  trainloss -1.73967  validloss -1.75230±0.00000  bestvalidloss -1.81640  last_update 3\n",
      "train: iter 97  trainloss -1.73772  validloss -1.70293±0.00000  bestvalidloss -1.81640  last_update 4\n",
      "train: iter 98  trainloss -1.73981  validloss -1.69000±0.00000  bestvalidloss -1.81640  last_update 5\n",
      "train: iter 99  trainloss -1.76290  validloss -1.66683±0.00000  bestvalidloss -1.81640  last_update 6\n",
      "train: iter 100  trainloss -1.78135  validloss -1.67959±0.00000  bestvalidloss -1.81640  last_update 7\n",
      "train: iter 101  trainloss -1.78226  validloss -1.77425±0.00000  bestvalidloss -1.81640  last_update 8\n",
      "train: iter 102  trainloss -1.76647  validloss -1.66683±0.00000  bestvalidloss -1.81640  last_update 9\n",
      "train: iter 103  trainloss -1.74021  validloss -1.79573±0.00000  bestvalidloss -1.81640  last_update 10\n",
      "train: iter 104  trainloss -1.76413  validloss -1.73779±0.00000  bestvalidloss -1.81640  last_update 11\n",
      "train: iter 105  trainloss -1.75410  validloss -1.80026±0.00000  bestvalidloss -1.81640  last_update 12\n",
      "train: iter 106  trainloss -1.76711  validloss -1.72682±0.00000  bestvalidloss -1.81640  last_update 13\n",
      "train: iter 107  trainloss -1.81238  validloss -1.63019±0.00000  bestvalidloss -1.81640  last_update 14\n",
      "train: iter 108  trainloss -1.78650  validloss -1.83290±0.00000  bestvalidloss -1.83290  last_update 0\n",
      "train: iter 109  trainloss -1.77565  validloss -1.83689±0.00000  bestvalidloss -1.83689  last_update 0\n",
      "train: iter 110  trainloss -1.80809  validloss -1.72638±0.00000  bestvalidloss -1.83689  last_update 1\n",
      "train: iter 111  trainloss -1.75917  validloss -1.73985±0.00000  bestvalidloss -1.83689  last_update 2\n",
      "train: iter 112  trainloss -1.77072  validloss -1.64743±0.00000  bestvalidloss -1.83689  last_update 3\n",
      "train: iter 113  trainloss -1.74474  validloss -1.66726±0.00000  bestvalidloss -1.83689  last_update 4\n",
      "train: iter 114  trainloss -1.81474  validloss -1.74159±0.00000  bestvalidloss -1.83689  last_update 5\n",
      "train: iter 115  trainloss -1.80128  validloss -1.71525±0.00000  bestvalidloss -1.83689  last_update 6\n",
      "train: iter 116  trainloss -1.78791  validloss -1.79502±0.00000  bestvalidloss -1.83689  last_update 7\n",
      "train: iter 117  trainloss -1.74627  validloss -1.69142±0.00000  bestvalidloss -1.83689  last_update 8\n",
      "train: iter 118  trainloss -1.79299  validloss -1.61742±0.00000  bestvalidloss -1.83689  last_update 9\n",
      "train: iter 119  trainloss -1.78395  validloss -1.70853±0.00000  bestvalidloss -1.83689  last_update 10\n",
      "train: iter 120  trainloss -1.79075  validloss -1.69589±0.00000  bestvalidloss -1.83689  last_update 11\n",
      "train: iter 121  trainloss -1.79612  validloss -1.75773±0.00000  bestvalidloss -1.83689  last_update 12\n",
      "train: iter 122  trainloss -1.77281  validloss -1.77316±0.00000  bestvalidloss -1.83689  last_update 13\n",
      "train: iter 123  trainloss -1.78202  validloss -1.73428±0.00000  bestvalidloss -1.83689  last_update 14\n",
      "train: iter 124  trainloss -1.79568  validloss -1.66845±0.00000  bestvalidloss -1.83689  last_update 15\n",
      "train: iter 125  trainloss -1.74323  validloss -1.78504±0.00000  bestvalidloss -1.83689  last_update 16\n",
      "train: iter 126  trainloss -1.72900  validloss -1.62711±0.00000  bestvalidloss -1.83689  last_update 17\n",
      "train: iter 127  trainloss -1.74631  validloss -1.73929±0.00000  bestvalidloss -1.83689  last_update 18\n",
      "train: iter 128  trainloss -1.77477  validloss -1.72552±0.00000  bestvalidloss -1.83689  last_update 19\n",
      "train: iter 129  trainloss -1.81114  validloss -1.68467±0.00000  bestvalidloss -1.83689  last_update 20\n",
      "train: iter 130  trainloss -1.77378  validloss -1.65021±0.00000  bestvalidloss -1.83689  last_update 21\n",
      "train: iter 131  trainloss -1.74645  validloss -1.75675±0.00000  bestvalidloss -1.83689  last_update 22\n",
      "train: iter 132  trainloss -1.76374  validloss -1.66157±0.00000  bestvalidloss -1.83689  last_update 23\n",
      "train: iter 133  trainloss -1.83541  validloss -1.76264±0.00000  bestvalidloss -1.83689  last_update 24\n",
      "train: iter 134  trainloss -1.75657  validloss -1.62093±0.00000  bestvalidloss -1.83689  last_update 25\n",
      "train: iter 135  trainloss -1.77887  validloss -1.79970±0.00000  bestvalidloss -1.83689  last_update 26\n",
      "train: iter 136  trainloss -1.76698  validloss -1.77887±0.00000  bestvalidloss -1.83689  last_update 27\n",
      "train: iter 137  trainloss -1.74271  validloss -1.70249±0.00000  bestvalidloss -1.83689  last_update 28\n",
      "train: iter 138  trainloss -1.79248  validloss -1.70843±0.00000  bestvalidloss -1.83689  last_update 29\n",
      "train: iter 139  trainloss -1.75105  validloss -1.74279±0.00000  bestvalidloss -1.83689  last_update 30\n",
      "train: iter 140  trainloss -1.84228  validloss -1.72407±0.00000  bestvalidloss -1.83689  last_update 31\n",
      "train: iter 141  trainloss -1.78120  validloss -1.76661±0.00000  bestvalidloss -1.83689  last_update 32\n",
      "train: iter 142  trainloss -1.84253  validloss -1.72597±0.00000  bestvalidloss -1.83689  last_update 33\n",
      "train: iter 143  trainloss -1.84423  validloss -1.67165±0.00000  bestvalidloss -1.83689  last_update 34\n",
      "train: iter 144  trainloss -1.86273  validloss -1.69666±0.00000  bestvalidloss -1.83689  last_update 35\n",
      "train: iter 145  trainloss -1.76989  validloss -1.75957±0.00000  bestvalidloss -1.83689  last_update 36\n",
      "train: iter 146  trainloss -1.82070  validloss -1.84294±0.00000  bestvalidloss -1.84294  last_update 0\n",
      "train: iter 147  trainloss -1.77483  validloss -1.72654±0.00000  bestvalidloss -1.84294  last_update 1\n",
      "train: iter 148  trainloss -1.78577  validloss -1.68426±0.00000  bestvalidloss -1.84294  last_update 2\n",
      "train: iter 149  trainloss -1.82563  validloss -1.77253±0.00000  bestvalidloss -1.84294  last_update 3\n",
      "train: iter 150  trainloss -1.78443  validloss -1.64013±0.00000  bestvalidloss -1.84294  last_update 4\n",
      "train: iter 151  trainloss -1.79379  validloss -1.71135±0.00000  bestvalidloss -1.84294  last_update 5\n",
      "train: iter 152  trainloss -1.73116  validloss -1.58509±0.00000  bestvalidloss -1.84294  last_update 6\n",
      "train: iter 153  trainloss -1.84586  validloss -1.78017±0.00000  bestvalidloss -1.84294  last_update 7\n",
      "train: iter 154  trainloss -1.76424  validloss -1.64672±0.00000  bestvalidloss -1.84294  last_update 8\n",
      "train: iter 155  trainloss -1.78166  validloss -1.71200±0.00000  bestvalidloss -1.84294  last_update 9\n",
      "train: iter 156  trainloss -1.74182  validloss -1.70686±0.00000  bestvalidloss -1.84294  last_update 10\n",
      "train: iter 157  trainloss -1.80194  validloss -1.78221±0.00000  bestvalidloss -1.84294  last_update 11\n",
      "train: iter 158  trainloss -1.77101  validloss -1.68782±0.00000  bestvalidloss -1.84294  last_update 12\n",
      "train: iter 159  trainloss -1.80086  validloss -1.66040±0.00000  bestvalidloss -1.84294  last_update 13\n",
      "train: iter 160  trainloss -1.81715  validloss -1.56376±0.00000  bestvalidloss -1.84294  last_update 14\n",
      "train: iter 161  trainloss -1.79804  validloss -1.94763±0.00000  bestvalidloss -1.94763  last_update 0\n",
      "train: iter 162  trainloss -1.74151  validloss -1.70047±0.00000  bestvalidloss -1.94763  last_update 1\n",
      "train: iter 163  trainloss -1.71968  validloss -1.76201±0.00000  bestvalidloss -1.94763  last_update 2\n",
      "train: iter 164  trainloss -1.84771  validloss -1.75899±0.00000  bestvalidloss -1.94763  last_update 3\n",
      "train: iter 165  trainloss -1.78005  validloss -1.78384±0.00000  bestvalidloss -1.94763  last_update 4\n",
      "train: iter 166  trainloss -1.78356  validloss -1.64596±0.00000  bestvalidloss -1.94763  last_update 5\n",
      "train: iter 167  trainloss -1.73541  validloss -1.73469±0.00000  bestvalidloss -1.94763  last_update 6\n",
      "train: iter 168  trainloss -1.80718  validloss -1.75255±0.00000  bestvalidloss -1.94763  last_update 7\n",
      "train: iter 169  trainloss -1.73917  validloss -1.70751±0.00000  bestvalidloss -1.94763  last_update 8\n",
      "train: iter 170  trainloss -1.78080  validloss -1.88451±0.00000  bestvalidloss -1.94763  last_update 9\n",
      "train: iter 171  trainloss -1.82693  validloss -1.65302±0.00000  bestvalidloss -1.94763  last_update 10\n",
      "train: iter 172  trainloss -1.75880  validloss -1.72196±0.00000  bestvalidloss -1.94763  last_update 11\n",
      "train: iter 173  trainloss -1.80991  validloss -1.68987±0.00000  bestvalidloss -1.94763  last_update 12\n",
      "train: iter 174  trainloss -1.80356  validloss -1.82629±0.00000  bestvalidloss -1.94763  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 175  trainloss -1.80895  validloss -1.72303±0.00000  bestvalidloss -1.94763  last_update 14\n",
      "train: iter 176  trainloss -1.71273  validloss -1.83152±0.00000  bestvalidloss -1.94763  last_update 15\n",
      "train: iter 177  trainloss -1.71800  validloss -1.81213±0.00000  bestvalidloss -1.94763  last_update 16\n",
      "train: iter 178  trainloss -1.76635  validloss -1.74906±0.00000  bestvalidloss -1.94763  last_update 17\n",
      "train: iter 179  trainloss -1.82356  validloss -1.71633±0.00000  bestvalidloss -1.94763  last_update 18\n",
      "train: iter 180  trainloss -1.78226  validloss -1.77090±0.00000  bestvalidloss -1.94763  last_update 19\n",
      "train: iter 181  trainloss -1.83539  validloss -1.59981±0.00000  bestvalidloss -1.94763  last_update 20\n",
      "train: iter 182  trainloss -1.80335  validloss -1.76162±0.00000  bestvalidloss -1.94763  last_update 21\n",
      "train: iter 183  trainloss -1.84148  validloss -1.74962±0.00000  bestvalidloss -1.94763  last_update 22\n",
      "train: iter 184  trainloss -1.81536  validloss -1.85534±0.00000  bestvalidloss -1.94763  last_update 23\n",
      "train: iter 185  trainloss -1.83534  validloss -1.74114±0.00000  bestvalidloss -1.94763  last_update 24\n",
      "train: iter 186  trainloss -1.80590  validloss -1.53395±0.00000  bestvalidloss -1.94763  last_update 25\n",
      "train: iter 187  trainloss -1.78885  validloss -1.69159±0.00000  bestvalidloss -1.94763  last_update 26\n",
      "train: iter 188  trainloss -1.80970  validloss -1.73418±0.00000  bestvalidloss -1.94763  last_update 27\n",
      "train: iter 189  trainloss -1.77210  validloss -1.67284±0.00000  bestvalidloss -1.94763  last_update 28\n",
      "train: iter 190  trainloss -1.80539  validloss -1.71013±0.00000  bestvalidloss -1.94763  last_update 29\n",
      "train: iter 191  trainloss -1.86317  validloss -1.71979±0.00000  bestvalidloss -1.94763  last_update 30\n",
      "train: iter 192  trainloss -1.78942  validloss -1.68033±0.00000  bestvalidloss -1.94763  last_update 31\n",
      "train: iter 193  trainloss -1.78190  validloss -1.75585±0.00000  bestvalidloss -1.94763  last_update 32\n",
      "train: iter 194  trainloss -1.82740  validloss -1.82206±0.00000  bestvalidloss -1.94763  last_update 33\n",
      "train: iter 195  trainloss -1.77431  validloss -1.63671±0.00000  bestvalidloss -1.94763  last_update 34\n",
      "train: iter 196  trainloss -1.77659  validloss -1.84469±0.00000  bestvalidloss -1.94763  last_update 35\n",
      "train: iter 197  trainloss -1.82277  validloss -1.63834±0.00000  bestvalidloss -1.94763  last_update 36\n",
      "train: iter 198  trainloss -1.81075  validloss -1.77740±0.00000  bestvalidloss -1.94763  last_update 37\n",
      "train: iter 199  trainloss -1.77276  validloss -1.80415±0.00000  bestvalidloss -1.94763  last_update 38\n",
      "train: iter 200  trainloss -1.82271  validloss -1.68470±0.00000  bestvalidloss -1.94763  last_update 39\n",
      "train: iter 201  trainloss -1.81399  validloss -1.63990±0.00000  bestvalidloss -1.94763  last_update 40\n",
      "train: iter 202  trainloss -1.78246  validloss -1.73148±0.00000  bestvalidloss -1.94763  last_update 41\n",
      "train: iter 203  trainloss -1.75610  validloss -1.61839±0.00000  bestvalidloss -1.94763  last_update 42\n",
      "train: iter 204  trainloss -1.75957  validloss -1.57370±0.00000  bestvalidloss -1.94763  last_update 43\n",
      "train: iter 205  trainloss -1.76063  validloss -1.71189±0.00000  bestvalidloss -1.94763  last_update 44\n",
      "train: iter 206  trainloss -1.81278  validloss -1.72916±0.00000  bestvalidloss -1.94763  last_update 45\n",
      "train: iter 207  trainloss -1.74219  validloss -1.70727±0.00000  bestvalidloss -1.94763  last_update 46\n",
      "train: iter 208  trainloss -1.76318  validloss -1.65677±0.00000  bestvalidloss -1.94763  last_update 47\n",
      "train: iter 209  trainloss -1.76209  validloss -1.79185±0.00000  bestvalidloss -1.94763  last_update 48\n",
      "train: iter 210  trainloss -1.79777  validloss -1.72142±0.00000  bestvalidloss -1.94763  last_update 49\n",
      "train: iter 211  trainloss -1.77635  validloss -1.61800±0.00000  bestvalidloss -1.94763  last_update 50\n",
      "train: iter 212  trainloss -1.78446  validloss -1.66897±0.00000  bestvalidloss -1.94763  last_update 51\n",
      "train: iter 213  trainloss -1.76397  validloss -1.60370±0.00000  bestvalidloss -1.94763  last_update 52\n",
      "train: iter 214  trainloss -1.80278  validloss -1.81245±0.00000  bestvalidloss -1.94763  last_update 53\n",
      "train: iter 215  trainloss -1.77765  validloss -1.60439±0.00000  bestvalidloss -1.94763  last_update 54\n",
      "train: iter 216  trainloss -1.79486  validloss -1.60577±0.00000  bestvalidloss -1.94763  last_update 55\n",
      "train: iter 217  trainloss -1.80060  validloss -1.72782±0.00000  bestvalidloss -1.94763  last_update 56\n",
      "train: iter 218  trainloss -1.78697  validloss -1.65598±0.00000  bestvalidloss -1.94763  last_update 57\n",
      "train: iter 219  trainloss -1.77845  validloss -1.71559±0.00000  bestvalidloss -1.94763  last_update 58\n",
      "train: iter 220  trainloss -1.80220  validloss -1.75570±0.00000  bestvalidloss -1.94763  last_update 59\n",
      "train: iter 221  trainloss -1.81593  validloss -1.67380±0.00000  bestvalidloss -1.94763  last_update 60\n",
      "train: iter 222  trainloss -1.82739  validloss -1.70024±0.00000  bestvalidloss -1.94763  last_update 61\n",
      "train: iter 223  trainloss -1.77177  validloss -1.80309±0.00000  bestvalidloss -1.94763  last_update 62\n",
      "train: iter 224  trainloss -1.77194  validloss -1.72506±0.00000  bestvalidloss -1.94763  last_update 63\n",
      "train: iter 225  trainloss -1.74633  validloss -1.56276±0.00000  bestvalidloss -1.94763  last_update 64\n",
      "train: iter 226  trainloss -1.78711  validloss -1.56367±0.00000  bestvalidloss -1.94763  last_update 65\n",
      "train: iter 227  trainloss -1.83252  validloss -1.67704±0.00000  bestvalidloss -1.94763  last_update 66\n",
      "train: iter 228  trainloss -1.81083  validloss -1.76501±0.00000  bestvalidloss -1.94763  last_update 67\n",
      "train: iter 229  trainloss -1.82592  validloss -1.70843±0.00000  bestvalidloss -1.94763  last_update 68\n",
      "train: iter 230  trainloss -1.79954  validloss -1.72341±0.00000  bestvalidloss -1.94763  last_update 69\n",
      "train: iter 231  trainloss -1.78690  validloss -1.74941±0.00000  bestvalidloss -1.94763  last_update 70\n",
      "train: iter 232  trainloss -1.78139  validloss -1.61725±0.00000  bestvalidloss -1.94763  last_update 71\n",
      "train: iter 233  trainloss -1.74771  validloss -1.72321±0.00000  bestvalidloss -1.94763  last_update 72\n",
      "train: iter 234  trainloss -1.82625  validloss -1.78183±0.00000  bestvalidloss -1.94763  last_update 73\n",
      "train: iter 235  trainloss -1.83976  validloss -1.80550±0.00000  bestvalidloss -1.94763  last_update 74\n",
      "train: iter 236  trainloss -1.80184  validloss -1.69346±0.00000  bestvalidloss -1.94763  last_update 75\n",
      "train: iter 237  trainloss -1.79069  validloss -1.78911±0.00000  bestvalidloss -1.94763  last_update 76\n",
      "train: iter 238  trainloss -1.78127  validloss -1.70846±0.00000  bestvalidloss -1.94763  last_update 77\n",
      "train: iter 239  trainloss -1.79832  validloss -1.72389±0.00000  bestvalidloss -1.94763  last_update 78\n",
      "train: iter 240  trainloss -1.76471  validloss -1.72416±0.00000  bestvalidloss -1.94763  last_update 79\n",
      "train: iter 241  trainloss -1.84728  validloss -1.77531±0.00000  bestvalidloss -1.94763  last_update 80\n",
      "train: iter 242  trainloss -1.78946  validloss -1.69576±0.00000  bestvalidloss -1.94763  last_update 81\n",
      "train: iter 243  trainloss -1.81500  validloss -1.71506±0.00000  bestvalidloss -1.94763  last_update 82\n",
      "train: iter 244  trainloss -1.78346  validloss -1.72397±0.00000  bestvalidloss -1.94763  last_update 83\n",
      "train: iter 245  trainloss -1.83760  validloss -1.75402±0.00000  bestvalidloss -1.94763  last_update 84\n",
      "train: iter 246  trainloss -1.82438  validloss -1.77776±0.00000  bestvalidloss -1.94763  last_update 85\n",
      "train: iter 247  trainloss -1.75456  validloss -1.56817±0.00000  bestvalidloss -1.94763  last_update 86\n",
      "train: iter 248  trainloss -1.79219  validloss -1.70195±0.00000  bestvalidloss -1.94763  last_update 87\n",
      "train: iter 249  trainloss -1.70701  validloss -1.61437±0.00000  bestvalidloss -1.94763  last_update 88\n",
      "train: iter 250  trainloss -1.81906  validloss -1.78274±0.00000  bestvalidloss -1.94763  last_update 89\n",
      "train: iter 251  trainloss -1.74007  validloss -1.70686±0.00000  bestvalidloss -1.94763  last_update 90\n",
      "train: iter 252  trainloss -1.76793  validloss -1.63285±0.00000  bestvalidloss -1.94763  last_update 91\n",
      "train: iter 253  trainloss -1.81820  validloss -1.71027±0.00000  bestvalidloss -1.94763  last_update 92\n",
      "train: iter 254  trainloss -1.83790  validloss -1.71416±0.00000  bestvalidloss -1.94763  last_update 93\n",
      "train: iter 255  trainloss -1.81293  validloss -1.66953±0.00000  bestvalidloss -1.94763  last_update 94\n",
      "train: iter 256  trainloss -1.75109  validloss -1.75946±0.00000  bestvalidloss -1.94763  last_update 95\n",
      "train: iter 257  trainloss -1.78369  validloss -1.73558±0.00000  bestvalidloss -1.94763  last_update 96\n",
      "train: iter 258  trainloss -1.82348  validloss -1.65390±0.00000  bestvalidloss -1.94763  last_update 97\n",
      "train: iter 259  trainloss -1.75851  validloss -1.70639±0.00000  bestvalidloss -1.94763  last_update 98\n",
      "train: iter 260  trainloss -1.78307  validloss -1.58547±0.00000  bestvalidloss -1.94763  last_update 99\n",
      "train: iter 261  trainloss -1.78559  validloss -1.72503±0.00000  bestvalidloss -1.94763  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.1338, -2.2508, -4.0849, -5.1723], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 99.60615  validloss 97.17910±0.00000  bestvalidloss 97.17910  last_update 0\n",
      "train: iter 1  trainloss 73.77340  validloss 77.14178±0.00000  bestvalidloss 77.14178  last_update 0\n",
      "train: iter 2  trainloss 52.53975  validloss 52.95061±0.00000  bestvalidloss 52.95061  last_update 0\n",
      "train: iter 3  trainloss 40.53590  validloss 38.92664±0.00000  bestvalidloss 38.92664  last_update 0\n",
      "train: iter 4  trainloss 31.83669  validloss 30.17403±0.00000  bestvalidloss 30.17403  last_update 0\n",
      "train: iter 5  trainloss 25.21159  validloss 23.64931±0.00000  bestvalidloss 23.64931  last_update 0\n",
      "train: iter 6  trainloss 20.09101  validloss 18.63675±0.00000  bestvalidloss 18.63675  last_update 0\n",
      "train: iter 7  trainloss 16.10031  validloss 15.08567±0.00000  bestvalidloss 15.08567  last_update 0\n",
      "train: iter 8  trainloss 12.94270  validloss 12.14365±0.00000  bestvalidloss 12.14365  last_update 0\n",
      "train: iter 9  trainloss 10.57237  validloss 10.04868±0.00000  bestvalidloss 10.04868  last_update 0\n",
      "train: iter 10  trainloss 8.66374  validloss 8.60528±0.00000  bestvalidloss 8.60528  last_update 0\n",
      "train: iter 11  trainloss 7.24862  validloss 7.40670±0.00000  bestvalidloss 7.40670  last_update 0\n",
      "train: iter 12  trainloss 6.16855  validloss 6.69932±0.00000  bestvalidloss 6.69932  last_update 0\n",
      "train: iter 13  trainloss 5.37934  validloss 6.08561±0.00000  bestvalidloss 6.08561  last_update 0\n",
      "train: iter 14  trainloss 4.78979  validloss 5.84389±0.00000  bestvalidloss 5.84389  last_update 0\n",
      "train: iter 15  trainloss 4.38556  validloss 5.53402±0.00000  bestvalidloss 5.53402  last_update 0\n",
      "train: iter 16  trainloss 4.09986  validloss 5.61419±0.00000  bestvalidloss 5.53402  last_update 1\n",
      "train: iter 17  trainloss 3.92685  validloss 5.37174±0.00000  bestvalidloss 5.37174  last_update 0\n",
      "train: iter 18  trainloss 3.78363  validloss 5.68318±0.00000  bestvalidloss 5.37174  last_update 1\n",
      "train: iter 19  trainloss 3.63626  validloss 5.76543±0.00000  bestvalidloss 5.37174  last_update 2\n",
      "train: iter 20  trainloss 3.56376  validloss 5.74209±0.00000  bestvalidloss 5.37174  last_update 3\n",
      "train: iter 21  trainloss 3.44245  validloss 5.68820±0.00000  bestvalidloss 5.37174  last_update 4\n",
      "train: iter 22  trainloss 3.45689  validloss 5.65874±0.00000  bestvalidloss 5.37174  last_update 5\n",
      "train: iter 23  trainloss 3.33611  validloss 5.78295±0.00000  bestvalidloss 5.37174  last_update 6\n",
      "train: iter 24  trainloss 3.33324  validloss 5.97099±0.00000  bestvalidloss 5.37174  last_update 7\n",
      "train: iter 25  trainloss 3.20155  validloss 5.83868±0.00000  bestvalidloss 5.37174  last_update 8\n",
      "train: iter 26  trainloss 3.30746  validloss 5.93449±0.00000  bestvalidloss 5.37174  last_update 9\n",
      "train: iter 27  trainloss 3.16170  validloss 5.78242±0.00000  bestvalidloss 5.37174  last_update 10\n",
      "train: iter 28  trainloss 3.14120  validloss 5.72721±0.00000  bestvalidloss 5.37174  last_update 11\n",
      "train: iter 29  trainloss 3.15509  validloss 5.69264±0.00000  bestvalidloss 5.37174  last_update 12\n",
      "train: iter 30  trainloss 3.14976  validloss 5.66047±0.00000  bestvalidloss 5.37174  last_update 13\n",
      "train: iter 31  trainloss 3.10365  validloss 5.69878±0.00000  bestvalidloss 5.37174  last_update 14\n",
      "train: iter 32  trainloss 3.07202  validloss 5.91248±0.00000  bestvalidloss 5.37174  last_update 15\n",
      "train: iter 33  trainloss 3.07078  validloss 5.79312±0.00000  bestvalidloss 5.37174  last_update 16\n",
      "train: iter 34  trainloss 3.14683  validloss 5.69995±0.00000  bestvalidloss 5.37174  last_update 17\n",
      "train: iter 35  trainloss 3.08188  validloss 5.61084±0.00000  bestvalidloss 5.37174  last_update 18\n",
      "train: iter 36  trainloss 2.97558  validloss 5.54070±0.00000  bestvalidloss 5.37174  last_update 19\n",
      "train: iter 37  trainloss 2.80120  validloss 5.09767±0.00000  bestvalidloss 5.09767  last_update 0\n",
      "train: iter 38  trainloss 2.76526  validloss 4.50883±0.00000  bestvalidloss 4.50883  last_update 0\n",
      "train: iter 39  trainloss 2.70138  validloss 4.48699±0.00000  bestvalidloss 4.48699  last_update 0\n",
      "train: iter 40  trainloss 2.59727  validloss 4.35709±0.00000  bestvalidloss 4.35709  last_update 0\n",
      "train: iter 41  trainloss 2.71721  validloss 4.69805±0.00000  bestvalidloss 4.35709  last_update 1\n",
      "train: iter 42  trainloss 2.59475  validloss 4.24727±0.00000  bestvalidloss 4.24727  last_update 0\n",
      "train: iter 43  trainloss 2.58796  validloss 4.32480±0.00000  bestvalidloss 4.24727  last_update 1\n",
      "train: iter 44  trainloss 2.59681  validloss 3.98240±0.00000  bestvalidloss 3.98240  last_update 0\n",
      "train: iter 45  trainloss 2.50688  validloss 4.26456±0.00000  bestvalidloss 3.98240  last_update 1\n",
      "train: iter 46  trainloss 2.53454  validloss 4.15388±0.00000  bestvalidloss 3.98240  last_update 2\n",
      "train: iter 47  trainloss 2.49362  validloss 4.12159±0.00000  bestvalidloss 3.98240  last_update 3\n",
      "train: iter 48  trainloss 2.50611  validloss 4.07496±0.00000  bestvalidloss 3.98240  last_update 4\n",
      "train: iter 49  trainloss 2.46715  validloss 4.22041±0.00000  bestvalidloss 3.98240  last_update 5\n",
      "train: iter 50  trainloss 2.51085  validloss 4.43457±0.00000  bestvalidloss 3.98240  last_update 6\n",
      "train: iter 51  trainloss 2.46679  validloss 4.15990±0.00000  bestvalidloss 3.98240  last_update 7\n",
      "train: iter 52  trainloss 2.48948  validloss 4.09988±0.00000  bestvalidloss 3.98240  last_update 8\n",
      "train: iter 53  trainloss 2.49696  validloss 3.96681±0.00000  bestvalidloss 3.96681  last_update 0\n",
      "train: iter 54  trainloss 2.47787  validloss 4.07963±0.00000  bestvalidloss 3.96681  last_update 1\n",
      "train: iter 55  trainloss 2.43567  validloss 4.05952±0.00000  bestvalidloss 3.96681  last_update 2\n",
      "train: iter 56  trainloss 2.41346  validloss 4.14434±0.00000  bestvalidloss 3.96681  last_update 3\n",
      "train: iter 57  trainloss 2.35882  validloss 4.04669±0.00000  bestvalidloss 3.96681  last_update 4\n",
      "train: iter 58  trainloss 2.44518  validloss 4.08029±0.00000  bestvalidloss 3.96681  last_update 5\n",
      "train: iter 59  trainloss 2.41859  validloss 4.03350±0.00000  bestvalidloss 3.96681  last_update 6\n",
      "train: iter 60  trainloss 2.34868  validloss 4.05364±0.00000  bestvalidloss 3.96681  last_update 7\n",
      "train: iter 61  trainloss 2.37545  validloss 4.02925±0.00000  bestvalidloss 3.96681  last_update 8\n",
      "train: iter 62  trainloss 2.38087  validloss 4.05476±0.00000  bestvalidloss 3.96681  last_update 9\n",
      "train: iter 63  trainloss 2.39047  validloss 3.89585±0.00000  bestvalidloss 3.89585  last_update 0\n",
      "train: iter 64  trainloss 2.39520  validloss 4.21694±0.00000  bestvalidloss 3.89585  last_update 1\n",
      "train: iter 65  trainloss 2.40166  validloss 4.08505±0.00000  bestvalidloss 3.89585  last_update 2\n",
      "train: iter 66  trainloss 2.27653  validloss 3.85474±0.00000  bestvalidloss 3.85474  last_update 0\n",
      "train: iter 67  trainloss 2.34291  validloss 3.72045±0.00000  bestvalidloss 3.72045  last_update 0\n",
      "train: iter 68  trainloss 2.32335  validloss 3.96396±0.00000  bestvalidloss 3.72045  last_update 1\n",
      "train: iter 69  trainloss 2.30772  validloss 3.77698±0.00000  bestvalidloss 3.72045  last_update 2\n",
      "train: iter 70  trainloss 2.23625  validloss 3.79097±0.00000  bestvalidloss 3.72045  last_update 3\n",
      "train: iter 71  trainloss 2.25120  validloss 3.87081±0.00000  bestvalidloss 3.72045  last_update 4\n",
      "train: iter 72  trainloss 2.21026  validloss 4.04994±0.00000  bestvalidloss 3.72045  last_update 5\n",
      "train: iter 73  trainloss 2.22596  validloss 4.15712±0.00000  bestvalidloss 3.72045  last_update 6\n",
      "train: iter 74  trainloss 2.30718  validloss 3.90178±0.00000  bestvalidloss 3.72045  last_update 7\n",
      "train: iter 75  trainloss 2.24752  validloss 3.65710±0.00000  bestvalidloss 3.65710  last_update 0\n",
      "train: iter 76  trainloss 2.19663  validloss 3.72719±0.00000  bestvalidloss 3.65710  last_update 1\n",
      "train: iter 77  trainloss 2.26445  validloss 3.77548±0.00000  bestvalidloss 3.65710  last_update 2\n",
      "train: iter 78  trainloss 2.24694  validloss 3.77186±0.00000  bestvalidloss 3.65710  last_update 3\n",
      "train: iter 79  trainloss 2.20168  validloss 3.52612±0.00000  bestvalidloss 3.52612  last_update 0\n",
      "train: iter 80  trainloss 2.23527  validloss 3.81856±0.00000  bestvalidloss 3.52612  last_update 1\n",
      "train: iter 81  trainloss 2.25503  validloss 4.03440±0.00000  bestvalidloss 3.52612  last_update 2\n",
      "train: iter 82  trainloss 2.18499  validloss 3.58870±0.00000  bestvalidloss 3.52612  last_update 3\n",
      "train: iter 83  trainloss 2.20295  validloss 3.74541±0.00000  bestvalidloss 3.52612  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 2.24855  validloss 4.12360±0.00000  bestvalidloss 3.52612  last_update 5\n",
      "train: iter 85  trainloss 2.19160  validloss 3.74845±0.00000  bestvalidloss 3.52612  last_update 6\n",
      "train: iter 86  trainloss 2.20589  validloss 3.92182±0.00000  bestvalidloss 3.52612  last_update 7\n",
      "train: iter 87  trainloss 2.19791  validloss 3.96572±0.00000  bestvalidloss 3.52612  last_update 8\n",
      "train: iter 88  trainloss 2.20155  validloss 3.81588±0.00000  bestvalidloss 3.52612  last_update 9\n",
      "train: iter 89  trainloss 2.18505  validloss 3.70069±0.00000  bestvalidloss 3.52612  last_update 10\n",
      "train: iter 90  trainloss 2.18081  validloss 3.71920±0.00000  bestvalidloss 3.52612  last_update 11\n",
      "train: iter 91  trainloss 2.12499  validloss 3.90866±0.00000  bestvalidloss 3.52612  last_update 12\n",
      "train: iter 92  trainloss 2.18921  validloss 4.24121±0.00000  bestvalidloss 3.52612  last_update 13\n",
      "train: iter 93  trainloss 2.20923  validloss 3.61872±0.00000  bestvalidloss 3.52612  last_update 14\n",
      "train: iter 94  trainloss 2.28918  validloss 3.89965±0.00000  bestvalidloss 3.52612  last_update 15\n",
      "train: iter 95  trainloss 2.16833  validloss 3.80732±0.00000  bestvalidloss 3.52612  last_update 16\n",
      "train: iter 96  trainloss 2.20729  validloss 3.85313±0.00000  bestvalidloss 3.52612  last_update 17\n",
      "train: iter 97  trainloss 2.13630  validloss 3.88269±0.00000  bestvalidloss 3.52612  last_update 18\n",
      "train: iter 98  trainloss 2.23436  validloss 4.01196±0.00000  bestvalidloss 3.52612  last_update 19\n",
      "train: iter 99  trainloss 2.16447  validloss 3.68015±0.00000  bestvalidloss 3.52612  last_update 20\n",
      "train: iter 100  trainloss 2.16532  validloss 3.88556±0.00000  bestvalidloss 3.52612  last_update 21\n",
      "train: iter 101  trainloss 2.16893  validloss 3.84993±0.00000  bestvalidloss 3.52612  last_update 22\n",
      "train: iter 102  trainloss 2.18748  validloss 3.71375±0.00000  bestvalidloss 3.52612  last_update 23\n",
      "train: iter 103  trainloss 2.18401  validloss 4.25298±0.00000  bestvalidloss 3.52612  last_update 24\n",
      "train: iter 104  trainloss 2.19500  validloss 3.83321±0.00000  bestvalidloss 3.52612  last_update 25\n",
      "train: iter 105  trainloss 2.13627  validloss 3.61094±0.00000  bestvalidloss 3.52612  last_update 26\n",
      "train: iter 106  trainloss 2.18723  validloss 3.83178±0.00000  bestvalidloss 3.52612  last_update 27\n",
      "train: iter 107  trainloss 2.13777  validloss 3.96991±0.00000  bestvalidloss 3.52612  last_update 28\n",
      "train: iter 108  trainloss 2.17109  validloss 3.82678±0.00000  bestvalidloss 3.52612  last_update 29\n",
      "train: iter 109  trainloss 2.18236  validloss 3.75605±0.00000  bestvalidloss 3.52612  last_update 30\n",
      "train: iter 110  trainloss 2.24477  validloss 3.94304±0.00000  bestvalidloss 3.52612  last_update 31\n",
      "train: iter 111  trainloss 2.15443  validloss 3.81396±0.00000  bestvalidloss 3.52612  last_update 32\n",
      "train: iter 112  trainloss 2.20880  validloss 3.74445±0.00000  bestvalidloss 3.52612  last_update 33\n",
      "train: iter 113  trainloss 2.20291  validloss 3.85312±0.00000  bestvalidloss 3.52612  last_update 34\n",
      "train: iter 114  trainloss 2.17451  validloss 3.60406±0.00000  bestvalidloss 3.52612  last_update 35\n",
      "train: iter 115  trainloss 2.13736  validloss 3.56280±0.00000  bestvalidloss 3.52612  last_update 36\n",
      "train: iter 116  trainloss 2.19044  validloss 3.33405±0.00000  bestvalidloss 3.33405  last_update 0\n",
      "train: iter 117  trainloss 2.18268  validloss 4.02787±0.00000  bestvalidloss 3.33405  last_update 1\n",
      "train: iter 118  trainloss 2.17887  validloss 4.00530±0.00000  bestvalidloss 3.33405  last_update 2\n",
      "train: iter 119  trainloss 2.18104  validloss 4.10034±0.00000  bestvalidloss 3.33405  last_update 3\n",
      "train: iter 120  trainloss 2.21953  validloss 3.43415±0.00000  bestvalidloss 3.33405  last_update 4\n",
      "train: iter 121  trainloss 2.17835  validloss 3.87473±0.00000  bestvalidloss 3.33405  last_update 5\n",
      "train: iter 122  trainloss 2.16102  validloss 3.66297±0.00000  bestvalidloss 3.33405  last_update 6\n",
      "train: iter 123  trainloss 2.14888  validloss 3.71680±0.00000  bestvalidloss 3.33405  last_update 7\n",
      "train: iter 124  trainloss 2.18924  validloss 3.68957±0.00000  bestvalidloss 3.33405  last_update 8\n",
      "train: iter 125  trainloss 2.18043  validloss 3.78173±0.00000  bestvalidloss 3.33405  last_update 9\n",
      "train: iter 126  trainloss 2.17878  validloss 3.73622±0.00000  bestvalidloss 3.33405  last_update 10\n",
      "train: iter 127  trainloss 2.18239  validloss 3.64499±0.00000  bestvalidloss 3.33405  last_update 11\n",
      "train: iter 128  trainloss 2.17891  validloss 4.06781±0.00000  bestvalidloss 3.33405  last_update 12\n",
      "train: iter 129  trainloss 2.17179  validloss 3.64182±0.00000  bestvalidloss 3.33405  last_update 13\n",
      "train: iter 130  trainloss 2.16482  validloss 3.77559±0.00000  bestvalidloss 3.33405  last_update 14\n",
      "train: iter 131  trainloss 2.23185  validloss 3.91334±0.00000  bestvalidloss 3.33405  last_update 15\n",
      "train: iter 132  trainloss 2.15845  validloss 3.76924±0.00000  bestvalidloss 3.33405  last_update 16\n",
      "train: iter 133  trainloss 2.17971  validloss 3.90828±0.00000  bestvalidloss 3.33405  last_update 17\n",
      "train: iter 134  trainloss 2.21049  validloss 3.67117±0.00000  bestvalidloss 3.33405  last_update 18\n",
      "train: iter 135  trainloss 2.24602  validloss 3.91273±0.00000  bestvalidloss 3.33405  last_update 19\n",
      "train: iter 136  trainloss 2.18075  validloss 3.72241±0.00000  bestvalidloss 3.33405  last_update 20\n",
      "train: iter 137  trainloss 2.18291  validloss 3.70543±0.00000  bestvalidloss 3.33405  last_update 21\n",
      "train: iter 138  trainloss 2.18906  validloss 3.76816±0.00000  bestvalidloss 3.33405  last_update 22\n",
      "train: iter 139  trainloss 2.15043  validloss 3.67578±0.00000  bestvalidloss 3.33405  last_update 23\n",
      "train: iter 140  trainloss 2.27900  validloss 3.88420±0.00000  bestvalidloss 3.33405  last_update 24\n",
      "train: iter 141  trainloss 2.23271  validloss 3.65454±0.00000  bestvalidloss 3.33405  last_update 25\n",
      "train: iter 142  trainloss 2.20269  validloss 3.80751±0.00000  bestvalidloss 3.33405  last_update 26\n",
      "train: iter 143  trainloss 2.14435  validloss 3.62035±0.00000  bestvalidloss 3.33405  last_update 27\n",
      "train: iter 144  trainloss 2.17928  validloss 3.62377±0.00000  bestvalidloss 3.33405  last_update 28\n",
      "train: iter 145  trainloss 2.18712  validloss 3.74191±0.00000  bestvalidloss 3.33405  last_update 29\n",
      "train: iter 146  trainloss 2.15462  validloss 3.89356±0.00000  bestvalidloss 3.33405  last_update 30\n",
      "train: iter 147  trainloss 2.15567  validloss 3.80149±0.00000  bestvalidloss 3.33405  last_update 31\n",
      "train: iter 148  trainloss 2.17699  validloss 3.73011±0.00000  bestvalidloss 3.33405  last_update 32\n",
      "train: iter 149  trainloss 2.14440  validloss 3.72884±0.00000  bestvalidloss 3.33405  last_update 33\n",
      "train: iter 150  trainloss 2.18221  validloss 3.96627±0.00000  bestvalidloss 3.33405  last_update 34\n",
      "train: iter 151  trainloss 2.14888  validloss 3.64223±0.00000  bestvalidloss 3.33405  last_update 35\n",
      "train: iter 152  trainloss 2.19890  validloss 3.89064±0.00000  bestvalidloss 3.33405  last_update 36\n",
      "train: iter 153  trainloss 2.18778  validloss 3.73897±0.00000  bestvalidloss 3.33405  last_update 37\n",
      "train: iter 154  trainloss 2.19476  validloss 3.61620±0.00000  bestvalidloss 3.33405  last_update 38\n",
      "train: iter 155  trainloss 2.18757  validloss 3.91581±0.00000  bestvalidloss 3.33405  last_update 39\n",
      "train: iter 156  trainloss 2.14335  validloss 3.95930±0.00000  bestvalidloss 3.33405  last_update 40\n",
      "train: iter 157  trainloss 2.11852  validloss 3.76249±0.00000  bestvalidloss 3.33405  last_update 41\n",
      "train: iter 158  trainloss 2.23896  validloss 3.67677±0.00000  bestvalidloss 3.33405  last_update 42\n",
      "train: iter 159  trainloss 2.19322  validloss 3.95492±0.00000  bestvalidloss 3.33405  last_update 43\n",
      "train: iter 160  trainloss 2.13740  validloss 4.18334±0.00000  bestvalidloss 3.33405  last_update 44\n",
      "train: iter 161  trainloss 2.13771  validloss 3.64780±0.00000  bestvalidloss 3.33405  last_update 45\n",
      "train: iter 162  trainloss 2.16377  validloss 3.90800±0.00000  bestvalidloss 3.33405  last_update 46\n",
      "train: iter 163  trainloss 2.17667  validloss 3.97474±0.00000  bestvalidloss 3.33405  last_update 47\n",
      "train: iter 164  trainloss 2.11172  validloss 3.67855±0.00000  bestvalidloss 3.33405  last_update 48\n",
      "train: iter 165  trainloss 2.16877  validloss 4.05411±0.00000  bestvalidloss 3.33405  last_update 49\n",
      "train: iter 166  trainloss 2.21182  validloss 3.53133±0.00000  bestvalidloss 3.33405  last_update 50\n",
      "train: iter 167  trainloss 2.12582  validloss 3.73487±0.00000  bestvalidloss 3.33405  last_update 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 2.14827  validloss 3.79013±0.00000  bestvalidloss 3.33405  last_update 52\n",
      "train: iter 169  trainloss 2.17306  validloss 3.98317±0.00000  bestvalidloss 3.33405  last_update 53\n",
      "train: iter 170  trainloss 2.16673  validloss 3.87318±0.00000  bestvalidloss 3.33405  last_update 54\n",
      "train: iter 171  trainloss 2.13887  validloss 3.88983±0.00000  bestvalidloss 3.33405  last_update 55\n",
      "train: iter 172  trainloss 2.16848  validloss 3.79495±0.00000  bestvalidloss 3.33405  last_update 56\n",
      "train: iter 173  trainloss 2.09272  validloss 3.74168±0.00000  bestvalidloss 3.33405  last_update 57\n",
      "train: iter 174  trainloss 2.17369  validloss 3.76829±0.00000  bestvalidloss 3.33405  last_update 58\n",
      "train: iter 175  trainloss 2.09235  validloss 3.98309±0.00000  bestvalidloss 3.33405  last_update 59\n",
      "train: iter 176  trainloss 2.16613  validloss 3.93025±0.00000  bestvalidloss 3.33405  last_update 60\n",
      "train: iter 177  trainloss 2.20983  validloss 3.70842±0.00000  bestvalidloss 3.33405  last_update 61\n",
      "train: iter 178  trainloss 2.19786  validloss 3.73359±0.00000  bestvalidloss 3.33405  last_update 62\n",
      "train: iter 179  trainloss 2.12929  validloss 3.72916±0.00000  bestvalidloss 3.33405  last_update 63\n",
      "train: iter 180  trainloss 2.18205  validloss 3.66902±0.00000  bestvalidloss 3.33405  last_update 64\n",
      "train: iter 181  trainloss 2.19413  validloss 3.64565±0.00000  bestvalidloss 3.33405  last_update 65\n",
      "train: iter 182  trainloss 2.10266  validloss 3.57609±0.00000  bestvalidloss 3.33405  last_update 66\n",
      "train: iter 183  trainloss 2.16385  validloss 4.09190±0.00000  bestvalidloss 3.33405  last_update 67\n",
      "train: iter 184  trainloss 2.14332  validloss 3.66002±0.00000  bestvalidloss 3.33405  last_update 68\n",
      "train: iter 185  trainloss 2.12718  validloss 3.84288±0.00000  bestvalidloss 3.33405  last_update 69\n",
      "train: iter 186  trainloss 2.12539  validloss 3.69915±0.00000  bestvalidloss 3.33405  last_update 70\n",
      "train: iter 187  trainloss 2.14862  validloss 3.97185±0.00000  bestvalidloss 3.33405  last_update 71\n",
      "train: iter 188  trainloss 2.15303  validloss 3.95716±0.00000  bestvalidloss 3.33405  last_update 72\n",
      "train: iter 189  trainloss 2.18435  validloss 3.83664±0.00000  bestvalidloss 3.33405  last_update 73\n",
      "train: iter 190  trainloss 2.13928  validloss 3.92991±0.00000  bestvalidloss 3.33405  last_update 74\n",
      "train: iter 191  trainloss 2.13652  validloss 3.67280±0.00000  bestvalidloss 3.33405  last_update 75\n",
      "train: iter 192  trainloss 2.14014  validloss 3.75052±0.00000  bestvalidloss 3.33405  last_update 76\n",
      "train: iter 193  trainloss 2.12350  validloss 3.65333±0.00000  bestvalidloss 3.33405  last_update 77\n",
      "train: iter 194  trainloss 2.22272  validloss 3.74820±0.00000  bestvalidloss 3.33405  last_update 78\n",
      "train: iter 195  trainloss 2.16196  validloss 3.89240±0.00000  bestvalidloss 3.33405  last_update 79\n",
      "train: iter 196  trainloss 2.16462  validloss 3.83474±0.00000  bestvalidloss 3.33405  last_update 80\n",
      "train: iter 197  trainloss 2.11230  validloss 3.64851±0.00000  bestvalidloss 3.33405  last_update 81\n",
      "train: iter 198  trainloss 2.16310  validloss 3.61365±0.00000  bestvalidloss 3.33405  last_update 82\n",
      "train: iter 199  trainloss 2.14765  validloss 3.78591±0.00000  bestvalidloss 3.33405  last_update 83\n",
      "train: iter 200  trainloss 2.14070  validloss 3.71626±0.00000  bestvalidloss 3.33405  last_update 84\n",
      "train: iter 201  trainloss 2.23855  validloss 3.47900±0.00000  bestvalidloss 3.33405  last_update 85\n",
      "train: iter 202  trainloss 2.18863  validloss 3.66817±0.00000  bestvalidloss 3.33405  last_update 86\n",
      "train: iter 203  trainloss 2.18311  validloss 3.57691±0.00000  bestvalidloss 3.33405  last_update 87\n",
      "train: iter 204  trainloss 2.14226  validloss 3.94811±0.00000  bestvalidloss 3.33405  last_update 88\n",
      "train: iter 205  trainloss 2.15406  validloss 3.95471±0.00000  bestvalidloss 3.33405  last_update 89\n",
      "train: iter 206  trainloss 2.14814  validloss 3.71227±0.00000  bestvalidloss 3.33405  last_update 90\n",
      "train: iter 207  trainloss 2.16093  validloss 3.62723±0.00000  bestvalidloss 3.33405  last_update 91\n",
      "train: iter 208  trainloss 2.19697  validloss 3.50279±0.00000  bestvalidloss 3.33405  last_update 92\n",
      "train: iter 209  trainloss 2.16399  validloss 3.49550±0.00000  bestvalidloss 3.33405  last_update 93\n",
      "train: iter 210  trainloss 2.13811  validloss 3.79067±0.00000  bestvalidloss 3.33405  last_update 94\n",
      "train: iter 211  trainloss 2.12121  validloss 3.76282±0.00000  bestvalidloss 3.33405  last_update 95\n",
      "train: iter 212  trainloss 2.15583  validloss 3.45201±0.00000  bestvalidloss 3.33405  last_update 96\n",
      "train: iter 213  trainloss 2.17492  validloss 3.92368±0.00000  bestvalidloss 3.33405  last_update 97\n",
      "train: iter 214  trainloss 2.14961  validloss 3.60719±0.00000  bestvalidloss 3.33405  last_update 98\n",
      "train: iter 215  trainloss 2.13580  validloss 3.68792±0.00000  bestvalidloss 3.33405  last_update 99\n",
      "train: iter 216  trainloss 2.12483  validloss 3.48192±0.00000  bestvalidloss 3.33405  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-12.6418)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(3.9616)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5428173481908225\n",
      "tensor([1.3300])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720684a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
