{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(7130.6104)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 714.02642  validloss 1151.87744±0.00000  bestvalidloss 1151.87744  last_update 0\n",
      "train: iter 1  trainloss 258.90668  validloss 476.56429±0.00000  bestvalidloss 476.56429  last_update 0\n",
      "train: iter 2  trainloss -46.59595  validloss 76.45371±0.00000  bestvalidloss 76.45371  last_update 0\n",
      "train: iter 3  trainloss -446.88010  validloss -200.02026±0.00000  bestvalidloss -200.02026  last_update 0\n",
      "train: iter 4  trainloss -617.23299  validloss -498.69998±0.00000  bestvalidloss -498.69998  last_update 0\n",
      "train: iter 5  trainloss -790.65586  validloss -631.41569±0.00000  bestvalidloss -631.41569  last_update 0\n",
      "train: iter 6  trainloss -909.54426  validloss -720.24344±0.00000  bestvalidloss -720.24344  last_update 0\n",
      "train: iter 7  trainloss -1006.94372  validloss -876.83221±0.00000  bestvalidloss -876.83221  last_update 0\n",
      "train: iter 8  trainloss -1053.02872  validloss -753.39948±0.00000  bestvalidloss -876.83221  last_update 1\n",
      "train: iter 9  trainloss -1129.35661  validloss -792.59383±0.00000  bestvalidloss -876.83221  last_update 2\n",
      "train: iter 10  trainloss -1185.78347  validloss -1028.09431±0.00000  bestvalidloss -1028.09431  last_update 0\n",
      "train: iter 11  trainloss -1240.41900  validloss -1165.31421±0.00000  bestvalidloss -1165.31421  last_update 0\n",
      "train: iter 12  trainloss -1340.42394  validloss -1154.57554±0.00000  bestvalidloss -1165.31421  last_update 1\n",
      "train: iter 13  trainloss -1319.27277  validloss -1083.18521±0.00000  bestvalidloss -1165.31421  last_update 2\n",
      "train: iter 14  trainloss -1381.67265  validloss -1247.03308±0.00000  bestvalidloss -1247.03308  last_update 0\n",
      "train: iter 15  trainloss -1446.33378  validloss -1351.59724±0.00000  bestvalidloss -1351.59724  last_update 0\n",
      "train: iter 16  trainloss -1494.75758  validloss -1307.56498±0.00000  bestvalidloss -1351.59724  last_update 1\n",
      "train: iter 17  trainloss -1522.71313  validloss -1362.39062±0.00000  bestvalidloss -1362.39062  last_update 0\n",
      "train: iter 18  trainloss -1523.76487  validloss -1413.64324±0.00000  bestvalidloss -1413.64324  last_update 0\n",
      "train: iter 19  trainloss -1441.52829  validloss -1381.67040±0.00000  bestvalidloss -1413.64324  last_update 1\n",
      "train: iter 20  trainloss -1580.71402  validloss -1325.32744±0.00000  bestvalidloss -1413.64324  last_update 2\n",
      "train: iter 21  trainloss -1629.73201  validloss -1439.75736±0.00000  bestvalidloss -1439.75736  last_update 0\n",
      "train: iter 22  trainloss -1647.59851  validloss -1545.09906±0.00000  bestvalidloss -1545.09906  last_update 0\n",
      "train: iter 23  trainloss -1598.05912  validloss -1491.57851±0.00000  bestvalidloss -1545.09906  last_update 1\n",
      "train: iter 24  trainloss -1525.11553  validloss -1509.07162±0.00000  bestvalidloss -1545.09906  last_update 2\n",
      "train: iter 25  trainloss -1683.71827  validloss -1547.49250±0.00000  bestvalidloss -1547.49250  last_update 0\n",
      "train: iter 26  trainloss -1630.20075  validloss -1560.88201±0.00000  bestvalidloss -1560.88201  last_update 0\n",
      "train: iter 27  trainloss -1717.44220  validloss -1570.70987±0.00000  bestvalidloss -1570.70987  last_update 0\n",
      "train: iter 28  trainloss -1681.19888  validloss -1212.98958±0.00000  bestvalidloss -1570.70987  last_update 1\n",
      "train: iter 29  trainloss -1715.61676  validloss -1594.20102±0.00000  bestvalidloss -1594.20102  last_update 0\n",
      "train: iter 30  trainloss -1763.92592  validloss -1664.70818±0.00000  bestvalidloss -1664.70818  last_update 0\n",
      "train: iter 31  trainloss -1799.48359  validloss -1696.32685±0.00000  bestvalidloss -1696.32685  last_update 0\n",
      "train: iter 32  trainloss -1811.33580  validloss -1711.78415±0.00000  bestvalidloss -1711.78415  last_update 0\n",
      "train: iter 33  trainloss -1822.08899  validloss -1725.20411±0.00000  bestvalidloss -1725.20411  last_update 0\n",
      "train: iter 34  trainloss -1820.04651  validloss -1705.73573±0.00000  bestvalidloss -1725.20411  last_update 1\n",
      "train: iter 35  trainloss -1742.55853  validloss -1679.52633±0.00000  bestvalidloss -1725.20411  last_update 2\n",
      "train: iter 36  trainloss -1810.53817  validloss -1740.79742±0.00000  bestvalidloss -1740.79742  last_update 0\n",
      "train: iter 37  trainloss -1835.98571  validloss -1590.42845±0.00000  bestvalidloss -1740.79742  last_update 1\n",
      "train: iter 38  trainloss -1843.41144  validloss -1654.13113±0.00000  bestvalidloss -1740.79742  last_update 2\n",
      "train: iter 39  trainloss -1883.32980  validloss -1751.17335±0.00000  bestvalidloss -1751.17335  last_update 0\n",
      "train: iter 40  trainloss -1871.15127  validloss -1799.49792±0.00000  bestvalidloss -1799.49792  last_update 0\n",
      "train: iter 41  trainloss -1861.51524  validloss -1748.01802±0.00000  bestvalidloss -1799.49792  last_update 1\n",
      "train: iter 42  trainloss -1844.30608  validloss -1732.28155±0.00000  bestvalidloss -1799.49792  last_update 2\n",
      "train: iter 43  trainloss -1880.11230  validloss -1755.52175±0.00000  bestvalidloss -1799.49792  last_update 3\n",
      "train: iter 44  trainloss -1922.35676  validloss -1762.75531±0.00000  bestvalidloss -1799.49792  last_update 4\n",
      "train: iter 45  trainloss -1911.13129  validloss -1812.47569±0.00000  bestvalidloss -1812.47569  last_update 0\n",
      "train: iter 46  trainloss -1915.79291  validloss -1785.24441±0.00000  bestvalidloss -1812.47569  last_update 1\n",
      "train: iter 47  trainloss -1929.32228  validloss -1835.11539±0.00000  bestvalidloss -1835.11539  last_update 0\n",
      "train: iter 48  trainloss -1895.78203  validloss -1810.86079±0.00000  bestvalidloss -1835.11539  last_update 1\n",
      "train: iter 49  trainloss -1894.30230  validloss -1816.07960±0.00000  bestvalidloss -1835.11539  last_update 2\n",
      "train: iter 50  trainloss -1879.61026  validloss -1671.81674±0.00000  bestvalidloss -1835.11539  last_update 3\n",
      "train: iter 51  trainloss -1911.74188  validloss -1831.09550±0.00000  bestvalidloss -1835.11539  last_update 4\n",
      "train: iter 52  trainloss -1956.36324  validloss -1861.46148±0.00000  bestvalidloss -1861.46148  last_update 0\n",
      "train: iter 53  trainloss -1963.94917  validloss -1789.68956±0.00000  bestvalidloss -1861.46148  last_update 1\n",
      "train: iter 54  trainloss -1904.09441  validloss -1811.10135±0.00000  bestvalidloss -1861.46148  last_update 2\n",
      "train: iter 55  trainloss -1950.31764  validloss -1833.01804±0.00000  bestvalidloss -1861.46148  last_update 3\n",
      "train: iter 56  trainloss -1852.33405  validloss -1857.47252±0.00000  bestvalidloss -1861.46148  last_update 4\n",
      "train: iter 57  trainloss -1918.20911  validloss -1675.68889±0.00000  bestvalidloss -1861.46148  last_update 5\n",
      "train: iter 58  trainloss -1923.41042  validloss -1780.08243±0.00000  bestvalidloss -1861.46148  last_update 6\n",
      "train: iter 59  trainloss -1877.51498  validloss -1772.80178±0.00000  bestvalidloss -1861.46148  last_update 7\n",
      "train: iter 60  trainloss -1929.89898  validloss -1594.40920±0.00000  bestvalidloss -1861.46148  last_update 8\n",
      "train: iter 61  trainloss -1967.24383  validloss -1797.77404±0.00000  bestvalidloss -1861.46148  last_update 9\n",
      "train: iter 62  trainloss -1951.48617  validloss -1840.81252±0.00000  bestvalidloss -1861.46148  last_update 10\n",
      "train: iter 63  trainloss -1946.41313  validloss -1827.96006±0.00000  bestvalidloss -1861.46148  last_update 11\n",
      "train: iter 64  trainloss -1963.77221  validloss -1867.49890±0.00000  bestvalidloss -1867.49890  last_update 0\n",
      "train: iter 65  trainloss -1843.01407  validloss -1769.37316±0.00000  bestvalidloss -1867.49890  last_update 1\n",
      "train: iter 66  trainloss -1985.54075  validloss -1858.79122±0.00000  bestvalidloss -1867.49890  last_update 2\n",
      "train: iter 67  trainloss -1970.81413  validloss -1855.61545±0.00000  bestvalidloss -1867.49890  last_update 3\n",
      "train: iter 68  trainloss -1991.95736  validloss -1841.05405±0.00000  bestvalidloss -1867.49890  last_update 4\n",
      "train: iter 69  trainloss -1966.95080  validloss -1881.18185±0.00000  bestvalidloss -1881.18185  last_update 0\n",
      "train: iter 70  trainloss -1982.71715  validloss -1833.46462±0.00000  bestvalidloss -1881.18185  last_update 1\n",
      "train: iter 71  trainloss -1972.28033  validloss -1870.76763±0.00000  bestvalidloss -1881.18185  last_update 2\n",
      "train: iter 72  trainloss -2003.98995  validloss -1884.86477±0.00000  bestvalidloss -1884.86477  last_update 0\n",
      "train: iter 73  trainloss -1964.31632  validloss -1895.17933±0.00000  bestvalidloss -1895.17933  last_update 0\n",
      "train: iter 74  trainloss -1993.08972  validloss -1914.72161±0.00000  bestvalidloss -1914.72161  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1887.67561  validloss -1789.05968±0.00000  bestvalidloss -1914.72161  last_update 1\n",
      "train: iter 76  trainloss -1986.87277  validloss -1874.49723±0.00000  bestvalidloss -1914.72161  last_update 2\n",
      "train: iter 77  trainloss -1996.39946  validloss -1900.45127±0.00000  bestvalidloss -1914.72161  last_update 3\n",
      "train: iter 78  trainloss -2004.91831  validloss -1896.08781±0.00000  bestvalidloss -1914.72161  last_update 4\n",
      "train: iter 79  trainloss -1993.25295  validloss -1854.10044±0.00000  bestvalidloss -1914.72161  last_update 5\n",
      "train: iter 80  trainloss -1960.20041  validloss -1763.27038±0.00000  bestvalidloss -1914.72161  last_update 6\n",
      "train: iter 81  trainloss -2006.97155  validloss -1889.47995±0.00000  bestvalidloss -1914.72161  last_update 7\n",
      "train: iter 82  trainloss -2001.54262  validloss -1825.30219±0.00000  bestvalidloss -1914.72161  last_update 8\n",
      "train: iter 83  trainloss -2015.67217  validloss -1924.49162±0.00000  bestvalidloss -1924.49162  last_update 0\n",
      "train: iter 84  trainloss -2030.91138  validloss -1941.63161±0.00000  bestvalidloss -1941.63161  last_update 0\n",
      "train: iter 85  trainloss -2008.18089  validloss -1775.24121±0.00000  bestvalidloss -1941.63161  last_update 1\n",
      "train: iter 86  trainloss -1795.17274  validloss -1933.17882±0.00000  bestvalidloss -1941.63161  last_update 2\n",
      "train: iter 87  trainloss -1776.22791  validloss -1772.91152±0.00000  bestvalidloss -1941.63161  last_update 3\n",
      "train: iter 88  trainloss -2018.80599  validloss -1916.05336±0.00000  bestvalidloss -1941.63161  last_update 4\n",
      "train: iter 89  trainloss -2032.37919  validloss -1946.83797±0.00000  bestvalidloss -1946.83797  last_update 0\n",
      "train: iter 90  trainloss -2027.04988  validloss -1938.85734±0.00000  bestvalidloss -1946.83797  last_update 1\n",
      "train: iter 91  trainloss -2022.43919  validloss -1912.88976±0.00000  bestvalidloss -1946.83797  last_update 2\n",
      "train: iter 92  trainloss -2050.93871  validloss -1959.99721±0.00000  bestvalidloss -1959.99721  last_update 0\n",
      "train: iter 93  trainloss -2022.78705  validloss -1935.70945±0.00000  bestvalidloss -1959.99721  last_update 1\n",
      "train: iter 94  trainloss -2028.87191  validloss -1979.88672±0.00000  bestvalidloss -1979.88672  last_update 0\n",
      "train: iter 95  trainloss -2014.39623  validloss -1953.44444±0.00000  bestvalidloss -1979.88672  last_update 1\n",
      "train: iter 96  trainloss -1975.52147  validloss -1945.47153±0.00000  bestvalidloss -1979.88672  last_update 2\n",
      "train: iter 97  trainloss -2047.17018  validloss -1984.32554±0.00000  bestvalidloss -1984.32554  last_update 0\n",
      "train: iter 98  trainloss -2041.39176  validloss -1982.71883±0.00000  bestvalidloss -1984.32554  last_update 1\n",
      "train: iter 99  trainloss -2028.75173  validloss -1984.55874±0.00000  bestvalidloss -1984.55874  last_update 0\n",
      "train: iter 100  trainloss -2019.05242  validloss -1963.99281±0.00000  bestvalidloss -1984.55874  last_update 1\n",
      "train: iter 101  trainloss -2023.08787  validloss -1931.27307±0.00000  bestvalidloss -1984.55874  last_update 2\n",
      "train: iter 102  trainloss -2033.94040  validloss -1962.54863±0.00000  bestvalidloss -1984.55874  last_update 3\n",
      "train: iter 103  trainloss -2038.65252  validloss -1972.69473±0.00000  bestvalidloss -1984.55874  last_update 4\n",
      "train: iter 104  trainloss -2059.72058  validloss -1991.04646±0.00000  bestvalidloss -1991.04646  last_update 0\n",
      "train: iter 105  trainloss -1934.69877  validloss -1844.41100±0.00000  bestvalidloss -1991.04646  last_update 1\n",
      "train: iter 106  trainloss -1956.56824  validloss -1974.67421±0.00000  bestvalidloss -1991.04646  last_update 2\n",
      "train: iter 107  trainloss -2029.58505  validloss -1984.75220±0.00000  bestvalidloss -1991.04646  last_update 3\n",
      "train: iter 108  trainloss -2062.62436  validloss -1978.45781±0.00000  bestvalidloss -1991.04646  last_update 4\n",
      "train: iter 109  trainloss -2007.10319  validloss -1983.44106±0.00000  bestvalidloss -1991.04646  last_update 5\n",
      "train: iter 110  trainloss -1961.14961  validloss -1848.05938±0.00000  bestvalidloss -1991.04646  last_update 6\n",
      "train: iter 111  trainloss -2038.88508  validloss -1873.93794±0.00000  bestvalidloss -1991.04646  last_update 7\n",
      "train: iter 112  trainloss -2060.96657  validloss -2006.18050±0.00000  bestvalidloss -2006.18050  last_update 0\n",
      "train: iter 113  trainloss -2061.06611  validloss -1961.48842±0.00000  bestvalidloss -2006.18050  last_update 1\n",
      "train: iter 114  trainloss -1994.85686  validloss -2009.61199±0.00000  bestvalidloss -2009.61199  last_update 0\n",
      "train: iter 115  trainloss -2058.03713  validloss -1900.22130±0.00000  bestvalidloss -2009.61199  last_update 1\n",
      "train: iter 116  trainloss -2041.54084  validloss -1992.87142±0.00000  bestvalidloss -2009.61199  last_update 2\n",
      "train: iter 117  trainloss -2015.15217  validloss -1998.76870±0.00000  bestvalidloss -2009.61199  last_update 3\n",
      "train: iter 118  trainloss -1950.02117  validloss -2001.73938±0.00000  bestvalidloss -2009.61199  last_update 4\n",
      "train: iter 119  trainloss -2052.96877  validloss -1939.19020±0.00000  bestvalidloss -2009.61199  last_update 5\n",
      "train: iter 120  trainloss -2065.32604  validloss -1996.18607±0.00000  bestvalidloss -2009.61199  last_update 6\n",
      "train: iter 121  trainloss -2030.32112  validloss -1987.64441±0.00000  bestvalidloss -2009.61199  last_update 7\n",
      "train: iter 122  trainloss -1888.04571  validloss -1879.93235±0.00000  bestvalidloss -2009.61199  last_update 8\n",
      "train: iter 123  trainloss -2062.81911  validloss -1880.03739±0.00000  bestvalidloss -2009.61199  last_update 9\n",
      "train: iter 124  trainloss -2079.95014  validloss -2005.60886±0.00000  bestvalidloss -2009.61199  last_update 10\n",
      "train: iter 125  trainloss -2062.20309  validloss -2007.67033±0.00000  bestvalidloss -2009.61199  last_update 11\n",
      "train: iter 126  trainloss -2048.57226  validloss -2005.18270±0.00000  bestvalidloss -2009.61199  last_update 12\n",
      "train: iter 127  trainloss -2099.50291  validloss -2040.50132±0.00000  bestvalidloss -2040.50132  last_update 0\n",
      "train: iter 128  trainloss -2047.53218  validloss -2029.56052±0.00000  bestvalidloss -2040.50132  last_update 1\n",
      "train: iter 129  trainloss -2066.37852  validloss -2018.89746±0.00000  bestvalidloss -2040.50132  last_update 2\n",
      "train: iter 130  trainloss -2042.86635  validloss -1991.20207±0.00000  bestvalidloss -2040.50132  last_update 3\n",
      "train: iter 131  trainloss -2081.44098  validloss -2041.27751±0.00000  bestvalidloss -2041.27751  last_update 0\n",
      "train: iter 132  trainloss -2060.90821  validloss -2034.43691±0.00000  bestvalidloss -2041.27751  last_update 1\n",
      "train: iter 133  trainloss -2056.12395  validloss -1979.81260±0.00000  bestvalidloss -2041.27751  last_update 2\n",
      "train: iter 134  trainloss -2041.12901  validloss -2026.01401±0.00000  bestvalidloss -2041.27751  last_update 3\n",
      "train: iter 135  trainloss -2050.47211  validloss -2019.68847±0.00000  bestvalidloss -2041.27751  last_update 4\n",
      "train: iter 136  trainloss -2080.18594  validloss -2003.14865±0.00000  bestvalidloss -2041.27751  last_update 5\n",
      "train: iter 137  trainloss -2040.22466  validloss -1992.47395±0.00000  bestvalidloss -2041.27751  last_update 6\n",
      "train: iter 138  trainloss -2070.40721  validloss -1936.88474±0.00000  bestvalidloss -2041.27751  last_update 7\n",
      "train: iter 139  trainloss -2045.44403  validloss -2016.65573±0.00000  bestvalidloss -2041.27751  last_update 8\n",
      "train: iter 140  trainloss -1640.16893  validloss -1792.55419±0.00000  bestvalidloss -2041.27751  last_update 9\n",
      "train: iter 141  trainloss -1977.80631  validloss -1946.11163±0.00000  bestvalidloss -2041.27751  last_update 10\n",
      "train: iter 142  trainloss -2049.14250  validloss -1903.58755±0.00000  bestvalidloss -2041.27751  last_update 11\n",
      "train: iter 143  trainloss -2104.33080  validloss -2028.36696±0.00000  bestvalidloss -2041.27751  last_update 12\n",
      "train: iter 144  trainloss -2100.84419  validloss -2025.62565±0.00000  bestvalidloss -2041.27751  last_update 13\n",
      "train: iter 145  trainloss -2105.42587  validloss -2015.01289±0.00000  bestvalidloss -2041.27751  last_update 14\n",
      "train: iter 146  trainloss -2081.83855  validloss -1993.66183±0.00000  bestvalidloss -2041.27751  last_update 15\n",
      "train: iter 147  trainloss -2088.66469  validloss -2021.44095±0.00000  bestvalidloss -2041.27751  last_update 16\n",
      "train: iter 148  trainloss -2093.03560  validloss -2004.92761±0.00000  bestvalidloss -2041.27751  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -2101.36173  validloss -2016.88383±0.00000  bestvalidloss -2041.27751  last_update 18\n",
      "train: iter 150  trainloss -2045.79413  validloss -1816.04192±0.00000  bestvalidloss -2041.27751  last_update 19\n",
      "train: iter 151  trainloss -2032.90017  validloss -1927.11497±0.00000  bestvalidloss -2041.27751  last_update 20\n",
      "train: iter 152  trainloss -2058.39086  validloss -2021.58583±0.00000  bestvalidloss -2041.27751  last_update 21\n",
      "train: iter 153  trainloss -2092.87587  validloss -1968.86277±0.00000  bestvalidloss -2041.27751  last_update 22\n",
      "train: iter 154  trainloss -2055.68262  validloss -1928.74893±0.00000  bestvalidloss -2041.27751  last_update 23\n",
      "train: iter 155  trainloss -1746.46735  validloss -1929.98619±0.00000  bestvalidloss -2041.27751  last_update 24\n",
      "train: iter 156  trainloss -2083.54880  validloss -1897.35718±0.00000  bestvalidloss -2041.27751  last_update 25\n",
      "train: iter 157  trainloss -2109.72400  validloss -2018.58378±0.00000  bestvalidloss -2041.27751  last_update 26\n",
      "train: iter 158  trainloss -2098.12191  validloss -2033.98384±0.00000  bestvalidloss -2041.27751  last_update 27\n",
      "train: iter 159  trainloss -2084.72509  validloss -2003.84088±0.00000  bestvalidloss -2041.27751  last_update 28\n",
      "train: iter 160  trainloss -2082.98085  validloss -2037.79586±0.00000  bestvalidloss -2041.27751  last_update 29\n",
      "train: iter 161  trainloss -2106.11243  validloss -2002.91068±0.00000  bestvalidloss -2041.27751  last_update 30\n",
      "train: iter 162  trainloss -2053.39138  validloss -2049.35317±0.00000  bestvalidloss -2049.35317  last_update 0\n",
      "train: iter 163  trainloss -2088.80328  validloss -1933.59358±0.00000  bestvalidloss -2049.35317  last_update 1\n",
      "train: iter 164  trainloss -2098.04376  validloss -2009.25025±0.00000  bestvalidloss -2049.35317  last_update 2\n",
      "train: iter 165  trainloss -2059.92920  validloss -2025.27673±0.00000  bestvalidloss -2049.35317  last_update 3\n",
      "train: iter 166  trainloss -2070.02075  validloss -1861.50723±0.00000  bestvalidloss -2049.35317  last_update 4\n",
      "train: iter 167  trainloss -2096.71406  validloss -2023.34755±0.00000  bestvalidloss -2049.35317  last_update 5\n",
      "train: iter 168  trainloss -2079.61646  validloss -1898.28006±0.00000  bestvalidloss -2049.35317  last_update 6\n",
      "train: iter 169  trainloss -2105.73349  validloss -2014.23031±0.00000  bestvalidloss -2049.35317  last_update 7\n",
      "train: iter 170  trainloss -2114.63243  validloss -2033.39759±0.00000  bestvalidloss -2049.35317  last_update 8\n",
      "train: iter 171  trainloss -2013.07888  validloss -1999.62845±0.00000  bestvalidloss -2049.35317  last_update 9\n",
      "train: iter 172  trainloss -2008.31028  validloss -1935.08924±0.00000  bestvalidloss -2049.35317  last_update 10\n",
      "train: iter 173  trainloss -2087.22352  validloss -1963.47669±0.00000  bestvalidloss -2049.35317  last_update 11\n",
      "train: iter 174  trainloss -2069.57668  validloss -1955.07657±0.00000  bestvalidloss -2049.35317  last_update 12\n",
      "train: iter 175  trainloss -2101.98206  validloss -2045.48821±0.00000  bestvalidloss -2049.35317  last_update 13\n",
      "train: iter 176  trainloss -2077.08964  validloss -2017.04805±0.00000  bestvalidloss -2049.35317  last_update 14\n",
      "train: iter 177  trainloss -2075.54743  validloss -2033.51823±0.00000  bestvalidloss -2049.35317  last_update 15\n",
      "train: iter 178  trainloss -1982.32055  validloss -1917.65785±0.00000  bestvalidloss -2049.35317  last_update 16\n",
      "train: iter 179  trainloss -2014.30428  validloss -1989.72570±0.00000  bestvalidloss -2049.35317  last_update 17\n",
      "train: iter 180  trainloss -1994.62210  validloss -1895.56939±0.00000  bestvalidloss -2049.35317  last_update 18\n",
      "train: iter 181  trainloss -2080.79317  validloss -1938.43024±0.00000  bestvalidloss -2049.35317  last_update 19\n",
      "train: iter 182  trainloss -2112.21825  validloss -2045.11319±0.00000  bestvalidloss -2049.35317  last_update 20\n",
      "train: iter 183  trainloss -2123.24452  validloss -2012.79928±0.00000  bestvalidloss -2049.35317  last_update 21\n",
      "train: iter 184  trainloss -2131.52641  validloss -2024.71964±0.00000  bestvalidloss -2049.35317  last_update 22\n",
      "train: iter 185  trainloss -2123.43835  validloss -2029.53898±0.00000  bestvalidloss -2049.35317  last_update 23\n",
      "train: iter 186  trainloss -2035.33197  validloss -2049.14051±0.00000  bestvalidloss -2049.35317  last_update 24\n",
      "train: iter 187  trainloss -2032.99662  validloss -1989.00738±0.00000  bestvalidloss -2049.35317  last_update 25\n",
      "train: iter 188  trainloss -2042.39758  validloss -2038.87945±0.00000  bestvalidloss -2049.35317  last_update 26\n",
      "train: iter 189  trainloss -2084.10899  validloss -2001.44021±0.00000  bestvalidloss -2049.35317  last_update 27\n",
      "train: iter 190  trainloss -2097.30152  validloss -1981.00053±0.00000  bestvalidloss -2049.35317  last_update 28\n",
      "train: iter 191  trainloss -2080.71546  validloss -2030.63213±0.00000  bestvalidloss -2049.35317  last_update 29\n",
      "train: iter 192  trainloss -2117.71519  validloss -2054.83451±0.00000  bestvalidloss -2054.83451  last_update 0\n",
      "train: iter 193  trainloss -2122.12811  validloss -2036.95768±0.00000  bestvalidloss -2054.83451  last_update 1\n",
      "train: iter 194  trainloss -2102.98386  validloss -1986.02769±0.00000  bestvalidloss -2054.83451  last_update 2\n",
      "train: iter 195  trainloss -2088.44754  validloss -2044.98551±0.00000  bestvalidloss -2054.83451  last_update 3\n",
      "train: iter 196  trainloss -2080.08824  validloss -2018.28187±0.00000  bestvalidloss -2054.83451  last_update 4\n",
      "train: iter 197  trainloss -2102.14458  validloss -2012.82525±0.00000  bestvalidloss -2054.83451  last_update 5\n",
      "train: iter 198  trainloss -2045.86128  validloss -2043.32717±0.00000  bestvalidloss -2054.83451  last_update 6\n",
      "train: iter 199  trainloss -2101.93204  validloss -1907.50529±0.00000  bestvalidloss -2054.83451  last_update 7\n",
      "train: iter 200  trainloss -2112.77523  validloss -2076.07807±0.00000  bestvalidloss -2076.07807  last_update 0\n",
      "train: iter 201  trainloss -2114.09075  validloss -2012.52450±0.00000  bestvalidloss -2076.07807  last_update 1\n",
      "train: iter 202  trainloss -2128.35890  validloss -2035.91812±0.00000  bestvalidloss -2076.07807  last_update 2\n",
      "train: iter 203  trainloss -2075.66985  validloss -2057.81421±0.00000  bestvalidloss -2076.07807  last_update 3\n",
      "train: iter 204  trainloss -2112.51886  validloss -2018.99159±0.00000  bestvalidloss -2076.07807  last_update 4\n",
      "train: iter 205  trainloss -2102.07650  validloss -2037.63995±0.00000  bestvalidloss -2076.07807  last_update 5\n",
      "train: iter 206  trainloss -2109.53657  validloss -1971.93489±0.00000  bestvalidloss -2076.07807  last_update 6\n",
      "train: iter 207  trainloss -2136.46542  validloss -2066.14319±0.00000  bestvalidloss -2076.07807  last_update 7\n",
      "train: iter 208  trainloss -2113.19487  validloss -2037.28769±0.00000  bestvalidloss -2076.07807  last_update 8\n",
      "train: iter 209  trainloss -2114.05946  validloss -2020.63019±0.00000  bestvalidloss -2076.07807  last_update 9\n",
      "train: iter 210  trainloss -2129.93005  validloss -2043.16966±0.00000  bestvalidloss -2076.07807  last_update 10\n",
      "train: iter 211  trainloss -2114.48423  validloss -2058.40858±0.00000  bestvalidloss -2076.07807  last_update 11\n",
      "train: iter 212  trainloss -2130.82624  validloss -2052.52794±0.00000  bestvalidloss -2076.07807  last_update 12\n",
      "train: iter 213  trainloss -2091.03520  validloss -2001.92438±0.00000  bestvalidloss -2076.07807  last_update 13\n",
      "train: iter 214  trainloss -2057.81384  validloss -2000.98441±0.00000  bestvalidloss -2076.07807  last_update 14\n",
      "train: iter 215  trainloss -2095.36712  validloss -1926.86217±0.00000  bestvalidloss -2076.07807  last_update 15\n",
      "train: iter 216  trainloss -1986.33551  validloss -2002.38906±0.00000  bestvalidloss -2076.07807  last_update 16\n",
      "train: iter 217  trainloss -2124.67900  validloss -2045.05257±0.00000  bestvalidloss -2076.07807  last_update 17\n",
      "train: iter 218  trainloss -2135.46708  validloss -2065.32043±0.00000  bestvalidloss -2076.07807  last_update 18\n",
      "train: iter 219  trainloss -2117.20313  validloss -2052.50887±0.00000  bestvalidloss -2076.07807  last_update 19\n",
      "train: iter 220  trainloss -2097.48733  validloss -1826.95663±0.00000  bestvalidloss -2076.07807  last_update 20\n",
      "train: iter 221  trainloss -2113.72200  validloss -2055.53289±0.00000  bestvalidloss -2076.07807  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 222  trainloss -2101.37487  validloss -2026.77850±0.00000  bestvalidloss -2076.07807  last_update 22\n",
      "train: iter 223  trainloss -2129.51301  validloss -2041.06486±0.00000  bestvalidloss -2076.07807  last_update 23\n",
      "train: iter 224  trainloss -2125.99211  validloss -2012.19445±0.00000  bestvalidloss -2076.07807  last_update 24\n",
      "train: iter 225  trainloss -1943.55720  validloss -1996.72014±0.00000  bestvalidloss -2076.07807  last_update 25\n",
      "train: iter 226  trainloss -2076.47968  validloss -1993.84103±0.00000  bestvalidloss -2076.07807  last_update 26\n",
      "train: iter 227  trainloss -2116.09740  validloss -1979.77129±0.00000  bestvalidloss -2076.07807  last_update 27\n",
      "train: iter 228  trainloss -2130.98284  validloss -2008.12581±0.00000  bestvalidloss -2076.07807  last_update 28\n",
      "train: iter 229  trainloss -2135.86692  validloss -2056.06879±0.00000  bestvalidloss -2076.07807  last_update 29\n",
      "train: iter 230  trainloss -2116.43138  validloss -2060.05226±0.00000  bestvalidloss -2076.07807  last_update 30\n",
      "train: iter 231  trainloss -2149.12529  validloss -2085.52899±0.00000  bestvalidloss -2085.52899  last_update 0\n",
      "train: iter 232  trainloss -2137.83444  validloss -2068.22162±0.00000  bestvalidloss -2085.52899  last_update 1\n",
      "train: iter 233  trainloss -2114.42965  validloss -2060.34909±0.00000  bestvalidloss -2085.52899  last_update 2\n",
      "train: iter 234  trainloss -2115.61784  validloss -2000.12154±0.00000  bestvalidloss -2085.52899  last_update 3\n",
      "train: iter 235  trainloss -2114.70851  validloss -1949.99594±0.00000  bestvalidloss -2085.52899  last_update 4\n",
      "train: iter 236  trainloss -2094.29069  validloss -2045.60697±0.00000  bestvalidloss -2085.52899  last_update 5\n",
      "train: iter 237  trainloss -2131.36452  validloss -1868.34074±0.00000  bestvalidloss -2085.52899  last_update 6\n",
      "train: iter 238  trainloss -2139.87763  validloss -2020.39272±0.00000  bestvalidloss -2085.52899  last_update 7\n",
      "train: iter 239  trainloss -2154.61736  validloss -2063.49695±0.00000  bestvalidloss -2085.52899  last_update 8\n",
      "train: iter 240  trainloss -2117.57292  validloss -2069.84054±0.00000  bestvalidloss -2085.52899  last_update 9\n",
      "train: iter 241  trainloss -2099.49297  validloss -2052.02021±0.00000  bestvalidloss -2085.52899  last_update 10\n",
      "train: iter 242  trainloss -2069.82111  validloss -2015.25292±0.00000  bestvalidloss -2085.52899  last_update 11\n",
      "train: iter 243  trainloss -1368.49672  validloss -1917.18350±0.00000  bestvalidloss -2085.52899  last_update 12\n",
      "train: iter 244  trainloss -1952.18183  validloss -986.94565±0.00000  bestvalidloss -2085.52899  last_update 13\n",
      "train: iter 245  trainloss -2100.32499  validloss -2035.35762±0.00000  bestvalidloss -2085.52899  last_update 14\n",
      "train: iter 246  trainloss -2152.52217  validloss -2067.32143±0.00000  bestvalidloss -2085.52899  last_update 15\n",
      "train: iter 247  trainloss -2152.44213  validloss -2074.18904±0.00000  bestvalidloss -2085.52899  last_update 16\n",
      "train: iter 248  trainloss -2151.76089  validloss -2082.00179±0.00000  bestvalidloss -2085.52899  last_update 17\n",
      "train: iter 249  trainloss -2151.62335  validloss -2041.22151±0.00000  bestvalidloss -2085.52899  last_update 18\n",
      "train: iter 250  trainloss -2153.90557  validloss -2090.18430±0.00000  bestvalidloss -2090.18430  last_update 0\n",
      "train: iter 251  trainloss -2158.30604  validloss -2026.43336±0.00000  bestvalidloss -2090.18430  last_update 1\n",
      "train: iter 252  trainloss -2152.04161  validloss -2030.65771±0.00000  bestvalidloss -2090.18430  last_update 2\n",
      "train: iter 253  trainloss -2110.79653  validloss -2087.23831±0.00000  bestvalidloss -2090.18430  last_update 3\n",
      "train: iter 254  trainloss -2151.20006  validloss -2053.40604±0.00000  bestvalidloss -2090.18430  last_update 4\n",
      "train: iter 255  trainloss -2115.22243  validloss -2089.07570±0.00000  bestvalidloss -2090.18430  last_update 5\n",
      "train: iter 256  trainloss -2155.25103  validloss -2080.76499±0.00000  bestvalidloss -2090.18430  last_update 6\n",
      "train: iter 257  trainloss -2163.50831  validloss -2080.97271±0.00000  bestvalidloss -2090.18430  last_update 7\n",
      "train: iter 258  trainloss -2146.97246  validloss -2071.26485±0.00000  bestvalidloss -2090.18430  last_update 8\n",
      "train: iter 259  trainloss -2129.44839  validloss -2038.78377±0.00000  bestvalidloss -2090.18430  last_update 9\n",
      "train: iter 260  trainloss -2139.43346  validloss -2069.81700±0.00000  bestvalidloss -2090.18430  last_update 10\n",
      "train: iter 261  trainloss -2153.72047  validloss -2081.81395±0.00000  bestvalidloss -2090.18430  last_update 11\n",
      "train: iter 262  trainloss -2134.87205  validloss -2041.11949±0.00000  bestvalidloss -2090.18430  last_update 12\n",
      "train: iter 263  trainloss -2131.53089  validloss -2089.18181±0.00000  bestvalidloss -2090.18430  last_update 13\n",
      "train: iter 264  trainloss -2122.53402  validloss -1891.23188±0.00000  bestvalidloss -2090.18430  last_update 14\n",
      "train: iter 265  trainloss -2117.97831  validloss -2046.61613±0.00000  bestvalidloss -2090.18430  last_update 15\n",
      "train: iter 266  trainloss -2154.41212  validloss -1970.89065±0.00000  bestvalidloss -2090.18430  last_update 16\n",
      "train: iter 267  trainloss -2134.90961  validloss -2074.84140±0.00000  bestvalidloss -2090.18430  last_update 17\n",
      "train: iter 268  trainloss -2133.34929  validloss -2070.43815±0.00000  bestvalidloss -2090.18430  last_update 18\n",
      "train: iter 269  trainloss -2111.35831  validloss -2070.84594±0.00000  bestvalidloss -2090.18430  last_update 19\n",
      "train: iter 270  trainloss -2068.27804  validloss -2007.26547±0.00000  bestvalidloss -2090.18430  last_update 20\n",
      "train: iter 271  trainloss -2115.71275  validloss -2011.31975±0.00000  bestvalidloss -2090.18430  last_update 21\n",
      "train: iter 272  trainloss -2098.86175  validloss -2000.77818±0.00000  bestvalidloss -2090.18430  last_update 22\n",
      "train: iter 273  trainloss -2139.77744  validloss -2052.38229±0.00000  bestvalidloss -2090.18430  last_update 23\n",
      "train: iter 274  trainloss -2147.28892  validloss -2097.80895±0.00000  bestvalidloss -2097.80895  last_update 0\n",
      "train: iter 275  trainloss -2118.93338  validloss -2060.64785±0.00000  bestvalidloss -2097.80895  last_update 1\n",
      "train: iter 276  trainloss -2144.08515  validloss -2053.46592±0.00000  bestvalidloss -2097.80895  last_update 2\n",
      "train: iter 277  trainloss -2147.30891  validloss -2088.42122±0.00000  bestvalidloss -2097.80895  last_update 3\n",
      "train: iter 278  trainloss -2153.61258  validloss -2064.74746±0.00000  bestvalidloss -2097.80895  last_update 4\n",
      "train: iter 279  trainloss -2130.03829  validloss -2090.25255±0.00000  bestvalidloss -2097.80895  last_update 5\n",
      "train: iter 280  trainloss -2137.73105  validloss -2054.24176±0.00000  bestvalidloss -2097.80895  last_update 6\n",
      "train: iter 281  trainloss -2125.42450  validloss -2027.43573±0.00000  bestvalidloss -2097.80895  last_update 7\n",
      "train: iter 282  trainloss -2150.01287  validloss -2104.83119±0.00000  bestvalidloss -2104.83119  last_update 0\n",
      "train: iter 283  trainloss -2177.59601  validloss -2101.35821±0.00000  bestvalidloss -2104.83119  last_update 1\n",
      "train: iter 284  trainloss -2166.82430  validloss -2099.88191±0.00000  bestvalidloss -2104.83119  last_update 2\n",
      "train: iter 285  trainloss -2138.83159  validloss -2070.66951±0.00000  bestvalidloss -2104.83119  last_update 3\n",
      "train: iter 286  trainloss -2170.02896  validloss -2092.90912±0.00000  bestvalidloss -2104.83119  last_update 4\n",
      "train: iter 287  trainloss -2137.21860  validloss -2032.42720±0.00000  bestvalidloss -2104.83119  last_update 5\n",
      "train: iter 288  trainloss -2061.10579  validloss -2048.59784±0.00000  bestvalidloss -2104.83119  last_update 6\n",
      "train: iter 289  trainloss -2121.02396  validloss -1832.83957±0.00000  bestvalidloss -2104.83119  last_update 7\n",
      "train: iter 290  trainloss -2066.68516  validloss -2026.54827±0.00000  bestvalidloss -2104.83119  last_update 8\n",
      "train: iter 291  trainloss -1745.63108  validloss -1963.58285±0.00000  bestvalidloss -2104.83119  last_update 9\n",
      "train: iter 292  trainloss -2114.49731  validloss -1721.48115±0.00000  bestvalidloss -2104.83119  last_update 10\n",
      "train: iter 293  trainloss -2193.53899  validloss -2093.85512±0.00000  bestvalidloss -2104.83119  last_update 11\n",
      "train: iter 294  trainloss -2181.14387  validloss -2114.61347±0.00000  bestvalidloss -2114.61347  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 295  trainloss -2154.25812  validloss -2109.04324±0.00000  bestvalidloss -2114.61347  last_update 1\n",
      "train: iter 296  trainloss -2174.18283  validloss -2093.43464±0.00000  bestvalidloss -2114.61347  last_update 2\n",
      "train: iter 297  trainloss -2170.44892  validloss -2096.88188±0.00000  bestvalidloss -2114.61347  last_update 3\n",
      "train: iter 298  trainloss -2172.77637  validloss -2045.38811±0.00000  bestvalidloss -2114.61347  last_update 4\n",
      "train: iter 299  trainloss -2194.69070  validloss -2063.19957±0.00000  bestvalidloss -2114.61347  last_update 5\n",
      "train: iter 300  trainloss -2175.05472  validloss -2101.90642±0.00000  bestvalidloss -2114.61347  last_update 6\n",
      "train: iter 301  trainloss -2090.82459  validloss -2095.53817±0.00000  bestvalidloss -2114.61347  last_update 7\n",
      "train: iter 302  trainloss -2161.88079  validloss -2010.64784±0.00000  bestvalidloss -2114.61347  last_update 8\n",
      "train: iter 303  trainloss -2181.28013  validloss -2079.75572±0.00000  bestvalidloss -2114.61347  last_update 9\n",
      "train: iter 304  trainloss -2198.15400  validloss -2096.37542±0.00000  bestvalidloss -2114.61347  last_update 10\n",
      "train: iter 305  trainloss -2163.14482  validloss -2091.92808±0.00000  bestvalidloss -2114.61347  last_update 11\n",
      "train: iter 306  trainloss -2167.50055  validloss -1959.11610±0.00000  bestvalidloss -2114.61347  last_update 12\n",
      "train: iter 307  trainloss -2180.78597  validloss -2117.01073±0.00000  bestvalidloss -2117.01073  last_update 0\n",
      "train: iter 308  trainloss -2196.10533  validloss -2086.94998±0.00000  bestvalidloss -2117.01073  last_update 1\n",
      "train: iter 309  trainloss -2190.06837  validloss -2111.88530±0.00000  bestvalidloss -2117.01073  last_update 2\n",
      "train: iter 310  trainloss -2160.66801  validloss -2106.35834±0.00000  bestvalidloss -2117.01073  last_update 3\n",
      "train: iter 311  trainloss -2193.16589  validloss -2110.33699±0.00000  bestvalidloss -2117.01073  last_update 4\n",
      "train: iter 312  trainloss -2147.16765  validloss -2109.29168±0.00000  bestvalidloss -2117.01073  last_update 5\n",
      "train: iter 313  trainloss -2191.61096  validloss -2107.84495±0.00000  bestvalidloss -2117.01073  last_update 6\n",
      "train: iter 314  trainloss -2186.98770  validloss -2098.83324±0.00000  bestvalidloss -2117.01073  last_update 7\n",
      "train: iter 315  trainloss -2167.07744  validloss -2091.05637±0.00000  bestvalidloss -2117.01073  last_update 8\n",
      "train: iter 316  trainloss -2183.78328  validloss -2052.00203±0.00000  bestvalidloss -2117.01073  last_update 9\n",
      "train: iter 317  trainloss -2160.58161  validloss -2086.10019±0.00000  bestvalidloss -2117.01073  last_update 10\n",
      "train: iter 318  trainloss -2155.87310  validloss -2089.94365±0.00000  bestvalidloss -2117.01073  last_update 11\n",
      "train: iter 319  trainloss -2043.35601  validloss -2064.56259±0.00000  bestvalidloss -2117.01073  last_update 12\n",
      "train: iter 320  trainloss -2165.55079  validloss -1945.16867±0.00000  bestvalidloss -2117.01073  last_update 13\n",
      "train: iter 321  trainloss -2113.80811  validloss -2017.84715±0.00000  bestvalidloss -2117.01073  last_update 14\n",
      "train: iter 322  trainloss -1651.36659  validloss -1803.80840±0.00000  bestvalidloss -2117.01073  last_update 15\n",
      "train: iter 323  trainloss -2165.65045  validloss -1986.76259±0.00000  bestvalidloss -2117.01073  last_update 16\n",
      "train: iter 324  trainloss -2190.48259  validloss -2023.54941±0.00000  bestvalidloss -2117.01073  last_update 17\n",
      "train: iter 325  trainloss -2195.84035  validloss -2064.04662±0.00000  bestvalidloss -2117.01073  last_update 18\n",
      "train: iter 326  trainloss -2191.66165  validloss -2106.94938±0.00000  bestvalidloss -2117.01073  last_update 19\n",
      "train: iter 327  trainloss -2202.55142  validloss -2111.40625±0.00000  bestvalidloss -2117.01073  last_update 20\n",
      "train: iter 328  trainloss -2211.49105  validloss -2094.02420±0.00000  bestvalidloss -2117.01073  last_update 21\n",
      "train: iter 329  trainloss -2207.01449  validloss -2129.44590±0.00000  bestvalidloss -2129.44590  last_update 0\n",
      "train: iter 330  trainloss -2212.60647  validloss -2106.44354±0.00000  bestvalidloss -2129.44590  last_update 1\n",
      "train: iter 331  trainloss -2188.45998  validloss -2081.59691±0.00000  bestvalidloss -2129.44590  last_update 2\n",
      "train: iter 332  trainloss -2208.49216  validloss -2111.52716±0.00000  bestvalidloss -2129.44590  last_update 3\n",
      "train: iter 333  trainloss -2209.47130  validloss -2112.30414±0.00000  bestvalidloss -2129.44590  last_update 4\n",
      "train: iter 334  trainloss -2156.33324  validloss -2121.62117±0.00000  bestvalidloss -2129.44590  last_update 5\n",
      "train: iter 335  trainloss -2181.71205  validloss -2026.80675±0.00000  bestvalidloss -2129.44590  last_update 6\n",
      "train: iter 336  trainloss -2187.41990  validloss -2112.01974±0.00000  bestvalidloss -2129.44590  last_update 7\n",
      "train: iter 337  trainloss -2199.33013  validloss -2113.28159±0.00000  bestvalidloss -2129.44590  last_update 8\n",
      "train: iter 338  trainloss -2194.78520  validloss -2120.44265±0.00000  bestvalidloss -2129.44590  last_update 9\n",
      "train: iter 339  trainloss -2191.11507  validloss -2121.93659±0.00000  bestvalidloss -2129.44590  last_update 10\n",
      "train: iter 340  trainloss -2191.18236  validloss -2023.27815±0.00000  bestvalidloss -2129.44590  last_update 11\n",
      "train: iter 341  trainloss -2194.28594  validloss -2118.08616±0.00000  bestvalidloss -2129.44590  last_update 12\n",
      "train: iter 342  trainloss -2207.20048  validloss -2109.74784±0.00000  bestvalidloss -2129.44590  last_update 13\n",
      "train: iter 343  trainloss -2142.07617  validloss -2151.10592±0.00000  bestvalidloss -2151.10592  last_update 0\n",
      "train: iter 344  trainloss -2121.90092  validloss -2035.00688±0.00000  bestvalidloss -2151.10592  last_update 1\n",
      "train: iter 345  trainloss -2196.32020  validloss -2074.76016±0.00000  bestvalidloss -2151.10592  last_update 2\n",
      "train: iter 346  trainloss -2164.22505  validloss -1990.40263±0.00000  bestvalidloss -2151.10592  last_update 3\n",
      "train: iter 347  trainloss -2190.05328  validloss -2126.32202±0.00000  bestvalidloss -2151.10592  last_update 4\n",
      "train: iter 348  trainloss -2156.49280  validloss -2107.25182±0.00000  bestvalidloss -2151.10592  last_update 5\n",
      "train: iter 349  trainloss -2164.46466  validloss -2076.49557±0.00000  bestvalidloss -2151.10592  last_update 6\n",
      "train: iter 350  trainloss -2155.73900  validloss -2105.44058±0.00000  bestvalidloss -2151.10592  last_update 7\n",
      "train: iter 351  trainloss -2186.01805  validloss -2030.71143±0.00000  bestvalidloss -2151.10592  last_update 8\n",
      "train: iter 352  trainloss -2195.00277  validloss -2133.80130±0.00000  bestvalidloss -2151.10592  last_update 9\n",
      "train: iter 353  trainloss -2210.08560  validloss -2104.76935±0.00000  bestvalidloss -2151.10592  last_update 10\n",
      "train: iter 354  trainloss -2209.76923  validloss -2143.65633±0.00000  bestvalidloss -2151.10592  last_update 11\n",
      "train: iter 355  trainloss -2185.12626  validloss -2136.31814±0.00000  bestvalidloss -2151.10592  last_update 12\n",
      "train: iter 356  trainloss -2181.02595  validloss -2084.07483±0.00000  bestvalidloss -2151.10592  last_update 13\n",
      "train: iter 357  trainloss -2178.66319  validloss -2075.42887±0.00000  bestvalidloss -2151.10592  last_update 14\n",
      "train: iter 358  trainloss -2040.71006  validloss -2102.34084±0.00000  bestvalidloss -2151.10592  last_update 15\n",
      "train: iter 359  trainloss -2177.62843  validloss -2069.70842±0.00000  bestvalidloss -2151.10592  last_update 16\n",
      "train: iter 360  trainloss -2197.18531  validloss -2135.16580±0.00000  bestvalidloss -2151.10592  last_update 17\n",
      "train: iter 361  trainloss -2207.18035  validloss -2110.58954±0.00000  bestvalidloss -2151.10592  last_update 18\n",
      "train: iter 362  trainloss -2160.87731  validloss -2153.72430±0.00000  bestvalidloss -2153.72430  last_update 0\n",
      "train: iter 363  trainloss -2178.24194  validloss -2118.56718±0.00000  bestvalidloss -2153.72430  last_update 1\n",
      "train: iter 364  trainloss -2202.01509  validloss -2137.58951±0.00000  bestvalidloss -2153.72430  last_update 2\n",
      "train: iter 365  trainloss -2212.05805  validloss -2125.12688±0.00000  bestvalidloss -2153.72430  last_update 3\n",
      "train: iter 366  trainloss -2216.58772  validloss -2140.72983±0.00000  bestvalidloss -2153.72430  last_update 4\n",
      "train: iter 367  trainloss -2196.62326  validloss -2137.05916±0.00000  bestvalidloss -2153.72430  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 368  trainloss -2214.90177  validloss -2113.08733±0.00000  bestvalidloss -2153.72430  last_update 6\n",
      "train: iter 369  trainloss -2216.67865  validloss -2143.37452±0.00000  bestvalidloss -2153.72430  last_update 7\n",
      "train: iter 370  trainloss -2197.38084  validloss -2113.23819±0.00000  bestvalidloss -2153.72430  last_update 8\n",
      "train: iter 371  trainloss -2104.65400  validloss -2094.46866±0.00000  bestvalidloss -2153.72430  last_update 9\n",
      "train: iter 372  trainloss -2115.63218  validloss -1842.52460±0.00000  bestvalidloss -2153.72430  last_update 10\n",
      "train: iter 373  trainloss -2113.04923  validloss -2049.39766±0.00000  bestvalidloss -2153.72430  last_update 11\n",
      "train: iter 374  trainloss -2210.43406  validloss -2133.18335±0.00000  bestvalidloss -2153.72430  last_update 12\n",
      "train: iter 375  trainloss -2199.11736  validloss -2141.71092±0.00000  bestvalidloss -2153.72430  last_update 13\n",
      "train: iter 376  trainloss -2221.74165  validloss -2149.58167±0.00000  bestvalidloss -2153.72430  last_update 14\n",
      "train: iter 377  trainloss -2227.53311  validloss -2137.95483±0.00000  bestvalidloss -2153.72430  last_update 15\n",
      "train: iter 378  trainloss -2206.60560  validloss -2158.89340±0.00000  bestvalidloss -2158.89340  last_update 0\n",
      "train: iter 379  trainloss -2197.95957  validloss -2141.32889±0.00000  bestvalidloss -2158.89340  last_update 1\n",
      "train: iter 380  trainloss -2202.95497  validloss -2129.38940±0.00000  bestvalidloss -2158.89340  last_update 2\n",
      "train: iter 381  trainloss -2219.60202  validloss -2156.27024±0.00000  bestvalidloss -2158.89340  last_update 3\n",
      "train: iter 382  trainloss -2216.96061  validloss -2131.05292±0.00000  bestvalidloss -2158.89340  last_update 4\n",
      "train: iter 383  trainloss -2198.34282  validloss -2139.64789±0.00000  bestvalidloss -2158.89340  last_update 5\n",
      "train: iter 384  trainloss -2200.31096  validloss -2143.15947±0.00000  bestvalidloss -2158.89340  last_update 6\n",
      "train: iter 385  trainloss -2225.42580  validloss -2128.29099±0.00000  bestvalidloss -2158.89340  last_update 7\n",
      "train: iter 386  trainloss -2216.62980  validloss -2123.85170±0.00000  bestvalidloss -2158.89340  last_update 8\n",
      "train: iter 387  trainloss -2221.40103  validloss -2151.18002±0.00000  bestvalidloss -2158.89340  last_update 9\n",
      "train: iter 388  trainloss -2191.56231  validloss -2125.67680±0.00000  bestvalidloss -2158.89340  last_update 10\n",
      "train: iter 389  trainloss -2204.85593  validloss -2136.58358±0.00000  bestvalidloss -2158.89340  last_update 11\n",
      "train: iter 390  trainloss -2182.58882  validloss -2030.13222±0.00000  bestvalidloss -2158.89340  last_update 12\n",
      "train: iter 391  trainloss -2226.30986  validloss -2072.72854±0.00000  bestvalidloss -2158.89340  last_update 13\n",
      "train: iter 392  trainloss -2228.84199  validloss -2153.45193±0.00000  bestvalidloss -2158.89340  last_update 14\n",
      "train: iter 393  trainloss -2145.22646  validloss -2126.80561±0.00000  bestvalidloss -2158.89340  last_update 15\n",
      "train: iter 394  trainloss -1891.91697  validloss -1482.29688±0.00000  bestvalidloss -2158.89340  last_update 16\n",
      "train: iter 395  trainloss -2190.93765  validloss -2008.92606±0.00000  bestvalidloss -2158.89340  last_update 17\n",
      "train: iter 396  trainloss -2203.93891  validloss -2089.34363±0.00000  bestvalidloss -2158.89340  last_update 18\n",
      "train: iter 397  trainloss -2236.56610  validloss -2157.15349±0.00000  bestvalidloss -2158.89340  last_update 19\n",
      "train: iter 398  trainloss -2220.83268  validloss -2170.12505±0.00000  bestvalidloss -2170.12505  last_update 0\n",
      "train: iter 399  trainloss -2231.86247  validloss -2123.81140±0.00000  bestvalidloss -2170.12505  last_update 1\n",
      "train: iter 400  trainloss -2236.53878  validloss -2155.85137±0.00000  bestvalidloss -2170.12505  last_update 2\n",
      "train: iter 401  trainloss -2222.11325  validloss -2196.40079±0.00000  bestvalidloss -2196.40079  last_update 0\n",
      "train: iter 402  trainloss -2236.30144  validloss -2137.13901±0.00000  bestvalidloss -2196.40079  last_update 1\n",
      "train: iter 403  trainloss -2197.47161  validloss -2130.74650±0.00000  bestvalidloss -2196.40079  last_update 2\n",
      "train: iter 404  trainloss -2139.68484  validloss -1988.14786±0.00000  bestvalidloss -2196.40079  last_update 3\n",
      "train: iter 405  trainloss -2234.55316  validloss -2129.58956±0.00000  bestvalidloss -2196.40079  last_update 4\n",
      "train: iter 406  trainloss -2226.94586  validloss -2152.95996±0.00000  bestvalidloss -2196.40079  last_update 5\n",
      "train: iter 407  trainloss -2234.45197  validloss -2076.08590±0.00000  bestvalidloss -2196.40079  last_update 6\n",
      "train: iter 408  trainloss -2218.72583  validloss -2112.44648±0.00000  bestvalidloss -2196.40079  last_update 7\n",
      "train: iter 409  trainloss -2235.04626  validloss -2162.23525±0.00000  bestvalidloss -2196.40079  last_update 8\n",
      "train: iter 410  trainloss -2222.54881  validloss -2129.03319±0.00000  bestvalidloss -2196.40079  last_update 9\n",
      "train: iter 411  trainloss -2235.55954  validloss -2146.00760±0.00000  bestvalidloss -2196.40079  last_update 10\n",
      "train: iter 412  trainloss -2211.72574  validloss -2147.96104±0.00000  bestvalidloss -2196.40079  last_update 11\n",
      "train: iter 413  trainloss -2207.83853  validloss -2121.61088±0.00000  bestvalidloss -2196.40079  last_update 12\n",
      "train: iter 414  trainloss -2204.05059  validloss -2116.01116±0.00000  bestvalidloss -2196.40079  last_update 13\n",
      "train: iter 415  trainloss -2236.36508  validloss -2135.93837±0.00000  bestvalidloss -2196.40079  last_update 14\n",
      "train: iter 416  trainloss -2140.55900  validloss -2083.60370±0.00000  bestvalidloss -2196.40079  last_update 15\n",
      "train: iter 417  trainloss -2142.31148  validloss -1897.13389±0.00000  bestvalidloss -2196.40079  last_update 16\n",
      "train: iter 418  trainloss -2230.51385  validloss -2105.38206±0.00000  bestvalidloss -2196.40079  last_update 17\n",
      "train: iter 419  trainloss -2241.94226  validloss -2157.49123±0.00000  bestvalidloss -2196.40079  last_update 18\n",
      "train: iter 420  trainloss -2249.46414  validloss -2150.22710±0.00000  bestvalidloss -2196.40079  last_update 19\n",
      "train: iter 421  trainloss -2235.33849  validloss -2179.43549±0.00000  bestvalidloss -2196.40079  last_update 20\n",
      "train: iter 422  trainloss -2226.46470  validloss -2141.81742±0.00000  bestvalidloss -2196.40079  last_update 21\n",
      "train: iter 423  trainloss -2173.40254  validloss -2146.66607±0.00000  bestvalidloss -2196.40079  last_update 22\n",
      "train: iter 424  trainloss -2213.39384  validloss -2054.73781±0.00000  bestvalidloss -2196.40079  last_update 23\n",
      "train: iter 425  trainloss -2247.19324  validloss -2158.19944±0.00000  bestvalidloss -2196.40079  last_update 24\n",
      "train: iter 426  trainloss -2238.12826  validloss -2150.27480±0.00000  bestvalidloss -2196.40079  last_update 25\n",
      "train: iter 427  trainloss -2238.21504  validloss -2135.89723±0.00000  bestvalidloss -2196.40079  last_update 26\n",
      "train: iter 428  trainloss -2226.34895  validloss -2151.99257±0.00000  bestvalidloss -2196.40079  last_update 27\n",
      "train: iter 429  trainloss -2228.24902  validloss -2164.81921±0.00000  bestvalidloss -2196.40079  last_update 28\n",
      "train: iter 430  trainloss -2243.08539  validloss -2172.10838±0.00000  bestvalidloss -2196.40079  last_update 29\n",
      "train: iter 431  trainloss -2227.71872  validloss -2141.02805±0.00000  bestvalidloss -2196.40079  last_update 30\n",
      "train: iter 432  trainloss -2237.43855  validloss -2151.85383±0.00000  bestvalidloss -2196.40079  last_update 31\n",
      "train: iter 433  trainloss -2230.55040  validloss -2140.27851±0.00000  bestvalidloss -2196.40079  last_update 32\n",
      "train: iter 434  trainloss -2222.30487  validloss -2146.75871±0.00000  bestvalidloss -2196.40079  last_update 33\n",
      "train: iter 435  trainloss -2223.26941  validloss -2170.04136±0.00000  bestvalidloss -2196.40079  last_update 34\n",
      "train: iter 436  trainloss -2183.79613  validloss -2145.36762±0.00000  bestvalidloss -2196.40079  last_update 35\n",
      "train: iter 437  trainloss -1955.18015  validloss -1795.81734±0.00000  bestvalidloss -2196.40079  last_update 36\n",
      "train: iter 438  trainloss -2140.66414  validloss -2013.35087±0.00000  bestvalidloss -2196.40079  last_update 37\n",
      "train: iter 439  trainloss -2239.24345  validloss -2094.71696±0.00000  bestvalidloss -2196.40079  last_update 38\n",
      "train: iter 440  trainloss -2241.34835  validloss -2153.86201±0.00000  bestvalidloss -2196.40079  last_update 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 441  trainloss -2241.45620  validloss -2191.43069±0.00000  bestvalidloss -2196.40079  last_update 40\n",
      "train: iter 442  trainloss -2248.19932  validloss -2149.72968±0.00000  bestvalidloss -2196.40079  last_update 41\n",
      "train: iter 443  trainloss -2232.21891  validloss -2122.04887±0.00000  bestvalidloss -2196.40079  last_update 42\n",
      "train: iter 444  trainloss -2258.84980  validloss -2157.35226±0.00000  bestvalidloss -2196.40079  last_update 43\n",
      "train: iter 445  trainloss -2256.02749  validloss -2181.41986±0.00000  bestvalidloss -2196.40079  last_update 44\n",
      "train: iter 446  trainloss -2248.20940  validloss -2186.11229±0.00000  bestvalidloss -2196.40079  last_update 45\n",
      "train: iter 447  trainloss -2229.79206  validloss -2155.15679±0.00000  bestvalidloss -2196.40079  last_update 46\n",
      "train: iter 448  trainloss -2240.69408  validloss -2141.34826±0.00000  bestvalidloss -2196.40079  last_update 47\n",
      "train: iter 449  trainloss -2255.67731  validloss -2187.19838±0.00000  bestvalidloss -2196.40079  last_update 48\n",
      "train: iter 450  trainloss -2259.56963  validloss -2194.73167±0.00000  bestvalidloss -2196.40079  last_update 49\n",
      "train: iter 451  trainloss -2204.75762  validloss -2143.81360±0.00000  bestvalidloss -2196.40079  last_update 50\n",
      "train: iter 452  trainloss -2229.77346  validloss -2157.82322±0.00000  bestvalidloss -2196.40079  last_update 51\n",
      "train: iter 453  trainloss -2233.08164  validloss -2142.11197±0.00000  bestvalidloss -2196.40079  last_update 52\n",
      "train: iter 454  trainloss -2181.24293  validloss -2194.04337±0.00000  bestvalidloss -2196.40079  last_update 53\n",
      "train: iter 455  trainloss -2205.75508  validloss -2138.11160±0.00000  bestvalidloss -2196.40079  last_update 54\n",
      "train: iter 456  trainloss -2172.20922  validloss -2051.35426±0.00000  bestvalidloss -2196.40079  last_update 55\n",
      "train: iter 457  trainloss -2246.45257  validloss -2154.53159±0.00000  bestvalidloss -2196.40079  last_update 56\n",
      "train: iter 458  trainloss -2256.84678  validloss -2115.66441±0.00000  bestvalidloss -2196.40079  last_update 57\n",
      "train: iter 459  trainloss -2247.86240  validloss -2129.33454±0.00000  bestvalidloss -2196.40079  last_update 58\n",
      "train: iter 460  trainloss -2263.49956  validloss -2148.49016±0.00000  bestvalidloss -2196.40079  last_update 59\n",
      "train: iter 461  trainloss -2247.88256  validloss -2145.00717±0.00000  bestvalidloss -2196.40079  last_update 60\n",
      "train: iter 462  trainloss -2231.41744  validloss -2107.39385±0.00000  bestvalidloss -2196.40079  last_update 61\n",
      "train: iter 463  trainloss -2223.06632  validloss -2103.37066±0.00000  bestvalidloss -2196.40079  last_update 62\n",
      "train: iter 464  trainloss -2220.98674  validloss -2139.17270±0.00000  bestvalidloss -2196.40079  last_update 63\n",
      "train: iter 465  trainloss -2249.10164  validloss -2175.62807±0.00000  bestvalidloss -2196.40079  last_update 64\n",
      "train: iter 466  trainloss -2198.71156  validloss -2125.01524±0.00000  bestvalidloss -2196.40079  last_update 65\n",
      "train: iter 467  trainloss -2263.34377  validloss -2166.87452±0.00000  bestvalidloss -2196.40079  last_update 66\n",
      "train: iter 468  trainloss -2251.61361  validloss -2160.38439±0.00000  bestvalidloss -2196.40079  last_update 67\n",
      "train: iter 469  trainloss -2266.74266  validloss -2160.18145±0.00000  bestvalidloss -2196.40079  last_update 68\n",
      "train: iter 470  trainloss -2144.64279  validloss -2162.88691±0.00000  bestvalidloss -2196.40079  last_update 69\n",
      "train: iter 471  trainloss -2052.17957  validloss -1679.06061±0.00000  bestvalidloss -2196.40079  last_update 70\n",
      "train: iter 472  trainloss -2132.18568  validloss -2091.45981±0.00000  bestvalidloss -2196.40079  last_update 71\n",
      "train: iter 473  trainloss -2207.65105  validloss -2084.56516±0.00000  bestvalidloss -2196.40079  last_update 72\n",
      "train: iter 474  trainloss -2254.82016  validloss -2109.55242±0.00000  bestvalidloss -2196.40079  last_update 73\n",
      "train: iter 475  trainloss -2271.62528  validloss -2160.06516±0.00000  bestvalidloss -2196.40079  last_update 74\n",
      "train: iter 476  trainloss -2251.09183  validloss -2153.59891±0.00000  bestvalidloss -2196.40079  last_update 75\n",
      "train: iter 477  trainloss -2262.19645  validloss -2143.19420±0.00000  bestvalidloss -2196.40079  last_update 76\n",
      "train: iter 478  trainloss -2270.33432  validloss -2180.40738±0.00000  bestvalidloss -2196.40079  last_update 77\n",
      "train: iter 479  trainloss -2264.83715  validloss -2184.70736±0.00000  bestvalidloss -2196.40079  last_update 78\n",
      "train: iter 480  trainloss -2278.06472  validloss -2176.73132±0.00000  bestvalidloss -2196.40079  last_update 79\n",
      "train: iter 481  trainloss -2269.87894  validloss -2187.46967±0.00000  bestvalidloss -2196.40079  last_update 80\n",
      "train: iter 482  trainloss -2235.88918  validloss -2157.62143±0.00000  bestvalidloss -2196.40079  last_update 81\n",
      "train: iter 483  trainloss -2216.77747  validloss -2160.57698±0.00000  bestvalidloss -2196.40079  last_update 82\n",
      "train: iter 484  trainloss -2249.75797  validloss -2144.23408±0.00000  bestvalidloss -2196.40079  last_update 83\n",
      "train: iter 485  trainloss -2225.73085  validloss -2067.92686±0.00000  bestvalidloss -2196.40079  last_update 84\n",
      "train: iter 486  trainloss -2225.54979  validloss -2160.40215±0.00000  bestvalidloss -2196.40079  last_update 85\n",
      "train: iter 487  trainloss -2250.73626  validloss -2174.28093±0.00000  bestvalidloss -2196.40079  last_update 86\n",
      "train: iter 488  trainloss -2258.51511  validloss -2199.74839±0.00000  bestvalidloss -2199.74839  last_update 0\n",
      "train: iter 489  trainloss -2244.35915  validloss -2171.53916±0.00000  bestvalidloss -2199.74839  last_update 1\n",
      "train: iter 490  trainloss -2241.32912  validloss -2129.84674±0.00000  bestvalidloss -2199.74839  last_update 2\n",
      "train: iter 491  trainloss -2244.24732  validloss -2193.05656±0.00000  bestvalidloss -2199.74839  last_update 3\n",
      "train: iter 492  trainloss -2259.34476  validloss -2127.71009±0.00000  bestvalidloss -2199.74839  last_update 4\n",
      "train: iter 493  trainloss -2191.48099  validloss -2185.45685±0.00000  bestvalidloss -2199.74839  last_update 5\n",
      "train: iter 494  trainloss -2249.19218  validloss -2185.00802±0.00000  bestvalidloss -2199.74839  last_update 6\n",
      "train: iter 495  trainloss -2261.68811  validloss -2170.42802±0.00000  bestvalidloss -2199.74839  last_update 7\n",
      "train: iter 496  trainloss -2231.51230  validloss -2104.74802±0.00000  bestvalidloss -2199.74839  last_update 8\n",
      "train: iter 497  trainloss -2257.26709  validloss -2196.52803±0.00000  bestvalidloss -2199.74839  last_update 9\n",
      "train: iter 498  trainloss -2233.50155  validloss -2058.66438±0.00000  bestvalidloss -2199.74839  last_update 10\n",
      "train: iter 499  trainloss -2267.45801  validloss -2180.41295±0.00000  bestvalidloss -2199.74839  last_update 11\n",
      "train: iter 500  trainloss -2259.90014  validloss -2203.05111±0.00000  bestvalidloss -2203.05111  last_update 0\n",
      "train: iter 501  trainloss -2197.64737  validloss -2189.83194±0.00000  bestvalidloss -2203.05111  last_update 1\n",
      "train: iter 502  trainloss -2247.31654  validloss -2125.64354±0.00000  bestvalidloss -2203.05111  last_update 2\n",
      "train: iter 503  trainloss -2277.25717  validloss -2195.35916±0.00000  bestvalidloss -2203.05111  last_update 3\n",
      "train: iter 504  trainloss -2274.58300  validloss -2211.41538±0.00000  bestvalidloss -2211.41538  last_update 0\n",
      "train: iter 505  trainloss -2275.48736  validloss -2210.62936±0.00000  bestvalidloss -2211.41538  last_update 1\n",
      "train: iter 506  trainloss -2261.65717  validloss -2160.34293±0.00000  bestvalidloss -2211.41538  last_update 2\n",
      "train: iter 507  trainloss -2262.80564  validloss -2126.96176±0.00000  bestvalidloss -2211.41538  last_update 3\n",
      "train: iter 508  trainloss -2264.04582  validloss -2184.63467±0.00000  bestvalidloss -2211.41538  last_update 4\n",
      "train: iter 509  trainloss -2254.43074  validloss -2177.98717±0.00000  bestvalidloss -2211.41538  last_update 5\n",
      "train: iter 510  trainloss -2186.41867  validloss -2112.67204±0.00000  bestvalidloss -2211.41538  last_update 6\n",
      "train: iter 511  trainloss -2027.97208  validloss -2042.89135±0.00000  bestvalidloss -2211.41538  last_update 7\n",
      "train: iter 512  trainloss -2225.49681  validloss -2029.81582±0.00000  bestvalidloss -2211.41538  last_update 8\n",
      "train: iter 513  trainloss -2265.22672  validloss -2162.53660±0.00000  bestvalidloss -2211.41538  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 514  trainloss -2274.65378  validloss -2193.06927±0.00000  bestvalidloss -2211.41538  last_update 10\n",
      "train: iter 515  trainloss -2260.53265  validloss -2188.42198±0.00000  bestvalidloss -2211.41538  last_update 11\n",
      "train: iter 516  trainloss -2272.28924  validloss -2188.78294±0.00000  bestvalidloss -2211.41538  last_update 12\n",
      "train: iter 517  trainloss -2266.47647  validloss -2189.74570±0.00000  bestvalidloss -2211.41538  last_update 13\n",
      "train: iter 518  trainloss -2171.85957  validloss -2074.27603±0.00000  bestvalidloss -2211.41538  last_update 14\n",
      "train: iter 519  trainloss -2261.73130  validloss -2178.08240±0.00000  bestvalidloss -2211.41538  last_update 15\n",
      "train: iter 520  trainloss -2269.75762  validloss -2152.83949±0.00000  bestvalidloss -2211.41538  last_update 16\n",
      "train: iter 521  trainloss -2244.99863  validloss -2208.58302±0.00000  bestvalidloss -2211.41538  last_update 17\n",
      "train: iter 522  trainloss -2272.20991  validloss -2189.40618±0.00000  bestvalidloss -2211.41538  last_update 18\n",
      "train: iter 523  trainloss -2275.47734  validloss -2154.97635±0.00000  bestvalidloss -2211.41538  last_update 19\n",
      "train: iter 524  trainloss -2258.99562  validloss -2193.55083±0.00000  bestvalidloss -2211.41538  last_update 20\n",
      "train: iter 525  trainloss -2264.72004  validloss -2206.60229±0.00000  bestvalidloss -2211.41538  last_update 21\n",
      "train: iter 526  trainloss -2275.22443  validloss -2205.81257±0.00000  bestvalidloss -2211.41538  last_update 22\n",
      "train: iter 527  trainloss -2262.20297  validloss -2207.31874±0.00000  bestvalidloss -2211.41538  last_update 23\n",
      "train: iter 528  trainloss -2233.73228  validloss -2081.17043±0.00000  bestvalidloss -2211.41538  last_update 24\n",
      "train: iter 529  trainloss -2240.94939  validloss -2160.99915±0.00000  bestvalidloss -2211.41538  last_update 25\n",
      "train: iter 530  trainloss -2267.96535  validloss -2183.26024±0.00000  bestvalidloss -2211.41538  last_update 26\n",
      "train: iter 531  trainloss -2095.86999  validloss -2141.24340±0.00000  bestvalidloss -2211.41538  last_update 27\n",
      "train: iter 532  trainloss -2248.41391  validloss -2118.02593±0.00000  bestvalidloss -2211.41538  last_update 28\n",
      "train: iter 533  trainloss -2265.05542  validloss -2159.45300±0.00000  bestvalidloss -2211.41538  last_update 29\n",
      "train: iter 534  trainloss -2258.06566  validloss -2191.08261±0.00000  bestvalidloss -2211.41538  last_update 30\n",
      "train: iter 535  trainloss -2231.23574  validloss -2122.64156±0.00000  bestvalidloss -2211.41538  last_update 31\n",
      "train: iter 536  trainloss -2266.63716  validloss -2163.56663±0.00000  bestvalidloss -2211.41538  last_update 32\n",
      "train: iter 537  trainloss -2268.55351  validloss -2169.05666±0.00000  bestvalidloss -2211.41538  last_update 33\n",
      "train: iter 538  trainloss -2282.07333  validloss -2160.00239±0.00000  bestvalidloss -2211.41538  last_update 34\n",
      "train: iter 539  trainloss -2272.21385  validloss -2182.99855±0.00000  bestvalidloss -2211.41538  last_update 35\n",
      "train: iter 540  trainloss -2268.75594  validloss -2190.25618±0.00000  bestvalidloss -2211.41538  last_update 36\n",
      "train: iter 541  trainloss -2265.36054  validloss -2219.93297±0.00000  bestvalidloss -2219.93297  last_update 0\n",
      "train: iter 542  trainloss -2262.60533  validloss -2139.49925±0.00000  bestvalidloss -2219.93297  last_update 1\n",
      "train: iter 543  trainloss -2261.51907  validloss -2183.63748±0.00000  bestvalidloss -2219.93297  last_update 2\n",
      "train: iter 544  trainloss -2214.34677  validloss -2124.55285±0.00000  bestvalidloss -2219.93297  last_update 3\n",
      "train: iter 545  trainloss -2224.59465  validloss -2038.12116±0.00000  bestvalidloss -2219.93297  last_update 4\n",
      "train: iter 546  trainloss -2185.41123  validloss -2134.65821±0.00000  bestvalidloss -2219.93297  last_update 5\n",
      "train: iter 547  trainloss -2144.33800  validloss -1968.62714±0.00000  bestvalidloss -2219.93297  last_update 6\n",
      "train: iter 548  trainloss -2216.47285  validloss -2189.95339±0.00000  bestvalidloss -2219.93297  last_update 7\n",
      "train: iter 549  trainloss -2188.11538  validloss -1837.56655±0.00000  bestvalidloss -2219.93297  last_update 8\n",
      "train: iter 550  trainloss -2273.95422  validloss -2190.14806±0.00000  bestvalidloss -2219.93297  last_update 9\n",
      "train: iter 551  trainloss -2267.98958  validloss -2193.20116±0.00000  bestvalidloss -2219.93297  last_update 10\n",
      "train: iter 552  trainloss -2274.15266  validloss -2187.11232±0.00000  bestvalidloss -2219.93297  last_update 11\n",
      "train: iter 553  trainloss -2265.26775  validloss -2202.67896±0.00000  bestvalidloss -2219.93297  last_update 12\n",
      "train: iter 554  trainloss -2284.78566  validloss -2218.40015±0.00000  bestvalidloss -2219.93297  last_update 13\n",
      "train: iter 555  trainloss -2279.12327  validloss -2191.63191±0.00000  bestvalidloss -2219.93297  last_update 14\n",
      "train: iter 556  trainloss -2256.50561  validloss -2179.58181±0.00000  bestvalidloss -2219.93297  last_update 15\n",
      "train: iter 557  trainloss -2267.74650  validloss -2135.58177±0.00000  bestvalidloss -2219.93297  last_update 16\n",
      "train: iter 558  trainloss -2261.07753  validloss -2203.12065±0.00000  bestvalidloss -2219.93297  last_update 17\n",
      "train: iter 559  trainloss -2268.46288  validloss -2216.66530±0.00000  bestvalidloss -2219.93297  last_update 18\n",
      "train: iter 560  trainloss -2270.87283  validloss -2187.06455±0.00000  bestvalidloss -2219.93297  last_update 19\n",
      "train: iter 561  trainloss -2241.38606  validloss -2187.97552±0.00000  bestvalidloss -2219.93297  last_update 20\n",
      "train: iter 562  trainloss -2254.38162  validloss -2135.75256±0.00000  bestvalidloss -2219.93297  last_update 21\n",
      "train: iter 563  trainloss -2273.49808  validloss -2222.22481±0.00000  bestvalidloss -2222.22481  last_update 0\n",
      "train: iter 564  trainloss -2233.85790  validloss -2197.49027±0.00000  bestvalidloss -2222.22481  last_update 1\n",
      "train: iter 565  trainloss -2140.56606  validloss -2060.98696±0.00000  bestvalidloss -2222.22481  last_update 2\n",
      "train: iter 566  trainloss -2257.91295  validloss -2133.10450±0.00000  bestvalidloss -2222.22481  last_update 3\n",
      "train: iter 567  trainloss -2280.84268  validloss -2224.38405±0.00000  bestvalidloss -2224.38405  last_update 0\n",
      "train: iter 568  trainloss -2260.83117  validloss -2187.13771±0.00000  bestvalidloss -2224.38405  last_update 1\n",
      "train: iter 569  trainloss -2256.58246  validloss -2178.30231±0.00000  bestvalidloss -2224.38405  last_update 2\n",
      "train: iter 570  trainloss -2274.95582  validloss -2199.92233±0.00000  bestvalidloss -2224.38405  last_update 3\n",
      "train: iter 571  trainloss -2267.54798  validloss -2129.41246±0.00000  bestvalidloss -2224.38405  last_update 4\n",
      "train: iter 572  trainloss -2273.18201  validloss -2165.64893±0.00000  bestvalidloss -2224.38405  last_update 5\n",
      "train: iter 573  trainloss -2198.36010  validloss -2188.36803±0.00000  bestvalidloss -2224.38405  last_update 6\n",
      "train: iter 574  trainloss -2182.21439  validloss -2130.38380±0.00000  bestvalidloss -2224.38405  last_update 7\n",
      "train: iter 575  trainloss -2248.59490  validloss -2064.82803±0.00000  bestvalidloss -2224.38405  last_update 8\n",
      "train: iter 576  trainloss -2257.20552  validloss -2172.57603±0.00000  bestvalidloss -2224.38405  last_update 9\n",
      "train: iter 577  trainloss -2254.40790  validloss -2176.35841±0.00000  bestvalidloss -2224.38405  last_update 10\n",
      "train: iter 578  trainloss -2272.36654  validloss -2215.39036±0.00000  bestvalidloss -2224.38405  last_update 11\n",
      "train: iter 579  trainloss -2282.50141  validloss -2188.95802±0.00000  bestvalidloss -2224.38405  last_update 12\n",
      "train: iter 580  trainloss -2283.64157  validloss -2230.85148±0.00000  bestvalidloss -2230.85148  last_update 0\n",
      "train: iter 581  trainloss -2280.99724  validloss -2230.99781±0.00000  bestvalidloss -2230.99781  last_update 0\n",
      "train: iter 582  trainloss -2279.54202  validloss -2218.91945±0.00000  bestvalidloss -2230.99781  last_update 1\n",
      "train: iter 583  trainloss -2282.68843  validloss -2238.13426±0.00000  bestvalidloss -2238.13426  last_update 0\n",
      "train: iter 584  trainloss -2269.34184  validloss -2223.40487±0.00000  bestvalidloss -2238.13426  last_update 1\n",
      "train: iter 585  trainloss -2272.83261  validloss -2219.87963±0.00000  bestvalidloss -2238.13426  last_update 2\n",
      "train: iter 586  trainloss -2264.57910  validloss -2210.85701±0.00000  bestvalidloss -2238.13426  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 587  trainloss -2162.23779  validloss -2168.80641±0.00000  bestvalidloss -2238.13426  last_update 4\n",
      "train: iter 588  trainloss -2254.54330  validloss -1957.65872±0.00000  bestvalidloss -2238.13426  last_update 5\n",
      "train: iter 589  trainloss -2272.87718  validloss -2221.23032±0.00000  bestvalidloss -2238.13426  last_update 6\n",
      "train: iter 590  trainloss -2274.31108  validloss -2230.38516±0.00000  bestvalidloss -2238.13426  last_update 7\n",
      "train: iter 591  trainloss -2284.50570  validloss -2197.33002±0.00000  bestvalidloss -2238.13426  last_update 8\n",
      "train: iter 592  trainloss -2271.11879  validloss -2231.82573±0.00000  bestvalidloss -2238.13426  last_update 9\n",
      "train: iter 593  trainloss -2235.71564  validloss -2208.36369±0.00000  bestvalidloss -2238.13426  last_update 10\n",
      "train: iter 594  trainloss -2241.61714  validloss -2110.62385±0.00000  bestvalidloss -2238.13426  last_update 11\n",
      "train: iter 595  trainloss -2248.32006  validloss -2153.17827±0.00000  bestvalidloss -2238.13426  last_update 12\n",
      "train: iter 596  trainloss -2248.92612  validloss -2166.89149±0.00000  bestvalidloss -2238.13426  last_update 13\n",
      "train: iter 597  trainloss -2259.60388  validloss -2123.26651±0.00000  bestvalidloss -2238.13426  last_update 14\n",
      "train: iter 598  trainloss -2235.88614  validloss -2148.67831±0.00000  bestvalidloss -2238.13426  last_update 15\n",
      "train: iter 599  trainloss -2253.88747  validloss -2182.19385±0.00000  bestvalidloss -2238.13426  last_update 16\n",
      "train: iter 600  trainloss -2267.69262  validloss -2183.52477±0.00000  bestvalidloss -2238.13426  last_update 17\n",
      "train: iter 601  trainloss -2245.32543  validloss -2201.40963±0.00000  bestvalidloss -2238.13426  last_update 18\n",
      "train: iter 602  trainloss -2253.76667  validloss -2133.70168±0.00000  bestvalidloss -2238.13426  last_update 19\n",
      "train: iter 603  trainloss -2269.56299  validloss -2224.30241±0.00000  bestvalidloss -2238.13426  last_update 20\n",
      "train: iter 604  trainloss -2271.40569  validloss -2187.49173±0.00000  bestvalidloss -2238.13426  last_update 21\n",
      "train: iter 605  trainloss -2250.10658  validloss -2161.46024±0.00000  bestvalidloss -2238.13426  last_update 22\n",
      "train: iter 606  trainloss -2248.35393  validloss -2193.63116±0.00000  bestvalidloss -2238.13426  last_update 23\n",
      "train: iter 607  trainloss -2243.99937  validloss -2016.75469±0.00000  bestvalidloss -2238.13426  last_update 24\n",
      "train: iter 608  trainloss -2284.43614  validloss -2194.46254±0.00000  bestvalidloss -2238.13426  last_update 25\n",
      "train: iter 609  trainloss -2281.41646  validloss -2235.16015±0.00000  bestvalidloss -2238.13426  last_update 26\n",
      "train: iter 610  trainloss -2269.01005  validloss -2231.06885±0.00000  bestvalidloss -2238.13426  last_update 27\n",
      "train: iter 611  trainloss -2272.17946  validloss -2219.50957±0.00000  bestvalidloss -2238.13426  last_update 28\n",
      "train: iter 612  trainloss -2274.09932  validloss -2224.37760±0.00000  bestvalidloss -2238.13426  last_update 29\n",
      "train: iter 613  trainloss -2245.09667  validloss -2245.15814±0.00000  bestvalidloss -2245.15814  last_update 0\n",
      "train: iter 614  trainloss -2274.57921  validloss -2183.61317±0.00000  bestvalidloss -2245.15814  last_update 1\n",
      "train: iter 615  trainloss -2277.43098  validloss -2243.24734±0.00000  bestvalidloss -2245.15814  last_update 2\n",
      "train: iter 616  trainloss -2272.08092  validloss -2222.95587±0.00000  bestvalidloss -2245.15814  last_update 3\n",
      "train: iter 617  trainloss -2282.37238  validloss -2209.82962±0.00000  bestvalidloss -2245.15814  last_update 4\n",
      "train: iter 618  trainloss -2284.74794  validloss -2225.04334±0.00000  bestvalidloss -2245.15814  last_update 5\n",
      "train: iter 619  trainloss -2273.50818  validloss -2174.00369±0.00000  bestvalidloss -2245.15814  last_update 6\n",
      "train: iter 620  trainloss -2273.65063  validloss -2190.97425±0.00000  bestvalidloss -2245.15814  last_update 7\n",
      "train: iter 621  trainloss -2264.98914  validloss -2226.08472±0.00000  bestvalidloss -2245.15814  last_update 8\n",
      "train: iter 622  trainloss -2093.68554  validloss -2220.65349±0.00000  bestvalidloss -2245.15814  last_update 9\n",
      "train: iter 623  trainloss -2266.98730  validloss -2207.05134±0.00000  bestvalidloss -2245.15814  last_update 10\n",
      "train: iter 624  trainloss -2280.96526  validloss -2237.14156±0.00000  bestvalidloss -2245.15814  last_update 11\n",
      "train: iter 625  trainloss -2240.65304  validloss -2243.09836±0.00000  bestvalidloss -2245.15814  last_update 12\n",
      "train: iter 626  trainloss -2259.04766  validloss -2198.97957±0.00000  bestvalidloss -2245.15814  last_update 13\n",
      "train: iter 627  trainloss -2274.54801  validloss -2167.49421±0.00000  bestvalidloss -2245.15814  last_update 14\n",
      "train: iter 628  trainloss -2278.30992  validloss -2221.08498±0.00000  bestvalidloss -2245.15814  last_update 15\n",
      "train: iter 629  trainloss -2290.71279  validloss -2232.62361±0.00000  bestvalidloss -2245.15814  last_update 16\n",
      "train: iter 630  trainloss -2271.71654  validloss -2236.20495±0.00000  bestvalidloss -2245.15814  last_update 17\n",
      "train: iter 631  trainloss -2274.73555  validloss -2202.77293±0.00000  bestvalidloss -2245.15814  last_update 18\n",
      "train: iter 632  trainloss -2266.67593  validloss -2241.19608±0.00000  bestvalidloss -2245.15814  last_update 19\n",
      "train: iter 633  trainloss -2270.38709  validloss -2241.66557±0.00000  bestvalidloss -2245.15814  last_update 20\n",
      "train: iter 634  trainloss -2270.20192  validloss -2213.67537±0.00000  bestvalidloss -2245.15814  last_update 21\n",
      "train: iter 635  trainloss -2235.13388  validloss -2222.48486±0.00000  bestvalidloss -2245.15814  last_update 22\n",
      "train: iter 636  trainloss -2265.81116  validloss -2145.89023±0.00000  bestvalidloss -2245.15814  last_update 23\n",
      "train: iter 637  trainloss -2235.54896  validloss -2206.21345±0.00000  bestvalidloss -2245.15814  last_update 24\n",
      "train: iter 638  trainloss -2254.08120  validloss -2233.32078±0.00000  bestvalidloss -2245.15814  last_update 25\n",
      "train: iter 639  trainloss -2261.92723  validloss -2234.38636±0.00000  bestvalidloss -2245.15814  last_update 26\n",
      "train: iter 640  trainloss -2223.95122  validloss -2243.48950±0.00000  bestvalidloss -2245.15814  last_update 27\n",
      "train: iter 641  trainloss -2267.64497  validloss -2211.27948±0.00000  bestvalidloss -2245.15814  last_update 28\n",
      "train: iter 642  trainloss -2289.42416  validloss -2255.07159±0.00000  bestvalidloss -2255.07159  last_update 0\n",
      "train: iter 643  trainloss -2283.39212  validloss -2232.23375±0.00000  bestvalidloss -2255.07159  last_update 1\n",
      "train: iter 644  trainloss -2254.72504  validloss -2215.00316±0.00000  bestvalidloss -2255.07159  last_update 2\n",
      "train: iter 645  trainloss -2180.10774  validloss -2155.90197±0.00000  bestvalidloss -2255.07159  last_update 3\n",
      "train: iter 646  trainloss -2166.44324  validloss -2173.74603±0.00000  bestvalidloss -2255.07159  last_update 4\n",
      "train: iter 647  trainloss -2240.10782  validloss -2106.99465±0.00000  bestvalidloss -2255.07159  last_update 5\n",
      "train: iter 648  trainloss -2266.29516  validloss -2221.42170±0.00000  bestvalidloss -2255.07159  last_update 6\n",
      "train: iter 649  trainloss -2291.21347  validloss -2248.38774±0.00000  bestvalidloss -2255.07159  last_update 7\n",
      "train: iter 650  trainloss -2291.22244  validloss -2256.09586±0.00000  bestvalidloss -2256.09586  last_update 0\n",
      "train: iter 651  trainloss -2247.47280  validloss -2242.18936±0.00000  bestvalidloss -2256.09586  last_update 1\n",
      "train: iter 652  trainloss -2270.92196  validloss -2249.44512±0.00000  bestvalidloss -2256.09586  last_update 2\n",
      "train: iter 653  trainloss -2275.20569  validloss -2241.74626±0.00000  bestvalidloss -2256.09586  last_update 3\n",
      "train: iter 654  trainloss -2254.13297  validloss -2193.61236±0.00000  bestvalidloss -2256.09586  last_update 4\n",
      "train: iter 655  trainloss -2284.15754  validloss -2247.32227±0.00000  bestvalidloss -2256.09586  last_update 5\n",
      "train: iter 656  trainloss -2278.16199  validloss -2254.94570±0.00000  bestvalidloss -2256.09586  last_update 6\n",
      "train: iter 657  trainloss -2277.65999  validloss -2248.66340±0.00000  bestvalidloss -2256.09586  last_update 7\n",
      "train: iter 658  trainloss -2278.93184  validloss -2215.11268±0.00000  bestvalidloss -2256.09586  last_update 8\n",
      "train: iter 659  trainloss -2275.12326  validloss -2219.67408±0.00000  bestvalidloss -2256.09586  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 660  trainloss -2196.90694  validloss -2219.20170±0.00000  bestvalidloss -2256.09586  last_update 10\n",
      "train: iter 661  trainloss -2275.65109  validloss -2227.31880±0.00000  bestvalidloss -2256.09586  last_update 11\n",
      "train: iter 662  trainloss -2259.67070  validloss -2228.25492±0.00000  bestvalidloss -2256.09586  last_update 12\n",
      "train: iter 663  trainloss -2271.67747  validloss -2253.71755±0.00000  bestvalidloss -2256.09586  last_update 13\n",
      "train: iter 664  trainloss -2285.89362  validloss -2203.54743±0.00000  bestvalidloss -2256.09586  last_update 14\n",
      "train: iter 665  trainloss -2277.81591  validloss -2251.76111±0.00000  bestvalidloss -2256.09586  last_update 15\n",
      "train: iter 666  trainloss -2265.67406  validloss -2234.22702±0.00000  bestvalidloss -2256.09586  last_update 16\n",
      "train: iter 667  trainloss -2270.66077  validloss -2253.08845±0.00000  bestvalidloss -2256.09586  last_update 17\n",
      "train: iter 668  trainloss -2285.08300  validloss -2249.38962±0.00000  bestvalidloss -2256.09586  last_update 18\n",
      "train: iter 669  trainloss -2281.24111  validloss -2207.90407±0.00000  bestvalidloss -2256.09586  last_update 19\n",
      "train: iter 670  trainloss -2265.21052  validloss -2246.16804±0.00000  bestvalidloss -2256.09586  last_update 20\n",
      "train: iter 671  trainloss -2282.03877  validloss -2209.81544±0.00000  bestvalidloss -2256.09586  last_update 21\n",
      "train: iter 672  trainloss -2290.08345  validloss -2228.12023±0.00000  bestvalidloss -2256.09586  last_update 22\n",
      "train: iter 673  trainloss -2115.51314  validloss -2207.66935±0.00000  bestvalidloss -2256.09586  last_update 23\n",
      "train: iter 674  trainloss -2246.12501  validloss -1931.32714±0.00000  bestvalidloss -2256.09586  last_update 24\n",
      "train: iter 675  trainloss -2273.53306  validloss -2227.62822±0.00000  bestvalidloss -2256.09586  last_update 25\n",
      "train: iter 676  trainloss -2287.42570  validloss -2256.27023±0.00000  bestvalidloss -2256.27023  last_update 0\n",
      "train: iter 677  trainloss -2281.95145  validloss -2216.52855±0.00000  bestvalidloss -2256.27023  last_update 1\n",
      "train: iter 678  trainloss -2285.05136  validloss -2235.22844±0.00000  bestvalidloss -2256.27023  last_update 2\n",
      "train: iter 679  trainloss -2284.35208  validloss -2213.64168±0.00000  bestvalidloss -2256.27023  last_update 3\n",
      "train: iter 680  trainloss -2164.83378  validloss -2242.43687±0.00000  bestvalidloss -2256.27023  last_update 4\n",
      "train: iter 681  trainloss -2240.59938  validloss -2169.68997±0.00000  bestvalidloss -2256.27023  last_update 5\n",
      "train: iter 682  trainloss -2275.39894  validloss -2186.02898±0.00000  bestvalidloss -2256.27023  last_update 6\n",
      "train: iter 683  trainloss -2272.91894  validloss -2239.29099±0.00000  bestvalidloss -2256.27023  last_update 7\n",
      "train: iter 684  trainloss -2264.77253  validloss -2223.00332±0.00000  bestvalidloss -2256.27023  last_update 8\n",
      "train: iter 685  trainloss -2243.88307  validloss -2227.41707±0.00000  bestvalidloss -2256.27023  last_update 9\n",
      "train: iter 686  trainloss -2292.28806  validloss -2229.82798±0.00000  bestvalidloss -2256.27023  last_update 10\n",
      "train: iter 687  trainloss -2281.25837  validloss -2230.05357±0.00000  bestvalidloss -2256.27023  last_update 11\n",
      "train: iter 688  trainloss -2281.61542  validloss -2232.23799±0.00000  bestvalidloss -2256.27023  last_update 12\n",
      "train: iter 689  trainloss -2285.65977  validloss -2246.75252±0.00000  bestvalidloss -2256.27023  last_update 13\n",
      "train: iter 690  trainloss -2278.91259  validloss -2230.53530±0.00000  bestvalidloss -2256.27023  last_update 14\n",
      "train: iter 691  trainloss -2272.05818  validloss -2221.98800±0.00000  bestvalidloss -2256.27023  last_update 15\n",
      "train: iter 692  trainloss -2273.71550  validloss -2204.72933±0.00000  bestvalidloss -2256.27023  last_update 16\n",
      "train: iter 693  trainloss -2263.16205  validloss -2236.88458±0.00000  bestvalidloss -2256.27023  last_update 17\n",
      "train: iter 694  trainloss -2243.61406  validloss -2193.28198±0.00000  bestvalidloss -2256.27023  last_update 18\n",
      "train: iter 695  trainloss -2287.00671  validloss -2197.54261±0.00000  bestvalidloss -2256.27023  last_update 19\n",
      "train: iter 696  trainloss -2290.31175  validloss -2239.20752±0.00000  bestvalidloss -2256.27023  last_update 20\n",
      "train: iter 697  trainloss -2284.64357  validloss -2237.83636±0.00000  bestvalidloss -2256.27023  last_update 21\n",
      "train: iter 698  trainloss -2282.14706  validloss -2233.33136±0.00000  bestvalidloss -2256.27023  last_update 22\n",
      "train: iter 699  trainloss -2277.63969  validloss -2248.82831±0.00000  bestvalidloss -2256.27023  last_update 23\n",
      "train: iter 700  trainloss -2275.13355  validloss -2242.21904±0.00000  bestvalidloss -2256.27023  last_update 24\n",
      "train: iter 701  trainloss -2263.31328  validloss -2215.39091±0.00000  bestvalidloss -2256.27023  last_update 25\n",
      "train: iter 702  trainloss -2277.43070  validloss -2209.15273±0.00000  bestvalidloss -2256.27023  last_update 26\n",
      "train: iter 703  trainloss -2258.06986  validloss -2206.43279±0.00000  bestvalidloss -2256.27023  last_update 27\n",
      "train: iter 704  trainloss -2254.75393  validloss -2228.12149±0.00000  bestvalidloss -2256.27023  last_update 28\n",
      "train: iter 705  trainloss -2151.61379  validloss -2163.10630±0.00000  bestvalidloss -2256.27023  last_update 29\n",
      "train: iter 706  trainloss -2268.50109  validloss -2196.01661±0.00000  bestvalidloss -2256.27023  last_update 30\n",
      "train: iter 707  trainloss -2270.21676  validloss -2215.10709±0.00000  bestvalidloss -2256.27023  last_update 31\n",
      "train: iter 708  trainloss -2292.87890  validloss -2247.64553±0.00000  bestvalidloss -2256.27023  last_update 32\n",
      "train: iter 709  trainloss -2268.77091  validloss -2247.40132±0.00000  bestvalidloss -2256.27023  last_update 33\n",
      "train: iter 710  trainloss -2272.80112  validloss -2155.05376±0.00000  bestvalidloss -2256.27023  last_update 34\n",
      "train: iter 711  trainloss -2277.04732  validloss -2231.70030±0.00000  bestvalidloss -2256.27023  last_update 35\n",
      "train: iter 712  trainloss -2288.08279  validloss -2181.59719±0.00000  bestvalidloss -2256.27023  last_update 36\n",
      "train: iter 713  trainloss -2284.87512  validloss -2245.58629±0.00000  bestvalidloss -2256.27023  last_update 37\n",
      "train: iter 714  trainloss -2288.45725  validloss -2261.49058±0.00000  bestvalidloss -2261.49058  last_update 0\n",
      "train: iter 715  trainloss -2291.82527  validloss -2236.77283±0.00000  bestvalidloss -2261.49058  last_update 1\n",
      "train: iter 716  trainloss -2266.42545  validloss -2246.31292±0.00000  bestvalidloss -2261.49058  last_update 2\n",
      "train: iter 717  trainloss -2279.05645  validloss -2232.49407±0.00000  bestvalidloss -2261.49058  last_update 3\n",
      "train: iter 718  trainloss -2274.33928  validloss -2239.69981±0.00000  bestvalidloss -2261.49058  last_update 4\n",
      "train: iter 719  trainloss -2286.59143  validloss -2251.05764±0.00000  bestvalidloss -2261.49058  last_update 5\n",
      "train: iter 720  trainloss -2269.38851  validloss -2242.58004±0.00000  bestvalidloss -2261.49058  last_update 6\n",
      "train: iter 721  trainloss -2275.15318  validloss -2228.79583±0.00000  bestvalidloss -2261.49058  last_update 7\n",
      "train: iter 722  trainloss -2287.82048  validloss -2255.22299±0.00000  bestvalidloss -2261.49058  last_update 8\n",
      "train: iter 723  trainloss -2284.24670  validloss -2249.80232±0.00000  bestvalidloss -2261.49058  last_update 9\n",
      "train: iter 724  trainloss -2276.67366  validloss -2257.26077±0.00000  bestvalidloss -2261.49058  last_update 10\n",
      "train: iter 725  trainloss -2274.12596  validloss -2234.70645±0.00000  bestvalidloss -2261.49058  last_update 11\n",
      "train: iter 726  trainloss -2241.80112  validloss -2143.44404±0.00000  bestvalidloss -2261.49058  last_update 12\n",
      "train: iter 727  trainloss -2279.77092  validloss -2250.34175±0.00000  bestvalidloss -2261.49058  last_update 13\n",
      "train: iter 728  trainloss -2281.34164  validloss -2245.93289±0.00000  bestvalidloss -2261.49058  last_update 14\n",
      "train: iter 729  trainloss -2238.38688  validloss -2195.48266±0.00000  bestvalidloss -2261.49058  last_update 15\n",
      "train: iter 730  trainloss -2271.84647  validloss -2165.37321±0.00000  bestvalidloss -2261.49058  last_update 16\n",
      "train: iter 731  trainloss -2282.55594  validloss -2249.72855±0.00000  bestvalidloss -2261.49058  last_update 17\n",
      "train: iter 732  trainloss -2262.04897  validloss -2250.69974±0.00000  bestvalidloss -2261.49058  last_update 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 733  trainloss -2272.83354  validloss -2225.80930±0.00000  bestvalidloss -2261.49058  last_update 19\n",
      "train: iter 734  trainloss -2276.59200  validloss -2254.94562±0.00000  bestvalidloss -2261.49058  last_update 20\n",
      "train: iter 735  trainloss -2277.78604  validloss -2247.27737±0.00000  bestvalidloss -2261.49058  last_update 21\n",
      "train: iter 736  trainloss -2280.92401  validloss -2278.76923±0.00000  bestvalidloss -2278.76923  last_update 0\n",
      "train: iter 737  trainloss -2283.98981  validloss -2241.60728±0.00000  bestvalidloss -2278.76923  last_update 1\n",
      "train: iter 738  trainloss -2291.28560  validloss -2267.65305±0.00000  bestvalidloss -2278.76923  last_update 2\n",
      "train: iter 739  trainloss -2292.11933  validloss -2253.35172±0.00000  bestvalidloss -2278.76923  last_update 3\n",
      "train: iter 740  trainloss -2277.41950  validloss -2267.52554±0.00000  bestvalidloss -2278.76923  last_update 4\n",
      "train: iter 741  trainloss -2292.99713  validloss -2270.62599±0.00000  bestvalidloss -2278.76923  last_update 5\n",
      "train: iter 742  trainloss -2276.28808  validloss -2250.19952±0.00000  bestvalidloss -2278.76923  last_update 6\n",
      "train: iter 743  trainloss -2215.44344  validloss -2121.23880±0.00000  bestvalidloss -2278.76923  last_update 7\n",
      "train: iter 744  trainloss -2287.84506  validloss -2265.61077±0.00000  bestvalidloss -2278.76923  last_update 8\n",
      "train: iter 745  trainloss -2281.73193  validloss -2256.15766±0.00000  bestvalidloss -2278.76923  last_update 9\n",
      "train: iter 746  trainloss -2256.89966  validloss -2218.89877±0.00000  bestvalidloss -2278.76923  last_update 10\n",
      "train: iter 747  trainloss -2265.21785  validloss -2219.72994±0.00000  bestvalidloss -2278.76923  last_update 11\n",
      "train: iter 748  trainloss -2259.52984  validloss -2252.47166±0.00000  bestvalidloss -2278.76923  last_update 12\n",
      "train: iter 749  trainloss -2278.59528  validloss -2252.44161±0.00000  bestvalidloss -2278.76923  last_update 13\n",
      "train: iter 750  trainloss -2237.93809  validloss -2242.38810±0.00000  bestvalidloss -2278.76923  last_update 14\n",
      "train: iter 751  trainloss -2248.46467  validloss -2204.26671±0.00000  bestvalidloss -2278.76923  last_update 15\n",
      "train: iter 752  trainloss -2248.75018  validloss -2236.67726±0.00000  bestvalidloss -2278.76923  last_update 16\n",
      "train: iter 753  trainloss -2287.09660  validloss -2260.26086±0.00000  bestvalidloss -2278.76923  last_update 17\n",
      "train: iter 754  trainloss -2295.56882  validloss -2252.38403±0.00000  bestvalidloss -2278.76923  last_update 18\n",
      "train: iter 755  trainloss -2286.34575  validloss -2278.65005±0.00000  bestvalidloss -2278.76923  last_update 19\n",
      "train: iter 756  trainloss -2293.08459  validloss -2261.67494±0.00000  bestvalidloss -2278.76923  last_update 20\n",
      "train: iter 757  trainloss -2260.29743  validloss -2224.09855±0.00000  bestvalidloss -2278.76923  last_update 21\n",
      "train: iter 758  trainloss -2286.08916  validloss -2229.90806±0.00000  bestvalidloss -2278.76923  last_update 22\n",
      "train: iter 759  trainloss -2285.61543  validloss -2268.96490±0.00000  bestvalidloss -2278.76923  last_update 23\n",
      "train: iter 760  trainloss -2269.40306  validloss -2219.90773±0.00000  bestvalidloss -2278.76923  last_update 24\n",
      "train: iter 761  trainloss -2291.72115  validloss -2252.55496±0.00000  bestvalidloss -2278.76923  last_update 25\n",
      "train: iter 762  trainloss -2280.13424  validloss -2243.02911±0.00000  bestvalidloss -2278.76923  last_update 26\n",
      "train: iter 763  trainloss -2232.41433  validloss -2257.16591±0.00000  bestvalidloss -2278.76923  last_update 27\n",
      "train: iter 764  trainloss -2275.35962  validloss -2147.04548±0.00000  bestvalidloss -2278.76923  last_update 28\n",
      "train: iter 765  trainloss -2282.71985  validloss -2261.94463±0.00000  bestvalidloss -2278.76923  last_update 29\n",
      "train: iter 766  trainloss -2266.36665  validloss -2176.05107±0.00000  bestvalidloss -2278.76923  last_update 30\n",
      "train: iter 767  trainloss -2288.55670  validloss -2270.98844±0.00000  bestvalidloss -2278.76923  last_update 31\n",
      "train: iter 768  trainloss -2281.28805  validloss -2219.57411±0.00000  bestvalidloss -2278.76923  last_update 32\n",
      "train: iter 769  trainloss -2241.38124  validloss -2260.82081±0.00000  bestvalidloss -2278.76923  last_update 33\n",
      "train: iter 770  trainloss -2275.46288  validloss -2123.50727±0.00000  bestvalidloss -2278.76923  last_update 34\n",
      "train: iter 771  trainloss -2279.92856  validloss -2257.63079±0.00000  bestvalidloss -2278.76923  last_update 35\n",
      "train: iter 772  trainloss -2289.02867  validloss -2258.25645±0.00000  bestvalidloss -2278.76923  last_update 36\n",
      "train: iter 773  trainloss -2272.40217  validloss -2246.83013±0.00000  bestvalidloss -2278.76923  last_update 37\n",
      "train: iter 774  trainloss -2267.47876  validloss -2212.52371±0.00000  bestvalidloss -2278.76923  last_update 38\n",
      "train: iter 775  trainloss -2285.85768  validloss -2244.15137±0.00000  bestvalidloss -2278.76923  last_update 39\n",
      "train: iter 776  trainloss -2253.60607  validloss -2208.55995±0.00000  bestvalidloss -2278.76923  last_update 40\n",
      "train: iter 777  trainloss -2279.72159  validloss -2250.76707±0.00000  bestvalidloss -2278.76923  last_update 41\n",
      "train: iter 778  trainloss -2267.68565  validloss -2262.38279±0.00000  bestvalidloss -2278.76923  last_update 42\n",
      "train: iter 779  trainloss -2263.28154  validloss -2247.07407±0.00000  bestvalidloss -2278.76923  last_update 43\n",
      "train: iter 780  trainloss -2287.86402  validloss -2269.77943±0.00000  bestvalidloss -2278.76923  last_update 44\n",
      "train: iter 781  trainloss -2226.34186  validloss -2141.10328±0.00000  bestvalidloss -2278.76923  last_update 45\n",
      "train: iter 782  trainloss -2261.44651  validloss -2240.34471±0.00000  bestvalidloss -2278.76923  last_update 46\n",
      "train: iter 783  trainloss -2277.62208  validloss -2260.11663±0.00000  bestvalidloss -2278.76923  last_update 47\n",
      "train: iter 784  trainloss -2287.39919  validloss -2258.75002±0.00000  bestvalidloss -2278.76923  last_update 48\n",
      "train: iter 785  trainloss -2263.44988  validloss -2262.61140±0.00000  bestvalidloss -2278.76923  last_update 49\n",
      "train: iter 786  trainloss -2294.00088  validloss -2268.35690±0.00000  bestvalidloss -2278.76923  last_update 50\n",
      "train: iter 787  trainloss -2274.34694  validloss -2258.61668±0.00000  bestvalidloss -2278.76923  last_update 51\n",
      "train: iter 788  trainloss -2221.50235  validloss -2237.70739±0.00000  bestvalidloss -2278.76923  last_update 52\n",
      "train: iter 789  trainloss -2250.30653  validloss -2082.54418±0.00000  bestvalidloss -2278.76923  last_update 53\n",
      "train: iter 790  trainloss -2280.01595  validloss -2237.19623±0.00000  bestvalidloss -2278.76923  last_update 54\n",
      "train: iter 791  trainloss -2293.72240  validloss -2236.19681±0.00000  bestvalidloss -2278.76923  last_update 55\n",
      "train: iter 792  trainloss -2291.35116  validloss -2250.32192±0.00000  bestvalidloss -2278.76923  last_update 56\n",
      "train: iter 793  trainloss -2291.45431  validloss -2267.42287±0.00000  bestvalidloss -2278.76923  last_update 57\n",
      "train: iter 794  trainloss -2284.96300  validloss -2250.90386±0.00000  bestvalidloss -2278.76923  last_update 58\n",
      "train: iter 795  trainloss -2286.59865  validloss -2211.52936±0.00000  bestvalidloss -2278.76923  last_update 59\n",
      "train: iter 796  trainloss -2285.16902  validloss -2258.54637±0.00000  bestvalidloss -2278.76923  last_update 60\n",
      "train: iter 797  trainloss -2285.77524  validloss -2266.68389±0.00000  bestvalidloss -2278.76923  last_update 61\n",
      "train: iter 798  trainloss -2285.44330  validloss -2236.21505±0.00000  bestvalidloss -2278.76923  last_update 62\n",
      "train: iter 799  trainloss -2282.74764  validloss -2258.59572±0.00000  bestvalidloss -2278.76923  last_update 63\n",
      "train: iter 800  trainloss -2292.45815  validloss -2262.27846±0.00000  bestvalidloss -2278.76923  last_update 64\n",
      "train: iter 801  trainloss -2296.10597  validloss -2269.23123±0.00000  bestvalidloss -2278.76923  last_update 65\n",
      "train: iter 802  trainloss -2289.05474  validloss -2275.54514±0.00000  bestvalidloss -2278.76923  last_update 66\n",
      "train: iter 803  trainloss -2287.15051  validloss -2216.61613±0.00000  bestvalidloss -2278.76923  last_update 67\n",
      "train: iter 804  trainloss -2264.59073  validloss -2266.77627±0.00000  bestvalidloss -2278.76923  last_update 68\n",
      "train: iter 805  trainloss -2083.11953  validloss -2206.13243±0.00000  bestvalidloss -2278.76923  last_update 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 806  trainloss -2242.32755  validloss -2159.67132±0.00000  bestvalidloss -2278.76923  last_update 70\n",
      "train: iter 807  trainloss -2280.90089  validloss -2237.43368±0.00000  bestvalidloss -2278.76923  last_update 71\n",
      "train: iter 808  trainloss -2282.67545  validloss -2271.63688±0.00000  bestvalidloss -2278.76923  last_update 72\n",
      "train: iter 809  trainloss -2286.85550  validloss -2283.14997±0.00000  bestvalidloss -2283.14997  last_update 0\n",
      "train: iter 810  trainloss -2287.31069  validloss -2268.77228±0.00000  bestvalidloss -2283.14997  last_update 1\n",
      "train: iter 811  trainloss -2274.75796  validloss -2242.69706±0.00000  bestvalidloss -2283.14997  last_update 2\n",
      "train: iter 812  trainloss -2283.49573  validloss -2263.21462±0.00000  bestvalidloss -2283.14997  last_update 3\n",
      "train: iter 813  trainloss -2268.30170  validloss -2266.59343±0.00000  bestvalidloss -2283.14997  last_update 4\n",
      "train: iter 814  trainloss -2265.69327  validloss -2223.36226±0.00000  bestvalidloss -2283.14997  last_update 5\n",
      "train: iter 815  trainloss -2280.19721  validloss -2252.83282±0.00000  bestvalidloss -2283.14997  last_update 6\n",
      "train: iter 816  trainloss -2240.32535  validloss -2236.08959±0.00000  bestvalidloss -2283.14997  last_update 7\n",
      "train: iter 817  trainloss -2273.92494  validloss -2171.43424±0.00000  bestvalidloss -2283.14997  last_update 8\n",
      "train: iter 818  trainloss -2279.27218  validloss -2275.57906±0.00000  bestvalidloss -2283.14997  last_update 9\n",
      "train: iter 819  trainloss -2292.79995  validloss -2258.53229±0.00000  bestvalidloss -2283.14997  last_update 10\n",
      "train: iter 820  trainloss -2273.06665  validloss -2242.75187±0.00000  bestvalidloss -2283.14997  last_update 11\n",
      "train: iter 821  trainloss -2259.16548  validloss -2278.86917±0.00000  bestvalidloss -2283.14997  last_update 12\n",
      "train: iter 822  trainloss -2236.70965  validloss -2170.80479±0.00000  bestvalidloss -2283.14997  last_update 13\n",
      "train: iter 823  trainloss -2261.27920  validloss -2225.16463±0.00000  bestvalidloss -2283.14997  last_update 14\n",
      "train: iter 824  trainloss -2286.35591  validloss -2257.62791±0.00000  bestvalidloss -2283.14997  last_update 15\n",
      "train: iter 825  trainloss -2294.50336  validloss -2266.92938±0.00000  bestvalidloss -2283.14997  last_update 16\n",
      "train: iter 826  trainloss -2300.13970  validloss -2278.01669±0.00000  bestvalidloss -2283.14997  last_update 17\n",
      "train: iter 827  trainloss -2284.43046  validloss -2206.62832±0.00000  bestvalidloss -2283.14997  last_update 18\n",
      "train: iter 828  trainloss -2290.34156  validloss -2248.34458±0.00000  bestvalidloss -2283.14997  last_update 19\n",
      "train: iter 829  trainloss -2294.50531  validloss -2271.18658±0.00000  bestvalidloss -2283.14997  last_update 20\n",
      "train: iter 830  trainloss -2300.97201  validloss -2277.48067±0.00000  bestvalidloss -2283.14997  last_update 21\n",
      "train: iter 831  trainloss -2297.91841  validloss -2259.08721±0.00000  bestvalidloss -2283.14997  last_update 22\n",
      "train: iter 832  trainloss -2281.19555  validloss -2279.75865±0.00000  bestvalidloss -2283.14997  last_update 23\n",
      "train: iter 833  trainloss -2285.42930  validloss -2252.78073±0.00000  bestvalidloss -2283.14997  last_update 24\n",
      "train: iter 834  trainloss -2280.02053  validloss -2268.20912±0.00000  bestvalidloss -2283.14997  last_update 25\n",
      "train: iter 835  trainloss -2253.26103  validloss -2256.62776±0.00000  bestvalidloss -2283.14997  last_update 26\n",
      "train: iter 836  trainloss -2288.15928  validloss -2240.08916±0.00000  bestvalidloss -2283.14997  last_update 27\n",
      "train: iter 837  trainloss -2288.02742  validloss -2270.75170±0.00000  bestvalidloss -2283.14997  last_update 28\n",
      "train: iter 838  trainloss -2251.13356  validloss -2270.85191±0.00000  bestvalidloss -2283.14997  last_update 29\n",
      "train: iter 839  trainloss -2243.83039  validloss -2236.67303±0.00000  bestvalidloss -2283.14997  last_update 30\n",
      "train: iter 840  trainloss -2277.70562  validloss -2260.33396±0.00000  bestvalidloss -2283.14997  last_update 31\n",
      "train: iter 841  trainloss -2274.94883  validloss -2240.39418±0.00000  bestvalidloss -2283.14997  last_update 32\n",
      "train: iter 842  trainloss -2291.04865  validloss -2229.77577±0.00000  bestvalidloss -2283.14997  last_update 33\n",
      "train: iter 843  trainloss -2288.54124  validloss -2257.93687±0.00000  bestvalidloss -2283.14997  last_update 34\n",
      "train: iter 844  trainloss -2284.78613  validloss -2254.85765±0.00000  bestvalidloss -2283.14997  last_update 35\n",
      "train: iter 845  trainloss -2280.41372  validloss -2282.27936±0.00000  bestvalidloss -2283.14997  last_update 36\n",
      "train: iter 846  trainloss -2287.57239  validloss -2266.48816±0.00000  bestvalidloss -2283.14997  last_update 37\n",
      "train: iter 847  trainloss -2290.34593  validloss -2265.11320±0.00000  bestvalidloss -2283.14997  last_update 38\n",
      "train: iter 848  trainloss -2290.87733  validloss -2268.93253±0.00000  bestvalidloss -2283.14997  last_update 39\n",
      "train: iter 849  trainloss -2289.62361  validloss -2275.16353±0.00000  bestvalidloss -2283.14997  last_update 40\n",
      "train: iter 850  trainloss -2280.67071  validloss -2288.75515±0.00000  bestvalidloss -2288.75515  last_update 0\n",
      "train: iter 851  trainloss -2264.22625  validloss -2272.52073±0.00000  bestvalidloss -2288.75515  last_update 1\n",
      "train: iter 852  trainloss -2233.53633  validloss -2175.03942±0.00000  bestvalidloss -2288.75515  last_update 2\n",
      "train: iter 853  trainloss -2284.26916  validloss -2244.81099±0.00000  bestvalidloss -2288.75515  last_update 3\n",
      "train: iter 854  trainloss -2300.36100  validloss -2287.78911±0.00000  bestvalidloss -2288.75515  last_update 4\n",
      "train: iter 855  trainloss -2277.25322  validloss -2273.00951±0.00000  bestvalidloss -2288.75515  last_update 5\n",
      "train: iter 856  trainloss -2296.69191  validloss -2248.49318±0.00000  bestvalidloss -2288.75515  last_update 6\n",
      "train: iter 857  trainloss -2267.80551  validloss -2260.07510±0.00000  bestvalidloss -2288.75515  last_update 7\n",
      "train: iter 858  trainloss -2278.51766  validloss -2278.00762±0.00000  bestvalidloss -2288.75515  last_update 8\n",
      "train: iter 859  trainloss -2277.43448  validloss -2275.61991±0.00000  bestvalidloss -2288.75515  last_update 9\n",
      "train: iter 860  trainloss -2269.95607  validloss -2264.68839±0.00000  bestvalidloss -2288.75515  last_update 10\n",
      "train: iter 861  trainloss -2295.55227  validloss -2271.21866±0.00000  bestvalidloss -2288.75515  last_update 11\n",
      "train: iter 862  trainloss -2280.80942  validloss -2257.88209±0.00000  bestvalidloss -2288.75515  last_update 12\n",
      "train: iter 863  trainloss -2285.06371  validloss -2248.59836±0.00000  bestvalidloss -2288.75515  last_update 13\n",
      "train: iter 864  trainloss -2287.71911  validloss -2281.28524±0.00000  bestvalidloss -2288.75515  last_update 14\n",
      "train: iter 865  trainloss -2283.89271  validloss -2276.26540±0.00000  bestvalidloss -2288.75515  last_update 15\n",
      "train: iter 866  trainloss -2263.10015  validloss -2239.58600±0.00000  bestvalidloss -2288.75515  last_update 16\n",
      "train: iter 867  trainloss -2206.60040  validloss -2093.11442±0.00000  bestvalidloss -2288.75515  last_update 17\n",
      "train: iter 868  trainloss -2286.62085  validloss -2256.88447±0.00000  bestvalidloss -2288.75515  last_update 18\n",
      "train: iter 869  trainloss -2288.70035  validloss -2281.09603±0.00000  bestvalidloss -2288.75515  last_update 19\n",
      "train: iter 870  trainloss -2275.38436  validloss -2225.47257±0.00000  bestvalidloss -2288.75515  last_update 20\n",
      "train: iter 871  trainloss -2292.49173  validloss -2272.23059±0.00000  bestvalidloss -2288.75515  last_update 21\n",
      "train: iter 872  trainloss -2294.42948  validloss -2285.63660±0.00000  bestvalidloss -2288.75515  last_update 22\n",
      "train: iter 873  trainloss -2281.11444  validloss -2268.85993±0.00000  bestvalidloss -2288.75515  last_update 23\n",
      "train: iter 874  trainloss -2290.22155  validloss -2277.59974±0.00000  bestvalidloss -2288.75515  last_update 24\n",
      "train: iter 875  trainloss -2295.29388  validloss -2255.44548±0.00000  bestvalidloss -2288.75515  last_update 25\n",
      "train: iter 876  trainloss -2290.57690  validloss -2251.41763±0.00000  bestvalidloss -2288.75515  last_update 26\n",
      "train: iter 877  trainloss -2276.11429  validloss -2278.23461±0.00000  bestvalidloss -2288.75515  last_update 27\n",
      "train: iter 878  trainloss -2278.87235  validloss -2283.43163±0.00000  bestvalidloss -2288.75515  last_update 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 879  trainloss -2291.78596  validloss -2276.42989±0.00000  bestvalidloss -2288.75515  last_update 29\n",
      "train: iter 880  trainloss -2295.95212  validloss -2279.45425±0.00000  bestvalidloss -2288.75515  last_update 30\n",
      "train: iter 881  trainloss -2289.78672  validloss -2294.19671±0.00000  bestvalidloss -2294.19671  last_update 0\n",
      "train: iter 882  trainloss -2270.70456  validloss -2264.43427±0.00000  bestvalidloss -2294.19671  last_update 1\n",
      "train: iter 883  trainloss -2274.66067  validloss -2214.69359±0.00000  bestvalidloss -2294.19671  last_update 2\n",
      "train: iter 884  trainloss -2212.22501  validloss -2248.44037±0.00000  bestvalidloss -2294.19671  last_update 3\n",
      "train: iter 885  trainloss -2261.17176  validloss -2193.63314±0.00000  bestvalidloss -2294.19671  last_update 4\n",
      "train: iter 886  trainloss -2283.90805  validloss -2254.26271±0.00000  bestvalidloss -2294.19671  last_update 5\n",
      "train: iter 887  trainloss -2288.79225  validloss -2301.13615±0.00000  bestvalidloss -2301.13615  last_update 0\n",
      "train: iter 888  trainloss -2284.72552  validloss -2244.60260±0.00000  bestvalidloss -2301.13615  last_update 1\n",
      "train: iter 889  trainloss -2296.59865  validloss -2275.20615±0.00000  bestvalidloss -2301.13615  last_update 2\n",
      "train: iter 890  trainloss -2267.35081  validloss -2259.66180±0.00000  bestvalidloss -2301.13615  last_update 3\n",
      "train: iter 891  trainloss -2261.63061  validloss -2252.70981±0.00000  bestvalidloss -2301.13615  last_update 4\n",
      "train: iter 892  trainloss -2272.25024  validloss -2198.11371±0.00000  bestvalidloss -2301.13615  last_update 5\n",
      "train: iter 893  trainloss -2283.56667  validloss -2238.87407±0.00000  bestvalidloss -2301.13615  last_update 6\n",
      "train: iter 894  trainloss -2294.76186  validloss -2276.59406±0.00000  bestvalidloss -2301.13615  last_update 7\n",
      "train: iter 895  trainloss -2299.42229  validloss -2287.38784±0.00000  bestvalidloss -2301.13615  last_update 8\n",
      "train: iter 896  trainloss -2284.85975  validloss -2288.15544±0.00000  bestvalidloss -2301.13615  last_update 9\n",
      "train: iter 897  trainloss -2186.25843  validloss -2286.18243±0.00000  bestvalidloss -2301.13615  last_update 10\n",
      "train: iter 898  trainloss -2278.03208  validloss -2260.65615±0.00000  bestvalidloss -2301.13615  last_update 11\n",
      "train: iter 899  trainloss -2295.37370  validloss -2280.15604±0.00000  bestvalidloss -2301.13615  last_update 12\n",
      "train: iter 900  trainloss -2299.21048  validloss -2290.61388±0.00000  bestvalidloss -2301.13615  last_update 13\n",
      "train: iter 901  trainloss -2299.12037  validloss -2284.87813±0.00000  bestvalidloss -2301.13615  last_update 14\n",
      "train: iter 902  trainloss -2293.83047  validloss -2300.64706±0.00000  bestvalidloss -2301.13615  last_update 15\n",
      "train: iter 903  trainloss -2289.88184  validloss -2250.03411±0.00000  bestvalidloss -2301.13615  last_update 16\n",
      "train: iter 904  trainloss -2289.79543  validloss -2264.97040±0.00000  bestvalidloss -2301.13615  last_update 17\n",
      "train: iter 905  trainloss -2299.23914  validloss -2294.52576±0.00000  bestvalidloss -2301.13615  last_update 18\n",
      "train: iter 906  trainloss -2295.59674  validloss -2278.07839±0.00000  bestvalidloss -2301.13615  last_update 19\n",
      "train: iter 907  trainloss -2294.63129  validloss -2277.94207±0.00000  bestvalidloss -2301.13615  last_update 20\n",
      "train: iter 908  trainloss -2296.08998  validloss -2281.48726±0.00000  bestvalidloss -2301.13615  last_update 21\n",
      "train: iter 909  trainloss -2278.15629  validloss -2271.41707±0.00000  bestvalidloss -2301.13615  last_update 22\n",
      "train: iter 910  trainloss -2287.86283  validloss -2281.08299±0.00000  bestvalidloss -2301.13615  last_update 23\n",
      "train: iter 911  trainloss -2283.90274  validloss -2223.92024±0.00000  bestvalidloss -2301.13615  last_update 24\n",
      "train: iter 912  trainloss -2241.27478  validloss -2256.35429±0.00000  bestvalidloss -2301.13615  last_update 25\n",
      "train: iter 913  trainloss -2296.43945  validloss -2280.07808±0.00000  bestvalidloss -2301.13615  last_update 26\n",
      "train: iter 914  trainloss -2298.51032  validloss -2287.67249±0.00000  bestvalidloss -2301.13615  last_update 27\n",
      "train: iter 915  trainloss -2279.38255  validloss -2286.76540±0.00000  bestvalidloss -2301.13615  last_update 28\n",
      "train: iter 916  trainloss -2296.08846  validloss -2273.70194±0.00000  bestvalidloss -2301.13615  last_update 29\n",
      "train: iter 917  trainloss -2294.12774  validloss -2276.22194±0.00000  bestvalidloss -2301.13615  last_update 30\n",
      "train: iter 918  trainloss -2285.74409  validloss -2281.41207±0.00000  bestvalidloss -2301.13615  last_update 31\n",
      "train: iter 919  trainloss -2252.68922  validloss -2267.73727±0.00000  bestvalidloss -2301.13615  last_update 32\n",
      "train: iter 920  trainloss -2273.57649  validloss -2248.88151±0.00000  bestvalidloss -2301.13615  last_update 33\n",
      "train: iter 921  trainloss -2268.10194  validloss -2285.91216±0.00000  bestvalidloss -2301.13615  last_update 34\n",
      "train: iter 922  trainloss -2256.33933  validloss -2131.06949±0.00000  bestvalidloss -2301.13615  last_update 35\n",
      "train: iter 923  trainloss -2275.28009  validloss -2265.70427±0.00000  bestvalidloss -2301.13615  last_update 36\n",
      "train: iter 924  trainloss -2292.64164  validloss -2282.93418±0.00000  bestvalidloss -2301.13615  last_update 37\n",
      "train: iter 925  trainloss -2285.32991  validloss -2278.76925±0.00000  bestvalidloss -2301.13615  last_update 38\n",
      "train: iter 926  trainloss -2291.12643  validloss -2287.54963±0.00000  bestvalidloss -2301.13615  last_update 39\n",
      "train: iter 927  trainloss -2287.50803  validloss -2290.82394±0.00000  bestvalidloss -2301.13615  last_update 40\n",
      "train: iter 928  trainloss -2289.38645  validloss -2258.50533±0.00000  bestvalidloss -2301.13615  last_update 41\n",
      "train: iter 929  trainloss -2295.76962  validloss -2297.52466±0.00000  bestvalidloss -2301.13615  last_update 42\n",
      "train: iter 930  trainloss -2270.27109  validloss -2295.93890±0.00000  bestvalidloss -2301.13615  last_update 43\n",
      "train: iter 931  trainloss -2280.23711  validloss -2197.16907±0.00000  bestvalidloss -2301.13615  last_update 44\n",
      "train: iter 932  trainloss -2294.04333  validloss -2264.06500±0.00000  bestvalidloss -2301.13615  last_update 45\n",
      "train: iter 933  trainloss -2285.08985  validloss -2286.56243±0.00000  bestvalidloss -2301.13615  last_update 46\n",
      "train: iter 934  trainloss -2295.72469  validloss -2253.75005±0.00000  bestvalidloss -2301.13615  last_update 47\n",
      "train: iter 935  trainloss -2286.59022  validloss -2273.40322±0.00000  bestvalidloss -2301.13615  last_update 48\n",
      "train: iter 936  trainloss -2289.24499  validloss -2288.73261±0.00000  bestvalidloss -2301.13615  last_update 49\n",
      "train: iter 937  trainloss -2286.26441  validloss -2272.60204±0.00000  bestvalidloss -2301.13615  last_update 50\n",
      "train: iter 938  trainloss -2279.01358  validloss -2294.41896±0.00000  bestvalidloss -2301.13615  last_update 51\n",
      "train: iter 939  trainloss -2266.88420  validloss -2225.24722±0.00000  bestvalidloss -2301.13615  last_update 52\n",
      "train: iter 940  trainloss -2274.56647  validloss -2274.17404±0.00000  bestvalidloss -2301.13615  last_update 53\n",
      "train: iter 941  trainloss -2292.78308  validloss -2231.14769±0.00000  bestvalidloss -2301.13615  last_update 54\n",
      "train: iter 942  trainloss -2284.58858  validloss -2266.02731±0.00000  bestvalidloss -2301.13615  last_update 55\n",
      "train: iter 943  trainloss -2287.61035  validloss -2295.20715±0.00000  bestvalidloss -2301.13615  last_update 56\n",
      "train: iter 944  trainloss -2305.73968  validloss -2281.15153±0.00000  bestvalidloss -2301.13615  last_update 57\n",
      "train: iter 945  trainloss -2293.97872  validloss -2301.22559±0.00000  bestvalidloss -2301.22559  last_update 0\n",
      "train: iter 946  trainloss -2292.34310  validloss -2275.88331±0.00000  bestvalidloss -2301.22559  last_update 1\n",
      "train: iter 947  trainloss -2293.49833  validloss -2265.54266±0.00000  bestvalidloss -2301.22559  last_update 2\n",
      "train: iter 948  trainloss -2285.21268  validloss -2259.83052±0.00000  bestvalidloss -2301.22559  last_update 3\n",
      "train: iter 949  trainloss -2274.38405  validloss -2237.81702±0.00000  bestvalidloss -2301.22559  last_update 4\n",
      "train: iter 950  trainloss -2289.77187  validloss -2270.34160±0.00000  bestvalidloss -2301.22559  last_update 5\n",
      "train: iter 951  trainloss -2298.02605  validloss -2275.28362±0.00000  bestvalidloss -2301.22559  last_update 6\n",
      "train: iter 952  trainloss -2287.57330  validloss -2247.97610±0.00000  bestvalidloss -2301.22559  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 953  trainloss -2275.62125  validloss -2250.20779±0.00000  bestvalidloss -2301.22559  last_update 8\n",
      "train: iter 954  trainloss -2280.25506  validloss -2199.08014±0.00000  bestvalidloss -2301.22559  last_update 9\n",
      "train: iter 955  trainloss -2282.88439  validloss -2284.68553±0.00000  bestvalidloss -2301.22559  last_update 10\n",
      "train: iter 956  trainloss -2294.79781  validloss -2294.97657±0.00000  bestvalidloss -2301.22559  last_update 11\n",
      "train: iter 957  trainloss -2272.96940  validloss -2268.17488±0.00000  bestvalidloss -2301.22559  last_update 12\n",
      "train: iter 958  trainloss -2267.56115  validloss -2189.22027±0.00000  bestvalidloss -2301.22559  last_update 13\n",
      "train: iter 959  trainloss -2297.02262  validloss -2223.27000±0.00000  bestvalidloss -2301.22559  last_update 14\n",
      "train: iter 960  trainloss -2289.17492  validloss -2274.35912±0.00000  bestvalidloss -2301.22559  last_update 15\n",
      "train: iter 961  trainloss -2284.97296  validloss -2267.53141±0.00000  bestvalidloss -2301.22559  last_update 16\n",
      "train: iter 962  trainloss -2301.53815  validloss -2268.53146±0.00000  bestvalidloss -2301.22559  last_update 17\n",
      "train: iter 963  trainloss -2281.03047  validloss -2301.48878±0.00000  bestvalidloss -2301.48878  last_update 0\n",
      "train: iter 964  trainloss -2292.43079  validloss -2236.20499±0.00000  bestvalidloss -2301.48878  last_update 1\n",
      "train: iter 965  trainloss -2288.90429  validloss -2284.86642±0.00000  bestvalidloss -2301.48878  last_update 2\n",
      "train: iter 966  trainloss -2296.91592  validloss -2283.82043±0.00000  bestvalidloss -2301.48878  last_update 3\n",
      "train: iter 967  trainloss -2301.99501  validloss -2278.63499±0.00000  bestvalidloss -2301.48878  last_update 4\n",
      "train: iter 968  trainloss -2298.19426  validloss -2294.68507±0.00000  bestvalidloss -2301.48878  last_update 5\n",
      "train: iter 969  trainloss -2297.11433  validloss -2298.89160±0.00000  bestvalidloss -2301.48878  last_update 6\n",
      "train: iter 970  trainloss -2292.69386  validloss -2285.72404±0.00000  bestvalidloss -2301.48878  last_update 7\n",
      "train: iter 971  trainloss -2288.16722  validloss -2256.31553±0.00000  bestvalidloss -2301.48878  last_update 8\n",
      "train: iter 972  trainloss -2285.36668  validloss -2285.04779±0.00000  bestvalidloss -2301.48878  last_update 9\n",
      "train: iter 973  trainloss -2263.16590  validloss -2248.88830±0.00000  bestvalidloss -2301.48878  last_update 10\n",
      "train: iter 974  trainloss -2291.03530  validloss -2280.74695±0.00000  bestvalidloss -2301.48878  last_update 11\n",
      "train: iter 975  trainloss -2265.08002  validloss -2265.04467±0.00000  bestvalidloss -2301.48878  last_update 12\n",
      "train: iter 976  trainloss -2265.24697  validloss -2254.72319±0.00000  bestvalidloss -2301.48878  last_update 13\n",
      "train: iter 977  trainloss -2237.68491  validloss -2158.86777±0.00000  bestvalidloss -2301.48878  last_update 14\n",
      "train: iter 978  trainloss -2294.75475  validloss -2275.72771±0.00000  bestvalidloss -2301.48878  last_update 15\n",
      "train: iter 979  trainloss -2294.66736  validloss -2273.37387±0.00000  bestvalidloss -2301.48878  last_update 16\n",
      "train: iter 980  trainloss -2305.40425  validloss -2295.66728±0.00000  bestvalidloss -2301.48878  last_update 17\n",
      "train: iter 981  trainloss -2296.83272  validloss -2300.85410±0.00000  bestvalidloss -2301.48878  last_update 18\n",
      "train: iter 982  trainloss -2301.07722  validloss -2292.76003±0.00000  bestvalidloss -2301.48878  last_update 19\n",
      "train: iter 983  trainloss -2283.75255  validloss -2273.75618±0.00000  bestvalidloss -2301.48878  last_update 20\n",
      "train: iter 984  trainloss -2287.55603  validloss -2282.07565±0.00000  bestvalidloss -2301.48878  last_update 21\n",
      "train: iter 985  trainloss -2270.63471  validloss -2253.07565±0.00000  bestvalidloss -2301.48878  last_update 22\n",
      "train: iter 986  trainloss -2295.74146  validloss -2278.55219±0.00000  bestvalidloss -2301.48878  last_update 23\n",
      "train: iter 987  trainloss -2302.68383  validloss -2281.60917±0.00000  bestvalidloss -2301.48878  last_update 24\n",
      "train: iter 988  trainloss -2298.77719  validloss -2263.96546±0.00000  bestvalidloss -2301.48878  last_update 25\n",
      "train: iter 989  trainloss -2301.12627  validloss -2287.11819±0.00000  bestvalidloss -2301.48878  last_update 26\n",
      "train: iter 990  trainloss -2304.41044  validloss -2289.53003±0.00000  bestvalidloss -2301.48878  last_update 27\n",
      "train: iter 991  trainloss -2287.08183  validloss -2272.47663±0.00000  bestvalidloss -2301.48878  last_update 28\n",
      "train: iter 992  trainloss -2275.94700  validloss -2281.50934±0.00000  bestvalidloss -2301.48878  last_update 29\n",
      "train: iter 993  trainloss -2295.93904  validloss -2271.67485±0.00000  bestvalidloss -2301.48878  last_update 30\n",
      "train: iter 994  trainloss -2288.37759  validloss -2246.73989±0.00000  bestvalidloss -2301.48878  last_update 31\n",
      "train: iter 995  trainloss -2271.88427  validloss -2277.95617±0.00000  bestvalidloss -2301.48878  last_update 32\n",
      "train: iter 996  trainloss -2290.30319  validloss -2271.55765±0.00000  bestvalidloss -2301.48878  last_update 33\n",
      "train: iter 997  trainloss -2293.44309  validloss -2265.24208±0.00000  bestvalidloss -2301.48878  last_update 34\n",
      "train: iter 998  trainloss -2302.38378  validloss -2287.02659±0.00000  bestvalidloss -2301.48878  last_update 35\n",
      "train: iter 999  trainloss -2307.61525  validloss -2291.48892±0.00000  bestvalidloss -2301.48878  last_update 36\n",
      "train: iter 1000  trainloss -2303.33544  validloss -2281.14851±0.00000  bestvalidloss -2301.48878  last_update 37\n",
      "train: iter 1001  trainloss -2296.25756  validloss -2286.97587±0.00000  bestvalidloss -2301.48878  last_update 38\n",
      "train: iter 1002  trainloss -2300.65992  validloss -2294.39236±0.00000  bestvalidloss -2301.48878  last_update 39\n",
      "train: iter 1003  trainloss -2292.64724  validloss -2277.56262±0.00000  bestvalidloss -2301.48878  last_update 40\n",
      "train: iter 1004  trainloss -2227.48507  validloss -2283.81177±0.00000  bestvalidloss -2301.48878  last_update 41\n",
      "train: iter 1005  trainloss -2236.73764  validloss -2168.36418±0.00000  bestvalidloss -2301.48878  last_update 42\n",
      "train: iter 1006  trainloss -2283.79186  validloss -2284.47906±0.00000  bestvalidloss -2301.48878  last_update 43\n",
      "train: iter 1007  trainloss -2295.57700  validloss -2289.29266±0.00000  bestvalidloss -2301.48878  last_update 44\n",
      "train: iter 1008  trainloss -2287.45888  validloss -2269.68991±0.00000  bestvalidloss -2301.48878  last_update 45\n",
      "train: iter 1009  trainloss -2285.04095  validloss -2285.07192±0.00000  bestvalidloss -2301.48878  last_update 46\n",
      "train: iter 1010  trainloss -2307.39964  validloss -2273.87275±0.00000  bestvalidloss -2301.48878  last_update 47\n",
      "train: iter 1011  trainloss -2309.27687  validloss -2291.26202±0.00000  bestvalidloss -2301.48878  last_update 48\n",
      "train: iter 1012  trainloss -2294.45846  validloss -2292.22712±0.00000  bestvalidloss -2301.48878  last_update 49\n",
      "train: iter 1013  trainloss -2293.72575  validloss -2300.22320±0.00000  bestvalidloss -2301.48878  last_update 50\n",
      "train: iter 1014  trainloss -2297.77223  validloss -2245.00366±0.00000  bestvalidloss -2301.48878  last_update 51\n",
      "train: iter 1015  trainloss -2305.16748  validloss -2301.50415±0.00000  bestvalidloss -2301.50415  last_update 0\n",
      "train: iter 1016  trainloss -2297.23634  validloss -2282.68359±0.00000  bestvalidloss -2301.50415  last_update 1\n",
      "train: iter 1017  trainloss -2275.03049  validloss -2289.44529±0.00000  bestvalidloss -2301.50415  last_update 2\n",
      "train: iter 1018  trainloss -2300.50385  validloss -2268.18115±0.00000  bestvalidloss -2301.50415  last_update 3\n",
      "train: iter 1019  trainloss -2308.93248  validloss -2299.40640±0.00000  bestvalidloss -2301.50415  last_update 4\n",
      "train: iter 1020  trainloss -2302.63028  validloss -2295.84489±0.00000  bestvalidloss -2301.50415  last_update 5\n",
      "train: iter 1021  trainloss -2304.41845  validloss -2286.61155±0.00000  bestvalidloss -2301.50415  last_update 6\n",
      "train: iter 1022  trainloss -2299.98860  validloss -2295.28831±0.00000  bestvalidloss -2301.50415  last_update 7\n",
      "train: iter 1023  trainloss -2296.87577  validloss -2256.75606±0.00000  bestvalidloss -2301.50415  last_update 8\n",
      "train: iter 1024  trainloss -2283.36473  validloss -2264.03395±0.00000  bestvalidloss -2301.50415  last_update 9\n",
      "train: iter 1025  trainloss -2299.42388  validloss -2290.74406±0.00000  bestvalidloss -2301.50415  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1026  trainloss -2295.45308  validloss -2262.44913±0.00000  bestvalidloss -2301.50415  last_update 11\n",
      "train: iter 1027  trainloss -2271.12992  validloss -2275.11096±0.00000  bestvalidloss -2301.50415  last_update 12\n",
      "train: iter 1028  trainloss -2278.95284  validloss -2270.84030±0.00000  bestvalidloss -2301.50415  last_update 13\n",
      "train: iter 1029  trainloss -2282.09018  validloss -2248.61071±0.00000  bestvalidloss -2301.50415  last_update 14\n",
      "train: iter 1030  trainloss -2302.11156  validloss -2291.00419±0.00000  bestvalidloss -2301.50415  last_update 15\n",
      "train: iter 1031  trainloss -2291.86823  validloss -2268.49883±0.00000  bestvalidloss -2301.50415  last_update 16\n",
      "train: iter 1032  trainloss -2304.24941  validloss -2294.17300±0.00000  bestvalidloss -2301.50415  last_update 17\n",
      "train: iter 1033  trainloss -2303.43129  validloss -2293.35317±0.00000  bestvalidloss -2301.50415  last_update 18\n",
      "train: iter 1034  trainloss -2303.01880  validloss -2301.88555±0.00000  bestvalidloss -2301.88555  last_update 0\n",
      "train: iter 1035  trainloss -2301.11726  validloss -2284.96164±0.00000  bestvalidloss -2301.88555  last_update 1\n",
      "train: iter 1036  trainloss -2298.15527  validloss -2293.96631±0.00000  bestvalidloss -2301.88555  last_update 2\n",
      "train: iter 1037  trainloss -2311.54731  validloss -2302.16287±0.00000  bestvalidloss -2302.16287  last_update 0\n",
      "train: iter 1038  trainloss -2305.70492  validloss -2292.72758±0.00000  bestvalidloss -2302.16287  last_update 1\n",
      "train: iter 1039  trainloss -2306.97886  validloss -2283.39586±0.00000  bestvalidloss -2302.16287  last_update 2\n",
      "train: iter 1040  trainloss -2295.08396  validloss -2278.27142±0.00000  bestvalidloss -2302.16287  last_update 3\n",
      "train: iter 1041  trainloss -2304.92936  validloss -2289.28979±0.00000  bestvalidloss -2302.16287  last_update 4\n",
      "train: iter 1042  trainloss -2298.58579  validloss -2289.22309±0.00000  bestvalidloss -2302.16287  last_update 5\n",
      "train: iter 1043  trainloss -2303.46133  validloss -2299.74915±0.00000  bestvalidloss -2302.16287  last_update 6\n",
      "train: iter 1044  trainloss -2286.96757  validloss -2285.41473±0.00000  bestvalidloss -2302.16287  last_update 7\n",
      "train: iter 1045  trainloss -2248.50014  validloss -2212.78252±0.00000  bestvalidloss -2302.16287  last_update 8\n",
      "train: iter 1046  trainloss -2304.33239  validloss -2246.47715±0.00000  bestvalidloss -2302.16287  last_update 9\n",
      "train: iter 1047  trainloss -2290.17057  validloss -2284.91721±0.00000  bestvalidloss -2302.16287  last_update 10\n",
      "train: iter 1048  trainloss -2288.27410  validloss -2259.61650±0.00000  bestvalidloss -2302.16287  last_update 11\n",
      "train: iter 1049  trainloss -2302.75382  validloss -2269.88353±0.00000  bestvalidloss -2302.16287  last_update 12\n",
      "train: iter 1050  trainloss -2300.52502  validloss -2286.68479±0.00000  bestvalidloss -2302.16287  last_update 13\n",
      "train: iter 1051  trainloss -2294.27260  validloss -2301.57797±0.00000  bestvalidloss -2302.16287  last_update 14\n",
      "train: iter 1052  trainloss -2311.46688  validloss -2280.91952±0.00000  bestvalidloss -2302.16287  last_update 15\n",
      "train: iter 1053  trainloss -2311.18422  validloss -2305.94860±0.00000  bestvalidloss -2305.94860  last_update 0\n",
      "train: iter 1054  trainloss -2306.13984  validloss -2286.37700±0.00000  bestvalidloss -2305.94860  last_update 1\n",
      "train: iter 1055  trainloss -2281.94413  validloss -2287.99466±0.00000  bestvalidloss -2305.94860  last_update 2\n",
      "train: iter 1056  trainloss -2264.76041  validloss -2107.05680±0.00000  bestvalidloss -2305.94860  last_update 3\n",
      "train: iter 1057  trainloss -2252.35082  validloss -2250.37241±0.00000  bestvalidloss -2305.94860  last_update 4\n",
      "train: iter 1058  trainloss -2298.59058  validloss -2214.32656±0.00000  bestvalidloss -2305.94860  last_update 5\n",
      "train: iter 1059  trainloss -2311.65703  validloss -2298.36900±0.00000  bestvalidloss -2305.94860  last_update 6\n",
      "train: iter 1060  trainloss -2307.71193  validloss -2281.55176±0.00000  bestvalidloss -2305.94860  last_update 7\n",
      "train: iter 1061  trainloss -2307.83232  validloss -2287.47800±0.00000  bestvalidloss -2305.94860  last_update 8\n",
      "train: iter 1062  trainloss -2283.62716  validloss -2285.63770±0.00000  bestvalidloss -2305.94860  last_update 9\n",
      "train: iter 1063  trainloss -2274.06311  validloss -2257.41795±0.00000  bestvalidloss -2305.94860  last_update 10\n",
      "train: iter 1064  trainloss -2292.93960  validloss -2258.96703±0.00000  bestvalidloss -2305.94860  last_update 11\n",
      "train: iter 1065  trainloss -2297.90806  validloss -2275.24014±0.00000  bestvalidloss -2305.94860  last_update 12\n",
      "train: iter 1066  trainloss -2307.80083  validloss -2301.43954±0.00000  bestvalidloss -2305.94860  last_update 13\n",
      "train: iter 1067  trainloss -2304.40806  validloss -2300.99122±0.00000  bestvalidloss -2305.94860  last_update 14\n",
      "train: iter 1068  trainloss -2309.21573  validloss -2286.87170±0.00000  bestvalidloss -2305.94860  last_update 15\n",
      "train: iter 1069  trainloss -2303.42273  validloss -2276.15333±0.00000  bestvalidloss -2305.94860  last_update 16\n",
      "train: iter 1070  trainloss -2302.31589  validloss -2277.01392±0.00000  bestvalidloss -2305.94860  last_update 17\n",
      "train: iter 1071  trainloss -2303.09153  validloss -2288.25023±0.00000  bestvalidloss -2305.94860  last_update 18\n",
      "train: iter 1072  trainloss -2306.11194  validloss -2279.94550±0.00000  bestvalidloss -2305.94860  last_update 19\n",
      "train: iter 1073  trainloss -2311.59801  validloss -2296.36316±0.00000  bestvalidloss -2305.94860  last_update 20\n",
      "train: iter 1074  trainloss -2297.16289  validloss -2296.63278±0.00000  bestvalidloss -2305.94860  last_update 21\n",
      "train: iter 1075  trainloss -2309.18566  validloss -2274.14875±0.00000  bestvalidloss -2305.94860  last_update 22\n",
      "train: iter 1076  trainloss -2284.04970  validloss -2278.78660±0.00000  bestvalidloss -2305.94860  last_update 23\n",
      "train: iter 1077  trainloss -2293.54508  validloss -2297.52265±0.00000  bestvalidloss -2305.94860  last_update 24\n",
      "train: iter 1078  trainloss -2305.65353  validloss -2299.29600±0.00000  bestvalidloss -2305.94860  last_update 25\n",
      "train: iter 1079  trainloss -2310.46074  validloss -2296.79250±0.00000  bestvalidloss -2305.94860  last_update 26\n",
      "train: iter 1080  trainloss -2311.88857  validloss -2303.11379±0.00000  bestvalidloss -2305.94860  last_update 27\n",
      "train: iter 1081  trainloss -2309.32913  validloss -2279.08332±0.00000  bestvalidloss -2305.94860  last_update 28\n",
      "train: iter 1082  trainloss -2269.52029  validloss -2288.79551±0.00000  bestvalidloss -2305.94860  last_update 29\n",
      "train: iter 1083  trainloss -2305.66391  validloss -2256.80831±0.00000  bestvalidloss -2305.94860  last_update 30\n",
      "train: iter 1084  trainloss -2307.45182  validloss -2274.00715±0.00000  bestvalidloss -2305.94860  last_update 31\n",
      "train: iter 1085  trainloss -2301.81788  validloss -2293.08823±0.00000  bestvalidloss -2305.94860  last_update 32\n",
      "train: iter 1086  trainloss -2292.75367  validloss -2233.07119±0.00000  bestvalidloss -2305.94860  last_update 33\n",
      "train: iter 1087  trainloss -2273.09512  validloss -2260.99494±0.00000  bestvalidloss -2305.94860  last_update 34\n",
      "train: iter 1088  trainloss -2284.28388  validloss -2274.56679±0.00000  bestvalidloss -2305.94860  last_update 35\n",
      "train: iter 1089  trainloss -2234.32605  validloss -2240.99435±0.00000  bestvalidloss -2305.94860  last_update 36\n",
      "train: iter 1090  trainloss -2305.40995  validloss -2289.04866±0.00000  bestvalidloss -2305.94860  last_update 37\n",
      "train: iter 1091  trainloss -2295.82086  validloss -2210.84062±0.00000  bestvalidloss -2305.94860  last_update 38\n",
      "train: iter 1092  trainloss -2291.61102  validloss -2283.29564±0.00000  bestvalidloss -2305.94860  last_update 39\n",
      "train: iter 1093  trainloss -2297.27698  validloss -2304.66813±0.00000  bestvalidloss -2305.94860  last_update 40\n",
      "train: iter 1094  trainloss -2309.10318  validloss -2283.03921±0.00000  bestvalidloss -2305.94860  last_update 41\n",
      "train: iter 1095  trainloss -2277.39165  validloss -2254.75258±0.00000  bestvalidloss -2305.94860  last_update 42\n",
      "train: iter 1096  trainloss -2302.85338  validloss -2286.36577±0.00000  bestvalidloss -2305.94860  last_update 43\n",
      "train: iter 1097  trainloss -2314.91748  validloss -2299.26663±0.00000  bestvalidloss -2305.94860  last_update 44\n",
      "train: iter 1098  trainloss -2298.69586  validloss -2291.23376±0.00000  bestvalidloss -2305.94860  last_update 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1099  trainloss -2309.25812  validloss -2272.16111±0.00000  bestvalidloss -2305.94860  last_update 46\n",
      "train: iter 1100  trainloss -2307.81317  validloss -2259.56119±0.00000  bestvalidloss -2305.94860  last_update 47\n",
      "train: iter 1101  trainloss -2319.68135  validloss -2293.04364±0.00000  bestvalidloss -2305.94860  last_update 48\n",
      "train: iter 1102  trainloss -2298.94215  validloss -2293.65251±0.00000  bestvalidloss -2305.94860  last_update 49\n",
      "train: iter 1103  trainloss -2286.85983  validloss -2245.68327±0.00000  bestvalidloss -2305.94860  last_update 50\n",
      "train: iter 1104  trainloss -2298.08553  validloss -2290.95246±0.00000  bestvalidloss -2305.94860  last_update 51\n",
      "train: iter 1105  trainloss -2295.93674  validloss -2291.98253±0.00000  bestvalidloss -2305.94860  last_update 52\n",
      "train: iter 1106  trainloss -2304.73784  validloss -2250.30319±0.00000  bestvalidloss -2305.94860  last_update 53\n",
      "train: iter 1107  trainloss -2235.76102  validloss -2295.61880±0.00000  bestvalidloss -2305.94860  last_update 54\n",
      "train: iter 1108  trainloss -2292.41137  validloss -2236.13451±0.00000  bestvalidloss -2305.94860  last_update 55\n",
      "train: iter 1109  trainloss -2305.38663  validloss -2264.81252±0.00000  bestvalidloss -2305.94860  last_update 56\n",
      "train: iter 1110  trainloss -2270.24309  validloss -2300.93259±0.00000  bestvalidloss -2305.94860  last_update 57\n",
      "train: iter 1111  trainloss -2282.05643  validloss -2272.89306±0.00000  bestvalidloss -2305.94860  last_update 58\n",
      "train: iter 1112  trainloss -2313.13543  validloss -2299.80010±0.00000  bestvalidloss -2305.94860  last_update 59\n",
      "train: iter 1113  trainloss -2316.49695  validloss -2302.44990±0.00000  bestvalidloss -2305.94860  last_update 60\n",
      "train: iter 1114  trainloss -2312.35857  validloss -2285.97443±0.00000  bestvalidloss -2305.94860  last_update 61\n",
      "train: iter 1115  trainloss -2309.55059  validloss -2281.60671±0.00000  bestvalidloss -2305.94860  last_update 62\n",
      "train: iter 1116  trainloss -2318.86288  validloss -2306.25634±0.00000  bestvalidloss -2306.25634  last_update 0\n",
      "train: iter 1117  trainloss -2317.17491  validloss -2297.89699±0.00000  bestvalidloss -2306.25634  last_update 1\n",
      "train: iter 1118  trainloss -2307.21219  validloss -2298.26324±0.00000  bestvalidloss -2306.25634  last_update 2\n",
      "train: iter 1119  trainloss -2308.92572  validloss -2300.98981±0.00000  bestvalidloss -2306.25634  last_update 3\n",
      "train: iter 1120  trainloss -2305.20735  validloss -2305.86130±0.00000  bestvalidloss -2306.25634  last_update 4\n",
      "train: iter 1121  trainloss -2307.15979  validloss -2297.76575±0.00000  bestvalidloss -2306.25634  last_update 5\n",
      "train: iter 1122  trainloss -2307.24600  validloss -2299.32074±0.00000  bestvalidloss -2306.25634  last_update 6\n",
      "train: iter 1123  trainloss -2296.99067  validloss -2296.28968±0.00000  bestvalidloss -2306.25634  last_update 7\n",
      "train: iter 1124  trainloss -2315.27752  validloss -2275.24663±0.00000  bestvalidloss -2306.25634  last_update 8\n",
      "train: iter 1125  trainloss -2285.45688  validloss -2264.73384±0.00000  bestvalidloss -2306.25634  last_update 9\n",
      "train: iter 1126  trainloss -2303.21895  validloss -2272.34072±0.00000  bestvalidloss -2306.25634  last_update 10\n",
      "train: iter 1127  trainloss -2298.60280  validloss -2296.22758±0.00000  bestvalidloss -2306.25634  last_update 11\n",
      "train: iter 1128  trainloss -2264.89665  validloss -2229.62870±0.00000  bestvalidloss -2306.25634  last_update 12\n",
      "train: iter 1129  trainloss -2244.13272  validloss -2261.82731±0.00000  bestvalidloss -2306.25634  last_update 13\n",
      "train: iter 1130  trainloss -2299.94209  validloss -2261.53984±0.00000  bestvalidloss -2306.25634  last_update 14\n",
      "train: iter 1131  trainloss -2315.40182  validloss -2295.81664±0.00000  bestvalidloss -2306.25634  last_update 15\n",
      "train: iter 1132  trainloss -2310.80580  validloss -2300.11855±0.00000  bestvalidloss -2306.25634  last_update 16\n",
      "train: iter 1133  trainloss -2300.38443  validloss -2261.97756±0.00000  bestvalidloss -2306.25634  last_update 17\n",
      "train: iter 1134  trainloss -2311.12389  validloss -2293.16006±0.00000  bestvalidloss -2306.25634  last_update 18\n",
      "train: iter 1135  trainloss -2298.99935  validloss -2267.89114±0.00000  bestvalidloss -2306.25634  last_update 19\n",
      "train: iter 1136  trainloss -2307.76945  validloss -2278.65300±0.00000  bestvalidloss -2306.25634  last_update 20\n",
      "train: iter 1137  trainloss -2307.35589  validloss -2290.12502±0.00000  bestvalidloss -2306.25634  last_update 21\n",
      "train: iter 1138  trainloss -2304.34441  validloss -2296.83934±0.00000  bestvalidloss -2306.25634  last_update 22\n",
      "train: iter 1139  trainloss -2305.87139  validloss -2282.99793±0.00000  bestvalidloss -2306.25634  last_update 23\n",
      "train: iter 1140  trainloss -2317.44527  validloss -2301.07333±0.00000  bestvalidloss -2306.25634  last_update 24\n",
      "train: iter 1141  trainloss -2310.93077  validloss -2288.18038±0.00000  bestvalidloss -2306.25634  last_update 25\n",
      "train: iter 1142  trainloss -2305.32385  validloss -2299.95355±0.00000  bestvalidloss -2306.25634  last_update 26\n",
      "train: iter 1143  trainloss -2312.76422  validloss -2283.00078±0.00000  bestvalidloss -2306.25634  last_update 27\n",
      "train: iter 1144  trainloss -2313.63648  validloss -2291.25527±0.00000  bestvalidloss -2306.25634  last_update 28\n",
      "train: iter 1145  trainloss -2311.38358  validloss -2294.44936±0.00000  bestvalidloss -2306.25634  last_update 29\n",
      "train: iter 1146  trainloss -2303.34341  validloss -2246.78716±0.00000  bestvalidloss -2306.25634  last_update 30\n",
      "train: iter 1147  trainloss -2309.75751  validloss -2289.73446±0.00000  bestvalidloss -2306.25634  last_update 31\n",
      "train: iter 1148  trainloss -2300.89037  validloss -2295.30714±0.00000  bestvalidloss -2306.25634  last_update 32\n",
      "train: iter 1149  trainloss -2278.92955  validloss -2270.43305±0.00000  bestvalidloss -2306.25634  last_update 33\n",
      "train: iter 1150  trainloss -2306.02112  validloss -2300.54597±0.00000  bestvalidloss -2306.25634  last_update 34\n",
      "train: iter 1151  trainloss -2276.18216  validloss -2268.47624±0.00000  bestvalidloss -2306.25634  last_update 35\n",
      "train: iter 1152  trainloss -2304.25341  validloss -2247.46871±0.00000  bestvalidloss -2306.25634  last_update 36\n",
      "train: iter 1153  trainloss -2291.43194  validloss -2275.76581±0.00000  bestvalidloss -2306.25634  last_update 37\n",
      "train: iter 1154  trainloss -2282.57226  validloss -2242.24240±0.00000  bestvalidloss -2306.25634  last_update 38\n",
      "train: iter 1155  trainloss -2310.31542  validloss -2293.52014±0.00000  bestvalidloss -2306.25634  last_update 39\n",
      "train: iter 1156  trainloss -2320.13030  validloss -2292.63597±0.00000  bestvalidloss -2306.25634  last_update 40\n",
      "train: iter 1157  trainloss -2314.08534  validloss -2295.27095±0.00000  bestvalidloss -2306.25634  last_update 41\n",
      "train: iter 1158  trainloss -2301.32591  validloss -2287.96762±0.00000  bestvalidloss -2306.25634  last_update 42\n",
      "train: iter 1159  trainloss -2304.50591  validloss -2294.43162±0.00000  bestvalidloss -2306.25634  last_update 43\n",
      "train: iter 1160  trainloss -2230.54368  validloss -2293.50648±0.00000  bestvalidloss -2306.25634  last_update 44\n",
      "train: iter 1161  trainloss -2244.14846  validloss -2217.85958±0.00000  bestvalidloss -2306.25634  last_update 45\n",
      "train: iter 1162  trainloss -2288.85202  validloss -2249.31254±0.00000  bestvalidloss -2306.25634  last_update 46\n",
      "train: iter 1163  trainloss -2314.19894  validloss -2295.73000±0.00000  bestvalidloss -2306.25634  last_update 47\n",
      "train: iter 1164  trainloss -2306.77971  validloss -2273.91275±0.00000  bestvalidloss -2306.25634  last_update 48\n",
      "train: iter 1165  trainloss -2312.40723  validloss -2284.91038±0.00000  bestvalidloss -2306.25634  last_update 49\n",
      "train: iter 1166  trainloss -2314.63530  validloss -2307.53204±0.00000  bestvalidloss -2307.53204  last_update 0\n",
      "train: iter 1167  trainloss -2315.84048  validloss -2297.22614±0.00000  bestvalidloss -2307.53204  last_update 1\n",
      "train: iter 1168  trainloss -2312.25406  validloss -2298.74715±0.00000  bestvalidloss -2307.53204  last_update 2\n",
      "train: iter 1169  trainloss -2300.84903  validloss -2294.31108±0.00000  bestvalidloss -2307.53204  last_update 3\n",
      "train: iter 1170  trainloss -2301.71674  validloss -2289.26835±0.00000  bestvalidloss -2307.53204  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1171  trainloss -2307.84060  validloss -2291.34510±0.00000  bestvalidloss -2307.53204  last_update 5\n",
      "train: iter 1172  trainloss -2309.84708  validloss -2289.17234±0.00000  bestvalidloss -2307.53204  last_update 6\n",
      "train: iter 1173  trainloss -2313.99543  validloss -2269.90416±0.00000  bestvalidloss -2307.53204  last_update 7\n",
      "train: iter 1174  trainloss -2298.55465  validloss -2291.04165±0.00000  bestvalidloss -2307.53204  last_update 8\n",
      "train: iter 1175  trainloss -2312.93136  validloss -2294.28314±0.00000  bestvalidloss -2307.53204  last_update 9\n",
      "train: iter 1176  trainloss -2313.11394  validloss -2301.56226±0.00000  bestvalidloss -2307.53204  last_update 10\n",
      "train: iter 1177  trainloss -2317.39543  validloss -2308.17352±0.00000  bestvalidloss -2308.17352  last_update 0\n",
      "train: iter 1178  trainloss -2303.14421  validloss -2297.93521±0.00000  bestvalidloss -2308.17352  last_update 1\n",
      "train: iter 1179  trainloss -2289.64793  validloss -2272.39040±0.00000  bestvalidloss -2308.17352  last_update 2\n",
      "train: iter 1180  trainloss -2296.94023  validloss -2290.66199±0.00000  bestvalidloss -2308.17352  last_update 3\n",
      "train: iter 1181  trainloss -2307.61891  validloss -2265.08950±0.00000  bestvalidloss -2308.17352  last_update 4\n",
      "train: iter 1182  trainloss -2311.74703  validloss -2288.74448±0.00000  bestvalidloss -2308.17352  last_update 5\n",
      "train: iter 1183  trainloss -2316.21765  validloss -2297.10677±0.00000  bestvalidloss -2308.17352  last_update 6\n",
      "train: iter 1184  trainloss -2312.25135  validloss -2290.44086±0.00000  bestvalidloss -2308.17352  last_update 7\n",
      "train: iter 1185  trainloss -2303.93907  validloss -2286.19612±0.00000  bestvalidloss -2308.17352  last_update 8\n",
      "train: iter 1186  trainloss -2301.95498  validloss -2310.39334±0.00000  bestvalidloss -2310.39334  last_update 0\n",
      "train: iter 1187  trainloss -2306.85078  validloss -2271.16484±0.00000  bestvalidloss -2310.39334  last_update 1\n",
      "train: iter 1188  trainloss -2316.81812  validloss -2274.04791±0.00000  bestvalidloss -2310.39334  last_update 2\n",
      "train: iter 1189  trainloss -2295.60861  validloss -2279.73809±0.00000  bestvalidloss -2310.39334  last_update 3\n",
      "train: iter 1190  trainloss -2301.24084  validloss -2252.40930±0.00000  bestvalidloss -2310.39334  last_update 4\n",
      "train: iter 1191  trainloss -2304.60616  validloss -2287.32473±0.00000  bestvalidloss -2310.39334  last_update 5\n",
      "train: iter 1192  trainloss -2288.90390  validloss -2292.04484±0.00000  bestvalidloss -2310.39334  last_update 6\n",
      "train: iter 1193  trainloss -2285.83436  validloss -2242.40306±0.00000  bestvalidloss -2310.39334  last_update 7\n",
      "train: iter 1194  trainloss -2310.31419  validloss -2252.93547±0.00000  bestvalidloss -2310.39334  last_update 8\n",
      "train: iter 1195  trainloss -2305.70620  validloss -2272.84044±0.00000  bestvalidloss -2310.39334  last_update 9\n",
      "train: iter 1196  trainloss -2305.47127  validloss -2284.83529±0.00000  bestvalidloss -2310.39334  last_update 10\n",
      "train: iter 1197  trainloss -2310.46326  validloss -2281.23799±0.00000  bestvalidloss -2310.39334  last_update 11\n",
      "train: iter 1198  trainloss -2308.56577  validloss -2284.56508±0.00000  bestvalidloss -2310.39334  last_update 12\n",
      "train: iter 1199  trainloss -2302.14217  validloss -2310.93801±0.00000  bestvalidloss -2310.93801  last_update 0\n",
      "train: iter 1200  trainloss -2297.27770  validloss -2258.74034±0.00000  bestvalidloss -2310.93801  last_update 1\n",
      "train: iter 1201  trainloss -2316.67509  validloss -2281.47549±0.00000  bestvalidloss -2310.93801  last_update 2\n",
      "train: iter 1202  trainloss -2307.80602  validloss -2281.08591±0.00000  bestvalidloss -2310.93801  last_update 3\n",
      "train: iter 1203  trainloss -2296.07241  validloss -2290.27798±0.00000  bestvalidloss -2310.93801  last_update 4\n",
      "train: iter 1204  trainloss -2275.86487  validloss -2296.22858±0.00000  bestvalidloss -2310.93801  last_update 5\n",
      "train: iter 1205  trainloss -2296.70506  validloss -2256.26060±0.00000  bestvalidloss -2310.93801  last_update 6\n",
      "train: iter 1206  trainloss -2306.56436  validloss -2252.89841±0.00000  bestvalidloss -2310.93801  last_update 7\n",
      "train: iter 1207  trainloss -2293.27546  validloss -2271.16497±0.00000  bestvalidloss -2310.93801  last_update 8\n",
      "train: iter 1208  trainloss -2211.24958  validloss -2246.65587±0.00000  bestvalidloss -2310.93801  last_update 9\n",
      "train: iter 1209  trainloss -2316.12748  validloss -2276.76041±0.00000  bestvalidloss -2310.93801  last_update 10\n",
      "train: iter 1210  trainloss -2312.97438  validloss -2296.11664±0.00000  bestvalidloss -2310.93801  last_update 11\n",
      "train: iter 1211  trainloss -2315.56477  validloss -2296.66157±0.00000  bestvalidloss -2310.93801  last_update 12\n",
      "train: iter 1212  trainloss -2316.09844  validloss -2307.90547±0.00000  bestvalidloss -2310.93801  last_update 13\n",
      "train: iter 1213  trainloss -2308.45601  validloss -2290.50017±0.00000  bestvalidloss -2310.93801  last_update 14\n",
      "train: iter 1214  trainloss -2311.21836  validloss -2282.28148±0.00000  bestvalidloss -2310.93801  last_update 15\n",
      "train: iter 1215  trainloss -2313.21955  validloss -2304.40040±0.00000  bestvalidloss -2310.93801  last_update 16\n",
      "train: iter 1216  trainloss -2313.69082  validloss -2300.79431±0.00000  bestvalidloss -2310.93801  last_update 17\n",
      "train: iter 1217  trainloss -2315.49623  validloss -2302.08638±0.00000  bestvalidloss -2310.93801  last_update 18\n",
      "train: iter 1218  trainloss -2310.98252  validloss -2306.73233±0.00000  bestvalidloss -2310.93801  last_update 19\n",
      "train: iter 1219  trainloss -2320.62569  validloss -2294.67437±0.00000  bestvalidloss -2310.93801  last_update 20\n",
      "train: iter 1220  trainloss -2309.76548  validloss -2261.34536±0.00000  bestvalidloss -2310.93801  last_update 21\n",
      "train: iter 1221  trainloss -2315.01135  validloss -2281.69033±0.00000  bestvalidloss -2310.93801  last_update 22\n",
      "train: iter 1222  trainloss -2300.56470  validloss -2299.56053±0.00000  bestvalidloss -2310.93801  last_update 23\n",
      "train: iter 1223  trainloss -2300.73836  validloss -2290.22347±0.00000  bestvalidloss -2310.93801  last_update 24\n",
      "train: iter 1224  trainloss -2277.08907  validloss -2273.29888±0.00000  bestvalidloss -2310.93801  last_update 25\n",
      "train: iter 1225  trainloss -2298.11369  validloss -2290.77528±0.00000  bestvalidloss -2310.93801  last_update 26\n",
      "train: iter 1226  trainloss -2311.31658  validloss -2226.46647±0.00000  bestvalidloss -2310.93801  last_update 27\n",
      "train: iter 1227  trainloss -2308.91862  validloss -2292.54219±0.00000  bestvalidloss -2310.93801  last_update 28\n",
      "train: iter 1228  trainloss -2289.78826  validloss -2279.09292±0.00000  bestvalidloss -2310.93801  last_update 29\n",
      "train: iter 1229  trainloss -2277.44055  validloss -2215.45953±0.00000  bestvalidloss -2310.93801  last_update 30\n",
      "train: iter 1230  trainloss -2307.36772  validloss -2290.37800±0.00000  bestvalidloss -2310.93801  last_update 31\n",
      "train: iter 1231  trainloss -2312.86981  validloss -2276.96907±0.00000  bestvalidloss -2310.93801  last_update 32\n",
      "train: iter 1232  trainloss -2308.56307  validloss -2301.72505±0.00000  bestvalidloss -2310.93801  last_update 33\n",
      "train: iter 1233  trainloss -2306.43383  validloss -2292.43741±0.00000  bestvalidloss -2310.93801  last_update 34\n",
      "train: iter 1234  trainloss -2304.18564  validloss -2289.75567±0.00000  bestvalidloss -2310.93801  last_update 35\n",
      "train: iter 1235  trainloss -2306.52056  validloss -2268.94336±0.00000  bestvalidloss -2310.93801  last_update 36\n",
      "train: iter 1236  trainloss -2314.64270  validloss -2289.38444±0.00000  bestvalidloss -2310.93801  last_update 37\n",
      "train: iter 1237  trainloss -2308.65086  validloss -2294.17432±0.00000  bestvalidloss -2310.93801  last_update 38\n",
      "train: iter 1238  trainloss -2311.32957  validloss -2265.41063±0.00000  bestvalidloss -2310.93801  last_update 39\n",
      "train: iter 1239  trainloss -2297.06533  validloss -2291.54150±0.00000  bestvalidloss -2310.93801  last_update 40\n",
      "train: iter 1240  trainloss -2272.76212  validloss -2217.36121±0.00000  bestvalidloss -2310.93801  last_update 41\n",
      "train: iter 1241  trainloss -2307.13050  validloss -2300.31712±0.00000  bestvalidloss -2310.93801  last_update 42\n",
      "train: iter 1242  trainloss -2301.63112  validloss -2288.97227±0.00000  bestvalidloss -2310.93801  last_update 43\n",
      "train: iter 1243  trainloss -2311.12864  validloss -2301.04579±0.00000  bestvalidloss -2310.93801  last_update 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1244  trainloss -2317.43029  validloss -2287.21507±0.00000  bestvalidloss -2310.93801  last_update 45\n",
      "train: iter 1245  trainloss -2295.36373  validloss -2299.36266±0.00000  bestvalidloss -2310.93801  last_update 46\n",
      "train: iter 1246  trainloss -2308.79263  validloss -2303.87147±0.00000  bestvalidloss -2310.93801  last_update 47\n",
      "train: iter 1247  trainloss -2302.09650  validloss -2241.02003±0.00000  bestvalidloss -2310.93801  last_update 48\n",
      "train: iter 1248  trainloss -2310.26398  validloss -2292.24529±0.00000  bestvalidloss -2310.93801  last_update 49\n",
      "train: iter 1249  trainloss -2306.39586  validloss -2289.81238±0.00000  bestvalidloss -2310.93801  last_update 50\n",
      "train: iter 1250  trainloss -2313.86632  validloss -2273.03461±0.00000  bestvalidloss -2310.93801  last_update 51\n",
      "train: iter 1251  trainloss -2308.88300  validloss -2271.29921±0.00000  bestvalidloss -2310.93801  last_update 52\n",
      "train: iter 1252  trainloss -2296.02329  validloss -2271.79832±0.00000  bestvalidloss -2310.93801  last_update 53\n",
      "train: iter 1253  trainloss -2294.50107  validloss -2252.74066±0.00000  bestvalidloss -2310.93801  last_update 54\n",
      "train: iter 1254  trainloss -2301.07453  validloss -2295.93401±0.00000  bestvalidloss -2310.93801  last_update 55\n",
      "train: iter 1255  trainloss -2311.12744  validloss -2291.35937±0.00000  bestvalidloss -2310.93801  last_update 56\n",
      "train: iter 1256  trainloss -2315.19676  validloss -2269.37709±0.00000  bestvalidloss -2310.93801  last_update 57\n",
      "train: iter 1257  trainloss -2312.40906  validloss -2301.66760±0.00000  bestvalidloss -2310.93801  last_update 58\n",
      "train: iter 1258  trainloss -2311.44235  validloss -2291.16642±0.00000  bestvalidloss -2310.93801  last_update 59\n",
      "train: iter 1259  trainloss -2318.73905  validloss -2296.06866±0.00000  bestvalidloss -2310.93801  last_update 60\n",
      "train: iter 1260  trainloss -2312.73386  validloss -2286.10782±0.00000  bestvalidloss -2310.93801  last_update 61\n",
      "train: iter 1261  trainloss -2304.32074  validloss -2277.49291±0.00000  bestvalidloss -2310.93801  last_update 62\n",
      "train: iter 1262  trainloss -2319.76023  validloss -2279.65727±0.00000  bestvalidloss -2310.93801  last_update 63\n",
      "train: iter 1263  trainloss -2313.70324  validloss -2261.92690±0.00000  bestvalidloss -2310.93801  last_update 64\n",
      "train: iter 1264  trainloss -2313.57684  validloss -2280.17095±0.00000  bestvalidloss -2310.93801  last_update 65\n",
      "train: iter 1265  trainloss -2311.09571  validloss -2203.91912±0.00000  bestvalidloss -2310.93801  last_update 66\n",
      "train: iter 1266  trainloss -2307.39381  validloss -2281.41035±0.00000  bestvalidloss -2310.93801  last_update 67\n",
      "train: iter 1267  trainloss -2319.01140  validloss -2291.41978±0.00000  bestvalidloss -2310.93801  last_update 68\n",
      "train: iter 1268  trainloss -2297.01841  validloss -2299.48136±0.00000  bestvalidloss -2310.93801  last_update 69\n",
      "train: iter 1269  trainloss -2304.81552  validloss -2257.41230±0.00000  bestvalidloss -2310.93801  last_update 70\n",
      "train: iter 1270  trainloss -2296.73776  validloss -2268.21108±0.00000  bestvalidloss -2310.93801  last_update 71\n",
      "train: iter 1271  trainloss -2289.15582  validloss -2275.13548±0.00000  bestvalidloss -2310.93801  last_update 72\n",
      "train: iter 1272  trainloss -2314.33240  validloss -2296.02647±0.00000  bestvalidloss -2310.93801  last_update 73\n",
      "train: iter 1273  trainloss -2301.55728  validloss -2295.77257±0.00000  bestvalidloss -2310.93801  last_update 74\n",
      "train: iter 1274  trainloss -2313.36466  validloss -2278.79188±0.00000  bestvalidloss -2310.93801  last_update 75\n",
      "train: iter 1275  trainloss -2308.97051  validloss -2268.70113±0.00000  bestvalidloss -2310.93801  last_update 76\n",
      "train: iter 1276  trainloss -2315.71186  validloss -2215.87163±0.00000  bestvalidloss -2310.93801  last_update 77\n",
      "train: iter 1277  trainloss -2327.84363  validloss -2307.35974±0.00000  bestvalidloss -2310.93801  last_update 78\n",
      "train: iter 1278  trainloss -2290.03956  validloss -2299.56957±0.00000  bestvalidloss -2310.93801  last_update 79\n",
      "train: iter 1279  trainloss -2286.79189  validloss -2251.97805±0.00000  bestvalidloss -2310.93801  last_update 80\n",
      "train: iter 1280  trainloss -2314.78246  validloss -2301.35313±0.00000  bestvalidloss -2310.93801  last_update 81\n",
      "train: iter 1281  trainloss -2316.40138  validloss -2286.25874±0.00000  bestvalidloss -2310.93801  last_update 82\n",
      "train: iter 1282  trainloss -2305.30517  validloss -2286.67892±0.00000  bestvalidloss -2310.93801  last_update 83\n",
      "train: iter 1283  trainloss -2307.52101  validloss -2252.54656±0.00000  bestvalidloss -2310.93801  last_update 84\n",
      "train: iter 1284  trainloss -2300.54234  validloss -2245.51230±0.00000  bestvalidloss -2310.93801  last_update 85\n",
      "train: iter 1285  trainloss -2299.89982  validloss -2231.69937±0.00000  bestvalidloss -2310.93801  last_update 86\n",
      "train: iter 1286  trainloss -2306.81015  validloss -2305.44721±0.00000  bestvalidloss -2310.93801  last_update 87\n",
      "train: iter 1287  trainloss -2318.42559  validloss -2294.76508±0.00000  bestvalidloss -2310.93801  last_update 88\n",
      "train: iter 1288  trainloss -2316.37373  validloss -2281.11927±0.00000  bestvalidloss -2310.93801  last_update 89\n",
      "train: iter 1289  trainloss -2312.15054  validloss -2276.43732±0.00000  bestvalidloss -2310.93801  last_update 90\n",
      "train: iter 1290  trainloss -2319.20745  validloss -2284.67788±0.00000  bestvalidloss -2310.93801  last_update 91\n",
      "train: iter 1291  trainloss -2297.99653  validloss -2283.50607±0.00000  bestvalidloss -2310.93801  last_update 92\n",
      "train: iter 1292  trainloss -2305.40232  validloss -2269.49116±0.00000  bestvalidloss -2310.93801  last_update 93\n",
      "train: iter 1293  trainloss -2307.24220  validloss -2298.28607±0.00000  bestvalidloss -2310.93801  last_update 94\n",
      "train: iter 1294  trainloss -2284.13195  validloss -2298.30394±0.00000  bestvalidloss -2310.93801  last_update 95\n",
      "train: iter 1295  trainloss -2266.39272  validloss -2244.43218±0.00000  bestvalidloss -2310.93801  last_update 96\n",
      "train: iter 1296  trainloss -2311.64698  validloss -2306.39016±0.00000  bestvalidloss -2310.93801  last_update 97\n",
      "train: iter 1297  trainloss -2305.94003  validloss -2289.82481±0.00000  bestvalidloss -2310.93801  last_update 98\n",
      "train: iter 1298  trainloss -2316.64529  validloss -2284.99462±0.00000  bestvalidloss -2310.93801  last_update 99\n",
      "train: iter 1299  trainloss -2303.46380  validloss -2280.33088±0.00000  bestvalidloss -2310.93801  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3240) penalty_target_max tensor(20.2573)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.66323  validloss 4.90594±0.00000  bestvalidloss 4.90594  last_update 0\n",
      "train: iter 1  trainloss 4.24380  validloss 4.46825±0.00000  bestvalidloss 4.46825  last_update 0\n",
      "train: iter 2  trainloss 3.90014  validloss 4.06896±0.00000  bestvalidloss 4.06896  last_update 0\n",
      "train: iter 3  trainloss 3.61096  validloss 3.76208±0.00000  bestvalidloss 3.76208  last_update 0\n",
      "train: iter 4  trainloss 3.36124  validloss 3.48925±0.00000  bestvalidloss 3.48925  last_update 0\n",
      "train: iter 5  trainloss 3.15129  validloss 3.26759±0.00000  bestvalidloss 3.26759  last_update 0\n",
      "train: iter 6  trainloss 2.97715  validloss 3.07498±0.00000  bestvalidloss 3.07498  last_update 0\n",
      "train: iter 7  trainloss 2.83236  validloss 2.91355±0.00000  bestvalidloss 2.91355  last_update 0\n",
      "train: iter 8  trainloss 2.70236  validloss 2.77296±0.00000  bestvalidloss 2.77296  last_update 0\n",
      "train: iter 9  trainloss 2.58409  validloss 2.65383±0.00000  bestvalidloss 2.65383  last_update 0\n",
      "train: iter 10  trainloss 2.48667  validloss 2.55312±0.00000  bestvalidloss 2.55312  last_update 0\n",
      "train: iter 11  trainloss 2.39940  validloss 2.44811±0.00000  bestvalidloss 2.44811  last_update 0\n",
      "train: iter 12  trainloss 2.32110  validloss 2.36810±0.00000  bestvalidloss 2.36810  last_update 0\n",
      "train: iter 13  trainloss 2.25230  validloss 2.29463±0.00000  bestvalidloss 2.29463  last_update 0\n",
      "train: iter 14  trainloss 2.19188  validloss 2.23098±0.00000  bestvalidloss 2.23098  last_update 0\n",
      "train: iter 15  trainloss 2.13524  validloss 2.17072±0.00000  bestvalidloss 2.17072  last_update 0\n",
      "train: iter 16  trainloss 2.08901  validloss 2.11697±0.00000  bestvalidloss 2.11697  last_update 0\n",
      "train: iter 17  trainloss 2.03850  validloss 2.07114±0.00000  bestvalidloss 2.07114  last_update 0\n",
      "train: iter 18  trainloss 1.99918  validloss 2.02989±0.00000  bestvalidloss 2.02989  last_update 0\n",
      "train: iter 19  trainloss 1.96061  validloss 1.98266±0.00000  bestvalidloss 1.98266  last_update 0\n",
      "train: iter 20  trainloss 1.92196  validloss 1.94471±0.00000  bestvalidloss 1.94471  last_update 0\n",
      "train: iter 21  trainloss 1.88686  validloss 1.90620±0.00000  bestvalidloss 1.90620  last_update 0\n",
      "train: iter 22  trainloss 1.85511  validloss 1.87758±0.00000  bestvalidloss 1.87758  last_update 0\n",
      "train: iter 23  trainloss 1.82321  validloss 1.84573±0.00000  bestvalidloss 1.84573  last_update 0\n",
      "train: iter 24  trainloss 1.78963  validloss 1.81756±0.00000  bestvalidloss 1.81756  last_update 0\n",
      "train: iter 25  trainloss 1.76277  validloss 1.78057±0.00000  bestvalidloss 1.78057  last_update 0\n",
      "train: iter 26  trainloss 1.73276  validloss 1.75162±0.00000  bestvalidloss 1.75162  last_update 0\n",
      "train: iter 27  trainloss 1.70418  validloss 1.72448±0.00000  bestvalidloss 1.72448  last_update 0\n",
      "train: iter 28  trainloss 1.67453  validloss 1.69132±0.00000  bestvalidloss 1.69132  last_update 0\n",
      "train: iter 29  trainloss 1.64279  validloss 1.66323±0.00000  bestvalidloss 1.66323  last_update 0\n",
      "train: iter 30  trainloss 1.61444  validloss 1.63531±0.00000  bestvalidloss 1.63531  last_update 0\n",
      "train: iter 31  trainloss 1.58178  validloss 1.60290±0.00000  bestvalidloss 1.60290  last_update 0\n",
      "train: iter 32  trainloss 1.55040  validloss 1.56923±0.00000  bestvalidloss 1.56923  last_update 0\n",
      "train: iter 33  trainloss 1.51721  validloss 1.54102±0.00000  bestvalidloss 1.54102  last_update 0\n",
      "train: iter 34  trainloss 1.48487  validloss 1.50498±0.00000  bestvalidloss 1.50498  last_update 0\n",
      "train: iter 35  trainloss 1.44969  validloss 1.47439±0.00000  bestvalidloss 1.47439  last_update 0\n",
      "train: iter 36  trainloss 1.41232  validloss 1.43555±0.00000  bestvalidloss 1.43555  last_update 0\n",
      "train: iter 37  trainloss 1.37487  validloss 1.40142±0.00000  bestvalidloss 1.40142  last_update 0\n",
      "train: iter 38  trainloss 1.33325  validloss 1.35737±0.00000  bestvalidloss 1.35737  last_update 0\n",
      "train: iter 39  trainloss 1.29281  validloss 1.31764±0.00000  bestvalidloss 1.31764  last_update 0\n",
      "train: iter 40  trainloss 1.24934  validloss 1.27585±0.00000  bestvalidloss 1.27585  last_update 0\n",
      "train: iter 41  trainloss 1.20483  validloss 1.23008±0.00000  bestvalidloss 1.23008  last_update 0\n",
      "train: iter 42  trainloss 1.15648  validloss 1.18284±0.00000  bestvalidloss 1.18284  last_update 0\n",
      "train: iter 43  trainloss 1.11136  validloss 1.13606±0.00000  bestvalidloss 1.13606  last_update 0\n",
      "train: iter 44  trainloss 1.06034  validloss 1.08787±0.00000  bestvalidloss 1.08787  last_update 0\n",
      "train: iter 45  trainloss 1.00926  validloss 1.03398±0.00000  bestvalidloss 1.03398  last_update 0\n",
      "train: iter 46  trainloss 0.95918  validloss 0.98681±0.00000  bestvalidloss 0.98681  last_update 0\n",
      "train: iter 47  trainloss 0.90720  validloss 0.93398±0.00000  bestvalidloss 0.93398  last_update 0\n",
      "train: iter 48  trainloss 0.85456  validloss 0.88488±0.00000  bestvalidloss 0.88488  last_update 0\n",
      "train: iter 49  trainloss 0.80402  validloss 0.83329±0.00000  bestvalidloss 0.83329  last_update 0\n",
      "train: iter 50  trainloss 0.75340  validloss 0.78060±0.00000  bestvalidloss 0.78060  last_update 0\n",
      "train: iter 51  trainloss 0.70405  validloss 0.72902±0.00000  bestvalidloss 0.72902  last_update 0\n",
      "train: iter 52  trainloss 0.65631  validloss 0.68132±0.00000  bestvalidloss 0.68132  last_update 0\n",
      "train: iter 53  trainloss 0.60952  validloss 0.63371±0.00000  bestvalidloss 0.63371  last_update 0\n",
      "train: iter 54  trainloss 0.56404  validloss 0.58679±0.00000  bestvalidloss 0.58679  last_update 0\n",
      "train: iter 55  trainloss 0.51945  validloss 0.54210±0.00000  bestvalidloss 0.54210  last_update 0\n",
      "train: iter 56  trainloss 0.47614  validloss 0.49836±0.00000  bestvalidloss 0.49836  last_update 0\n",
      "train: iter 57  trainloss 0.43313  validloss 0.45476±0.00000  bestvalidloss 0.45476  last_update 0\n",
      "train: iter 58  trainloss 0.39079  validloss 0.41092±0.00000  bestvalidloss 0.41092  last_update 0\n",
      "train: iter 59  trainloss 0.34849  validloss 0.36861±0.00000  bestvalidloss 0.36861  last_update 0\n",
      "train: iter 60  trainloss 0.30694  validloss 0.32728±0.00000  bestvalidloss 0.32728  last_update 0\n",
      "train: iter 61  trainloss 0.26528  validloss 0.28545±0.00000  bestvalidloss 0.28545  last_update 0\n",
      "train: iter 62  trainloss 0.22393  validloss 0.24335±0.00000  bestvalidloss 0.24335  last_update 0\n",
      "train: iter 63  trainloss 0.18301  validloss 0.20246±0.00000  bestvalidloss 0.20246  last_update 0\n",
      "train: iter 64  trainloss 0.14164  validloss 0.16099±0.00000  bestvalidloss 0.16099  last_update 0\n",
      "train: iter 65  trainloss 0.10078  validloss 0.11981±0.00000  bestvalidloss 0.11981  last_update 0\n",
      "train: iter 66  trainloss 0.05955  validloss 0.07840±0.00000  bestvalidloss 0.07840  last_update 0\n",
      "train: iter 67  trainloss 0.01952  validloss 0.03739±0.00000  bestvalidloss 0.03739  last_update 0\n",
      "train: iter 68  trainloss -0.02088  validloss -0.00071±0.00000  bestvalidloss -0.00071  last_update 0\n",
      "train: iter 69  trainloss -0.06102  validloss -0.04298±0.00000  bestvalidloss -0.04298  last_update 0\n",
      "train: iter 70  trainloss -0.10204  validloss -0.08455±0.00000  bestvalidloss -0.08455  last_update 0\n",
      "train: iter 71  trainloss -0.14286  validloss -0.12611±0.00000  bestvalidloss -0.12611  last_update 0\n",
      "train: iter 72  trainloss -0.18370  validloss -0.16611±0.00000  bestvalidloss -0.16611  last_update 0\n",
      "train: iter 73  trainloss -0.22169  validloss -0.20479±0.00000  bestvalidloss -0.20479  last_update 0\n",
      "train: iter 74  trainloss -0.26156  validloss -0.24607±0.00000  bestvalidloss -0.24607  last_update 0\n",
      "train: iter 75  trainloss -0.30181  validloss -0.28351±0.00000  bestvalidloss -0.28351  last_update 0\n",
      "train: iter 76  trainloss -0.34109  validloss -0.32318±0.00000  bestvalidloss -0.32318  last_update 0\n",
      "train: iter 77  trainloss -0.38108  validloss -0.36646±0.00000  bestvalidloss -0.36646  last_update 0\n",
      "train: iter 78  trainloss -0.42000  validloss -0.40467±0.00000  bestvalidloss -0.40467  last_update 0\n",
      "train: iter 79  trainloss -0.45927  validloss -0.44294±0.00000  bestvalidloss -0.44294  last_update 0\n",
      "train: iter 80  trainloss -0.49748  validloss -0.48582±0.00000  bestvalidloss -0.48582  last_update 0\n",
      "train: iter 81  trainloss -0.53559  validloss -0.52202±0.00000  bestvalidloss -0.52202  last_update 0\n",
      "train: iter 82  trainloss -0.57708  validloss -0.56352±0.00000  bestvalidloss -0.56352  last_update 0\n",
      "train: iter 83  trainloss -0.61400  validloss -0.59986±0.00000  bestvalidloss -0.59986  last_update 0\n",
      "train: iter 84  trainloss -0.65265  validloss -0.64103±0.00000  bestvalidloss -0.64103  last_update 0\n",
      "train: iter 85  trainloss -0.69225  validloss -0.68328±0.00000  bestvalidloss -0.68328  last_update 0\n",
      "train: iter 86  trainloss -0.72910  validloss -0.71640±0.00000  bestvalidloss -0.71640  last_update 0\n",
      "train: iter 87  trainloss -0.76833  validloss -0.75039±0.00000  bestvalidloss -0.75039  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 88  trainloss -0.80761  validloss -0.79745±0.00000  bestvalidloss -0.79745  last_update 0\n",
      "train: iter 89  trainloss -0.84571  validloss -0.83353±0.00000  bestvalidloss -0.83353  last_update 0\n",
      "train: iter 90  trainloss -0.88474  validloss -0.87139±0.00000  bestvalidloss -0.87139  last_update 0\n",
      "train: iter 91  trainloss -0.91987  validloss -0.90607±0.00000  bestvalidloss -0.90607  last_update 0\n",
      "train: iter 92  trainloss -0.94940  validloss -0.94926±0.00000  bestvalidloss -0.94926  last_update 0\n",
      "train: iter 93  trainloss -0.99432  validloss -0.98843±0.00000  bestvalidloss -0.98843  last_update 0\n",
      "train: iter 94  trainloss -1.03222  validloss -1.01890±0.00000  bestvalidloss -1.01890  last_update 0\n",
      "train: iter 95  trainloss -1.06791  validloss -1.05361±0.00000  bestvalidloss -1.05361  last_update 0\n",
      "train: iter 96  trainloss -1.10252  validloss -1.10205±0.00000  bestvalidloss -1.10205  last_update 0\n",
      "train: iter 97  trainloss -1.14541  validloss -1.12986±0.00000  bestvalidloss -1.12986  last_update 0\n",
      "train: iter 98  trainloss -1.16755  validloss -1.16235±0.00000  bestvalidloss -1.16235  last_update 0\n",
      "train: iter 99  trainloss -1.20410  validloss -1.21547±0.00000  bestvalidloss -1.21547  last_update 0\n",
      "train: iter 100  trainloss -1.24944  validloss -1.25185±0.00000  bestvalidloss -1.25185  last_update 0\n",
      "train: iter 101  trainloss -1.27739  validloss -1.28995±0.00000  bestvalidloss -1.28995  last_update 0\n",
      "train: iter 102  trainloss -1.31277  validloss -1.30554±0.00000  bestvalidloss -1.30554  last_update 0\n",
      "train: iter 103  trainloss -1.35208  validloss -1.35598±0.00000  bestvalidloss -1.35598  last_update 0\n",
      "train: iter 104  trainloss -1.37035  validloss -1.35392±0.00000  bestvalidloss -1.35598  last_update 1\n",
      "train: iter 105  trainloss -1.40282  validloss -1.40975±0.00000  bestvalidloss -1.40975  last_update 0\n",
      "train: iter 106  trainloss -1.43160  validloss -1.44756±0.00000  bestvalidloss -1.44756  last_update 0\n",
      "train: iter 107  trainloss -1.47353  validloss -1.48640±0.00000  bestvalidloss -1.48640  last_update 0\n",
      "train: iter 108  trainloss -1.49907  validloss -1.50713±0.00000  bestvalidloss -1.50713  last_update 0\n",
      "train: iter 109  trainloss -1.53131  validloss -1.55990±0.00000  bestvalidloss -1.55990  last_update 0\n",
      "train: iter 110  trainloss -1.53540  validloss -1.57853±0.00000  bestvalidloss -1.57853  last_update 0\n",
      "train: iter 111  trainloss -1.57697  validloss -1.64152±0.00000  bestvalidloss -1.64152  last_update 0\n",
      "train: iter 112  trainloss -1.60327  validloss -1.64042±0.00000  bestvalidloss -1.64152  last_update 1\n",
      "train: iter 113  trainloss -1.61213  validloss -1.65700±0.00000  bestvalidloss -1.65700  last_update 0\n",
      "train: iter 114  trainloss -1.66891  validloss -1.71521±0.00000  bestvalidloss -1.71521  last_update 0\n",
      "train: iter 115  trainloss -1.68555  validloss -1.74583±0.00000  bestvalidloss -1.74583  last_update 0\n",
      "train: iter 116  trainloss -1.71634  validloss -1.73924±0.00000  bestvalidloss -1.74583  last_update 1\n",
      "train: iter 117  trainloss -1.74584  validloss -1.80423±0.00000  bestvalidloss -1.80423  last_update 0\n",
      "train: iter 118  trainloss -1.72687  validloss -1.84459±0.00000  bestvalidloss -1.84459  last_update 0\n",
      "train: iter 119  trainloss -1.80500  validloss -1.82391±0.00000  bestvalidloss -1.84459  last_update 1\n",
      "train: iter 120  trainloss -1.82034  validloss -1.87857±0.00000  bestvalidloss -1.87857  last_update 0\n",
      "train: iter 121  trainloss -1.79936  validloss -1.91181±0.00000  bestvalidloss -1.91181  last_update 0\n",
      "train: iter 122  trainloss -1.81210  validloss -1.90873±0.00000  bestvalidloss -1.91181  last_update 1\n",
      "train: iter 123  trainloss -1.85841  validloss -1.89298±0.00000  bestvalidloss -1.91181  last_update 2\n",
      "train: iter 124  trainloss -1.85193  validloss -1.91289±0.00000  bestvalidloss -1.91289  last_update 0\n",
      "train: iter 125  trainloss -1.87420  validloss -2.01324±0.00000  bestvalidloss -2.01324  last_update 0\n",
      "train: iter 126  trainloss -1.91583  validloss -1.98629±0.00000  bestvalidloss -2.01324  last_update 1\n",
      "train: iter 127  trainloss -1.85404  validloss -2.01113±0.00000  bestvalidloss -2.01324  last_update 2\n",
      "train: iter 128  trainloss -1.93014  validloss -1.96358±0.00000  bestvalidloss -2.01324  last_update 3\n",
      "train: iter 129  trainloss -1.88260  validloss -2.02074±0.00000  bestvalidloss -2.02074  last_update 0\n",
      "train: iter 130  trainloss -1.95024  validloss -2.00645±0.00000  bestvalidloss -2.02074  last_update 1\n",
      "train: iter 131  trainloss -1.97074  validloss -2.08909±0.00000  bestvalidloss -2.08909  last_update 0\n",
      "train: iter 132  trainloss -1.89736  validloss -2.03722±0.00000  bestvalidloss -2.08909  last_update 1\n",
      "train: iter 133  trainloss -1.98628  validloss -2.08523±0.00000  bestvalidloss -2.08909  last_update 2\n",
      "train: iter 134  trainloss -1.97527  validloss -2.10774±0.00000  bestvalidloss -2.10774  last_update 0\n",
      "train: iter 135  trainloss -1.92700  validloss -2.08393±0.00000  bestvalidloss -2.10774  last_update 1\n",
      "train: iter 136  trainloss -2.00180  validloss -2.00367±0.00000  bestvalidloss -2.10774  last_update 2\n",
      "train: iter 137  trainloss -1.86824  validloss -2.04724±0.00000  bestvalidloss -2.10774  last_update 3\n",
      "train: iter 138  trainloss -1.93090  validloss -2.19797±0.00000  bestvalidloss -2.19797  last_update 0\n",
      "train: iter 139  trainloss -1.91605  validloss -2.04376±0.00000  bestvalidloss -2.19797  last_update 1\n",
      "train: iter 140  trainloss -1.89982  validloss -2.13231±0.00000  bestvalidloss -2.19797  last_update 2\n",
      "train: iter 141  trainloss -1.91758  validloss -2.16463±0.00000  bestvalidloss -2.19797  last_update 3\n",
      "train: iter 142  trainloss -1.95077  validloss -2.00415±0.00000  bestvalidloss -2.19797  last_update 4\n",
      "train: iter 143  trainloss -2.00445  validloss -2.02241±0.00000  bestvalidloss -2.19797  last_update 5\n",
      "train: iter 144  trainloss -1.86493  validloss -2.13673±0.00000  bestvalidloss -2.19797  last_update 6\n",
      "train: iter 145  trainloss -2.02946  validloss -2.13864±0.00000  bestvalidloss -2.19797  last_update 7\n",
      "train: iter 146  trainloss -1.87983  validloss -2.06561±0.00000  bestvalidloss -2.19797  last_update 8\n",
      "train: iter 147  trainloss -1.91714  validloss -2.15179±0.00000  bestvalidloss -2.19797  last_update 9\n",
      "train: iter 148  trainloss -2.01656  validloss -2.11337±0.00000  bestvalidloss -2.19797  last_update 10\n",
      "train: iter 149  trainloss -1.95892  validloss -2.00753±0.00000  bestvalidloss -2.19797  last_update 11\n",
      "train: iter 150  trainloss -1.93270  validloss -2.12821±0.00000  bestvalidloss -2.19797  last_update 12\n",
      "train: iter 151  trainloss -1.94484  validloss -2.07736±0.00000  bestvalidloss -2.19797  last_update 13\n",
      "train: iter 152  trainloss -1.99287  validloss -1.98168±0.00000  bestvalidloss -2.19797  last_update 14\n",
      "train: iter 153  trainloss -1.94388  validloss -2.12793±0.00000  bestvalidloss -2.19797  last_update 15\n",
      "train: iter 154  trainloss -2.03891  validloss -1.99269±0.00000  bestvalidloss -2.19797  last_update 16\n",
      "train: iter 155  trainloss -1.96466  validloss -2.13565±0.00000  bestvalidloss -2.19797  last_update 17\n",
      "train: iter 156  trainloss -1.94246  validloss -2.05777±0.00000  bestvalidloss -2.19797  last_update 18\n",
      "train: iter 157  trainloss -2.05699  validloss -2.14613±0.00000  bestvalidloss -2.19797  last_update 19\n",
      "train: iter 158  trainloss -1.88527  validloss -2.03700±0.00000  bestvalidloss -2.19797  last_update 20\n",
      "train: iter 159  trainloss -1.93430  validloss -2.11169±0.00000  bestvalidloss -2.19797  last_update 21\n",
      "train: iter 160  trainloss -1.98639  validloss -2.17963±0.00000  bestvalidloss -2.19797  last_update 22\n",
      "train: iter 161  trainloss -1.98252  validloss -2.02848±0.00000  bestvalidloss -2.19797  last_update 23\n",
      "train: iter 162  trainloss -1.93498  validloss -2.12410±0.00000  bestvalidloss -2.19797  last_update 24\n",
      "train: iter 163  trainloss -1.90464  validloss -2.19005±0.00000  bestvalidloss -2.19797  last_update 25\n",
      "train: iter 164  trainloss -2.00423  validloss -2.15384±0.00000  bestvalidloss -2.19797  last_update 26\n",
      "train: iter 165  trainloss -1.94283  validloss -2.04201±0.00000  bestvalidloss -2.19797  last_update 27\n",
      "train: iter 166  trainloss -2.01765  validloss -2.19611±0.00000  bestvalidloss -2.19797  last_update 28\n",
      "train: iter 167  trainloss -1.89509  validloss -2.09236±0.00000  bestvalidloss -2.19797  last_update 29\n",
      "train: iter 168  trainloss -2.02906  validloss -2.31530±0.00000  bestvalidloss -2.31530  last_update 0\n",
      "train: iter 169  trainloss -1.98734  validloss -2.10494±0.00000  bestvalidloss -2.31530  last_update 1\n",
      "train: iter 170  trainloss -1.90212  validloss -2.15457±0.00000  bestvalidloss -2.31530  last_update 2\n",
      "train: iter 171  trainloss -1.92409  validloss -2.29248±0.00000  bestvalidloss -2.31530  last_update 3\n",
      "train: iter 172  trainloss -1.93046  validloss -2.19234±0.00000  bestvalidloss -2.31530  last_update 4\n",
      "train: iter 173  trainloss -1.96581  validloss -2.08905±0.00000  bestvalidloss -2.31530  last_update 5\n",
      "train: iter 174  trainloss -1.93326  validloss -2.09732±0.00000  bestvalidloss -2.31530  last_update 6\n",
      "train: iter 175  trainloss -2.01679  validloss -2.06364±0.00000  bestvalidloss -2.31530  last_update 7\n",
      "train: iter 176  trainloss -1.87570  validloss -2.13561±0.00000  bestvalidloss -2.31530  last_update 8\n",
      "train: iter 177  trainloss -1.90267  validloss -2.23473±0.00000  bestvalidloss -2.31530  last_update 9\n",
      "train: iter 178  trainloss -1.97909  validloss -2.13705±0.00000  bestvalidloss -2.31530  last_update 10\n",
      "train: iter 179  trainloss -1.99303  validloss -2.20769±0.00000  bestvalidloss -2.31530  last_update 11\n",
      "train: iter 180  trainloss -1.86268  validloss -2.15554±0.00000  bestvalidloss -2.31530  last_update 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 181  trainloss -1.99590  validloss -2.04526±0.00000  bestvalidloss -2.31530  last_update 13\n",
      "train: iter 182  trainloss -1.83877  validloss -2.20598±0.00000  bestvalidloss -2.31530  last_update 14\n",
      "train: iter 183  trainloss -1.99617  validloss -2.05426±0.00000  bestvalidloss -2.31530  last_update 15\n",
      "train: iter 184  trainloss -2.00666  validloss -2.13702±0.00000  bestvalidloss -2.31530  last_update 16\n",
      "train: iter 185  trainloss -2.04223  validloss -2.02574±0.00000  bestvalidloss -2.31530  last_update 17\n",
      "train: iter 186  trainloss -1.96468  validloss -2.05436±0.00000  bestvalidloss -2.31530  last_update 18\n",
      "train: iter 187  trainloss -1.86624  validloss -2.21757±0.00000  bestvalidloss -2.31530  last_update 19\n",
      "train: iter 188  trainloss -1.92953  validloss -2.12628±0.00000  bestvalidloss -2.31530  last_update 20\n",
      "train: iter 189  trainloss -1.99711  validloss -2.13110±0.00000  bestvalidloss -2.31530  last_update 21\n",
      "train: iter 190  trainloss -1.97110  validloss -2.09627±0.00000  bestvalidloss -2.31530  last_update 22\n",
      "train: iter 191  trainloss -1.94245  validloss -1.96579±0.00000  bestvalidloss -2.31530  last_update 23\n",
      "train: iter 192  trainloss -1.83918  validloss -2.15270±0.00000  bestvalidloss -2.31530  last_update 24\n",
      "train: iter 193  trainloss -1.97320  validloss -2.11698±0.00000  bestvalidloss -2.31530  last_update 25\n",
      "train: iter 194  trainloss -1.99540  validloss -2.11410±0.00000  bestvalidloss -2.31530  last_update 26\n",
      "train: iter 195  trainloss -2.04875  validloss -2.17198±0.00000  bestvalidloss -2.31530  last_update 27\n",
      "train: iter 196  trainloss -1.84212  validloss -2.19222±0.00000  bestvalidloss -2.31530  last_update 28\n",
      "train: iter 197  trainloss -1.90835  validloss -2.16233±0.00000  bestvalidloss -2.31530  last_update 29\n",
      "train: iter 198  trainloss -1.89695  validloss -2.03735±0.00000  bestvalidloss -2.31530  last_update 30\n",
      "train: iter 199  trainloss -1.90782  validloss -2.16359±0.00000  bestvalidloss -2.31530  last_update 31\n",
      "train: iter 200  trainloss -1.99096  validloss -2.07445±0.00000  bestvalidloss -2.31530  last_update 32\n",
      "train: iter 201  trainloss -1.98996  validloss -2.08813±0.00000  bestvalidloss -2.31530  last_update 33\n",
      "train: iter 202  trainloss -1.96369  validloss -2.06077±0.00000  bestvalidloss -2.31530  last_update 34\n",
      "train: iter 203  trainloss -1.99613  validloss -2.20569±0.00000  bestvalidloss -2.31530  last_update 35\n",
      "train: iter 204  trainloss -2.01411  validloss -2.12813±0.00000  bestvalidloss -2.31530  last_update 36\n",
      "train: iter 205  trainloss -2.00027  validloss -2.19025±0.00000  bestvalidloss -2.31530  last_update 37\n",
      "train: iter 206  trainloss -2.04158  validloss -1.97474±0.00000  bestvalidloss -2.31530  last_update 38\n",
      "train: iter 207  trainloss -2.02262  validloss -2.22341±0.00000  bestvalidloss -2.31530  last_update 39\n",
      "train: iter 208  trainloss -2.01388  validloss -2.07621±0.00000  bestvalidloss -2.31530  last_update 40\n",
      "train: iter 209  trainloss -1.91238  validloss -2.14305±0.00000  bestvalidloss -2.31530  last_update 41\n",
      "train: iter 210  trainloss -1.87640  validloss -2.07024±0.00000  bestvalidloss -2.31530  last_update 42\n",
      "train: iter 211  trainloss -1.89065  validloss -2.06863±0.00000  bestvalidloss -2.31530  last_update 43\n",
      "train: iter 212  trainloss -1.85644  validloss -2.03679±0.00000  bestvalidloss -2.31530  last_update 44\n",
      "train: iter 213  trainloss -1.86374  validloss -2.27889±0.00000  bestvalidloss -2.31530  last_update 45\n",
      "train: iter 214  trainloss -1.98265  validloss -2.13102±0.00000  bestvalidloss -2.31530  last_update 46\n",
      "train: iter 215  trainloss -2.03791  validloss -2.09702±0.00000  bestvalidloss -2.31530  last_update 47\n",
      "train: iter 216  trainloss -1.91769  validloss -2.05560±0.00000  bestvalidloss -2.31530  last_update 48\n",
      "train: iter 217  trainloss -1.93062  validloss -1.93597±0.00000  bestvalidloss -2.31530  last_update 49\n",
      "train: iter 218  trainloss -1.96903  validloss -2.18615±0.00000  bestvalidloss -2.31530  last_update 50\n",
      "train: iter 219  trainloss -1.85640  validloss -2.14078±0.00000  bestvalidloss -2.31530  last_update 51\n",
      "train: iter 220  trainloss -1.93359  validloss -2.19033±0.00000  bestvalidloss -2.31530  last_update 52\n",
      "train: iter 221  trainloss -1.90398  validloss -2.15285±0.00000  bestvalidloss -2.31530  last_update 53\n",
      "train: iter 222  trainloss -1.86928  validloss -2.24666±0.00000  bestvalidloss -2.31530  last_update 54\n",
      "train: iter 223  trainloss -1.86965  validloss -2.05884±0.00000  bestvalidloss -2.31530  last_update 55\n",
      "train: iter 224  trainloss -1.96398  validloss -2.08194±0.00000  bestvalidloss -2.31530  last_update 56\n",
      "train: iter 225  trainloss -1.90529  validloss -2.20876±0.00000  bestvalidloss -2.31530  last_update 57\n",
      "train: iter 226  trainloss -2.00671  validloss -2.16689±0.00000  bestvalidloss -2.31530  last_update 58\n",
      "train: iter 227  trainloss -2.05306  validloss -2.22285±0.00000  bestvalidloss -2.31530  last_update 59\n",
      "train: iter 228  trainloss -1.90891  validloss -2.14022±0.00000  bestvalidloss -2.31530  last_update 60\n",
      "train: iter 229  trainloss -1.96838  validloss -1.96663±0.00000  bestvalidloss -2.31530  last_update 61\n",
      "train: iter 230  trainloss -2.00025  validloss -2.09148±0.00000  bestvalidloss -2.31530  last_update 62\n",
      "train: iter 231  trainloss -1.97757  validloss -2.14914±0.00000  bestvalidloss -2.31530  last_update 63\n",
      "train: iter 232  trainloss -1.93530  validloss -2.06084±0.00000  bestvalidloss -2.31530  last_update 64\n",
      "train: iter 233  trainloss -1.92309  validloss -2.18757±0.00000  bestvalidloss -2.31530  last_update 65\n",
      "train: iter 234  trainloss -1.89328  validloss -2.09238±0.00000  bestvalidloss -2.31530  last_update 66\n",
      "train: iter 235  trainloss -2.04243  validloss -2.07691±0.00000  bestvalidloss -2.31530  last_update 67\n",
      "train: iter 236  trainloss -1.88463  validloss -1.78710±0.00000  bestvalidloss -2.31530  last_update 68\n",
      "train: iter 237  trainloss -2.02741  validloss -2.01670±0.00000  bestvalidloss -2.31530  last_update 69\n",
      "train: iter 238  trainloss -1.91519  validloss -2.19129±0.00000  bestvalidloss -2.31530  last_update 70\n",
      "train: iter 239  trainloss -1.95099  validloss -2.05319±0.00000  bestvalidloss -2.31530  last_update 71\n",
      "train: iter 240  trainloss -1.94935  validloss -2.09071±0.00000  bestvalidloss -2.31530  last_update 72\n",
      "train: iter 241  trainloss -1.93991  validloss -2.15938±0.00000  bestvalidloss -2.31530  last_update 73\n",
      "train: iter 242  trainloss -1.86146  validloss -2.25227±0.00000  bestvalidloss -2.31530  last_update 74\n",
      "train: iter 243  trainloss -1.88902  validloss -2.21940±0.00000  bestvalidloss -2.31530  last_update 75\n",
      "train: iter 244  trainloss -1.82655  validloss -2.28682±0.00000  bestvalidloss -2.31530  last_update 76\n",
      "train: iter 245  trainloss -2.00960  validloss -2.02367±0.00000  bestvalidloss -2.31530  last_update 77\n",
      "train: iter 246  trainloss -1.93550  validloss -2.21568±0.00000  bestvalidloss -2.31530  last_update 78\n",
      "train: iter 247  trainloss -1.86109  validloss -2.10248±0.00000  bestvalidloss -2.31530  last_update 79\n",
      "train: iter 248  trainloss -2.02469  validloss -2.25373±0.00000  bestvalidloss -2.31530  last_update 80\n",
      "train: iter 249  trainloss -1.92637  validloss -2.01119±0.00000  bestvalidloss -2.31530  last_update 81\n",
      "train: iter 250  trainloss -1.97196  validloss -2.05120±0.00000  bestvalidloss -2.31530  last_update 82\n",
      "train: iter 251  trainloss -1.94721  validloss -2.24871±0.00000  bestvalidloss -2.31530  last_update 83\n",
      "train: iter 252  trainloss -2.09242  validloss -2.09543±0.00000  bestvalidloss -2.31530  last_update 84\n",
      "train: iter 253  trainloss -1.96951  validloss -2.20244±0.00000  bestvalidloss -2.31530  last_update 85\n",
      "train: iter 254  trainloss -2.00581  validloss -2.05137±0.00000  bestvalidloss -2.31530  last_update 86\n",
      "train: iter 255  trainloss -1.81309  validloss -1.98158±0.00000  bestvalidloss -2.31530  last_update 87\n",
      "train: iter 256  trainloss -1.94764  validloss -2.14307±0.00000  bestvalidloss -2.31530  last_update 88\n",
      "train: iter 257  trainloss -1.92405  validloss -2.14120±0.00000  bestvalidloss -2.31530  last_update 89\n",
      "train: iter 258  trainloss -2.01640  validloss -2.17376±0.00000  bestvalidloss -2.31530  last_update 90\n",
      "train: iter 259  trainloss -2.02035  validloss -2.13479±0.00000  bestvalidloss -2.31530  last_update 91\n",
      "train: iter 260  trainloss -1.98145  validloss -2.19752±0.00000  bestvalidloss -2.31530  last_update 92\n",
      "train: iter 261  trainloss -1.94855  validloss -1.94755±0.00000  bestvalidloss -2.31530  last_update 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 262  trainloss -1.95419  validloss -2.23417±0.00000  bestvalidloss -2.31530  last_update 94\n",
      "train: iter 263  trainloss -1.91345  validloss -1.93682±0.00000  bestvalidloss -2.31530  last_update 95\n",
      "train: iter 264  trainloss -1.99550  validloss -2.22050±0.00000  bestvalidloss -2.31530  last_update 96\n",
      "train: iter 265  trainloss -1.97605  validloss -2.11204±0.00000  bestvalidloss -2.31530  last_update 97\n",
      "train: iter 266  trainloss -1.98919  validloss -2.10753±0.00000  bestvalidloss -2.31530  last_update 98\n",
      "train: iter 267  trainloss -1.92658  validloss -2.24502±0.00000  bestvalidloss -2.31530  last_update 99\n",
      "train: iter 268  trainloss -1.89092  validloss -2.24182±0.00000  bestvalidloss -2.31530  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.8244, -6.7396], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 129.23136  validloss 140.88033±0.00000  bestvalidloss 140.88033  last_update 0\n",
      "train: iter 1  trainloss 97.11752  validloss 113.59100±0.00000  bestvalidloss 113.59100  last_update 0\n",
      "train: iter 2  trainloss 73.53124  validloss 83.04096±0.00000  bestvalidloss 83.04096  last_update 0\n",
      "train: iter 3  trainloss 58.31380  validloss 64.68049±0.00000  bestvalidloss 64.68049  last_update 0\n",
      "train: iter 4  trainloss 46.82809  validloss 52.01321±0.00000  bestvalidloss 52.01321  last_update 0\n",
      "train: iter 5  trainloss 37.83215  validloss 42.13834±0.00000  bestvalidloss 42.13834  last_update 0\n",
      "train: iter 6  trainloss 30.64631  validloss 34.25031±0.00000  bestvalidloss 34.25031  last_update 0\n",
      "train: iter 7  trainloss 24.74656  validloss 27.85874±0.00000  bestvalidloss 27.85874  last_update 0\n",
      "train: iter 8  trainloss 19.87746  validloss 22.58892±0.00000  bestvalidloss 22.58892  last_update 0\n",
      "train: iter 9  trainloss 15.86784  validloss 18.00702±0.00000  bestvalidloss 18.00702  last_update 0\n",
      "train: iter 10  trainloss 12.59954  validloss 14.85994±0.00000  bestvalidloss 14.85994  last_update 0\n",
      "train: iter 11  trainloss 9.96302  validloss 11.79076±0.00000  bestvalidloss 11.79076  last_update 0\n",
      "train: iter 12  trainloss 7.85180  validloss 9.47705±0.00000  bestvalidloss 9.47705  last_update 0\n",
      "train: iter 13  trainloss 6.18103  validloss 7.86854±0.00000  bestvalidloss 7.86854  last_update 0\n",
      "train: iter 14  trainloss 4.84657  validloss 6.54605±0.00000  bestvalidloss 6.54605  last_update 0\n",
      "train: iter 15  trainloss 3.84082  validloss 5.20568±0.00000  bestvalidloss 5.20568  last_update 0\n",
      "train: iter 16  trainloss 3.04955  validloss 4.26226±0.00000  bestvalidloss 4.26226  last_update 0\n",
      "train: iter 17  trainloss 2.46578  validloss 3.61763±0.00000  bestvalidloss 3.61763  last_update 0\n",
      "train: iter 18  trainloss 2.04815  validloss 3.42335±0.00000  bestvalidloss 3.42335  last_update 0\n",
      "train: iter 19  trainloss 1.71121  validloss 3.06833±0.00000  bestvalidloss 3.06833  last_update 0\n",
      "train: iter 20  trainloss 1.49025  validloss 2.98133±0.00000  bestvalidloss 2.98133  last_update 0\n",
      "train: iter 21  trainloss 1.33439  validloss 2.34997±0.00000  bestvalidloss 2.34997  last_update 0\n",
      "train: iter 22  trainloss 1.21615  validloss 2.94696±0.00000  bestvalidloss 2.34997  last_update 1\n",
      "train: iter 23  trainloss 1.14916  validloss 2.55440±0.00000  bestvalidloss 2.34997  last_update 2\n",
      "train: iter 24  trainloss 1.09898  validloss 2.72303±0.00000  bestvalidloss 2.34997  last_update 3\n",
      "train: iter 25  trainloss 1.06856  validloss 2.40304±0.00000  bestvalidloss 2.34997  last_update 4\n",
      "train: iter 26  trainloss 1.04745  validloss 2.69044±0.00000  bestvalidloss 2.34997  last_update 5\n",
      "train: iter 27  trainloss 1.03454  validloss 2.31650±0.00000  bestvalidloss 2.31650  last_update 0\n",
      "train: iter 28  trainloss 1.01983  validloss 2.63972±0.00000  bestvalidloss 2.31650  last_update 1\n",
      "train: iter 29  trainloss 1.02131  validloss 2.41104±0.00000  bestvalidloss 2.31650  last_update 2\n",
      "train: iter 30  trainloss 1.01535  validloss 2.37675±0.00000  bestvalidloss 2.31650  last_update 3\n",
      "train: iter 31  trainloss 1.03128  validloss 2.34219±0.00000  bestvalidloss 2.31650  last_update 4\n",
      "train: iter 32  trainloss 1.01946  validloss 2.22639±0.00000  bestvalidloss 2.22639  last_update 0\n",
      "train: iter 33  trainloss 1.01517  validloss 2.06445±0.00000  bestvalidloss 2.06445  last_update 0\n",
      "train: iter 34  trainloss 1.01337  validloss 3.03689±0.00000  bestvalidloss 2.06445  last_update 1\n",
      "train: iter 35  trainloss 1.01890  validloss 2.01473±0.00000  bestvalidloss 2.01473  last_update 0\n",
      "train: iter 36  trainloss 1.03132  validloss 2.53222±0.00000  bestvalidloss 2.01473  last_update 1\n",
      "train: iter 37  trainloss 1.01801  validloss 2.66456±0.00000  bestvalidloss 2.01473  last_update 2\n",
      "train: iter 38  trainloss 1.01651  validloss 2.30743±0.00000  bestvalidloss 2.01473  last_update 3\n",
      "train: iter 39  trainloss 1.00941  validloss 2.04892±0.00000  bestvalidloss 2.01473  last_update 4\n",
      "train: iter 40  trainloss 1.01398  validloss 2.83459±0.00000  bestvalidloss 2.01473  last_update 5\n",
      "train: iter 41  trainloss 1.02441  validloss 2.27455±0.00000  bestvalidloss 2.01473  last_update 6\n",
      "train: iter 42  trainloss 1.01895  validloss 2.48514±0.00000  bestvalidloss 2.01473  last_update 7\n",
      "train: iter 43  trainloss 1.02425  validloss 2.50676±0.00000  bestvalidloss 2.01473  last_update 8\n",
      "train: iter 44  trainloss 1.01211  validloss 2.51668±0.00000  bestvalidloss 2.01473  last_update 9\n",
      "train: iter 45  trainloss 1.01628  validloss 2.29164±0.00000  bestvalidloss 2.01473  last_update 10\n",
      "train: iter 46  trainloss 1.01721  validloss 2.63493±0.00000  bestvalidloss 2.01473  last_update 11\n",
      "train: iter 47  trainloss 1.01238  validloss 2.04604±0.00000  bestvalidloss 2.01473  last_update 12\n",
      "train: iter 48  trainloss 1.01710  validloss 2.55982±0.00000  bestvalidloss 2.01473  last_update 13\n",
      "train: iter 49  trainloss 1.02249  validloss 2.63931±0.00000  bestvalidloss 2.01473  last_update 14\n",
      "train: iter 50  trainloss 1.01911  validloss 2.20712±0.00000  bestvalidloss 2.01473  last_update 15\n",
      "train: iter 51  trainloss 1.00743  validloss 2.05700±0.00000  bestvalidloss 2.01473  last_update 16\n",
      "train: iter 52  trainloss 1.01581  validloss 2.01434±0.00000  bestvalidloss 2.01434  last_update 0\n",
      "train: iter 53  trainloss 1.02038  validloss 2.31196±0.00000  bestvalidloss 2.01434  last_update 1\n",
      "train: iter 54  trainloss 1.01366  validloss 2.79493±0.00000  bestvalidloss 2.01434  last_update 2\n",
      "train: iter 55  trainloss 1.02142  validloss 2.85297±0.00000  bestvalidloss 2.01434  last_update 3\n",
      "train: iter 56  trainloss 1.02107  validloss 2.38111±0.00000  bestvalidloss 2.01434  last_update 4\n",
      "train: iter 57  trainloss 1.02902  validloss 2.01632±0.00000  bestvalidloss 2.01434  last_update 5\n",
      "train: iter 58  trainloss 1.03099  validloss 2.76458±0.00000  bestvalidloss 2.01434  last_update 6\n",
      "train: iter 59  trainloss 1.02481  validloss 2.43791±0.00000  bestvalidloss 2.01434  last_update 7\n",
      "train: iter 60  trainloss 1.01883  validloss 2.23307±0.00000  bestvalidloss 2.01434  last_update 8\n",
      "train: iter 61  trainloss 1.02158  validloss 1.92779±0.00000  bestvalidloss 1.92779  last_update 0\n",
      "train: iter 62  trainloss 1.00792  validloss 2.23271±0.00000  bestvalidloss 1.92779  last_update 1\n",
      "train: iter 63  trainloss 1.01222  validloss 1.99590±0.00000  bestvalidloss 1.92779  last_update 2\n",
      "train: iter 64  trainloss 1.01805  validloss 2.30808±0.00000  bestvalidloss 1.92779  last_update 3\n",
      "train: iter 65  trainloss 1.01795  validloss 2.69849±0.00000  bestvalidloss 1.92779  last_update 4\n",
      "train: iter 66  trainloss 1.01700  validloss 2.26845±0.00000  bestvalidloss 1.92779  last_update 5\n",
      "train: iter 67  trainloss 1.01882  validloss 2.80609±0.00000  bestvalidloss 1.92779  last_update 6\n",
      "train: iter 68  trainloss 1.01874  validloss 2.52245±0.00000  bestvalidloss 1.92779  last_update 7\n",
      "train: iter 69  trainloss 1.01226  validloss 2.03579±0.00000  bestvalidloss 1.92779  last_update 8\n",
      "train: iter 70  trainloss 1.01874  validloss 2.49032±0.00000  bestvalidloss 1.92779  last_update 9\n",
      "train: iter 71  trainloss 1.02275  validloss 2.40786±0.00000  bestvalidloss 1.92779  last_update 10\n",
      "train: iter 72  trainloss 1.00997  validloss 2.05027±0.00000  bestvalidloss 1.92779  last_update 11\n",
      "train: iter 73  trainloss 1.01951  validloss 2.26266±0.00000  bestvalidloss 1.92779  last_update 12\n",
      "train: iter 74  trainloss 1.01266  validloss 2.08675±0.00000  bestvalidloss 1.92779  last_update 13\n",
      "train: iter 75  trainloss 1.01088  validloss 2.40270±0.00000  bestvalidloss 1.92779  last_update 14\n",
      "train: iter 76  trainloss 1.01717  validloss 2.20576±0.00000  bestvalidloss 1.92779  last_update 15\n",
      "train: iter 77  trainloss 1.00970  validloss 2.68064±0.00000  bestvalidloss 1.92779  last_update 16\n",
      "train: iter 78  trainloss 1.02094  validloss 2.73505±0.00000  bestvalidloss 1.92779  last_update 17\n",
      "train: iter 79  trainloss 0.98524  validloss 2.06821±0.00000  bestvalidloss 1.92779  last_update 18\n",
      "train: iter 80  trainloss 0.88068  validloss 2.54234±0.00000  bestvalidloss 1.92779  last_update 19\n",
      "train: iter 81  trainloss 0.82166  validloss 2.01095±0.00000  bestvalidloss 1.92779  last_update 20\n",
      "train: iter 82  trainloss 0.82106  validloss 1.99055±0.00000  bestvalidloss 1.92779  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 0.80151  validloss 2.00142±0.00000  bestvalidloss 1.92779  last_update 22\n",
      "train: iter 84  trainloss 0.79293  validloss 2.25895±0.00000  bestvalidloss 1.92779  last_update 23\n",
      "train: iter 85  trainloss 0.78968  validloss 2.19544±0.00000  bestvalidloss 1.92779  last_update 24\n",
      "train: iter 86  trainloss 0.78259  validloss 2.31839±0.00000  bestvalidloss 1.92779  last_update 25\n",
      "train: iter 87  trainloss 0.79663  validloss 2.09779±0.00000  bestvalidloss 1.92779  last_update 26\n",
      "train: iter 88  trainloss 0.78641  validloss 2.47577±0.00000  bestvalidloss 1.92779  last_update 27\n",
      "train: iter 89  trainloss 0.78135  validloss 1.68457±0.00000  bestvalidloss 1.68457  last_update 0\n",
      "train: iter 90  trainloss 0.77475  validloss 1.94497±0.00000  bestvalidloss 1.68457  last_update 1\n",
      "train: iter 91  trainloss 0.77773  validloss 1.94609±0.00000  bestvalidloss 1.68457  last_update 2\n",
      "train: iter 92  trainloss 0.76909  validloss 2.45831±0.00000  bestvalidloss 1.68457  last_update 3\n",
      "train: iter 93  trainloss 0.76687  validloss 2.92056±0.00000  bestvalidloss 1.68457  last_update 4\n",
      "train: iter 94  trainloss 0.76343  validloss 2.41932±0.00000  bestvalidloss 1.68457  last_update 5\n",
      "train: iter 95  trainloss 0.76758  validloss 3.18161±0.00000  bestvalidloss 1.68457  last_update 6\n",
      "train: iter 96  trainloss 0.76800  validloss 2.18288±0.00000  bestvalidloss 1.68457  last_update 7\n",
      "train: iter 97  trainloss 0.76108  validloss 1.91641±0.00000  bestvalidloss 1.68457  last_update 8\n",
      "train: iter 98  trainloss 0.74537  validloss 2.35543±0.00000  bestvalidloss 1.68457  last_update 9\n",
      "train: iter 99  trainloss 0.75904  validloss 2.35013±0.00000  bestvalidloss 1.68457  last_update 10\n",
      "train: iter 100  trainloss 0.75557  validloss 2.35718±0.00000  bestvalidloss 1.68457  last_update 11\n",
      "train: iter 101  trainloss 0.75575  validloss 2.23584±0.00000  bestvalidloss 1.68457  last_update 12\n",
      "train: iter 102  trainloss 0.74228  validloss 2.08803±0.00000  bestvalidloss 1.68457  last_update 13\n",
      "train: iter 103  trainloss 0.73404  validloss 2.22688±0.00000  bestvalidloss 1.68457  last_update 14\n",
      "train: iter 104  trainloss 0.73193  validloss 2.22940±0.00000  bestvalidloss 1.68457  last_update 15\n",
      "train: iter 105  trainloss 0.74059  validloss 1.84138±0.00000  bestvalidloss 1.68457  last_update 16\n",
      "train: iter 106  trainloss 0.72596  validloss 1.93871±0.00000  bestvalidloss 1.68457  last_update 17\n",
      "train: iter 107  trainloss 0.72261  validloss 1.94209±0.00000  bestvalidloss 1.68457  last_update 18\n",
      "train: iter 108  trainloss 0.72064  validloss 2.34956±0.00000  bestvalidloss 1.68457  last_update 19\n",
      "train: iter 109  trainloss 0.72844  validloss 2.22376±0.00000  bestvalidloss 1.68457  last_update 20\n",
      "train: iter 110  trainloss 0.71943  validloss 2.61233±0.00000  bestvalidloss 1.68457  last_update 21\n",
      "train: iter 111  trainloss 0.70461  validloss 2.18279±0.00000  bestvalidloss 1.68457  last_update 22\n",
      "train: iter 112  trainloss 0.71297  validloss 2.16632±0.00000  bestvalidloss 1.68457  last_update 23\n",
      "train: iter 113  trainloss 0.71841  validloss 2.05562±0.00000  bestvalidloss 1.68457  last_update 24\n",
      "train: iter 114  trainloss 0.71178  validloss 2.52253±0.00000  bestvalidloss 1.68457  last_update 25\n",
      "train: iter 115  trainloss 0.71440  validloss 2.01926±0.00000  bestvalidloss 1.68457  last_update 26\n",
      "train: iter 116  trainloss 0.70109  validloss 2.38036±0.00000  bestvalidloss 1.68457  last_update 27\n",
      "train: iter 117  trainloss 0.70531  validloss 1.89618±0.00000  bestvalidloss 1.68457  last_update 28\n",
      "train: iter 118  trainloss 0.70997  validloss 2.14286±0.00000  bestvalidloss 1.68457  last_update 29\n",
      "train: iter 119  trainloss 0.69923  validloss 1.82784±0.00000  bestvalidloss 1.68457  last_update 30\n",
      "train: iter 120  trainloss 0.70174  validloss 2.12444±0.00000  bestvalidloss 1.68457  last_update 31\n",
      "train: iter 121  trainloss 0.70278  validloss 2.52453±0.00000  bestvalidloss 1.68457  last_update 32\n",
      "train: iter 122  trainloss 0.70684  validloss 2.10436±0.00000  bestvalidloss 1.68457  last_update 33\n",
      "train: iter 123  trainloss 0.70473  validloss 1.90157±0.00000  bestvalidloss 1.68457  last_update 34\n",
      "train: iter 124  trainloss 0.70130  validloss 2.19406±0.00000  bestvalidloss 1.68457  last_update 35\n",
      "train: iter 125  trainloss 0.69486  validloss 2.38839±0.00000  bestvalidloss 1.68457  last_update 36\n",
      "train: iter 126  trainloss 0.71049  validloss 1.85771±0.00000  bestvalidloss 1.68457  last_update 37\n",
      "train: iter 127  trainloss 0.70561  validloss 2.21434±0.00000  bestvalidloss 1.68457  last_update 38\n",
      "train: iter 128  trainloss 0.70452  validloss 2.81694±0.00000  bestvalidloss 1.68457  last_update 39\n",
      "train: iter 129  trainloss 0.70486  validloss 2.17160±0.00000  bestvalidloss 1.68457  last_update 40\n",
      "train: iter 130  trainloss 0.70977  validloss 2.09609±0.00000  bestvalidloss 1.68457  last_update 41\n",
      "train: iter 131  trainloss 0.71391  validloss 2.16003±0.00000  bestvalidloss 1.68457  last_update 42\n",
      "train: iter 132  trainloss 0.71092  validloss 2.13873±0.00000  bestvalidloss 1.68457  last_update 43\n",
      "train: iter 133  trainloss 0.70385  validloss 2.20017±0.00000  bestvalidloss 1.68457  last_update 44\n",
      "train: iter 134  trainloss 0.70208  validloss 2.22761±0.00000  bestvalidloss 1.68457  last_update 45\n",
      "train: iter 135  trainloss 0.69855  validloss 2.00866±0.00000  bestvalidloss 1.68457  last_update 46\n",
      "train: iter 136  trainloss 0.71026  validloss 2.26701±0.00000  bestvalidloss 1.68457  last_update 47\n",
      "train: iter 137  trainloss 0.69327  validloss 2.02769±0.00000  bestvalidloss 1.68457  last_update 48\n",
      "train: iter 138  trainloss 0.69343  validloss 2.33066±0.00000  bestvalidloss 1.68457  last_update 49\n",
      "train: iter 139  trainloss 0.69694  validloss 2.41837±0.00000  bestvalidloss 1.68457  last_update 50\n",
      "train: iter 140  trainloss 0.69699  validloss 2.11843±0.00000  bestvalidloss 1.68457  last_update 51\n",
      "train: iter 141  trainloss 0.72011  validloss 2.30693±0.00000  bestvalidloss 1.68457  last_update 52\n",
      "train: iter 142  trainloss 0.70326  validloss 2.28572±0.00000  bestvalidloss 1.68457  last_update 53\n",
      "train: iter 143  trainloss 0.69839  validloss 2.46066±0.00000  bestvalidloss 1.68457  last_update 54\n",
      "train: iter 144  trainloss 0.70027  validloss 2.03498±0.00000  bestvalidloss 1.68457  last_update 55\n",
      "train: iter 145  trainloss 0.69769  validloss 2.03732±0.00000  bestvalidloss 1.68457  last_update 56\n",
      "train: iter 146  trainloss 0.70378  validloss 2.18276±0.00000  bestvalidloss 1.68457  last_update 57\n",
      "train: iter 147  trainloss 0.69479  validloss 2.71130±0.00000  bestvalidloss 1.68457  last_update 58\n",
      "train: iter 148  trainloss 0.69917  validloss 2.05697±0.00000  bestvalidloss 1.68457  last_update 59\n",
      "train: iter 149  trainloss 0.70502  validloss 1.85329±0.00000  bestvalidloss 1.68457  last_update 60\n",
      "train: iter 150  trainloss 0.69285  validloss 1.83449±0.00000  bestvalidloss 1.68457  last_update 61\n",
      "train: iter 151  trainloss 0.69255  validloss 1.89660±0.00000  bestvalidloss 1.68457  last_update 62\n",
      "train: iter 152  trainloss 0.70276  validloss 2.54890±0.00000  bestvalidloss 1.68457  last_update 63\n",
      "train: iter 153  trainloss 0.69094  validloss 2.57737±0.00000  bestvalidloss 1.68457  last_update 64\n",
      "train: iter 154  trainloss 0.69050  validloss 2.20138±0.00000  bestvalidloss 1.68457  last_update 65\n",
      "train: iter 155  trainloss 0.70018  validloss 1.74352±0.00000  bestvalidloss 1.68457  last_update 66\n",
      "train: iter 156  trainloss 0.69550  validloss 2.15242±0.00000  bestvalidloss 1.68457  last_update 67\n",
      "train: iter 157  trainloss 0.69233  validloss 1.83544±0.00000  bestvalidloss 1.68457  last_update 68\n",
      "train: iter 158  trainloss 0.69529  validloss 2.03904±0.00000  bestvalidloss 1.68457  last_update 69\n",
      "train: iter 159  trainloss 0.69120  validloss 1.77199±0.00000  bestvalidloss 1.68457  last_update 70\n",
      "train: iter 160  trainloss 0.69776  validloss 1.86560±0.00000  bestvalidloss 1.68457  last_update 71\n",
      "train: iter 161  trainloss 0.70285  validloss 2.10546±0.00000  bestvalidloss 1.68457  last_update 72\n",
      "train: iter 162  trainloss 0.69413  validloss 1.86915±0.00000  bestvalidloss 1.68457  last_update 73\n",
      "train: iter 163  trainloss 0.69832  validloss 2.17829±0.00000  bestvalidloss 1.68457  last_update 74\n",
      "train: iter 164  trainloss 0.69582  validloss 1.96001±0.00000  bestvalidloss 1.68457  last_update 75\n",
      "train: iter 165  trainloss 0.70101  validloss 2.35155±0.00000  bestvalidloss 1.68457  last_update 76\n",
      "train: iter 166  trainloss 0.69923  validloss 1.67936±0.00000  bestvalidloss 1.67936  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 0.68731  validloss 1.99563±0.00000  bestvalidloss 1.67936  last_update 1\n",
      "train: iter 168  trainloss 0.69236  validloss 1.71217±0.00000  bestvalidloss 1.67936  last_update 2\n",
      "train: iter 169  trainloss 0.68851  validloss 1.76763±0.00000  bestvalidloss 1.67936  last_update 3\n",
      "train: iter 170  trainloss 0.69738  validloss 1.77327±0.00000  bestvalidloss 1.67936  last_update 4\n",
      "train: iter 171  trainloss 0.69577  validloss 2.17994±0.00000  bestvalidloss 1.67936  last_update 5\n",
      "train: iter 172  trainloss 0.69598  validloss 2.17114±0.00000  bestvalidloss 1.67936  last_update 6\n",
      "train: iter 173  trainloss 0.70358  validloss 1.90144±0.00000  bestvalidloss 1.67936  last_update 7\n",
      "train: iter 174  trainloss 0.68966  validloss 2.56003±0.00000  bestvalidloss 1.67936  last_update 8\n",
      "train: iter 175  trainloss 0.68229  validloss 2.28501±0.00000  bestvalidloss 1.67936  last_update 9\n",
      "train: iter 176  trainloss 0.70683  validloss 2.17293±0.00000  bestvalidloss 1.67936  last_update 10\n",
      "train: iter 177  trainloss 0.69269  validloss 2.06773±0.00000  bestvalidloss 1.67936  last_update 11\n",
      "train: iter 178  trainloss 0.69044  validloss 1.93976±0.00000  bestvalidloss 1.67936  last_update 12\n",
      "train: iter 179  trainloss 0.69486  validloss 1.75059±0.00000  bestvalidloss 1.67936  last_update 13\n",
      "train: iter 180  trainloss 0.69740  validloss 2.11064±0.00000  bestvalidloss 1.67936  last_update 14\n",
      "train: iter 181  trainloss 0.70235  validloss 1.89642±0.00000  bestvalidloss 1.67936  last_update 15\n",
      "train: iter 182  trainloss 0.68588  validloss 1.77277±0.00000  bestvalidloss 1.67936  last_update 16\n",
      "train: iter 183  trainloss 0.68667  validloss 1.81661±0.00000  bestvalidloss 1.67936  last_update 17\n",
      "train: iter 184  trainloss 0.68022  validloss 2.59384±0.00000  bestvalidloss 1.67936  last_update 18\n",
      "train: iter 185  trainloss 0.68052  validloss 2.00763±0.00000  bestvalidloss 1.67936  last_update 19\n",
      "train: iter 186  trainloss 0.68946  validloss 2.51353±0.00000  bestvalidloss 1.67936  last_update 20\n",
      "train: iter 187  trainloss 0.68531  validloss 2.16404±0.00000  bestvalidloss 1.67936  last_update 21\n",
      "train: iter 188  trainloss 0.69569  validloss 2.32957±0.00000  bestvalidloss 1.67936  last_update 22\n",
      "train: iter 189  trainloss 0.68961  validloss 2.02454±0.00000  bestvalidloss 1.67936  last_update 23\n",
      "train: iter 190  trainloss 0.69434  validloss 2.21101±0.00000  bestvalidloss 1.67936  last_update 24\n",
      "train: iter 191  trainloss 0.69439  validloss 2.18815±0.00000  bestvalidloss 1.67936  last_update 25\n",
      "train: iter 192  trainloss 0.69245  validloss 2.40854±0.00000  bestvalidloss 1.67936  last_update 26\n",
      "train: iter 193  trainloss 0.69393  validloss 2.23522±0.00000  bestvalidloss 1.67936  last_update 27\n",
      "train: iter 194  trainloss 0.70366  validloss 1.98205±0.00000  bestvalidloss 1.67936  last_update 28\n",
      "train: iter 195  trainloss 0.67911  validloss 1.97847±0.00000  bestvalidloss 1.67936  last_update 29\n",
      "train: iter 196  trainloss 0.69295  validloss 1.83398±0.00000  bestvalidloss 1.67936  last_update 30\n",
      "train: iter 197  trainloss 0.69509  validloss 1.76920±0.00000  bestvalidloss 1.67936  last_update 31\n",
      "train: iter 198  trainloss 0.68397  validloss 2.39923±0.00000  bestvalidloss 1.67936  last_update 32\n",
      "train: iter 199  trainloss 0.69182  validloss 1.66319±0.00000  bestvalidloss 1.66319  last_update 0\n",
      "train: iter 200  trainloss 0.68801  validloss 2.01441±0.00000  bestvalidloss 1.66319  last_update 1\n",
      "train: iter 201  trainloss 0.68659  validloss 2.02374±0.00000  bestvalidloss 1.66319  last_update 2\n",
      "train: iter 202  trainloss 0.68908  validloss 2.10823±0.00000  bestvalidloss 1.66319  last_update 3\n",
      "train: iter 203  trainloss 0.67645  validloss 2.50487±0.00000  bestvalidloss 1.66319  last_update 4\n",
      "train: iter 204  trainloss 0.69335  validloss 2.15599±0.00000  bestvalidloss 1.66319  last_update 5\n",
      "train: iter 205  trainloss 0.68443  validloss 2.12637±0.00000  bestvalidloss 1.66319  last_update 6\n",
      "train: iter 206  trainloss 0.69959  validloss 1.95005±0.00000  bestvalidloss 1.66319  last_update 7\n",
      "train: iter 207  trainloss 0.69539  validloss 1.83618±0.00000  bestvalidloss 1.66319  last_update 8\n",
      "train: iter 208  trainloss 0.68412  validloss 2.21341±0.00000  bestvalidloss 1.66319  last_update 9\n",
      "train: iter 209  trainloss 0.68570  validloss 2.05710±0.00000  bestvalidloss 1.66319  last_update 10\n",
      "train: iter 210  trainloss 0.68127  validloss 2.05962±0.00000  bestvalidloss 1.66319  last_update 11\n",
      "train: iter 211  trainloss 0.68786  validloss 1.94431±0.00000  bestvalidloss 1.66319  last_update 12\n",
      "train: iter 212  trainloss 0.68955  validloss 2.00936±0.00000  bestvalidloss 1.66319  last_update 13\n",
      "train: iter 213  trainloss 0.68853  validloss 2.15765±0.00000  bestvalidloss 1.66319  last_update 14\n",
      "train: iter 214  trainloss 0.69284  validloss 1.95966±0.00000  bestvalidloss 1.66319  last_update 15\n",
      "train: iter 215  trainloss 0.68653  validloss 1.93271±0.00000  bestvalidloss 1.66319  last_update 16\n",
      "train: iter 216  trainloss 0.67585  validloss 1.88135±0.00000  bestvalidloss 1.66319  last_update 17\n",
      "train: iter 217  trainloss 0.67989  validloss 2.07562±0.00000  bestvalidloss 1.66319  last_update 18\n",
      "train: iter 218  trainloss 0.68447  validloss 2.21714±0.00000  bestvalidloss 1.66319  last_update 19\n",
      "train: iter 219  trainloss 0.69039  validloss 2.03802±0.00000  bestvalidloss 1.66319  last_update 20\n",
      "train: iter 220  trainloss 0.69608  validloss 2.34419±0.00000  bestvalidloss 1.66319  last_update 21\n",
      "train: iter 221  trainloss 0.68366  validloss 2.63919±0.00000  bestvalidloss 1.66319  last_update 22\n",
      "train: iter 222  trainloss 0.68891  validloss 1.94052±0.00000  bestvalidloss 1.66319  last_update 23\n",
      "train: iter 223  trainloss 0.68756  validloss 2.29616±0.00000  bestvalidloss 1.66319  last_update 24\n",
      "train: iter 224  trainloss 0.69427  validloss 1.74380±0.00000  bestvalidloss 1.66319  last_update 25\n",
      "train: iter 225  trainloss 0.68486  validloss 2.42065±0.00000  bestvalidloss 1.66319  last_update 26\n",
      "train: iter 226  trainloss 0.68720  validloss 1.96583±0.00000  bestvalidloss 1.66319  last_update 27\n",
      "train: iter 227  trainloss 0.68790  validloss 2.69683±0.00000  bestvalidloss 1.66319  last_update 28\n",
      "train: iter 228  trainloss 0.68676  validloss 1.98019±0.00000  bestvalidloss 1.66319  last_update 29\n",
      "train: iter 229  trainloss 0.68547  validloss 1.80620±0.00000  bestvalidloss 1.66319  last_update 30\n",
      "train: iter 230  trainloss 0.68550  validloss 2.47767±0.00000  bestvalidloss 1.66319  last_update 31\n",
      "train: iter 231  trainloss 0.68551  validloss 2.33750±0.00000  bestvalidloss 1.66319  last_update 32\n",
      "train: iter 232  trainloss 0.68465  validloss 1.95845±0.00000  bestvalidloss 1.66319  last_update 33\n",
      "train: iter 233  trainloss 0.68828  validloss 2.31089±0.00000  bestvalidloss 1.66319  last_update 34\n",
      "train: iter 234  trainloss 0.68145  validloss 2.25340±0.00000  bestvalidloss 1.66319  last_update 35\n",
      "train: iter 235  trainloss 0.67750  validloss 2.52868±0.00000  bestvalidloss 1.66319  last_update 36\n",
      "train: iter 236  trainloss 0.70025  validloss 2.10911±0.00000  bestvalidloss 1.66319  last_update 37\n",
      "train: iter 237  trainloss 0.67832  validloss 2.00255±0.00000  bestvalidloss 1.66319  last_update 38\n",
      "train: iter 238  trainloss 0.68947  validloss 1.99523±0.00000  bestvalidloss 1.66319  last_update 39\n",
      "train: iter 239  trainloss 0.69253  validloss 2.26391±0.00000  bestvalidloss 1.66319  last_update 40\n",
      "train: iter 240  trainloss 0.69438  validloss 2.22325±0.00000  bestvalidloss 1.66319  last_update 41\n",
      "train: iter 241  trainloss 0.67292  validloss 2.02448±0.00000  bestvalidloss 1.66319  last_update 42\n",
      "train: iter 242  trainloss 0.67905  validloss 2.31035±0.00000  bestvalidloss 1.66319  last_update 43\n",
      "train: iter 243  trainloss 0.68201  validloss 2.02154±0.00000  bestvalidloss 1.66319  last_update 44\n",
      "train: iter 244  trainloss 0.67878  validloss 2.31684±0.00000  bestvalidloss 1.66319  last_update 45\n",
      "train: iter 245  trainloss 0.68388  validloss 2.08008±0.00000  bestvalidloss 1.66319  last_update 46\n",
      "train: iter 246  trainloss 0.68704  validloss 2.02135±0.00000  bestvalidloss 1.66319  last_update 47\n",
      "train: iter 247  trainloss 0.68203  validloss 2.25334±0.00000  bestvalidloss 1.66319  last_update 48\n",
      "train: iter 248  trainloss 0.68423  validloss 2.17830±0.00000  bestvalidloss 1.66319  last_update 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 249  trainloss 0.67437  validloss 2.26242±0.00000  bestvalidloss 1.66319  last_update 50\n",
      "train: iter 250  trainloss 0.68884  validloss 2.22298±0.00000  bestvalidloss 1.66319  last_update 51\n",
      "train: iter 251  trainloss 0.67983  validloss 2.12519±0.00000  bestvalidloss 1.66319  last_update 52\n",
      "train: iter 252  trainloss 0.68224  validloss 1.83220±0.00000  bestvalidloss 1.66319  last_update 53\n",
      "train: iter 253  trainloss 0.68929  validloss 1.91906±0.00000  bestvalidloss 1.66319  last_update 54\n",
      "train: iter 254  trainloss 0.68169  validloss 2.07993±0.00000  bestvalidloss 1.66319  last_update 55\n",
      "train: iter 255  trainloss 0.68568  validloss 1.86962±0.00000  bestvalidloss 1.66319  last_update 56\n",
      "train: iter 256  trainloss 0.68464  validloss 1.77390±0.00000  bestvalidloss 1.66319  last_update 57\n",
      "train: iter 257  trainloss 0.67574  validloss 2.68381±0.00000  bestvalidloss 1.66319  last_update 58\n",
      "train: iter 258  trainloss 0.68181  validloss 2.10759±0.00000  bestvalidloss 1.66319  last_update 59\n",
      "train: iter 259  trainloss 0.68480  validloss 1.78623±0.00000  bestvalidloss 1.66319  last_update 60\n",
      "train: iter 260  trainloss 0.68722  validloss 2.13230±0.00000  bestvalidloss 1.66319  last_update 61\n",
      "train: iter 261  trainloss 0.67978  validloss 2.07105±0.00000  bestvalidloss 1.66319  last_update 62\n",
      "train: iter 262  trainloss 0.68749  validloss 2.21148±0.00000  bestvalidloss 1.66319  last_update 63\n",
      "train: iter 263  trainloss 0.68909  validloss 2.37936±0.00000  bestvalidloss 1.66319  last_update 64\n",
      "train: iter 264  trainloss 0.67476  validloss 1.87064±0.00000  bestvalidloss 1.66319  last_update 65\n",
      "train: iter 265  trainloss 0.68451  validloss 1.68227±0.00000  bestvalidloss 1.66319  last_update 66\n",
      "train: iter 266  trainloss 0.67742  validloss 2.16604±0.00000  bestvalidloss 1.66319  last_update 67\n",
      "train: iter 267  trainloss 0.69556  validloss 2.05709±0.00000  bestvalidloss 1.66319  last_update 68\n",
      "train: iter 268  trainloss 0.66797  validloss 2.14723±0.00000  bestvalidloss 1.66319  last_update 69\n",
      "train: iter 269  trainloss 0.67916  validloss 2.31212±0.00000  bestvalidloss 1.66319  last_update 70\n",
      "train: iter 270  trainloss 0.67406  validloss 2.22822±0.00000  bestvalidloss 1.66319  last_update 71\n",
      "train: iter 271  trainloss 0.68097  validloss 2.02456±0.00000  bestvalidloss 1.66319  last_update 72\n",
      "train: iter 272  trainloss 0.68644  validloss 1.91004±0.00000  bestvalidloss 1.66319  last_update 73\n",
      "train: iter 273  trainloss 0.68835  validloss 1.98455±0.00000  bestvalidloss 1.66319  last_update 74\n",
      "train: iter 274  trainloss 0.67853  validloss 2.32347±0.00000  bestvalidloss 1.66319  last_update 75\n",
      "train: iter 275  trainloss 0.67305  validloss 1.78224±0.00000  bestvalidloss 1.66319  last_update 76\n",
      "train: iter 276  trainloss 0.69048  validloss 1.70715±0.00000  bestvalidloss 1.66319  last_update 77\n",
      "train: iter 277  trainloss 0.67758  validloss 1.84120±0.00000  bestvalidloss 1.66319  last_update 78\n",
      "train: iter 278  trainloss 0.67872  validloss 2.00221±0.00000  bestvalidloss 1.66319  last_update 79\n",
      "train: iter 279  trainloss 0.67342  validloss 2.60894±0.00000  bestvalidloss 1.66319  last_update 80\n",
      "train: iter 280  trainloss 0.67243  validloss 2.30265±0.00000  bestvalidloss 1.66319  last_update 81\n",
      "train: iter 281  trainloss 0.68068  validloss 2.54650±0.00000  bestvalidloss 1.66319  last_update 82\n",
      "train: iter 282  trainloss 0.68101  validloss 2.13417±0.00000  bestvalidloss 1.66319  last_update 83\n",
      "train: iter 283  trainloss 0.69023  validloss 2.11745±0.00000  bestvalidloss 1.66319  last_update 84\n",
      "train: iter 284  trainloss 0.69370  validloss 1.84124±0.00000  bestvalidloss 1.66319  last_update 85\n",
      "train: iter 285  trainloss 0.66677  validloss 2.90188±0.00000  bestvalidloss 1.66319  last_update 86\n",
      "train: iter 286  trainloss 0.68397  validloss 1.91956±0.00000  bestvalidloss 1.66319  last_update 87\n",
      "train: iter 287  trainloss 0.67361  validloss 2.33309±0.00000  bestvalidloss 1.66319  last_update 88\n",
      "train: iter 288  trainloss 0.66208  validloss 1.83884±0.00000  bestvalidloss 1.66319  last_update 89\n",
      "train: iter 289  trainloss 0.67735  validloss 1.91200±0.00000  bestvalidloss 1.66319  last_update 90\n",
      "train: iter 290  trainloss 0.67328  validloss 1.88466±0.00000  bestvalidloss 1.66319  last_update 91\n",
      "train: iter 291  trainloss 0.67231  validloss 1.81264±0.00000  bestvalidloss 1.66319  last_update 92\n",
      "train: iter 292  trainloss 0.67392  validloss 1.98593±0.00000  bestvalidloss 1.66319  last_update 93\n",
      "train: iter 293  trainloss 0.68240  validloss 2.01019±0.00000  bestvalidloss 1.66319  last_update 94\n",
      "train: iter 294  trainloss 0.67441  validloss 1.97202±0.00000  bestvalidloss 1.66319  last_update 95\n",
      "train: iter 295  trainloss 0.68721  validloss 1.98379±0.00000  bestvalidloss 1.66319  last_update 96\n",
      "train: iter 296  trainloss 0.68685  validloss 1.98480±0.00000  bestvalidloss 1.66319  last_update 97\n",
      "train: iter 297  trainloss 0.67821  validloss 1.84736±0.00000  bestvalidloss 1.66319  last_update 98\n",
      "train: iter 298  trainloss 0.68207  validloss 1.80264±0.00000  bestvalidloss 1.66319  last_update 99\n",
      "train: iter 299  trainloss 0.68152  validloss 2.39253±0.00000  bestvalidloss 1.66319  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-9.5640)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-4.4099)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.280383794748961\n",
      "tensor([0.4151])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
