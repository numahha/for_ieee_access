{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n",
      "cfg_env cartpole\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)\n",
    "print(\"cfg_env\",cfg_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(2138.1060)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 28264.93153  validloss 304575.92111±0.00000  bestvalidloss 304575.92111  last_update 0\n",
      "train: iter 1  trainloss 3278.07044  validloss 42395.40266±0.00000  bestvalidloss 42395.40266  last_update 0\n",
      "train: iter 2  trainloss 1263.70313  validloss 29539.54360±0.00000  bestvalidloss 29539.54360  last_update 0\n",
      "train: iter 3  trainloss 1104.03384  validloss 3969.45456±0.00000  bestvalidloss 3969.45456  last_update 0\n",
      "train: iter 4  trainloss 933.74903  validloss 2157.14777±0.00000  bestvalidloss 2157.14777  last_update 0\n",
      "train: iter 5  trainloss 814.43292  validloss 1708.20273±0.00000  bestvalidloss 1708.20273  last_update 0\n",
      "train: iter 6  trainloss 773.75078  validloss 1496.20672±0.00000  bestvalidloss 1496.20672  last_update 0\n",
      "train: iter 7  trainloss 687.23287  validloss 1069.27965±0.00000  bestvalidloss 1069.27965  last_update 0\n",
      "train: iter 8  trainloss 636.43444  validloss 964.16371±0.00000  bestvalidloss 964.16371  last_update 0\n",
      "train: iter 9  trainloss 572.05305  validloss 773.90424±0.00000  bestvalidloss 773.90424  last_update 0\n",
      "train: iter 10  trainloss 557.21531  validloss 729.09024±0.00000  bestvalidloss 729.09024  last_update 0\n",
      "train: iter 11  trainloss 584.65557  validloss 621.58345±0.00000  bestvalidloss 621.58345  last_update 0\n",
      "train: iter 12  trainloss 437.88471  validloss 572.72538±0.00000  bestvalidloss 572.72538  last_update 0\n",
      "train: iter 13  trainloss 335.52840  validloss 419.88073±0.00000  bestvalidloss 419.88073  last_update 0\n",
      "train: iter 14  trainloss 289.20270  validloss 315.96208±0.00000  bestvalidloss 315.96208  last_update 0\n",
      "train: iter 15  trainloss 202.42090  validloss 251.24647±0.00000  bestvalidloss 251.24647  last_update 0\n",
      "train: iter 16  trainloss 171.23972  validloss 130.88507±0.00000  bestvalidloss 130.88507  last_update 0\n",
      "train: iter 17  trainloss 124.27534  validloss 81.32673±0.00000  bestvalidloss 81.32673  last_update 0\n",
      "train: iter 18  trainloss 50.35606  validloss 85.12700±0.00000  bestvalidloss 81.32673  last_update 1\n",
      "train: iter 19  trainloss 68.58510  validloss 18.74097±0.00000  bestvalidloss 18.74097  last_update 0\n",
      "train: iter 20  trainloss -22.90273  validloss -33.41274±0.00000  bestvalidloss -33.41274  last_update 0\n",
      "train: iter 21  trainloss -31.37189  validloss -68.80365±0.00000  bestvalidloss -68.80365  last_update 0\n",
      "train: iter 22  trainloss -39.16851  validloss -13.66195±0.00000  bestvalidloss -68.80365  last_update 1\n",
      "train: iter 23  trainloss -129.88973  validloss -147.67264±0.00000  bestvalidloss -147.67264  last_update 0\n",
      "train: iter 24  trainloss -168.48166  validloss -173.05694±0.00000  bestvalidloss -173.05694  last_update 0\n",
      "train: iter 25  trainloss -112.99907  validloss -124.63171±0.00000  bestvalidloss -173.05694  last_update 1\n",
      "train: iter 26  trainloss -168.65137  validloss -166.33356±0.00000  bestvalidloss -173.05694  last_update 2\n",
      "train: iter 27  trainloss -101.20845  validloss -210.64148±0.00000  bestvalidloss -210.64148  last_update 0\n",
      "train: iter 28  trainloss -218.75375  validloss -143.78344±0.00000  bestvalidloss -210.64148  last_update 1\n",
      "train: iter 29  trainloss -189.93441  validloss -166.94016±0.00000  bestvalidloss -210.64148  last_update 2\n",
      "train: iter 30  trainloss -262.36723  validloss -209.82673±0.00000  bestvalidloss -210.64148  last_update 3\n",
      "train: iter 31  trainloss -278.02453  validloss -274.93537±0.00000  bestvalidloss -274.93537  last_update 0\n",
      "train: iter 32  trainloss -303.69692  validloss -322.25388±0.00000  bestvalidloss -322.25388  last_update 0\n",
      "train: iter 33  trainloss -250.78537  validloss -273.00007±0.00000  bestvalidloss -322.25388  last_update 1\n",
      "train: iter 34  trainloss -299.80650  validloss -254.83454±0.00000  bestvalidloss -322.25388  last_update 2\n",
      "train: iter 35  trainloss -258.51667  validloss -315.77888±0.00000  bestvalidloss -322.25388  last_update 3\n",
      "train: iter 36  trainloss -356.11279  validloss -339.30404±0.00000  bestvalidloss -339.30404  last_update 0\n",
      "train: iter 37  trainloss -309.21393  validloss -335.01154±0.00000  bestvalidloss -339.30404  last_update 1\n",
      "train: iter 38  trainloss -336.89286  validloss -268.84257±0.00000  bestvalidloss -339.30404  last_update 2\n",
      "train: iter 39  trainloss -394.72316  validloss -412.09234±0.00000  bestvalidloss -412.09234  last_update 0\n",
      "train: iter 40  trainloss -416.88193  validloss -425.15413±0.00000  bestvalidloss -425.15413  last_update 0\n",
      "train: iter 41  trainloss -365.10737  validloss -415.76327±0.00000  bestvalidloss -425.15413  last_update 1\n",
      "train: iter 42  trainloss -394.22462  validloss -413.82988±0.00000  bestvalidloss -425.15413  last_update 2\n",
      "train: iter 43  trainloss -447.80835  validloss -398.85572±0.00000  bestvalidloss -425.15413  last_update 3\n",
      "train: iter 44  trainloss -366.02542  validloss -361.04911±0.00000  bestvalidloss -425.15413  last_update 4\n",
      "train: iter 45  trainloss -341.23009  validloss -159.19321±0.00000  bestvalidloss -425.15413  last_update 5\n",
      "train: iter 46  trainloss -439.01635  validloss -325.78070±0.00000  bestvalidloss -425.15413  last_update 6\n",
      "train: iter 47  trainloss -478.99128  validloss -451.82564±0.00000  bestvalidloss -451.82564  last_update 0\n",
      "train: iter 48  trainloss -508.24318  validloss -507.09257±0.00000  bestvalidloss -507.09257  last_update 0\n",
      "train: iter 49  trainloss -455.39864  validloss -447.55705±0.00000  bestvalidloss -507.09257  last_update 1\n",
      "train: iter 50  trainloss -444.56692  validloss -531.98057±0.00000  bestvalidloss -531.98057  last_update 0\n",
      "train: iter 51  trainloss -531.39510  validloss -478.62125±0.00000  bestvalidloss -531.98057  last_update 1\n",
      "train: iter 52  trainloss -540.12909  validloss -545.55397±0.00000  bestvalidloss -545.55397  last_update 0\n",
      "train: iter 53  trainloss -521.37631  validloss -554.76582±0.00000  bestvalidloss -554.76582  last_update 0\n",
      "train: iter 54  trainloss -508.69380  validloss -511.60523±0.00000  bestvalidloss -554.76582  last_update 1\n",
      "train: iter 55  trainloss -514.51927  validloss -563.58694±0.00000  bestvalidloss -563.58694  last_update 0\n",
      "train: iter 56  trainloss -554.85600  validloss -564.83328±0.00000  bestvalidloss -564.83328  last_update 0\n",
      "train: iter 57  trainloss -531.95843  validloss -580.43086±0.00000  bestvalidloss -580.43086  last_update 0\n",
      "train: iter 58  trainloss -554.22548  validloss -548.39181±0.00000  bestvalidloss -580.43086  last_update 1\n",
      "train: iter 59  trainloss -451.96603  validloss -602.04900±0.00000  bestvalidloss -602.04900  last_update 0\n",
      "train: iter 60  trainloss -534.23992  validloss -536.26972±0.00000  bestvalidloss -602.04900  last_update 1\n",
      "train: iter 61  trainloss -577.09640  validloss -592.78655±0.00000  bestvalidloss -602.04900  last_update 2\n",
      "train: iter 62  trainloss -612.63391  validloss -612.18393±0.00000  bestvalidloss -612.18393  last_update 0\n",
      "train: iter 63  trainloss -593.88894  validloss -545.69923±0.00000  bestvalidloss -612.18393  last_update 1\n",
      "train: iter 64  trainloss -605.42901  validloss -653.45367±0.00000  bestvalidloss -653.45367  last_update 0\n",
      "train: iter 65  trainloss -630.51563  validloss -603.96640±0.00000  bestvalidloss -653.45367  last_update 1\n",
      "train: iter 66  trainloss -638.55755  validloss -678.24325±0.00000  bestvalidloss -678.24325  last_update 0\n",
      "train: iter 67  trainloss -587.67748  validloss -579.47067±0.00000  bestvalidloss -678.24325  last_update 1\n",
      "train: iter 68  trainloss -613.97076  validloss -567.67219±0.00000  bestvalidloss -678.24325  last_update 2\n",
      "train: iter 69  trainloss -655.79647  validloss -671.18091±0.00000  bestvalidloss -678.24325  last_update 3\n",
      "train: iter 70  trainloss -673.97305  validloss -673.95829±0.00000  bestvalidloss -678.24325  last_update 4\n",
      "train: iter 71  trainloss -645.86115  validloss -713.07746±0.00000  bestvalidloss -713.07746  last_update 0\n",
      "train: iter 72  trainloss -671.24693  validloss -637.36576±0.00000  bestvalidloss -713.07746  last_update 1\n",
      "train: iter 73  trainloss -668.71509  validloss -715.24274±0.00000  bestvalidloss -715.24274  last_update 0\n",
      "train: iter 74  trainloss -680.36222  validloss -682.77056±0.00000  bestvalidloss -715.24274  last_update 1\n",
      "train: iter 75  trainloss -646.17866  validloss -617.92225±0.00000  bestvalidloss -715.24274  last_update 2\n",
      "train: iter 76  trainloss -666.89326  validloss -695.09530±0.00000  bestvalidloss -715.24274  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -712.68491  validloss -555.74461±0.00000  bestvalidloss -715.24274  last_update 4\n",
      "train: iter 78  trainloss -718.15292  validloss -718.77838±0.00000  bestvalidloss -718.77838  last_update 0\n",
      "train: iter 79  trainloss -683.62979  validloss -679.68870±0.00000  bestvalidloss -718.77838  last_update 1\n",
      "train: iter 80  trainloss -641.78623  validloss -573.25523±0.00000  bestvalidloss -718.77838  last_update 2\n",
      "train: iter 81  trainloss -690.79408  validloss -713.00733±0.00000  bestvalidloss -718.77838  last_update 3\n",
      "train: iter 82  trainloss -704.00047  validloss -608.40840±0.00000  bestvalidloss -718.77838  last_update 4\n",
      "train: iter 83  trainloss -753.31485  validloss -739.72317±0.00000  bestvalidloss -739.72317  last_update 0\n",
      "train: iter 84  trainloss -633.17293  validloss -744.40859±0.00000  bestvalidloss -744.40859  last_update 0\n",
      "train: iter 85  trainloss -620.81551  validloss -505.20569±0.00000  bestvalidloss -744.40859  last_update 1\n",
      "train: iter 86  trainloss -687.75818  validloss -707.02802±0.00000  bestvalidloss -744.40859  last_update 2\n",
      "train: iter 87  trainloss -782.38741  validloss -757.34062±0.00000  bestvalidloss -757.34062  last_update 0\n",
      "train: iter 88  trainloss -781.02660  validloss -794.36502±0.00000  bestvalidloss -794.36502  last_update 0\n",
      "train: iter 89  trainloss -669.33012  validloss -765.00978±0.00000  bestvalidloss -794.36502  last_update 1\n",
      "train: iter 90  trainloss -685.06025  validloss -747.24324±0.00000  bestvalidloss -794.36502  last_update 2\n",
      "train: iter 91  trainloss -741.83070  validloss -795.14769±0.00000  bestvalidloss -795.14769  last_update 0\n",
      "train: iter 92  trainloss -736.83557  validloss -798.93715±0.00000  bestvalidloss -798.93715  last_update 0\n",
      "train: iter 93  trainloss -776.96820  validloss -809.99828±0.00000  bestvalidloss -809.99828  last_update 0\n",
      "train: iter 94  trainloss -737.63231  validloss -734.83471±0.00000  bestvalidloss -809.99828  last_update 1\n",
      "train: iter 95  trainloss -728.73705  validloss -759.16183±0.00000  bestvalidloss -809.99828  last_update 2\n",
      "train: iter 96  trainloss -784.25039  validloss -759.99772±0.00000  bestvalidloss -809.99828  last_update 3\n",
      "train: iter 97  trainloss -708.51067  validloss -765.60932±0.00000  bestvalidloss -809.99828  last_update 4\n",
      "train: iter 98  trainloss -781.57789  validloss -833.31577±0.00000  bestvalidloss -833.31577  last_update 0\n",
      "train: iter 99  trainloss -782.22114  validloss -851.54492±0.00000  bestvalidloss -851.54492  last_update 0\n",
      "train: iter 100  trainloss -826.24443  validloss -816.83743±0.00000  bestvalidloss -851.54492  last_update 1\n",
      "train: iter 101  trainloss -761.72057  validloss -885.36502±0.00000  bestvalidloss -885.36502  last_update 0\n",
      "train: iter 102  trainloss -710.62082  validloss -618.11670±0.00000  bestvalidloss -885.36502  last_update 1\n",
      "train: iter 103  trainloss -770.47838  validloss -774.09322±0.00000  bestvalidloss -885.36502  last_update 2\n",
      "train: iter 104  trainloss -796.43393  validloss -795.30065±0.00000  bestvalidloss -885.36502  last_update 3\n",
      "train: iter 105  trainloss -824.90629  validloss -590.67522±0.00000  bestvalidloss -885.36502  last_update 4\n",
      "train: iter 106  trainloss -793.81088  validloss -886.88201±0.00000  bestvalidloss -886.88201  last_update 0\n",
      "train: iter 107  trainloss -724.28922  validloss -346.40637±0.00000  bestvalidloss -886.88201  last_update 1\n",
      "train: iter 108  trainloss -776.30792  validloss -827.01949±0.00000  bestvalidloss -886.88201  last_update 2\n",
      "train: iter 109  trainloss -796.16325  validloss -822.35135±0.00000  bestvalidloss -886.88201  last_update 3\n",
      "train: iter 110  trainloss -854.19607  validloss -866.97376±0.00000  bestvalidloss -886.88201  last_update 4\n",
      "train: iter 111  trainloss -907.96604  validloss -881.31302±0.00000  bestvalidloss -886.88201  last_update 5\n",
      "train: iter 112  trainloss -856.92566  validloss -914.21000±0.00000  bestvalidloss -914.21000  last_update 0\n",
      "train: iter 113  trainloss -889.74755  validloss -824.40110±0.00000  bestvalidloss -914.21000  last_update 1\n",
      "train: iter 114  trainloss -835.04946  validloss -728.73675±0.00000  bestvalidloss -914.21000  last_update 2\n",
      "train: iter 115  trainloss -888.77847  validloss -906.49487±0.00000  bestvalidloss -914.21000  last_update 3\n",
      "train: iter 116  trainloss -820.50060  validloss -518.50704±0.00000  bestvalidloss -914.21000  last_update 4\n",
      "train: iter 117  trainloss -889.76422  validloss -914.27854±0.00000  bestvalidloss -914.27854  last_update 0\n",
      "train: iter 118  trainloss -773.68044  validloss -983.94460±0.00000  bestvalidloss -983.94460  last_update 0\n",
      "train: iter 119  trainloss -767.14788  validloss -697.65376±0.00000  bestvalidloss -983.94460  last_update 1\n",
      "train: iter 120  trainloss -795.02641  validloss -843.62206±0.00000  bestvalidloss -983.94460  last_update 2\n",
      "train: iter 121  trainloss -816.59641  validloss -817.31141±0.00000  bestvalidloss -983.94460  last_update 3\n",
      "train: iter 122  trainloss -906.73596  validloss -910.07539±0.00000  bestvalidloss -983.94460  last_update 4\n",
      "train: iter 123  trainloss -875.85653  validloss -908.22991±0.00000  bestvalidloss -983.94460  last_update 5\n",
      "train: iter 124  trainloss -960.76439  validloss -895.99080±0.00000  bestvalidloss -983.94460  last_update 6\n",
      "train: iter 125  trainloss -911.11578  validloss -908.06266±0.00000  bestvalidloss -983.94460  last_update 7\n",
      "train: iter 126  trainloss -803.67354  validloss -902.22848±0.00000  bestvalidloss -983.94460  last_update 8\n",
      "train: iter 127  trainloss -884.25341  validloss -837.18279±0.00000  bestvalidloss -983.94460  last_update 9\n",
      "train: iter 128  trainloss -879.31158  validloss -900.92083±0.00000  bestvalidloss -983.94460  last_update 10\n",
      "train: iter 129  trainloss -900.08399  validloss -952.18130±0.00000  bestvalidloss -983.94460  last_update 11\n",
      "train: iter 130  trainloss -970.53058  validloss -1021.80833±0.00000  bestvalidloss -1021.80833  last_update 0\n",
      "train: iter 131  trainloss -988.09885  validloss -1030.75127±0.00000  bestvalidloss -1030.75127  last_update 0\n",
      "train: iter 132  trainloss -896.13569  validloss -886.96742±0.00000  bestvalidloss -1030.75127  last_update 1\n",
      "train: iter 133  trainloss -875.55366  validloss -773.88766±0.00000  bestvalidloss -1030.75127  last_update 2\n",
      "train: iter 134  trainloss -695.13711  validloss -764.76210±0.00000  bestvalidloss -1030.75127  last_update 3\n",
      "train: iter 135  trainloss -872.09472  validloss -888.07866±0.00000  bestvalidloss -1030.75127  last_update 4\n",
      "train: iter 136  trainloss -974.29396  validloss -966.35467±0.00000  bestvalidloss -1030.75127  last_update 5\n",
      "train: iter 137  trainloss -985.92086  validloss -640.91667±0.00000  bestvalidloss -1030.75127  last_update 6\n",
      "train: iter 138  trainloss -991.25874  validloss -1013.95011±0.00000  bestvalidloss -1030.75127  last_update 7\n",
      "train: iter 139  trainloss -691.21187  validloss -938.76093±0.00000  bestvalidloss -1030.75127  last_update 8\n",
      "train: iter 140  trainloss -853.93416  validloss -620.66597±0.00000  bestvalidloss -1030.75127  last_update 9\n",
      "train: iter 141  trainloss -971.14241  validloss -998.66197±0.00000  bestvalidloss -1030.75127  last_update 10\n",
      "train: iter 142  trainloss -1064.69764  validloss -1060.02393±0.00000  bestvalidloss -1060.02393  last_update 0\n",
      "train: iter 143  trainloss -917.35185  validloss -1066.62997±0.00000  bestvalidloss -1066.62997  last_update 0\n",
      "train: iter 144  trainloss -428.86708  validloss -1028.11167±0.00000  bestvalidloss -1066.62997  last_update 1\n",
      "train: iter 145  trainloss -797.77596  validloss -523.32878±0.00000  bestvalidloss -1066.62997  last_update 2\n",
      "train: iter 146  trainloss -886.39620  validloss -979.68818±0.00000  bestvalidloss -1066.62997  last_update 3\n",
      "train: iter 147  trainloss -990.58199  validloss -1021.54638±0.00000  bestvalidloss -1066.62997  last_update 4\n",
      "train: iter 148  trainloss -949.35473  validloss -827.50702±0.00000  bestvalidloss -1066.62997  last_update 5\n",
      "train: iter 149  trainloss -1059.21574  validloss -1082.46293±0.00000  bestvalidloss -1082.46293  last_update 0\n",
      "train: iter 150  trainloss -1048.99212  validloss -1089.68830±0.00000  bestvalidloss -1089.68830  last_update 0\n",
      "train: iter 151  trainloss -910.88917  validloss -1010.91798±0.00000  bestvalidloss -1089.68830  last_update 1\n",
      "train: iter 152  trainloss -1020.46755  validloss -1061.44507±0.00000  bestvalidloss -1089.68830  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -1066.73996  validloss -1138.48385±0.00000  bestvalidloss -1138.48385  last_update 0\n",
      "train: iter 154  trainloss -1021.06269  validloss -1049.15496±0.00000  bestvalidloss -1138.48385  last_update 1\n",
      "train: iter 155  trainloss -947.44027  validloss -674.22585±0.00000  bestvalidloss -1138.48385  last_update 2\n",
      "train: iter 156  trainloss -1086.54653  validloss -1086.40996±0.00000  bestvalidloss -1138.48385  last_update 3\n",
      "train: iter 157  trainloss -1091.05707  validloss -1059.92829±0.00000  bestvalidloss -1138.48385  last_update 4\n",
      "train: iter 158  trainloss -992.67836  validloss -1068.95004±0.00000  bestvalidloss -1138.48385  last_update 5\n",
      "train: iter 159  trainloss -1094.59624  validloss -1180.31105±0.00000  bestvalidloss -1180.31105  last_update 0\n",
      "train: iter 160  trainloss -922.04332  validloss -1098.69142±0.00000  bestvalidloss -1180.31105  last_update 1\n",
      "train: iter 161  trainloss -910.62703  validloss -725.85534±0.00000  bestvalidloss -1180.31105  last_update 2\n",
      "train: iter 162  trainloss -997.81573  validloss -1048.23600±0.00000  bestvalidloss -1180.31105  last_update 3\n",
      "train: iter 163  trainloss -992.88061  validloss -1131.63857±0.00000  bestvalidloss -1180.31105  last_update 4\n",
      "train: iter 164  trainloss -934.99726  validloss -683.86902±0.00000  bestvalidloss -1180.31105  last_update 5\n",
      "train: iter 165  trainloss -1104.84836  validloss -1094.96712±0.00000  bestvalidloss -1180.31105  last_update 6\n",
      "train: iter 166  trainloss -1083.84492  validloss -1135.47528±0.00000  bestvalidloss -1180.31105  last_update 7\n",
      "train: iter 167  trainloss -1112.18849  validloss -1139.91035±0.00000  bestvalidloss -1180.31105  last_update 8\n",
      "train: iter 168  trainloss -1047.41605  validloss -1117.37982±0.00000  bestvalidloss -1180.31105  last_update 9\n",
      "train: iter 169  trainloss -868.06887  validloss -1110.56396±0.00000  bestvalidloss -1180.31105  last_update 10\n",
      "train: iter 170  trainloss -1083.74886  validloss -1077.83938±0.00000  bestvalidloss -1180.31105  last_update 11\n",
      "train: iter 171  trainloss -1130.79006  validloss -1174.96315±0.00000  bestvalidloss -1180.31105  last_update 12\n",
      "train: iter 172  trainloss -924.00747  validloss -910.65136±0.00000  bestvalidloss -1180.31105  last_update 13\n",
      "train: iter 173  trainloss -1103.87384  validloss -1114.72305±0.00000  bestvalidloss -1180.31105  last_update 14\n",
      "train: iter 174  trainloss -1156.73737  validloss -1129.83463±0.00000  bestvalidloss -1180.31105  last_update 15\n",
      "train: iter 175  trainloss -1133.91274  validloss -1181.37049±0.00000  bestvalidloss -1181.37049  last_update 0\n",
      "train: iter 176  trainloss -887.85385  validloss -799.22870±0.00000  bestvalidloss -1181.37049  last_update 1\n",
      "train: iter 177  trainloss -1150.35539  validloss -1062.85349±0.00000  bestvalidloss -1181.37049  last_update 2\n",
      "train: iter 178  trainloss -1035.29994  validloss -1098.86453±0.00000  bestvalidloss -1181.37049  last_update 3\n",
      "train: iter 179  trainloss -1135.50603  validloss -1120.45314±0.00000  bestvalidloss -1181.37049  last_update 4\n",
      "train: iter 180  trainloss -1038.75851  validloss -1133.96377±0.00000  bestvalidloss -1181.37049  last_update 5\n",
      "train: iter 181  trainloss -1059.77001  validloss -938.74825±0.00000  bestvalidloss -1181.37049  last_update 6\n",
      "train: iter 182  trainloss -769.00493  validloss -1105.12485±0.00000  bestvalidloss -1181.37049  last_update 7\n",
      "train: iter 183  trainloss -849.60667  validloss -787.49765±0.00000  bestvalidloss -1181.37049  last_update 8\n",
      "train: iter 184  trainloss -1045.73459  validloss -866.12783±0.00000  bestvalidloss -1181.37049  last_update 9\n",
      "train: iter 185  trainloss -1144.97205  validloss -1136.68306±0.00000  bestvalidloss -1181.37049  last_update 10\n",
      "train: iter 186  trainloss -1201.77069  validloss -1201.73236±0.00000  bestvalidloss -1201.73236  last_update 0\n",
      "train: iter 187  trainloss -1115.32770  validloss -1201.97700±0.00000  bestvalidloss -1201.97700  last_update 0\n",
      "train: iter 188  trainloss -1118.43190  validloss -1223.65436±0.00000  bestvalidloss -1223.65436  last_update 0\n",
      "train: iter 189  trainloss -994.61862  validloss -923.26747±0.00000  bestvalidloss -1223.65436  last_update 1\n",
      "train: iter 190  trainloss -1208.68738  validloss -1194.01290±0.00000  bestvalidloss -1223.65436  last_update 2\n",
      "train: iter 191  trainloss -1099.64357  validloss -1222.68897±0.00000  bestvalidloss -1223.65436  last_update 3\n",
      "train: iter 192  trainloss -1125.23874  validloss -1063.28639±0.00000  bestvalidloss -1223.65436  last_update 4\n",
      "train: iter 193  trainloss -1124.24850  validloss -1182.35031±0.00000  bestvalidloss -1223.65436  last_update 5\n",
      "train: iter 194  trainloss -1080.83595  validloss -1009.59245±0.00000  bestvalidloss -1223.65436  last_update 6\n",
      "train: iter 195  trainloss -1187.58522  validloss -1122.57939±0.00000  bestvalidloss -1223.65436  last_update 7\n",
      "train: iter 196  trainloss -1134.39024  validloss -1168.97204±0.00000  bestvalidloss -1223.65436  last_update 8\n",
      "train: iter 197  trainloss -1036.98022  validloss -989.95736±0.00000  bestvalidloss -1223.65436  last_update 9\n",
      "train: iter 198  trainloss -1159.62851  validloss -1117.86936±0.00000  bestvalidloss -1223.65436  last_update 10\n",
      "train: iter 199  trainloss -987.35622  validloss -1212.94171±0.00000  bestvalidloss -1223.65436  last_update 11\n",
      "train: iter 200  trainloss -1202.82177  validloss -1170.65843±0.00000  bestvalidloss -1223.65436  last_update 12\n",
      "train: iter 201  trainloss -1086.62616  validloss -1152.45341±0.00000  bestvalidloss -1223.65436  last_update 13\n",
      "train: iter 202  trainloss -1172.15011  validloss -1238.26458±0.00000  bestvalidloss -1238.26458  last_update 0\n",
      "train: iter 203  trainloss -1125.07972  validloss -990.62057±0.00000  bestvalidloss -1238.26458  last_update 1\n",
      "train: iter 204  trainloss -1166.82299  validloss -1184.35269±0.00000  bestvalidloss -1238.26458  last_update 2\n",
      "train: iter 205  trainloss -1215.92014  validloss -1195.25351±0.00000  bestvalidloss -1238.26458  last_update 3\n",
      "train: iter 206  trainloss -1181.00255  validloss -1218.58008±0.00000  bestvalidloss -1238.26458  last_update 4\n",
      "train: iter 207  trainloss -1217.62070  validloss -1268.16310±0.00000  bestvalidloss -1268.16310  last_update 0\n",
      "train: iter 208  trainloss -1017.44072  validloss -1179.82257±0.00000  bestvalidloss -1268.16310  last_update 1\n",
      "train: iter 209  trainloss -1191.31941  validloss -1226.93542±0.00000  bestvalidloss -1268.16310  last_update 2\n",
      "train: iter 210  trainloss -1124.11155  validloss -1102.98790±0.00000  bestvalidloss -1268.16310  last_update 3\n",
      "train: iter 211  trainloss -1185.28950  validloss -1075.88942±0.00000  bestvalidloss -1268.16310  last_update 4\n",
      "train: iter 212  trainloss -1143.54593  validloss -1163.89918±0.00000  bestvalidloss -1268.16310  last_update 5\n",
      "train: iter 213  trainloss -1144.79788  validloss -956.25841±0.00000  bestvalidloss -1268.16310  last_update 6\n",
      "train: iter 214  trainloss -1236.29128  validloss -1260.37809±0.00000  bestvalidloss -1268.16310  last_update 7\n",
      "train: iter 215  trainloss -985.02217  validloss -1142.84861±0.00000  bestvalidloss -1268.16310  last_update 8\n",
      "train: iter 216  trainloss -1262.56630  validloss -1186.84900±0.00000  bestvalidloss -1268.16310  last_update 9\n",
      "train: iter 217  trainloss -1253.65027  validloss -1283.09403±0.00000  bestvalidloss -1283.09403  last_update 0\n",
      "train: iter 218  trainloss -995.61736  validloss -644.98941±0.00000  bestvalidloss -1283.09403  last_update 1\n",
      "train: iter 219  trainloss -1226.67827  validloss -1025.14488±0.00000  bestvalidloss -1283.09403  last_update 2\n",
      "train: iter 220  trainloss -1044.14973  validloss -1307.99209±0.00000  bestvalidloss -1307.99209  last_update 0\n",
      "train: iter 221  trainloss -1159.71247  validloss -1258.83400±0.00000  bestvalidloss -1307.99209  last_update 1\n",
      "train: iter 222  trainloss -906.98406  validloss -1114.63729±0.00000  bestvalidloss -1307.99209  last_update 2\n",
      "train: iter 223  trainloss -1071.42735  validloss -996.87696±0.00000  bestvalidloss -1307.99209  last_update 3\n",
      "train: iter 224  trainloss -979.97765  validloss -884.59247±0.00000  bestvalidloss -1307.99209  last_update 4\n",
      "train: iter 225  trainloss -1158.75156  validloss -1099.51436±0.00000  bestvalidloss -1307.99209  last_update 5\n",
      "train: iter 226  trainloss -1230.25637  validloss -1165.08670±0.00000  bestvalidloss -1307.99209  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 227  trainloss -1218.97411  validloss -1265.08099±0.00000  bestvalidloss -1307.99209  last_update 7\n",
      "train: iter 228  trainloss -1285.59198  validloss -1180.84347±0.00000  bestvalidloss -1307.99209  last_update 8\n",
      "train: iter 229  trainloss -1200.47626  validloss -1168.23683±0.00000  bestvalidloss -1307.99209  last_update 9\n",
      "train: iter 230  trainloss -1170.18447  validloss -1083.64268±0.00000  bestvalidloss -1307.99209  last_update 10\n",
      "train: iter 231  trainloss -1203.19523  validloss -1212.72442±0.00000  bestvalidloss -1307.99209  last_update 11\n",
      "train: iter 232  trainloss -1167.38683  validloss -1224.22125±0.00000  bestvalidloss -1307.99209  last_update 12\n",
      "train: iter 233  trainloss -1223.82049  validloss -1092.87655±0.00000  bestvalidloss -1307.99209  last_update 13\n",
      "train: iter 234  trainloss -1303.59648  validloss -1273.18269±0.00000  bestvalidloss -1307.99209  last_update 14\n",
      "train: iter 235  trainloss -1130.03645  validloss -1163.62298±0.00000  bestvalidloss -1307.99209  last_update 15\n",
      "train: iter 236  trainloss -1181.09866  validloss -788.90374±0.00000  bestvalidloss -1307.99209  last_update 16\n",
      "train: iter 237  trainloss -998.64028  validloss -1214.17491±0.00000  bestvalidloss -1307.99209  last_update 17\n",
      "train: iter 238  trainloss -1138.28608  validloss -1200.44970±0.00000  bestvalidloss -1307.99209  last_update 18\n",
      "train: iter 239  trainloss -1268.48789  validloss -954.46518±0.00000  bestvalidloss -1307.99209  last_update 19\n",
      "train: iter 240  trainloss -1316.56018  validloss -1255.69240±0.00000  bestvalidloss -1307.99209  last_update 20\n",
      "train: iter 241  trainloss -1279.29614  validloss -1336.28905±0.00000  bestvalidloss -1336.28905  last_update 0\n",
      "train: iter 242  trainloss -1322.03546  validloss -1282.92191±0.00000  bestvalidloss -1336.28905  last_update 1\n",
      "train: iter 243  trainloss -1293.35060  validloss -1319.56735±0.00000  bestvalidloss -1336.28905  last_update 2\n",
      "train: iter 244  trainloss -1243.11326  validloss -1317.18246±0.00000  bestvalidloss -1336.28905  last_update 3\n",
      "train: iter 245  trainloss -1222.82752  validloss -1145.92732±0.00000  bestvalidloss -1336.28905  last_update 4\n",
      "train: iter 246  trainloss -1236.91030  validloss -1145.77727±0.00000  bestvalidloss -1336.28905  last_update 5\n",
      "train: iter 247  trainloss -1206.86659  validloss -1108.21670±0.00000  bestvalidloss -1336.28905  last_update 6\n",
      "train: iter 248  trainloss -1341.97580  validloss -1283.46974±0.00000  bestvalidloss -1336.28905  last_update 7\n",
      "train: iter 249  trainloss -1244.12562  validloss -1041.45280±0.00000  bestvalidloss -1336.28905  last_update 8\n",
      "train: iter 250  trainloss -1128.69222  validloss -1268.84697±0.00000  bestvalidloss -1336.28905  last_update 9\n",
      "train: iter 251  trainloss -1308.44569  validloss -1060.90991±0.00000  bestvalidloss -1336.28905  last_update 10\n",
      "train: iter 252  trainloss -1100.80789  validloss -1356.77217±0.00000  bestvalidloss -1356.77217  last_update 0\n",
      "train: iter 253  trainloss -1186.40819  validloss -1278.37530±0.00000  bestvalidloss -1356.77217  last_update 1\n",
      "train: iter 254  trainloss -1356.83641  validloss -1306.28472±0.00000  bestvalidloss -1356.77217  last_update 2\n",
      "train: iter 255  trainloss -1262.12771  validloss -1383.08918±0.00000  bestvalidloss -1383.08918  last_update 0\n",
      "train: iter 256  trainloss -1296.92611  validloss -1188.05896±0.00000  bestvalidloss -1383.08918  last_update 1\n",
      "train: iter 257  trainloss -1221.77954  validloss -1283.33929±0.00000  bestvalidloss -1383.08918  last_update 2\n",
      "train: iter 258  trainloss -1294.10843  validloss -1300.79136±0.00000  bestvalidloss -1383.08918  last_update 3\n",
      "train: iter 259  trainloss -1365.99362  validloss -1377.89811±0.00000  bestvalidloss -1383.08918  last_update 4\n",
      "train: iter 260  trainloss -946.73183  validloss -1318.81420±0.00000  bestvalidloss -1383.08918  last_update 5\n",
      "train: iter 261  trainloss -854.74732  validloss -363.76513±0.00000  bestvalidloss -1383.08918  last_update 6\n",
      "train: iter 262  trainloss -1149.83809  validloss -985.82684±0.00000  bestvalidloss -1383.08918  last_update 7\n",
      "train: iter 263  trainloss -1231.91729  validloss -1272.47593±0.00000  bestvalidloss -1383.08918  last_update 8\n",
      "train: iter 264  trainloss -1285.06504  validloss -1291.63457±0.00000  bestvalidloss -1383.08918  last_update 9\n",
      "train: iter 265  trainloss -1353.93141  validloss -1270.57842±0.00000  bestvalidloss -1383.08918  last_update 10\n",
      "train: iter 266  trainloss -1270.95442  validloss -1342.89343±0.00000  bestvalidloss -1383.08918  last_update 11\n",
      "train: iter 267  trainloss -1309.79981  validloss -1243.81645±0.00000  bestvalidloss -1383.08918  last_update 12\n",
      "train: iter 268  trainloss -1257.83110  validloss -1337.84561±0.00000  bestvalidloss -1383.08918  last_update 13\n",
      "train: iter 269  trainloss -1373.07919  validloss -1339.13698±0.00000  bestvalidloss -1383.08918  last_update 14\n",
      "train: iter 270  trainloss -1156.80125  validloss -887.41815±0.00000  bestvalidloss -1383.08918  last_update 15\n",
      "train: iter 271  trainloss -1183.06379  validloss -1273.30309±0.00000  bestvalidloss -1383.08918  last_update 16\n",
      "train: iter 272  trainloss -1336.52391  validloss -1315.18470±0.00000  bestvalidloss -1383.08918  last_update 17\n",
      "train: iter 273  trainloss -1384.92108  validloss -1377.86208±0.00000  bestvalidloss -1383.08918  last_update 18\n",
      "train: iter 274  trainloss -1255.88549  validloss -1306.35233±0.00000  bestvalidloss -1383.08918  last_update 19\n",
      "train: iter 275  trainloss -1349.71006  validloss -1151.65673±0.00000  bestvalidloss -1383.08918  last_update 20\n",
      "train: iter 276  trainloss -1339.12891  validloss -1356.44712±0.00000  bestvalidloss -1383.08918  last_update 21\n",
      "train: iter 277  trainloss -1274.39172  validloss -1368.14520±0.00000  bestvalidloss -1383.08918  last_update 22\n",
      "train: iter 278  trainloss -1182.66954  validloss -1285.93245±0.00000  bestvalidloss -1383.08918  last_update 23\n",
      "train: iter 279  trainloss -1356.79963  validloss -1311.26293±0.00000  bestvalidloss -1383.08918  last_update 24\n",
      "train: iter 280  trainloss -1352.28675  validloss -1385.20795±0.00000  bestvalidloss -1385.20795  last_update 0\n",
      "train: iter 281  trainloss -1249.18118  validloss -1219.90804±0.00000  bestvalidloss -1385.20795  last_update 1\n",
      "train: iter 282  trainloss -1363.64457  validloss -1180.84013±0.00000  bestvalidloss -1385.20795  last_update 2\n",
      "train: iter 283  trainloss -1392.60058  validloss -1368.28564±0.00000  bestvalidloss -1385.20795  last_update 3\n",
      "train: iter 284  trainloss -1211.64139  validloss -1196.27151±0.00000  bestvalidloss -1385.20795  last_update 4\n",
      "train: iter 285  trainloss -1336.14165  validloss -1335.76044±0.00000  bestvalidloss -1385.20795  last_update 5\n",
      "train: iter 286  trainloss -1277.04011  validloss -1361.08867±0.00000  bestvalidloss -1385.20795  last_update 6\n",
      "train: iter 287  trainloss -1145.29557  validloss -574.42011±0.00000  bestvalidloss -1385.20795  last_update 7\n",
      "train: iter 288  trainloss -1353.26403  validloss -1365.20216±0.00000  bestvalidloss -1385.20795  last_update 8\n",
      "train: iter 289  trainloss -1351.46941  validloss -1205.15284±0.00000  bestvalidloss -1385.20795  last_update 9\n",
      "train: iter 290  trainloss -1347.24701  validloss -1369.34439±0.00000  bestvalidloss -1385.20795  last_update 10\n",
      "train: iter 291  trainloss -1201.62961  validloss -1251.95481±0.00000  bestvalidloss -1385.20795  last_update 11\n",
      "train: iter 292  trainloss -1297.66096  validloss -1037.42328±0.00000  bestvalidloss -1385.20795  last_update 12\n",
      "train: iter 293  trainloss -1397.87255  validloss -1370.62603±0.00000  bestvalidloss -1385.20795  last_update 13\n",
      "train: iter 294  trainloss -772.34568  validloss -484.18306±0.00000  bestvalidloss -1385.20795  last_update 14\n",
      "train: iter 295  trainloss -1271.72955  validloss -1219.74160±0.00000  bestvalidloss -1385.20795  last_update 15\n",
      "train: iter 296  trainloss -1347.43974  validloss -1321.33445±0.00000  bestvalidloss -1385.20795  last_update 16\n",
      "train: iter 297  trainloss -1242.14851  validloss -1129.41292±0.00000  bestvalidloss -1385.20795  last_update 17\n",
      "train: iter 298  trainloss -1367.57253  validloss -1376.14146±0.00000  bestvalidloss -1385.20795  last_update 18\n",
      "train: iter 299  trainloss -1282.63779  validloss -1326.70397±0.00000  bestvalidloss -1385.20795  last_update 19\n",
      "train: iter 300  trainloss -1414.13990  validloss -1259.72238±0.00000  bestvalidloss -1385.20795  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 301  trainloss -1362.54286  validloss -1412.08897±0.00000  bestvalidloss -1412.08897  last_update 0\n",
      "train: iter 302  trainloss -1436.64196  validloss -1360.77511±0.00000  bestvalidloss -1412.08897  last_update 1\n",
      "train: iter 303  trainloss -1241.57979  validloss -1401.74295±0.00000  bestvalidloss -1412.08897  last_update 2\n",
      "train: iter 304  trainloss -1363.91051  validloss -1341.19203±0.00000  bestvalidloss -1412.08897  last_update 3\n",
      "train: iter 305  trainloss -1409.10383  validloss -1347.87432±0.00000  bestvalidloss -1412.08897  last_update 4\n",
      "train: iter 306  trainloss -1359.63058  validloss -1393.62937±0.00000  bestvalidloss -1412.08897  last_update 5\n",
      "train: iter 307  trainloss -1211.31803  validloss -1088.03430±0.00000  bestvalidloss -1412.08897  last_update 6\n",
      "train: iter 308  trainloss -1420.05215  validloss -1386.56769±0.00000  bestvalidloss -1412.08897  last_update 7\n",
      "train: iter 309  trainloss -1386.20473  validloss -1377.36114±0.00000  bestvalidloss -1412.08897  last_update 8\n",
      "train: iter 310  trainloss -1417.63911  validloss -1341.43058±0.00000  bestvalidloss -1412.08897  last_update 9\n",
      "train: iter 311  trainloss -1210.82838  validloss -1345.34057±0.00000  bestvalidloss -1412.08897  last_update 10\n",
      "train: iter 312  trainloss -1313.27178  validloss -1188.55553±0.00000  bestvalidloss -1412.08897  last_update 11\n",
      "train: iter 313  trainloss -1386.03425  validloss -1402.44720±0.00000  bestvalidloss -1412.08897  last_update 12\n",
      "train: iter 314  trainloss -1333.15211  validloss -1364.12980±0.00000  bestvalidloss -1412.08897  last_update 13\n",
      "train: iter 315  trainloss -1200.31665  validloss -859.52999±0.00000  bestvalidloss -1412.08897  last_update 14\n",
      "train: iter 316  trainloss -1393.56981  validloss -1402.41212±0.00000  bestvalidloss -1412.08897  last_update 15\n",
      "train: iter 317  trainloss -1367.88408  validloss -1327.43859±0.00000  bestvalidloss -1412.08897  last_update 16\n",
      "train: iter 318  trainloss -1460.55773  validloss -1412.10778±0.00000  bestvalidloss -1412.10778  last_update 0\n",
      "train: iter 319  trainloss -1356.12602  validloss -1434.96841±0.00000  bestvalidloss -1434.96841  last_update 0\n",
      "train: iter 320  trainloss -1215.13494  validloss -1210.34591±0.00000  bestvalidloss -1434.96841  last_update 1\n",
      "train: iter 321  trainloss -1440.17409  validloss -1401.23039±0.00000  bestvalidloss -1434.96841  last_update 2\n",
      "train: iter 322  trainloss -1388.82718  validloss -1430.82079±0.00000  bestvalidloss -1434.96841  last_update 3\n",
      "train: iter 323  trainloss -1341.16644  validloss -1313.07937±0.00000  bestvalidloss -1434.96841  last_update 4\n",
      "train: iter 324  trainloss -1323.77680  validloss -1417.73289±0.00000  bestvalidloss -1434.96841  last_update 5\n",
      "train: iter 325  trainloss -1381.82913  validloss -1305.04660±0.00000  bestvalidloss -1434.96841  last_update 6\n",
      "train: iter 326  trainloss -1460.74228  validloss -1419.05090±0.00000  bestvalidloss -1434.96841  last_update 7\n",
      "train: iter 327  trainloss -1408.00421  validloss -1450.20804±0.00000  bestvalidloss -1450.20804  last_update 0\n",
      "train: iter 328  trainloss -1348.16156  validloss -1422.13446±0.00000  bestvalidloss -1450.20804  last_update 1\n",
      "train: iter 329  trainloss -1211.63219  validloss -1406.53968±0.00000  bestvalidloss -1450.20804  last_update 2\n",
      "train: iter 330  trainloss -1345.31709  validloss -1356.62814±0.00000  bestvalidloss -1450.20804  last_update 3\n",
      "train: iter 331  trainloss -1382.39955  validloss -1362.18571±0.00000  bestvalidloss -1450.20804  last_update 4\n",
      "train: iter 332  trainloss -1210.71873  validloss -1250.10205±0.00000  bestvalidloss -1450.20804  last_update 5\n",
      "train: iter 333  trainloss -1447.88638  validloss -1379.15672±0.00000  bestvalidloss -1450.20804  last_update 6\n",
      "train: iter 334  trainloss -1387.68946  validloss -1380.02481±0.00000  bestvalidloss -1450.20804  last_update 7\n",
      "train: iter 335  trainloss -1476.96530  validloss -1459.32451±0.00000  bestvalidloss -1459.32451  last_update 0\n",
      "train: iter 336  trainloss -1412.44471  validloss -1450.87238±0.00000  bestvalidloss -1459.32451  last_update 1\n",
      "train: iter 337  trainloss -1407.11839  validloss -1394.20775±0.00000  bestvalidloss -1459.32451  last_update 2\n",
      "train: iter 338  trainloss -1367.16411  validloss -1451.99433±0.00000  bestvalidloss -1459.32451  last_update 3\n",
      "train: iter 339  trainloss -1327.41062  validloss -1228.75586±0.00000  bestvalidloss -1459.32451  last_update 4\n",
      "train: iter 340  trainloss -1430.98997  validloss -1399.24861±0.00000  bestvalidloss -1459.32451  last_update 5\n",
      "train: iter 341  trainloss -1443.43890  validloss -1449.43841±0.00000  bestvalidloss -1459.32451  last_update 6\n",
      "train: iter 342  trainloss -1269.50464  validloss -1407.43343±0.00000  bestvalidloss -1459.32451  last_update 7\n",
      "train: iter 343  trainloss -1364.45396  validloss -971.36088±0.00000  bestvalidloss -1459.32451  last_update 8\n",
      "train: iter 344  trainloss -1468.15516  validloss -1437.33685±0.00000  bestvalidloss -1459.32451  last_update 9\n",
      "train: iter 345  trainloss -1373.13107  validloss -1483.83593±0.00000  bestvalidloss -1483.83593  last_update 0\n",
      "train: iter 346  trainloss -1319.46051  validloss -727.68349±0.00000  bestvalidloss -1483.83593  last_update 1\n",
      "train: iter 347  trainloss -1405.93117  validloss -1330.43267±0.00000  bestvalidloss -1483.83593  last_update 2\n",
      "train: iter 348  trainloss -1380.05251  validloss -1369.83102±0.00000  bestvalidloss -1483.83593  last_update 3\n",
      "train: iter 349  trainloss -1411.60230  validloss -1105.54416±0.00000  bestvalidloss -1483.83593  last_update 4\n",
      "train: iter 350  trainloss -1457.86248  validloss -1451.97145±0.00000  bestvalidloss -1483.83593  last_update 5\n",
      "train: iter 351  trainloss -1281.29430  validloss -1385.51499±0.00000  bestvalidloss -1483.83593  last_update 6\n",
      "train: iter 352  trainloss -1373.76400  validloss -1398.12876±0.00000  bestvalidloss -1483.83593  last_update 7\n",
      "train: iter 353  trainloss -1422.22681  validloss -1272.06942±0.00000  bestvalidloss -1483.83593  last_update 8\n",
      "train: iter 354  trainloss -1487.26378  validloss -1469.25836±0.00000  bestvalidloss -1483.83593  last_update 9\n",
      "train: iter 355  trainloss -1244.42185  validloss -1394.93588±0.00000  bestvalidloss -1483.83593  last_update 10\n",
      "train: iter 356  trainloss -1286.43072  validloss -1207.82684±0.00000  bestvalidloss -1483.83593  last_update 11\n",
      "train: iter 357  trainloss -1366.53391  validloss -1236.70770±0.00000  bestvalidloss -1483.83593  last_update 12\n",
      "train: iter 358  trainloss -1445.95722  validloss -1300.52451±0.00000  bestvalidloss -1483.83593  last_update 13\n",
      "train: iter 359  trainloss -1385.84982  validloss -1386.55290±0.00000  bestvalidloss -1483.83593  last_update 14\n",
      "train: iter 360  trainloss -1337.34781  validloss -1201.72368±0.00000  bestvalidloss -1483.83593  last_update 15\n",
      "train: iter 361  trainloss -1389.44428  validloss -1388.61180±0.00000  bestvalidloss -1483.83593  last_update 16\n",
      "train: iter 362  trainloss -1406.42268  validloss -1386.24764±0.00000  bestvalidloss -1483.83593  last_update 17\n",
      "train: iter 363  trainloss -1356.41791  validloss -1364.20759±0.00000  bestvalidloss -1483.83593  last_update 18\n",
      "train: iter 364  trainloss -1229.39893  validloss -999.16493±0.00000  bestvalidloss -1483.83593  last_update 19\n",
      "train: iter 365  trainloss -1481.48335  validloss -1398.94316±0.00000  bestvalidloss -1483.83593  last_update 20\n",
      "train: iter 366  trainloss -1478.08619  validloss -1467.99213±0.00000  bestvalidloss -1483.83593  last_update 21\n",
      "train: iter 367  trainloss -1433.51981  validloss -1352.42647±0.00000  bestvalidloss -1483.83593  last_update 22\n",
      "train: iter 368  trainloss -1424.19693  validloss -1281.16257±0.00000  bestvalidloss -1483.83593  last_update 23\n",
      "train: iter 369  trainloss -1493.25960  validloss -1418.45925±0.00000  bestvalidloss -1483.83593  last_update 24\n",
      "train: iter 370  trainloss -1455.54660  validloss -1495.01327±0.00000  bestvalidloss -1495.01327  last_update 0\n",
      "train: iter 371  trainloss -1261.98007  validloss -1314.31000±0.00000  bestvalidloss -1495.01327  last_update 1\n",
      "train: iter 372  trainloss -1411.79814  validloss -1468.55428±0.00000  bestvalidloss -1495.01327  last_update 2\n",
      "train: iter 373  trainloss -1467.42557  validloss -1467.54369±0.00000  bestvalidloss -1495.01327  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 374  trainloss -1380.76761  validloss -1465.84016±0.00000  bestvalidloss -1495.01327  last_update 4\n",
      "train: iter 375  trainloss -1463.25567  validloss -1437.09384±0.00000  bestvalidloss -1495.01327  last_update 5\n",
      "train: iter 376  trainloss -1458.09192  validloss -1484.65135±0.00000  bestvalidloss -1495.01327  last_update 6\n",
      "train: iter 377  trainloss -1393.09930  validloss -1400.56110±0.00000  bestvalidloss -1495.01327  last_update 7\n",
      "train: iter 378  trainloss -1516.98814  validloss -1478.53345±0.00000  bestvalidloss -1495.01327  last_update 8\n",
      "train: iter 379  trainloss -1348.89451  validloss -1445.26235±0.00000  bestvalidloss -1495.01327  last_update 9\n",
      "train: iter 380  trainloss -1268.24179  validloss -1352.61765±0.00000  bestvalidloss -1495.01327  last_update 10\n",
      "train: iter 381  trainloss -1458.08248  validloss -1289.77469±0.00000  bestvalidloss -1495.01327  last_update 11\n",
      "train: iter 382  trainloss -1470.03252  validloss -1473.99331±0.00000  bestvalidloss -1495.01327  last_update 12\n",
      "train: iter 383  trainloss -1444.41570  validloss -1304.29573±0.00000  bestvalidloss -1495.01327  last_update 13\n",
      "train: iter 384  trainloss -1442.64635  validloss -1429.08333±0.00000  bestvalidloss -1495.01327  last_update 14\n",
      "train: iter 385  trainloss -1461.12550  validloss -1421.32369±0.00000  bestvalidloss -1495.01327  last_update 15\n",
      "train: iter 386  trainloss -1485.01893  validloss -1480.48095±0.00000  bestvalidloss -1495.01327  last_update 16\n",
      "train: iter 387  trainloss -1456.09034  validloss -1464.17503±0.00000  bestvalidloss -1495.01327  last_update 17\n",
      "train: iter 388  trainloss -1432.59330  validloss -1382.73723±0.00000  bestvalidloss -1495.01327  last_update 18\n",
      "train: iter 389  trainloss -1445.49327  validloss -1431.87830±0.00000  bestvalidloss -1495.01327  last_update 19\n",
      "train: iter 390  trainloss -1519.57958  validloss -1508.74684±0.00000  bestvalidloss -1508.74684  last_update 0\n",
      "train: iter 391  trainloss -1440.82856  validloss -1490.47255±0.00000  bestvalidloss -1508.74684  last_update 1\n",
      "train: iter 392  trainloss -1476.64147  validloss -1459.41407±0.00000  bestvalidloss -1508.74684  last_update 2\n",
      "train: iter 393  trainloss -1296.93413  validloss -1424.12650±0.00000  bestvalidloss -1508.74684  last_update 3\n",
      "train: iter 394  trainloss -1416.54413  validloss -1385.16011±0.00000  bestvalidloss -1508.74684  last_update 4\n",
      "train: iter 395  trainloss -1430.63492  validloss -1320.98045±0.00000  bestvalidloss -1508.74684  last_update 5\n",
      "train: iter 396  trainloss -1419.91090  validloss -1517.14370±0.00000  bestvalidloss -1517.14370  last_update 0\n",
      "train: iter 397  trainloss -1517.28740  validloss -1391.02382±0.00000  bestvalidloss -1517.14370  last_update 1\n",
      "train: iter 398  trainloss -1435.02130  validloss -1471.87503±0.00000  bestvalidloss -1517.14370  last_update 2\n",
      "train: iter 399  trainloss -1193.49792  validloss -823.12864±0.00000  bestvalidloss -1517.14370  last_update 3\n",
      "train: iter 400  trainloss -1368.04444  validloss -1302.32040±0.00000  bestvalidloss -1517.14370  last_update 4\n",
      "train: iter 401  trainloss -1505.76281  validloss -1468.82534±0.00000  bestvalidloss -1517.14370  last_update 5\n",
      "train: iter 402  trainloss -1499.04617  validloss -1488.22799±0.00000  bestvalidloss -1517.14370  last_update 6\n",
      "train: iter 403  trainloss -1522.87365  validloss -1439.12891±0.00000  bestvalidloss -1517.14370  last_update 7\n",
      "train: iter 404  trainloss -1127.41582  validloss -1430.09293±0.00000  bestvalidloss -1517.14370  last_update 8\n",
      "train: iter 405  trainloss -858.33066  validloss -623.47769±0.00000  bestvalidloss -1517.14370  last_update 9\n",
      "train: iter 406  trainloss -894.50850  validloss -600.00576±0.00000  bestvalidloss -1517.14370  last_update 10\n",
      "train: iter 407  trainloss -915.31689  validloss -498.76850±0.00000  bestvalidloss -1517.14370  last_update 11\n",
      "train: iter 408  trainloss -1241.14935  validloss -1150.72262±0.00000  bestvalidloss -1517.14370  last_update 12\n",
      "train: iter 409  trainloss -1369.18288  validloss -1282.49021±0.00000  bestvalidloss -1517.14370  last_update 13\n",
      "train: iter 410  trainloss -1374.17414  validloss -1360.57925±0.00000  bestvalidloss -1517.14370  last_update 14\n",
      "train: iter 411  trainloss -1450.00376  validloss -1395.36550±0.00000  bestvalidloss -1517.14370  last_update 15\n",
      "train: iter 412  trainloss -1398.42122  validloss -1302.77440±0.00000  bestvalidloss -1517.14370  last_update 16\n",
      "train: iter 413  trainloss -1485.87571  validloss -1426.78244±0.00000  bestvalidloss -1517.14370  last_update 17\n",
      "train: iter 414  trainloss -1486.31789  validloss -1407.19170±0.00000  bestvalidloss -1517.14370  last_update 18\n",
      "train: iter 415  trainloss -1459.21968  validloss -1452.90507±0.00000  bestvalidloss -1517.14370  last_update 19\n",
      "train: iter 416  trainloss -1483.78230  validloss -1316.06962±0.00000  bestvalidloss -1517.14370  last_update 20\n",
      "train: iter 417  trainloss -1505.70560  validloss -1470.68047±0.00000  bestvalidloss -1517.14370  last_update 21\n",
      "train: iter 418  trainloss -1363.68928  validloss -1380.18384±0.00000  bestvalidloss -1517.14370  last_update 22\n",
      "train: iter 419  trainloss -1425.31650  validloss -1280.23170±0.00000  bestvalidloss -1517.14370  last_update 23\n",
      "train: iter 420  trainloss -1524.11060  validloss -1394.53877±0.00000  bestvalidloss -1517.14370  last_update 24\n",
      "train: iter 421  trainloss -1541.13506  validloss -1482.34010±0.00000  bestvalidloss -1517.14370  last_update 25\n",
      "train: iter 422  trainloss -1511.87963  validloss -1522.46295±0.00000  bestvalidloss -1522.46295  last_update 0\n",
      "train: iter 423  trainloss -1417.59315  validloss -1392.78471±0.00000  bestvalidloss -1522.46295  last_update 1\n",
      "train: iter 424  trainloss -1525.50246  validloss -1468.31490±0.00000  bestvalidloss -1522.46295  last_update 2\n",
      "train: iter 425  trainloss -1532.56544  validloss -1499.43401±0.00000  bestvalidloss -1522.46295  last_update 3\n",
      "train: iter 426  trainloss -1515.72728  validloss -1484.04258±0.00000  bestvalidloss -1522.46295  last_update 4\n",
      "train: iter 427  trainloss -1476.51217  validloss -1495.46941±0.00000  bestvalidloss -1522.46295  last_update 5\n",
      "train: iter 428  trainloss -1411.45558  validloss -1324.49824±0.00000  bestvalidloss -1522.46295  last_update 6\n",
      "train: iter 429  trainloss -1502.56712  validloss -1479.08963±0.00000  bestvalidloss -1522.46295  last_update 7\n",
      "train: iter 430  trainloss -1500.20607  validloss -1492.42477±0.00000  bestvalidloss -1522.46295  last_update 8\n",
      "train: iter 431  trainloss -1541.54604  validloss -1529.05458±0.00000  bestvalidloss -1529.05458  last_update 0\n",
      "train: iter 432  trainloss -1490.43404  validloss -1426.73834±0.00000  bestvalidloss -1529.05458  last_update 1\n",
      "train: iter 433  trainloss -1485.38174  validloss -1448.59014±0.00000  bestvalidloss -1529.05458  last_update 2\n",
      "train: iter 434  trainloss -1396.60332  validloss -1244.72382±0.00000  bestvalidloss -1529.05458  last_update 3\n",
      "train: iter 435  trainloss -1540.91493  validloss -1482.73290±0.00000  bestvalidloss -1529.05458  last_update 4\n",
      "train: iter 436  trainloss -1511.32289  validloss -1513.03725±0.00000  bestvalidloss -1529.05458  last_update 5\n",
      "train: iter 437  trainloss -1298.18669  validloss -1164.47640±0.00000  bestvalidloss -1529.05458  last_update 6\n",
      "train: iter 438  trainloss -1472.55137  validloss -1328.01402±0.00000  bestvalidloss -1529.05458  last_update 7\n",
      "train: iter 439  trainloss -1538.88066  validloss -1472.36520±0.00000  bestvalidloss -1529.05458  last_update 8\n",
      "train: iter 440  trainloss -1270.01599  validloss -1504.82094±0.00000  bestvalidloss -1529.05458  last_update 9\n",
      "train: iter 441  trainloss -1518.26291  validloss -1444.50904±0.00000  bestvalidloss -1529.05458  last_update 10\n",
      "train: iter 442  trainloss -1470.40417  validloss -1500.30257±0.00000  bestvalidloss -1529.05458  last_update 11\n",
      "train: iter 443  trainloss -1486.77914  validloss -1383.81465±0.00000  bestvalidloss -1529.05458  last_update 12\n",
      "train: iter 444  trainloss -1461.49001  validloss -1165.63461±0.00000  bestvalidloss -1529.05458  last_update 13\n",
      "train: iter 445  trainloss -1550.11275  validloss -1501.80015±0.00000  bestvalidloss -1529.05458  last_update 14\n",
      "train: iter 446  trainloss -1430.73759  validloss -1494.01175±0.00000  bestvalidloss -1529.05458  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 447  trainloss -1507.98395  validloss -1468.87494±0.00000  bestvalidloss -1529.05458  last_update 16\n",
      "train: iter 448  trainloss -1534.98240  validloss -1464.01059±0.00000  bestvalidloss -1529.05458  last_update 17\n",
      "train: iter 449  trainloss -1519.55887  validloss -1540.09329±0.00000  bestvalidloss -1540.09329  last_update 0\n",
      "train: iter 450  trainloss -1415.89194  validloss -1462.33901±0.00000  bestvalidloss -1540.09329  last_update 1\n",
      "train: iter 451  trainloss -1471.65562  validloss -1259.90891±0.00000  bestvalidloss -1540.09329  last_update 2\n",
      "train: iter 452  trainloss -1318.16663  validloss -1514.10396±0.00000  bestvalidloss -1540.09329  last_update 3\n",
      "train: iter 453  trainloss -1458.91072  validloss -1130.57901±0.00000  bestvalidloss -1540.09329  last_update 4\n",
      "train: iter 454  trainloss -1559.37027  validloss -1456.84762±0.00000  bestvalidloss -1540.09329  last_update 5\n",
      "train: iter 455  trainloss -1582.24564  validloss -1560.44355±0.00000  bestvalidloss -1560.44355  last_update 0\n",
      "train: iter 456  trainloss -1463.77302  validloss -1480.01759±0.00000  bestvalidloss -1560.44355  last_update 1\n",
      "train: iter 457  trainloss -1459.76201  validloss -1355.51370±0.00000  bestvalidloss -1560.44355  last_update 2\n",
      "train: iter 458  trainloss -1546.51937  validloss -1477.73063±0.00000  bestvalidloss -1560.44355  last_update 3\n",
      "train: iter 459  trainloss -1587.21638  validloss -1530.10419±0.00000  bestvalidloss -1560.44355  last_update 4\n",
      "train: iter 460  trainloss -1462.49827  validloss -1546.63894±0.00000  bestvalidloss -1560.44355  last_update 5\n",
      "train: iter 461  trainloss -1455.79326  validloss -1128.00473±0.00000  bestvalidloss -1560.44355  last_update 6\n",
      "train: iter 462  trainloss -1298.02735  validloss -1296.32816±0.00000  bestvalidloss -1560.44355  last_update 7\n",
      "train: iter 463  trainloss -1545.50505  validloss -1448.54901±0.00000  bestvalidloss -1560.44355  last_update 8\n",
      "train: iter 464  trainloss -1563.08272  validloss -1539.90451±0.00000  bestvalidloss -1560.44355  last_update 9\n",
      "train: iter 465  trainloss -1277.41668  validloss -690.39396±0.00000  bestvalidloss -1560.44355  last_update 10\n",
      "train: iter 466  trainloss -1500.81346  validloss -1433.98781±0.00000  bestvalidloss -1560.44355  last_update 11\n",
      "train: iter 467  trainloss -1547.70119  validloss -1479.93316±0.00000  bestvalidloss -1560.44355  last_update 12\n",
      "train: iter 468  trainloss -1548.21231  validloss -1466.15570±0.00000  bestvalidloss -1560.44355  last_update 13\n",
      "train: iter 469  trainloss -1503.46218  validloss -1496.12905±0.00000  bestvalidloss -1560.44355  last_update 14\n",
      "train: iter 470  trainloss -1489.41890  validloss -1428.25741±0.00000  bestvalidloss -1560.44355  last_update 15\n",
      "train: iter 471  trainloss -1479.97627  validloss -1497.93812±0.00000  bestvalidloss -1560.44355  last_update 16\n",
      "train: iter 472  trainloss -1382.48511  validloss -1463.29056±0.00000  bestvalidloss -1560.44355  last_update 17\n",
      "train: iter 473  trainloss -1396.91909  validloss -1182.65206±0.00000  bestvalidloss -1560.44355  last_update 18\n",
      "train: iter 474  trainloss -1548.09177  validloss -1488.44150±0.00000  bestvalidloss -1560.44355  last_update 19\n",
      "train: iter 475  trainloss -1525.90258  validloss -1490.05611±0.00000  bestvalidloss -1560.44355  last_update 20\n",
      "train: iter 476  trainloss -1565.47696  validloss -1511.09981±0.00000  bestvalidloss -1560.44355  last_update 21\n",
      "train: iter 477  trainloss -1541.27183  validloss -1474.90400±0.00000  bestvalidloss -1560.44355  last_update 22\n",
      "train: iter 478  trainloss -1496.75060  validloss -1529.49315±0.00000  bestvalidloss -1560.44355  last_update 23\n",
      "train: iter 479  trainloss -1563.58367  validloss -1536.22185±0.00000  bestvalidloss -1560.44355  last_update 24\n",
      "train: iter 480  trainloss -1477.38478  validloss -1565.41866±0.00000  bestvalidloss -1565.41866  last_update 0\n",
      "train: iter 481  trainloss -1574.65705  validloss -1488.12149±0.00000  bestvalidloss -1565.41866  last_update 1\n",
      "train: iter 482  trainloss -1495.27844  validloss -1364.69923±0.00000  bestvalidloss -1565.41866  last_update 2\n",
      "train: iter 483  trainloss -1521.27764  validloss -1506.13750±0.00000  bestvalidloss -1565.41866  last_update 3\n",
      "train: iter 484  trainloss -1559.57260  validloss -1539.69855±0.00000  bestvalidloss -1565.41866  last_update 4\n",
      "train: iter 485  trainloss -1286.87748  validloss -1508.71670±0.00000  bestvalidloss -1565.41866  last_update 5\n",
      "train: iter 486  trainloss -1452.15086  validloss -1246.00856±0.00000  bestvalidloss -1565.41866  last_update 6\n",
      "train: iter 487  trainloss -1575.04596  validloss -1516.89426±0.00000  bestvalidloss -1565.41866  last_update 7\n",
      "train: iter 488  trainloss -1480.63551  validloss -1528.38328±0.00000  bestvalidloss -1565.41866  last_update 8\n",
      "train: iter 489  trainloss -1527.61790  validloss -1499.65928±0.00000  bestvalidloss -1565.41866  last_update 9\n",
      "train: iter 490  trainloss -1575.49318  validloss -1515.15894±0.00000  bestvalidloss -1565.41866  last_update 10\n",
      "train: iter 491  trainloss -1510.22496  validloss -1560.48588±0.00000  bestvalidloss -1565.41866  last_update 11\n",
      "train: iter 492  trainloss -1534.37637  validloss -1526.33629±0.00000  bestvalidloss -1565.41866  last_update 12\n",
      "train: iter 493  trainloss -1543.67703  validloss -1540.06086±0.00000  bestvalidloss -1565.41866  last_update 13\n",
      "train: iter 494  trainloss -1450.16307  validloss -1562.69026±0.00000  bestvalidloss -1565.41866  last_update 14\n",
      "train: iter 495  trainloss -1549.90449  validloss -1453.78385±0.00000  bestvalidloss -1565.41866  last_update 15\n",
      "train: iter 496  trainloss -1378.47274  validloss -1463.25878±0.00000  bestvalidloss -1565.41866  last_update 16\n",
      "train: iter 497  trainloss -1496.44505  validloss -1359.55894±0.00000  bestvalidloss -1565.41866  last_update 17\n",
      "train: iter 498  trainloss -1580.58183  validloss -1539.34001±0.00000  bestvalidloss -1565.41866  last_update 18\n",
      "train: iter 499  trainloss -1441.40117  validloss -1469.51360±0.00000  bestvalidloss -1565.41866  last_update 19\n",
      "train: iter 500  trainloss -1584.84393  validloss -1525.01074±0.00000  bestvalidloss -1565.41866  last_update 20\n",
      "train: iter 501  trainloss -1540.46872  validloss -1564.04592±0.00000  bestvalidloss -1565.41866  last_update 21\n",
      "train: iter 502  trainloss -1572.72446  validloss -1511.15879±0.00000  bestvalidloss -1565.41866  last_update 22\n",
      "train: iter 503  trainloss -1523.77931  validloss -1410.12394±0.00000  bestvalidloss -1565.41866  last_update 23\n",
      "train: iter 504  trainloss -1338.22046  validloss -1244.02112±0.00000  bestvalidloss -1565.41866  last_update 24\n",
      "train: iter 505  trainloss -1526.58819  validloss -1449.85939±0.00000  bestvalidloss -1565.41866  last_update 25\n",
      "train: iter 506  trainloss -1527.86289  validloss -1497.84827±0.00000  bestvalidloss -1565.41866  last_update 26\n",
      "train: iter 507  trainloss -1571.09235  validloss -1558.22015±0.00000  bestvalidloss -1565.41866  last_update 27\n",
      "train: iter 508  trainloss -1588.38282  validloss -1547.08363±0.00000  bestvalidloss -1565.41866  last_update 28\n",
      "train: iter 509  trainloss -1567.63876  validloss -1565.40213±0.00000  bestvalidloss -1565.41866  last_update 29\n",
      "train: iter 510  trainloss -1511.80951  validloss -1505.35824±0.00000  bestvalidloss -1565.41866  last_update 30\n",
      "train: iter 511  trainloss -1544.56498  validloss -1449.01008±0.00000  bestvalidloss -1565.41866  last_update 31\n",
      "train: iter 512  trainloss -1611.84993  validloss -1560.29641±0.00000  bestvalidloss -1565.41866  last_update 32\n",
      "train: iter 513  trainloss -1378.15170  validloss -1552.58443±0.00000  bestvalidloss -1565.41866  last_update 33\n",
      "train: iter 514  trainloss -1579.89295  validloss -1495.04795±0.00000  bestvalidloss -1565.41866  last_update 34\n",
      "train: iter 515  trainloss -1442.38059  validloss -1563.81331±0.00000  bestvalidloss -1565.41866  last_update 35\n",
      "train: iter 516  trainloss -1202.41226  validloss -976.63088±0.00000  bestvalidloss -1565.41866  last_update 36\n",
      "train: iter 517  trainloss -1509.13417  validloss -1477.25663±0.00000  bestvalidloss -1565.41866  last_update 37\n",
      "train: iter 518  trainloss -1594.96567  validloss -1570.69505±0.00000  bestvalidloss -1570.69505  last_update 0\n",
      "train: iter 519  trainloss -1520.39163  validloss -1195.51860±0.00000  bestvalidloss -1570.69505  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 520  trainloss -1597.70132  validloss -1539.55243±0.00000  bestvalidloss -1570.69505  last_update 2\n",
      "train: iter 521  trainloss -1562.24591  validloss -1589.96924±0.00000  bestvalidloss -1589.96924  last_update 0\n",
      "train: iter 522  trainloss -1372.69984  validloss -1337.28764±0.00000  bestvalidloss -1589.96924  last_update 1\n",
      "train: iter 523  trainloss -1532.31296  validloss -1291.31982±0.00000  bestvalidloss -1589.96924  last_update 2\n",
      "train: iter 524  trainloss -1452.82214  validloss -1417.93068±0.00000  bestvalidloss -1589.96924  last_update 3\n",
      "train: iter 525  trainloss -1572.26221  validloss -1507.94855±0.00000  bestvalidloss -1589.96924  last_update 4\n",
      "train: iter 526  trainloss -1592.78514  validloss -1531.49764±0.00000  bestvalidloss -1589.96924  last_update 5\n",
      "train: iter 527  trainloss -1403.69849  validloss -1549.97500±0.00000  bestvalidloss -1589.96924  last_update 6\n",
      "train: iter 528  trainloss -1436.68476  validloss -1345.74445±0.00000  bestvalidloss -1589.96924  last_update 7\n",
      "train: iter 529  trainloss -1467.04848  validloss -1327.00720±0.00000  bestvalidloss -1589.96924  last_update 8\n",
      "train: iter 530  trainloss -1413.91112  validloss -1480.85408±0.00000  bestvalidloss -1589.96924  last_update 9\n",
      "train: iter 531  trainloss -1503.29438  validloss -1251.26195±0.00000  bestvalidloss -1589.96924  last_update 10\n",
      "train: iter 532  trainloss -1590.87663  validloss -1502.09034±0.00000  bestvalidloss -1589.96924  last_update 11\n",
      "train: iter 533  trainloss -1608.49293  validloss -1568.26667±0.00000  bestvalidloss -1589.96924  last_update 12\n",
      "train: iter 534  trainloss -1314.29440  validloss -1567.87229±0.00000  bestvalidloss -1589.96924  last_update 13\n",
      "train: iter 535  trainloss -1422.18963  validloss -1378.99879±0.00000  bestvalidloss -1589.96924  last_update 14\n",
      "train: iter 536  trainloss -1496.33391  validloss -1363.12151±0.00000  bestvalidloss -1589.96924  last_update 15\n",
      "train: iter 537  trainloss -1493.41784  validloss -1499.19365±0.00000  bestvalidloss -1589.96924  last_update 16\n",
      "train: iter 538  trainloss -1580.12184  validloss -1470.09196±0.00000  bestvalidloss -1589.96924  last_update 17\n",
      "train: iter 539  trainloss -1593.76483  validloss -1557.66802±0.00000  bestvalidloss -1589.96924  last_update 18\n",
      "train: iter 540  trainloss -1435.98872  validloss -1560.99184±0.00000  bestvalidloss -1589.96924  last_update 19\n",
      "train: iter 541  trainloss -1524.45921  validloss -1514.23642±0.00000  bestvalidloss -1589.96924  last_update 20\n",
      "train: iter 542  trainloss -1578.57883  validloss -1434.23107±0.00000  bestvalidloss -1589.96924  last_update 21\n",
      "train: iter 543  trainloss -1511.53143  validloss -1569.28746±0.00000  bestvalidloss -1589.96924  last_update 22\n",
      "train: iter 544  trainloss -1550.29790  validloss -1459.94586±0.00000  bestvalidloss -1589.96924  last_update 23\n",
      "train: iter 545  trainloss -1544.35629  validloss -1522.13710±0.00000  bestvalidloss -1589.96924  last_update 24\n",
      "train: iter 546  trainloss -1574.09489  validloss -1520.35042±0.00000  bestvalidloss -1589.96924  last_update 25\n",
      "train: iter 547  trainloss -1559.62005  validloss -1584.11933±0.00000  bestvalidloss -1589.96924  last_update 26\n",
      "train: iter 548  trainloss -1149.22679  validloss -1567.89176±0.00000  bestvalidloss -1589.96924  last_update 27\n",
      "train: iter 549  trainloss -1388.31907  validloss -1267.86080±0.00000  bestvalidloss -1589.96924  last_update 28\n",
      "train: iter 550  trainloss -1541.17680  validloss -1391.07009±0.00000  bestvalidloss -1589.96924  last_update 29\n",
      "train: iter 551  trainloss -1552.16137  validloss -1513.06212±0.00000  bestvalidloss -1589.96924  last_update 30\n",
      "train: iter 552  trainloss -1552.75352  validloss -1540.96377±0.00000  bestvalidloss -1589.96924  last_update 31\n",
      "train: iter 553  trainloss -1496.48510  validloss -760.58249±0.00000  bestvalidloss -1589.96924  last_update 32\n",
      "train: iter 554  trainloss -1558.95529  validloss -1527.86001±0.00000  bestvalidloss -1589.96924  last_update 33\n",
      "train: iter 555  trainloss -1609.28618  validloss -1481.66948±0.00000  bestvalidloss -1589.96924  last_update 34\n",
      "train: iter 556  trainloss -1516.47281  validloss -1553.41880±0.00000  bestvalidloss -1589.96924  last_update 35\n",
      "train: iter 557  trainloss -1461.57376  validloss -1322.62959±0.00000  bestvalidloss -1589.96924  last_update 36\n",
      "train: iter 558  trainloss -1549.26866  validloss -1462.55081±0.00000  bestvalidloss -1589.96924  last_update 37\n",
      "train: iter 559  trainloss -1559.12065  validloss -1406.59917±0.00000  bestvalidloss -1589.96924  last_update 38\n",
      "train: iter 560  trainloss -1633.48645  validloss -1575.42041±0.00000  bestvalidloss -1589.96924  last_update 39\n",
      "train: iter 561  trainloss -1562.23590  validloss -1590.20621±0.00000  bestvalidloss -1590.20621  last_update 0\n",
      "train: iter 562  trainloss -1590.71271  validloss -1439.61490±0.00000  bestvalidloss -1590.20621  last_update 1\n",
      "train: iter 563  trainloss -1566.39555  validloss -1537.41544±0.00000  bestvalidloss -1590.20621  last_update 2\n",
      "train: iter 564  trainloss -1428.19911  validloss -1503.16934±0.00000  bestvalidloss -1590.20621  last_update 3\n",
      "train: iter 565  trainloss -1536.96073  validloss -1429.61169±0.00000  bestvalidloss -1590.20621  last_update 4\n",
      "train: iter 566  trainloss -1530.32137  validloss -1576.36116±0.00000  bestvalidloss -1590.20621  last_update 5\n",
      "train: iter 567  trainloss -1607.23534  validloss -1482.14122±0.00000  bestvalidloss -1590.20621  last_update 6\n",
      "train: iter 568  trainloss -1618.50261  validloss -1556.57813±0.00000  bestvalidloss -1590.20621  last_update 7\n",
      "train: iter 569  trainloss -1492.73170  validloss -1457.54120±0.00000  bestvalidloss -1590.20621  last_update 8\n",
      "train: iter 570  trainloss -1580.01089  validloss -1278.26045±0.00000  bestvalidloss -1590.20621  last_update 9\n",
      "train: iter 571  trainloss -1490.46299  validloss -1496.84240±0.00000  bestvalidloss -1590.20621  last_update 10\n",
      "train: iter 572  trainloss -1522.53399  validloss -1561.26913±0.00000  bestvalidloss -1590.20621  last_update 11\n",
      "train: iter 573  trainloss -1567.54860  validloss -1584.19285±0.00000  bestvalidloss -1590.20621  last_update 12\n",
      "train: iter 574  trainloss -1548.35702  validloss -1519.81185±0.00000  bestvalidloss -1590.20621  last_update 13\n",
      "train: iter 575  trainloss -1580.21852  validloss -1553.55522±0.00000  bestvalidloss -1590.20621  last_update 14\n",
      "train: iter 576  trainloss -1602.04320  validloss -1576.51615±0.00000  bestvalidloss -1590.20621  last_update 15\n",
      "train: iter 577  trainloss -1521.44959  validloss -1517.21808±0.00000  bestvalidloss -1590.20621  last_update 16\n",
      "train: iter 578  trainloss -1622.59713  validloss -1520.98775±0.00000  bestvalidloss -1590.20621  last_update 17\n",
      "train: iter 579  trainloss -1518.56767  validloss -1581.61964±0.00000  bestvalidloss -1590.20621  last_update 18\n",
      "train: iter 580  trainloss -1582.58987  validloss -1550.54699±0.00000  bestvalidloss -1590.20621  last_update 19\n",
      "train: iter 581  trainloss -1577.53841  validloss -1530.72770±0.00000  bestvalidloss -1590.20621  last_update 20\n",
      "train: iter 582  trainloss -1621.35364  validloss -1557.74837±0.00000  bestvalidloss -1590.20621  last_update 21\n",
      "train: iter 583  trainloss -1630.58117  validloss -1593.50001±0.00000  bestvalidloss -1593.50001  last_update 0\n",
      "train: iter 584  trainloss -1444.83321  validloss -1585.58686±0.00000  bestvalidloss -1593.50001  last_update 1\n",
      "train: iter 585  trainloss -1545.25230  validloss -1489.06488±0.00000  bestvalidloss -1593.50001  last_update 2\n",
      "train: iter 586  trainloss -1624.57332  validloss -1555.69872±0.00000  bestvalidloss -1593.50001  last_update 3\n",
      "train: iter 587  trainloss -1611.31873  validloss -1592.21753±0.00000  bestvalidloss -1593.50001  last_update 4\n",
      "train: iter 588  trainloss -1594.23189  validloss -1556.90888±0.00000  bestvalidloss -1593.50001  last_update 5\n",
      "train: iter 589  trainloss -1472.35783  validloss -1449.52983±0.00000  bestvalidloss -1593.50001  last_update 6\n",
      "train: iter 590  trainloss -1551.95373  validloss -1444.47532±0.00000  bestvalidloss -1593.50001  last_update 7\n",
      "train: iter 591  trainloss -1614.69038  validloss -1581.71566±0.00000  bestvalidloss -1593.50001  last_update 8\n",
      "train: iter 592  trainloss -1623.68116  validloss -1567.11631±0.00000  bestvalidloss -1593.50001  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 593  trainloss -1525.77433  validloss -1576.59041±0.00000  bestvalidloss -1593.50001  last_update 10\n",
      "train: iter 594  trainloss -1573.66131  validloss -1489.57971±0.00000  bestvalidloss -1593.50001  last_update 11\n",
      "train: iter 595  trainloss -1564.94655  validloss -1393.67944±0.00000  bestvalidloss -1593.50001  last_update 12\n",
      "train: iter 596  trainloss -1564.89907  validloss -1514.77643±0.00000  bestvalidloss -1593.50001  last_update 13\n",
      "train: iter 597  trainloss -1626.99209  validloss -1567.40285±0.00000  bestvalidloss -1593.50001  last_update 14\n",
      "train: iter 598  trainloss -1641.25254  validloss -1602.77770±0.00000  bestvalidloss -1602.77770  last_update 0\n",
      "train: iter 599  trainloss -1319.15478  validloss -1582.88761±0.00000  bestvalidloss -1602.77770  last_update 1\n",
      "train: iter 600  trainloss -1577.77648  validloss -1439.28248±0.00000  bestvalidloss -1602.77770  last_update 2\n",
      "train: iter 601  trainloss -1562.75137  validloss -1527.19538±0.00000  bestvalidloss -1602.77770  last_update 3\n",
      "train: iter 602  trainloss -1610.35302  validloss -1537.90190±0.00000  bestvalidloss -1602.77770  last_update 4\n",
      "train: iter 603  trainloss -1498.44778  validloss -1572.41213±0.00000  bestvalidloss -1602.77770  last_update 5\n",
      "train: iter 604  trainloss -1552.81783  validloss -1512.87681±0.00000  bestvalidloss -1602.77770  last_update 6\n",
      "train: iter 605  trainloss -1586.12387  validloss -1564.92628±0.00000  bestvalidloss -1602.77770  last_update 7\n",
      "train: iter 606  trainloss -1552.98289  validloss -1490.63002±0.00000  bestvalidloss -1602.77770  last_update 8\n",
      "train: iter 607  trainloss -1389.12901  validloss -1478.77127±0.00000  bestvalidloss -1602.77770  last_update 9\n",
      "train: iter 608  trainloss -1513.74563  validloss -1344.64052±0.00000  bestvalidloss -1602.77770  last_update 10\n",
      "train: iter 609  trainloss -1016.27323  validloss -1509.54018±0.00000  bestvalidloss -1602.77770  last_update 11\n",
      "train: iter 610  trainloss -1449.12150  validloss -1295.34757±0.00000  bestvalidloss -1602.77770  last_update 12\n",
      "train: iter 611  trainloss -1485.58878  validloss -1417.84296±0.00000  bestvalidloss -1602.77770  last_update 13\n",
      "train: iter 612  trainloss -1570.21842  validloss -1439.47727±0.00000  bestvalidloss -1602.77770  last_update 14\n",
      "train: iter 613  trainloss -1570.26292  validloss -1534.62026±0.00000  bestvalidloss -1602.77770  last_update 15\n",
      "train: iter 614  trainloss -1444.75828  validloss -1525.37679±0.00000  bestvalidloss -1602.77770  last_update 16\n",
      "train: iter 615  trainloss -1584.34455  validloss -1391.78386±0.00000  bestvalidloss -1602.77770  last_update 17\n",
      "train: iter 616  trainloss -1604.29908  validloss -1564.18716±0.00000  bestvalidloss -1602.77770  last_update 18\n",
      "train: iter 617  trainloss -1629.65207  validloss -1590.80234±0.00000  bestvalidloss -1602.77770  last_update 19\n",
      "train: iter 618  trainloss -1651.51337  validloss -1591.00724±0.00000  bestvalidloss -1602.77770  last_update 20\n",
      "train: iter 619  trainloss -1382.84578  validloss -1029.09163±0.00000  bestvalidloss -1602.77770  last_update 21\n",
      "train: iter 620  trainloss -1575.58621  validloss -1403.98118±0.00000  bestvalidloss -1602.77770  last_update 22\n",
      "train: iter 621  trainloss -1657.50689  validloss -1589.24138±0.00000  bestvalidloss -1602.77770  last_update 23\n",
      "train: iter 622  trainloss -1637.73318  validloss -1575.65233±0.00000  bestvalidloss -1602.77770  last_update 24\n",
      "train: iter 623  trainloss -1559.34984  validloss -1618.64623±0.00000  bestvalidloss -1618.64623  last_update 0\n",
      "train: iter 624  trainloss -1356.86242  validloss -1488.83640±0.00000  bestvalidloss -1618.64623  last_update 1\n",
      "train: iter 625  trainloss -1609.71941  validloss -1549.73776±0.00000  bestvalidloss -1618.64623  last_update 2\n",
      "train: iter 626  trainloss -1643.85116  validloss -1610.64063±0.00000  bestvalidloss -1618.64623  last_update 3\n",
      "train: iter 627  trainloss -1604.47954  validloss -1616.98136±0.00000  bestvalidloss -1618.64623  last_update 4\n",
      "train: iter 628  trainloss -1159.73913  validloss -922.41954±0.00000  bestvalidloss -1618.64623  last_update 5\n",
      "train: iter 629  trainloss -1551.18162  validloss -1361.91348±0.00000  bestvalidloss -1618.64623  last_update 6\n",
      "train: iter 630  trainloss -1632.78271  validloss -1558.61220±0.00000  bestvalidloss -1618.64623  last_update 7\n",
      "train: iter 631  trainloss -1590.70793  validloss -1522.23890±0.00000  bestvalidloss -1618.64623  last_update 8\n",
      "train: iter 632  trainloss -1623.22644  validloss -1579.59617±0.00000  bestvalidloss -1618.64623  last_update 9\n",
      "train: iter 633  trainloss -1464.87819  validloss -1591.46820±0.00000  bestvalidloss -1618.64623  last_update 10\n",
      "train: iter 634  trainloss -1570.17352  validloss -1554.84611±0.00000  bestvalidloss -1618.64623  last_update 11\n",
      "train: iter 635  trainloss -1620.77710  validloss -1569.07215±0.00000  bestvalidloss -1618.64623  last_update 12\n",
      "train: iter 636  trainloss -1578.81441  validloss -1508.77767±0.00000  bestvalidloss -1618.64623  last_update 13\n",
      "train: iter 637  trainloss -1619.98598  validloss -1559.25354±0.00000  bestvalidloss -1618.64623  last_update 14\n",
      "train: iter 638  trainloss -1542.17375  validloss -1599.74628±0.00000  bestvalidloss -1618.64623  last_update 15\n",
      "train: iter 639  trainloss -1545.24957  validloss -1287.90474±0.00000  bestvalidloss -1618.64623  last_update 16\n",
      "train: iter 640  trainloss -1594.12340  validloss -1585.39518±0.00000  bestvalidloss -1618.64623  last_update 17\n",
      "train: iter 641  trainloss -1612.35058  validloss -1518.21288±0.00000  bestvalidloss -1618.64623  last_update 18\n",
      "train: iter 642  trainloss -1623.66370  validloss -1599.10620±0.00000  bestvalidloss -1618.64623  last_update 19\n",
      "train: iter 643  trainloss -1604.96877  validloss -1616.19232±0.00000  bestvalidloss -1618.64623  last_update 20\n",
      "train: iter 644  trainloss -1498.90229  validloss -1579.71426±0.00000  bestvalidloss -1618.64623  last_update 21\n",
      "train: iter 645  trainloss -1611.86621  validloss -1466.30224±0.00000  bestvalidloss -1618.64623  last_update 22\n",
      "train: iter 646  trainloss -1648.26573  validloss -1592.21622±0.00000  bestvalidloss -1618.64623  last_update 23\n",
      "train: iter 647  trainloss -1555.50228  validloss -1596.42644±0.00000  bestvalidloss -1618.64623  last_update 24\n",
      "train: iter 648  trainloss -1616.27319  validloss -1500.04808±0.00000  bestvalidloss -1618.64623  last_update 25\n",
      "train: iter 649  trainloss -1422.14340  validloss -1453.30229±0.00000  bestvalidloss -1618.64623  last_update 26\n",
      "train: iter 650  trainloss -1575.50312  validloss -1452.69012±0.00000  bestvalidloss -1618.64623  last_update 27\n",
      "train: iter 651  trainloss -1597.77156  validloss -1592.48776±0.00000  bestvalidloss -1618.64623  last_update 28\n",
      "train: iter 652  trainloss -1608.68293  validloss -1571.64024±0.00000  bestvalidloss -1618.64623  last_update 29\n",
      "train: iter 653  trainloss -1578.52871  validloss -1498.39182±0.00000  bestvalidloss -1618.64623  last_update 30\n",
      "train: iter 654  trainloss -1632.37192  validloss -1599.75547±0.00000  bestvalidloss -1618.64623  last_update 31\n",
      "train: iter 655  trainloss -1578.36817  validloss -1557.49058±0.00000  bestvalidloss -1618.64623  last_update 32\n",
      "train: iter 656  trainloss -1613.28605  validloss -1528.40936±0.00000  bestvalidloss -1618.64623  last_update 33\n",
      "train: iter 657  trainloss -1653.66907  validloss -1498.22284±0.00000  bestvalidloss -1618.64623  last_update 34\n",
      "train: iter 658  trainloss -1590.11283  validloss -1629.79620±0.00000  bestvalidloss -1629.79620  last_update 0\n",
      "train: iter 659  trainloss -1641.61917  validloss -1562.52284±0.00000  bestvalidloss -1629.79620  last_update 1\n",
      "train: iter 660  trainloss -1668.78450  validloss -1594.50666±0.00000  bestvalidloss -1629.79620  last_update 2\n",
      "train: iter 661  trainloss -1633.30607  validloss -1496.30204±0.00000  bestvalidloss -1629.79620  last_update 3\n",
      "train: iter 662  trainloss -1415.66417  validloss -850.90911±0.00000  bestvalidloss -1629.79620  last_update 4\n",
      "train: iter 663  trainloss -1642.43148  validloss -1512.02295±0.00000  bestvalidloss -1629.79620  last_update 5\n",
      "train: iter 664  trainloss -1597.23494  validloss -1575.26842±0.00000  bestvalidloss -1629.79620  last_update 6\n",
      "train: iter 665  trainloss -1626.93454  validloss -1538.02671±0.00000  bestvalidloss -1629.79620  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 666  trainloss -1507.71232  validloss -1568.71831±0.00000  bestvalidloss -1629.79620  last_update 8\n",
      "train: iter 667  trainloss -1509.06441  validloss -1273.49209±0.00000  bestvalidloss -1629.79620  last_update 9\n",
      "train: iter 668  trainloss -1529.44726  validloss -1558.99088±0.00000  bestvalidloss -1629.79620  last_update 10\n",
      "train: iter 669  trainloss -1586.64561  validloss -1551.56037±0.00000  bestvalidloss -1629.79620  last_update 11\n",
      "train: iter 670  trainloss -1632.46176  validloss -1554.78605±0.00000  bestvalidloss -1629.79620  last_update 12\n",
      "train: iter 671  trainloss -1597.42592  validloss -1541.39581±0.00000  bestvalidloss -1629.79620  last_update 13\n",
      "train: iter 672  trainloss -1444.02466  validloss -1511.46375±0.00000  bestvalidloss -1629.79620  last_update 14\n",
      "train: iter 673  trainloss -1488.71260  validloss -1580.28765±0.00000  bestvalidloss -1629.79620  last_update 15\n",
      "train: iter 674  trainloss -1546.38012  validloss -1343.94627±0.00000  bestvalidloss -1629.79620  last_update 16\n",
      "train: iter 675  trainloss -1621.47721  validloss -1587.15769±0.00000  bestvalidloss -1629.79620  last_update 17\n",
      "train: iter 676  trainloss -1626.03821  validloss -1561.01657±0.00000  bestvalidloss -1629.79620  last_update 18\n",
      "train: iter 677  trainloss -1626.10589  validloss -1550.18739±0.00000  bestvalidloss -1629.79620  last_update 19\n",
      "train: iter 678  trainloss -1625.78358  validloss -1511.72052±0.00000  bestvalidloss -1629.79620  last_update 20\n",
      "train: iter 679  trainloss -1536.54532  validloss -1575.67859±0.00000  bestvalidloss -1629.79620  last_update 21\n",
      "train: iter 680  trainloss -1604.22017  validloss -1569.95059±0.00000  bestvalidloss -1629.79620  last_update 22\n",
      "train: iter 681  trainloss -1626.61553  validloss -1587.40531±0.00000  bestvalidloss -1629.79620  last_update 23\n",
      "train: iter 682  trainloss -1587.60897  validloss -1381.92961±0.00000  bestvalidloss -1629.79620  last_update 24\n",
      "train: iter 683  trainloss -1673.48612  validloss -1625.46255±0.00000  bestvalidloss -1629.79620  last_update 25\n",
      "train: iter 684  trainloss -1604.80279  validloss -1625.87573±0.00000  bestvalidloss -1629.79620  last_update 26\n",
      "train: iter 685  trainloss -1531.81606  validloss -1480.43328±0.00000  bestvalidloss -1629.79620  last_update 27\n",
      "train: iter 686  trainloss -1616.47905  validloss -1577.30276±0.00000  bestvalidloss -1629.79620  last_update 28\n",
      "train: iter 687  trainloss -1614.95073  validloss -1399.62562±0.00000  bestvalidloss -1629.79620  last_update 29\n",
      "train: iter 688  trainloss -1611.16718  validloss -1603.22064±0.00000  bestvalidloss -1629.79620  last_update 30\n",
      "train: iter 689  trainloss -1621.45204  validloss -1574.55082±0.00000  bestvalidloss -1629.79620  last_update 31\n",
      "train: iter 690  trainloss -1419.50672  validloss -1476.38061±0.00000  bestvalidloss -1629.79620  last_update 32\n",
      "train: iter 691  trainloss -1617.24583  validloss -1564.70440±0.00000  bestvalidloss -1629.79620  last_update 33\n",
      "train: iter 692  trainloss -1636.59049  validloss -1616.43533±0.00000  bestvalidloss -1629.79620  last_update 34\n",
      "train: iter 693  trainloss -1634.63897  validloss -1599.50920±0.00000  bestvalidloss -1629.79620  last_update 35\n",
      "train: iter 694  trainloss -1626.24133  validloss -1586.03436±0.00000  bestvalidloss -1629.79620  last_update 36\n",
      "train: iter 695  trainloss -1435.74602  validloss -1598.41423±0.00000  bestvalidloss -1629.79620  last_update 37\n",
      "train: iter 696  trainloss -1596.58839  validloss -1493.33474±0.00000  bestvalidloss -1629.79620  last_update 38\n",
      "train: iter 697  trainloss -1447.96580  validloss -1483.48214±0.00000  bestvalidloss -1629.79620  last_update 39\n",
      "train: iter 698  trainloss -1603.85055  validloss -1449.23222±0.00000  bestvalidloss -1629.79620  last_update 40\n",
      "train: iter 699  trainloss -1628.98340  validloss -1599.42755±0.00000  bestvalidloss -1629.79620  last_update 41\n",
      "train: iter 700  trainloss -1679.77751  validloss -1614.08382±0.00000  bestvalidloss -1629.79620  last_update 42\n",
      "train: iter 701  trainloss -1619.73458  validloss -1632.79346±0.00000  bestvalidloss -1632.79346  last_update 0\n",
      "train: iter 702  trainloss -1566.14556  validloss -1350.04660±0.00000  bestvalidloss -1632.79346  last_update 1\n",
      "train: iter 703  trainloss -1651.15508  validloss -1592.16328±0.00000  bestvalidloss -1632.79346  last_update 2\n",
      "train: iter 704  trainloss -1602.98328  validloss -1589.44792±0.00000  bestvalidloss -1632.79346  last_update 3\n",
      "train: iter 705  trainloss -1592.21449  validloss -1561.77305±0.00000  bestvalidloss -1632.79346  last_update 4\n",
      "train: iter 706  trainloss -1632.30915  validloss -1530.25853±0.00000  bestvalidloss -1632.79346  last_update 5\n",
      "train: iter 707  trainloss -1640.02954  validloss -1611.36826±0.00000  bestvalidloss -1632.79346  last_update 6\n",
      "train: iter 708  trainloss -1606.41889  validloss -1394.89333±0.00000  bestvalidloss -1632.79346  last_update 7\n",
      "train: iter 709  trainloss -1666.22256  validloss -1622.21136±0.00000  bestvalidloss -1632.79346  last_update 8\n",
      "train: iter 710  trainloss -1541.96252  validloss -1511.77173±0.00000  bestvalidloss -1632.79346  last_update 9\n",
      "train: iter 711  trainloss -1630.92713  validloss -1515.06414±0.00000  bestvalidloss -1632.79346  last_update 10\n",
      "train: iter 712  trainloss -1516.93241  validloss -1437.09486±0.00000  bestvalidloss -1632.79346  last_update 11\n",
      "train: iter 713  trainloss -1650.74062  validloss -1517.87999±0.00000  bestvalidloss -1632.79346  last_update 12\n",
      "train: iter 714  trainloss -1630.59882  validloss -1561.10344±0.00000  bestvalidloss -1632.79346  last_update 13\n",
      "train: iter 715  trainloss -1591.19979  validloss -1581.06166±0.00000  bestvalidloss -1632.79346  last_update 14\n",
      "train: iter 716  trainloss -1564.86281  validloss -1291.66358±0.00000  bestvalidloss -1632.79346  last_update 15\n",
      "train: iter 717  trainloss -1563.57373  validloss -1367.93086±0.00000  bestvalidloss -1632.79346  last_update 16\n",
      "train: iter 718  trainloss -1645.11559  validloss -1582.29261±0.00000  bestvalidloss -1632.79346  last_update 17\n",
      "train: iter 719  trainloss -1512.28138  validloss -1628.35303±0.00000  bestvalidloss -1632.79346  last_update 18\n",
      "train: iter 720  trainloss -1535.57155  validloss -1568.49860±0.00000  bestvalidloss -1632.79346  last_update 19\n",
      "train: iter 721  trainloss -1649.42579  validloss -1583.56931±0.00000  bestvalidloss -1632.79346  last_update 20\n",
      "train: iter 722  trainloss -1626.86164  validloss -1588.59042±0.00000  bestvalidloss -1632.79346  last_update 21\n",
      "train: iter 723  trainloss -1520.07030  validloss -1619.47606±0.00000  bestvalidloss -1632.79346  last_update 22\n",
      "train: iter 724  trainloss -1608.46257  validloss -1538.25488±0.00000  bestvalidloss -1632.79346  last_update 23\n",
      "train: iter 725  trainloss -1657.90743  validloss -1582.50449±0.00000  bestvalidloss -1632.79346  last_update 24\n",
      "train: iter 726  trainloss -1209.10886  validloss -1623.40163±0.00000  bestvalidloss -1632.79346  last_update 25\n",
      "train: iter 727  trainloss -1423.54700  validloss -1057.26146±0.00000  bestvalidloss -1632.79346  last_update 26\n",
      "train: iter 728  trainloss -1599.22249  validloss -1500.72483±0.00000  bestvalidloss -1632.79346  last_update 27\n",
      "train: iter 729  trainloss -1640.45204  validloss -1547.59526±0.00000  bestvalidloss -1632.79346  last_update 28\n",
      "train: iter 730  trainloss -1637.03583  validloss -1590.81139±0.00000  bestvalidloss -1632.79346  last_update 29\n",
      "train: iter 731  trainloss -1528.31074  validloss -1563.45106±0.00000  bestvalidloss -1632.79346  last_update 30\n",
      "train: iter 732  trainloss -1562.33797  validloss -1549.89465±0.00000  bestvalidloss -1632.79346  last_update 31\n",
      "train: iter 733  trainloss -1638.74383  validloss -1593.93029±0.00000  bestvalidloss -1632.79346  last_update 32\n",
      "train: iter 734  trainloss -1660.55652  validloss -1581.11860±0.00000  bestvalidloss -1632.79346  last_update 33\n",
      "train: iter 735  trainloss -1635.20828  validloss -1599.85576±0.00000  bestvalidloss -1632.79346  last_update 34\n",
      "train: iter 736  trainloss -1593.06212  validloss -1556.75037±0.00000  bestvalidloss -1632.79346  last_update 35\n",
      "train: iter 737  trainloss -1642.95525  validloss -1590.06871±0.00000  bestvalidloss -1632.79346  last_update 36\n",
      "train: iter 738  trainloss -1662.17420  validloss -1601.93090±0.00000  bestvalidloss -1632.79346  last_update 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 739  trainloss -1606.31408  validloss -1593.90463±0.00000  bestvalidloss -1632.79346  last_update 38\n",
      "train: iter 740  trainloss -1463.24214  validloss -1524.21577±0.00000  bestvalidloss -1632.79346  last_update 39\n",
      "train: iter 741  trainloss -1584.91086  validloss -1545.99934±0.00000  bestvalidloss -1632.79346  last_update 40\n",
      "train: iter 742  trainloss -1641.77583  validloss -1575.13925±0.00000  bestvalidloss -1632.79346  last_update 41\n",
      "train: iter 743  trainloss -1620.34484  validloss -1635.01693±0.00000  bestvalidloss -1635.01693  last_update 0\n",
      "train: iter 744  trainloss -1657.03780  validloss -1575.38675±0.00000  bestvalidloss -1635.01693  last_update 1\n",
      "train: iter 745  trainloss -1596.42444  validloss -1585.16323±0.00000  bestvalidloss -1635.01693  last_update 2\n",
      "train: iter 746  trainloss -1582.90065  validloss -1561.86738±0.00000  bestvalidloss -1635.01693  last_update 3\n",
      "train: iter 747  trainloss -1615.38737  validloss -1590.49600±0.00000  bestvalidloss -1635.01693  last_update 4\n",
      "train: iter 748  trainloss -1574.42886  validloss -1482.20765±0.00000  bestvalidloss -1635.01693  last_update 5\n",
      "train: iter 749  trainloss -1597.62063  validloss -1389.33204±0.00000  bestvalidloss -1635.01693  last_update 6\n",
      "train: iter 750  trainloss -1648.50933  validloss -1587.32839±0.00000  bestvalidloss -1635.01693  last_update 7\n",
      "train: iter 751  trainloss -1622.72692  validloss -1529.09079±0.00000  bestvalidloss -1635.01693  last_update 8\n",
      "train: iter 752  trainloss -1578.06953  validloss -1403.64581±0.00000  bestvalidloss -1635.01693  last_update 9\n",
      "train: iter 753  trainloss -1568.49342  validloss -1566.87581±0.00000  bestvalidloss -1635.01693  last_update 10\n",
      "train: iter 754  trainloss -1659.66083  validloss -1578.97238±0.00000  bestvalidloss -1635.01693  last_update 11\n",
      "train: iter 755  trainloss -1644.76079  validloss -1601.19360±0.00000  bestvalidloss -1635.01693  last_update 12\n",
      "train: iter 756  trainloss -1629.80905  validloss -1627.93175±0.00000  bestvalidloss -1635.01693  last_update 13\n",
      "train: iter 757  trainloss -1599.06528  validloss -1580.31119±0.00000  bestvalidloss -1635.01693  last_update 14\n",
      "train: iter 758  trainloss -1614.72781  validloss -1535.76882±0.00000  bestvalidloss -1635.01693  last_update 15\n",
      "train: iter 759  trainloss -1640.06780  validloss -1628.93675±0.00000  bestvalidloss -1635.01693  last_update 16\n",
      "train: iter 760  trainloss -1556.57230  validloss -1613.13918±0.00000  bestvalidloss -1635.01693  last_update 17\n",
      "train: iter 761  trainloss -1610.61696  validloss -1531.81348±0.00000  bestvalidloss -1635.01693  last_update 18\n",
      "train: iter 762  trainloss -1635.60531  validloss -1584.60488±0.00000  bestvalidloss -1635.01693  last_update 19\n",
      "train: iter 763  trainloss -1651.69659  validloss -1593.48340±0.00000  bestvalidloss -1635.01693  last_update 20\n",
      "train: iter 764  trainloss -1454.49178  validloss -987.06754±0.00000  bestvalidloss -1635.01693  last_update 21\n",
      "train: iter 765  trainloss -1634.46761  validloss -1593.33273±0.00000  bestvalidloss -1635.01693  last_update 22\n",
      "train: iter 766  trainloss -1630.65670  validloss -1599.49595±0.00000  bestvalidloss -1635.01693  last_update 23\n",
      "train: iter 767  trainloss -1654.34285  validloss -1585.41862±0.00000  bestvalidloss -1635.01693  last_update 24\n",
      "train: iter 768  trainloss -1557.77965  validloss -1538.75587±0.00000  bestvalidloss -1635.01693  last_update 25\n",
      "train: iter 769  trainloss -1601.89889  validloss -1584.20588±0.00000  bestvalidloss -1635.01693  last_update 26\n",
      "train: iter 770  trainloss -1670.43450  validloss -1557.13678±0.00000  bestvalidloss -1635.01693  last_update 27\n",
      "train: iter 771  trainloss -1628.90078  validloss -1607.73503±0.00000  bestvalidloss -1635.01693  last_update 28\n",
      "train: iter 772  trainloss -1585.29876  validloss -1636.37457±0.00000  bestvalidloss -1636.37457  last_update 0\n",
      "train: iter 773  trainloss -1495.33491  validloss -1499.08444±0.00000  bestvalidloss -1636.37457  last_update 1\n",
      "train: iter 774  trainloss -1637.25448  validloss -1483.28717±0.00000  bestvalidloss -1636.37457  last_update 2\n",
      "train: iter 775  trainloss -1549.46177  validloss -1400.12729±0.00000  bestvalidloss -1636.37457  last_update 3\n",
      "train: iter 776  trainloss -1641.97382  validloss -1509.08864±0.00000  bestvalidloss -1636.37457  last_update 4\n",
      "train: iter 777  trainloss -1589.39967  validloss -1594.79263±0.00000  bestvalidloss -1636.37457  last_update 5\n",
      "train: iter 778  trainloss -1596.91893  validloss -1592.86301±0.00000  bestvalidloss -1636.37457  last_update 6\n",
      "train: iter 779  trainloss -1529.08845  validloss -1535.41621±0.00000  bestvalidloss -1636.37457  last_update 7\n",
      "train: iter 780  trainloss -1573.01278  validloss -1335.98845±0.00000  bestvalidloss -1636.37457  last_update 8\n",
      "train: iter 781  trainloss -1666.60424  validloss -1597.21811±0.00000  bestvalidloss -1636.37457  last_update 9\n",
      "train: iter 782  trainloss -1636.40008  validloss -1555.52885±0.00000  bestvalidloss -1636.37457  last_update 10\n",
      "train: iter 783  trainloss -1577.60889  validloss -1583.99475±0.00000  bestvalidloss -1636.37457  last_update 11\n",
      "train: iter 784  trainloss -1451.92630  validloss -1603.41332±0.00000  bestvalidloss -1636.37457  last_update 12\n",
      "train: iter 785  trainloss -1419.29922  validloss -1246.69881±0.00000  bestvalidloss -1636.37457  last_update 13\n",
      "train: iter 786  trainloss -1635.25241  validloss -1528.14597±0.00000  bestvalidloss -1636.37457  last_update 14\n",
      "train: iter 787  trainloss -1662.80651  validloss -1580.07214±0.00000  bestvalidloss -1636.37457  last_update 15\n",
      "train: iter 788  trainloss -1594.72897  validloss -1613.95009±0.00000  bestvalidloss -1636.37457  last_update 16\n",
      "train: iter 789  trainloss -1621.60464  validloss -1576.82067±0.00000  bestvalidloss -1636.37457  last_update 17\n",
      "train: iter 790  trainloss -1616.83511  validloss -1378.68535±0.00000  bestvalidloss -1636.37457  last_update 18\n",
      "train: iter 791  trainloss -1679.97452  validloss -1554.83225±0.00000  bestvalidloss -1636.37457  last_update 19\n",
      "train: iter 792  trainloss -1692.86082  validloss -1622.30122±0.00000  bestvalidloss -1636.37457  last_update 20\n",
      "train: iter 793  trainloss -1692.33485  validloss -1604.50574±0.00000  bestvalidloss -1636.37457  last_update 21\n",
      "train: iter 794  trainloss -1475.28980  validloss -1527.41307±0.00000  bestvalidloss -1636.37457  last_update 22\n",
      "train: iter 795  trainloss -1521.86502  validloss -1525.08012±0.00000  bestvalidloss -1636.37457  last_update 23\n",
      "train: iter 796  trainloss -1554.08037  validloss -1382.14377±0.00000  bestvalidloss -1636.37457  last_update 24\n",
      "train: iter 797  trainloss -1671.80580  validloss -1587.90342±0.00000  bestvalidloss -1636.37457  last_update 25\n",
      "train: iter 798  trainloss -1693.30438  validloss -1642.83134±0.00000  bestvalidloss -1642.83134  last_update 0\n",
      "train: iter 799  trainloss -1549.85807  validloss -1627.85354±0.00000  bestvalidloss -1642.83134  last_update 1\n",
      "train: iter 800  trainloss -1666.81600  validloss -1619.16376±0.00000  bestvalidloss -1642.83134  last_update 2\n",
      "train: iter 801  trainloss -1637.51426  validloss -1647.60569±0.00000  bestvalidloss -1647.60569  last_update 0\n",
      "train: iter 802  trainloss -1559.27194  validloss -1322.08560±0.00000  bestvalidloss -1647.60569  last_update 1\n",
      "train: iter 803  trainloss -1608.79274  validloss -1557.69119±0.00000  bestvalidloss -1647.60569  last_update 2\n",
      "train: iter 804  trainloss -1632.70065  validloss -1595.98042±0.00000  bestvalidloss -1647.60569  last_update 3\n",
      "train: iter 805  trainloss -1616.59617  validloss -1331.88050±0.00000  bestvalidloss -1647.60569  last_update 4\n",
      "train: iter 806  trainloss -1521.41929  validloss -1215.40222±0.00000  bestvalidloss -1647.60569  last_update 5\n",
      "train: iter 807  trainloss -1614.31988  validloss -1592.61836±0.00000  bestvalidloss -1647.60569  last_update 6\n",
      "train: iter 808  trainloss -1443.35115  validloss -1066.65879±0.00000  bestvalidloss -1647.60569  last_update 7\n",
      "train: iter 809  trainloss -1652.27547  validloss -1553.94595±0.00000  bestvalidloss -1647.60569  last_update 8\n",
      "train: iter 810  trainloss -1637.50135  validloss -1581.49627±0.00000  bestvalidloss -1647.60569  last_update 9\n",
      "train: iter 811  trainloss -1615.53501  validloss -1586.98552±0.00000  bestvalidloss -1647.60569  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 812  trainloss -1668.78920  validloss -1616.41202±0.00000  bestvalidloss -1647.60569  last_update 11\n",
      "train: iter 813  trainloss -1506.86494  validloss -1632.62572±0.00000  bestvalidloss -1647.60569  last_update 12\n",
      "train: iter 814  trainloss -1617.42538  validloss -1536.21374±0.00000  bestvalidloss -1647.60569  last_update 13\n",
      "train: iter 815  trainloss -1622.30918  validloss -1619.35480±0.00000  bestvalidloss -1647.60569  last_update 14\n",
      "train: iter 816  trainloss -1548.30416  validloss -1532.56549±0.00000  bestvalidloss -1647.60569  last_update 15\n",
      "train: iter 817  trainloss -1671.31460  validloss -1576.18058±0.00000  bestvalidloss -1647.60569  last_update 16\n",
      "train: iter 818  trainloss -1661.61674  validloss -1603.14105±0.00000  bestvalidloss -1647.60569  last_update 17\n",
      "train: iter 819  trainloss -1637.47738  validloss -1461.52593±0.00000  bestvalidloss -1647.60569  last_update 18\n",
      "train: iter 820  trainloss -1641.50665  validloss -1546.13337±0.00000  bestvalidloss -1647.60569  last_update 19\n",
      "train: iter 821  trainloss -1636.05963  validloss -1597.27783±0.00000  bestvalidloss -1647.60569  last_update 20\n",
      "train: iter 822  trainloss -1615.88747  validloss -1530.92635±0.00000  bestvalidloss -1647.60569  last_update 21\n",
      "train: iter 823  trainloss -1684.94471  validloss -1590.72530±0.00000  bestvalidloss -1647.60569  last_update 22\n",
      "train: iter 824  trainloss -1590.36143  validloss -1653.77406±0.00000  bestvalidloss -1653.77406  last_update 0\n",
      "train: iter 825  trainloss -1612.01234  validloss -1471.23650±0.00000  bestvalidloss -1653.77406  last_update 1\n",
      "train: iter 826  trainloss -1674.96179  validloss -1626.92971±0.00000  bestvalidloss -1653.77406  last_update 2\n",
      "train: iter 827  trainloss -1638.80381  validloss -1620.06020±0.00000  bestvalidloss -1653.77406  last_update 3\n",
      "train: iter 828  trainloss -1663.45801  validloss -1506.34522±0.00000  bestvalidloss -1653.77406  last_update 4\n",
      "train: iter 829  trainloss -1404.73038  validloss -1530.46785±0.00000  bestvalidloss -1653.77406  last_update 5\n",
      "train: iter 830  trainloss -1665.19904  validloss -1544.86088±0.00000  bestvalidloss -1653.77406  last_update 6\n",
      "train: iter 831  trainloss -1682.82215  validloss -1561.67068±0.00000  bestvalidloss -1653.77406  last_update 7\n",
      "train: iter 832  trainloss -1653.72921  validloss -1616.28616±0.00000  bestvalidloss -1653.77406  last_update 8\n",
      "train: iter 833  trainloss -1608.81499  validloss -1615.27699±0.00000  bestvalidloss -1653.77406  last_update 9\n",
      "train: iter 834  trainloss -1669.16025  validloss -1605.42822±0.00000  bestvalidloss -1653.77406  last_update 10\n",
      "train: iter 835  trainloss -1498.27742  validloss -1588.95949±0.00000  bestvalidloss -1653.77406  last_update 11\n",
      "train: iter 836  trainloss -1672.28331  validloss -1574.42542±0.00000  bestvalidloss -1653.77406  last_update 12\n",
      "train: iter 837  trainloss -1674.13015  validloss -1640.74168±0.00000  bestvalidloss -1653.77406  last_update 13\n",
      "train: iter 838  trainloss -1662.36776  validloss -1634.72534±0.00000  bestvalidloss -1653.77406  last_update 14\n",
      "train: iter 839  trainloss -1583.67307  validloss -1625.67852±0.00000  bestvalidloss -1653.77406  last_update 15\n",
      "train: iter 840  trainloss -1629.00554  validloss -1358.97571±0.00000  bestvalidloss -1653.77406  last_update 16\n",
      "train: iter 841  trainloss -1671.25378  validloss -1639.16784±0.00000  bestvalidloss -1653.77406  last_update 17\n",
      "train: iter 842  trainloss -1663.57689  validloss -1618.09855±0.00000  bestvalidloss -1653.77406  last_update 18\n",
      "train: iter 843  trainloss -1697.65037  validloss -1617.96159±0.00000  bestvalidloss -1653.77406  last_update 19\n",
      "train: iter 844  trainloss -1693.15776  validloss -1589.60473±0.00000  bestvalidloss -1653.77406  last_update 20\n",
      "train: iter 845  trainloss -1416.19146  validloss -1245.02329±0.00000  bestvalidloss -1653.77406  last_update 21\n",
      "train: iter 846  trainloss -1653.83366  validloss -1560.11357±0.00000  bestvalidloss -1653.77406  last_update 22\n",
      "train: iter 847  trainloss -1648.22900  validloss -1523.60640±0.00000  bestvalidloss -1653.77406  last_update 23\n",
      "train: iter 848  trainloss -1562.98933  validloss -1442.36696±0.00000  bestvalidloss -1653.77406  last_update 24\n",
      "train: iter 849  trainloss -1668.30156  validloss -1594.33604±0.00000  bestvalidloss -1653.77406  last_update 25\n",
      "train: iter 850  trainloss -1686.52720  validloss -1570.17118±0.00000  bestvalidloss -1653.77406  last_update 26\n",
      "train: iter 851  trainloss -1460.66094  validloss -1645.38930±0.00000  bestvalidloss -1653.77406  last_update 27\n",
      "train: iter 852  trainloss -1554.87036  validloss -1211.55092±0.00000  bestvalidloss -1653.77406  last_update 28\n",
      "train: iter 853  trainloss -1614.45446  validloss -1507.58625±0.00000  bestvalidloss -1653.77406  last_update 29\n",
      "train: iter 854  trainloss -1594.34284  validloss -1555.36441±0.00000  bestvalidloss -1653.77406  last_update 30\n",
      "train: iter 855  trainloss -1675.13322  validloss -1574.32522±0.00000  bestvalidloss -1653.77406  last_update 31\n",
      "train: iter 856  trainloss -1693.14429  validloss -1647.83040±0.00000  bestvalidloss -1653.77406  last_update 32\n",
      "train: iter 857  trainloss -1679.13915  validloss -1610.33371±0.00000  bestvalidloss -1653.77406  last_update 33\n",
      "train: iter 858  trainloss -1635.87430  validloss -1506.18631±0.00000  bestvalidloss -1653.77406  last_update 34\n",
      "train: iter 859  trainloss -1702.30835  validloss -1608.80639±0.00000  bestvalidloss -1653.77406  last_update 35\n",
      "train: iter 860  trainloss -1623.51935  validloss -1622.03032±0.00000  bestvalidloss -1653.77406  last_update 36\n",
      "train: iter 861  trainloss -1586.52916  validloss -1611.09373±0.00000  bestvalidloss -1653.77406  last_update 37\n",
      "train: iter 862  trainloss -1532.24781  validloss -1442.83138±0.00000  bestvalidloss -1653.77406  last_update 38\n",
      "train: iter 863  trainloss -1656.43620  validloss -1553.91122±0.00000  bestvalidloss -1653.77406  last_update 39\n",
      "train: iter 864  trainloss -1688.58091  validloss -1572.64953±0.00000  bestvalidloss -1653.77406  last_update 40\n",
      "train: iter 865  trainloss -1668.14072  validloss -1626.01142±0.00000  bestvalidloss -1653.77406  last_update 41\n",
      "train: iter 866  trainloss -1701.33205  validloss -1598.10119±0.00000  bestvalidloss -1653.77406  last_update 42\n",
      "train: iter 867  trainloss -1586.96148  validloss -1636.38284±0.00000  bestvalidloss -1653.77406  last_update 43\n",
      "train: iter 868  trainloss -1658.14052  validloss -1428.45535±0.00000  bestvalidloss -1653.77406  last_update 44\n",
      "train: iter 869  trainloss -1629.79502  validloss -1675.80087±0.00000  bestvalidloss -1675.80087  last_update 0\n",
      "train: iter 870  trainloss -1439.95250  validloss -1548.01422±0.00000  bestvalidloss -1675.80087  last_update 1\n",
      "train: iter 871  trainloss -1666.40644  validloss -1576.40837±0.00000  bestvalidloss -1675.80087  last_update 2\n",
      "train: iter 872  trainloss -1688.85252  validloss -1586.48618±0.00000  bestvalidloss -1675.80087  last_update 3\n",
      "train: iter 873  trainloss -1645.96121  validloss -1643.62096±0.00000  bestvalidloss -1675.80087  last_update 4\n",
      "train: iter 874  trainloss -1547.45086  validloss -1487.87636±0.00000  bestvalidloss -1675.80087  last_update 5\n",
      "train: iter 875  trainloss -1678.84439  validloss -1555.86240±0.00000  bestvalidloss -1675.80087  last_update 6\n",
      "train: iter 876  trainloss -1610.95965  validloss -1602.37680±0.00000  bestvalidloss -1675.80087  last_update 7\n",
      "train: iter 877  trainloss -1604.34608  validloss -1586.54964±0.00000  bestvalidloss -1675.80087  last_update 8\n",
      "train: iter 878  trainloss -1640.99464  validloss -1573.61875±0.00000  bestvalidloss -1675.80087  last_update 9\n",
      "train: iter 879  trainloss -1672.75052  validloss -1606.73955±0.00000  bestvalidloss -1675.80087  last_update 10\n",
      "train: iter 880  trainloss -1629.04734  validloss -1619.09928±0.00000  bestvalidloss -1675.80087  last_update 11\n",
      "train: iter 881  trainloss -1699.33573  validloss -1633.26722±0.00000  bestvalidloss -1675.80087  last_update 12\n",
      "train: iter 882  trainloss -1685.26749  validloss -1606.42114±0.00000  bestvalidloss -1675.80087  last_update 13\n",
      "train: iter 883  trainloss -1643.83813  validloss -1544.11553±0.00000  bestvalidloss -1675.80087  last_update 14\n",
      "train: iter 884  trainloss -1703.41823  validloss -1656.65502±0.00000  bestvalidloss -1675.80087  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 885  trainloss -1557.24479  validloss -1346.71672±0.00000  bestvalidloss -1675.80087  last_update 16\n",
      "train: iter 886  trainloss -1638.96024  validloss -1572.91118±0.00000  bestvalidloss -1675.80087  last_update 17\n",
      "train: iter 887  trainloss -1640.69902  validloss -1484.00735±0.00000  bestvalidloss -1675.80087  last_update 18\n",
      "train: iter 888  trainloss -1694.36810  validloss -1625.65496±0.00000  bestvalidloss -1675.80087  last_update 19\n",
      "train: iter 889  trainloss -1442.17764  validloss -1663.72381±0.00000  bestvalidloss -1675.80087  last_update 20\n",
      "train: iter 890  trainloss -1629.45945  validloss -1582.48259±0.00000  bestvalidloss -1675.80087  last_update 21\n",
      "train: iter 891  trainloss -1666.62004  validloss -1588.61983±0.00000  bestvalidloss -1675.80087  last_update 22\n",
      "train: iter 892  trainloss -1694.33258  validloss -1569.52179±0.00000  bestvalidloss -1675.80087  last_update 23\n",
      "train: iter 893  trainloss -1683.20215  validloss -1629.19364±0.00000  bestvalidloss -1675.80087  last_update 24\n",
      "train: iter 894  trainloss -1638.09304  validloss -1623.02246±0.00000  bestvalidloss -1675.80087  last_update 25\n",
      "train: iter 895  trainloss -1697.05985  validloss -1627.68858±0.00000  bestvalidloss -1675.80087  last_update 26\n",
      "train: iter 896  trainloss -1552.93251  validloss -1246.86124±0.00000  bestvalidloss -1675.80087  last_update 27\n",
      "train: iter 897  trainloss -1563.88027  validloss -1403.42773±0.00000  bestvalidloss -1675.80087  last_update 28\n",
      "train: iter 898  trainloss -1553.93599  validloss -1562.92330±0.00000  bestvalidloss -1675.80087  last_update 29\n",
      "train: iter 899  trainloss -1582.14990  validloss -1365.12277±0.00000  bestvalidloss -1675.80087  last_update 30\n",
      "train: iter 900  trainloss -1704.85799  validloss -1641.05233±0.00000  bestvalidloss -1675.80087  last_update 31\n",
      "train: iter 901  trainloss -1532.10740  validloss -1668.58075±0.00000  bestvalidloss -1675.80087  last_update 32\n",
      "train: iter 902  trainloss -1673.93544  validloss -1444.20873±0.00000  bestvalidloss -1675.80087  last_update 33\n",
      "train: iter 903  trainloss -1641.03554  validloss -1659.12189±0.00000  bestvalidloss -1675.80087  last_update 34\n",
      "train: iter 904  trainloss -1700.29419  validloss -1637.87202±0.00000  bestvalidloss -1675.80087  last_update 35\n",
      "train: iter 905  trainloss -1552.19558  validloss -1084.97416±0.00000  bestvalidloss -1675.80087  last_update 36\n",
      "train: iter 906  trainloss -1698.12466  validloss -1562.76634±0.00000  bestvalidloss -1675.80087  last_update 37\n",
      "train: iter 907  trainloss -1683.88441  validloss -1641.08844±0.00000  bestvalidloss -1675.80087  last_update 38\n",
      "train: iter 908  trainloss -1205.39262  validloss -1537.55498±0.00000  bestvalidloss -1675.80087  last_update 39\n",
      "train: iter 909  trainloss -1600.49966  validloss -1486.57635±0.00000  bestvalidloss -1675.80087  last_update 40\n",
      "train: iter 910  trainloss -1685.72112  validloss -1614.83769±0.00000  bestvalidloss -1675.80087  last_update 41\n",
      "train: iter 911  trainloss -1691.61423  validloss -1642.25655±0.00000  bestvalidloss -1675.80087  last_update 42\n",
      "train: iter 912  trainloss -1711.13665  validloss -1620.68317±0.00000  bestvalidloss -1675.80087  last_update 43\n",
      "train: iter 913  trainloss -1670.18775  validloss -1535.92042±0.00000  bestvalidloss -1675.80087  last_update 44\n",
      "train: iter 914  trainloss -1702.25949  validloss -1636.07609±0.00000  bestvalidloss -1675.80087  last_update 45\n",
      "train: iter 915  trainloss -1702.52713  validloss -1632.40129±0.00000  bestvalidloss -1675.80087  last_update 46\n",
      "train: iter 916  trainloss -1652.90444  validloss -1669.56886±0.00000  bestvalidloss -1675.80087  last_update 47\n",
      "train: iter 917  trainloss -1581.36313  validloss -1510.46048±0.00000  bestvalidloss -1675.80087  last_update 48\n",
      "train: iter 918  trainloss -1668.07728  validloss -1619.63217±0.00000  bestvalidloss -1675.80087  last_update 49\n",
      "train: iter 919  trainloss -1644.82089  validloss -1602.38586±0.00000  bestvalidloss -1675.80087  last_update 50\n",
      "train: iter 920  trainloss -1709.02469  validloss -1634.90661±0.00000  bestvalidloss -1675.80087  last_update 51\n",
      "train: iter 921  trainloss -1650.57337  validloss -1670.32454±0.00000  bestvalidloss -1675.80087  last_update 52\n",
      "train: iter 922  trainloss -1685.79139  validloss -1589.17278±0.00000  bestvalidloss -1675.80087  last_update 53\n",
      "train: iter 923  trainloss -1719.75897  validloss -1649.95996±0.00000  bestvalidloss -1675.80087  last_update 54\n",
      "train: iter 924  trainloss -1563.77367  validloss -1697.92124±0.00000  bestvalidloss -1697.92124  last_update 0\n",
      "train: iter 925  trainloss -1536.87051  validloss -1325.18361±0.00000  bestvalidloss -1697.92124  last_update 1\n",
      "train: iter 926  trainloss -1666.10952  validloss -1577.51254±0.00000  bestvalidloss -1697.92124  last_update 2\n",
      "train: iter 927  trainloss -1680.68518  validloss -1639.75270±0.00000  bestvalidloss -1697.92124  last_update 3\n",
      "train: iter 928  trainloss -1657.88879  validloss -1620.75403±0.00000  bestvalidloss -1697.92124  last_update 4\n",
      "train: iter 929  trainloss -1640.18436  validloss -1582.41359±0.00000  bestvalidloss -1697.92124  last_update 5\n",
      "train: iter 930  trainloss -1621.03509  validloss -1565.03657±0.00000  bestvalidloss -1697.92124  last_update 6\n",
      "train: iter 931  trainloss -1696.53564  validloss -1635.52412±0.00000  bestvalidloss -1697.92124  last_update 7\n",
      "train: iter 932  trainloss -1307.66497  validloss -1540.61455±0.00000  bestvalidloss -1697.92124  last_update 8\n",
      "train: iter 933  trainloss -1631.68558  validloss -1464.83435±0.00000  bestvalidloss -1697.92124  last_update 9\n",
      "train: iter 934  trainloss -1661.56506  validloss -1644.81235±0.00000  bestvalidloss -1697.92124  last_update 10\n",
      "train: iter 935  trainloss -1665.74359  validloss -1581.08809±0.00000  bestvalidloss -1697.92124  last_update 11\n",
      "train: iter 936  trainloss -1683.30166  validloss -1662.74995±0.00000  bestvalidloss -1697.92124  last_update 12\n",
      "train: iter 937  trainloss -1702.35958  validloss -1640.21443±0.00000  bestvalidloss -1697.92124  last_update 13\n",
      "train: iter 938  trainloss -1553.73949  validloss -821.51011±0.00000  bestvalidloss -1697.92124  last_update 14\n",
      "train: iter 939  trainloss -1683.76356  validloss -1622.10238±0.00000  bestvalidloss -1697.92124  last_update 15\n",
      "train: iter 940  trainloss -1656.42256  validloss -1490.68620±0.00000  bestvalidloss -1697.92124  last_update 16\n",
      "train: iter 941  trainloss -1665.18048  validloss -1565.83680±0.00000  bestvalidloss -1697.92124  last_update 17\n",
      "train: iter 942  trainloss -1688.77278  validloss -1581.30920±0.00000  bestvalidloss -1697.92124  last_update 18\n",
      "train: iter 943  trainloss -1698.07679  validloss -1629.24382±0.00000  bestvalidloss -1697.92124  last_update 19\n",
      "train: iter 944  trainloss -1634.20512  validloss -1628.43730±0.00000  bestvalidloss -1697.92124  last_update 20\n",
      "train: iter 945  trainloss -1519.62520  validloss -1572.27131±0.00000  bestvalidloss -1697.92124  last_update 21\n",
      "train: iter 946  trainloss -1653.73520  validloss -1481.76861±0.00000  bestvalidloss -1697.92124  last_update 22\n",
      "train: iter 947  trainloss -1601.58112  validloss -1443.79051±0.00000  bestvalidloss -1697.92124  last_update 23\n",
      "train: iter 948  trainloss -1694.56583  validloss -1588.67263±0.00000  bestvalidloss -1697.92124  last_update 24\n",
      "train: iter 949  trainloss -1653.51301  validloss -1632.36860±0.00000  bestvalidloss -1697.92124  last_update 25\n",
      "train: iter 950  trainloss -862.59725  validloss -595.52310±0.00000  bestvalidloss -1697.92124  last_update 26\n",
      "train: iter 951  trainloss -1520.26423  validloss -1375.67303±0.00000  bestvalidloss -1697.92124  last_update 27\n",
      "train: iter 952  trainloss -1637.94862  validloss -1517.82066±0.00000  bestvalidloss -1697.92124  last_update 28\n",
      "train: iter 953  trainloss -1582.82865  validloss -1592.59223±0.00000  bestvalidloss -1697.92124  last_update 29\n",
      "train: iter 954  trainloss -1665.49963  validloss -1554.38592±0.00000  bestvalidloss -1697.92124  last_update 30\n",
      "train: iter 955  trainloss -1670.72348  validloss -1603.96145±0.00000  bestvalidloss -1697.92124  last_update 31\n",
      "train: iter 956  trainloss -1631.99187  validloss -1598.77813±0.00000  bestvalidloss -1697.92124  last_update 32\n",
      "train: iter 957  trainloss -1645.69777  validloss -1579.31431±0.00000  bestvalidloss -1697.92124  last_update 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 958  trainloss -1657.44099  validloss -1595.95809±0.00000  bestvalidloss -1697.92124  last_update 34\n",
      "train: iter 959  trainloss -1684.26705  validloss -1579.70039±0.00000  bestvalidloss -1697.92124  last_update 35\n",
      "train: iter 960  trainloss -1599.29137  validloss -1514.89283±0.00000  bestvalidloss -1697.92124  last_update 36\n",
      "train: iter 961  trainloss -1679.09858  validloss -1454.46530±0.00000  bestvalidloss -1697.92124  last_update 37\n",
      "train: iter 962  trainloss -1637.30910  validloss -1573.94508±0.00000  bestvalidloss -1697.92124  last_update 38\n",
      "train: iter 963  trainloss -1667.29314  validloss -1640.81288±0.00000  bestvalidloss -1697.92124  last_update 39\n",
      "train: iter 964  trainloss -1468.29065  validloss -1437.10544±0.00000  bestvalidloss -1697.92124  last_update 40\n",
      "train: iter 965  trainloss -1688.60766  validloss -1572.02387±0.00000  bestvalidloss -1697.92124  last_update 41\n",
      "train: iter 966  trainloss -1682.45873  validloss -1592.90982±0.00000  bestvalidloss -1697.92124  last_update 42\n",
      "train: iter 967  trainloss -1652.83409  validloss -1519.00892±0.00000  bestvalidloss -1697.92124  last_update 43\n",
      "train: iter 968  trainloss -1680.84786  validloss -1562.21232±0.00000  bestvalidloss -1697.92124  last_update 44\n",
      "train: iter 969  trainloss -1698.37581  validloss -1608.46496±0.00000  bestvalidloss -1697.92124  last_update 45\n",
      "train: iter 970  trainloss -1664.76908  validloss -1593.78553±0.00000  bestvalidloss -1697.92124  last_update 46\n",
      "train: iter 971  trainloss -1668.16886  validloss -1449.25981±0.00000  bestvalidloss -1697.92124  last_update 47\n",
      "train: iter 972  trainloss -1645.13880  validloss -1616.00288±0.00000  bestvalidloss -1697.92124  last_update 48\n",
      "train: iter 973  trainloss -1654.38307  validloss -1456.46523±0.00000  bestvalidloss -1697.92124  last_update 49\n",
      "train: iter 974  trainloss -1703.47894  validloss -1641.78466±0.00000  bestvalidloss -1697.92124  last_update 50\n",
      "train: iter 975  trainloss -1656.00565  validloss -1642.69700±0.00000  bestvalidloss -1697.92124  last_update 51\n",
      "train: iter 976  trainloss -1588.41394  validloss -1511.47335±0.00000  bestvalidloss -1697.92124  last_update 52\n",
      "train: iter 977  trainloss -1561.14570  validloss -1416.14912±0.00000  bestvalidloss -1697.92124  last_update 53\n",
      "train: iter 978  trainloss -1679.34758  validloss -1597.96101±0.00000  bestvalidloss -1697.92124  last_update 54\n",
      "train: iter 979  trainloss -1668.89398  validloss -1633.12081±0.00000  bestvalidloss -1697.92124  last_update 55\n",
      "train: iter 980  trainloss -1591.70275  validloss -1672.60194±0.00000  bestvalidloss -1697.92124  last_update 56\n",
      "train: iter 981  trainloss -1696.09135  validloss -1627.36581±0.00000  bestvalidloss -1697.92124  last_update 57\n",
      "train: iter 982  trainloss -1715.64879  validloss -1673.45219±0.00000  bestvalidloss -1697.92124  last_update 58\n",
      "train: iter 983  trainloss -1688.97639  validloss -1605.85401±0.00000  bestvalidloss -1697.92124  last_update 59\n",
      "train: iter 984  trainloss -1625.99468  validloss -1579.06810±0.00000  bestvalidloss -1697.92124  last_update 60\n",
      "train: iter 985  trainloss -1696.60028  validloss -1574.40306±0.00000  bestvalidloss -1697.92124  last_update 61\n",
      "train: iter 986  trainloss -1701.28123  validloss -1672.90769±0.00000  bestvalidloss -1697.92124  last_update 62\n",
      "train: iter 987  trainloss -1659.33045  validloss -1597.46351±0.00000  bestvalidloss -1697.92124  last_update 63\n",
      "train: iter 988  trainloss -1657.42211  validloss -1588.69818±0.00000  bestvalidloss -1697.92124  last_update 64\n",
      "train: iter 989  trainloss -1595.35650  validloss -1525.35742±0.00000  bestvalidloss -1697.92124  last_update 65\n",
      "train: iter 990  trainloss -1682.34417  validloss -1553.90326±0.00000  bestvalidloss -1697.92124  last_update 66\n",
      "train: iter 991  trainloss -1619.56670  validloss -1620.12210±0.00000  bestvalidloss -1697.92124  last_update 67\n",
      "train: iter 992  trainloss -1651.58475  validloss -1597.78276±0.00000  bestvalidloss -1697.92124  last_update 68\n",
      "train: iter 993  trainloss -1538.66219  validloss -1500.36028±0.00000  bestvalidloss -1697.92124  last_update 69\n",
      "train: iter 994  trainloss -1678.30745  validloss -1559.87993±0.00000  bestvalidloss -1697.92124  last_update 70\n",
      "train: iter 995  trainloss -1639.72708  validloss -1600.17449±0.00000  bestvalidloss -1697.92124  last_update 71\n",
      "train: iter 996  trainloss -1718.30291  validloss -1634.16586±0.00000  bestvalidloss -1697.92124  last_update 72\n",
      "train: iter 997  trainloss -1694.68029  validloss -1648.11106±0.00000  bestvalidloss -1697.92124  last_update 73\n",
      "train: iter 998  trainloss -1594.87414  validloss -1598.56210±0.00000  bestvalidloss -1697.92124  last_update 74\n",
      "train: iter 999  trainloss -1720.11644  validloss -1656.00247±0.00000  bestvalidloss -1697.92124  last_update 75\n",
      "train: iter 1000  trainloss -1378.93457  validloss -1659.49674±0.00000  bestvalidloss -1697.92124  last_update 76\n",
      "train: iter 1001  trainloss -1472.57998  validloss -754.86638±0.00000  bestvalidloss -1697.92124  last_update 77\n",
      "train: iter 1002  trainloss -1663.65515  validloss -1582.88377±0.00000  bestvalidloss -1697.92124  last_update 78\n",
      "train: iter 1003  trainloss -1656.77127  validloss -1635.84578±0.00000  bestvalidloss -1697.92124  last_update 79\n",
      "train: iter 1004  trainloss -1650.09961  validloss -1470.19462±0.00000  bestvalidloss -1697.92124  last_update 80\n",
      "train: iter 1005  trainloss -1695.15469  validloss -1626.71755±0.00000  bestvalidloss -1697.92124  last_update 81\n",
      "train: iter 1006  trainloss -1649.45937  validloss -1639.45019±0.00000  bestvalidloss -1697.92124  last_update 82\n",
      "train: iter 1007  trainloss -1658.57378  validloss -1523.87297±0.00000  bestvalidloss -1697.92124  last_update 83\n",
      "train: iter 1008  trainloss -1719.46902  validloss -1653.50140±0.00000  bestvalidloss -1697.92124  last_update 84\n",
      "train: iter 1009  trainloss -1546.80408  validloss -1631.44909±0.00000  bestvalidloss -1697.92124  last_update 85\n",
      "train: iter 1010  trainloss -1697.47527  validloss -1569.27863±0.00000  bestvalidloss -1697.92124  last_update 86\n",
      "train: iter 1011  trainloss -1533.93662  validloss -1546.03539±0.00000  bestvalidloss -1697.92124  last_update 87\n",
      "train: iter 1012  trainloss -1472.13383  validloss -1208.11939±0.00000  bestvalidloss -1697.92124  last_update 88\n",
      "train: iter 1013  trainloss -1684.38332  validloss -1588.49805±0.00000  bestvalidloss -1697.92124  last_update 89\n",
      "train: iter 1014  trainloss -1671.75645  validloss -1533.68542±0.00000  bestvalidloss -1697.92124  last_update 90\n",
      "train: iter 1015  trainloss -1667.81604  validloss -1629.41159±0.00000  bestvalidloss -1697.92124  last_update 91\n",
      "train: iter 1016  trainloss -1731.39416  validloss -1650.43528±0.00000  bestvalidloss -1697.92124  last_update 92\n",
      "train: iter 1017  trainloss -1523.37769  validloss -1621.25171±0.00000  bestvalidloss -1697.92124  last_update 93\n",
      "train: iter 1018  trainloss -1674.13622  validloss -1572.69708±0.00000  bestvalidloss -1697.92124  last_update 94\n",
      "train: iter 1019  trainloss -1705.06655  validloss -1615.90622±0.00000  bestvalidloss -1697.92124  last_update 95\n",
      "train: iter 1020  trainloss -1700.67184  validloss -1626.06708±0.00000  bestvalidloss -1697.92124  last_update 96\n",
      "train: iter 1021  trainloss -1609.43895  validloss -1468.10802±0.00000  bestvalidloss -1697.92124  last_update 97\n",
      "train: iter 1022  trainloss -1586.88790  validloss -1346.55304±0.00000  bestvalidloss -1697.92124  last_update 98\n",
      "train: iter 1023  trainloss -1691.62227  validloss -1601.61806±0.00000  bestvalidloss -1697.92124  last_update 99\n",
      "train: iter 1024  trainloss -1717.05865  validloss -1613.78618±0.00000  bestvalidloss -1697.92124  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.8176) penalty_target_max tensor(3.9962)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 7.33988  validloss 7.74052±0.00000  bestvalidloss 7.74052  last_update 0\n",
      "train: iter 1  trainloss 6.72926  validloss 7.03945±0.00000  bestvalidloss 7.03945  last_update 0\n",
      "train: iter 2  trainloss 6.19306  validloss 6.45527±0.00000  bestvalidloss 6.45527  last_update 0\n",
      "train: iter 3  trainloss 5.74963  validloss 5.95835±0.00000  bestvalidloss 5.95835  last_update 0\n",
      "train: iter 4  trainloss 5.36432  validloss 5.55882±0.00000  bestvalidloss 5.55882  last_update 0\n",
      "train: iter 5  trainloss 5.03012  validloss 5.19665±0.00000  bestvalidloss 5.19665  last_update 0\n",
      "train: iter 6  trainloss 4.73421  validloss 4.88042±0.00000  bestvalidloss 4.88042  last_update 0\n",
      "train: iter 7  trainloss 4.47961  validloss 4.61957±0.00000  bestvalidloss 4.61957  last_update 0\n",
      "train: iter 8  trainloss 4.26161  validloss 4.36912±0.00000  bestvalidloss 4.36912  last_update 0\n",
      "train: iter 9  trainloss 4.06104  validloss 4.14619±0.00000  bestvalidloss 4.14619  last_update 0\n",
      "train: iter 10  trainloss 3.88099  validloss 3.94945±0.00000  bestvalidloss 3.94945  last_update 0\n",
      "train: iter 11  trainloss 3.72185  validloss 3.78192±0.00000  bestvalidloss 3.78192  last_update 0\n",
      "train: iter 12  trainloss 3.57954  validloss 3.63087±0.00000  bestvalidloss 3.63087  last_update 0\n",
      "train: iter 13  trainloss 3.45308  validloss 3.49284±0.00000  bestvalidloss 3.49284  last_update 0\n",
      "train: iter 14  trainloss 3.32925  validloss 3.36768±0.00000  bestvalidloss 3.36768  last_update 0\n",
      "train: iter 15  trainloss 3.22339  validloss 3.25015±0.00000  bestvalidloss 3.25015  last_update 0\n",
      "train: iter 16  trainloss 3.14212  validloss 3.14760±0.00000  bestvalidloss 3.14760  last_update 0\n",
      "train: iter 17  trainloss 3.04081  validloss 3.07771±0.00000  bestvalidloss 3.07771  last_update 0\n",
      "train: iter 18  trainloss 2.97244  validloss 2.97043±0.00000  bestvalidloss 2.97043  last_update 0\n",
      "train: iter 19  trainloss 2.90283  validloss 2.89427±0.00000  bestvalidloss 2.89427  last_update 0\n",
      "train: iter 20  trainloss 2.82524  validloss 2.83771±0.00000  bestvalidloss 2.83771  last_update 0\n",
      "train: iter 21  trainloss 2.77254  validloss 2.74928±0.00000  bestvalidloss 2.74928  last_update 0\n",
      "train: iter 22  trainloss 2.71995  validloss 2.69500±0.00000  bestvalidloss 2.69500  last_update 0\n",
      "train: iter 23  trainloss 2.67653  validloss 2.64372±0.00000  bestvalidloss 2.64372  last_update 0\n",
      "train: iter 24  trainloss 2.62352  validloss 2.59023±0.00000  bestvalidloss 2.59023  last_update 0\n",
      "train: iter 25  trainloss 2.57526  validloss 2.55226±0.00000  bestvalidloss 2.55226  last_update 0\n",
      "train: iter 26  trainloss 2.52928  validloss 2.49623±0.00000  bestvalidloss 2.49623  last_update 0\n",
      "train: iter 27  trainloss 2.50345  validloss 2.47507±0.00000  bestvalidloss 2.47507  last_update 0\n",
      "train: iter 28  trainloss 2.46771  validloss 2.42902±0.00000  bestvalidloss 2.42902  last_update 0\n",
      "train: iter 29  trainloss 2.43320  validloss 2.39694±0.00000  bestvalidloss 2.39694  last_update 0\n",
      "train: iter 30  trainloss 2.39834  validloss 2.36833±0.00000  bestvalidloss 2.36833  last_update 0\n",
      "train: iter 31  trainloss 2.37195  validloss 2.33768±0.00000  bestvalidloss 2.33768  last_update 0\n",
      "train: iter 32  trainloss 2.33299  validloss 2.30544±0.00000  bestvalidloss 2.30544  last_update 0\n",
      "train: iter 33  trainloss 2.30905  validloss 2.27799±0.00000  bestvalidloss 2.27799  last_update 0\n",
      "train: iter 34  trainloss 2.28225  validloss 2.19192±0.00000  bestvalidloss 2.19192  last_update 0\n",
      "train: iter 35  trainloss 2.26290  validloss 2.20528±0.00000  bestvalidloss 2.19192  last_update 1\n",
      "train: iter 36  trainloss 2.23606  validloss 2.17107±0.00000  bestvalidloss 2.17107  last_update 0\n",
      "train: iter 37  trainloss 2.19722  validloss 2.13877±0.00000  bestvalidloss 2.13877  last_update 0\n",
      "train: iter 38  trainloss 2.19065  validloss 2.13440±0.00000  bestvalidloss 2.13440  last_update 0\n",
      "train: iter 39  trainloss 2.15446  validloss 2.11668±0.00000  bestvalidloss 2.11668  last_update 0\n",
      "train: iter 40  trainloss 2.12921  validloss 2.06059±0.00000  bestvalidloss 2.06059  last_update 0\n",
      "train: iter 41  trainloss 2.12245  validloss 2.07361±0.00000  bestvalidloss 2.06059  last_update 1\n",
      "train: iter 42  trainloss 2.08411  validloss 2.01604±0.00000  bestvalidloss 2.01604  last_update 0\n",
      "train: iter 43  trainloss 2.02669  validloss 2.00891±0.00000  bestvalidloss 2.00891  last_update 0\n",
      "train: iter 44  trainloss 2.00643  validloss 1.96805±0.00000  bestvalidloss 1.96805  last_update 0\n",
      "train: iter 45  trainloss 1.99168  validloss 1.91111±0.00000  bestvalidloss 1.91111  last_update 0\n",
      "train: iter 46  trainloss 1.94420  validloss 1.91103±0.00000  bestvalidloss 1.91103  last_update 0\n",
      "train: iter 47  trainloss 1.89347  validloss 1.87090±0.00000  bestvalidloss 1.87090  last_update 0\n",
      "train: iter 48  trainloss 1.88459  validloss 1.83493±0.00000  bestvalidloss 1.83493  last_update 0\n",
      "train: iter 49  trainloss 1.85393  validloss 1.80627±0.00000  bestvalidloss 1.80627  last_update 0\n",
      "train: iter 50  trainloss 1.81213  validloss 1.75759±0.00000  bestvalidloss 1.75759  last_update 0\n",
      "train: iter 51  trainloss 1.76465  validloss 1.72350±0.00000  bestvalidloss 1.72350  last_update 0\n",
      "train: iter 52  trainloss 1.73902  validloss 1.64673±0.00000  bestvalidloss 1.64673  last_update 0\n",
      "train: iter 53  trainloss 1.69300  validloss 1.65318±0.00000  bestvalidloss 1.64673  last_update 1\n",
      "train: iter 54  trainloss 1.65290  validloss 1.56678±0.00000  bestvalidloss 1.56678  last_update 0\n",
      "train: iter 55  trainloss 1.61863  validloss 1.53212±0.00000  bestvalidloss 1.53212  last_update 0\n",
      "train: iter 56  trainloss 1.55062  validloss 1.48319±0.00000  bestvalidloss 1.48319  last_update 0\n",
      "train: iter 57  trainloss 1.49584  validloss 1.44363±0.00000  bestvalidloss 1.44363  last_update 0\n",
      "train: iter 58  trainloss 1.47040  validloss 1.40561±0.00000  bestvalidloss 1.40561  last_update 0\n",
      "train: iter 59  trainloss 1.40194  validloss 1.35667±0.00000  bestvalidloss 1.35667  last_update 0\n",
      "train: iter 60  trainloss 1.36384  validloss 1.27103±0.00000  bestvalidloss 1.27103  last_update 0\n",
      "train: iter 61  trainloss 1.28285  validloss 1.25018±0.00000  bestvalidloss 1.25018  last_update 0\n",
      "train: iter 62  trainloss 1.26869  validloss 1.17534±0.00000  bestvalidloss 1.17534  last_update 0\n",
      "train: iter 63  trainloss 1.21663  validloss 1.18211±0.00000  bestvalidloss 1.17534  last_update 1\n",
      "train: iter 64  trainloss 1.17381  validloss 1.12522±0.00000  bestvalidloss 1.12522  last_update 0\n",
      "train: iter 65  trainloss 1.13559  validloss 1.07526±0.00000  bestvalidloss 1.07526  last_update 0\n",
      "train: iter 66  trainloss 1.08958  validloss 1.01670±0.00000  bestvalidloss 1.01670  last_update 0\n",
      "train: iter 67  trainloss 1.03146  validloss 0.97872±0.00000  bestvalidloss 0.97872  last_update 0\n",
      "train: iter 68  trainloss 1.00371  validloss 0.93001±0.00000  bestvalidloss 0.93001  last_update 0\n",
      "train: iter 69  trainloss 0.96079  validloss 0.90343±0.00000  bestvalidloss 0.90343  last_update 0\n",
      "train: iter 70  trainloss 0.91608  validloss 0.84705±0.00000  bestvalidloss 0.84705  last_update 0\n",
      "train: iter 71  trainloss 0.85963  validloss 0.81413±0.00000  bestvalidloss 0.81413  last_update 0\n",
      "train: iter 72  trainloss 0.85935  validloss 0.80096±0.00000  bestvalidloss 0.80096  last_update 0\n",
      "train: iter 73  trainloss 0.80805  validloss 0.73667±0.00000  bestvalidloss 0.73667  last_update 0\n",
      "train: iter 74  trainloss 0.75383  validloss 0.70251±0.00000  bestvalidloss 0.70251  last_update 0\n",
      "train: iter 75  trainloss 0.72583  validloss 0.66744±0.00000  bestvalidloss 0.66744  last_update 0\n",
      "train: iter 76  trainloss 0.68868  validloss 0.58438±0.00000  bestvalidloss 0.58438  last_update 0\n",
      "train: iter 77  trainloss 0.63906  validloss 0.57468±0.00000  bestvalidloss 0.57468  last_update 0\n",
      "train: iter 78  trainloss 0.59821  validloss 0.51468±0.00000  bestvalidloss 0.51468  last_update 0\n",
      "train: iter 79  trainloss 0.56076  validloss 0.48306±0.00000  bestvalidloss 0.48306  last_update 0\n",
      "train: iter 80  trainloss 0.53009  validloss 0.45665±0.00000  bestvalidloss 0.45665  last_update 0\n",
      "train: iter 81  trainloss 0.48744  validloss 0.42015±0.00000  bestvalidloss 0.42015  last_update 0\n",
      "train: iter 82  trainloss 0.45486  validloss 0.37557±0.00000  bestvalidloss 0.37557  last_update 0\n",
      "train: iter 83  trainloss 0.40353  validloss 0.34631±0.00000  bestvalidloss 0.34631  last_update 0\n",
      "train: iter 84  trainloss 0.39077  validloss 0.33433±0.00000  bestvalidloss 0.33433  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 0.34678  validloss 0.27575±0.00000  bestvalidloss 0.27575  last_update 0\n",
      "train: iter 86  trainloss 0.30557  validloss 0.23084±0.00000  bestvalidloss 0.23084  last_update 0\n",
      "train: iter 87  trainloss 0.28504  validloss 0.20065±0.00000  bestvalidloss 0.20065  last_update 0\n",
      "train: iter 88  trainloss 0.22329  validloss 0.14411±0.00000  bestvalidloss 0.14411  last_update 0\n",
      "train: iter 89  trainloss 0.19655  validloss 0.13749±0.00000  bestvalidloss 0.13749  last_update 0\n",
      "train: iter 90  trainloss 0.14845  validloss 0.09402±0.00000  bestvalidloss 0.09402  last_update 0\n",
      "train: iter 91  trainloss 0.12132  validloss 0.05133±0.00000  bestvalidloss 0.05133  last_update 0\n",
      "train: iter 92  trainloss 0.09824  validloss 0.01550±0.00000  bestvalidloss 0.01550  last_update 0\n",
      "train: iter 93  trainloss 0.06512  validloss -0.04931±0.00000  bestvalidloss -0.04931  last_update 0\n",
      "train: iter 94  trainloss 0.02791  validloss -0.07426±0.00000  bestvalidloss -0.07426  last_update 0\n",
      "train: iter 95  trainloss -0.00282  validloss -0.08653±0.00000  bestvalidloss -0.08653  last_update 0\n",
      "train: iter 96  trainloss -0.01987  validloss -0.15248±0.00000  bestvalidloss -0.15248  last_update 0\n",
      "train: iter 97  trainloss -0.06500  validloss -0.14871±0.00000  bestvalidloss -0.15248  last_update 1\n",
      "train: iter 98  trainloss -0.08949  validloss -0.24434±0.00000  bestvalidloss -0.24434  last_update 0\n",
      "train: iter 99  trainloss -0.10994  validloss -0.19502±0.00000  bestvalidloss -0.24434  last_update 1\n",
      "train: iter 100  trainloss -0.14924  validloss -0.26758±0.00000  bestvalidloss -0.26758  last_update 0\n",
      "train: iter 101  trainloss -0.17230  validloss -0.26380±0.00000  bestvalidloss -0.26758  last_update 1\n",
      "train: iter 102  trainloss -0.22509  validloss -0.33128±0.00000  bestvalidloss -0.33128  last_update 0\n",
      "train: iter 103  trainloss -0.23570  validloss -0.38404±0.00000  bestvalidloss -0.38404  last_update 0\n",
      "train: iter 104  trainloss -0.22862  validloss -0.38323±0.00000  bestvalidloss -0.38404  last_update 1\n",
      "train: iter 105  trainloss -0.26899  validloss -0.39551±0.00000  bestvalidloss -0.39551  last_update 0\n",
      "train: iter 106  trainloss -0.30360  validloss -0.47444±0.00000  bestvalidloss -0.47444  last_update 0\n",
      "train: iter 107  trainloss -0.32828  validloss -0.47501±0.00000  bestvalidloss -0.47501  last_update 0\n",
      "train: iter 108  trainloss -0.32316  validloss -0.46102±0.00000  bestvalidloss -0.47501  last_update 1\n",
      "train: iter 109  trainloss -0.33509  validloss -0.51781±0.00000  bestvalidloss -0.51781  last_update 0\n",
      "train: iter 110  trainloss -0.35938  validloss -0.54857±0.00000  bestvalidloss -0.54857  last_update 0\n",
      "train: iter 111  trainloss -0.37146  validloss -0.51210±0.00000  bestvalidloss -0.54857  last_update 1\n",
      "train: iter 112  trainloss -0.40818  validloss -0.51748±0.00000  bestvalidloss -0.54857  last_update 2\n",
      "train: iter 113  trainloss -0.39978  validloss -0.55281±0.00000  bestvalidloss -0.55281  last_update 0\n",
      "train: iter 114  trainloss -0.41065  validloss -0.62622±0.00000  bestvalidloss -0.62622  last_update 0\n",
      "train: iter 115  trainloss -0.45535  validloss -0.62300±0.00000  bestvalidloss -0.62622  last_update 1\n",
      "train: iter 116  trainloss -0.45124  validloss -0.63262±0.00000  bestvalidloss -0.63262  last_update 0\n",
      "train: iter 117  trainloss -0.43301  validloss -0.64686±0.00000  bestvalidloss -0.64686  last_update 0\n",
      "train: iter 118  trainloss -0.48559  validloss -0.63400±0.00000  bestvalidloss -0.64686  last_update 1\n",
      "train: iter 119  trainloss -0.44590  validloss -0.64963±0.00000  bestvalidloss -0.64963  last_update 0\n",
      "train: iter 120  trainloss -0.49514  validloss -0.66737±0.00000  bestvalidloss -0.66737  last_update 0\n",
      "train: iter 121  trainloss -0.47766  validloss -0.75158±0.00000  bestvalidloss -0.75158  last_update 0\n",
      "train: iter 122  trainloss -0.50043  validloss -0.72483±0.00000  bestvalidloss -0.75158  last_update 1\n",
      "train: iter 123  trainloss -0.50099  validloss -0.77087±0.00000  bestvalidloss -0.77087  last_update 0\n",
      "train: iter 124  trainloss -0.46645  validloss -0.73895±0.00000  bestvalidloss -0.77087  last_update 1\n",
      "train: iter 125  trainloss -0.50357  validloss -0.72648±0.00000  bestvalidloss -0.77087  last_update 2\n",
      "train: iter 126  trainloss -0.50107  validloss -0.78704±0.00000  bestvalidloss -0.78704  last_update 0\n",
      "train: iter 127  trainloss -0.50402  validloss -0.72509±0.00000  bestvalidloss -0.78704  last_update 1\n",
      "train: iter 128  trainloss -0.50423  validloss -0.74809±0.00000  bestvalidloss -0.78704  last_update 2\n",
      "train: iter 129  trainloss -0.49778  validloss -0.71587±0.00000  bestvalidloss -0.78704  last_update 3\n",
      "train: iter 130  trainloss -0.51634  validloss -0.77908±0.00000  bestvalidloss -0.78704  last_update 4\n",
      "train: iter 131  trainloss -0.48281  validloss -0.78147±0.00000  bestvalidloss -0.78704  last_update 5\n",
      "train: iter 132  trainloss -0.49081  validloss -0.75897±0.00000  bestvalidloss -0.78704  last_update 6\n",
      "train: iter 133  trainloss -0.50401  validloss -0.78386±0.00000  bestvalidloss -0.78704  last_update 7\n",
      "train: iter 134  trainloss -0.52348  validloss -0.76989±0.00000  bestvalidloss -0.78704  last_update 8\n",
      "train: iter 135  trainloss -0.51703  validloss -0.72608±0.00000  bestvalidloss -0.78704  last_update 9\n",
      "train: iter 136  trainloss -0.49817  validloss -0.78621±0.00000  bestvalidloss -0.78704  last_update 10\n",
      "train: iter 137  trainloss -0.53433  validloss -0.78613±0.00000  bestvalidloss -0.78704  last_update 11\n",
      "train: iter 138  trainloss -0.49743  validloss -0.75188±0.00000  bestvalidloss -0.78704  last_update 12\n",
      "train: iter 139  trainloss -0.50857  validloss -0.82086±0.00000  bestvalidloss -0.82086  last_update 0\n",
      "train: iter 140  trainloss -0.54338  validloss -0.71565±0.00000  bestvalidloss -0.82086  last_update 1\n",
      "train: iter 141  trainloss -0.49037  validloss -0.81761±0.00000  bestvalidloss -0.82086  last_update 2\n",
      "train: iter 142  trainloss -0.54826  validloss -0.81201±0.00000  bestvalidloss -0.82086  last_update 3\n",
      "train: iter 143  trainloss -0.53341  validloss -0.77638±0.00000  bestvalidloss -0.82086  last_update 4\n",
      "train: iter 144  trainloss -0.52114  validloss -0.76461±0.00000  bestvalidloss -0.82086  last_update 5\n",
      "train: iter 145  trainloss -0.56749  validloss -0.82618±0.00000  bestvalidloss -0.82618  last_update 0\n",
      "train: iter 146  trainloss -0.46283  validloss -0.75218±0.00000  bestvalidloss -0.82618  last_update 1\n",
      "train: iter 147  trainloss -0.54154  validloss -0.78153±0.00000  bestvalidloss -0.82618  last_update 2\n",
      "train: iter 148  trainloss -0.53018  validloss -0.75784±0.00000  bestvalidloss -0.82618  last_update 3\n",
      "train: iter 149  trainloss -0.55377  validloss -0.79774±0.00000  bestvalidloss -0.82618  last_update 4\n",
      "train: iter 150  trainloss -0.54586  validloss -0.82898±0.00000  bestvalidloss -0.82898  last_update 0\n",
      "train: iter 151  trainloss -0.56164  validloss -0.76334±0.00000  bestvalidloss -0.82898  last_update 1\n",
      "train: iter 152  trainloss -0.55746  validloss -0.71580±0.00000  bestvalidloss -0.82898  last_update 2\n",
      "train: iter 153  trainloss -0.51037  validloss -0.77810±0.00000  bestvalidloss -0.82898  last_update 3\n",
      "train: iter 154  trainloss -0.50227  validloss -0.80842±0.00000  bestvalidloss -0.82898  last_update 4\n",
      "train: iter 155  trainloss -0.52156  validloss -0.73650±0.00000  bestvalidloss -0.82898  last_update 5\n",
      "train: iter 156  trainloss -0.57450  validloss -0.79687±0.00000  bestvalidloss -0.82898  last_update 6\n",
      "train: iter 157  trainloss -0.53679  validloss -0.82131±0.00000  bestvalidloss -0.82898  last_update 7\n",
      "train: iter 158  trainloss -0.54196  validloss -0.80663±0.00000  bestvalidloss -0.82898  last_update 8\n",
      "train: iter 159  trainloss -0.51162  validloss -0.80121±0.00000  bestvalidloss -0.82898  last_update 9\n",
      "train: iter 160  trainloss -0.47880  validloss -0.74929±0.00000  bestvalidloss -0.82898  last_update 10\n",
      "train: iter 161  trainloss -0.55368  validloss -0.81638±0.00000  bestvalidloss -0.82898  last_update 11\n",
      "train: iter 162  trainloss -0.55091  validloss -0.82305±0.00000  bestvalidloss -0.82898  last_update 12\n",
      "train: iter 163  trainloss -0.56140  validloss -0.80225±0.00000  bestvalidloss -0.82898  last_update 13\n",
      "train: iter 164  trainloss -0.54240  validloss -0.83611±0.00000  bestvalidloss -0.83611  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 165  trainloss -0.51770  validloss -0.81258±0.00000  bestvalidloss -0.83611  last_update 1\n",
      "train: iter 166  trainloss -0.51840  validloss -0.82811±0.00000  bestvalidloss -0.83611  last_update 2\n",
      "train: iter 167  trainloss -0.46826  validloss -0.82155±0.00000  bestvalidloss -0.83611  last_update 3\n",
      "train: iter 168  trainloss -0.51661  validloss -0.80622±0.00000  bestvalidloss -0.83611  last_update 4\n",
      "train: iter 169  trainloss -0.46828  validloss -0.83151±0.00000  bestvalidloss -0.83611  last_update 5\n",
      "train: iter 170  trainloss -0.49812  validloss -0.78714±0.00000  bestvalidloss -0.83611  last_update 6\n",
      "train: iter 171  trainloss -0.53094  validloss -0.79759±0.00000  bestvalidloss -0.83611  last_update 7\n",
      "train: iter 172  trainloss -0.51574  validloss -0.80649±0.00000  bestvalidloss -0.83611  last_update 8\n",
      "train: iter 173  trainloss -0.56745  validloss -0.84318±0.00000  bestvalidloss -0.84318  last_update 0\n",
      "train: iter 174  trainloss -0.53636  validloss -0.76709±0.00000  bestvalidloss -0.84318  last_update 1\n",
      "train: iter 175  trainloss -0.47461  validloss -0.84309±0.00000  bestvalidloss -0.84318  last_update 2\n",
      "train: iter 176  trainloss -0.50627  validloss -0.81291±0.00000  bestvalidloss -0.84318  last_update 3\n",
      "train: iter 177  trainloss -0.52716  validloss -0.87141±0.00000  bestvalidloss -0.87141  last_update 0\n",
      "train: iter 178  trainloss -0.51768  validloss -0.82682±0.00000  bestvalidloss -0.87141  last_update 1\n",
      "train: iter 179  trainloss -0.50467  validloss -0.81944±0.00000  bestvalidloss -0.87141  last_update 2\n",
      "train: iter 180  trainloss -0.54270  validloss -0.79853±0.00000  bestvalidloss -0.87141  last_update 3\n",
      "train: iter 181  trainloss -0.49907  validloss -0.73311±0.00000  bestvalidloss -0.87141  last_update 4\n",
      "train: iter 182  trainloss -0.54506  validloss -0.78324±0.00000  bestvalidloss -0.87141  last_update 5\n",
      "train: iter 183  trainloss -0.51485  validloss -0.90075±0.00000  bestvalidloss -0.90075  last_update 0\n",
      "train: iter 184  trainloss -0.54840  validloss -0.77030±0.00000  bestvalidloss -0.90075  last_update 1\n",
      "train: iter 185  trainloss -0.52871  validloss -0.78233±0.00000  bestvalidloss -0.90075  last_update 2\n",
      "train: iter 186  trainloss -0.54862  validloss -0.78004±0.00000  bestvalidloss -0.90075  last_update 3\n",
      "train: iter 187  trainloss -0.55227  validloss -0.80032±0.00000  bestvalidloss -0.90075  last_update 4\n",
      "train: iter 188  trainloss -0.48850  validloss -0.87644±0.00000  bestvalidloss -0.90075  last_update 5\n",
      "train: iter 189  trainloss -0.53747  validloss -0.75403±0.00000  bestvalidloss -0.90075  last_update 6\n",
      "train: iter 190  trainloss -0.56632  validloss -0.87911±0.00000  bestvalidloss -0.90075  last_update 7\n",
      "train: iter 191  trainloss -0.50585  validloss -0.75103±0.00000  bestvalidloss -0.90075  last_update 8\n",
      "train: iter 192  trainloss -0.52397  validloss -0.86329±0.00000  bestvalidloss -0.90075  last_update 9\n",
      "train: iter 193  trainloss -0.55994  validloss -0.74022±0.00000  bestvalidloss -0.90075  last_update 10\n",
      "train: iter 194  trainloss -0.53122  validloss -0.80532±0.00000  bestvalidloss -0.90075  last_update 11\n",
      "train: iter 195  trainloss -0.53269  validloss -0.84793±0.00000  bestvalidloss -0.90075  last_update 12\n",
      "train: iter 196  trainloss -0.51785  validloss -0.84057±0.00000  bestvalidloss -0.90075  last_update 13\n",
      "train: iter 197  trainloss -0.51754  validloss -0.84385±0.00000  bestvalidloss -0.90075  last_update 14\n",
      "train: iter 198  trainloss -0.55602  validloss -0.82775±0.00000  bestvalidloss -0.90075  last_update 15\n",
      "train: iter 199  trainloss -0.51254  validloss -0.85174±0.00000  bestvalidloss -0.90075  last_update 16\n",
      "train: iter 200  trainloss -0.56175  validloss -0.73090±0.00000  bestvalidloss -0.90075  last_update 17\n",
      "train: iter 201  trainloss -0.48461  validloss -0.83407±0.00000  bestvalidloss -0.90075  last_update 18\n",
      "train: iter 202  trainloss -0.55661  validloss -0.77545±0.00000  bestvalidloss -0.90075  last_update 19\n",
      "train: iter 203  trainloss -0.52799  validloss -0.89818±0.00000  bestvalidloss -0.90075  last_update 20\n",
      "train: iter 204  trainloss -0.54297  validloss -0.86910±0.00000  bestvalidloss -0.90075  last_update 21\n",
      "train: iter 205  trainloss -0.53827  validloss -0.85511±0.00000  bestvalidloss -0.90075  last_update 22\n",
      "train: iter 206  trainloss -0.52882  validloss -0.82736±0.00000  bestvalidloss -0.90075  last_update 23\n",
      "train: iter 207  trainloss -0.54538  validloss -0.82636±0.00000  bestvalidloss -0.90075  last_update 24\n",
      "train: iter 208  trainloss -0.55740  validloss -0.77289±0.00000  bestvalidloss -0.90075  last_update 25\n",
      "train: iter 209  trainloss -0.53507  validloss -0.73509±0.00000  bestvalidloss -0.90075  last_update 26\n",
      "train: iter 210  trainloss -0.53385  validloss -0.81089±0.00000  bestvalidloss -0.90075  last_update 27\n",
      "train: iter 211  trainloss -0.56567  validloss -0.86403±0.00000  bestvalidloss -0.90075  last_update 28\n",
      "train: iter 212  trainloss -0.50364  validloss -0.73863±0.00000  bestvalidloss -0.90075  last_update 29\n",
      "train: iter 213  trainloss -0.51750  validloss -0.85293±0.00000  bestvalidloss -0.90075  last_update 30\n",
      "train: iter 214  trainloss -0.53013  validloss -0.84149±0.00000  bestvalidloss -0.90075  last_update 31\n",
      "train: iter 215  trainloss -0.52630  validloss -0.87435±0.00000  bestvalidloss -0.90075  last_update 32\n",
      "train: iter 216  trainloss -0.48729  validloss -0.82456±0.00000  bestvalidloss -0.90075  last_update 33\n",
      "train: iter 217  trainloss -0.54255  validloss -0.84691±0.00000  bestvalidloss -0.90075  last_update 34\n",
      "train: iter 218  trainloss -0.58499  validloss -0.80509±0.00000  bestvalidloss -0.90075  last_update 35\n",
      "train: iter 219  trainloss -0.54823  validloss -0.77896±0.00000  bestvalidloss -0.90075  last_update 36\n",
      "train: iter 220  trainloss -0.58672  validloss -0.83121±0.00000  bestvalidloss -0.90075  last_update 37\n",
      "train: iter 221  trainloss -0.52850  validloss -0.77623±0.00000  bestvalidloss -0.90075  last_update 38\n",
      "train: iter 222  trainloss -0.51617  validloss -0.84300±0.00000  bestvalidloss -0.90075  last_update 39\n",
      "train: iter 223  trainloss -0.46031  validloss -0.79404±0.00000  bestvalidloss -0.90075  last_update 40\n",
      "train: iter 224  trainloss -0.52734  validloss -0.84257±0.00000  bestvalidloss -0.90075  last_update 41\n",
      "train: iter 225  trainloss -0.53373  validloss -0.81141±0.00000  bestvalidloss -0.90075  last_update 42\n",
      "train: iter 226  trainloss -0.49921  validloss -0.79340±0.00000  bestvalidloss -0.90075  last_update 43\n",
      "train: iter 227  trainloss -0.58509  validloss -0.86393±0.00000  bestvalidloss -0.90075  last_update 44\n",
      "train: iter 228  trainloss -0.50476  validloss -0.85944±0.00000  bestvalidloss -0.90075  last_update 45\n",
      "train: iter 229  trainloss -0.54721  validloss -0.87035±0.00000  bestvalidloss -0.90075  last_update 46\n",
      "train: iter 230  trainloss -0.54885  validloss -0.76673±0.00000  bestvalidloss -0.90075  last_update 47\n",
      "train: iter 231  trainloss -0.53432  validloss -0.80374±0.00000  bestvalidloss -0.90075  last_update 48\n",
      "train: iter 232  trainloss -0.51525  validloss -0.78206±0.00000  bestvalidloss -0.90075  last_update 49\n",
      "train: iter 233  trainloss -0.51071  validloss -0.81166±0.00000  bestvalidloss -0.90075  last_update 50\n",
      "train: iter 234  trainloss -0.47219  validloss -0.78382±0.00000  bestvalidloss -0.90075  last_update 51\n",
      "train: iter 235  trainloss -0.51054  validloss -0.86443±0.00000  bestvalidloss -0.90075  last_update 52\n",
      "train: iter 236  trainloss -0.51259  validloss -0.75793±0.00000  bestvalidloss -0.90075  last_update 53\n",
      "train: iter 237  trainloss -0.46216  validloss -0.77087±0.00000  bestvalidloss -0.90075  last_update 54\n",
      "train: iter 238  trainloss -0.55711  validloss -0.85724±0.00000  bestvalidloss -0.90075  last_update 55\n",
      "train: iter 239  trainloss -0.56211  validloss -0.88467±0.00000  bestvalidloss -0.90075  last_update 56\n",
      "train: iter 240  trainloss -0.52297  validloss -0.79314±0.00000  bestvalidloss -0.90075  last_update 57\n",
      "train: iter 241  trainloss -0.56141  validloss -0.76406±0.00000  bestvalidloss -0.90075  last_update 58\n",
      "train: iter 242  trainloss -0.50439  validloss -0.82741±0.00000  bestvalidloss -0.90075  last_update 59\n",
      "train: iter 243  trainloss -0.53658  validloss -0.84915±0.00000  bestvalidloss -0.90075  last_update 60\n",
      "train: iter 244  trainloss -0.56101  validloss -0.81775±0.00000  bestvalidloss -0.90075  last_update 61\n",
      "train: iter 245  trainloss -0.50349  validloss -0.89317±0.00000  bestvalidloss -0.90075  last_update 62\n",
      "train: iter 246  trainloss -0.54156  validloss -0.81746±0.00000  bestvalidloss -0.90075  last_update 63\n",
      "train: iter 247  trainloss -0.57902  validloss -0.89012±0.00000  bestvalidloss -0.90075  last_update 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 248  trainloss -0.52363  validloss -0.82779±0.00000  bestvalidloss -0.90075  last_update 65\n",
      "train: iter 249  trainloss -0.51569  validloss -0.79246±0.00000  bestvalidloss -0.90075  last_update 66\n",
      "train: iter 250  trainloss -0.53706  validloss -0.78547±0.00000  bestvalidloss -0.90075  last_update 67\n",
      "train: iter 251  trainloss -0.52605  validloss -0.76089±0.00000  bestvalidloss -0.90075  last_update 68\n",
      "train: iter 252  trainloss -0.54992  validloss -0.83960±0.00000  bestvalidloss -0.90075  last_update 69\n",
      "train: iter 253  trainloss -0.51475  validloss -0.78767±0.00000  bestvalidloss -0.90075  last_update 70\n",
      "train: iter 254  trainloss -0.56621  validloss -0.76924±0.00000  bestvalidloss -0.90075  last_update 71\n",
      "train: iter 255  trainloss -0.53239  validloss -0.82978±0.00000  bestvalidloss -0.90075  last_update 72\n",
      "train: iter 256  trainloss -0.53381  validloss -0.83751±0.00000  bestvalidloss -0.90075  last_update 73\n",
      "train: iter 257  trainloss -0.55966  validloss -0.80710±0.00000  bestvalidloss -0.90075  last_update 74\n",
      "train: iter 258  trainloss -0.52352  validloss -0.83089±0.00000  bestvalidloss -0.90075  last_update 75\n",
      "train: iter 259  trainloss -0.52957  validloss -0.81416±0.00000  bestvalidloss -0.90075  last_update 76\n",
      "train: iter 260  trainloss -0.50478  validloss -0.84576±0.00000  bestvalidloss -0.90075  last_update 77\n",
      "train: iter 261  trainloss -0.56498  validloss -0.84739±0.00000  bestvalidloss -0.90075  last_update 78\n",
      "train: iter 262  trainloss -0.50184  validloss -0.79069±0.00000  bestvalidloss -0.90075  last_update 79\n",
      "train: iter 263  trainloss -0.54310  validloss -0.77927±0.00000  bestvalidloss -0.90075  last_update 80\n",
      "train: iter 264  trainloss -0.52121  validloss -0.79811±0.00000  bestvalidloss -0.90075  last_update 81\n",
      "train: iter 265  trainloss -0.51940  validloss -0.89837±0.00000  bestvalidloss -0.90075  last_update 82\n",
      "train: iter 266  trainloss -0.58222  validloss -0.84631±0.00000  bestvalidloss -0.90075  last_update 83\n",
      "train: iter 267  trainloss -0.59518  validloss -0.80615±0.00000  bestvalidloss -0.90075  last_update 84\n",
      "train: iter 268  trainloss -0.57288  validloss -0.80306±0.00000  bestvalidloss -0.90075  last_update 85\n",
      "train: iter 269  trainloss -0.55637  validloss -0.89790±0.00000  bestvalidloss -0.90075  last_update 86\n",
      "train: iter 270  trainloss -0.55746  validloss -0.81403±0.00000  bestvalidloss -0.90075  last_update 87\n",
      "train: iter 271  trainloss -0.53588  validloss -0.87051±0.00000  bestvalidloss -0.90075  last_update 88\n",
      "train: iter 272  trainloss -0.52066  validloss -0.87388±0.00000  bestvalidloss -0.90075  last_update 89\n",
      "train: iter 273  trainloss -0.51722  validloss -0.81132±0.00000  bestvalidloss -0.90075  last_update 90\n",
      "train: iter 274  trainloss -0.51666  validloss -0.84989±0.00000  bestvalidloss -0.90075  last_update 91\n",
      "train: iter 275  trainloss -0.53133  validloss -0.80330±0.00000  bestvalidloss -0.90075  last_update 92\n",
      "train: iter 276  trainloss -0.52987  validloss -0.78608±0.00000  bestvalidloss -0.90075  last_update 93\n",
      "train: iter 277  trainloss -0.55247  validloss -0.84875±0.00000  bestvalidloss -0.90075  last_update 94\n",
      "train: iter 278  trainloss -0.50342  validloss -0.82436±0.00000  bestvalidloss -0.90075  last_update 95\n",
      "train: iter 279  trainloss -0.49853  validloss -0.79916±0.00000  bestvalidloss -0.90075  last_update 96\n",
      "train: iter 280  trainloss -0.53107  validloss -0.84116±0.00000  bestvalidloss -0.90075  last_update 97\n",
      "train: iter 281  trainloss -0.49402  validloss -0.81370±0.00000  bestvalidloss -0.90075  last_update 98\n",
      "train: iter 282  trainloss -0.56183  validloss -0.82286±0.00000  bestvalidloss -0.90075  last_update 99\n",
      "train: iter 283  trainloss -0.55255  validloss -0.76407±0.00000  bestvalidloss -0.90075  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.3984, -0.0369, -4.6606, -2.0509], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 73.26220  validloss 79.78729±0.00000  bestvalidloss 79.78729  last_update 0\n",
      "train: iter 1  trainloss 52.55297  validloss 61.33328±0.00000  bestvalidloss 61.33328  last_update 0\n",
      "train: iter 2  trainloss 37.12792  validloss 41.96709±0.00000  bestvalidloss 41.96709  last_update 0\n",
      "train: iter 3  trainloss 27.35730  validloss 31.19867±0.00000  bestvalidloss 31.19867  last_update 0\n",
      "train: iter 4  trainloss 20.76290  validloss 23.31572±0.00000  bestvalidloss 23.31572  last_update 0\n",
      "train: iter 5  trainloss 16.42229  validloss 18.60270±0.00000  bestvalidloss 18.60270  last_update 0\n",
      "train: iter 6  trainloss 13.44568  validloss 15.20841±0.00000  bestvalidloss 15.20841  last_update 0\n",
      "train: iter 7  trainloss 11.32023  validloss 12.88715±0.00000  bestvalidloss 12.88715  last_update 0\n",
      "train: iter 8  trainloss 9.74235  validloss 11.34522±0.00000  bestvalidloss 11.34522  last_update 0\n",
      "train: iter 9  trainloss 8.61924  validloss 10.11495±0.00000  bestvalidloss 10.11495  last_update 0\n",
      "train: iter 10  trainloss 7.82560  validloss 9.27511±0.00000  bestvalidloss 9.27511  last_update 0\n",
      "train: iter 11  trainloss 7.16694  validloss 8.70065±0.00000  bestvalidloss 8.70065  last_update 0\n",
      "train: iter 12  trainloss 6.61626  validloss 8.20206±0.00000  bestvalidloss 8.20206  last_update 0\n",
      "train: iter 13  trainloss 6.09435  validloss 7.50132±0.00000  bestvalidloss 7.50132  last_update 0\n",
      "train: iter 14  trainloss 5.66494  validloss 7.02866±0.00000  bestvalidloss 7.02866  last_update 0\n",
      "train: iter 15  trainloss 5.37494  validloss 6.66188±0.00000  bestvalidloss 6.66188  last_update 0\n",
      "train: iter 16  trainloss 5.12245  validloss 6.21590±0.00000  bestvalidloss 6.21590  last_update 0\n",
      "train: iter 17  trainloss 4.92195  validloss 6.01511±0.00000  bestvalidloss 6.01511  last_update 0\n",
      "train: iter 18  trainloss 4.72864  validloss 5.76502±0.00000  bestvalidloss 5.76502  last_update 0\n",
      "train: iter 19  trainloss 4.59178  validloss 5.62991±0.00000  bestvalidloss 5.62991  last_update 0\n",
      "train: iter 20  trainloss 4.49842  validloss 5.39816±0.00000  bestvalidloss 5.39816  last_update 0\n",
      "train: iter 21  trainloss 4.44965  validloss 5.29478±0.00000  bestvalidloss 5.29478  last_update 0\n",
      "train: iter 22  trainloss 4.37574  validloss 5.35065±0.00000  bestvalidloss 5.29478  last_update 1\n",
      "train: iter 23  trainloss 4.31207  validloss 5.11896±0.00000  bestvalidloss 5.11896  last_update 0\n",
      "train: iter 24  trainloss 4.25193  validloss 5.10688±0.00000  bestvalidloss 5.10688  last_update 0\n",
      "train: iter 25  trainloss 4.22144  validloss 5.04080±0.00000  bestvalidloss 5.04080  last_update 0\n",
      "train: iter 26  trainloss 4.21832  validloss 5.04629±0.00000  bestvalidloss 5.04080  last_update 1\n",
      "train: iter 27  trainloss 4.16320  validloss 4.99493±0.00000  bestvalidloss 4.99493  last_update 0\n",
      "train: iter 28  trainloss 4.13936  validloss 4.94027±0.00000  bestvalidloss 4.94027  last_update 0\n",
      "train: iter 29  trainloss 4.13346  validloss 5.05648±0.00000  bestvalidloss 4.94027  last_update 1\n",
      "train: iter 30  trainloss 4.09281  validloss 4.98460±0.00000  bestvalidloss 4.94027  last_update 2\n",
      "train: iter 31  trainloss 4.06050  validloss 4.98910±0.00000  bestvalidloss 4.94027  last_update 3\n",
      "train: iter 32  trainloss 4.03733  validloss 4.98562±0.00000  bestvalidloss 4.94027  last_update 4\n",
      "train: iter 33  trainloss 3.96198  validloss 4.84290±0.00000  bestvalidloss 4.84290  last_update 0\n",
      "train: iter 34  trainloss 3.92782  validloss 4.84890±0.00000  bestvalidloss 4.84290  last_update 1\n",
      "train: iter 35  trainloss 3.90698  validloss 4.88308±0.00000  bestvalidloss 4.84290  last_update 2\n",
      "train: iter 36  trainloss 3.85993  validloss 4.86885±0.00000  bestvalidloss 4.84290  last_update 3\n",
      "train: iter 37  trainloss 3.82511  validloss 4.69279±0.00000  bestvalidloss 4.69279  last_update 0\n",
      "train: iter 38  trainloss 3.80867  validloss 4.83173±0.00000  bestvalidloss 4.69279  last_update 1\n",
      "train: iter 39  trainloss 3.78161  validloss 4.88396±0.00000  bestvalidloss 4.69279  last_update 2\n",
      "train: iter 40  trainloss 3.75741  validloss 4.81961±0.00000  bestvalidloss 4.69279  last_update 3\n",
      "train: iter 41  trainloss 3.72627  validloss 4.82741±0.00000  bestvalidloss 4.69279  last_update 4\n",
      "train: iter 42  trainloss 3.72977  validloss 4.77948±0.00000  bestvalidloss 4.69279  last_update 5\n",
      "train: iter 43  trainloss 3.68971  validloss 4.75135±0.00000  bestvalidloss 4.69279  last_update 6\n",
      "train: iter 44  trainloss 3.61710  validloss 4.79954±0.00000  bestvalidloss 4.69279  last_update 7\n",
      "train: iter 45  trainloss 3.65268  validloss 4.72117±0.00000  bestvalidloss 4.69279  last_update 8\n",
      "train: iter 46  trainloss 3.65416  validloss 4.78017±0.00000  bestvalidloss 4.69279  last_update 9\n",
      "train: iter 47  trainloss 3.63836  validloss 4.73836±0.00000  bestvalidloss 4.69279  last_update 10\n",
      "train: iter 48  trainloss 3.58705  validloss 4.87115±0.00000  bestvalidloss 4.69279  last_update 11\n",
      "train: iter 49  trainloss 3.56831  validloss 4.78405±0.00000  bestvalidloss 4.69279  last_update 12\n",
      "train: iter 50  trainloss 3.59335  validloss 4.79288±0.00000  bestvalidloss 4.69279  last_update 13\n",
      "train: iter 51  trainloss 3.54165  validloss 4.95143±0.00000  bestvalidloss 4.69279  last_update 14\n",
      "train: iter 52  trainloss 3.55605  validloss 4.75037±0.00000  bestvalidloss 4.69279  last_update 15\n",
      "train: iter 53  trainloss 3.56230  validloss 4.71813±0.00000  bestvalidloss 4.69279  last_update 16\n",
      "train: iter 54  trainloss 3.55568  validloss 4.84808±0.00000  bestvalidloss 4.69279  last_update 17\n",
      "train: iter 55  trainloss 3.51904  validloss 4.79135±0.00000  bestvalidloss 4.69279  last_update 18\n",
      "train: iter 56  trainloss 3.51568  validloss 4.92354±0.00000  bestvalidloss 4.69279  last_update 19\n",
      "train: iter 57  trainloss 3.53628  validloss 4.82083±0.00000  bestvalidloss 4.69279  last_update 20\n",
      "train: iter 58  trainloss 3.51213  validloss 4.76795±0.00000  bestvalidloss 4.69279  last_update 21\n",
      "train: iter 59  trainloss 3.48254  validloss 5.02546±0.00000  bestvalidloss 4.69279  last_update 22\n",
      "train: iter 60  trainloss 3.52786  validloss 4.82578±0.00000  bestvalidloss 4.69279  last_update 23\n",
      "train: iter 61  trainloss 3.49935  validloss 4.77388±0.00000  bestvalidloss 4.69279  last_update 24\n",
      "train: iter 62  trainloss 3.50905  validloss 4.70816±0.00000  bestvalidloss 4.69279  last_update 25\n",
      "train: iter 63  trainloss 3.49022  validloss 4.83937±0.00000  bestvalidloss 4.69279  last_update 26\n",
      "train: iter 64  trainloss 3.47528  validloss 4.77788±0.00000  bestvalidloss 4.69279  last_update 27\n",
      "train: iter 65  trainloss 3.50104  validloss 4.75659±0.00000  bestvalidloss 4.69279  last_update 28\n",
      "train: iter 66  trainloss 3.44163  validloss 4.70922±0.00000  bestvalidloss 4.69279  last_update 29\n",
      "train: iter 67  trainloss 3.43529  validloss 4.81097±0.00000  bestvalidloss 4.69279  last_update 30\n",
      "train: iter 68  trainloss 3.44222  validloss 4.72903±0.00000  bestvalidloss 4.69279  last_update 31\n",
      "train: iter 69  trainloss 3.45176  validloss 4.69663±0.00000  bestvalidloss 4.69279  last_update 32\n",
      "train: iter 70  trainloss 3.44598  validloss 4.62467±0.00000  bestvalidloss 4.62467  last_update 0\n",
      "train: iter 71  trainloss 3.36817  validloss 4.70344±0.00000  bestvalidloss 4.62467  last_update 1\n",
      "train: iter 72  trainloss 3.39115  validloss 4.70801±0.00000  bestvalidloss 4.62467  last_update 2\n",
      "train: iter 73  trainloss 3.45828  validloss 4.76691±0.00000  bestvalidloss 4.62467  last_update 3\n",
      "train: iter 74  trainloss 3.39300  validloss 4.69810±0.00000  bestvalidloss 4.62467  last_update 4\n",
      "train: iter 75  trainloss 3.38472  validloss 4.58095±0.00000  bestvalidloss 4.58095  last_update 0\n",
      "train: iter 76  trainloss 3.38552  validloss 4.66245±0.00000  bestvalidloss 4.58095  last_update 1\n",
      "train: iter 77  trainloss 3.38262  validloss 4.66239±0.00000  bestvalidloss 4.58095  last_update 2\n",
      "train: iter 78  trainloss 3.38839  validloss 4.67255±0.00000  bestvalidloss 4.58095  last_update 3\n",
      "train: iter 79  trainloss 3.42081  validloss 4.74096±0.00000  bestvalidloss 4.58095  last_update 4\n",
      "train: iter 80  trainloss 3.39029  validloss 4.60845±0.00000  bestvalidloss 4.58095  last_update 5\n",
      "train: iter 81  trainloss 3.39817  validloss 4.64524±0.00000  bestvalidloss 4.58095  last_update 6\n",
      "train: iter 82  trainloss 3.38621  validloss 4.73502±0.00000  bestvalidloss 4.58095  last_update 7\n",
      "train: iter 83  trainloss 3.39786  validloss 4.67557±0.00000  bestvalidloss 4.58095  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 3.39803  validloss 4.65146±0.00000  bestvalidloss 4.58095  last_update 9\n",
      "train: iter 85  trainloss 3.43234  validloss 4.65250±0.00000  bestvalidloss 4.58095  last_update 10\n",
      "train: iter 86  trainloss 3.38379  validloss 4.79820±0.00000  bestvalidloss 4.58095  last_update 11\n",
      "train: iter 87  trainloss 3.40013  validloss 4.57023±0.00000  bestvalidloss 4.57023  last_update 0\n",
      "train: iter 88  trainloss 3.37583  validloss 4.72169±0.00000  bestvalidloss 4.57023  last_update 1\n",
      "train: iter 89  trainloss 3.38384  validloss 4.64047±0.00000  bestvalidloss 4.57023  last_update 2\n",
      "train: iter 90  trainloss 3.37259  validloss 4.64689±0.00000  bestvalidloss 4.57023  last_update 3\n",
      "train: iter 91  trainloss 3.39043  validloss 4.69438±0.00000  bestvalidloss 4.57023  last_update 4\n",
      "train: iter 92  trainloss 3.40605  validloss 4.69675±0.00000  bestvalidloss 4.57023  last_update 5\n",
      "train: iter 93  trainloss 3.34281  validloss 4.62382±0.00000  bestvalidloss 4.57023  last_update 6\n",
      "train: iter 94  trainloss 3.39763  validloss 4.59235±0.00000  bestvalidloss 4.57023  last_update 7\n",
      "train: iter 95  trainloss 3.39052  validloss 4.72965±0.00000  bestvalidloss 4.57023  last_update 8\n",
      "train: iter 96  trainloss 3.36875  validloss 4.52608±0.00000  bestvalidloss 4.52608  last_update 0\n",
      "train: iter 97  trainloss 3.34805  validloss 4.61992±0.00000  bestvalidloss 4.52608  last_update 1\n",
      "train: iter 98  trainloss 3.39385  validloss 4.53687±0.00000  bestvalidloss 4.52608  last_update 2\n",
      "train: iter 99  trainloss 3.38273  validloss 4.61658±0.00000  bestvalidloss 4.52608  last_update 3\n",
      "train: iter 100  trainloss 3.38144  validloss 4.66102±0.00000  bestvalidloss 4.52608  last_update 4\n",
      "train: iter 101  trainloss 3.35992  validloss 4.50756±0.00000  bestvalidloss 4.50756  last_update 0\n",
      "train: iter 102  trainloss 3.34273  validloss 4.68191±0.00000  bestvalidloss 4.50756  last_update 1\n",
      "train: iter 103  trainloss 3.34951  validloss 4.53296±0.00000  bestvalidloss 4.50756  last_update 2\n",
      "train: iter 104  trainloss 3.38877  validloss 4.78990±0.00000  bestvalidloss 4.50756  last_update 3\n",
      "train: iter 105  trainloss 3.33627  validloss 4.63866±0.00000  bestvalidloss 4.50756  last_update 4\n",
      "train: iter 106  trainloss 3.37588  validloss 4.72915±0.00000  bestvalidloss 4.50756  last_update 5\n",
      "train: iter 107  trainloss 3.36319  validloss 4.51836±0.00000  bestvalidloss 4.50756  last_update 6\n",
      "train: iter 108  trainloss 3.34297  validloss 4.57948±0.00000  bestvalidloss 4.50756  last_update 7\n",
      "train: iter 109  trainloss 3.37856  validloss 4.70119±0.00000  bestvalidloss 4.50756  last_update 8\n",
      "train: iter 110  trainloss 3.35233  validloss 4.66338±0.00000  bestvalidloss 4.50756  last_update 9\n",
      "train: iter 111  trainloss 3.42174  validloss 4.65412±0.00000  bestvalidloss 4.50756  last_update 10\n",
      "train: iter 112  trainloss 3.35778  validloss 4.59985±0.00000  bestvalidloss 4.50756  last_update 11\n",
      "train: iter 113  trainloss 3.32549  validloss 4.57482±0.00000  bestvalidloss 4.50756  last_update 12\n",
      "train: iter 114  trainloss 3.36472  validloss 4.68461±0.00000  bestvalidloss 4.50756  last_update 13\n",
      "train: iter 115  trainloss 3.35082  validloss 4.55551±0.00000  bestvalidloss 4.50756  last_update 14\n",
      "train: iter 116  trainloss 3.31448  validloss 4.52234±0.00000  bestvalidloss 4.50756  last_update 15\n",
      "train: iter 117  trainloss 3.34148  validloss 4.54274±0.00000  bestvalidloss 4.50756  last_update 16\n",
      "train: iter 118  trainloss 3.33306  validloss 4.49154±0.00000  bestvalidloss 4.49154  last_update 0\n",
      "train: iter 119  trainloss 3.36268  validloss 4.52275±0.00000  bestvalidloss 4.49154  last_update 1\n",
      "train: iter 120  trainloss 3.34438  validloss 4.43546±0.00000  bestvalidloss 4.43546  last_update 0\n",
      "train: iter 121  trainloss 3.33825  validloss 4.58327±0.00000  bestvalidloss 4.43546  last_update 1\n",
      "train: iter 122  trainloss 3.32975  validloss 4.57955±0.00000  bestvalidloss 4.43546  last_update 2\n",
      "train: iter 123  trainloss 3.32187  validloss 4.49627±0.00000  bestvalidloss 4.43546  last_update 3\n",
      "train: iter 124  trainloss 3.32789  validloss 4.49664±0.00000  bestvalidloss 4.43546  last_update 4\n",
      "train: iter 125  trainloss 3.32423  validloss 4.47140±0.00000  bestvalidloss 4.43546  last_update 5\n",
      "train: iter 126  trainloss 3.35764  validloss 4.50046±0.00000  bestvalidloss 4.43546  last_update 6\n",
      "train: iter 127  trainloss 3.33238  validloss 4.60772±0.00000  bestvalidloss 4.43546  last_update 7\n",
      "train: iter 128  trainloss 3.34005  validloss 4.63631±0.00000  bestvalidloss 4.43546  last_update 8\n",
      "train: iter 129  trainloss 3.32910  validloss 4.55861±0.00000  bestvalidloss 4.43546  last_update 9\n",
      "train: iter 130  trainloss 3.31292  validloss 4.62077±0.00000  bestvalidloss 4.43546  last_update 10\n",
      "train: iter 131  trainloss 3.33689  validloss 4.50809±0.00000  bestvalidloss 4.43546  last_update 11\n",
      "train: iter 132  trainloss 3.29998  validloss 4.66092±0.00000  bestvalidloss 4.43546  last_update 12\n",
      "train: iter 133  trainloss 3.33574  validloss 4.56165±0.00000  bestvalidloss 4.43546  last_update 13\n",
      "train: iter 134  trainloss 3.33549  validloss 4.57602±0.00000  bestvalidloss 4.43546  last_update 14\n",
      "train: iter 135  trainloss 3.34916  validloss 4.47758±0.00000  bestvalidloss 4.43546  last_update 15\n",
      "train: iter 136  trainloss 3.30297  validloss 4.56350±0.00000  bestvalidloss 4.43546  last_update 16\n",
      "train: iter 137  trainloss 3.30273  validloss 4.44247±0.00000  bestvalidloss 4.43546  last_update 17\n",
      "train: iter 138  trainloss 3.30758  validloss 4.51457±0.00000  bestvalidloss 4.43546  last_update 18\n",
      "train: iter 139  trainloss 3.31104  validloss 4.58626±0.00000  bestvalidloss 4.43546  last_update 19\n",
      "train: iter 140  trainloss 3.32337  validloss 4.60228±0.00000  bestvalidloss 4.43546  last_update 20\n",
      "train: iter 141  trainloss 3.32637  validloss 4.48852±0.00000  bestvalidloss 4.43546  last_update 21\n",
      "train: iter 142  trainloss 3.35298  validloss 4.42765±0.00000  bestvalidloss 4.42765  last_update 0\n",
      "train: iter 143  trainloss 3.36252  validloss 4.57053±0.00000  bestvalidloss 4.42765  last_update 1\n",
      "train: iter 144  trainloss 3.30874  validloss 4.55389±0.00000  bestvalidloss 4.42765  last_update 2\n",
      "train: iter 145  trainloss 3.30817  validloss 4.53017±0.00000  bestvalidloss 4.42765  last_update 3\n",
      "train: iter 146  trainloss 3.30083  validloss 4.50694±0.00000  bestvalidloss 4.42765  last_update 4\n",
      "train: iter 147  trainloss 3.33329  validloss 4.58002±0.00000  bestvalidloss 4.42765  last_update 5\n",
      "train: iter 148  trainloss 3.30330  validloss 4.50732±0.00000  bestvalidloss 4.42765  last_update 6\n",
      "train: iter 149  trainloss 3.31322  validloss 4.54409±0.00000  bestvalidloss 4.42765  last_update 7\n",
      "train: iter 150  trainloss 3.27159  validloss 4.42984±0.00000  bestvalidloss 4.42765  last_update 8\n",
      "train: iter 151  trainloss 3.34593  validloss 4.72819±0.00000  bestvalidloss 4.42765  last_update 9\n",
      "train: iter 152  trainloss 3.30683  validloss 4.35577±0.00000  bestvalidloss 4.35577  last_update 0\n",
      "train: iter 153  trainloss 3.27845  validloss 4.47234±0.00000  bestvalidloss 4.35577  last_update 1\n",
      "train: iter 154  trainloss 3.28209  validloss 4.67243±0.00000  bestvalidloss 4.35577  last_update 2\n",
      "train: iter 155  trainloss 3.27198  validloss 4.48590±0.00000  bestvalidloss 4.35577  last_update 3\n",
      "train: iter 156  trainloss 3.32289  validloss 4.47488±0.00000  bestvalidloss 4.35577  last_update 4\n",
      "train: iter 157  trainloss 3.27411  validloss 4.44642±0.00000  bestvalidloss 4.35577  last_update 5\n",
      "train: iter 158  trainloss 3.32970  validloss 4.55092±0.00000  bestvalidloss 4.35577  last_update 6\n",
      "train: iter 159  trainloss 3.26248  validloss 4.47357±0.00000  bestvalidloss 4.35577  last_update 7\n",
      "train: iter 160  trainloss 3.31399  validloss 4.70180±0.00000  bestvalidloss 4.35577  last_update 8\n",
      "train: iter 161  trainloss 3.32599  validloss 4.46392±0.00000  bestvalidloss 4.35577  last_update 9\n",
      "train: iter 162  trainloss 3.35302  validloss 4.60381±0.00000  bestvalidloss 4.35577  last_update 10\n",
      "train: iter 163  trainloss 3.31500  validloss 4.54502±0.00000  bestvalidloss 4.35577  last_update 11\n",
      "train: iter 164  trainloss 3.30529  validloss 4.36543±0.00000  bestvalidloss 4.35577  last_update 12\n",
      "train: iter 165  trainloss 3.31530  validloss 4.52462±0.00000  bestvalidloss 4.35577  last_update 13\n",
      "train: iter 166  trainloss 3.28117  validloss 4.44606±0.00000  bestvalidloss 4.35577  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 3.26072  validloss 4.59159±0.00000  bestvalidloss 4.35577  last_update 15\n",
      "train: iter 168  trainloss 3.27972  validloss 4.49327±0.00000  bestvalidloss 4.35577  last_update 16\n",
      "train: iter 169  trainloss 3.30238  validloss 4.53673±0.00000  bestvalidloss 4.35577  last_update 17\n",
      "train: iter 170  trainloss 3.24361  validloss 4.62573±0.00000  bestvalidloss 4.35577  last_update 18\n",
      "train: iter 171  trainloss 3.28484  validloss 4.56770±0.00000  bestvalidloss 4.35577  last_update 19\n",
      "train: iter 172  trainloss 3.30582  validloss 4.39590±0.00000  bestvalidloss 4.35577  last_update 20\n",
      "train: iter 173  trainloss 3.26224  validloss 4.53599±0.00000  bestvalidloss 4.35577  last_update 21\n",
      "train: iter 174  trainloss 3.33014  validloss 4.51401±0.00000  bestvalidloss 4.35577  last_update 22\n",
      "train: iter 175  trainloss 3.30506  validloss 4.60776±0.00000  bestvalidloss 4.35577  last_update 23\n",
      "train: iter 176  trainloss 3.29952  validloss 4.44877±0.00000  bestvalidloss 4.35577  last_update 24\n",
      "train: iter 177  trainloss 3.31558  validloss 4.49284±0.00000  bestvalidloss 4.35577  last_update 25\n",
      "train: iter 178  trainloss 3.27470  validloss 4.52799±0.00000  bestvalidloss 4.35577  last_update 26\n",
      "train: iter 179  trainloss 3.25769  validloss 4.45053±0.00000  bestvalidloss 4.35577  last_update 27\n",
      "train: iter 180  trainloss 3.31482  validloss 4.62293±0.00000  bestvalidloss 4.35577  last_update 28\n",
      "train: iter 181  trainloss 3.29942  validloss 4.45794±0.00000  bestvalidloss 4.35577  last_update 29\n",
      "train: iter 182  trainloss 3.30821  validloss 4.52339±0.00000  bestvalidloss 4.35577  last_update 30\n",
      "train: iter 183  trainloss 3.27398  validloss 4.59353±0.00000  bestvalidloss 4.35577  last_update 31\n",
      "train: iter 184  trainloss 3.29804  validloss 4.47548±0.00000  bestvalidloss 4.35577  last_update 32\n",
      "train: iter 185  trainloss 3.24825  validloss 4.54419±0.00000  bestvalidloss 4.35577  last_update 33\n",
      "train: iter 186  trainloss 3.28914  validloss 4.44085±0.00000  bestvalidloss 4.35577  last_update 34\n",
      "train: iter 187  trainloss 3.31240  validloss 4.49110±0.00000  bestvalidloss 4.35577  last_update 35\n",
      "train: iter 188  trainloss 3.31458  validloss 4.49256±0.00000  bestvalidloss 4.35577  last_update 36\n",
      "train: iter 189  trainloss 3.27220  validloss 4.56026±0.00000  bestvalidloss 4.35577  last_update 37\n",
      "train: iter 190  trainloss 3.29902  validloss 4.52384±0.00000  bestvalidloss 4.35577  last_update 38\n",
      "train: iter 191  trainloss 3.31156  validloss 4.58571±0.00000  bestvalidloss 4.35577  last_update 39\n",
      "train: iter 192  trainloss 3.28256  validloss 4.43334±0.00000  bestvalidloss 4.35577  last_update 40\n",
      "train: iter 193  trainloss 3.27788  validloss 4.43027±0.00000  bestvalidloss 4.35577  last_update 41\n",
      "train: iter 194  trainloss 3.29531  validloss 4.40520±0.00000  bestvalidloss 4.35577  last_update 42\n",
      "train: iter 195  trainloss 3.26939  validloss 4.42561±0.00000  bestvalidloss 4.35577  last_update 43\n",
      "train: iter 196  trainloss 3.26874  validloss 4.59678±0.00000  bestvalidloss 4.35577  last_update 44\n",
      "train: iter 197  trainloss 3.27820  validloss 4.62718±0.00000  bestvalidloss 4.35577  last_update 45\n",
      "train: iter 198  trainloss 3.27484  validloss 4.49386±0.00000  bestvalidloss 4.35577  last_update 46\n",
      "train: iter 199  trainloss 3.26505  validloss 4.42352±0.00000  bestvalidloss 4.35577  last_update 47\n",
      "train: iter 200  trainloss 3.28432  validloss 4.48957±0.00000  bestvalidloss 4.35577  last_update 48\n",
      "train: iter 201  trainloss 3.27111  validloss 4.37666±0.00000  bestvalidloss 4.35577  last_update 49\n",
      "train: iter 202  trainloss 3.25922  validloss 4.44632±0.00000  bestvalidloss 4.35577  last_update 50\n",
      "train: iter 203  trainloss 3.26229  validloss 4.41364±0.00000  bestvalidloss 4.35577  last_update 51\n",
      "train: iter 204  trainloss 3.28322  validloss 4.40871±0.00000  bestvalidloss 4.35577  last_update 52\n",
      "train: iter 205  trainloss 3.28552  validloss 4.38845±0.00000  bestvalidloss 4.35577  last_update 53\n",
      "train: iter 206  trainloss 3.29003  validloss 4.60123±0.00000  bestvalidloss 4.35577  last_update 54\n",
      "train: iter 207  trainloss 3.26094  validloss 4.41272±0.00000  bestvalidloss 4.35577  last_update 55\n",
      "train: iter 208  trainloss 3.29048  validloss 4.44585±0.00000  bestvalidloss 4.35577  last_update 56\n",
      "train: iter 209  trainloss 3.29463  validloss 4.50808±0.00000  bestvalidloss 4.35577  last_update 57\n",
      "train: iter 210  trainloss 3.28554  validloss 4.35618±0.00000  bestvalidloss 4.35577  last_update 58\n",
      "train: iter 211  trainloss 3.27051  validloss 4.48892±0.00000  bestvalidloss 4.35577  last_update 59\n",
      "train: iter 212  trainloss 3.27307  validloss 4.33671±0.00000  bestvalidloss 4.33671  last_update 0\n",
      "train: iter 213  trainloss 3.24123  validloss 4.48289±0.00000  bestvalidloss 4.33671  last_update 1\n",
      "train: iter 214  trainloss 3.31161  validloss 4.49006±0.00000  bestvalidloss 4.33671  last_update 2\n",
      "train: iter 215  trainloss 3.27912  validloss 4.45803±0.00000  bestvalidloss 4.33671  last_update 3\n",
      "train: iter 216  trainloss 3.23426  validloss 4.41459±0.00000  bestvalidloss 4.33671  last_update 4\n",
      "train: iter 217  trainloss 3.27095  validloss 4.44441±0.00000  bestvalidloss 4.33671  last_update 5\n",
      "train: iter 218  trainloss 3.27034  validloss 4.64619±0.00000  bestvalidloss 4.33671  last_update 6\n",
      "train: iter 219  trainloss 3.23349  validloss 4.34362±0.00000  bestvalidloss 4.33671  last_update 7\n",
      "train: iter 220  trainloss 3.25129  validloss 4.50909±0.00000  bestvalidloss 4.33671  last_update 8\n",
      "train: iter 221  trainloss 3.28560  validloss 4.53344±0.00000  bestvalidloss 4.33671  last_update 9\n",
      "train: iter 222  trainloss 3.26702  validloss 4.51448±0.00000  bestvalidloss 4.33671  last_update 10\n",
      "train: iter 223  trainloss 3.24522  validloss 4.42083±0.00000  bestvalidloss 4.33671  last_update 11\n",
      "train: iter 224  trainloss 3.23780  validloss 4.46026±0.00000  bestvalidloss 4.33671  last_update 12\n",
      "train: iter 225  trainloss 3.25936  validloss 4.48938±0.00000  bestvalidloss 4.33671  last_update 13\n",
      "train: iter 226  trainloss 3.22292  validloss 4.41578±0.00000  bestvalidloss 4.33671  last_update 14\n",
      "train: iter 227  trainloss 3.29186  validloss 4.47352±0.00000  bestvalidloss 4.33671  last_update 15\n",
      "train: iter 228  trainloss 3.26702  validloss 4.49412±0.00000  bestvalidloss 4.33671  last_update 16\n",
      "train: iter 229  trainloss 3.22789  validloss 4.37610±0.00000  bestvalidloss 4.33671  last_update 17\n",
      "train: iter 230  trainloss 3.26538  validloss 4.57446±0.00000  bestvalidloss 4.33671  last_update 18\n",
      "train: iter 231  trainloss 3.23059  validloss 4.51227±0.00000  bestvalidloss 4.33671  last_update 19\n",
      "train: iter 232  trainloss 3.26392  validloss 4.39564±0.00000  bestvalidloss 4.33671  last_update 20\n",
      "train: iter 233  trainloss 3.23833  validloss 4.54190±0.00000  bestvalidloss 4.33671  last_update 21\n",
      "train: iter 234  trainloss 3.25269  validloss 4.38933±0.00000  bestvalidloss 4.33671  last_update 22\n",
      "train: iter 235  trainloss 3.25597  validloss 4.55556±0.00000  bestvalidloss 4.33671  last_update 23\n",
      "train: iter 236  trainloss 3.29382  validloss 4.34777±0.00000  bestvalidloss 4.33671  last_update 24\n",
      "train: iter 237  trainloss 3.27987  validloss 4.40463±0.00000  bestvalidloss 4.33671  last_update 25\n",
      "train: iter 238  trainloss 3.26840  validloss 4.40623±0.00000  bestvalidloss 4.33671  last_update 26\n",
      "train: iter 239  trainloss 3.27222  validloss 4.58487±0.00000  bestvalidloss 4.33671  last_update 27\n",
      "train: iter 240  trainloss 3.26127  validloss 4.34366±0.00000  bestvalidloss 4.33671  last_update 28\n",
      "train: iter 241  trainloss 3.27166  validloss 4.39768±0.00000  bestvalidloss 4.33671  last_update 29\n",
      "train: iter 242  trainloss 3.25064  validloss 4.42519±0.00000  bestvalidloss 4.33671  last_update 30\n",
      "train: iter 243  trainloss 3.25236  validloss 4.35245±0.00000  bestvalidloss 4.33671  last_update 31\n",
      "train: iter 244  trainloss 3.28839  validloss 4.49197±0.00000  bestvalidloss 4.33671  last_update 32\n",
      "train: iter 245  trainloss 3.26425  validloss 4.34216±0.00000  bestvalidloss 4.33671  last_update 33\n",
      "train: iter 246  trainloss 3.24418  validloss 4.37631±0.00000  bestvalidloss 4.33671  last_update 34\n",
      "train: iter 247  trainloss 3.23515  validloss 4.70761±0.00000  bestvalidloss 4.33671  last_update 35\n",
      "train: iter 248  trainloss 3.28334  validloss 4.31541±0.00000  bestvalidloss 4.31541  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 249  trainloss 3.30407  validloss 4.29635±0.00000  bestvalidloss 4.29635  last_update 0\n",
      "train: iter 250  trainloss 3.26071  validloss 4.44758±0.00000  bestvalidloss 4.29635  last_update 1\n",
      "train: iter 251  trainloss 3.25925  validloss 4.32388±0.00000  bestvalidloss 4.29635  last_update 2\n",
      "train: iter 252  trainloss 3.22272  validloss 4.36352±0.00000  bestvalidloss 4.29635  last_update 3\n",
      "train: iter 253  trainloss 3.27377  validloss 4.45681±0.00000  bestvalidloss 4.29635  last_update 4\n",
      "train: iter 254  trainloss 3.22978  validloss 4.60204±0.00000  bestvalidloss 4.29635  last_update 5\n",
      "train: iter 255  trainloss 3.25676  validloss 4.35285±0.00000  bestvalidloss 4.29635  last_update 6\n",
      "train: iter 256  trainloss 3.23365  validloss 4.36103±0.00000  bestvalidloss 4.29635  last_update 7\n",
      "train: iter 257  trainloss 3.23984  validloss 4.55371±0.00000  bestvalidloss 4.29635  last_update 8\n",
      "train: iter 258  trainloss 3.23495  validloss 4.37565±0.00000  bestvalidloss 4.29635  last_update 9\n",
      "train: iter 259  trainloss 3.22875  validloss 4.44154±0.00000  bestvalidloss 4.29635  last_update 10\n",
      "train: iter 260  trainloss 3.25174  validloss 4.37480±0.00000  bestvalidloss 4.29635  last_update 11\n",
      "train: iter 261  trainloss 3.23654  validloss 4.35116±0.00000  bestvalidloss 4.29635  last_update 12\n",
      "train: iter 262  trainloss 3.24396  validloss 4.42486±0.00000  bestvalidloss 4.29635  last_update 13\n",
      "train: iter 263  trainloss 3.24749  validloss 4.45079±0.00000  bestvalidloss 4.29635  last_update 14\n",
      "train: iter 264  trainloss 3.24626  validloss 4.43341±0.00000  bestvalidloss 4.29635  last_update 15\n",
      "train: iter 265  trainloss 3.22634  validloss 4.38414±0.00000  bestvalidloss 4.29635  last_update 16\n",
      "train: iter 266  trainloss 3.23884  validloss 4.58211±0.00000  bestvalidloss 4.29635  last_update 17\n",
      "train: iter 267  trainloss 3.27030  validloss 4.44166±0.00000  bestvalidloss 4.29635  last_update 18\n",
      "train: iter 268  trainloss 3.25613  validloss 4.42835±0.00000  bestvalidloss 4.29635  last_update 19\n",
      "train: iter 269  trainloss 3.22669  validloss 4.42226±0.00000  bestvalidloss 4.29635  last_update 20\n",
      "train: iter 270  trainloss 3.21678  validloss 4.42605±0.00000  bestvalidloss 4.29635  last_update 21\n",
      "train: iter 271  trainloss 3.24392  validloss 4.35003±0.00000  bestvalidloss 4.29635  last_update 22\n",
      "train: iter 272  trainloss 3.24793  validloss 4.41507±0.00000  bestvalidloss 4.29635  last_update 23\n",
      "train: iter 273  trainloss 3.22882  validloss 4.35966±0.00000  bestvalidloss 4.29635  last_update 24\n",
      "train: iter 274  trainloss 3.23681  validloss 4.28097±0.00000  bestvalidloss 4.28097  last_update 0\n",
      "train: iter 275  trainloss 3.22458  validloss 4.39964±0.00000  bestvalidloss 4.28097  last_update 1\n",
      "train: iter 276  trainloss 3.26089  validloss 4.37275±0.00000  bestvalidloss 4.28097  last_update 2\n",
      "train: iter 277  trainloss 3.23267  validloss 4.39549±0.00000  bestvalidloss 4.28097  last_update 3\n",
      "train: iter 278  trainloss 3.22748  validloss 4.56683±0.00000  bestvalidloss 4.28097  last_update 4\n",
      "train: iter 279  trainloss 3.22019  validloss 4.46013±0.00000  bestvalidloss 4.28097  last_update 5\n",
      "train: iter 280  trainloss 3.23696  validloss 4.45278±0.00000  bestvalidloss 4.28097  last_update 6\n",
      "train: iter 281  trainloss 3.22155  validloss 4.47724±0.00000  bestvalidloss 4.28097  last_update 7\n",
      "train: iter 282  trainloss 3.22457  validloss 4.30485±0.00000  bestvalidloss 4.28097  last_update 8\n",
      "train: iter 283  trainloss 3.26752  validloss 4.38098±0.00000  bestvalidloss 4.28097  last_update 9\n",
      "train: iter 284  trainloss 3.24426  validloss 4.43501±0.00000  bestvalidloss 4.28097  last_update 10\n",
      "train: iter 285  trainloss 3.24902  validloss 4.44004±0.00000  bestvalidloss 4.28097  last_update 11\n",
      "train: iter 286  trainloss 3.20646  validloss 4.31657±0.00000  bestvalidloss 4.28097  last_update 12\n",
      "train: iter 287  trainloss 3.22362  validloss 4.44163±0.00000  bestvalidloss 4.28097  last_update 13\n",
      "train: iter 288  trainloss 3.23622  validloss 4.37176±0.00000  bestvalidloss 4.28097  last_update 14\n",
      "train: iter 289  trainloss 3.25285  validloss 4.40297±0.00000  bestvalidloss 4.28097  last_update 15\n",
      "train: iter 290  trainloss 3.21239  validloss 4.47183±0.00000  bestvalidloss 4.28097  last_update 16\n",
      "train: iter 291  trainloss 3.23670  validloss 4.46111±0.00000  bestvalidloss 4.28097  last_update 17\n",
      "train: iter 292  trainloss 3.20500  validloss 4.39256±0.00000  bestvalidloss 4.28097  last_update 18\n",
      "train: iter 293  trainloss 3.22449  validloss 4.46256±0.00000  bestvalidloss 4.28097  last_update 19\n",
      "train: iter 294  trainloss 3.24620  validloss 4.41314±0.00000  bestvalidloss 4.28097  last_update 20\n",
      "train: iter 295  trainloss 3.22455  validloss 4.46575±0.00000  bestvalidloss 4.28097  last_update 21\n",
      "train: iter 296  trainloss 3.22489  validloss 4.35724±0.00000  bestvalidloss 4.28097  last_update 22\n",
      "train: iter 297  trainloss 3.21331  validloss 4.54956±0.00000  bestvalidloss 4.28097  last_update 23\n",
      "train: iter 298  trainloss 3.19909  validloss 4.35262±0.00000  bestvalidloss 4.28097  last_update 24\n",
      "train: iter 299  trainloss 3.22938  validloss 4.36838±0.00000  bestvalidloss 4.28097  last_update 25\n",
      "train: iter 300  trainloss 3.22316  validloss 4.38294±0.00000  bestvalidloss 4.28097  last_update 26\n",
      "train: iter 301  trainloss 3.21992  validloss 4.42644±0.00000  bestvalidloss 4.28097  last_update 27\n",
      "train: iter 302  trainloss 3.20775  validloss 4.52737±0.00000  bestvalidloss 4.28097  last_update 28\n",
      "train: iter 303  trainloss 3.20136  validloss 4.43921±0.00000  bestvalidloss 4.28097  last_update 29\n",
      "train: iter 304  trainloss 3.29257  validloss 4.44939±0.00000  bestvalidloss 4.28097  last_update 30\n",
      "train: iter 305  trainloss 3.25137  validloss 4.45254±0.00000  bestvalidloss 4.28097  last_update 31\n",
      "train: iter 306  trainloss 3.19244  validloss 4.33404±0.00000  bestvalidloss 4.28097  last_update 32\n",
      "train: iter 307  trainloss 3.18596  validloss 4.37585±0.00000  bestvalidloss 4.28097  last_update 33\n",
      "train: iter 308  trainloss 3.20591  validloss 4.41996±0.00000  bestvalidloss 4.28097  last_update 34\n",
      "train: iter 309  trainloss 3.17515  validloss 4.48073±0.00000  bestvalidloss 4.28097  last_update 35\n",
      "train: iter 310  trainloss 3.22207  validloss 4.51912±0.00000  bestvalidloss 4.28097  last_update 36\n",
      "train: iter 311  trainloss 3.21624  validloss 4.44330±0.00000  bestvalidloss 4.28097  last_update 37\n",
      "train: iter 312  trainloss 3.21124  validloss 4.42972±0.00000  bestvalidloss 4.28097  last_update 38\n",
      "train: iter 313  trainloss 3.28895  validloss 4.32140±0.00000  bestvalidloss 4.28097  last_update 39\n",
      "train: iter 314  trainloss 3.21380  validloss 4.34896±0.00000  bestvalidloss 4.28097  last_update 40\n",
      "train: iter 315  trainloss 3.18634  validloss 4.48679±0.00000  bestvalidloss 4.28097  last_update 41\n",
      "train: iter 316  trainloss 3.23289  validloss 4.33940±0.00000  bestvalidloss 4.28097  last_update 42\n",
      "train: iter 317  trainloss 3.24589  validloss 4.36946±0.00000  bestvalidloss 4.28097  last_update 43\n",
      "train: iter 318  trainloss 3.18416  validloss 4.44179±0.00000  bestvalidloss 4.28097  last_update 44\n",
      "train: iter 319  trainloss 3.22550  validloss 4.68566±0.00000  bestvalidloss 4.28097  last_update 45\n",
      "train: iter 320  trainloss 3.23546  validloss 4.39201±0.00000  bestvalidloss 4.28097  last_update 46\n",
      "train: iter 321  trainloss 3.17095  validloss 4.58954±0.00000  bestvalidloss 4.28097  last_update 47\n",
      "train: iter 322  trainloss 3.19889  validloss 4.45040±0.00000  bestvalidloss 4.28097  last_update 48\n",
      "train: iter 323  trainloss 3.20952  validloss 4.39067±0.00000  bestvalidloss 4.28097  last_update 49\n",
      "train: iter 324  trainloss 3.19829  validloss 4.42677±0.00000  bestvalidloss 4.28097  last_update 50\n",
      "train: iter 325  trainloss 3.21052  validloss 4.43544±0.00000  bestvalidloss 4.28097  last_update 51\n",
      "train: iter 326  trainloss 3.21707  validloss 4.39059±0.00000  bestvalidloss 4.28097  last_update 52\n",
      "train: iter 327  trainloss 3.19272  validloss 4.32337±0.00000  bestvalidloss 4.28097  last_update 53\n",
      "train: iter 328  trainloss 3.17566  validloss 4.41846±0.00000  bestvalidloss 4.28097  last_update 54\n",
      "train: iter 329  trainloss 3.19681  validloss 4.48691±0.00000  bestvalidloss 4.28097  last_update 55\n",
      "train: iter 330  trainloss 3.20633  validloss 4.40357±0.00000  bestvalidloss 4.28097  last_update 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 331  trainloss 3.20042  validloss 4.44272±0.00000  bestvalidloss 4.28097  last_update 57\n",
      "train: iter 332  trainloss 3.22107  validloss 4.42326±0.00000  bestvalidloss 4.28097  last_update 58\n",
      "train: iter 333  trainloss 3.24877  validloss 4.39081±0.00000  bestvalidloss 4.28097  last_update 59\n",
      "train: iter 334  trainloss 3.22368  validloss 4.70954±0.00000  bestvalidloss 4.28097  last_update 60\n",
      "train: iter 335  trainloss 3.19386  validloss 4.42297±0.00000  bestvalidloss 4.28097  last_update 61\n",
      "train: iter 336  trainloss 3.22109  validloss 4.37077±0.00000  bestvalidloss 4.28097  last_update 62\n",
      "train: iter 337  trainloss 3.18699  validloss 4.46493±0.00000  bestvalidloss 4.28097  last_update 63\n",
      "train: iter 338  trainloss 3.21748  validloss 4.45621±0.00000  bestvalidloss 4.28097  last_update 64\n",
      "train: iter 339  trainloss 3.17338  validloss 4.39608±0.00000  bestvalidloss 4.28097  last_update 65\n",
      "train: iter 340  trainloss 3.18383  validloss 4.39956±0.00000  bestvalidloss 4.28097  last_update 66\n",
      "train: iter 341  trainloss 3.21286  validloss 4.41629±0.00000  bestvalidloss 4.28097  last_update 67\n",
      "train: iter 342  trainloss 3.22231  validloss 4.43167±0.00000  bestvalidloss 4.28097  last_update 68\n",
      "train: iter 343  trainloss 3.22336  validloss 4.44959±0.00000  bestvalidloss 4.28097  last_update 69\n",
      "train: iter 344  trainloss 3.22424  validloss 4.48762±0.00000  bestvalidloss 4.28097  last_update 70\n",
      "train: iter 345  trainloss 3.18338  validloss 4.73375±0.00000  bestvalidloss 4.28097  last_update 71\n",
      "train: iter 346  trainloss 3.21073  validloss 4.43484±0.00000  bestvalidloss 4.28097  last_update 72\n",
      "train: iter 347  trainloss 3.18926  validloss 4.27248±0.00000  bestvalidloss 4.27248  last_update 0\n",
      "train: iter 348  trainloss 3.21171  validloss 4.43097±0.00000  bestvalidloss 4.27248  last_update 1\n",
      "train: iter 349  trainloss 3.19790  validloss 4.65551±0.00000  bestvalidloss 4.27248  last_update 2\n",
      "train: iter 350  trainloss 3.18943  validloss 4.43596±0.00000  bestvalidloss 4.27248  last_update 3\n",
      "train: iter 351  trainloss 3.19108  validloss 4.33008±0.00000  bestvalidloss 4.27248  last_update 4\n",
      "train: iter 352  trainloss 3.17946  validloss 4.38199±0.00000  bestvalidloss 4.27248  last_update 5\n",
      "train: iter 353  trainloss 3.20827  validloss 4.34242±0.00000  bestvalidloss 4.27248  last_update 6\n",
      "train: iter 354  trainloss 3.19974  validloss 4.38336±0.00000  bestvalidloss 4.27248  last_update 7\n",
      "train: iter 355  trainloss 3.21046  validloss 4.40733±0.00000  bestvalidloss 4.27248  last_update 8\n",
      "train: iter 356  trainloss 3.20962  validloss 4.26362±0.00000  bestvalidloss 4.26362  last_update 0\n",
      "train: iter 357  trainloss 3.18744  validloss 4.54432±0.00000  bestvalidloss 4.26362  last_update 1\n",
      "train: iter 358  trainloss 3.19592  validloss 4.41520±0.00000  bestvalidloss 4.26362  last_update 2\n",
      "train: iter 359  trainloss 3.26359  validloss 4.48904±0.00000  bestvalidloss 4.26362  last_update 3\n",
      "train: iter 360  trainloss 3.20665  validloss 4.35851±0.00000  bestvalidloss 4.26362  last_update 4\n",
      "train: iter 361  trainloss 3.17498  validloss 4.55548±0.00000  bestvalidloss 4.26362  last_update 5\n",
      "train: iter 362  trainloss 3.16527  validloss 4.45262±0.00000  bestvalidloss 4.26362  last_update 6\n",
      "train: iter 363  trainloss 3.22664  validloss 4.37845±0.00000  bestvalidloss 4.26362  last_update 7\n",
      "train: iter 364  trainloss 3.20063  validloss 4.38127±0.00000  bestvalidloss 4.26362  last_update 8\n",
      "train: iter 365  trainloss 3.21062  validloss 4.38482±0.00000  bestvalidloss 4.26362  last_update 9\n",
      "train: iter 366  trainloss 3.16117  validloss 4.41384±0.00000  bestvalidloss 4.26362  last_update 10\n",
      "train: iter 367  trainloss 3.19233  validloss 4.48870±0.00000  bestvalidloss 4.26362  last_update 11\n",
      "train: iter 368  trainloss 3.25240  validloss 4.39312±0.00000  bestvalidloss 4.26362  last_update 12\n",
      "train: iter 369  trainloss 3.20825  validloss 4.68373±0.00000  bestvalidloss 4.26362  last_update 13\n",
      "train: iter 370  trainloss 3.15826  validloss 4.39732±0.00000  bestvalidloss 4.26362  last_update 14\n",
      "train: iter 371  trainloss 3.19670  validloss 4.40701±0.00000  bestvalidloss 4.26362  last_update 15\n",
      "train: iter 372  trainloss 3.20852  validloss 4.43802±0.00000  bestvalidloss 4.26362  last_update 16\n",
      "train: iter 373  trainloss 3.16087  validloss 4.43161±0.00000  bestvalidloss 4.26362  last_update 17\n",
      "train: iter 374  trainloss 3.20856  validloss 4.46077±0.00000  bestvalidloss 4.26362  last_update 18\n",
      "train: iter 375  trainloss 3.18684  validloss 4.53291±0.00000  bestvalidloss 4.26362  last_update 19\n",
      "train: iter 376  trainloss 3.15201  validloss 4.42508±0.00000  bestvalidloss 4.26362  last_update 20\n",
      "train: iter 377  trainloss 3.20270  validloss 4.42410±0.00000  bestvalidloss 4.26362  last_update 21\n",
      "train: iter 378  trainloss 3.22870  validloss 4.29904±0.00000  bestvalidloss 4.26362  last_update 22\n",
      "train: iter 379  trainloss 3.17940  validloss 4.50502±0.00000  bestvalidloss 4.26362  last_update 23\n",
      "train: iter 380  trainloss 3.19263  validloss 4.36846±0.00000  bestvalidloss 4.26362  last_update 24\n",
      "train: iter 381  trainloss 3.22070  validloss 4.49370±0.00000  bestvalidloss 4.26362  last_update 25\n",
      "train: iter 382  trainloss 3.17987  validloss 4.56120±0.00000  bestvalidloss 4.26362  last_update 26\n",
      "train: iter 383  trainloss 3.19775  validloss 4.40686±0.00000  bestvalidloss 4.26362  last_update 27\n",
      "train: iter 384  trainloss 3.21514  validloss 4.45023±0.00000  bestvalidloss 4.26362  last_update 28\n",
      "train: iter 385  trainloss 3.17624  validloss 4.42475±0.00000  bestvalidloss 4.26362  last_update 29\n",
      "train: iter 386  trainloss 3.19092  validloss 4.41894±0.00000  bestvalidloss 4.26362  last_update 30\n",
      "train: iter 387  trainloss 3.17759  validloss 4.59878±0.00000  bestvalidloss 4.26362  last_update 31\n",
      "train: iter 388  trainloss 3.17957  validloss 4.34435±0.00000  bestvalidloss 4.26362  last_update 32\n",
      "train: iter 389  trainloss 3.15597  validloss 4.66249±0.00000  bestvalidloss 4.26362  last_update 33\n",
      "train: iter 390  trainloss 3.17786  validloss 4.43069±0.00000  bestvalidloss 4.26362  last_update 34\n",
      "train: iter 391  trainloss 3.18756  validloss 4.44866±0.00000  bestvalidloss 4.26362  last_update 35\n",
      "train: iter 392  trainloss 3.19505  validloss 4.43661±0.00000  bestvalidloss 4.26362  last_update 36\n",
      "train: iter 393  trainloss 3.15451  validloss 4.39778±0.00000  bestvalidloss 4.26362  last_update 37\n",
      "train: iter 394  trainloss 3.16959  validloss 4.34751±0.00000  bestvalidloss 4.26362  last_update 38\n",
      "train: iter 395  trainloss 3.16914  validloss 4.38536±0.00000  bestvalidloss 4.26362  last_update 39\n",
      "train: iter 396  trainloss 3.19585  validloss 4.49669±0.00000  bestvalidloss 4.26362  last_update 40\n",
      "train: iter 397  trainloss 3.15723  validloss 4.46064±0.00000  bestvalidloss 4.26362  last_update 41\n",
      "train: iter 398  trainloss 3.18452  validloss 4.57610±0.00000  bestvalidloss 4.26362  last_update 42\n",
      "train: iter 399  trainloss 3.15927  validloss 4.43993±0.00000  bestvalidloss 4.26362  last_update 43\n",
      "train: iter 400  trainloss 3.22491  validloss 4.47750±0.00000  bestvalidloss 4.26362  last_update 44\n",
      "train: iter 401  trainloss 3.18813  validloss 4.37279±0.00000  bestvalidloss 4.26362  last_update 45\n",
      "train: iter 402  trainloss 3.19901  validloss 4.58572±0.00000  bestvalidloss 4.26362  last_update 46\n",
      "train: iter 403  trainloss 3.17976  validloss 4.62423±0.00000  bestvalidloss 4.26362  last_update 47\n",
      "train: iter 404  trainloss 3.23715  validloss 4.42704±0.00000  bestvalidloss 4.26362  last_update 48\n",
      "train: iter 405  trainloss 3.16777  validloss 4.53981±0.00000  bestvalidloss 4.26362  last_update 49\n",
      "train: iter 406  trainloss 3.13478  validloss 4.48351±0.00000  bestvalidloss 4.26362  last_update 50\n",
      "train: iter 407  trainloss 3.22054  validloss 4.46304±0.00000  bestvalidloss 4.26362  last_update 51\n",
      "train: iter 408  trainloss 3.15625  validloss 4.44440±0.00000  bestvalidloss 4.26362  last_update 52\n",
      "train: iter 409  trainloss 3.13074  validloss 4.39125±0.00000  bestvalidloss 4.26362  last_update 53\n",
      "train: iter 410  trainloss 3.17824  validloss 4.52539±0.00000  bestvalidloss 4.26362  last_update 54\n",
      "train: iter 411  trainloss 3.21149  validloss 4.46881±0.00000  bestvalidloss 4.26362  last_update 55\n",
      "train: iter 412  trainloss 3.15596  validloss 4.39690±0.00000  bestvalidloss 4.26362  last_update 56\n",
      "train: iter 413  trainloss 3.14411  validloss 4.41285±0.00000  bestvalidloss 4.26362  last_update 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 414  trainloss 3.16632  validloss 4.52687±0.00000  bestvalidloss 4.26362  last_update 58\n",
      "train: iter 415  trainloss 3.16491  validloss 4.46588±0.00000  bestvalidloss 4.26362  last_update 59\n",
      "train: iter 416  trainloss 3.15433  validloss 4.49985±0.00000  bestvalidloss 4.26362  last_update 60\n",
      "train: iter 417  trainloss 3.17912  validloss 4.37168±0.00000  bestvalidloss 4.26362  last_update 61\n",
      "train: iter 418  trainloss 3.16667  validloss 4.53550±0.00000  bestvalidloss 4.26362  last_update 62\n",
      "train: iter 419  trainloss 3.14794  validloss 4.44041±0.00000  bestvalidloss 4.26362  last_update 63\n",
      "train: iter 420  trainloss 3.13293  validloss 4.46201±0.00000  bestvalidloss 4.26362  last_update 64\n",
      "train: iter 421  trainloss 3.16231  validloss 4.45883±0.00000  bestvalidloss 4.26362  last_update 65\n",
      "train: iter 422  trainloss 3.18397  validloss 4.42863±0.00000  bestvalidloss 4.26362  last_update 66\n",
      "train: iter 423  trainloss 3.20186  validloss 4.55754±0.00000  bestvalidloss 4.26362  last_update 67\n",
      "train: iter 424  trainloss 3.17906  validloss 4.41268±0.00000  bestvalidloss 4.26362  last_update 68\n",
      "train: iter 425  trainloss 3.18305  validloss 4.40323±0.00000  bestvalidloss 4.26362  last_update 69\n",
      "train: iter 426  trainloss 3.19384  validloss 4.37724±0.00000  bestvalidloss 4.26362  last_update 70\n",
      "train: iter 427  trainloss 3.14612  validloss 4.53786±0.00000  bestvalidloss 4.26362  last_update 71\n",
      "train: iter 428  trainloss 3.21023  validloss 4.64822±0.00000  bestvalidloss 4.26362  last_update 72\n",
      "train: iter 429  trainloss 3.20519  validloss 4.44040±0.00000  bestvalidloss 4.26362  last_update 73\n",
      "train: iter 430  trainloss 3.16249  validloss 4.62424±0.00000  bestvalidloss 4.26362  last_update 74\n",
      "train: iter 431  trainloss 3.16499  validloss 4.42605±0.00000  bestvalidloss 4.26362  last_update 75\n",
      "train: iter 432  trainloss 3.16562  validloss 4.44932±0.00000  bestvalidloss 4.26362  last_update 76\n",
      "train: iter 433  trainloss 3.18856  validloss 4.48406±0.00000  bestvalidloss 4.26362  last_update 77\n",
      "train: iter 434  trainloss 3.14759  validloss 4.32410±0.00000  bestvalidloss 4.26362  last_update 78\n",
      "train: iter 435  trainloss 3.16205  validloss 4.45940±0.00000  bestvalidloss 4.26362  last_update 79\n",
      "train: iter 436  trainloss 3.15536  validloss 4.58037±0.00000  bestvalidloss 4.26362  last_update 80\n",
      "train: iter 437  trainloss 3.16142  validloss 4.41431±0.00000  bestvalidloss 4.26362  last_update 81\n",
      "train: iter 438  trainloss 3.15033  validloss 4.51255±0.00000  bestvalidloss 4.26362  last_update 82\n",
      "train: iter 439  trainloss 3.15486  validloss 4.54369±0.00000  bestvalidloss 4.26362  last_update 83\n",
      "train: iter 440  trainloss 3.14551  validloss 4.42615±0.00000  bestvalidloss 4.26362  last_update 84\n",
      "train: iter 441  trainloss 3.16814  validloss 4.50025±0.00000  bestvalidloss 4.26362  last_update 85\n",
      "train: iter 442  trainloss 3.19082  validloss 4.44489±0.00000  bestvalidloss 4.26362  last_update 86\n",
      "train: iter 443  trainloss 3.11836  validloss 4.36492±0.00000  bestvalidloss 4.26362  last_update 87\n",
      "train: iter 444  trainloss 3.13617  validloss 4.43962±0.00000  bestvalidloss 4.26362  last_update 88\n",
      "train: iter 445  trainloss 3.12325  validloss 4.40911±0.00000  bestvalidloss 4.26362  last_update 89\n",
      "train: iter 446  trainloss 3.17113  validloss 4.33892±0.00000  bestvalidloss 4.26362  last_update 90\n",
      "train: iter 447  trainloss 3.18196  validloss 4.41842±0.00000  bestvalidloss 4.26362  last_update 91\n",
      "train: iter 448  trainloss 3.18594  validloss 4.45442±0.00000  bestvalidloss 4.26362  last_update 92\n",
      "train: iter 449  trainloss 3.16444  validloss 4.46586±0.00000  bestvalidloss 4.26362  last_update 93\n",
      "train: iter 450  trainloss 3.12701  validloss 4.37037±0.00000  bestvalidloss 4.26362  last_update 94\n",
      "train: iter 451  trainloss 3.16230  validloss 4.39435±0.00000  bestvalidloss 4.26362  last_update 95\n",
      "train: iter 452  trainloss 3.12320  validloss 4.39049±0.00000  bestvalidloss 4.26362  last_update 96\n",
      "train: iter 453  trainloss 3.15813  validloss 4.49770±0.00000  bestvalidloss 4.26362  last_update 97\n",
      "train: iter 454  trainloss 3.18885  validloss 4.42855±0.00000  bestvalidloss 4.26362  last_update 98\n",
      "train: iter 455  trainloss 3.18013  validloss 4.37327±0.00000  bestvalidloss 4.26362  last_update 99\n",
      "train: iter 456  trainloss 3.13415  validloss 4.41570±0.00000  bestvalidloss 4.26362  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-10.1468)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(2.2703)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6464246525362085\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfff682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c9ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e0943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198825bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f45ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33660c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f08a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d77961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129676a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7f114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c970e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
