{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(10196.7881)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 8127.43986  validloss 331300.10906±0.00000  bestvalidloss 331300.10906  last_update 0\n",
      "train: iter 1  trainloss 1370.05141  validloss 10560.84131±0.00000  bestvalidloss 10560.84131  last_update 0\n",
      "train: iter 2  trainloss 1145.95099  validloss 2226.67050±0.00000  bestvalidloss 2226.67050  last_update 0\n",
      "train: iter 3  trainloss 1045.69858  validloss 2376.21435±0.00000  bestvalidloss 2226.67050  last_update 1\n",
      "train: iter 4  trainloss 959.77880  validloss 1596.00425±0.00000  bestvalidloss 1596.00425  last_update 0\n",
      "train: iter 5  trainloss 892.82001  validloss 1557.11229±0.00000  bestvalidloss 1557.11229  last_update 0\n",
      "train: iter 6  trainloss 845.74345  validloss 1508.53335±0.00000  bestvalidloss 1508.53335  last_update 0\n",
      "train: iter 7  trainloss 824.79009  validloss 1969.60122±0.00000  bestvalidloss 1508.53335  last_update 1\n",
      "train: iter 8  trainloss 833.67252  validloss 2288.69890±0.00000  bestvalidloss 1508.53335  last_update 2\n",
      "train: iter 9  trainloss 853.28072  validloss 1554.97031±0.00000  bestvalidloss 1508.53335  last_update 3\n",
      "train: iter 10  trainloss 750.21986  validloss 1322.41800±0.00000  bestvalidloss 1322.41800  last_update 0\n",
      "train: iter 11  trainloss 727.89715  validloss 1715.06521±0.00000  bestvalidloss 1322.41800  last_update 1\n",
      "train: iter 12  trainloss 697.62756  validloss 1126.50878±0.00000  bestvalidloss 1126.50878  last_update 0\n",
      "train: iter 13  trainloss 733.61809  validloss 1028.05169±0.00000  bestvalidloss 1028.05169  last_update 0\n",
      "train: iter 14  trainloss 654.23801  validloss 911.74256±0.00000  bestvalidloss 911.74256  last_update 0\n",
      "train: iter 15  trainloss 566.77571  validloss 736.66008±0.00000  bestvalidloss 736.66008  last_update 0\n",
      "train: iter 16  trainloss 493.70812  validloss 914.90441±0.00000  bestvalidloss 736.66008  last_update 1\n",
      "train: iter 17  trainloss 422.44618  validloss 648.85720±0.00000  bestvalidloss 648.85720  last_update 0\n",
      "train: iter 18  trainloss 385.40248  validloss 597.64726±0.00000  bestvalidloss 597.64726  last_update 0\n",
      "train: iter 19  trainloss 303.87107  validloss 626.83013±0.00000  bestvalidloss 597.64726  last_update 1\n",
      "train: iter 20  trainloss 184.69890  validloss 376.83275±0.00000  bestvalidloss 376.83275  last_update 0\n",
      "train: iter 21  trainloss 199.07195  validloss 481.19994±0.00000  bestvalidloss 376.83275  last_update 1\n",
      "train: iter 22  trainloss 95.02215  validloss 255.95425±0.00000  bestvalidloss 255.95425  last_update 0\n",
      "train: iter 23  trainloss 158.78462  validloss 299.43177±0.00000  bestvalidloss 255.95425  last_update 1\n",
      "train: iter 24  trainloss 81.50925  validloss 269.24065±0.00000  bestvalidloss 255.95425  last_update 2\n",
      "train: iter 25  trainloss 56.93126  validloss 251.52962±0.00000  bestvalidloss 251.52962  last_update 0\n",
      "train: iter 26  trainloss 56.31485  validloss 433.09361±0.00000  bestvalidloss 251.52962  last_update 1\n",
      "train: iter 27  trainloss 19.29510  validloss 151.10406±0.00000  bestvalidloss 151.10406  last_update 0\n",
      "train: iter 28  trainloss -52.92185  validloss 92.24180±0.00000  bestvalidloss 92.24180  last_update 0\n",
      "train: iter 29  trainloss -149.92978  validloss 178.85887±0.00000  bestvalidloss 92.24180  last_update 1\n",
      "train: iter 30  trainloss -227.60299  validloss -33.74348±0.00000  bestvalidloss -33.74348  last_update 0\n",
      "train: iter 31  trainloss -199.51297  validloss -3.67543±0.00000  bestvalidloss -33.74348  last_update 1\n",
      "train: iter 32  trainloss -100.30099  validloss -36.39992±0.00000  bestvalidloss -36.39992  last_update 0\n",
      "train: iter 33  trainloss 21.14497  validloss 140.30507±0.00000  bestvalidloss -36.39992  last_update 1\n",
      "train: iter 34  trainloss -48.72363  validloss 145.77568±0.00000  bestvalidloss -36.39992  last_update 2\n",
      "train: iter 35  trainloss -253.86972  validloss -83.97392±0.00000  bestvalidloss -83.97392  last_update 0\n",
      "train: iter 36  trainloss -299.97476  validloss -133.64362±0.00000  bestvalidloss -133.64362  last_update 0\n",
      "train: iter 37  trainloss -365.63138  validloss -183.83037±0.00000  bestvalidloss -183.83037  last_update 0\n",
      "train: iter 38  trainloss -364.07216  validloss -261.93709±0.00000  bestvalidloss -261.93709  last_update 0\n",
      "train: iter 39  trainloss -366.92677  validloss -41.65125±0.00000  bestvalidloss -261.93709  last_update 1\n",
      "train: iter 40  trainloss -399.25087  validloss -96.20434±0.00000  bestvalidloss -261.93709  last_update 2\n",
      "train: iter 41  trainloss -409.34243  validloss -261.17031±0.00000  bestvalidloss -261.93709  last_update 3\n",
      "train: iter 42  trainloss 104.10546  validloss -164.60622±0.00000  bestvalidloss -261.93709  last_update 4\n",
      "train: iter 43  trainloss -214.72917  validloss 258.84060±0.00000  bestvalidloss -261.93709  last_update 5\n",
      "train: iter 44  trainloss -447.07295  validloss -171.65418±0.00000  bestvalidloss -261.93709  last_update 6\n",
      "train: iter 45  trainloss -374.15493  validloss -380.01948±0.00000  bestvalidloss -380.01948  last_update 0\n",
      "train: iter 46  trainloss -495.24946  validloss -367.26272±0.00000  bestvalidloss -380.01948  last_update 1\n",
      "train: iter 47  trainloss -408.16067  validloss -423.63428±0.00000  bestvalidloss -423.63428  last_update 0\n",
      "train: iter 48  trainloss -420.03623  validloss -345.64541±0.00000  bestvalidloss -423.63428  last_update 1\n",
      "train: iter 49  trainloss -501.39454  validloss -202.80128±0.00000  bestvalidloss -423.63428  last_update 2\n",
      "train: iter 50  trainloss -465.39775  validloss -412.99717±0.00000  bestvalidloss -423.63428  last_update 3\n",
      "train: iter 51  trainloss -437.09626  validloss -362.77978±0.00000  bestvalidloss -423.63428  last_update 4\n",
      "train: iter 52  trainloss -441.60840  validloss -463.86469±0.00000  bestvalidloss -463.86469  last_update 0\n",
      "train: iter 53  trainloss -352.56781  validloss -385.97333±0.00000  bestvalidloss -463.86469  last_update 1\n",
      "train: iter 54  trainloss -440.13246  validloss -318.24172±0.00000  bestvalidloss -463.86469  last_update 2\n",
      "train: iter 55  trainloss -469.59889  validloss -505.81532±0.00000  bestvalidloss -505.81532  last_update 0\n",
      "train: iter 56  trainloss -462.22365  validloss -265.21733±0.00000  bestvalidloss -505.81532  last_update 1\n",
      "train: iter 57  trainloss -550.01749  validloss -373.05282±0.00000  bestvalidloss -505.81532  last_update 2\n",
      "train: iter 58  trainloss -578.07307  validloss -439.98205±0.00000  bestvalidloss -505.81532  last_update 3\n",
      "train: iter 59  trainloss -599.08371  validloss -524.73487±0.00000  bestvalidloss -524.73487  last_update 0\n",
      "train: iter 60  trainloss -652.37549  validloss -545.79173±0.00000  bestvalidloss -545.79173  last_update 0\n",
      "train: iter 61  trainloss -558.10466  validloss -611.48921±0.00000  bestvalidloss -611.48921  last_update 0\n",
      "train: iter 62  trainloss -607.30153  validloss -511.47987±0.00000  bestvalidloss -611.48921  last_update 1\n",
      "train: iter 63  trainloss -601.99481  validloss -610.25095±0.00000  bestvalidloss -611.48921  last_update 2\n",
      "train: iter 64  trainloss -677.27611  validloss -551.93912±0.00000  bestvalidloss -611.48921  last_update 3\n",
      "train: iter 65  trainloss -627.21324  validloss -589.39203±0.00000  bestvalidloss -611.48921  last_update 4\n",
      "train: iter 66  trainloss -722.96202  validloss -572.92222±0.00000  bestvalidloss -611.48921  last_update 5\n",
      "train: iter 67  trainloss -496.78071  validloss -572.86437±0.00000  bestvalidloss -611.48921  last_update 6\n",
      "train: iter 68  trainloss -656.64856  validloss -450.24687±0.00000  bestvalidloss -611.48921  last_update 7\n",
      "train: iter 69  trainloss -682.02940  validloss -609.76717±0.00000  bestvalidloss -611.48921  last_update 8\n",
      "train: iter 70  trainloss -723.59117  validloss -535.64474±0.00000  bestvalidloss -611.48921  last_update 9\n",
      "train: iter 71  trainloss -711.00638  validloss -593.07081±0.00000  bestvalidloss -611.48921  last_update 10\n",
      "train: iter 72  trainloss -714.64101  validloss -639.51442±0.00000  bestvalidloss -639.51442  last_update 0\n",
      "train: iter 73  trainloss -582.09208  validloss -512.51137±0.00000  bestvalidloss -639.51442  last_update 1\n",
      "train: iter 74  trainloss -557.68332  validloss -447.42873±0.00000  bestvalidloss -639.51442  last_update 2\n",
      "train: iter 75  trainloss -626.21585  validloss -305.37559±0.00000  bestvalidloss -639.51442  last_update 3\n",
      "train: iter 76  trainloss -711.83079  validloss -570.74190±0.00000  bestvalidloss -639.51442  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -736.88609  validloss -529.63827±0.00000  bestvalidloss -639.51442  last_update 5\n",
      "train: iter 78  trainloss -763.55423  validloss -722.09453±0.00000  bestvalidloss -722.09453  last_update 0\n",
      "train: iter 79  trainloss -661.09254  validloss -656.01348±0.00000  bestvalidloss -722.09453  last_update 1\n",
      "train: iter 80  trainloss -761.71185  validloss -447.59387±0.00000  bestvalidloss -722.09453  last_update 2\n",
      "train: iter 81  trainloss -686.71525  validloss -745.57929±0.00000  bestvalidloss -745.57929  last_update 0\n",
      "train: iter 82  trainloss -538.77528  validloss -480.89989±0.00000  bestvalidloss -745.57929  last_update 1\n",
      "train: iter 83  trainloss -446.41278  validloss -571.46364±0.00000  bestvalidloss -745.57929  last_update 2\n",
      "train: iter 84  trainloss -501.38770  validloss 37.91164±0.00000  bestvalidloss -745.57929  last_update 3\n",
      "train: iter 85  trainloss -789.64118  validloss -589.99635±0.00000  bestvalidloss -745.57929  last_update 4\n",
      "train: iter 86  trainloss -718.33989  validloss -652.42579±0.00000  bestvalidloss -745.57929  last_update 5\n",
      "train: iter 87  trainloss -798.06619  validloss -540.35997±0.00000  bestvalidloss -745.57929  last_update 6\n",
      "train: iter 88  trainloss -814.19092  validloss -610.63229±0.00000  bestvalidloss -745.57929  last_update 7\n",
      "train: iter 89  trainloss -603.33253  validloss -739.02654±0.00000  bestvalidloss -745.57929  last_update 8\n",
      "train: iter 90  trainloss -636.79861  validloss -526.65775±0.00000  bestvalidloss -745.57929  last_update 9\n",
      "train: iter 91  trainloss -783.06304  validloss -662.76135±0.00000  bestvalidloss -745.57929  last_update 10\n",
      "train: iter 92  trainloss -765.11570  validloss -514.41839±0.00000  bestvalidloss -745.57929  last_update 11\n",
      "train: iter 93  trainloss -759.01363  validloss -691.70794±0.00000  bestvalidloss -745.57929  last_update 12\n",
      "train: iter 94  trainloss -817.82003  validloss -713.50202±0.00000  bestvalidloss -745.57929  last_update 13\n",
      "train: iter 95  trainloss -747.23335  validloss -777.55509±0.00000  bestvalidloss -777.55509  last_update 0\n",
      "train: iter 96  trainloss -851.76669  validloss -747.00318±0.00000  bestvalidloss -777.55509  last_update 1\n",
      "train: iter 97  trainloss -670.77139  validloss -776.29335±0.00000  bestvalidloss -777.55509  last_update 2\n",
      "train: iter 98  trainloss -719.98214  validloss -574.68833±0.00000  bestvalidloss -777.55509  last_update 3\n",
      "train: iter 99  trainloss -600.91113  validloss -504.66392±0.00000  bestvalidloss -777.55509  last_update 4\n",
      "train: iter 100  trainloss -817.95344  validloss -587.50893±0.00000  bestvalidloss -777.55509  last_update 5\n",
      "train: iter 101  trainloss -750.79958  validloss -657.87442±0.00000  bestvalidloss -777.55509  last_update 6\n",
      "train: iter 102  trainloss -852.99900  validloss -685.39534±0.00000  bestvalidloss -777.55509  last_update 7\n",
      "train: iter 103  trainloss -741.16266  validloss -664.20043±0.00000  bestvalidloss -777.55509  last_update 8\n",
      "train: iter 104  trainloss -795.47493  validloss -640.37550±0.00000  bestvalidloss -777.55509  last_update 9\n",
      "train: iter 105  trainloss -650.60605  validloss -769.42629±0.00000  bestvalidloss -777.55509  last_update 10\n",
      "train: iter 106  trainloss -889.17066  validloss -674.59292±0.00000  bestvalidloss -777.55509  last_update 11\n",
      "train: iter 107  trainloss -907.73874  validloss -838.48555±0.00000  bestvalidloss -838.48555  last_update 0\n",
      "train: iter 108  trainloss -834.99808  validloss -803.90424±0.00000  bestvalidloss -838.48555  last_update 1\n",
      "train: iter 109  trainloss -879.60013  validloss -787.06414±0.00000  bestvalidloss -838.48555  last_update 2\n",
      "train: iter 110  trainloss -787.48477  validloss -788.24441±0.00000  bestvalidloss -838.48555  last_update 3\n",
      "train: iter 111  trainloss -885.84541  validloss -824.63214±0.00000  bestvalidloss -838.48555  last_update 4\n",
      "train: iter 112  trainloss -919.65114  validloss -821.62569±0.00000  bestvalidloss -838.48555  last_update 5\n",
      "train: iter 113  trainloss -837.26290  validloss -745.73989±0.00000  bestvalidloss -838.48555  last_update 6\n",
      "train: iter 114  trainloss -883.37974  validloss -849.60850±0.00000  bestvalidloss -849.60850  last_update 0\n",
      "train: iter 115  trainloss -838.36713  validloss -826.39717±0.00000  bestvalidloss -849.60850  last_update 1\n",
      "train: iter 116  trainloss -836.30516  validloss -611.88396±0.00000  bestvalidloss -849.60850  last_update 2\n",
      "train: iter 117  trainloss -810.40210  validloss -797.17182±0.00000  bestvalidloss -849.60850  last_update 3\n",
      "train: iter 118  trainloss -892.05713  validloss -638.48937±0.00000  bestvalidloss -849.60850  last_update 4\n",
      "train: iter 119  trainloss -927.52689  validloss -875.12076±0.00000  bestvalidloss -875.12076  last_update 0\n",
      "train: iter 120  trainloss -812.27845  validloss -458.48559±0.00000  bestvalidloss -875.12076  last_update 1\n",
      "train: iter 121  trainloss -852.94066  validloss -764.75617±0.00000  bestvalidloss -875.12076  last_update 2\n",
      "train: iter 122  trainloss -938.67219  validloss -640.25256±0.00000  bestvalidloss -875.12076  last_update 3\n",
      "train: iter 123  trainloss -839.19306  validloss -636.24940±0.00000  bestvalidloss -875.12076  last_update 4\n",
      "train: iter 124  trainloss -985.08489  validloss -688.63683±0.00000  bestvalidloss -875.12076  last_update 5\n",
      "train: iter 125  trainloss -974.41170  validloss -876.09118±0.00000  bestvalidloss -876.09118  last_update 0\n",
      "train: iter 126  trainloss -990.71458  validloss -714.89811±0.00000  bestvalidloss -876.09118  last_update 1\n",
      "train: iter 127  trainloss -910.17324  validloss -894.60721±0.00000  bestvalidloss -894.60721  last_update 0\n",
      "train: iter 128  trainloss -826.97337  validloss -775.13385±0.00000  bestvalidloss -894.60721  last_update 1\n",
      "train: iter 129  trainloss -908.80795  validloss -778.70644±0.00000  bestvalidloss -894.60721  last_update 2\n",
      "train: iter 130  trainloss -921.29581  validloss -757.15323±0.00000  bestvalidloss -894.60721  last_update 3\n",
      "train: iter 131  trainloss -942.38922  validloss -592.54982±0.00000  bestvalidloss -894.60721  last_update 4\n",
      "train: iter 132  trainloss -827.88347  validloss -719.48874±0.00000  bestvalidloss -894.60721  last_update 5\n",
      "train: iter 133  trainloss -873.85564  validloss -638.99043±0.00000  bestvalidloss -894.60721  last_update 6\n",
      "train: iter 134  trainloss -994.07621  validloss -806.78134±0.00000  bestvalidloss -894.60721  last_update 7\n",
      "train: iter 135  trainloss -896.59571  validloss -886.12289±0.00000  bestvalidloss -894.60721  last_update 8\n",
      "train: iter 136  trainloss -876.75414  validloss -795.79623±0.00000  bestvalidloss -894.60721  last_update 9\n",
      "train: iter 137  trainloss -964.67921  validloss -857.98289±0.00000  bestvalidloss -894.60721  last_update 10\n",
      "train: iter 138  trainloss -740.45488  validloss -948.49175±0.00000  bestvalidloss -948.49175  last_update 0\n",
      "train: iter 139  trainloss -892.70455  validloss -783.32563±0.00000  bestvalidloss -948.49175  last_update 1\n",
      "train: iter 140  trainloss -793.28161  validloss -779.15201±0.00000  bestvalidloss -948.49175  last_update 2\n",
      "train: iter 141  trainloss -993.06245  validloss -875.62268±0.00000  bestvalidloss -948.49175  last_update 3\n",
      "train: iter 142  trainloss -942.79413  validloss -893.66375±0.00000  bestvalidloss -948.49175  last_update 4\n",
      "train: iter 143  trainloss -973.12305  validloss -934.73866±0.00000  bestvalidloss -948.49175  last_update 5\n",
      "train: iter 144  trainloss -1017.49906  validloss -823.69684±0.00000  bestvalidloss -948.49175  last_update 6\n",
      "train: iter 145  trainloss -1065.88430  validloss -908.73398±0.00000  bestvalidloss -948.49175  last_update 7\n",
      "train: iter 146  trainloss -1061.75063  validloss -917.10915±0.00000  bestvalidloss -948.49175  last_update 8\n",
      "train: iter 147  trainloss -1023.43016  validloss -934.10742±0.00000  bestvalidloss -948.49175  last_update 9\n",
      "train: iter 148  trainloss -1062.40248  validloss -906.82843±0.00000  bestvalidloss -948.49175  last_update 10\n",
      "train: iter 149  trainloss -968.27522  validloss -871.40442±0.00000  bestvalidloss -948.49175  last_update 11\n",
      "train: iter 150  trainloss -873.74722  validloss -765.85875±0.00000  bestvalidloss -948.49175  last_update 12\n",
      "train: iter 151  trainloss -1059.30625  validloss -864.24474±0.00000  bestvalidloss -948.49175  last_update 13\n",
      "train: iter 152  trainloss -1020.64284  validloss -931.27909±0.00000  bestvalidloss -948.49175  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -922.12612  validloss -371.59996±0.00000  bestvalidloss -948.49175  last_update 15\n",
      "train: iter 154  trainloss -936.24886  validloss -862.19925±0.00000  bestvalidloss -948.49175  last_update 16\n",
      "train: iter 155  trainloss -796.14108  validloss -820.04410±0.00000  bestvalidloss -948.49175  last_update 17\n",
      "train: iter 156  trainloss -789.50362  validloss -290.43966±0.00000  bestvalidloss -948.49175  last_update 18\n",
      "train: iter 157  trainloss -1019.86686  validloss -870.45268±0.00000  bestvalidloss -948.49175  last_update 19\n",
      "train: iter 158  trainloss -983.07868  validloss -943.36139±0.00000  bestvalidloss -948.49175  last_update 20\n",
      "train: iter 159  trainloss -1033.81366  validloss -848.90444±0.00000  bestvalidloss -948.49175  last_update 21\n",
      "train: iter 160  trainloss -1035.33221  validloss -972.43788±0.00000  bestvalidloss -972.43788  last_update 0\n",
      "train: iter 161  trainloss -1035.15799  validloss -921.62621±0.00000  bestvalidloss -972.43788  last_update 1\n",
      "train: iter 162  trainloss -1072.68384  validloss -945.27122±0.00000  bestvalidloss -972.43788  last_update 2\n",
      "train: iter 163  trainloss -1098.47069  validloss -853.42448±0.00000  bestvalidloss -972.43788  last_update 3\n",
      "train: iter 164  trainloss -1038.71719  validloss -908.12293±0.00000  bestvalidloss -972.43788  last_update 4\n",
      "train: iter 165  trainloss -1004.25478  validloss -802.28763±0.00000  bestvalidloss -972.43788  last_update 5\n",
      "train: iter 166  trainloss -935.84786  validloss -906.11328±0.00000  bestvalidloss -972.43788  last_update 6\n",
      "train: iter 167  trainloss -885.18777  validloss -990.29735±0.00000  bestvalidloss -990.29735  last_update 0\n",
      "train: iter 168  trainloss -940.39566  validloss -390.71220±0.00000  bestvalidloss -990.29735  last_update 1\n",
      "train: iter 169  trainloss -1004.36050  validloss -727.97058±0.00000  bestvalidloss -990.29735  last_update 2\n",
      "train: iter 170  trainloss -1102.15642  validloss -975.34474±0.00000  bestvalidloss -990.29735  last_update 3\n",
      "train: iter 171  trainloss -1058.99118  validloss -748.18946±0.00000  bestvalidloss -990.29735  last_update 4\n",
      "train: iter 172  trainloss -960.23857  validloss -998.68040±0.00000  bestvalidloss -998.68040  last_update 0\n",
      "train: iter 173  trainloss -1086.69292  validloss -961.90176±0.00000  bestvalidloss -998.68040  last_update 1\n",
      "train: iter 174  trainloss -1017.91036  validloss -984.94728±0.00000  bestvalidloss -998.68040  last_update 2\n",
      "train: iter 175  trainloss -1019.78604  validloss -839.16717±0.00000  bestvalidloss -998.68040  last_update 3\n",
      "train: iter 176  trainloss -1103.32440  validloss -1019.36974±0.00000  bestvalidloss -1019.36974  last_update 0\n",
      "train: iter 177  trainloss -969.12829  validloss -757.62868±0.00000  bestvalidloss -1019.36974  last_update 1\n",
      "train: iter 178  trainloss -989.36019  validloss -931.19282±0.00000  bestvalidloss -1019.36974  last_update 2\n",
      "train: iter 179  trainloss -1078.74059  validloss -911.22030±0.00000  bestvalidloss -1019.36974  last_update 3\n",
      "train: iter 180  trainloss -1051.15218  validloss -766.35856±0.00000  bestvalidloss -1019.36974  last_update 4\n",
      "train: iter 181  trainloss -902.34650  validloss -844.97608±0.00000  bestvalidloss -1019.36974  last_update 5\n",
      "train: iter 182  trainloss -1097.81695  validloss -814.73468±0.00000  bestvalidloss -1019.36974  last_update 6\n",
      "train: iter 183  trainloss -971.29825  validloss -999.70129±0.00000  bestvalidloss -1019.36974  last_update 7\n",
      "train: iter 184  trainloss -869.70477  validloss -915.27325±0.00000  bestvalidloss -1019.36974  last_update 8\n",
      "train: iter 185  trainloss -779.78251  validloss -319.64159±0.00000  bestvalidloss -1019.36974  last_update 9\n",
      "train: iter 186  trainloss -1080.51107  validloss -875.73424±0.00000  bestvalidloss -1019.36974  last_update 10\n",
      "train: iter 187  trainloss -1122.47008  validloss -865.65943±0.00000  bestvalidloss -1019.36974  last_update 11\n",
      "train: iter 188  trainloss -1023.79776  validloss -984.91863±0.00000  bestvalidloss -1019.36974  last_update 12\n",
      "train: iter 189  trainloss -1049.78167  validloss -706.05031±0.00000  bestvalidloss -1019.36974  last_update 13\n",
      "train: iter 190  trainloss -1072.85976  validloss -941.47082±0.00000  bestvalidloss -1019.36974  last_update 14\n",
      "train: iter 191  trainloss -1001.68156  validloss -930.83692±0.00000  bestvalidloss -1019.36974  last_update 15\n",
      "train: iter 192  trainloss -1154.86025  validloss -963.34250±0.00000  bestvalidloss -1019.36974  last_update 16\n",
      "train: iter 193  trainloss -1113.99544  validloss -937.28089±0.00000  bestvalidloss -1019.36974  last_update 17\n",
      "train: iter 194  trainloss -1061.58184  validloss -902.56973±0.00000  bestvalidloss -1019.36974  last_update 18\n",
      "train: iter 195  trainloss -1033.80368  validloss -941.81475±0.00000  bestvalidloss -1019.36974  last_update 19\n",
      "train: iter 196  trainloss -1115.55793  validloss -872.99005±0.00000  bestvalidloss -1019.36974  last_update 20\n",
      "train: iter 197  trainloss -1123.52929  validloss -914.30537±0.00000  bestvalidloss -1019.36974  last_update 21\n",
      "train: iter 198  trainloss -1079.41806  validloss -1037.80055±0.00000  bestvalidloss -1037.80055  last_update 0\n",
      "train: iter 199  trainloss -1118.00338  validloss -734.46552±0.00000  bestvalidloss -1037.80055  last_update 1\n",
      "train: iter 200  trainloss -1156.22733  validloss -967.57953±0.00000  bestvalidloss -1037.80055  last_update 2\n",
      "train: iter 201  trainloss -1173.79474  validloss -892.82642±0.00000  bestvalidloss -1037.80055  last_update 3\n",
      "train: iter 202  trainloss -1007.54031  validloss -754.61457±0.00000  bestvalidloss -1037.80055  last_update 4\n",
      "train: iter 203  trainloss -859.56085  validloss -861.02177±0.00000  bestvalidloss -1037.80055  last_update 5\n",
      "train: iter 204  trainloss -1136.67989  validloss -849.77740±0.00000  bestvalidloss -1037.80055  last_update 6\n",
      "train: iter 205  trainloss -1102.11238  validloss -881.34610±0.00000  bestvalidloss -1037.80055  last_update 7\n",
      "train: iter 206  trainloss -1150.29432  validloss -1086.93474±0.00000  bestvalidloss -1086.93474  last_update 0\n",
      "train: iter 207  trainloss -1134.63710  validloss -955.76783±0.00000  bestvalidloss -1086.93474  last_update 1\n",
      "train: iter 208  trainloss -1052.30730  validloss -957.11252±0.00000  bestvalidloss -1086.93474  last_update 2\n",
      "train: iter 209  trainloss -1050.23683  validloss -644.03347±0.00000  bestvalidloss -1086.93474  last_update 3\n",
      "train: iter 210  trainloss -1149.51076  validloss -1014.77308±0.00000  bestvalidloss -1086.93474  last_update 4\n",
      "train: iter 211  trainloss -1138.29455  validloss -988.22068±0.00000  bestvalidloss -1086.93474  last_update 5\n",
      "train: iter 212  trainloss -1079.38809  validloss -793.13202±0.00000  bestvalidloss -1086.93474  last_update 6\n",
      "train: iter 213  trainloss -1199.35167  validloss -913.57719±0.00000  bestvalidloss -1086.93474  last_update 7\n",
      "train: iter 214  trainloss -1157.42569  validloss -736.37610±0.00000  bestvalidloss -1086.93474  last_update 8\n",
      "train: iter 215  trainloss -1006.59261  validloss -843.83687±0.00000  bestvalidloss -1086.93474  last_update 9\n",
      "train: iter 216  trainloss -985.82416  validloss -834.31377±0.00000  bestvalidloss -1086.93474  last_update 10\n",
      "train: iter 217  trainloss -980.62490  validloss -788.05101±0.00000  bestvalidloss -1086.93474  last_update 11\n",
      "train: iter 218  trainloss -1149.36156  validloss -938.92353±0.00000  bestvalidloss -1086.93474  last_update 12\n",
      "train: iter 219  trainloss -1040.77670  validloss -855.62848±0.00000  bestvalidloss -1086.93474  last_update 13\n",
      "train: iter 220  trainloss -1119.82743  validloss -899.51379±0.00000  bestvalidloss -1086.93474  last_update 14\n",
      "train: iter 221  trainloss -1041.97349  validloss -959.24068±0.00000  bestvalidloss -1086.93474  last_update 15\n",
      "train: iter 222  trainloss -1052.56162  validloss -1052.57961±0.00000  bestvalidloss -1086.93474  last_update 16\n",
      "train: iter 223  trainloss -1145.08509  validloss -1061.75741±0.00000  bestvalidloss -1086.93474  last_update 17\n",
      "train: iter 224  trainloss -1149.76148  validloss -795.42997±0.00000  bestvalidloss -1086.93474  last_update 18\n",
      "train: iter 225  trainloss -1189.17714  validloss -1063.05115±0.00000  bestvalidloss -1086.93474  last_update 19\n",
      "train: iter 226  trainloss -1151.85264  validloss -817.31369±0.00000  bestvalidloss -1086.93474  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 227  trainloss -1168.05748  validloss -1012.56834±0.00000  bestvalidloss -1086.93474  last_update 21\n",
      "train: iter 228  trainloss -1170.10890  validloss -1112.67066±0.00000  bestvalidloss -1112.67066  last_update 0\n",
      "train: iter 229  trainloss -1196.48105  validloss -1048.44716±0.00000  bestvalidloss -1112.67066  last_update 1\n",
      "train: iter 230  trainloss -1018.27570  validloss -917.90222±0.00000  bestvalidloss -1112.67066  last_update 2\n",
      "train: iter 231  trainloss -1062.71869  validloss -947.25729±0.00000  bestvalidloss -1112.67066  last_update 3\n",
      "train: iter 232  trainloss -1085.75816  validloss -1021.06132±0.00000  bestvalidloss -1112.67066  last_update 4\n",
      "train: iter 233  trainloss -1121.02056  validloss -1004.36691±0.00000  bestvalidloss -1112.67066  last_update 5\n",
      "train: iter 234  trainloss -1180.35529  validloss -1099.09804±0.00000  bestvalidloss -1112.67066  last_update 6\n",
      "train: iter 235  trainloss -916.94897  validloss -1140.82609±0.00000  bestvalidloss -1140.82609  last_update 0\n",
      "train: iter 236  trainloss -1034.25035  validloss -880.34196±0.00000  bestvalidloss -1140.82609  last_update 1\n",
      "train: iter 237  trainloss -1222.23711  validloss -986.65213±0.00000  bestvalidloss -1140.82609  last_update 2\n",
      "train: iter 238  trainloss -1212.82621  validloss -1123.42847±0.00000  bestvalidloss -1140.82609  last_update 3\n",
      "train: iter 239  trainloss -1214.58667  validloss -1132.06264±0.00000  bestvalidloss -1140.82609  last_update 4\n",
      "train: iter 240  trainloss -1130.37145  validloss -901.94637±0.00000  bestvalidloss -1140.82609  last_update 5\n",
      "train: iter 241  trainloss -1214.29755  validloss -1121.38894±0.00000  bestvalidloss -1140.82609  last_update 6\n",
      "train: iter 242  trainloss -963.27499  validloss -932.30519±0.00000  bestvalidloss -1140.82609  last_update 7\n",
      "train: iter 243  trainloss -1061.63489  validloss -790.25014±0.00000  bestvalidloss -1140.82609  last_update 8\n",
      "train: iter 244  trainloss -1159.17679  validloss -980.14726±0.00000  bestvalidloss -1140.82609  last_update 9\n",
      "train: iter 245  trainloss -1225.54997  validloss -1068.29168±0.00000  bestvalidloss -1140.82609  last_update 10\n",
      "train: iter 246  trainloss -1217.79746  validloss -1129.45620±0.00000  bestvalidloss -1140.82609  last_update 11\n",
      "train: iter 247  trainloss -1143.89023  validloss -923.27991±0.00000  bestvalidloss -1140.82609  last_update 12\n",
      "train: iter 248  trainloss -1115.79544  validloss -979.55533±0.00000  bestvalidloss -1140.82609  last_update 13\n",
      "train: iter 249  trainloss -1198.01008  validloss -1061.14576±0.00000  bestvalidloss -1140.82609  last_update 14\n",
      "train: iter 250  trainloss -1000.05727  validloss -1056.27454±0.00000  bestvalidloss -1140.82609  last_update 15\n",
      "train: iter 251  trainloss -1077.11542  validloss -1081.55753±0.00000  bestvalidloss -1140.82609  last_update 16\n",
      "train: iter 252  trainloss -1191.88143  validloss -1119.04433±0.00000  bestvalidloss -1140.82609  last_update 17\n",
      "train: iter 253  trainloss -1211.72388  validloss -1149.40872±0.00000  bestvalidloss -1149.40872  last_update 0\n",
      "train: iter 254  trainloss -1190.47320  validloss -745.43876±0.00000  bestvalidloss -1149.40872  last_update 1\n",
      "train: iter 255  trainloss -1181.49367  validloss -1143.47652±0.00000  bestvalidloss -1149.40872  last_update 2\n",
      "train: iter 256  trainloss -1171.68968  validloss -973.10463±0.00000  bestvalidloss -1149.40872  last_update 3\n",
      "train: iter 257  trainloss -1194.25903  validloss -885.78512±0.00000  bestvalidloss -1149.40872  last_update 4\n",
      "train: iter 258  trainloss -1120.15731  validloss -1176.42401±0.00000  bestvalidloss -1176.42401  last_update 0\n",
      "train: iter 259  trainloss -947.56213  validloss -799.70513±0.00000  bestvalidloss -1176.42401  last_update 1\n",
      "train: iter 260  trainloss -1152.44585  validloss -1031.77870±0.00000  bestvalidloss -1176.42401  last_update 2\n",
      "train: iter 261  trainloss -1137.49433  validloss -1062.66719±0.00000  bestvalidloss -1176.42401  last_update 3\n",
      "train: iter 262  trainloss -1146.36182  validloss -1071.03288±0.00000  bestvalidloss -1176.42401  last_update 4\n",
      "train: iter 263  trainloss -1248.52942  validloss -1151.80228±0.00000  bestvalidloss -1176.42401  last_update 5\n",
      "train: iter 264  trainloss -1239.24062  validloss -1150.94552±0.00000  bestvalidloss -1176.42401  last_update 6\n",
      "train: iter 265  trainloss -1129.10371  validloss -1204.24149±0.00000  bestvalidloss -1204.24149  last_update 0\n",
      "train: iter 266  trainloss -1226.52139  validloss -1050.98508±0.00000  bestvalidloss -1204.24149  last_update 1\n",
      "train: iter 267  trainloss -1161.72686  validloss -1077.83191±0.00000  bestvalidloss -1204.24149  last_update 2\n",
      "train: iter 268  trainloss -1228.08093  validloss -982.71973±0.00000  bestvalidloss -1204.24149  last_update 3\n",
      "train: iter 269  trainloss -1198.57166  validloss -1206.42142±0.00000  bestvalidloss -1206.42142  last_update 0\n",
      "train: iter 270  trainloss -1064.87941  validloss -526.25131±0.00000  bestvalidloss -1206.42142  last_update 1\n",
      "train: iter 271  trainloss -1204.26576  validloss -1028.62356±0.00000  bestvalidloss -1206.42142  last_update 2\n",
      "train: iter 272  trainloss -1223.84462  validloss -1204.56223±0.00000  bestvalidloss -1206.42142  last_update 3\n",
      "train: iter 273  trainloss -1210.35870  validloss -950.83812±0.00000  bestvalidloss -1206.42142  last_update 4\n",
      "train: iter 274  trainloss -1217.57991  validloss -1135.58738±0.00000  bestvalidloss -1206.42142  last_update 5\n",
      "train: iter 275  trainloss -1255.65391  validloss -1210.75403±0.00000  bestvalidloss -1210.75403  last_update 0\n",
      "train: iter 276  trainloss -1203.85708  validloss -1116.92779±0.00000  bestvalidloss -1210.75403  last_update 1\n",
      "train: iter 277  trainloss -1227.75891  validloss -1125.67925±0.00000  bestvalidloss -1210.75403  last_update 2\n",
      "train: iter 278  trainloss -1161.08436  validloss -981.42168±0.00000  bestvalidloss -1210.75403  last_update 3\n",
      "train: iter 279  trainloss -1225.48882  validloss -930.25348±0.00000  bestvalidloss -1210.75403  last_update 4\n",
      "train: iter 280  trainloss -1282.35470  validloss -1165.81057±0.00000  bestvalidloss -1210.75403  last_update 5\n",
      "train: iter 281  trainloss -1120.66350  validloss -1231.46243±0.00000  bestvalidloss -1231.46243  last_update 0\n",
      "train: iter 282  trainloss -1253.96407  validloss -1073.23342±0.00000  bestvalidloss -1231.46243  last_update 1\n",
      "train: iter 283  trainloss -1164.83992  validloss -1052.12128±0.00000  bestvalidloss -1231.46243  last_update 2\n",
      "train: iter 284  trainloss -1227.02479  validloss -1119.92272±0.00000  bestvalidloss -1231.46243  last_update 3\n",
      "train: iter 285  trainloss -1182.46958  validloss -1148.94189±0.00000  bestvalidloss -1231.46243  last_update 4\n",
      "train: iter 286  trainloss -1271.29583  validloss -1072.99397±0.00000  bestvalidloss -1231.46243  last_update 5\n",
      "train: iter 287  trainloss -1130.86908  validloss -1167.70159±0.00000  bestvalidloss -1231.46243  last_update 6\n",
      "train: iter 288  trainloss -1296.74738  validloss -1165.05164±0.00000  bestvalidloss -1231.46243  last_update 7\n",
      "train: iter 289  trainloss -1261.96400  validloss -1182.11992±0.00000  bestvalidloss -1231.46243  last_update 8\n",
      "train: iter 290  trainloss -1107.84457  validloss -389.77102±0.00000  bestvalidloss -1231.46243  last_update 9\n",
      "train: iter 291  trainloss -1277.77979  validloss -1149.27798±0.00000  bestvalidloss -1231.46243  last_update 10\n",
      "train: iter 292  trainloss -1218.32737  validloss -961.74114±0.00000  bestvalidloss -1231.46243  last_update 11\n",
      "train: iter 293  trainloss -1003.10457  validloss -1222.20650±0.00000  bestvalidloss -1231.46243  last_update 12\n",
      "train: iter 294  trainloss -1190.65433  validloss -1096.16057±0.00000  bestvalidloss -1231.46243  last_update 13\n",
      "train: iter 295  trainloss -1198.21502  validloss -1058.34756±0.00000  bestvalidloss -1231.46243  last_update 14\n",
      "train: iter 296  trainloss -1229.73846  validloss -1079.26648±0.00000  bestvalidloss -1231.46243  last_update 15\n",
      "train: iter 297  trainloss -1273.11238  validloss -771.84307±0.00000  bestvalidloss -1231.46243  last_update 16\n",
      "train: iter 298  trainloss -1133.74889  validloss -1149.16761±0.00000  bestvalidloss -1231.46243  last_update 17\n",
      "train: iter 299  trainloss -1291.33012  validloss -1152.13156±0.00000  bestvalidloss -1231.46243  last_update 18\n",
      "train: iter 300  trainloss -1278.14878  validloss -1199.03882±0.00000  bestvalidloss -1231.46243  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 301  trainloss -1064.10669  validloss -1123.16266±0.00000  bestvalidloss -1231.46243  last_update 20\n",
      "train: iter 302  trainloss -1256.27587  validloss -1004.52530±0.00000  bestvalidloss -1231.46243  last_update 21\n",
      "train: iter 303  trainloss -1285.01005  validloss -1027.69158±0.00000  bestvalidloss -1231.46243  last_update 22\n",
      "train: iter 304  trainloss -1004.19061  validloss -1257.37804±0.00000  bestvalidloss -1257.37804  last_update 0\n",
      "train: iter 305  trainloss -1206.16439  validloss -959.06793±0.00000  bestvalidloss -1257.37804  last_update 1\n",
      "train: iter 306  trainloss -1269.02611  validloss -1182.48320±0.00000  bestvalidloss -1257.37804  last_update 2\n",
      "train: iter 307  trainloss -1238.07916  validloss -1185.48084±0.00000  bestvalidloss -1257.37804  last_update 3\n",
      "train: iter 308  trainloss -1337.04102  validloss -1198.83258±0.00000  bestvalidloss -1257.37804  last_update 4\n",
      "train: iter 309  trainloss -1142.46552  validloss -1284.81594±0.00000  bestvalidloss -1284.81594  last_update 0\n",
      "train: iter 310  trainloss -1288.25183  validloss -1079.46289±0.00000  bestvalidloss -1284.81594  last_update 1\n",
      "train: iter 311  trainloss -1179.58787  validloss -1220.99854±0.00000  bestvalidloss -1284.81594  last_update 2\n",
      "train: iter 312  trainloss -1170.53635  validloss -626.79024±0.00000  bestvalidloss -1284.81594  last_update 3\n",
      "train: iter 313  trainloss -1215.63801  validloss -811.84520±0.00000  bestvalidloss -1284.81594  last_update 4\n",
      "train: iter 314  trainloss -1346.12940  validloss -1230.58019±0.00000  bestvalidloss -1284.81594  last_update 5\n",
      "train: iter 315  trainloss -1191.51948  validloss -1176.99262±0.00000  bestvalidloss -1284.81594  last_update 6\n",
      "train: iter 316  trainloss -1328.33946  validloss -1232.34254±0.00000  bestvalidloss -1284.81594  last_update 7\n",
      "train: iter 317  trainloss -1189.28931  validloss -1234.33665±0.00000  bestvalidloss -1284.81594  last_update 8\n",
      "train: iter 318  trainloss -1284.21541  validloss -1017.40163±0.00000  bestvalidloss -1284.81594  last_update 9\n",
      "train: iter 319  trainloss -1281.27478  validloss -1245.91870±0.00000  bestvalidloss -1284.81594  last_update 10\n",
      "train: iter 320  trainloss -1153.99279  validloss -1120.88785±0.00000  bestvalidloss -1284.81594  last_update 11\n",
      "train: iter 321  trainloss -1329.15777  validloss -1237.06678±0.00000  bestvalidloss -1284.81594  last_update 12\n",
      "train: iter 322  trainloss -1266.25208  validloss -1191.11247±0.00000  bestvalidloss -1284.81594  last_update 13\n",
      "train: iter 323  trainloss -1310.76174  validloss -1183.22698±0.00000  bestvalidloss -1284.81594  last_update 14\n",
      "train: iter 324  trainloss -1315.69842  validloss -1235.73012±0.00000  bestvalidloss -1284.81594  last_update 15\n",
      "train: iter 325  trainloss -1175.95357  validloss -1146.20426±0.00000  bestvalidloss -1284.81594  last_update 16\n",
      "train: iter 326  trainloss -1365.12116  validloss -1245.10362±0.00000  bestvalidloss -1284.81594  last_update 17\n",
      "train: iter 327  trainloss -1241.49478  validloss -1190.75428±0.00000  bestvalidloss -1284.81594  last_update 18\n",
      "train: iter 328  trainloss -1207.68696  validloss -1072.27547±0.00000  bestvalidloss -1284.81594  last_update 19\n",
      "train: iter 329  trainloss -1329.66144  validloss -1188.65127±0.00000  bestvalidloss -1284.81594  last_update 20\n",
      "train: iter 330  trainloss -1363.58432  validloss -1147.92840±0.00000  bestvalidloss -1284.81594  last_update 21\n",
      "train: iter 331  trainloss -1265.25397  validloss -1233.80889±0.00000  bestvalidloss -1284.81594  last_update 22\n",
      "train: iter 332  trainloss -1298.25361  validloss -1153.26552±0.00000  bestvalidloss -1284.81594  last_update 23\n",
      "train: iter 333  trainloss -1315.95209  validloss -1195.15879±0.00000  bestvalidloss -1284.81594  last_update 24\n",
      "train: iter 334  trainloss -1338.43068  validloss -1257.85448±0.00000  bestvalidloss -1284.81594  last_update 25\n",
      "train: iter 335  trainloss -1284.23083  validloss -1253.84182±0.00000  bestvalidloss -1284.81594  last_update 26\n",
      "train: iter 336  trainloss -1088.83042  validloss -1150.05178±0.00000  bestvalidloss -1284.81594  last_update 27\n",
      "train: iter 337  trainloss -1273.44844  validloss -1172.01114±0.00000  bestvalidloss -1284.81594  last_update 28\n",
      "train: iter 338  trainloss -1350.83283  validloss -1220.80657±0.00000  bestvalidloss -1284.81594  last_update 29\n",
      "train: iter 339  trainloss -1362.50474  validloss -1230.27557±0.00000  bestvalidloss -1284.81594  last_update 30\n",
      "train: iter 340  trainloss -1324.80860  validloss -1301.29884±0.00000  bestvalidloss -1301.29884  last_update 0\n",
      "train: iter 341  trainloss -1115.03406  validloss -1232.37145±0.00000  bestvalidloss -1301.29884  last_update 1\n",
      "train: iter 342  trainloss -1119.17083  validloss -316.42159±0.00000  bestvalidloss -1301.29884  last_update 2\n",
      "train: iter 343  trainloss -1333.30995  validloss -1119.68107±0.00000  bestvalidloss -1301.29884  last_update 3\n",
      "train: iter 344  trainloss -1190.19238  validloss -1293.07524±0.00000  bestvalidloss -1301.29884  last_update 4\n",
      "train: iter 345  trainloss -1253.60360  validloss -683.35809±0.00000  bestvalidloss -1301.29884  last_update 5\n",
      "train: iter 346  trainloss -1330.46789  validloss -1095.29570±0.00000  bestvalidloss -1301.29884  last_update 6\n",
      "train: iter 347  trainloss -1383.88449  validloss -1335.15853±0.00000  bestvalidloss -1335.15853  last_update 0\n",
      "train: iter 348  trainloss -1253.05812  validloss -549.85092±0.00000  bestvalidloss -1335.15853  last_update 1\n",
      "train: iter 349  trainloss -1298.17676  validloss -1209.03508±0.00000  bestvalidloss -1335.15853  last_update 2\n",
      "train: iter 350  trainloss -1288.38395  validloss -1173.98608±0.00000  bestvalidloss -1335.15853  last_update 3\n",
      "train: iter 351  trainloss -1277.49690  validloss -895.09388±0.00000  bestvalidloss -1335.15853  last_update 4\n",
      "train: iter 352  trainloss -1351.87831  validloss -1126.53294±0.00000  bestvalidloss -1335.15853  last_update 5\n",
      "train: iter 353  trainloss -1339.74854  validloss -1111.28494±0.00000  bestvalidloss -1335.15853  last_update 6\n",
      "train: iter 354  trainloss -1359.20440  validloss -1194.64243±0.00000  bestvalidloss -1335.15853  last_update 7\n",
      "train: iter 355  trainloss -1296.91201  validloss -1242.22716±0.00000  bestvalidloss -1335.15853  last_update 8\n",
      "train: iter 356  trainloss -1300.39788  validloss -1110.85782±0.00000  bestvalidloss -1335.15853  last_update 9\n",
      "train: iter 357  trainloss -1298.58945  validloss -1014.82182±0.00000  bestvalidloss -1335.15853  last_update 10\n",
      "train: iter 358  trainloss -1248.58223  validloss -1291.48554±0.00000  bestvalidloss -1335.15853  last_update 11\n",
      "train: iter 359  trainloss -1237.51276  validloss -974.10241±0.00000  bestvalidloss -1335.15853  last_update 12\n",
      "train: iter 360  trainloss -1181.67095  validloss -1004.34997±0.00000  bestvalidloss -1335.15853  last_update 13\n",
      "train: iter 361  trainloss -1383.90604  validloss -1261.44460±0.00000  bestvalidloss -1335.15853  last_update 14\n",
      "train: iter 362  trainloss -1409.90919  validloss -1307.03757±0.00000  bestvalidloss -1335.15853  last_update 15\n",
      "train: iter 363  trainloss -1366.94909  validloss -1267.56204±0.00000  bestvalidloss -1335.15853  last_update 16\n",
      "train: iter 364  trainloss -1372.83653  validloss -1302.77864±0.00000  bestvalidloss -1335.15853  last_update 17\n",
      "train: iter 365  trainloss -1039.44578  validloss -1215.68698±0.00000  bestvalidloss -1335.15853  last_update 18\n",
      "train: iter 366  trainloss -1306.81036  validloss -1155.10484±0.00000  bestvalidloss -1335.15853  last_update 19\n",
      "train: iter 367  trainloss -1386.53049  validloss -1270.87230±0.00000  bestvalidloss -1335.15853  last_update 20\n",
      "train: iter 368  trainloss -1362.65821  validloss -1307.47417±0.00000  bestvalidloss -1335.15853  last_update 21\n",
      "train: iter 369  trainloss -1269.15752  validloss -1197.89994±0.00000  bestvalidloss -1335.15853  last_update 22\n",
      "train: iter 370  trainloss -96.56979  validloss -129.62007±0.00000  bestvalidloss -1335.15853  last_update 23\n",
      "train: iter 371  trainloss -834.91143  validloss -663.67724±0.00000  bestvalidloss -1335.15853  last_update 24\n",
      "train: iter 372  trainloss -1170.53910  validloss -976.08340±0.00000  bestvalidloss -1335.15853  last_update 25\n",
      "train: iter 373  trainloss -1220.41562  validloss -1115.92530±0.00000  bestvalidloss -1335.15853  last_update 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 374  trainloss -1310.45466  validloss -1168.99796±0.00000  bestvalidloss -1335.15853  last_update 27\n",
      "train: iter 375  trainloss -1328.18365  validloss -1188.98141±0.00000  bestvalidloss -1335.15853  last_update 28\n",
      "train: iter 376  trainloss -1242.27824  validloss -838.50778±0.00000  bestvalidloss -1335.15853  last_update 29\n",
      "train: iter 377  trainloss -1307.41387  validloss -1239.86012±0.00000  bestvalidloss -1335.15853  last_update 30\n",
      "train: iter 378  trainloss -1334.92233  validloss -1245.22395±0.00000  bestvalidloss -1335.15853  last_update 31\n",
      "train: iter 379  trainloss -1264.35337  validloss -1279.29815±0.00000  bestvalidloss -1335.15853  last_update 32\n",
      "train: iter 380  trainloss -1374.68015  validloss -1268.84681±0.00000  bestvalidloss -1335.15853  last_update 33\n",
      "train: iter 381  trainloss -1383.87511  validloss -1288.81850±0.00000  bestvalidloss -1335.15853  last_update 34\n",
      "train: iter 382  trainloss -1400.35123  validloss -1284.79749±0.00000  bestvalidloss -1335.15853  last_update 35\n",
      "train: iter 383  trainloss -1320.87056  validloss -1262.18327±0.00000  bestvalidloss -1335.15853  last_update 36\n",
      "train: iter 384  trainloss -1220.46358  validloss -806.51003±0.00000  bestvalidloss -1335.15853  last_update 37\n",
      "train: iter 385  trainloss -1357.24680  validloss -972.27054±0.00000  bestvalidloss -1335.15853  last_update 38\n",
      "train: iter 386  trainloss -1412.46501  validloss -1288.57307±0.00000  bestvalidloss -1335.15853  last_update 39\n",
      "train: iter 387  trainloss -1429.35410  validloss -1326.23855±0.00000  bestvalidloss -1335.15853  last_update 40\n",
      "train: iter 388  trainloss -1359.96273  validloss -1161.97963±0.00000  bestvalidloss -1335.15853  last_update 41\n",
      "train: iter 389  trainloss -1328.36765  validloss -1146.93295±0.00000  bestvalidloss -1335.15853  last_update 42\n",
      "train: iter 390  trainloss -1414.67721  validloss -1304.06282±0.00000  bestvalidloss -1335.15853  last_update 43\n",
      "train: iter 391  trainloss -1389.66782  validloss -1305.95540±0.00000  bestvalidloss -1335.15853  last_update 44\n",
      "train: iter 392  trainloss -1277.64241  validloss -1219.07643±0.00000  bestvalidloss -1335.15853  last_update 45\n",
      "train: iter 393  trainloss -1268.38690  validloss -961.26218±0.00000  bestvalidloss -1335.15853  last_update 46\n",
      "train: iter 394  trainloss -1370.94771  validloss -1227.63047±0.00000  bestvalidloss -1335.15853  last_update 47\n",
      "train: iter 395  trainloss -1357.66143  validloss -1271.98061±0.00000  bestvalidloss -1335.15853  last_update 48\n",
      "train: iter 396  trainloss -1266.24093  validloss -1347.56290±0.00000  bestvalidloss -1347.56290  last_update 0\n",
      "train: iter 397  trainloss -1375.94962  validloss -1196.84583±0.00000  bestvalidloss -1347.56290  last_update 1\n",
      "train: iter 398  trainloss -1421.97720  validloss -1264.31570±0.00000  bestvalidloss -1347.56290  last_update 2\n",
      "train: iter 399  trainloss -1362.57085  validloss -1343.61760±0.00000  bestvalidloss -1347.56290  last_update 3\n",
      "train: iter 400  trainloss -1343.92981  validloss -1280.34310±0.00000  bestvalidloss -1347.56290  last_update 4\n",
      "train: iter 401  trainloss -1249.27022  validloss -957.98619±0.00000  bestvalidloss -1347.56290  last_update 5\n",
      "train: iter 402  trainloss -1205.33128  validloss -973.60510±0.00000  bestvalidloss -1347.56290  last_update 6\n",
      "train: iter 403  trainloss -1384.21143  validloss -1134.15670±0.00000  bestvalidloss -1347.56290  last_update 7\n",
      "train: iter 404  trainloss -1231.27968  validloss -1338.38656±0.00000  bestvalidloss -1347.56290  last_update 8\n",
      "train: iter 405  trainloss -1339.10784  validloss -1281.26604±0.00000  bestvalidloss -1347.56290  last_update 9\n",
      "train: iter 406  trainloss -1420.04663  validloss -1324.01961±0.00000  bestvalidloss -1347.56290  last_update 10\n",
      "train: iter 407  trainloss -1433.33960  validloss -1335.01402±0.00000  bestvalidloss -1347.56290  last_update 11\n",
      "train: iter 408  trainloss -1391.53599  validloss -1343.61536±0.00000  bestvalidloss -1347.56290  last_update 12\n",
      "train: iter 409  trainloss -1084.99928  validloss -1234.54940±0.00000  bestvalidloss -1347.56290  last_update 13\n",
      "train: iter 410  trainloss -1225.62202  validloss -936.42694±0.00000  bestvalidloss -1347.56290  last_update 14\n",
      "train: iter 411  trainloss -1128.69637  validloss -1117.85117±0.00000  bestvalidloss -1347.56290  last_update 15\n",
      "train: iter 412  trainloss -1407.03373  validloss -1213.56735±0.00000  bestvalidloss -1347.56290  last_update 16\n",
      "train: iter 413  trainloss -1384.73034  validloss -1325.79839±0.00000  bestvalidloss -1347.56290  last_update 17\n",
      "train: iter 414  trainloss -1403.06659  validloss -1271.34452±0.00000  bestvalidloss -1347.56290  last_update 18\n",
      "train: iter 415  trainloss -1403.57262  validloss -1312.36469±0.00000  bestvalidloss -1347.56290  last_update 19\n",
      "train: iter 416  trainloss -1429.95279  validloss -1351.40756±0.00000  bestvalidloss -1351.40756  last_update 0\n",
      "train: iter 417  trainloss -1365.15730  validloss -1264.19537±0.00000  bestvalidloss -1351.40756  last_update 1\n",
      "train: iter 418  trainloss -1381.49919  validloss -1382.97216±0.00000  bestvalidloss -1382.97216  last_update 0\n",
      "train: iter 419  trainloss -1371.04500  validloss -1285.81622±0.00000  bestvalidloss -1382.97216  last_update 1\n",
      "train: iter 420  trainloss -1390.53570  validloss -1314.31616±0.00000  bestvalidloss -1382.97216  last_update 2\n",
      "train: iter 421  trainloss -1426.93994  validloss -1297.30746±0.00000  bestvalidloss -1382.97216  last_update 3\n",
      "train: iter 422  trainloss -1348.12765  validloss -1363.30383±0.00000  bestvalidloss -1382.97216  last_update 4\n",
      "train: iter 423  trainloss -1409.71756  validloss -1296.28250±0.00000  bestvalidloss -1382.97216  last_update 5\n",
      "train: iter 424  trainloss -1371.68742  validloss -1288.68766±0.00000  bestvalidloss -1382.97216  last_update 6\n",
      "train: iter 425  trainloss -1404.83321  validloss -1136.26673±0.00000  bestvalidloss -1382.97216  last_update 7\n",
      "train: iter 426  trainloss -1392.44103  validloss -1367.05667±0.00000  bestvalidloss -1382.97216  last_update 8\n",
      "train: iter 427  trainloss -1276.38769  validloss -1368.36955±0.00000  bestvalidloss -1382.97216  last_update 9\n",
      "train: iter 428  trainloss -1388.93285  validloss -1238.91798±0.00000  bestvalidloss -1382.97216  last_update 10\n",
      "train: iter 429  trainloss -1455.63466  validloss -1351.00320±0.00000  bestvalidloss -1382.97216  last_update 11\n",
      "train: iter 430  trainloss -1366.38862  validloss -1365.31602±0.00000  bestvalidloss -1382.97216  last_update 12\n",
      "train: iter 431  trainloss -1342.21468  validloss -1346.87200±0.00000  bestvalidloss -1382.97216  last_update 13\n",
      "train: iter 432  trainloss -1220.78262  validloss -1273.21004±0.00000  bestvalidloss -1382.97216  last_update 14\n",
      "train: iter 433  trainloss -1318.63135  validloss -1288.74049±0.00000  bestvalidloss -1382.97216  last_update 15\n",
      "train: iter 434  trainloss -1424.61822  validloss -1356.87042±0.00000  bestvalidloss -1382.97216  last_update 16\n",
      "train: iter 435  trainloss -1361.60576  validloss -1296.08834±0.00000  bestvalidloss -1382.97216  last_update 17\n",
      "train: iter 436  trainloss -1454.59444  validloss -1338.86703±0.00000  bestvalidloss -1382.97216  last_update 18\n",
      "train: iter 437  trainloss -1474.83887  validloss -1372.15949±0.00000  bestvalidloss -1382.97216  last_update 19\n",
      "train: iter 438  trainloss -1253.88696  validloss -1391.64576±0.00000  bestvalidloss -1391.64576  last_update 0\n",
      "train: iter 439  trainloss -1407.27536  validloss -1202.83984±0.00000  bestvalidloss -1391.64576  last_update 1\n",
      "train: iter 440  trainloss -1399.22861  validloss -1289.10113±0.00000  bestvalidloss -1391.64576  last_update 2\n",
      "train: iter 441  trainloss -1347.93914  validloss -975.09778±0.00000  bestvalidloss -1391.64576  last_update 3\n",
      "train: iter 442  trainloss -1460.95567  validloss -1379.12496±0.00000  bestvalidloss -1391.64576  last_update 4\n",
      "train: iter 443  trainloss -1394.33598  validloss -1255.76500±0.00000  bestvalidloss -1391.64576  last_update 5\n",
      "train: iter 444  trainloss -1419.26461  validloss -1315.52798±0.00000  bestvalidloss -1391.64576  last_update 6\n",
      "train: iter 445  trainloss -1443.07878  validloss -1367.36259±0.00000  bestvalidloss -1391.64576  last_update 7\n",
      "train: iter 446  trainloss -1271.27297  validloss -1117.78018±0.00000  bestvalidloss -1391.64576  last_update 8\n",
      "train: iter 447  trainloss -1385.49204  validloss -1274.48588±0.00000  bestvalidloss -1391.64576  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 448  trainloss -1429.36226  validloss -1346.53327±0.00000  bestvalidloss -1391.64576  last_update 10\n",
      "train: iter 449  trainloss -1314.99870  validloss -1387.80646±0.00000  bestvalidloss -1391.64576  last_update 11\n",
      "train: iter 450  trainloss -1382.96784  validloss -1276.34202±0.00000  bestvalidloss -1391.64576  last_update 12\n",
      "train: iter 451  trainloss -1479.71202  validloss -1320.70258±0.00000  bestvalidloss -1391.64576  last_update 13\n",
      "train: iter 452  trainloss -1416.19918  validloss -1420.85123±0.00000  bestvalidloss -1420.85123  last_update 0\n",
      "train: iter 453  trainloss -1015.63801  validloss -1273.40971±0.00000  bestvalidloss -1420.85123  last_update 1\n",
      "train: iter 454  trainloss -1223.73624  validloss -681.99562±0.00000  bestvalidloss -1420.85123  last_update 2\n",
      "train: iter 455  trainloss -1296.02162  validloss -658.23105±0.00000  bestvalidloss -1420.85123  last_update 3\n",
      "train: iter 456  trainloss -1420.62303  validloss -1286.83231±0.00000  bestvalidloss -1420.85123  last_update 4\n",
      "train: iter 457  trainloss -1442.79567  validloss -1352.67366±0.00000  bestvalidloss -1420.85123  last_update 5\n",
      "train: iter 458  trainloss -1322.38551  validloss -1284.96500±0.00000  bestvalidloss -1420.85123  last_update 6\n",
      "train: iter 459  trainloss -1387.32916  validloss -989.20864±0.00000  bestvalidloss -1420.85123  last_update 7\n",
      "train: iter 460  trainloss -1468.13727  validloss -1387.68138±0.00000  bestvalidloss -1420.85123  last_update 8\n",
      "train: iter 461  trainloss -1380.58391  validloss -1407.61026±0.00000  bestvalidloss -1420.85123  last_update 9\n",
      "train: iter 462  trainloss -1378.43574  validloss -1218.89724±0.00000  bestvalidloss -1420.85123  last_update 10\n",
      "train: iter 463  trainloss -1474.33010  validloss -1345.54356±0.00000  bestvalidloss -1420.85123  last_update 11\n",
      "train: iter 464  trainloss -1409.36238  validloss -1356.95731±0.00000  bestvalidloss -1420.85123  last_update 12\n",
      "train: iter 465  trainloss -1435.49632  validloss -1287.73504±0.00000  bestvalidloss -1420.85123  last_update 13\n",
      "train: iter 466  trainloss -1336.54811  validloss -1292.42807±0.00000  bestvalidloss -1420.85123  last_update 14\n",
      "train: iter 467  trainloss -1383.27577  validloss -1257.81773±0.00000  bestvalidloss -1420.85123  last_update 15\n",
      "train: iter 468  trainloss -1343.71153  validloss -1039.90171±0.00000  bestvalidloss -1420.85123  last_update 16\n",
      "train: iter 469  trainloss -1457.60574  validloss -1338.41800±0.00000  bestvalidloss -1420.85123  last_update 17\n",
      "train: iter 470  trainloss -1301.49672  validloss -1395.37820±0.00000  bestvalidloss -1420.85123  last_update 18\n",
      "train: iter 471  trainloss -1237.97828  validloss -1000.51500±0.00000  bestvalidloss -1420.85123  last_update 19\n",
      "train: iter 472  trainloss -1460.78239  validloss -1322.98579±0.00000  bestvalidloss -1420.85123  last_update 20\n",
      "train: iter 473  trainloss -1426.04564  validloss -1395.43846±0.00000  bestvalidloss -1420.85123  last_update 21\n",
      "train: iter 474  trainloss -1493.94745  validloss -1382.64932±0.00000  bestvalidloss -1420.85123  last_update 22\n",
      "train: iter 475  trainloss -1379.22279  validloss -1317.67712±0.00000  bestvalidloss -1420.85123  last_update 23\n",
      "train: iter 476  trainloss -1378.02492  validloss -1135.72814±0.00000  bestvalidloss -1420.85123  last_update 24\n",
      "train: iter 477  trainloss -1439.72070  validloss -1356.10999±0.00000  bestvalidloss -1420.85123  last_update 25\n",
      "train: iter 478  trainloss -1455.53275  validloss -1338.69448±0.00000  bestvalidloss -1420.85123  last_update 26\n",
      "train: iter 479  trainloss -1482.65753  validloss -1367.82446±0.00000  bestvalidloss -1420.85123  last_update 27\n",
      "train: iter 480  trainloss -1359.55970  validloss -1332.07984±0.00000  bestvalidloss -1420.85123  last_update 28\n",
      "train: iter 481  trainloss -1415.46699  validloss -1181.81412±0.00000  bestvalidloss -1420.85123  last_update 29\n",
      "train: iter 482  trainloss -1470.06780  validloss -1368.49473±0.00000  bestvalidloss -1420.85123  last_update 30\n",
      "train: iter 483  trainloss -984.05828  validloss -1365.37607±0.00000  bestvalidloss -1420.85123  last_update 31\n",
      "train: iter 484  trainloss -1254.44833  validloss -770.40384±0.00000  bestvalidloss -1420.85123  last_update 32\n",
      "train: iter 485  trainloss -1390.18912  validloss -1190.74907±0.00000  bestvalidloss -1420.85123  last_update 33\n",
      "train: iter 486  trainloss -1440.14818  validloss -1267.86064±0.00000  bestvalidloss -1420.85123  last_update 34\n",
      "train: iter 487  trainloss -1450.21294  validloss -1368.12686±0.00000  bestvalidloss -1420.85123  last_update 35\n",
      "train: iter 488  trainloss -1457.56885  validloss -1301.57743±0.00000  bestvalidloss -1420.85123  last_update 36\n",
      "train: iter 489  trainloss -1463.50533  validloss -1250.57634±0.00000  bestvalidloss -1420.85123  last_update 37\n",
      "train: iter 490  trainloss -1365.11960  validloss -1195.98962±0.00000  bestvalidloss -1420.85123  last_update 38\n",
      "train: iter 491  trainloss -1362.05147  validloss -1312.72224±0.00000  bestvalidloss -1420.85123  last_update 39\n",
      "train: iter 492  trainloss -1403.08548  validloss -1206.42974±0.00000  bestvalidloss -1420.85123  last_update 40\n",
      "train: iter 493  trainloss -1329.18542  validloss -1285.95702±0.00000  bestvalidloss -1420.85123  last_update 41\n",
      "train: iter 494  trainloss -814.04393  validloss -44.91845±0.00000  bestvalidloss -1420.85123  last_update 42\n",
      "train: iter 495  trainloss -1182.87570  validloss -902.75018±0.00000  bestvalidloss -1420.85123  last_update 43\n",
      "train: iter 496  trainloss -1292.08755  validloss -1030.28363±0.00000  bestvalidloss -1420.85123  last_update 44\n",
      "train: iter 497  trainloss -1382.05580  validloss -1221.97744±0.00000  bestvalidloss -1420.85123  last_update 45\n",
      "train: iter 498  trainloss -1406.17092  validloss -1252.77793±0.00000  bestvalidloss -1420.85123  last_update 46\n",
      "train: iter 499  trainloss -1469.87720  validloss -1323.92449±0.00000  bestvalidloss -1420.85123  last_update 47\n",
      "train: iter 500  trainloss -1466.69428  validloss -1363.64844±0.00000  bestvalidloss -1420.85123  last_update 48\n",
      "train: iter 501  trainloss -1448.29588  validloss -1195.65397±0.00000  bestvalidloss -1420.85123  last_update 49\n",
      "train: iter 502  trainloss -1436.70723  validloss -1333.84915±0.00000  bestvalidloss -1420.85123  last_update 50\n",
      "train: iter 503  trainloss -1427.02430  validloss -1375.93070±0.00000  bestvalidloss -1420.85123  last_update 51\n",
      "train: iter 504  trainloss -1445.17764  validloss -1250.82577±0.00000  bestvalidloss -1420.85123  last_update 52\n",
      "train: iter 505  trainloss -1416.50547  validloss -1339.62140±0.00000  bestvalidloss -1420.85123  last_update 53\n",
      "train: iter 506  trainloss -1351.60260  validloss -1325.81798±0.00000  bestvalidloss -1420.85123  last_update 54\n",
      "train: iter 507  trainloss -1415.19726  validloss -1281.96206±0.00000  bestvalidloss -1420.85123  last_update 55\n",
      "train: iter 508  trainloss -1463.01171  validloss -1368.75041±0.00000  bestvalidloss -1420.85123  last_update 56\n",
      "train: iter 509  trainloss -1445.20471  validloss -1323.93440±0.00000  bestvalidloss -1420.85123  last_update 57\n",
      "train: iter 510  trainloss -1452.96909  validloss -1341.82161±0.00000  bestvalidloss -1420.85123  last_update 58\n",
      "train: iter 511  trainloss -1381.37803  validloss -1394.20644±0.00000  bestvalidloss -1420.85123  last_update 59\n",
      "train: iter 512  trainloss -1425.68516  validloss -1339.12703±0.00000  bestvalidloss -1420.85123  last_update 60\n",
      "train: iter 513  trainloss -1518.04855  validloss -1401.64043±0.00000  bestvalidloss -1420.85123  last_update 61\n",
      "train: iter 514  trainloss -1349.66135  validloss -1392.28432±0.00000  bestvalidloss -1420.85123  last_update 62\n",
      "train: iter 515  trainloss -1440.41196  validloss -1365.68713±0.00000  bestvalidloss -1420.85123  last_update 63\n",
      "train: iter 516  trainloss -1351.21235  validloss -1264.75338±0.00000  bestvalidloss -1420.85123  last_update 64\n",
      "train: iter 517  trainloss -1329.57734  validloss -1102.87188±0.00000  bestvalidloss -1420.85123  last_update 65\n",
      "train: iter 518  trainloss -1512.52906  validloss -1355.29991±0.00000  bestvalidloss -1420.85123  last_update 66\n",
      "train: iter 519  trainloss -1474.28758  validloss -1397.84494±0.00000  bestvalidloss -1420.85123  last_update 67\n",
      "train: iter 520  trainloss -1357.06688  validloss -1248.68840±0.00000  bestvalidloss -1420.85123  last_update 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 521  trainloss -1477.00417  validloss -1371.34752±0.00000  bestvalidloss -1420.85123  last_update 69\n",
      "train: iter 522  trainloss -1463.12017  validloss -1402.07131±0.00000  bestvalidloss -1420.85123  last_update 70\n",
      "train: iter 523  trainloss -1430.94597  validloss -1246.20914±0.00000  bestvalidloss -1420.85123  last_update 71\n",
      "train: iter 524  trainloss -1480.83287  validloss -1426.20462±0.00000  bestvalidloss -1426.20462  last_update 0\n",
      "train: iter 525  trainloss -1406.96016  validloss -1169.66577±0.00000  bestvalidloss -1426.20462  last_update 1\n",
      "train: iter 526  trainloss -1442.05254  validloss -1380.69867±0.00000  bestvalidloss -1426.20462  last_update 2\n",
      "train: iter 527  trainloss -1376.65991  validloss -1072.64895±0.00000  bestvalidloss -1426.20462  last_update 3\n",
      "train: iter 528  trainloss -1401.10120  validloss -652.52409±0.00000  bestvalidloss -1426.20462  last_update 4\n",
      "train: iter 529  trainloss -1464.92362  validloss -1365.14262±0.00000  bestvalidloss -1426.20462  last_update 5\n",
      "train: iter 530  trainloss -1469.27695  validloss -1325.75618±0.00000  bestvalidloss -1426.20462  last_update 6\n",
      "train: iter 531  trainloss -1423.00978  validloss -1332.84356±0.00000  bestvalidloss -1426.20462  last_update 7\n",
      "train: iter 532  trainloss -1456.66128  validloss -1323.24639±0.00000  bestvalidloss -1426.20462  last_update 8\n",
      "train: iter 533  trainloss -1356.36194  validloss -1404.34866±0.00000  bestvalidloss -1426.20462  last_update 9\n",
      "train: iter 534  trainloss -1439.44282  validloss -958.64061±0.00000  bestvalidloss -1426.20462  last_update 10\n",
      "train: iter 535  trainloss -1473.04625  validloss -1397.76632±0.00000  bestvalidloss -1426.20462  last_update 11\n",
      "train: iter 536  trainloss -1444.36479  validloss -1400.51560±0.00000  bestvalidloss -1426.20462  last_update 12\n",
      "train: iter 537  trainloss -1452.00349  validloss -1222.63609±0.00000  bestvalidloss -1426.20462  last_update 13\n",
      "train: iter 538  trainloss -1421.42772  validloss -1422.27086±0.00000  bestvalidloss -1426.20462  last_update 14\n",
      "train: iter 539  trainloss -1419.60665  validloss -1285.27488±0.00000  bestvalidloss -1426.20462  last_update 15\n",
      "train: iter 540  trainloss -1324.98679  validloss -1079.95771±0.00000  bestvalidloss -1426.20462  last_update 16\n",
      "train: iter 541  trainloss -1437.27320  validloss -1339.48422±0.00000  bestvalidloss -1426.20462  last_update 17\n",
      "train: iter 542  trainloss -1495.38109  validloss -1397.18992±0.00000  bestvalidloss -1426.20462  last_update 18\n",
      "train: iter 543  trainloss -1388.84805  validloss -1387.74102±0.00000  bestvalidloss -1426.20462  last_update 19\n",
      "train: iter 544  trainloss -1485.98509  validloss -1400.76429±0.00000  bestvalidloss -1426.20462  last_update 20\n",
      "train: iter 545  trainloss -1489.78710  validloss -1439.12243±0.00000  bestvalidloss -1439.12243  last_update 0\n",
      "train: iter 546  trainloss -1472.45713  validloss -1382.89038±0.00000  bestvalidloss -1439.12243  last_update 1\n",
      "train: iter 547  trainloss -1444.80657  validloss -1030.05638±0.00000  bestvalidloss -1439.12243  last_update 2\n",
      "train: iter 548  trainloss -1475.95883  validloss -1432.99125±0.00000  bestvalidloss -1439.12243  last_update 3\n",
      "train: iter 549  trainloss -1390.27847  validloss -1349.04673±0.00000  bestvalidloss -1439.12243  last_update 4\n",
      "train: iter 550  trainloss -1476.41003  validloss -1379.27531±0.00000  bestvalidloss -1439.12243  last_update 5\n",
      "train: iter 551  trainloss -1278.80130  validloss -1423.28123±0.00000  bestvalidloss -1439.12243  last_update 6\n",
      "train: iter 552  trainloss -1397.95152  validloss -1038.64123±0.00000  bestvalidloss -1439.12243  last_update 7\n",
      "train: iter 553  trainloss -1300.40868  validloss -1268.77329±0.00000  bestvalidloss -1439.12243  last_update 8\n",
      "train: iter 554  trainloss -1454.59973  validloss -1260.63644±0.00000  bestvalidloss -1439.12243  last_update 9\n",
      "train: iter 555  trainloss -1492.77628  validloss -1391.61108±0.00000  bestvalidloss -1439.12243  last_update 10\n",
      "train: iter 556  trainloss -1383.94571  validloss -1432.19894±0.00000  bestvalidloss -1439.12243  last_update 11\n",
      "train: iter 557  trainloss -1227.86909  validloss -1284.26568±0.00000  bestvalidloss -1439.12243  last_update 12\n",
      "train: iter 558  trainloss -1449.84395  validloss -1332.46420±0.00000  bestvalidloss -1439.12243  last_update 13\n",
      "train: iter 559  trainloss -1487.59540  validloss -1350.14192±0.00000  bestvalidloss -1439.12243  last_update 14\n",
      "train: iter 560  trainloss -1494.83457  validloss -1424.69994±0.00000  bestvalidloss -1439.12243  last_update 15\n",
      "train: iter 561  trainloss -1502.25347  validloss -1445.12581±0.00000  bestvalidloss -1445.12581  last_update 0\n",
      "train: iter 562  trainloss -1401.71105  validloss -1428.84809±0.00000  bestvalidloss -1445.12581  last_update 1\n",
      "train: iter 563  trainloss -1427.36033  validloss -1079.51936±0.00000  bestvalidloss -1445.12581  last_update 2\n",
      "train: iter 564  trainloss -1452.86233  validloss -1372.18443±0.00000  bestvalidloss -1445.12581  last_update 3\n",
      "train: iter 565  trainloss -1347.49084  validloss -1167.50274±0.00000  bestvalidloss -1445.12581  last_update 4\n",
      "train: iter 566  trainloss -1408.24929  validloss -1313.61392±0.00000  bestvalidloss -1445.12581  last_update 5\n",
      "train: iter 567  trainloss -1508.89200  validloss -1397.35840±0.00000  bestvalidloss -1445.12581  last_update 6\n",
      "train: iter 568  trainloss -1445.47957  validloss -1431.29221±0.00000  bestvalidloss -1445.12581  last_update 7\n",
      "train: iter 569  trainloss -1448.02982  validloss -1311.50114±0.00000  bestvalidloss -1445.12581  last_update 8\n",
      "train: iter 570  trainloss -1435.06646  validloss -1315.40900±0.00000  bestvalidloss -1445.12581  last_update 9\n",
      "train: iter 571  trainloss -1186.18610  validloss -1417.87113±0.00000  bestvalidloss -1445.12581  last_update 10\n",
      "train: iter 572  trainloss -1025.43597  validloss -490.33131±0.00000  bestvalidloss -1445.12581  last_update 11\n",
      "train: iter 573  trainloss -1367.04200  validloss -1157.10511±0.00000  bestvalidloss -1445.12581  last_update 12\n",
      "train: iter 574  trainloss -1439.83416  validloss -1265.81615±0.00000  bestvalidloss -1445.12581  last_update 13\n",
      "train: iter 575  trainloss -1434.39429  validloss -1349.02509±0.00000  bestvalidloss -1445.12581  last_update 14\n",
      "train: iter 576  trainloss -1459.46302  validloss -1297.59157±0.00000  bestvalidloss -1445.12581  last_update 15\n",
      "train: iter 577  trainloss -1508.71439  validloss -1360.76446±0.00000  bestvalidloss -1445.12581  last_update 16\n",
      "train: iter 578  trainloss -1480.56279  validloss -1420.27268±0.00000  bestvalidloss -1445.12581  last_update 17\n",
      "train: iter 579  trainloss -1496.87566  validloss -1379.96800±0.00000  bestvalidloss -1445.12581  last_update 18\n",
      "train: iter 580  trainloss -1460.50542  validloss -1428.18237±0.00000  bestvalidloss -1445.12581  last_update 19\n",
      "train: iter 581  trainloss -1367.69224  validloss -1364.41795±0.00000  bestvalidloss -1445.12581  last_update 20\n",
      "train: iter 582  trainloss -1488.42693  validloss -1340.89541±0.00000  bestvalidloss -1445.12581  last_update 21\n",
      "train: iter 583  trainloss -1469.34017  validloss -1432.38984±0.00000  bestvalidloss -1445.12581  last_update 22\n",
      "train: iter 584  trainloss -1477.82330  validloss -1375.33730±0.00000  bestvalidloss -1445.12581  last_update 23\n",
      "train: iter 585  trainloss -1231.44358  validloss -1326.98944±0.00000  bestvalidloss -1445.12581  last_update 24\n",
      "train: iter 586  trainloss -1309.35512  validloss -1088.99288±0.00000  bestvalidloss -1445.12581  last_update 25\n",
      "train: iter 587  trainloss -1477.30274  validloss -1250.20849±0.00000  bestvalidloss -1445.12581  last_update 26\n",
      "train: iter 588  trainloss -1399.48063  validloss -1406.51216±0.00000  bestvalidloss -1445.12581  last_update 27\n",
      "train: iter 589  trainloss -1456.13205  validloss -1328.98331±0.00000  bestvalidloss -1445.12581  last_update 28\n",
      "train: iter 590  trainloss -1403.41562  validloss -1343.10714±0.00000  bestvalidloss -1445.12581  last_update 29\n",
      "train: iter 591  trainloss -1480.34950  validloss -1346.81998±0.00000  bestvalidloss -1445.12581  last_update 30\n",
      "train: iter 592  trainloss -1521.15351  validloss -1376.49614±0.00000  bestvalidloss -1445.12581  last_update 31\n",
      "train: iter 593  trainloss -1257.37303  validloss -1299.74478±0.00000  bestvalidloss -1445.12581  last_update 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 594  trainloss -1435.05202  validloss -1248.09251±0.00000  bestvalidloss -1445.12581  last_update 33\n",
      "train: iter 595  trainloss -1494.78811  validloss -1358.38217±0.00000  bestvalidloss -1445.12581  last_update 34\n",
      "train: iter 596  trainloss -1453.70286  validloss -1279.48940±0.00000  bestvalidloss -1445.12581  last_update 35\n",
      "train: iter 597  trainloss -1489.30225  validloss -1236.78884±0.00000  bestvalidloss -1445.12581  last_update 36\n",
      "train: iter 598  trainloss -1391.43199  validloss -1452.86035±0.00000  bestvalidloss -1452.86035  last_update 0\n",
      "train: iter 599  trainloss -1424.64434  validloss -1293.43823±0.00000  bestvalidloss -1452.86035  last_update 1\n",
      "train: iter 600  trainloss -1532.20699  validloss -1417.23624±0.00000  bestvalidloss -1452.86035  last_update 2\n",
      "train: iter 601  trainloss -1505.29144  validloss -1460.17431±0.00000  bestvalidloss -1460.17431  last_update 0\n",
      "train: iter 602  trainloss -1483.57710  validloss -1344.22360±0.00000  bestvalidloss -1460.17431  last_update 1\n",
      "train: iter 603  trainloss -1450.44597  validloss -1400.71224±0.00000  bestvalidloss -1460.17431  last_update 2\n",
      "train: iter 604  trainloss -1407.57430  validloss -1217.45838±0.00000  bestvalidloss -1460.17431  last_update 3\n",
      "train: iter 605  trainloss -1520.50731  validloss -1414.05522±0.00000  bestvalidloss -1460.17431  last_update 4\n",
      "train: iter 606  trainloss -1500.91289  validloss -1454.61126±0.00000  bestvalidloss -1460.17431  last_update 5\n",
      "train: iter 607  trainloss -1483.75259  validloss -1388.85322±0.00000  bestvalidloss -1460.17431  last_update 6\n",
      "train: iter 608  trainloss -1493.04614  validloss -1393.08983±0.00000  bestvalidloss -1460.17431  last_update 7\n",
      "train: iter 609  trainloss -1404.31662  validloss -1246.09303±0.00000  bestvalidloss -1460.17431  last_update 8\n",
      "train: iter 610  trainloss -1429.01378  validloss -1375.15325±0.00000  bestvalidloss -1460.17431  last_update 9\n",
      "train: iter 611  trainloss -1329.42303  validloss -1239.87930±0.00000  bestvalidloss -1460.17431  last_update 10\n",
      "train: iter 612  trainloss -1500.45653  validloss -1318.14686±0.00000  bestvalidloss -1460.17431  last_update 11\n",
      "train: iter 613  trainloss -1531.96803  validloss -1425.05578±0.00000  bestvalidloss -1460.17431  last_update 12\n",
      "train: iter 614  trainloss -1468.11066  validloss -1454.49498±0.00000  bestvalidloss -1460.17431  last_update 13\n",
      "train: iter 615  trainloss -1496.89622  validloss -1347.65670±0.00000  bestvalidloss -1460.17431  last_update 14\n",
      "train: iter 616  trainloss -1453.82852  validloss -1389.08532±0.00000  bestvalidloss -1460.17431  last_update 15\n",
      "train: iter 617  trainloss -1449.58617  validloss -1301.76333±0.00000  bestvalidloss -1460.17431  last_update 16\n",
      "train: iter 618  trainloss -1310.56828  validloss -1440.83824±0.00000  bestvalidloss -1460.17431  last_update 17\n",
      "train: iter 619  trainloss -1407.16026  validloss -1235.85061±0.00000  bestvalidloss -1460.17431  last_update 18\n",
      "train: iter 620  trainloss -1468.67245  validloss -1303.60586±0.00000  bestvalidloss -1460.17431  last_update 19\n",
      "train: iter 621  trainloss -1485.65186  validloss -1429.26664±0.00000  bestvalidloss -1460.17431  last_update 20\n",
      "train: iter 622  trainloss -760.00934  validloss -996.00808±0.00000  bestvalidloss -1460.17431  last_update 21\n",
      "train: iter 623  trainloss -1155.52720  validloss -724.00442±0.00000  bestvalidloss -1460.17431  last_update 22\n",
      "train: iter 624  trainloss -1332.28488  validloss -1202.61570±0.00000  bestvalidloss -1460.17431  last_update 23\n",
      "train: iter 625  trainloss -1382.11771  validloss -1143.22083±0.00000  bestvalidloss -1460.17431  last_update 24\n",
      "train: iter 626  trainloss -1447.98816  validloss -1324.90325±0.00000  bestvalidloss -1460.17431  last_update 25\n",
      "train: iter 627  trainloss -1343.67235  validloss -990.65677±0.00000  bestvalidloss -1460.17431  last_update 26\n",
      "train: iter 628  trainloss -1379.11042  validloss -1224.48493±0.00000  bestvalidloss -1460.17431  last_update 27\n",
      "train: iter 629  trainloss -1432.28684  validloss -1290.74890±0.00000  bestvalidloss -1460.17431  last_update 28\n",
      "train: iter 630  trainloss -1432.46687  validloss -717.15919±0.00000  bestvalidloss -1460.17431  last_update 29\n",
      "train: iter 631  trainloss -1454.50711  validloss -1337.47384±0.00000  bestvalidloss -1460.17431  last_update 30\n",
      "train: iter 632  trainloss -1488.36943  validloss -1378.51853±0.00000  bestvalidloss -1460.17431  last_update 31\n",
      "train: iter 633  trainloss -1470.49586  validloss -1386.52567±0.00000  bestvalidloss -1460.17431  last_update 32\n",
      "train: iter 634  trainloss -1343.54297  validloss -1367.78448±0.00000  bestvalidloss -1460.17431  last_update 33\n",
      "train: iter 635  trainloss -1431.06571  validloss -1247.72591±0.00000  bestvalidloss -1460.17431  last_update 34\n",
      "train: iter 636  trainloss -1488.59114  validloss -1399.21015±0.00000  bestvalidloss -1460.17431  last_update 35\n",
      "train: iter 637  trainloss -1096.75596  validloss -1260.76226±0.00000  bestvalidloss -1460.17431  last_update 36\n",
      "train: iter 638  trainloss -1357.78302  validloss -1272.12517±0.00000  bestvalidloss -1460.17431  last_update 37\n",
      "train: iter 639  trainloss -1502.00683  validloss -1358.21444±0.00000  bestvalidloss -1460.17431  last_update 38\n",
      "train: iter 640  trainloss -1494.15443  validloss -1387.47530±0.00000  bestvalidloss -1460.17431  last_update 39\n",
      "train: iter 641  trainloss -1442.72668  validloss -1348.53530±0.00000  bestvalidloss -1460.17431  last_update 40\n",
      "train: iter 642  trainloss -1508.98962  validloss -1445.75551±0.00000  bestvalidloss -1460.17431  last_update 41\n",
      "train: iter 643  trainloss -1442.65247  validloss -1252.97295±0.00000  bestvalidloss -1460.17431  last_update 42\n",
      "train: iter 644  trainloss -1531.62501  validloss -1430.56486±0.00000  bestvalidloss -1460.17431  last_update 43\n",
      "train: iter 645  trainloss -1506.24713  validloss -1469.15301±0.00000  bestvalidloss -1469.15301  last_update 0\n",
      "train: iter 646  trainloss -1451.78364  validloss -1355.32694±0.00000  bestvalidloss -1469.15301  last_update 1\n",
      "train: iter 647  trainloss -1483.73214  validloss -1265.24244±0.00000  bestvalidloss -1469.15301  last_update 2\n",
      "train: iter 648  trainloss -1539.27970  validloss -1444.55594±0.00000  bestvalidloss -1469.15301  last_update 3\n",
      "train: iter 649  trainloss -1532.65024  validloss -1446.80086±0.00000  bestvalidloss -1469.15301  last_update 4\n",
      "train: iter 650  trainloss -1331.66133  validloss -1428.45760±0.00000  bestvalidloss -1469.15301  last_update 5\n",
      "train: iter 651  trainloss -1408.40127  validloss -1121.06614±0.00000  bestvalidloss -1469.15301  last_update 6\n",
      "train: iter 652  trainloss -1470.84041  validloss -1365.42771±0.00000  bestvalidloss -1469.15301  last_update 7\n",
      "train: iter 653  trainloss -1540.32890  validloss -1426.81376±0.00000  bestvalidloss -1469.15301  last_update 8\n",
      "train: iter 654  trainloss -1514.02244  validloss -1463.30999±0.00000  bestvalidloss -1469.15301  last_update 9\n",
      "train: iter 655  trainloss -1449.23957  validloss -1331.64303±0.00000  bestvalidloss -1469.15301  last_update 10\n",
      "train: iter 656  trainloss -1466.75474  validloss -1149.00989±0.00000  bestvalidloss -1469.15301  last_update 11\n",
      "train: iter 657  trainloss -1525.54314  validloss -1382.29331±0.00000  bestvalidloss -1469.15301  last_update 12\n",
      "train: iter 658  trainloss -1529.94531  validloss -1424.54779±0.00000  bestvalidloss -1469.15301  last_update 13\n",
      "train: iter 659  trainloss -1448.91032  validloss -1440.62753±0.00000  bestvalidloss -1469.15301  last_update 14\n",
      "train: iter 660  trainloss -1382.14178  validloss -1252.93465±0.00000  bestvalidloss -1469.15301  last_update 15\n",
      "train: iter 661  trainloss -1467.33562  validloss -1336.76504±0.00000  bestvalidloss -1469.15301  last_update 16\n",
      "train: iter 662  trainloss -1416.70882  validloss -1075.45327±0.00000  bestvalidloss -1469.15301  last_update 17\n",
      "train: iter 663  trainloss -1340.09289  validloss -1431.17982±0.00000  bestvalidloss -1469.15301  last_update 18\n",
      "train: iter 664  trainloss -1481.30584  validloss -1305.60477±0.00000  bestvalidloss -1469.15301  last_update 19\n",
      "train: iter 665  trainloss -1532.35076  validloss -1399.36811±0.00000  bestvalidloss -1469.15301  last_update 20\n",
      "train: iter 666  trainloss -1513.68416  validloss -1380.18513±0.00000  bestvalidloss -1469.15301  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 667  trainloss -1441.19561  validloss -1265.67201±0.00000  bestvalidloss -1469.15301  last_update 22\n",
      "train: iter 668  trainloss -1486.59156  validloss -1407.09101±0.00000  bestvalidloss -1469.15301  last_update 23\n",
      "train: iter 669  trainloss -1535.75773  validloss -1362.62189±0.00000  bestvalidloss -1469.15301  last_update 24\n",
      "train: iter 670  trainloss -1514.22196  validloss -1475.79296±0.00000  bestvalidloss -1475.79296  last_update 0\n",
      "train: iter 671  trainloss -1321.19401  validloss -1075.10116±0.00000  bestvalidloss -1475.79296  last_update 1\n",
      "train: iter 672  trainloss -1473.70589  validloss -1346.00424±0.00000  bestvalidloss -1475.79296  last_update 2\n",
      "train: iter 673  trainloss -1429.28009  validloss -1344.41488±0.00000  bestvalidloss -1475.79296  last_update 3\n",
      "train: iter 674  trainloss -1514.36024  validloss -1324.30040±0.00000  bestvalidloss -1475.79296  last_update 4\n",
      "train: iter 675  trainloss -1487.37311  validloss -1413.73065±0.00000  bestvalidloss -1475.79296  last_update 5\n",
      "train: iter 676  trainloss -1026.90081  validloss -977.77098±0.00000  bestvalidloss -1475.79296  last_update 6\n",
      "train: iter 677  trainloss -1419.86945  validloss -1221.74755±0.00000  bestvalidloss -1475.79296  last_update 7\n",
      "train: iter 678  trainloss -1403.28574  validloss -1038.01290±0.00000  bestvalidloss -1475.79296  last_update 8\n",
      "train: iter 679  trainloss -1466.16077  validloss -1336.77708±0.00000  bestvalidloss -1475.79296  last_update 9\n",
      "train: iter 680  trainloss -1400.27316  validloss -1431.22131±0.00000  bestvalidloss -1475.79296  last_update 10\n",
      "train: iter 681  trainloss -1492.46489  validloss -1382.97179±0.00000  bestvalidloss -1475.79296  last_update 11\n",
      "train: iter 682  trainloss -1390.13535  validloss -1321.23568±0.00000  bestvalidloss -1475.79296  last_update 12\n",
      "train: iter 683  trainloss -1383.24941  validloss -1090.85871±0.00000  bestvalidloss -1475.79296  last_update 13\n",
      "train: iter 684  trainloss -1497.01913  validloss -1334.28472±0.00000  bestvalidloss -1475.79296  last_update 14\n",
      "train: iter 685  trainloss -1519.72300  validloss -1401.99592±0.00000  bestvalidloss -1475.79296  last_update 15\n",
      "train: iter 686  trainloss -1546.39072  validloss -1394.84827±0.00000  bestvalidloss -1475.79296  last_update 16\n",
      "train: iter 687  trainloss -1540.43270  validloss -1440.95853±0.00000  bestvalidloss -1475.79296  last_update 17\n",
      "train: iter 688  trainloss -1516.49675  validloss -1453.51456±0.00000  bestvalidloss -1475.79296  last_update 18\n",
      "train: iter 689  trainloss -1443.14101  validloss -1469.60288±0.00000  bestvalidloss -1475.79296  last_update 19\n",
      "train: iter 690  trainloss -1481.75225  validloss -1390.38821±0.00000  bestvalidloss -1475.79296  last_update 20\n",
      "train: iter 691  trainloss -1328.74263  validloss -1134.28732±0.00000  bestvalidloss -1475.79296  last_update 21\n",
      "train: iter 692  trainloss -1517.64841  validloss -1326.90619±0.00000  bestvalidloss -1475.79296  last_update 22\n",
      "train: iter 693  trainloss -1524.08376  validloss -1411.65231±0.00000  bestvalidloss -1475.79296  last_update 23\n",
      "train: iter 694  trainloss -1235.72567  validloss -1319.56182±0.00000  bestvalidloss -1475.79296  last_update 24\n",
      "train: iter 695  trainloss -1497.45407  validloss -1325.42794±0.00000  bestvalidloss -1475.79296  last_update 25\n",
      "train: iter 696  trainloss -1534.38885  validloss -1427.93269±0.00000  bestvalidloss -1475.79296  last_update 26\n",
      "train: iter 697  trainloss -1502.94104  validloss -1442.02066±0.00000  bestvalidloss -1475.79296  last_update 27\n",
      "train: iter 698  trainloss -1523.76273  validloss -1352.33645±0.00000  bestvalidloss -1475.79296  last_update 28\n",
      "train: iter 699  trainloss -1518.80915  validloss -1396.55344±0.00000  bestvalidloss -1475.79296  last_update 29\n",
      "train: iter 700  trainloss -1321.08626  validloss -1370.50579±0.00000  bestvalidloss -1475.79296  last_update 30\n",
      "train: iter 701  trainloss -1438.13875  validloss -1146.53203±0.00000  bestvalidloss -1475.79296  last_update 31\n",
      "train: iter 702  trainloss -1536.69614  validloss -1416.56106±0.00000  bestvalidloss -1475.79296  last_update 32\n",
      "train: iter 703  trainloss -1515.76697  validloss -1454.57322±0.00000  bestvalidloss -1475.79296  last_update 33\n",
      "train: iter 704  trainloss -1532.04711  validloss -1392.40755±0.00000  bestvalidloss -1475.79296  last_update 34\n",
      "train: iter 705  trainloss -1304.38160  validloss -1449.27141±0.00000  bestvalidloss -1475.79296  last_update 35\n",
      "train: iter 706  trainloss -1467.97172  validloss -1272.64479±0.00000  bestvalidloss -1475.79296  last_update 36\n",
      "train: iter 707  trainloss -1515.26227  validloss -1387.63746±0.00000  bestvalidloss -1475.79296  last_update 37\n",
      "train: iter 708  trainloss -1512.47478  validloss -1432.19239±0.00000  bestvalidloss -1475.79296  last_update 38\n",
      "train: iter 709  trainloss -1502.17642  validloss -1381.29808±0.00000  bestvalidloss -1475.79296  last_update 39\n",
      "train: iter 710  trainloss -1554.33626  validloss -1435.80115±0.00000  bestvalidloss -1475.79296  last_update 40\n",
      "train: iter 711  trainloss -1430.72876  validloss -1477.44295±0.00000  bestvalidloss -1477.44295  last_update 0\n",
      "train: iter 712  trainloss -1238.97242  validloss -61.20536±0.00000  bestvalidloss -1477.44295  last_update 1\n",
      "train: iter 713  trainloss -1500.97040  validloss -1363.40411±0.00000  bestvalidloss -1477.44295  last_update 2\n",
      "train: iter 714  trainloss -1521.64533  validloss -1401.75241±0.00000  bestvalidloss -1477.44295  last_update 3\n",
      "train: iter 715  trainloss -1496.13325  validloss -1419.19365±0.00000  bestvalidloss -1477.44295  last_update 4\n",
      "train: iter 716  trainloss -1473.59529  validloss -1255.10458±0.00000  bestvalidloss -1477.44295  last_update 5\n",
      "train: iter 717  trainloss -1527.60571  validloss -1441.15560±0.00000  bestvalidloss -1477.44295  last_update 6\n",
      "train: iter 718  trainloss -1400.45248  validloss -1458.53096±0.00000  bestvalidloss -1477.44295  last_update 7\n",
      "train: iter 719  trainloss -1487.82188  validloss -1369.76483±0.00000  bestvalidloss -1477.44295  last_update 8\n",
      "train: iter 720  trainloss -1523.16023  validloss -1439.15825±0.00000  bestvalidloss -1477.44295  last_update 9\n",
      "train: iter 721  trainloss -1480.08018  validloss -1285.78382±0.00000  bestvalidloss -1477.44295  last_update 10\n",
      "train: iter 722  trainloss -1503.74699  validloss -1380.71109±0.00000  bestvalidloss -1477.44295  last_update 11\n",
      "train: iter 723  trainloss -1378.98019  validloss -1457.48481±0.00000  bestvalidloss -1477.44295  last_update 12\n",
      "train: iter 724  trainloss -1326.84825  validloss -651.47157±0.00000  bestvalidloss -1477.44295  last_update 13\n",
      "train: iter 725  trainloss -1463.01428  validloss -1362.54919±0.00000  bestvalidloss -1477.44295  last_update 14\n",
      "train: iter 726  trainloss -1509.09747  validloss -1348.87266±0.00000  bestvalidloss -1477.44295  last_update 15\n",
      "train: iter 727  trainloss -1507.40473  validloss -1404.82632±0.00000  bestvalidloss -1477.44295  last_update 16\n",
      "train: iter 728  trainloss -1531.90131  validloss -1367.10321±0.00000  bestvalidloss -1477.44295  last_update 17\n",
      "train: iter 729  trainloss -1525.76173  validloss -1443.14008±0.00000  bestvalidloss -1477.44295  last_update 18\n",
      "train: iter 730  trainloss -1119.18859  validloss -1433.77719±0.00000  bestvalidloss -1477.44295  last_update 19\n",
      "train: iter 731  trainloss -1295.20075  validloss -859.40812±0.00000  bestvalidloss -1477.44295  last_update 20\n",
      "train: iter 732  trainloss -1480.40897  validloss -1323.25973±0.00000  bestvalidloss -1477.44295  last_update 21\n",
      "train: iter 733  trainloss -1518.03339  validloss -1352.93536±0.00000  bestvalidloss -1477.44295  last_update 22\n",
      "train: iter 734  trainloss -1475.06144  validloss -1361.74353±0.00000  bestvalidloss -1477.44295  last_update 23\n",
      "train: iter 735  trainloss -1513.10788  validloss -1347.20721±0.00000  bestvalidloss -1477.44295  last_update 24\n",
      "train: iter 736  trainloss -1471.82039  validloss -1441.47355±0.00000  bestvalidloss -1477.44295  last_update 25\n",
      "train: iter 737  trainloss -1460.62735  validloss -1289.13824±0.00000  bestvalidloss -1477.44295  last_update 26\n",
      "train: iter 738  trainloss -1533.50702  validloss -1393.27511±0.00000  bestvalidloss -1477.44295  last_update 27\n",
      "train: iter 739  trainloss -1498.24869  validloss -1430.15000±0.00000  bestvalidloss -1477.44295  last_update 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 740  trainloss -1488.16393  validloss -1304.93577±0.00000  bestvalidloss -1477.44295  last_update 29\n",
      "train: iter 741  trainloss -1547.62611  validloss -1412.24011±0.00000  bestvalidloss -1477.44295  last_update 30\n",
      "train: iter 742  trainloss -1514.87143  validloss -1472.52605±0.00000  bestvalidloss -1477.44295  last_update 31\n",
      "train: iter 743  trainloss -1437.37364  validloss -1066.84410±0.00000  bestvalidloss -1477.44295  last_update 32\n",
      "train: iter 744  trainloss -1535.71172  validloss -1404.73266±0.00000  bestvalidloss -1477.44295  last_update 33\n",
      "train: iter 745  trainloss -1470.22580  validloss -1377.73666±0.00000  bestvalidloss -1477.44295  last_update 34\n",
      "train: iter 746  trainloss -1529.67126  validloss -1324.41585±0.00000  bestvalidloss -1477.44295  last_update 35\n",
      "train: iter 747  trainloss -1511.08805  validloss -1447.20122±0.00000  bestvalidloss -1477.44295  last_update 36\n",
      "train: iter 748  trainloss -1558.92151  validloss -1433.68962±0.00000  bestvalidloss -1477.44295  last_update 37\n",
      "train: iter 749  trainloss -1406.84805  validloss -1432.83005±0.00000  bestvalidloss -1477.44295  last_update 38\n",
      "train: iter 750  trainloss -1436.41297  validloss -1322.14191±0.00000  bestvalidloss -1477.44295  last_update 39\n",
      "train: iter 751  trainloss -1520.78870  validloss -1397.97661±0.00000  bestvalidloss -1477.44295  last_update 40\n",
      "train: iter 752  trainloss -1549.67763  validloss -1453.20299±0.00000  bestvalidloss -1477.44295  last_update 41\n",
      "train: iter 753  trainloss -1486.98953  validloss -1311.76721±0.00000  bestvalidloss -1477.44295  last_update 42\n",
      "train: iter 754  trainloss -1528.40912  validloss -1435.31998±0.00000  bestvalidloss -1477.44295  last_update 43\n",
      "train: iter 755  trainloss -1434.89459  validloss -1463.81720±0.00000  bestvalidloss -1477.44295  last_update 44\n",
      "train: iter 756  trainloss -1478.92810  validloss -1281.45197±0.00000  bestvalidloss -1477.44295  last_update 45\n",
      "train: iter 757  trainloss -1514.90811  validloss -1320.90989±0.00000  bestvalidloss -1477.44295  last_update 46\n",
      "train: iter 758  trainloss -1527.26076  validloss -1389.10589±0.00000  bestvalidloss -1477.44295  last_update 47\n",
      "train: iter 759  trainloss -1517.18688  validloss -1448.04753±0.00000  bestvalidloss -1477.44295  last_update 48\n",
      "train: iter 760  trainloss -1518.47689  validloss -1269.27124±0.00000  bestvalidloss -1477.44295  last_update 49\n",
      "train: iter 761  trainloss -1432.67989  validloss -1422.69602±0.00000  bestvalidloss -1477.44295  last_update 50\n",
      "train: iter 762  trainloss -1506.39549  validloss -1410.72020±0.00000  bestvalidloss -1477.44295  last_update 51\n",
      "train: iter 763  trainloss -1500.27372  validloss -1394.20854±0.00000  bestvalidloss -1477.44295  last_update 52\n",
      "train: iter 764  trainloss -1519.33197  validloss -1476.84302±0.00000  bestvalidloss -1477.44295  last_update 53\n",
      "train: iter 765  trainloss -1280.58248  validloss -1390.52642±0.00000  bestvalidloss -1477.44295  last_update 54\n",
      "train: iter 766  trainloss -1353.49090  validloss -962.74694±0.00000  bestvalidloss -1477.44295  last_update 55\n",
      "train: iter 767  trainloss -1497.23617  validloss -1364.14092±0.00000  bestvalidloss -1477.44295  last_update 56\n",
      "train: iter 768  trainloss -1503.84202  validloss -1398.79908±0.00000  bestvalidloss -1477.44295  last_update 57\n",
      "train: iter 769  trainloss -1410.24456  validloss -1283.85331±0.00000  bestvalidloss -1477.44295  last_update 58\n",
      "train: iter 770  trainloss -1504.42908  validloss -1416.10724±0.00000  bestvalidloss -1477.44295  last_update 59\n",
      "train: iter 771  trainloss -1517.37540  validloss -1422.21780±0.00000  bestvalidloss -1477.44295  last_update 60\n",
      "train: iter 772  trainloss -1518.28903  validloss -1437.03132±0.00000  bestvalidloss -1477.44295  last_update 61\n",
      "train: iter 773  trainloss -1496.40614  validloss -1397.24437±0.00000  bestvalidloss -1477.44295  last_update 62\n",
      "train: iter 774  trainloss -1502.45912  validloss -1425.15068±0.00000  bestvalidloss -1477.44295  last_update 63\n",
      "train: iter 775  trainloss -1510.36618  validloss -1329.06489±0.00000  bestvalidloss -1477.44295  last_update 64\n",
      "train: iter 776  trainloss -1487.68093  validloss -1440.70326±0.00000  bestvalidloss -1477.44295  last_update 65\n",
      "train: iter 777  trainloss -1543.53340  validloss -1407.28809±0.00000  bestvalidloss -1477.44295  last_update 66\n",
      "train: iter 778  trainloss -1409.98436  validloss -1490.28341±0.00000  bestvalidloss -1490.28341  last_update 0\n",
      "train: iter 779  trainloss -1454.33412  validloss -1329.08159±0.00000  bestvalidloss -1490.28341  last_update 1\n",
      "train: iter 780  trainloss -1508.46692  validloss -1279.06803±0.00000  bestvalidloss -1490.28341  last_update 2\n",
      "train: iter 781  trainloss -1495.82221  validloss -1471.35389±0.00000  bestvalidloss -1490.28341  last_update 3\n",
      "train: iter 782  trainloss -1487.37405  validloss -1277.79458±0.00000  bestvalidloss -1490.28341  last_update 4\n",
      "train: iter 783  trainloss -1553.27591  validloss -1441.40494±0.00000  bestvalidloss -1490.28341  last_update 5\n",
      "train: iter 784  trainloss -1505.84165  validloss -1442.42625±0.00000  bestvalidloss -1490.28341  last_update 6\n",
      "train: iter 785  trainloss -1541.63551  validloss -1408.96009±0.00000  bestvalidloss -1490.28341  last_update 7\n",
      "train: iter 786  trainloss -1496.03797  validloss -1414.75096±0.00000  bestvalidloss -1490.28341  last_update 8\n",
      "train: iter 787  trainloss -1463.48384  validloss -1255.54471±0.00000  bestvalidloss -1490.28341  last_update 9\n",
      "train: iter 788  trainloss -1529.78219  validloss -1416.25673±0.00000  bestvalidloss -1490.28341  last_update 10\n",
      "train: iter 789  trainloss -1555.99836  validloss -1383.46378±0.00000  bestvalidloss -1490.28341  last_update 11\n",
      "train: iter 790  trainloss -1483.42945  validloss -1425.40136±0.00000  bestvalidloss -1490.28341  last_update 12\n",
      "train: iter 791  trainloss -1505.44878  validloss -1281.49493±0.00000  bestvalidloss -1490.28341  last_update 13\n",
      "train: iter 792  trainloss -1415.51691  validloss -1317.09602±0.00000  bestvalidloss -1490.28341  last_update 14\n",
      "train: iter 793  trainloss -1468.92130  validloss -1057.39636±0.00000  bestvalidloss -1490.28341  last_update 15\n",
      "train: iter 794  trainloss -1556.70384  validloss -1445.97144±0.00000  bestvalidloss -1490.28341  last_update 16\n",
      "train: iter 795  trainloss -1539.30357  validloss -1454.06480±0.00000  bestvalidloss -1490.28341  last_update 17\n",
      "train: iter 796  trainloss -1065.12013  validloss -1365.67017±0.00000  bestvalidloss -1490.28341  last_update 18\n",
      "train: iter 797  trainloss -1373.95136  validloss -1169.25267±0.00000  bestvalidloss -1490.28341  last_update 19\n",
      "train: iter 798  trainloss -1462.16602  validloss -1322.44943±0.00000  bestvalidloss -1490.28341  last_update 20\n",
      "train: iter 799  trainloss -1474.57340  validloss -1391.73173±0.00000  bestvalidloss -1490.28341  last_update 21\n",
      "train: iter 800  trainloss -1500.05144  validloss -1412.72318±0.00000  bestvalidloss -1490.28341  last_update 22\n",
      "train: iter 801  trainloss -1479.11822  validloss -1472.21145±0.00000  bestvalidloss -1490.28341  last_update 23\n",
      "train: iter 802  trainloss -1524.36085  validloss -1400.66709±0.00000  bestvalidloss -1490.28341  last_update 24\n",
      "train: iter 803  trainloss -1521.58131  validloss -1463.34408±0.00000  bestvalidloss -1490.28341  last_update 25\n",
      "train: iter 804  trainloss -1470.30402  validloss -1353.71225±0.00000  bestvalidloss -1490.28341  last_update 26\n",
      "train: iter 805  trainloss -1548.76369  validloss -1449.14238±0.00000  bestvalidloss -1490.28341  last_update 27\n",
      "train: iter 806  trainloss -1542.22522  validloss -1373.51872±0.00000  bestvalidloss -1490.28341  last_update 28\n",
      "train: iter 807  trainloss -1526.07407  validloss -1427.04499±0.00000  bestvalidloss -1490.28341  last_update 29\n",
      "train: iter 808  trainloss -1444.16828  validloss -363.17213±0.00000  bestvalidloss -1490.28341  last_update 30\n",
      "train: iter 809  trainloss -1529.72022  validloss -1349.58655±0.00000  bestvalidloss -1490.28341  last_update 31\n",
      "train: iter 810  trainloss -1482.70550  validloss -1434.67504±0.00000  bestvalidloss -1490.28341  last_update 32\n",
      "train: iter 811  trainloss -1449.88564  validloss -1299.44707±0.00000  bestvalidloss -1490.28341  last_update 33\n",
      "train: iter 812  trainloss -1453.32749  validloss -1391.11243±0.00000  bestvalidloss -1490.28341  last_update 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 813  trainloss -1533.08285  validloss -1374.54068±0.00000  bestvalidloss -1490.28341  last_update 35\n",
      "train: iter 814  trainloss -1570.28538  validloss -1434.12164±0.00000  bestvalidloss -1490.28341  last_update 36\n",
      "train: iter 815  trainloss -1547.69215  validloss -1482.13781±0.00000  bestvalidloss -1490.28341  last_update 37\n",
      "train: iter 816  trainloss -1313.13602  validloss -1444.84071±0.00000  bestvalidloss -1490.28341  last_update 38\n",
      "train: iter 817  trainloss -1535.04219  validloss -1374.82112±0.00000  bestvalidloss -1490.28341  last_update 39\n",
      "train: iter 818  trainloss -1535.18041  validloss -1465.04856±0.00000  bestvalidloss -1490.28341  last_update 40\n",
      "train: iter 819  trainloss -1526.04203  validloss -1394.84250±0.00000  bestvalidloss -1490.28341  last_update 41\n",
      "train: iter 820  trainloss -1526.55931  validloss -1511.27047±0.00000  bestvalidloss -1511.27047  last_update 0\n",
      "train: iter 821  trainloss -1460.06487  validloss -893.56743±0.00000  bestvalidloss -1511.27047  last_update 1\n",
      "train: iter 822  trainloss -1530.26328  validloss -1406.00552±0.00000  bestvalidloss -1511.27047  last_update 2\n",
      "train: iter 823  trainloss -1545.56352  validloss -1441.76971±0.00000  bestvalidloss -1511.27047  last_update 3\n",
      "train: iter 824  trainloss -1511.30589  validloss -1427.55517±0.00000  bestvalidloss -1511.27047  last_update 4\n",
      "train: iter 825  trainloss -1445.89596  validloss -1131.18547±0.00000  bestvalidloss -1511.27047  last_update 5\n",
      "train: iter 826  trainloss -1548.48527  validloss -1439.76372±0.00000  bestvalidloss -1511.27047  last_update 6\n",
      "train: iter 827  trainloss -1544.02004  validloss -1479.07342±0.00000  bestvalidloss -1511.27047  last_update 7\n",
      "train: iter 828  trainloss -1445.66629  validloss -1424.63064±0.00000  bestvalidloss -1511.27047  last_update 8\n",
      "train: iter 829  trainloss -922.20343  validloss -765.35951±0.00000  bestvalidloss -1511.27047  last_update 9\n",
      "train: iter 830  trainloss -1443.17643  validloss -1265.15098±0.00000  bestvalidloss -1511.27047  last_update 10\n",
      "train: iter 831  trainloss -1479.29300  validloss -1432.75150±0.00000  bestvalidloss -1511.27047  last_update 11\n",
      "train: iter 832  trainloss -1550.43814  validloss -1441.00262±0.00000  bestvalidloss -1511.27047  last_update 12\n",
      "train: iter 833  trainloss -1472.27167  validloss -1336.88273±0.00000  bestvalidloss -1511.27047  last_update 13\n",
      "train: iter 834  trainloss -1541.01452  validloss -1353.71794±0.00000  bestvalidloss -1511.27047  last_update 14\n",
      "train: iter 835  trainloss -1568.45279  validloss -1459.24306±0.00000  bestvalidloss -1511.27047  last_update 15\n",
      "train: iter 836  trainloss -1415.82591  validloss -1391.41712±0.00000  bestvalidloss -1511.27047  last_update 16\n",
      "train: iter 837  trainloss -1526.37115  validloss -1375.82514±0.00000  bestvalidloss -1511.27047  last_update 17\n",
      "train: iter 838  trainloss -1521.03177  validloss -1354.46429±0.00000  bestvalidloss -1511.27047  last_update 18\n",
      "train: iter 839  trainloss -1373.54861  validloss -1405.88935±0.00000  bestvalidloss -1511.27047  last_update 19\n",
      "train: iter 840  trainloss -1122.52811  validloss 680.52740±0.00000  bestvalidloss -1511.27047  last_update 20\n",
      "train: iter 841  trainloss -1521.07629  validloss -1366.32700±0.00000  bestvalidloss -1511.27047  last_update 21\n",
      "train: iter 842  trainloss -1529.51389  validloss -1422.96840±0.00000  bestvalidloss -1511.27047  last_update 22\n",
      "train: iter 843  trainloss -1430.12115  validloss -1330.54355±0.00000  bestvalidloss -1511.27047  last_update 23\n",
      "train: iter 844  trainloss -1534.47767  validloss -1397.38547±0.00000  bestvalidloss -1511.27047  last_update 24\n",
      "train: iter 845  trainloss -1555.63128  validloss -1456.20780±0.00000  bestvalidloss -1511.27047  last_update 25\n",
      "train: iter 846  trainloss -1561.81816  validloss -1456.32487±0.00000  bestvalidloss -1511.27047  last_update 26\n",
      "train: iter 847  trainloss -1549.91358  validloss -1456.50380±0.00000  bestvalidloss -1511.27047  last_update 27\n",
      "train: iter 848  trainloss -1549.95786  validloss -1388.48403±0.00000  bestvalidloss -1511.27047  last_update 28\n",
      "train: iter 849  trainloss -1565.80121  validloss -1480.52008±0.00000  bestvalidloss -1511.27047  last_update 29\n",
      "train: iter 850  trainloss -1527.50963  validloss -1452.82826±0.00000  bestvalidloss -1511.27047  last_update 30\n",
      "train: iter 851  trainloss -1540.50721  validloss -1372.72417±0.00000  bestvalidloss -1511.27047  last_update 31\n",
      "train: iter 852  trainloss -1545.00413  validloss -1420.00442±0.00000  bestvalidloss -1511.27047  last_update 32\n",
      "train: iter 853  trainloss -1511.24884  validloss -1466.63626±0.00000  bestvalidloss -1511.27047  last_update 33\n",
      "train: iter 854  trainloss -1010.48740  validloss -1234.72514±0.00000  bestvalidloss -1511.27047  last_update 34\n",
      "train: iter 855  trainloss -1519.46599  validloss -1318.56525±0.00000  bestvalidloss -1511.27047  last_update 35\n",
      "train: iter 856  trainloss -1542.51407  validloss -1445.83731±0.00000  bestvalidloss -1511.27047  last_update 36\n",
      "train: iter 857  trainloss -1516.73037  validloss -1444.23820±0.00000  bestvalidloss -1511.27047  last_update 37\n",
      "train: iter 858  trainloss -1546.83809  validloss -1421.78041±0.00000  bestvalidloss -1511.27047  last_update 38\n",
      "train: iter 859  trainloss -1508.32662  validloss -1424.27148±0.00000  bestvalidloss -1511.27047  last_update 39\n",
      "train: iter 860  trainloss -1439.88809  validloss -1454.16278±0.00000  bestvalidloss -1511.27047  last_update 40\n",
      "train: iter 861  trainloss -1559.51586  validloss -1421.70553±0.00000  bestvalidloss -1511.27047  last_update 41\n",
      "train: iter 862  trainloss -1570.11036  validloss -1470.69157±0.00000  bestvalidloss -1511.27047  last_update 42\n",
      "train: iter 863  trainloss -1552.42827  validloss -1428.51839±0.00000  bestvalidloss -1511.27047  last_update 43\n",
      "train: iter 864  trainloss -1446.74322  validloss -1482.75979±0.00000  bestvalidloss -1511.27047  last_update 44\n",
      "train: iter 865  trainloss -996.61827  validloss -1214.30581±0.00000  bestvalidloss -1511.27047  last_update 45\n",
      "train: iter 866  trainloss -1403.98776  validloss -1019.26439±0.00000  bestvalidloss -1511.27047  last_update 46\n",
      "train: iter 867  trainloss -1524.25167  validloss -1337.20335±0.00000  bestvalidloss -1511.27047  last_update 47\n",
      "train: iter 868  trainloss -1514.33820  validloss -1424.37787±0.00000  bestvalidloss -1511.27047  last_update 48\n",
      "train: iter 869  trainloss -1557.54012  validloss -1423.17001±0.00000  bestvalidloss -1511.27047  last_update 49\n",
      "train: iter 870  trainloss -1513.15970  validloss -1409.14594±0.00000  bestvalidloss -1511.27047  last_update 50\n",
      "train: iter 871  trainloss -1553.00167  validloss -1419.05061±0.00000  bestvalidloss -1511.27047  last_update 51\n",
      "train: iter 872  trainloss -1493.15754  validloss -1375.74703±0.00000  bestvalidloss -1511.27047  last_update 52\n",
      "train: iter 873  trainloss -1556.70292  validloss -1462.23538±0.00000  bestvalidloss -1511.27047  last_update 53\n",
      "train: iter 874  trainloss -1503.97057  validloss -1411.91646±0.00000  bestvalidloss -1511.27047  last_update 54\n",
      "train: iter 875  trainloss -1541.07928  validloss -1440.10690±0.00000  bestvalidloss -1511.27047  last_update 55\n",
      "train: iter 876  trainloss -1498.36226  validloss -1462.29939±0.00000  bestvalidloss -1511.27047  last_update 56\n",
      "train: iter 877  trainloss -1500.93890  validloss -1402.49175±0.00000  bestvalidloss -1511.27047  last_update 57\n",
      "train: iter 878  trainloss -1496.91025  validloss -1424.37808±0.00000  bestvalidloss -1511.27047  last_update 58\n",
      "train: iter 879  trainloss -1542.78309  validloss -1408.62462±0.00000  bestvalidloss -1511.27047  last_update 59\n",
      "train: iter 880  trainloss -1554.68530  validloss -1472.37700±0.00000  bestvalidloss -1511.27047  last_update 60\n",
      "train: iter 881  trainloss -1349.72217  validloss -1461.24848±0.00000  bestvalidloss -1511.27047  last_update 61\n",
      "train: iter 882  trainloss -1515.16091  validloss -1270.17127±0.00000  bestvalidloss -1511.27047  last_update 62\n",
      "train: iter 883  trainloss -1537.81246  validloss -1462.82668±0.00000  bestvalidloss -1511.27047  last_update 63\n",
      "train: iter 884  trainloss -1538.66605  validloss -1442.06818±0.00000  bestvalidloss -1511.27047  last_update 64\n",
      "train: iter 885  trainloss -1576.75842  validloss -1476.78144±0.00000  bestvalidloss -1511.27047  last_update 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 886  trainloss -1512.05130  validloss -1467.48972±0.00000  bestvalidloss -1511.27047  last_update 66\n",
      "train: iter 887  trainloss -1549.11521  validloss -1366.68558±0.00000  bestvalidloss -1511.27047  last_update 67\n",
      "train: iter 888  trainloss -1524.60550  validloss -1473.75477±0.00000  bestvalidloss -1511.27047  last_update 68\n",
      "train: iter 889  trainloss -1495.02516  validloss -1403.46242±0.00000  bestvalidloss -1511.27047  last_update 69\n",
      "train: iter 890  trainloss -1568.13222  validloss -1424.64607±0.00000  bestvalidloss -1511.27047  last_update 70\n",
      "train: iter 891  trainloss -1548.84734  validloss -1479.27227±0.00000  bestvalidloss -1511.27047  last_update 71\n",
      "train: iter 892  trainloss -1525.01956  validloss -1509.04295±0.00000  bestvalidloss -1511.27047  last_update 72\n",
      "train: iter 893  trainloss -1216.07837  validloss -1421.73908±0.00000  bestvalidloss -1511.27047  last_update 73\n",
      "train: iter 894  trainloss -1455.52858  validloss -1120.39336±0.00000  bestvalidloss -1511.27047  last_update 74\n",
      "train: iter 895  trainloss -1550.04801  validloss -1415.53553±0.00000  bestvalidloss -1511.27047  last_update 75\n",
      "train: iter 896  trainloss -1556.43982  validloss -1411.00373±0.00000  bestvalidloss -1511.27047  last_update 76\n",
      "train: iter 897  trainloss -1573.93063  validloss -1468.03099±0.00000  bestvalidloss -1511.27047  last_update 77\n",
      "train: iter 898  trainloss -1559.32257  validloss -1444.89425±0.00000  bestvalidloss -1511.27047  last_update 78\n",
      "train: iter 899  trainloss -1532.74048  validloss -1433.39112±0.00000  bestvalidloss -1511.27047  last_update 79\n",
      "train: iter 900  trainloss -1548.53615  validloss -1426.64613±0.00000  bestvalidloss -1511.27047  last_update 80\n",
      "train: iter 901  trainloss -1558.90518  validloss -1443.58121±0.00000  bestvalidloss -1511.27047  last_update 81\n",
      "train: iter 902  trainloss -1564.72806  validloss -1486.81578±0.00000  bestvalidloss -1511.27047  last_update 82\n",
      "train: iter 903  trainloss -1542.18122  validloss -1410.66431±0.00000  bestvalidloss -1511.27047  last_update 83\n",
      "train: iter 904  trainloss -1555.13786  validloss -1455.98076±0.00000  bestvalidloss -1511.27047  last_update 84\n",
      "train: iter 905  trainloss -1428.09698  validloss -1241.98443±0.00000  bestvalidloss -1511.27047  last_update 85\n",
      "train: iter 906  trainloss -1480.24276  validloss -1428.19907±0.00000  bestvalidloss -1511.27047  last_update 86\n",
      "train: iter 907  trainloss -1507.06850  validloss -1300.14372±0.00000  bestvalidloss -1511.27047  last_update 87\n",
      "train: iter 908  trainloss -1553.45443  validloss -1456.55423±0.00000  bestvalidloss -1511.27047  last_update 88\n",
      "train: iter 909  trainloss -1530.18976  validloss -1280.51853±0.00000  bestvalidloss -1511.27047  last_update 89\n",
      "train: iter 910  trainloss -1210.03758  validloss -1483.86668±0.00000  bestvalidloss -1511.27047  last_update 90\n",
      "train: iter 911  trainloss -1340.42185  validloss -895.85432±0.00000  bestvalidloss -1511.27047  last_update 91\n",
      "train: iter 912  trainloss -1514.16276  validloss -1364.12781±0.00000  bestvalidloss -1511.27047  last_update 92\n",
      "train: iter 913  trainloss -1526.84714  validloss -1413.20905±0.00000  bestvalidloss -1511.27047  last_update 93\n",
      "train: iter 914  trainloss -1457.95556  validloss -1377.39416±0.00000  bestvalidloss -1511.27047  last_update 94\n",
      "train: iter 915  trainloss -1445.51787  validloss -1097.23051±0.00000  bestvalidloss -1511.27047  last_update 95\n",
      "train: iter 916  trainloss -1545.70322  validloss -1404.73814±0.00000  bestvalidloss -1511.27047  last_update 96\n",
      "train: iter 917  trainloss -1547.45816  validloss -1437.26028±0.00000  bestvalidloss -1511.27047  last_update 97\n",
      "train: iter 918  trainloss -1534.17208  validloss -1384.37889±0.00000  bestvalidloss -1511.27047  last_update 98\n",
      "train: iter 919  trainloss -1558.03951  validloss -1437.87466±0.00000  bestvalidloss -1511.27047  last_update 99\n",
      "train: iter 920  trainloss -1584.45820  validloss -1467.01913±0.00000  bestvalidloss -1511.27047  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.0937) penalty_target_max tensor(10.0831)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 6.28300  validloss 6.60712±0.00000  bestvalidloss 6.60712  last_update 0\n",
      "train: iter 1  trainloss 5.76794  validloss 6.04515±0.00000  bestvalidloss 6.04515  last_update 0\n",
      "train: iter 2  trainloss 5.34979  validloss 5.55691±0.00000  bestvalidloss 5.55691  last_update 0\n",
      "train: iter 3  trainloss 5.00356  validloss 5.19412±0.00000  bestvalidloss 5.19412  last_update 0\n",
      "train: iter 4  trainloss 4.71537  validloss 4.87512±0.00000  bestvalidloss 4.87512  last_update 0\n",
      "train: iter 5  trainloss 4.47103  validloss 4.60383±0.00000  bestvalidloss 4.60383  last_update 0\n",
      "train: iter 6  trainloss 4.26541  validloss 4.38208±0.00000  bestvalidloss 4.38208  last_update 0\n",
      "train: iter 7  trainloss 4.08082  validloss 4.20052±0.00000  bestvalidloss 4.20052  last_update 0\n",
      "train: iter 8  trainloss 3.92219  validloss 4.01004±0.00000  bestvalidloss 4.01004  last_update 0\n",
      "train: iter 9  trainloss 3.77176  validloss 3.85893±0.00000  bestvalidloss 3.85893  last_update 0\n",
      "train: iter 10  trainloss 3.63605  validloss 3.71811±0.00000  bestvalidloss 3.71811  last_update 0\n",
      "train: iter 11  trainloss 3.50306  validloss 3.58298±0.00000  bestvalidloss 3.58298  last_update 0\n",
      "train: iter 12  trainloss 3.37971  validloss 3.45738±0.00000  bestvalidloss 3.45738  last_update 0\n",
      "train: iter 13  trainloss 3.26335  validloss 3.34768±0.00000  bestvalidloss 3.34768  last_update 0\n",
      "train: iter 14  trainloss 3.14425  validloss 3.20505±0.00000  bestvalidloss 3.20505  last_update 0\n",
      "train: iter 15  trainloss 3.02156  validloss 3.09757±0.00000  bestvalidloss 3.09757  last_update 0\n",
      "train: iter 16  trainloss 2.90383  validloss 2.97684±0.00000  bestvalidloss 2.97684  last_update 0\n",
      "train: iter 17  trainloss 2.78903  validloss 2.85674±0.00000  bestvalidloss 2.85674  last_update 0\n",
      "train: iter 18  trainloss 2.66551  validloss 2.73395±0.00000  bestvalidloss 2.73395  last_update 0\n",
      "train: iter 19  trainloss 2.55452  validloss 2.62304±0.00000  bestvalidloss 2.62304  last_update 0\n",
      "train: iter 20  trainloss 2.43990  validloss 2.50614±0.00000  bestvalidloss 2.50614  last_update 0\n",
      "train: iter 21  trainloss 2.33085  validloss 2.39222±0.00000  bestvalidloss 2.39222  last_update 0\n",
      "train: iter 22  trainloss 2.22228  validloss 2.28610±0.00000  bestvalidloss 2.28610  last_update 0\n",
      "train: iter 23  trainloss 2.12441  validloss 2.18093±0.00000  bestvalidloss 2.18093  last_update 0\n",
      "train: iter 24  trainloss 2.03179  validloss 2.08057±0.00000  bestvalidloss 2.08057  last_update 0\n",
      "train: iter 25  trainloss 1.94214  validloss 1.99415±0.00000  bestvalidloss 1.99415  last_update 0\n",
      "train: iter 26  trainloss 1.85399  validloss 1.90005±0.00000  bestvalidloss 1.90005  last_update 0\n",
      "train: iter 27  trainloss 1.77276  validloss 1.81339±0.00000  bestvalidloss 1.81339  last_update 0\n",
      "train: iter 28  trainloss 1.68934  validloss 1.73545±0.00000  bestvalidloss 1.73545  last_update 0\n",
      "train: iter 29  trainloss 1.61033  validloss 1.64983±0.00000  bestvalidloss 1.64983  last_update 0\n",
      "train: iter 30  trainloss 1.52923  validloss 1.56939±0.00000  bestvalidloss 1.56939  last_update 0\n",
      "train: iter 31  trainloss 1.44795  validloss 1.48759±0.00000  bestvalidloss 1.48759  last_update 0\n",
      "train: iter 32  trainloss 1.36680  validloss 1.40318±0.00000  bestvalidloss 1.40318  last_update 0\n",
      "train: iter 33  trainloss 1.28244  validloss 1.32402±0.00000  bestvalidloss 1.32402  last_update 0\n",
      "train: iter 34  trainloss 1.20176  validloss 1.24978±0.00000  bestvalidloss 1.24978  last_update 0\n",
      "train: iter 35  trainloss 1.11550  validloss 1.15783±0.00000  bestvalidloss 1.15783  last_update 0\n",
      "train: iter 36  trainloss 1.03113  validloss 1.07911±0.00000  bestvalidloss 1.07911  last_update 0\n",
      "train: iter 37  trainloss 0.94533  validloss 0.98379±0.00000  bestvalidloss 0.98379  last_update 0\n",
      "train: iter 38  trainloss 0.85849  validloss 0.90968±0.00000  bestvalidloss 0.90968  last_update 0\n",
      "train: iter 39  trainloss 0.76830  validloss 0.81238±0.00000  bestvalidloss 0.81238  last_update 0\n",
      "train: iter 40  trainloss 0.67832  validloss 0.71889±0.00000  bestvalidloss 0.71889  last_update 0\n",
      "train: iter 41  trainloss 0.59027  validloss 0.63208±0.00000  bestvalidloss 0.63208  last_update 0\n",
      "train: iter 42  trainloss 0.50042  validloss 0.53761±0.00000  bestvalidloss 0.53761  last_update 0\n",
      "train: iter 43  trainloss 0.41301  validloss 0.44881±0.00000  bestvalidloss 0.44881  last_update 0\n",
      "train: iter 44  trainloss 0.32609  validloss 0.35471±0.00000  bestvalidloss 0.35471  last_update 0\n",
      "train: iter 45  trainloss 0.23574  validloss 0.27722±0.00000  bestvalidloss 0.27722  last_update 0\n",
      "train: iter 46  trainloss 0.14642  validloss 0.18733±0.00000  bestvalidloss 0.18733  last_update 0\n",
      "train: iter 47  trainloss 0.05943  validloss 0.08849±0.00000  bestvalidloss 0.08849  last_update 0\n",
      "train: iter 48  trainloss -0.02962  validloss 0.00304±0.00000  bestvalidloss 0.00304  last_update 0\n",
      "train: iter 49  trainloss -0.08757  validloss -0.07037±0.00000  bestvalidloss -0.07037  last_update 0\n",
      "train: iter 50  trainloss -0.17508  validloss -0.16252±0.00000  bestvalidloss -0.16252  last_update 0\n",
      "train: iter 51  trainloss -0.24738  validloss -0.23503±0.00000  bestvalidloss -0.23503  last_update 0\n",
      "train: iter 52  trainloss -0.33270  validloss -0.31651±0.00000  bestvalidloss -0.31651  last_update 0\n",
      "train: iter 53  trainloss -0.38694  validloss -0.37399±0.00000  bestvalidloss -0.37399  last_update 0\n",
      "train: iter 54  trainloss -0.46292  validloss -0.46855±0.00000  bestvalidloss -0.46855  last_update 0\n",
      "train: iter 55  trainloss -0.53650  validloss -0.51632±0.00000  bestvalidloss -0.51632  last_update 0\n",
      "train: iter 56  trainloss -0.61217  validloss -0.59150±0.00000  bestvalidloss -0.59150  last_update 0\n",
      "train: iter 57  trainloss -0.68464  validloss -0.66587±0.00000  bestvalidloss -0.66587  last_update 0\n",
      "train: iter 58  trainloss -0.74693  validloss -0.72571±0.00000  bestvalidloss -0.72571  last_update 0\n",
      "train: iter 59  trainloss -0.79702  validloss -0.81247±0.00000  bestvalidloss -0.81247  last_update 0\n",
      "train: iter 60  trainloss -0.86768  validloss -0.88057±0.00000  bestvalidloss -0.88057  last_update 0\n",
      "train: iter 61  trainloss -0.90553  validloss -0.90282±0.00000  bestvalidloss -0.90282  last_update 0\n",
      "train: iter 62  trainloss -0.98460  validloss -0.98577±0.00000  bestvalidloss -0.98577  last_update 0\n",
      "train: iter 63  trainloss -1.04683  validloss -1.04998±0.00000  bestvalidloss -1.04998  last_update 0\n",
      "train: iter 64  trainloss -1.09338  validloss -1.10574±0.00000  bestvalidloss -1.10574  last_update 0\n",
      "train: iter 65  trainloss -1.14581  validloss -1.16391±0.00000  bestvalidloss -1.16391  last_update 0\n",
      "train: iter 66  trainloss -1.18055  validloss -1.20717±0.00000  bestvalidloss -1.20717  last_update 0\n",
      "train: iter 67  trainloss -1.22207  validloss -1.27459±0.00000  bestvalidloss -1.27459  last_update 0\n",
      "train: iter 68  trainloss -1.29727  validloss -1.31393±0.00000  bestvalidloss -1.31393  last_update 0\n",
      "train: iter 69  trainloss -1.35674  validloss -1.39014±0.00000  bestvalidloss -1.39014  last_update 0\n",
      "train: iter 70  trainloss -1.39856  validloss -1.43194±0.00000  bestvalidloss -1.43194  last_update 0\n",
      "train: iter 71  trainloss -1.42884  validloss -1.47130±0.00000  bestvalidloss -1.47130  last_update 0\n",
      "train: iter 72  trainloss -1.45670  validloss -1.55818±0.00000  bestvalidloss -1.55818  last_update 0\n",
      "train: iter 73  trainloss -1.51691  validloss -1.57104±0.00000  bestvalidloss -1.57104  last_update 0\n",
      "train: iter 74  trainloss -1.56144  validloss -1.60318±0.00000  bestvalidloss -1.60318  last_update 0\n",
      "train: iter 75  trainloss -1.62073  validloss -1.67830±0.00000  bestvalidloss -1.67830  last_update 0\n",
      "train: iter 76  trainloss -1.65332  validloss -1.63474±0.00000  bestvalidloss -1.67830  last_update 1\n",
      "train: iter 77  trainloss -1.68988  validloss -1.71848±0.00000  bestvalidloss -1.71848  last_update 0\n",
      "train: iter 78  trainloss -1.71198  validloss -1.77922±0.00000  bestvalidloss -1.77922  last_update 0\n",
      "train: iter 79  trainloss -1.73892  validloss -1.77324±0.00000  bestvalidloss -1.77922  last_update 1\n",
      "train: iter 80  trainloss -1.69021  validloss -1.86674±0.00000  bestvalidloss -1.86674  last_update 0\n",
      "train: iter 81  trainloss -1.78799  validloss -1.86835±0.00000  bestvalidloss -1.86835  last_update 0\n",
      "train: iter 82  trainloss -1.79887  validloss -1.89351±0.00000  bestvalidloss -1.89351  last_update 0\n",
      "train: iter 83  trainloss -1.88108  validloss -1.95154±0.00000  bestvalidloss -1.95154  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss -1.83204  validloss -1.98106±0.00000  bestvalidloss -1.98106  last_update 0\n",
      "train: iter 85  trainloss -1.89617  validloss -2.00642±0.00000  bestvalidloss -2.00642  last_update 0\n",
      "train: iter 86  trainloss -1.97386  validloss -1.98540±0.00000  bestvalidloss -2.00642  last_update 1\n",
      "train: iter 87  trainloss -1.89185  validloss -2.04332±0.00000  bestvalidloss -2.04332  last_update 0\n",
      "train: iter 88  trainloss -1.89657  validloss -2.07187±0.00000  bestvalidloss -2.07187  last_update 0\n",
      "train: iter 89  trainloss -1.93047  validloss -2.03696±0.00000  bestvalidloss -2.07187  last_update 1\n",
      "train: iter 90  trainloss -2.00151  validloss -2.11616±0.00000  bestvalidloss -2.11616  last_update 0\n",
      "train: iter 91  trainloss -1.94135  validloss -2.05782±0.00000  bestvalidloss -2.11616  last_update 1\n",
      "train: iter 92  trainloss -2.05028  validloss -2.11767±0.00000  bestvalidloss -2.11767  last_update 0\n",
      "train: iter 93  trainloss -1.99690  validloss -2.06812±0.00000  bestvalidloss -2.11767  last_update 1\n",
      "train: iter 94  trainloss -2.04679  validloss -2.15812±0.00000  bestvalidloss -2.15812  last_update 0\n",
      "train: iter 95  trainloss -2.01383  validloss -2.22317±0.00000  bestvalidloss -2.22317  last_update 0\n",
      "train: iter 96  trainloss -2.06739  validloss -2.20594±0.00000  bestvalidloss -2.22317  last_update 1\n",
      "train: iter 97  trainloss -2.03138  validloss -2.11374±0.00000  bestvalidloss -2.22317  last_update 2\n",
      "train: iter 98  trainloss -2.07881  validloss -2.14331±0.00000  bestvalidloss -2.22317  last_update 3\n",
      "train: iter 99  trainloss -2.04975  validloss -2.15422±0.00000  bestvalidloss -2.22317  last_update 4\n",
      "train: iter 100  trainloss -2.11443  validloss -2.16587±0.00000  bestvalidloss -2.22317  last_update 5\n",
      "train: iter 101  trainloss -2.03021  validloss -2.21832±0.00000  bestvalidloss -2.22317  last_update 6\n",
      "train: iter 102  trainloss -2.09701  validloss -2.21153±0.00000  bestvalidloss -2.22317  last_update 7\n",
      "train: iter 103  trainloss -2.11973  validloss -2.28484±0.00000  bestvalidloss -2.28484  last_update 0\n",
      "train: iter 104  trainloss -2.03151  validloss -2.15376±0.00000  bestvalidloss -2.28484  last_update 1\n",
      "train: iter 105  trainloss -2.04677  validloss -2.19743±0.00000  bestvalidloss -2.28484  last_update 2\n",
      "train: iter 106  trainloss -2.05301  validloss -2.31679±0.00000  bestvalidloss -2.31679  last_update 0\n",
      "train: iter 107  trainloss -2.11019  validloss -2.25902±0.00000  bestvalidloss -2.31679  last_update 1\n",
      "train: iter 108  trainloss -2.10510  validloss -2.27512±0.00000  bestvalidloss -2.31679  last_update 2\n",
      "train: iter 109  trainloss -2.16028  validloss -2.20154±0.00000  bestvalidloss -2.31679  last_update 3\n",
      "train: iter 110  trainloss -2.12051  validloss -2.13568±0.00000  bestvalidloss -2.31679  last_update 4\n",
      "train: iter 111  trainloss -2.08040  validloss -2.23784±0.00000  bestvalidloss -2.31679  last_update 5\n",
      "train: iter 112  trainloss -2.17989  validloss -2.20814±0.00000  bestvalidloss -2.31679  last_update 6\n",
      "train: iter 113  trainloss -2.10390  validloss -2.24333±0.00000  bestvalidloss -2.31679  last_update 7\n",
      "train: iter 114  trainloss -2.09454  validloss -2.30382±0.00000  bestvalidloss -2.31679  last_update 8\n",
      "train: iter 115  trainloss -2.07251  validloss -2.24765±0.00000  bestvalidloss -2.31679  last_update 9\n",
      "train: iter 116  trainloss -2.18834  validloss -2.21272±0.00000  bestvalidloss -2.31679  last_update 10\n",
      "train: iter 117  trainloss -2.15418  validloss -2.30395±0.00000  bestvalidloss -2.31679  last_update 11\n",
      "train: iter 118  trainloss -2.16702  validloss -2.25886±0.00000  bestvalidloss -2.31679  last_update 12\n",
      "train: iter 119  trainloss -2.17827  validloss -2.25149±0.00000  bestvalidloss -2.31679  last_update 13\n",
      "train: iter 120  trainloss -2.14420  validloss -2.25941±0.00000  bestvalidloss -2.31679  last_update 14\n",
      "train: iter 121  trainloss -2.18326  validloss -2.08084±0.00000  bestvalidloss -2.31679  last_update 15\n",
      "train: iter 122  trainloss -2.14676  validloss -2.29219±0.00000  bestvalidloss -2.31679  last_update 16\n",
      "train: iter 123  trainloss -2.14552  validloss -2.25562±0.00000  bestvalidloss -2.31679  last_update 17\n",
      "train: iter 124  trainloss -2.08903  validloss -2.26596±0.00000  bestvalidloss -2.31679  last_update 18\n",
      "train: iter 125  trainloss -2.19451  validloss -2.30502±0.00000  bestvalidloss -2.31679  last_update 19\n",
      "train: iter 126  trainloss -2.11070  validloss -2.27015±0.00000  bestvalidloss -2.31679  last_update 20\n",
      "train: iter 127  trainloss -2.19045  validloss -2.23008±0.00000  bestvalidloss -2.31679  last_update 21\n",
      "train: iter 128  trainloss -2.08993  validloss -2.31858±0.00000  bestvalidloss -2.31858  last_update 0\n",
      "train: iter 129  trainloss -2.13050  validloss -2.18363±0.00000  bestvalidloss -2.31858  last_update 1\n",
      "train: iter 130  trainloss -2.19128  validloss -2.09917±0.00000  bestvalidloss -2.31858  last_update 2\n",
      "train: iter 131  trainloss -2.20878  validloss -2.22896±0.00000  bestvalidloss -2.31858  last_update 3\n",
      "train: iter 132  trainloss -2.19391  validloss -2.16721±0.00000  bestvalidloss -2.31858  last_update 4\n",
      "train: iter 133  trainloss -2.18383  validloss -2.22313±0.00000  bestvalidloss -2.31858  last_update 5\n",
      "train: iter 134  trainloss -2.22075  validloss -2.33386±0.00000  bestvalidloss -2.33386  last_update 0\n",
      "train: iter 135  trainloss -2.11986  validloss -2.27317±0.00000  bestvalidloss -2.33386  last_update 1\n",
      "train: iter 136  trainloss -2.10371  validloss -2.32706±0.00000  bestvalidloss -2.33386  last_update 2\n",
      "train: iter 137  trainloss -2.15098  validloss -2.41206±0.00000  bestvalidloss -2.41206  last_update 0\n",
      "train: iter 138  trainloss -2.08494  validloss -2.32819±0.00000  bestvalidloss -2.41206  last_update 1\n",
      "train: iter 139  trainloss -2.05281  validloss -2.21692±0.00000  bestvalidloss -2.41206  last_update 2\n",
      "train: iter 140  trainloss -2.09887  validloss -2.28906±0.00000  bestvalidloss -2.41206  last_update 3\n",
      "train: iter 141  trainloss -2.11465  validloss -2.33667±0.00000  bestvalidloss -2.41206  last_update 4\n",
      "train: iter 142  trainloss -2.12011  validloss -2.17568±0.00000  bestvalidloss -2.41206  last_update 5\n",
      "train: iter 143  trainloss -2.07675  validloss -2.32803±0.00000  bestvalidloss -2.41206  last_update 6\n",
      "train: iter 144  trainloss -2.14767  validloss -2.36385±0.00000  bestvalidloss -2.41206  last_update 7\n",
      "train: iter 145  trainloss -2.15178  validloss -2.30275±0.00000  bestvalidloss -2.41206  last_update 8\n",
      "train: iter 146  trainloss -2.14126  validloss -2.18763±0.00000  bestvalidloss -2.41206  last_update 9\n",
      "train: iter 147  trainloss -2.16581  validloss -2.29507±0.00000  bestvalidloss -2.41206  last_update 10\n",
      "train: iter 148  trainloss -2.25760  validloss -2.34917±0.00000  bestvalidloss -2.41206  last_update 11\n",
      "train: iter 149  trainloss -2.12165  validloss -2.34146±0.00000  bestvalidloss -2.41206  last_update 12\n",
      "train: iter 150  trainloss -2.26259  validloss -2.29069±0.00000  bestvalidloss -2.41206  last_update 13\n",
      "train: iter 151  trainloss -2.16939  validloss -2.26975±0.00000  bestvalidloss -2.41206  last_update 14\n",
      "train: iter 152  trainloss -2.20953  validloss -2.23164±0.00000  bestvalidloss -2.41206  last_update 15\n",
      "train: iter 153  trainloss -2.07050  validloss -2.24915±0.00000  bestvalidloss -2.41206  last_update 16\n",
      "train: iter 154  trainloss -2.15747  validloss -2.24853±0.00000  bestvalidloss -2.41206  last_update 17\n",
      "train: iter 155  trainloss -2.11459  validloss -2.20126±0.00000  bestvalidloss -2.41206  last_update 18\n",
      "train: iter 156  trainloss -2.12858  validloss -2.35861±0.00000  bestvalidloss -2.41206  last_update 19\n",
      "train: iter 157  trainloss -2.16752  validloss -2.27260±0.00000  bestvalidloss -2.41206  last_update 20\n",
      "train: iter 158  trainloss -2.18776  validloss -2.22730±0.00000  bestvalidloss -2.41206  last_update 21\n",
      "train: iter 159  trainloss -2.09297  validloss -2.30093±0.00000  bestvalidloss -2.41206  last_update 22\n",
      "train: iter 160  trainloss -2.18463  validloss -2.29420±0.00000  bestvalidloss -2.41206  last_update 23\n",
      "train: iter 161  trainloss -2.20403  validloss -2.05234±0.00000  bestvalidloss -2.41206  last_update 24\n",
      "train: iter 162  trainloss -2.18683  validloss -2.32170±0.00000  bestvalidloss -2.41206  last_update 25\n",
      "train: iter 163  trainloss -2.07142  validloss -2.38309±0.00000  bestvalidloss -2.41206  last_update 26\n",
      "train: iter 164  trainloss -2.16201  validloss -2.36157±0.00000  bestvalidloss -2.41206  last_update 27\n",
      "train: iter 165  trainloss -2.17913  validloss -2.27390±0.00000  bestvalidloss -2.41206  last_update 28\n",
      "train: iter 166  trainloss -2.12673  validloss -2.33801±0.00000  bestvalidloss -2.41206  last_update 29\n",
      "train: iter 167  trainloss -2.17066  validloss -2.29063±0.00000  bestvalidloss -2.41206  last_update 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss -2.16092  validloss -2.39874±0.00000  bestvalidloss -2.41206  last_update 31\n",
      "train: iter 169  trainloss -2.21493  validloss -2.29716±0.00000  bestvalidloss -2.41206  last_update 32\n",
      "train: iter 170  trainloss -2.12326  validloss -2.32718±0.00000  bestvalidloss -2.41206  last_update 33\n",
      "train: iter 171  trainloss -2.13116  validloss -2.29289±0.00000  bestvalidloss -2.41206  last_update 34\n",
      "train: iter 172  trainloss -2.20180  validloss -2.28073±0.00000  bestvalidloss -2.41206  last_update 35\n",
      "train: iter 173  trainloss -2.19674  validloss -2.22018±0.00000  bestvalidloss -2.41206  last_update 36\n",
      "train: iter 174  trainloss -2.17969  validloss -2.35419±0.00000  bestvalidloss -2.41206  last_update 37\n",
      "train: iter 175  trainloss -2.11638  validloss -2.32466±0.00000  bestvalidloss -2.41206  last_update 38\n",
      "train: iter 176  trainloss -2.17215  validloss -2.34381±0.00000  bestvalidloss -2.41206  last_update 39\n",
      "train: iter 177  trainloss -2.16085  validloss -2.33615±0.00000  bestvalidloss -2.41206  last_update 40\n",
      "train: iter 178  trainloss -2.22936  validloss -2.20957±0.00000  bestvalidloss -2.41206  last_update 41\n",
      "train: iter 179  trainloss -2.18424  validloss -2.30116±0.00000  bestvalidloss -2.41206  last_update 42\n",
      "train: iter 180  trainloss -2.21455  validloss -2.25527±0.00000  bestvalidloss -2.41206  last_update 43\n",
      "train: iter 181  trainloss -2.19687  validloss -2.26270±0.00000  bestvalidloss -2.41206  last_update 44\n",
      "train: iter 182  trainloss -2.10576  validloss -2.17947±0.00000  bestvalidloss -2.41206  last_update 45\n",
      "train: iter 183  trainloss -2.13958  validloss -2.26156±0.00000  bestvalidloss -2.41206  last_update 46\n",
      "train: iter 184  trainloss -2.07082  validloss -2.26086±0.00000  bestvalidloss -2.41206  last_update 47\n",
      "train: iter 185  trainloss -2.08923  validloss -2.26656±0.00000  bestvalidloss -2.41206  last_update 48\n",
      "train: iter 186  trainloss -2.04299  validloss -2.24597±0.00000  bestvalidloss -2.41206  last_update 49\n",
      "train: iter 187  trainloss -2.14078  validloss -2.24120±0.00000  bestvalidloss -2.41206  last_update 50\n",
      "train: iter 188  trainloss -2.17274  validloss -2.12499±0.00000  bestvalidloss -2.41206  last_update 51\n",
      "train: iter 189  trainloss -2.07950  validloss -2.20440±0.00000  bestvalidloss -2.41206  last_update 52\n",
      "train: iter 190  trainloss -2.16510  validloss -2.38124±0.00000  bestvalidloss -2.41206  last_update 53\n",
      "train: iter 191  trainloss -2.12376  validloss -2.24486±0.00000  bestvalidloss -2.41206  last_update 54\n",
      "train: iter 192  trainloss -2.04724  validloss -2.25210±0.00000  bestvalidloss -2.41206  last_update 55\n",
      "train: iter 193  trainloss -2.22951  validloss -2.32222±0.00000  bestvalidloss -2.41206  last_update 56\n",
      "train: iter 194  trainloss -2.10517  validloss -2.28457±0.00000  bestvalidloss -2.41206  last_update 57\n",
      "train: iter 195  trainloss -2.18087  validloss -2.26871±0.00000  bestvalidloss -2.41206  last_update 58\n",
      "train: iter 196  trainloss -2.07009  validloss -2.20359±0.00000  bestvalidloss -2.41206  last_update 59\n",
      "train: iter 197  trainloss -2.12430  validloss -2.26837±0.00000  bestvalidloss -2.41206  last_update 60\n",
      "train: iter 198  trainloss -2.15809  validloss -2.32444±0.00000  bestvalidloss -2.41206  last_update 61\n",
      "train: iter 199  trainloss -2.15583  validloss -2.25546±0.00000  bestvalidloss -2.41206  last_update 62\n",
      "train: iter 200  trainloss -2.06276  validloss -2.35645±0.00000  bestvalidloss -2.41206  last_update 63\n",
      "train: iter 201  trainloss -2.07765  validloss -2.16142±0.00000  bestvalidloss -2.41206  last_update 64\n",
      "train: iter 202  trainloss -2.11522  validloss -2.25164±0.00000  bestvalidloss -2.41206  last_update 65\n",
      "train: iter 203  trainloss -2.18131  validloss -2.28246±0.00000  bestvalidloss -2.41206  last_update 66\n",
      "train: iter 204  trainloss -2.05101  validloss -2.31171±0.00000  bestvalidloss -2.41206  last_update 67\n",
      "train: iter 205  trainloss -2.17236  validloss -2.31058±0.00000  bestvalidloss -2.41206  last_update 68\n",
      "train: iter 206  trainloss -2.07193  validloss -2.30401±0.00000  bestvalidloss -2.41206  last_update 69\n",
      "train: iter 207  trainloss -2.17726  validloss -2.19885±0.00000  bestvalidloss -2.41206  last_update 70\n",
      "train: iter 208  trainloss -2.19899  validloss -2.32952±0.00000  bestvalidloss -2.41206  last_update 71\n",
      "train: iter 209  trainloss -2.12951  validloss -2.31455±0.00000  bestvalidloss -2.41206  last_update 72\n",
      "train: iter 210  trainloss -2.08228  validloss -2.21575±0.00000  bestvalidloss -2.41206  last_update 73\n",
      "train: iter 211  trainloss -2.02231  validloss -2.44428±0.00000  bestvalidloss -2.44428  last_update 0\n",
      "train: iter 212  trainloss -2.07022  validloss -2.28735±0.00000  bestvalidloss -2.44428  last_update 1\n",
      "train: iter 213  trainloss -2.12424  validloss -2.19649±0.00000  bestvalidloss -2.44428  last_update 2\n",
      "train: iter 214  trainloss -2.06885  validloss -2.38143±0.00000  bestvalidloss -2.44428  last_update 3\n",
      "train: iter 215  trainloss -2.14454  validloss -2.34445±0.00000  bestvalidloss -2.44428  last_update 4\n",
      "train: iter 216  trainloss -2.13856  validloss -2.26007±0.00000  bestvalidloss -2.44428  last_update 5\n",
      "train: iter 217  trainloss -2.19468  validloss -2.28286±0.00000  bestvalidloss -2.44428  last_update 6\n",
      "train: iter 218  trainloss -2.13885  validloss -2.10824±0.00000  bestvalidloss -2.44428  last_update 7\n",
      "train: iter 219  trainloss -2.12045  validloss -2.27347±0.00000  bestvalidloss -2.44428  last_update 8\n",
      "train: iter 220  trainloss -2.19066  validloss -2.37560±0.00000  bestvalidloss -2.44428  last_update 9\n",
      "train: iter 221  trainloss -2.14599  validloss -2.38019±0.00000  bestvalidloss -2.44428  last_update 10\n",
      "train: iter 222  trainloss -2.17407  validloss -2.30474±0.00000  bestvalidloss -2.44428  last_update 11\n",
      "train: iter 223  trainloss -2.15386  validloss -2.31138±0.00000  bestvalidloss -2.44428  last_update 12\n",
      "train: iter 224  trainloss -2.12231  validloss -2.38386±0.00000  bestvalidloss -2.44428  last_update 13\n",
      "train: iter 225  trainloss -2.09192  validloss -2.33152±0.00000  bestvalidloss -2.44428  last_update 14\n",
      "train: iter 226  trainloss -2.25670  validloss -2.29474±0.00000  bestvalidloss -2.44428  last_update 15\n",
      "train: iter 227  trainloss -2.14952  validloss -2.28277±0.00000  bestvalidloss -2.44428  last_update 16\n",
      "train: iter 228  trainloss -2.16625  validloss -2.18500±0.00000  bestvalidloss -2.44428  last_update 17\n",
      "train: iter 229  trainloss -2.10690  validloss -2.45752±0.00000  bestvalidloss -2.45752  last_update 0\n",
      "train: iter 230  trainloss -2.25437  validloss -2.13552±0.00000  bestvalidloss -2.45752  last_update 1\n",
      "train: iter 231  trainloss -2.25679  validloss -2.27802±0.00000  bestvalidloss -2.45752  last_update 2\n",
      "train: iter 232  trainloss -2.10273  validloss -2.25314±0.00000  bestvalidloss -2.45752  last_update 3\n",
      "train: iter 233  trainloss -2.11770  validloss -2.36583±0.00000  bestvalidloss -2.45752  last_update 4\n",
      "train: iter 234  trainloss -2.13870  validloss -2.21504±0.00000  bestvalidloss -2.45752  last_update 5\n",
      "train: iter 235  trainloss -2.09460  validloss -2.27152±0.00000  bestvalidloss -2.45752  last_update 6\n",
      "train: iter 236  trainloss -2.13976  validloss -2.30002±0.00000  bestvalidloss -2.45752  last_update 7\n",
      "train: iter 237  trainloss -2.07732  validloss -2.33626±0.00000  bestvalidloss -2.45752  last_update 8\n",
      "train: iter 238  trainloss -2.17809  validloss -2.29783±0.00000  bestvalidloss -2.45752  last_update 9\n",
      "train: iter 239  trainloss -2.18416  validloss -2.30495±0.00000  bestvalidloss -2.45752  last_update 10\n",
      "train: iter 240  trainloss -2.18636  validloss -2.14391±0.00000  bestvalidloss -2.45752  last_update 11\n",
      "train: iter 241  trainloss -2.21647  validloss -2.30985±0.00000  bestvalidloss -2.45752  last_update 12\n",
      "train: iter 242  trainloss -2.14616  validloss -2.31143±0.00000  bestvalidloss -2.45752  last_update 13\n",
      "train: iter 243  trainloss -2.14159  validloss -2.30726±0.00000  bestvalidloss -2.45752  last_update 14\n",
      "train: iter 244  trainloss -2.12834  validloss -2.27708±0.00000  bestvalidloss -2.45752  last_update 15\n",
      "train: iter 245  trainloss -2.12597  validloss -2.32012±0.00000  bestvalidloss -2.45752  last_update 16\n",
      "train: iter 246  trainloss -2.14362  validloss -2.28955±0.00000  bestvalidloss -2.45752  last_update 17\n",
      "train: iter 247  trainloss -2.13508  validloss -2.21976±0.00000  bestvalidloss -2.45752  last_update 18\n",
      "train: iter 248  trainloss -2.14707  validloss -2.20708±0.00000  bestvalidloss -2.45752  last_update 19\n",
      "train: iter 249  trainloss -2.16626  validloss -2.17670±0.00000  bestvalidloss -2.45752  last_update 20\n",
      "train: iter 250  trainloss -2.24670  validloss -2.34108±0.00000  bestvalidloss -2.45752  last_update 21\n",
      "train: iter 251  trainloss -2.17435  validloss -2.24488±0.00000  bestvalidloss -2.45752  last_update 22\n",
      "train: iter 252  trainloss -2.13649  validloss -2.34753±0.00000  bestvalidloss -2.45752  last_update 23\n",
      "train: iter 253  trainloss -2.11123  validloss -2.20811±0.00000  bestvalidloss -2.45752  last_update 24\n",
      "train: iter 254  trainloss -2.12928  validloss -2.31594±0.00000  bestvalidloss -2.45752  last_update 25\n",
      "train: iter 255  trainloss -2.12556  validloss -2.26884±0.00000  bestvalidloss -2.45752  last_update 26\n",
      "train: iter 256  trainloss -2.17390  validloss -2.32280±0.00000  bestvalidloss -2.45752  last_update 27\n",
      "train: iter 257  trainloss -2.10697  validloss -2.33534±0.00000  bestvalidloss -2.45752  last_update 28\n",
      "train: iter 258  trainloss -2.06428  validloss -2.39246±0.00000  bestvalidloss -2.45752  last_update 29\n",
      "train: iter 259  trainloss -2.16901  validloss -2.38560±0.00000  bestvalidloss -2.45752  last_update 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 260  trainloss -2.23349  validloss -2.25419±0.00000  bestvalidloss -2.45752  last_update 31\n",
      "train: iter 261  trainloss -2.14426  validloss -2.33018±0.00000  bestvalidloss -2.45752  last_update 32\n",
      "train: iter 262  trainloss -2.09037  validloss -2.33085±0.00000  bestvalidloss -2.45752  last_update 33\n",
      "train: iter 263  trainloss -2.19641  validloss -2.32416±0.00000  bestvalidloss -2.45752  last_update 34\n",
      "train: iter 264  trainloss -2.13563  validloss -2.29289±0.00000  bestvalidloss -2.45752  last_update 35\n",
      "train: iter 265  trainloss -2.18856  validloss -2.33347±0.00000  bestvalidloss -2.45752  last_update 36\n",
      "train: iter 266  trainloss -2.09278  validloss -2.26372±0.00000  bestvalidloss -2.45752  last_update 37\n",
      "train: iter 267  trainloss -2.14719  validloss -2.27098±0.00000  bestvalidloss -2.45752  last_update 38\n",
      "train: iter 268  trainloss -2.11373  validloss -2.24034±0.00000  bestvalidloss -2.45752  last_update 39\n",
      "train: iter 269  trainloss -2.21322  validloss -2.27767±0.00000  bestvalidloss -2.45752  last_update 40\n",
      "train: iter 270  trainloss -2.20031  validloss -2.30069±0.00000  bestvalidloss -2.45752  last_update 41\n",
      "train: iter 271  trainloss -2.08659  validloss -2.43833±0.00000  bestvalidloss -2.45752  last_update 42\n",
      "train: iter 272  trainloss -2.21088  validloss -2.31476±0.00000  bestvalidloss -2.45752  last_update 43\n",
      "train: iter 273  trainloss -2.14531  validloss -2.33538±0.00000  bestvalidloss -2.45752  last_update 44\n",
      "train: iter 274  trainloss -2.09251  validloss -2.35184±0.00000  bestvalidloss -2.45752  last_update 45\n",
      "train: iter 275  trainloss -2.08192  validloss -2.21952±0.00000  bestvalidloss -2.45752  last_update 46\n",
      "train: iter 276  trainloss -2.16990  validloss -2.23152±0.00000  bestvalidloss -2.45752  last_update 47\n",
      "train: iter 277  trainloss -2.12975  validloss -2.31827±0.00000  bestvalidloss -2.45752  last_update 48\n",
      "train: iter 278  trainloss -2.09894  validloss -2.38266±0.00000  bestvalidloss -2.45752  last_update 49\n",
      "train: iter 279  trainloss -2.16738  validloss -2.42470±0.00000  bestvalidloss -2.45752  last_update 50\n",
      "train: iter 280  trainloss -2.11395  validloss -2.33884±0.00000  bestvalidloss -2.45752  last_update 51\n",
      "train: iter 281  trainloss -2.22722  validloss -2.28046±0.00000  bestvalidloss -2.45752  last_update 52\n",
      "train: iter 282  trainloss -2.06231  validloss -2.31336±0.00000  bestvalidloss -2.45752  last_update 53\n",
      "train: iter 283  trainloss -2.10213  validloss -2.24611±0.00000  bestvalidloss -2.45752  last_update 54\n",
      "train: iter 284  trainloss -2.13690  validloss -2.26728±0.00000  bestvalidloss -2.45752  last_update 55\n",
      "train: iter 285  trainloss -2.15152  validloss -2.29899±0.00000  bestvalidloss -2.45752  last_update 56\n",
      "train: iter 286  trainloss -2.18581  validloss -2.34855±0.00000  bestvalidloss -2.45752  last_update 57\n",
      "train: iter 287  trainloss -2.16808  validloss -2.29415±0.00000  bestvalidloss -2.45752  last_update 58\n",
      "train: iter 288  trainloss -2.13973  validloss -2.26210±0.00000  bestvalidloss -2.45752  last_update 59\n",
      "train: iter 289  trainloss -2.18894  validloss -2.32125±0.00000  bestvalidloss -2.45752  last_update 60\n",
      "train: iter 290  trainloss -2.12337  validloss -2.23358±0.00000  bestvalidloss -2.45752  last_update 61\n",
      "train: iter 291  trainloss -2.06100  validloss -2.26291±0.00000  bestvalidloss -2.45752  last_update 62\n",
      "train: iter 292  trainloss -2.18853  validloss -2.29927±0.00000  bestvalidloss -2.45752  last_update 63\n",
      "train: iter 293  trainloss -2.18631  validloss -2.29082±0.00000  bestvalidloss -2.45752  last_update 64\n",
      "train: iter 294  trainloss -2.09643  validloss -2.27788±0.00000  bestvalidloss -2.45752  last_update 65\n",
      "train: iter 295  trainloss -2.11463  validloss -2.29882±0.00000  bestvalidloss -2.45752  last_update 66\n",
      "train: iter 296  trainloss -2.18791  validloss -2.19599±0.00000  bestvalidloss -2.45752  last_update 67\n",
      "train: iter 297  trainloss -2.11665  validloss -2.46597±0.00000  bestvalidloss -2.46597  last_update 0\n",
      "train: iter 298  trainloss -2.09873  validloss -2.26568±0.00000  bestvalidloss -2.46597  last_update 1\n",
      "train: iter 299  trainloss -2.05869  validloss -2.20799±0.00000  bestvalidloss -2.46597  last_update 2\n",
      "train: iter 300  trainloss -2.09577  validloss -2.22213±0.00000  bestvalidloss -2.46597  last_update 3\n",
      "train: iter 301  trainloss -2.19635  validloss -2.24789±0.00000  bestvalidloss -2.46597  last_update 4\n",
      "train: iter 302  trainloss -2.13405  validloss -2.26647±0.00000  bestvalidloss -2.46597  last_update 5\n",
      "train: iter 303  trainloss -2.13103  validloss -2.20793±0.00000  bestvalidloss -2.46597  last_update 6\n",
      "train: iter 304  trainloss -2.21236  validloss -2.35993±0.00000  bestvalidloss -2.46597  last_update 7\n",
      "train: iter 305  trainloss -2.12132  validloss -2.23856±0.00000  bestvalidloss -2.46597  last_update 8\n",
      "train: iter 306  trainloss -2.04508  validloss -2.27000±0.00000  bestvalidloss -2.46597  last_update 9\n",
      "train: iter 307  trainloss -2.18078  validloss -2.24956±0.00000  bestvalidloss -2.46597  last_update 10\n",
      "train: iter 308  trainloss -2.16758  validloss -2.26530±0.00000  bestvalidloss -2.46597  last_update 11\n",
      "train: iter 309  trainloss -2.15330  validloss -2.36586±0.00000  bestvalidloss -2.46597  last_update 12\n",
      "train: iter 310  trainloss -2.16544  validloss -2.35281±0.00000  bestvalidloss -2.46597  last_update 13\n",
      "train: iter 311  trainloss -2.25228  validloss -2.26055±0.00000  bestvalidloss -2.46597  last_update 14\n",
      "train: iter 312  trainloss -2.12665  validloss -2.29170±0.00000  bestvalidloss -2.46597  last_update 15\n",
      "train: iter 313  trainloss -2.19079  validloss -2.39578±0.00000  bestvalidloss -2.46597  last_update 16\n",
      "train: iter 314  trainloss -2.11597  validloss -2.37428±0.00000  bestvalidloss -2.46597  last_update 17\n",
      "train: iter 315  trainloss -2.12034  validloss -2.34414±0.00000  bestvalidloss -2.46597  last_update 18\n",
      "train: iter 316  trainloss -2.21029  validloss -2.34548±0.00000  bestvalidloss -2.46597  last_update 19\n",
      "train: iter 317  trainloss -2.10601  validloss -2.31843±0.00000  bestvalidloss -2.46597  last_update 20\n",
      "train: iter 318  trainloss -2.04877  validloss -2.23668±0.00000  bestvalidloss -2.46597  last_update 21\n",
      "train: iter 319  trainloss -2.13456  validloss -2.32145±0.00000  bestvalidloss -2.46597  last_update 22\n",
      "train: iter 320  trainloss -2.12939  validloss -2.17481±0.00000  bestvalidloss -2.46597  last_update 23\n",
      "train: iter 321  trainloss -2.11047  validloss -2.23783±0.00000  bestvalidloss -2.46597  last_update 24\n",
      "train: iter 322  trainloss -2.08866  validloss -2.26961±0.00000  bestvalidloss -2.46597  last_update 25\n",
      "train: iter 323  trainloss -2.06286  validloss -2.33300±0.00000  bestvalidloss -2.46597  last_update 26\n",
      "train: iter 324  trainloss -2.15904  validloss -2.26824±0.00000  bestvalidloss -2.46597  last_update 27\n",
      "train: iter 325  trainloss -2.14595  validloss -2.24833±0.00000  bestvalidloss -2.46597  last_update 28\n",
      "train: iter 326  trainloss -2.05505  validloss -2.32498±0.00000  bestvalidloss -2.46597  last_update 29\n",
      "train: iter 327  trainloss -2.14934  validloss -2.28650±0.00000  bestvalidloss -2.46597  last_update 30\n",
      "train: iter 328  trainloss -2.15647  validloss -2.27606±0.00000  bestvalidloss -2.46597  last_update 31\n",
      "train: iter 329  trainloss -2.15412  validloss -2.27807±0.00000  bestvalidloss -2.46597  last_update 32\n",
      "train: iter 330  trainloss -2.13277  validloss -2.29027±0.00000  bestvalidloss -2.46597  last_update 33\n",
      "train: iter 331  trainloss -2.13806  validloss -2.14364±0.00000  bestvalidloss -2.46597  last_update 34\n",
      "train: iter 332  trainloss -2.11520  validloss -2.35479±0.00000  bestvalidloss -2.46597  last_update 35\n",
      "train: iter 333  trainloss -2.18668  validloss -2.29519±0.00000  bestvalidloss -2.46597  last_update 36\n",
      "train: iter 334  trainloss -2.18141  validloss -2.22209±0.00000  bestvalidloss -2.46597  last_update 37\n",
      "train: iter 335  trainloss -2.19332  validloss -2.34623±0.00000  bestvalidloss -2.46597  last_update 38\n",
      "train: iter 336  trainloss -2.15490  validloss -2.34016±0.00000  bestvalidloss -2.46597  last_update 39\n",
      "train: iter 337  trainloss -2.16899  validloss -2.31260±0.00000  bestvalidloss -2.46597  last_update 40\n",
      "train: iter 338  trainloss -2.22229  validloss -2.22299±0.00000  bestvalidloss -2.46597  last_update 41\n",
      "train: iter 339  trainloss -2.14929  validloss -2.25419±0.00000  bestvalidloss -2.46597  last_update 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 340  trainloss -2.16103  validloss -2.35887±0.00000  bestvalidloss -2.46597  last_update 43\n",
      "train: iter 341  trainloss -2.09736  validloss -2.25708±0.00000  bestvalidloss -2.46597  last_update 44\n",
      "train: iter 342  trainloss -2.16951  validloss -2.31907±0.00000  bestvalidloss -2.46597  last_update 45\n",
      "train: iter 343  trainloss -2.18963  validloss -2.41574±0.00000  bestvalidloss -2.46597  last_update 46\n",
      "train: iter 344  trainloss -2.20591  validloss -2.26133±0.00000  bestvalidloss -2.46597  last_update 47\n",
      "train: iter 345  trainloss -2.14442  validloss -2.32667±0.00000  bestvalidloss -2.46597  last_update 48\n",
      "train: iter 346  trainloss -2.13646  validloss -2.25510±0.00000  bestvalidloss -2.46597  last_update 49\n",
      "train: iter 347  trainloss -2.17801  validloss -2.39641±0.00000  bestvalidloss -2.46597  last_update 50\n",
      "train: iter 348  trainloss -2.14133  validloss -2.26035±0.00000  bestvalidloss -2.46597  last_update 51\n",
      "train: iter 349  trainloss -2.14681  validloss -2.08555±0.00000  bestvalidloss -2.46597  last_update 52\n",
      "train: iter 350  trainloss -2.18165  validloss -2.27112±0.00000  bestvalidloss -2.46597  last_update 53\n",
      "train: iter 351  trainloss -2.13885  validloss -2.30956±0.00000  bestvalidloss -2.46597  last_update 54\n",
      "train: iter 352  trainloss -2.10133  validloss -2.25043±0.00000  bestvalidloss -2.46597  last_update 55\n",
      "train: iter 353  trainloss -2.05935  validloss -2.41434±0.00000  bestvalidloss -2.46597  last_update 56\n",
      "train: iter 354  trainloss -2.15322  validloss -2.39327±0.00000  bestvalidloss -2.46597  last_update 57\n",
      "train: iter 355  trainloss -2.19883  validloss -2.25365±0.00000  bestvalidloss -2.46597  last_update 58\n",
      "train: iter 356  trainloss -2.13110  validloss -2.35685±0.00000  bestvalidloss -2.46597  last_update 59\n",
      "train: iter 357  trainloss -2.09984  validloss -2.28263±0.00000  bestvalidloss -2.46597  last_update 60\n",
      "train: iter 358  trainloss -2.12273  validloss -2.25002±0.00000  bestvalidloss -2.46597  last_update 61\n",
      "train: iter 359  trainloss -2.10267  validloss -2.33343±0.00000  bestvalidloss -2.46597  last_update 62\n",
      "train: iter 360  trainloss -2.25278  validloss -2.39583±0.00000  bestvalidloss -2.46597  last_update 63\n",
      "train: iter 361  trainloss -2.18419  validloss -2.21700±0.00000  bestvalidloss -2.46597  last_update 64\n",
      "train: iter 362  trainloss -2.01183  validloss -2.39516±0.00000  bestvalidloss -2.46597  last_update 65\n",
      "train: iter 363  trainloss -2.11669  validloss -2.35295±0.00000  bestvalidloss -2.46597  last_update 66\n",
      "train: iter 364  trainloss -2.15003  validloss -2.34471±0.00000  bestvalidloss -2.46597  last_update 67\n",
      "train: iter 365  trainloss -2.17450  validloss -2.26356±0.00000  bestvalidloss -2.46597  last_update 68\n",
      "train: iter 366  trainloss -2.05828  validloss -2.25672±0.00000  bestvalidloss -2.46597  last_update 69\n",
      "train: iter 367  trainloss -2.22191  validloss -2.28023±0.00000  bestvalidloss -2.46597  last_update 70\n",
      "train: iter 368  trainloss -2.17143  validloss -2.33765±0.00000  bestvalidloss -2.46597  last_update 71\n",
      "train: iter 369  trainloss -2.10872  validloss -2.29909±0.00000  bestvalidloss -2.46597  last_update 72\n",
      "train: iter 370  trainloss -2.13914  validloss -2.30518±0.00000  bestvalidloss -2.46597  last_update 73\n",
      "train: iter 371  trainloss -2.13844  validloss -2.14046±0.00000  bestvalidloss -2.46597  last_update 74\n",
      "train: iter 372  trainloss -2.16597  validloss -2.24962±0.00000  bestvalidloss -2.46597  last_update 75\n",
      "train: iter 373  trainloss -2.11513  validloss -2.39134±0.00000  bestvalidloss -2.46597  last_update 76\n",
      "train: iter 374  trainloss -2.14117  validloss -2.38080±0.00000  bestvalidloss -2.46597  last_update 77\n",
      "train: iter 375  trainloss -2.18028  validloss -2.39752±0.00000  bestvalidloss -2.46597  last_update 78\n",
      "train: iter 376  trainloss -2.17391  validloss -2.26719±0.00000  bestvalidloss -2.46597  last_update 79\n",
      "train: iter 377  trainloss -2.16296  validloss -2.31263±0.00000  bestvalidloss -2.46597  last_update 80\n",
      "train: iter 378  trainloss -2.15714  validloss -2.31026±0.00000  bestvalidloss -2.46597  last_update 81\n",
      "train: iter 379  trainloss -2.15770  validloss -2.40032±0.00000  bestvalidloss -2.46597  last_update 82\n",
      "train: iter 380  trainloss -2.19748  validloss -2.25456±0.00000  bestvalidloss -2.46597  last_update 83\n",
      "train: iter 381  trainloss -2.10836  validloss -2.39344±0.00000  bestvalidloss -2.46597  last_update 84\n",
      "train: iter 382  trainloss -2.10310  validloss -2.35194±0.00000  bestvalidloss -2.46597  last_update 85\n",
      "train: iter 383  trainloss -2.05203  validloss -2.38318±0.00000  bestvalidloss -2.46597  last_update 86\n",
      "train: iter 384  trainloss -2.17264  validloss -2.22767±0.00000  bestvalidloss -2.46597  last_update 87\n",
      "train: iter 385  trainloss -2.10656  validloss -2.25721±0.00000  bestvalidloss -2.46597  last_update 88\n",
      "train: iter 386  trainloss -2.10473  validloss -2.20573±0.00000  bestvalidloss -2.46597  last_update 89\n",
      "train: iter 387  trainloss -2.09220  validloss -2.26863±0.00000  bestvalidloss -2.46597  last_update 90\n",
      "train: iter 388  trainloss -2.19383  validloss -2.27356±0.00000  bestvalidloss -2.46597  last_update 91\n",
      "train: iter 389  trainloss -2.15233  validloss -2.19537±0.00000  bestvalidloss -2.46597  last_update 92\n",
      "train: iter 390  trainloss -2.02352  validloss -2.29904±0.00000  bestvalidloss -2.46597  last_update 93\n",
      "train: iter 391  trainloss -2.13248  validloss -2.31416±0.00000  bestvalidloss -2.46597  last_update 94\n",
      "train: iter 392  trainloss -2.16924  validloss -2.31937±0.00000  bestvalidloss -2.46597  last_update 95\n",
      "train: iter 393  trainloss -2.20075  validloss -2.30475±0.00000  bestvalidloss -2.46597  last_update 96\n",
      "train: iter 394  trainloss -2.09885  validloss -2.34978±0.00000  bestvalidloss -2.46597  last_update 97\n",
      "train: iter 395  trainloss -2.09695  validloss -2.21908±0.00000  bestvalidloss -2.46597  last_update 98\n",
      "train: iter 396  trainloss -2.19995  validloss -2.33036±0.00000  bestvalidloss -2.46597  last_update 99\n",
      "train: iter 397  trainloss -2.16314  validloss -2.24673±0.00000  bestvalidloss -2.46597  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.5908, -2.6323, -5.5467, -4.4183], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 68.84001  validloss 73.12857±0.00000  bestvalidloss 73.12857  last_update 0\n",
      "train: iter 1  trainloss 48.91132  validloss 58.48966±0.00000  bestvalidloss 58.48966  last_update 0\n",
      "train: iter 2  trainloss 31.93014  validloss 38.99240±0.00000  bestvalidloss 38.99240  last_update 0\n",
      "train: iter 3  trainloss 22.84652  validloss 27.09224±0.00000  bestvalidloss 27.09224  last_update 0\n",
      "train: iter 4  trainloss 17.46308  validloss 20.83030±0.00000  bestvalidloss 20.83030  last_update 0\n",
      "train: iter 5  trainloss 13.86371  validloss 16.88943±0.00000  bestvalidloss 16.88943  last_update 0\n",
      "train: iter 6  trainloss 11.42465  validloss 14.29758±0.00000  bestvalidloss 14.29758  last_update 0\n",
      "train: iter 7  trainloss 9.71676  validloss 12.49165±0.00000  bestvalidloss 12.49165  last_update 0\n",
      "train: iter 8  trainloss 8.52993  validloss 11.41335±0.00000  bestvalidloss 11.41335  last_update 0\n",
      "train: iter 9  trainloss 7.67736  validloss 10.65209±0.00000  bestvalidloss 10.65209  last_update 0\n",
      "train: iter 10  trainloss 7.08716  validloss 10.00287±0.00000  bestvalidloss 10.00287  last_update 0\n",
      "train: iter 11  trainloss 6.68077  validloss 9.64267±0.00000  bestvalidloss 9.64267  last_update 0\n",
      "train: iter 12  trainloss 6.38291  validloss 9.32181±0.00000  bestvalidloss 9.32181  last_update 0\n",
      "train: iter 13  trainloss 6.09894  validloss 8.92895±0.00000  bestvalidloss 8.92895  last_update 0\n",
      "train: iter 14  trainloss 5.81768  validloss 8.52843±0.00000  bestvalidloss 8.52843  last_update 0\n",
      "train: iter 15  trainloss 5.59190  validloss 8.00664±0.00000  bestvalidloss 8.00664  last_update 0\n",
      "train: iter 16  trainloss 5.36612  validloss 7.48206±0.00000  bestvalidloss 7.48206  last_update 0\n",
      "train: iter 17  trainloss 5.22727  validloss 7.13417±0.00000  bestvalidloss 7.13417  last_update 0\n",
      "train: iter 18  trainloss 5.07690  validloss 6.92778±0.00000  bestvalidloss 6.92778  last_update 0\n",
      "train: iter 19  trainloss 4.98613  validloss 6.80005±0.00000  bestvalidloss 6.80005  last_update 0\n",
      "train: iter 20  trainloss 4.86421  validloss 6.48259±0.00000  bestvalidloss 6.48259  last_update 0\n",
      "train: iter 21  trainloss 4.75141  validloss 6.41219±0.00000  bestvalidloss 6.41219  last_update 0\n",
      "train: iter 22  trainloss 4.63551  validloss 6.24113±0.00000  bestvalidloss 6.24113  last_update 0\n",
      "train: iter 23  trainloss 4.53535  validloss 6.16730±0.00000  bestvalidloss 6.16730  last_update 0\n",
      "train: iter 24  trainloss 4.48954  validloss 6.17097±0.00000  bestvalidloss 6.16730  last_update 1\n",
      "train: iter 25  trainloss 4.38117  validloss 5.89353±0.00000  bestvalidloss 5.89353  last_update 0\n",
      "train: iter 26  trainloss 4.32088  validloss 5.93856±0.00000  bestvalidloss 5.89353  last_update 1\n",
      "train: iter 27  trainloss 4.22301  validloss 5.85465±0.00000  bestvalidloss 5.85465  last_update 0\n",
      "train: iter 28  trainloss 4.20140  validloss 5.84453±0.00000  bestvalidloss 5.84453  last_update 0\n",
      "train: iter 29  trainloss 4.10215  validloss 5.64042±0.00000  bestvalidloss 5.64042  last_update 0\n",
      "train: iter 30  trainloss 4.05553  validloss 5.65166±0.00000  bestvalidloss 5.64042  last_update 1\n",
      "train: iter 31  trainloss 4.01183  validloss 5.57683±0.00000  bestvalidloss 5.57683  last_update 0\n",
      "train: iter 32  trainloss 3.97599  validloss 5.56512±0.00000  bestvalidloss 5.56512  last_update 0\n",
      "train: iter 33  trainloss 3.94374  validloss 5.45851±0.00000  bestvalidloss 5.45851  last_update 0\n",
      "train: iter 34  trainloss 3.91227  validloss 5.48516±0.00000  bestvalidloss 5.45851  last_update 1\n",
      "train: iter 35  trainloss 3.89835  validloss 5.41973±0.00000  bestvalidloss 5.41973  last_update 0\n",
      "train: iter 36  trainloss 3.89414  validloss 5.55567±0.00000  bestvalidloss 5.41973  last_update 1\n",
      "train: iter 37  trainloss 3.83640  validloss 5.32659±0.00000  bestvalidloss 5.32659  last_update 0\n",
      "train: iter 38  trainloss 3.84036  validloss 5.36222±0.00000  bestvalidloss 5.32659  last_update 1\n",
      "train: iter 39  trainloss 3.81694  validloss 5.20544±0.00000  bestvalidloss 5.20544  last_update 0\n",
      "train: iter 40  trainloss 3.79482  validloss 5.31842±0.00000  bestvalidloss 5.20544  last_update 1\n",
      "train: iter 41  trainloss 3.76538  validloss 5.23455±0.00000  bestvalidloss 5.20544  last_update 2\n",
      "train: iter 42  trainloss 3.74284  validloss 5.35085±0.00000  bestvalidloss 5.20544  last_update 3\n",
      "train: iter 43  trainloss 3.78530  validloss 5.11671±0.00000  bestvalidloss 5.11671  last_update 0\n",
      "train: iter 44  trainloss 3.75129  validloss 5.23271±0.00000  bestvalidloss 5.11671  last_update 1\n",
      "train: iter 45  trainloss 3.74600  validloss 5.11772±0.00000  bestvalidloss 5.11671  last_update 2\n",
      "train: iter 46  trainloss 3.73378  validloss 5.15615±0.00000  bestvalidloss 5.11671  last_update 3\n",
      "train: iter 47  trainloss 3.71993  validloss 5.13557±0.00000  bestvalidloss 5.11671  last_update 4\n",
      "train: iter 48  trainloss 3.68572  validloss 5.18451±0.00000  bestvalidloss 5.11671  last_update 5\n",
      "train: iter 49  trainloss 3.69329  validloss 5.15544±0.00000  bestvalidloss 5.11671  last_update 6\n",
      "train: iter 50  trainloss 3.66833  validloss 5.13246±0.00000  bestvalidloss 5.11671  last_update 7\n",
      "train: iter 51  trainloss 3.64968  validloss 5.05023±0.00000  bestvalidloss 5.05023  last_update 0\n",
      "train: iter 52  trainloss 3.64614  validloss 5.07659±0.00000  bestvalidloss 5.05023  last_update 1\n",
      "train: iter 53  trainloss 3.57902  validloss 5.04989±0.00000  bestvalidloss 5.04989  last_update 0\n",
      "train: iter 54  trainloss 3.62326  validloss 5.04339±0.00000  bestvalidloss 5.04339  last_update 0\n",
      "train: iter 55  trainloss 3.58219  validloss 5.00090±0.00000  bestvalidloss 5.00090  last_update 0\n",
      "train: iter 56  trainloss 3.57554  validloss 4.92461±0.00000  bestvalidloss 4.92461  last_update 0\n",
      "train: iter 57  trainloss 3.54192  validloss 4.97626±0.00000  bestvalidloss 4.92461  last_update 1\n",
      "train: iter 58  trainloss 3.53845  validloss 5.04323±0.00000  bestvalidloss 4.92461  last_update 2\n",
      "train: iter 59  trainloss 3.52536  validloss 5.06363±0.00000  bestvalidloss 4.92461  last_update 3\n",
      "train: iter 60  trainloss 3.52589  validloss 4.97044±0.00000  bestvalidloss 4.92461  last_update 4\n",
      "train: iter 61  trainloss 3.49504  validloss 4.98835±0.00000  bestvalidloss 4.92461  last_update 5\n",
      "train: iter 62  trainloss 3.48610  validloss 4.83935±0.00000  bestvalidloss 4.83935  last_update 0\n",
      "train: iter 63  trainloss 3.48454  validloss 4.88233±0.00000  bestvalidloss 4.83935  last_update 1\n",
      "train: iter 64  trainloss 3.50270  validloss 4.87352±0.00000  bestvalidloss 4.83935  last_update 2\n",
      "train: iter 65  trainloss 3.48756  validloss 4.93540±0.00000  bestvalidloss 4.83935  last_update 3\n",
      "train: iter 66  trainloss 3.45696  validloss 4.92410±0.00000  bestvalidloss 4.83935  last_update 4\n",
      "train: iter 67  trainloss 3.48140  validloss 4.88902±0.00000  bestvalidloss 4.83935  last_update 5\n",
      "train: iter 68  trainloss 3.48508  validloss 4.87930±0.00000  bestvalidloss 4.83935  last_update 6\n",
      "train: iter 69  trainloss 3.49128  validloss 4.79556±0.00000  bestvalidloss 4.79556  last_update 0\n",
      "train: iter 70  trainloss 3.48396  validloss 4.82345±0.00000  bestvalidloss 4.79556  last_update 1\n",
      "train: iter 71  trainloss 3.51857  validloss 4.81563±0.00000  bestvalidloss 4.79556  last_update 2\n",
      "train: iter 72  trainloss 3.51805  validloss 4.84293±0.00000  bestvalidloss 4.79556  last_update 3\n",
      "train: iter 73  trainloss 3.48631  validloss 4.90585±0.00000  bestvalidloss 4.79556  last_update 4\n",
      "train: iter 74  trainloss 3.49756  validloss 4.87910±0.00000  bestvalidloss 4.79556  last_update 5\n",
      "train: iter 75  trainloss 3.44136  validloss 4.87383±0.00000  bestvalidloss 4.79556  last_update 6\n",
      "train: iter 76  trainloss 3.50935  validloss 4.89610±0.00000  bestvalidloss 4.79556  last_update 7\n",
      "train: iter 77  trainloss 3.47476  validloss 4.82348±0.00000  bestvalidloss 4.79556  last_update 8\n",
      "train: iter 78  trainloss 3.42868  validloss 4.71851±0.00000  bestvalidloss 4.71851  last_update 0\n",
      "train: iter 79  trainloss 3.47430  validloss 4.83919±0.00000  bestvalidloss 4.71851  last_update 1\n",
      "train: iter 80  trainloss 3.44637  validloss 4.85927±0.00000  bestvalidloss 4.71851  last_update 2\n",
      "train: iter 81  trainloss 3.45352  validloss 4.77371±0.00000  bestvalidloss 4.71851  last_update 3\n",
      "train: iter 82  trainloss 3.47538  validloss 4.79605±0.00000  bestvalidloss 4.71851  last_update 4\n",
      "train: iter 83  trainloss 3.44315  validloss 4.80580±0.00000  bestvalidloss 4.71851  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 3.43845  validloss 4.85068±0.00000  bestvalidloss 4.71851  last_update 6\n",
      "train: iter 85  trainloss 3.40992  validloss 4.76463±0.00000  bestvalidloss 4.71851  last_update 7\n",
      "train: iter 86  trainloss 3.41981  validloss 4.93738±0.00000  bestvalidloss 4.71851  last_update 8\n",
      "train: iter 87  trainloss 3.46072  validloss 4.85193±0.00000  bestvalidloss 4.71851  last_update 9\n",
      "train: iter 88  trainloss 3.44357  validloss 4.79661±0.00000  bestvalidloss 4.71851  last_update 10\n",
      "train: iter 89  trainloss 3.45620  validloss 4.91514±0.00000  bestvalidloss 4.71851  last_update 11\n",
      "train: iter 90  trainloss 3.42384  validloss 4.74351±0.00000  bestvalidloss 4.71851  last_update 12\n",
      "train: iter 91  trainloss 3.42089  validloss 4.71484±0.00000  bestvalidloss 4.71484  last_update 0\n",
      "train: iter 92  trainloss 3.43941  validloss 4.93919±0.00000  bestvalidloss 4.71484  last_update 1\n",
      "train: iter 93  trainloss 3.46616  validloss 4.76503±0.00000  bestvalidloss 4.71484  last_update 2\n",
      "train: iter 94  trainloss 3.43298  validloss 4.75331±0.00000  bestvalidloss 4.71484  last_update 3\n",
      "train: iter 95  trainloss 3.45888  validloss 4.74382±0.00000  bestvalidloss 4.71484  last_update 4\n",
      "train: iter 96  trainloss 3.42805  validloss 4.74090±0.00000  bestvalidloss 4.71484  last_update 5\n",
      "train: iter 97  trainloss 3.41361  validloss 4.71477±0.00000  bestvalidloss 4.71477  last_update 0\n",
      "train: iter 98  trainloss 3.41757  validloss 4.82063±0.00000  bestvalidloss 4.71477  last_update 1\n",
      "train: iter 99  trainloss 3.45302  validloss 4.73008±0.00000  bestvalidloss 4.71477  last_update 2\n",
      "train: iter 100  trainloss 3.39812  validloss 4.75960±0.00000  bestvalidloss 4.71477  last_update 3\n",
      "train: iter 101  trainloss 3.43429  validloss 4.90604±0.00000  bestvalidloss 4.71477  last_update 4\n",
      "train: iter 102  trainloss 3.44535  validloss 4.69506±0.00000  bestvalidloss 4.69506  last_update 0\n",
      "train: iter 103  trainloss 3.41128  validloss 4.74143±0.00000  bestvalidloss 4.69506  last_update 1\n",
      "train: iter 104  trainloss 3.41757  validloss 4.82195±0.00000  bestvalidloss 4.69506  last_update 2\n",
      "train: iter 105  trainloss 3.42579  validloss 4.71699±0.00000  bestvalidloss 4.69506  last_update 3\n",
      "train: iter 106  trainloss 3.41014  validloss 4.79981±0.00000  bestvalidloss 4.69506  last_update 4\n",
      "train: iter 107  trainloss 3.45252  validloss 4.80107±0.00000  bestvalidloss 4.69506  last_update 5\n",
      "train: iter 108  trainloss 3.42024  validloss 4.74881±0.00000  bestvalidloss 4.69506  last_update 6\n",
      "train: iter 109  trainloss 3.41359  validloss 4.80558±0.00000  bestvalidloss 4.69506  last_update 7\n",
      "train: iter 110  trainloss 3.44414  validloss 4.73973±0.00000  bestvalidloss 4.69506  last_update 8\n",
      "train: iter 111  trainloss 3.40041  validloss 4.76483±0.00000  bestvalidloss 4.69506  last_update 9\n",
      "train: iter 112  trainloss 3.40568  validloss 4.75033±0.00000  bestvalidloss 4.69506  last_update 10\n",
      "train: iter 113  trainloss 3.43082  validloss 4.74215±0.00000  bestvalidloss 4.69506  last_update 11\n",
      "train: iter 114  trainloss 3.45889  validloss 4.65454±0.00000  bestvalidloss 4.65454  last_update 0\n",
      "train: iter 115  trainloss 3.43370  validloss 4.64144±0.00000  bestvalidloss 4.64144  last_update 0\n",
      "train: iter 116  trainloss 3.43035  validloss 4.72758±0.00000  bestvalidloss 4.64144  last_update 1\n",
      "train: iter 117  trainloss 3.40524  validloss 4.74592±0.00000  bestvalidloss 4.64144  last_update 2\n",
      "train: iter 118  trainloss 3.40486  validloss 4.79115±0.00000  bestvalidloss 4.64144  last_update 3\n",
      "train: iter 119  trainloss 3.39080  validloss 4.67956±0.00000  bestvalidloss 4.64144  last_update 4\n",
      "train: iter 120  trainloss 3.40929  validloss 4.75799±0.00000  bestvalidloss 4.64144  last_update 5\n",
      "train: iter 121  trainloss 3.40627  validloss 4.70068±0.00000  bestvalidloss 4.64144  last_update 6\n",
      "train: iter 122  trainloss 3.38416  validloss 4.85658±0.00000  bestvalidloss 4.64144  last_update 7\n",
      "train: iter 123  trainloss 3.44957  validloss 4.75062±0.00000  bestvalidloss 4.64144  last_update 8\n",
      "train: iter 124  trainloss 3.37246  validloss 4.76866±0.00000  bestvalidloss 4.64144  last_update 9\n",
      "train: iter 125  trainloss 3.38920  validloss 4.68342±0.00000  bestvalidloss 4.64144  last_update 10\n",
      "train: iter 126  trainloss 3.40782  validloss 4.80108±0.00000  bestvalidloss 4.64144  last_update 11\n",
      "train: iter 127  trainloss 3.39389  validloss 4.73128±0.00000  bestvalidloss 4.64144  last_update 12\n",
      "train: iter 128  trainloss 3.36713  validloss 4.83110±0.00000  bestvalidloss 4.64144  last_update 13\n",
      "train: iter 129  trainloss 3.43925  validloss 4.73909±0.00000  bestvalidloss 4.64144  last_update 14\n",
      "train: iter 130  trainloss 3.39602  validloss 4.67715±0.00000  bestvalidloss 4.64144  last_update 15\n",
      "train: iter 131  trainloss 3.40825  validloss 4.77341±0.00000  bestvalidloss 4.64144  last_update 16\n",
      "train: iter 132  trainloss 3.40731  validloss 4.69465±0.00000  bestvalidloss 4.64144  last_update 17\n",
      "train: iter 133  trainloss 3.39024  validloss 4.70922±0.00000  bestvalidloss 4.64144  last_update 18\n",
      "train: iter 134  trainloss 3.38601  validloss 4.68899±0.00000  bestvalidloss 4.64144  last_update 19\n",
      "train: iter 135  trainloss 3.40083  validloss 4.95215±0.00000  bestvalidloss 4.64144  last_update 20\n",
      "train: iter 136  trainloss 3.39425  validloss 4.72131±0.00000  bestvalidloss 4.64144  last_update 21\n",
      "train: iter 137  trainloss 3.39018  validloss 4.69081±0.00000  bestvalidloss 4.64144  last_update 22\n",
      "train: iter 138  trainloss 3.39381  validloss 4.82347±0.00000  bestvalidloss 4.64144  last_update 23\n",
      "train: iter 139  trainloss 3.41389  validloss 4.82658±0.00000  bestvalidloss 4.64144  last_update 24\n",
      "train: iter 140  trainloss 3.39510  validloss 4.73833±0.00000  bestvalidloss 4.64144  last_update 25\n",
      "train: iter 141  trainloss 3.38746  validloss 4.74467±0.00000  bestvalidloss 4.64144  last_update 26\n",
      "train: iter 142  trainloss 3.38476  validloss 4.81273±0.00000  bestvalidloss 4.64144  last_update 27\n",
      "train: iter 143  trainloss 3.38805  validloss 4.67659±0.00000  bestvalidloss 4.64144  last_update 28\n",
      "train: iter 144  trainloss 3.38866  validloss 4.70575±0.00000  bestvalidloss 4.64144  last_update 29\n",
      "train: iter 145  trainloss 3.36578  validloss 4.66282±0.00000  bestvalidloss 4.64144  last_update 30\n",
      "train: iter 146  trainloss 3.39877  validloss 4.77024±0.00000  bestvalidloss 4.64144  last_update 31\n",
      "train: iter 147  trainloss 3.39051  validloss 4.77561±0.00000  bestvalidloss 4.64144  last_update 32\n",
      "train: iter 148  trainloss 3.37329  validloss 4.71981±0.00000  bestvalidloss 4.64144  last_update 33\n",
      "train: iter 149  trainloss 3.39083  validloss 4.66162±0.00000  bestvalidloss 4.64144  last_update 34\n",
      "train: iter 150  trainloss 3.38100  validloss 4.67934±0.00000  bestvalidloss 4.64144  last_update 35\n",
      "train: iter 151  trainloss 3.38724  validloss 4.59511±0.00000  bestvalidloss 4.59511  last_update 0\n",
      "train: iter 152  trainloss 3.39349  validloss 4.79410±0.00000  bestvalidloss 4.59511  last_update 1\n",
      "train: iter 153  trainloss 3.38208  validloss 4.75042±0.00000  bestvalidloss 4.59511  last_update 2\n",
      "train: iter 154  trainloss 3.39345  validloss 4.76147±0.00000  bestvalidloss 4.59511  last_update 3\n",
      "train: iter 155  trainloss 3.37661  validloss 4.71257±0.00000  bestvalidloss 4.59511  last_update 4\n",
      "train: iter 156  trainloss 3.38451  validloss 4.63592±0.00000  bestvalidloss 4.59511  last_update 5\n",
      "train: iter 157  trainloss 3.35912  validloss 4.74147±0.00000  bestvalidloss 4.59511  last_update 6\n",
      "train: iter 158  trainloss 3.34419  validloss 4.71545±0.00000  bestvalidloss 4.59511  last_update 7\n",
      "train: iter 159  trainloss 3.34481  validloss 4.79477±0.00000  bestvalidloss 4.59511  last_update 8\n",
      "train: iter 160  trainloss 3.38800  validloss 4.72740±0.00000  bestvalidloss 4.59511  last_update 9\n",
      "train: iter 161  trainloss 3.36769  validloss 4.67203±0.00000  bestvalidloss 4.59511  last_update 10\n",
      "train: iter 162  trainloss 3.37999  validloss 4.76901±0.00000  bestvalidloss 4.59511  last_update 11\n",
      "train: iter 163  trainloss 3.36679  validloss 4.64216±0.00000  bestvalidloss 4.59511  last_update 12\n",
      "train: iter 164  trainloss 3.36741  validloss 4.68014±0.00000  bestvalidloss 4.59511  last_update 13\n",
      "train: iter 165  trainloss 3.38636  validloss 4.74767±0.00000  bestvalidloss 4.59511  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 166  trainloss 3.36865  validloss 4.71688±0.00000  bestvalidloss 4.59511  last_update 15\n",
      "train: iter 167  trainloss 3.36138  validloss 4.68623±0.00000  bestvalidloss 4.59511  last_update 16\n",
      "train: iter 168  trainloss 3.36449  validloss 4.67932±0.00000  bestvalidloss 4.59511  last_update 17\n",
      "train: iter 169  trainloss 3.37121  validloss 4.81728±0.00000  bestvalidloss 4.59511  last_update 18\n",
      "train: iter 170  trainloss 3.37242  validloss 4.78142±0.00000  bestvalidloss 4.59511  last_update 19\n",
      "train: iter 171  trainloss 3.35781  validloss 4.73253±0.00000  bestvalidloss 4.59511  last_update 20\n",
      "train: iter 172  trainloss 3.38288  validloss 4.81599±0.00000  bestvalidloss 4.59511  last_update 21\n",
      "train: iter 173  trainloss 3.36955  validloss 4.73870±0.00000  bestvalidloss 4.59511  last_update 22\n",
      "train: iter 174  trainloss 3.35787  validloss 4.69746±0.00000  bestvalidloss 4.59511  last_update 23\n",
      "train: iter 175  trainloss 3.37480  validloss 4.80436±0.00000  bestvalidloss 4.59511  last_update 24\n",
      "train: iter 176  trainloss 3.37297  validloss 4.63424±0.00000  bestvalidloss 4.59511  last_update 25\n",
      "train: iter 177  trainloss 3.37481  validloss 4.77984±0.00000  bestvalidloss 4.59511  last_update 26\n",
      "train: iter 178  trainloss 3.37073  validloss 4.66131±0.00000  bestvalidloss 4.59511  last_update 27\n",
      "train: iter 179  trainloss 3.35831  validloss 4.72830±0.00000  bestvalidloss 4.59511  last_update 28\n",
      "train: iter 180  trainloss 3.36371  validloss 4.78511±0.00000  bestvalidloss 4.59511  last_update 29\n",
      "train: iter 181  trainloss 3.35699  validloss 4.69521±0.00000  bestvalidloss 4.59511  last_update 30\n",
      "train: iter 182  trainloss 3.38147  validloss 4.59601±0.00000  bestvalidloss 4.59511  last_update 31\n",
      "train: iter 183  trainloss 3.38840  validloss 4.66688±0.00000  bestvalidloss 4.59511  last_update 32\n",
      "train: iter 184  trainloss 3.39198  validloss 4.63372±0.00000  bestvalidloss 4.59511  last_update 33\n",
      "train: iter 185  trainloss 3.36144  validloss 4.63408±0.00000  bestvalidloss 4.59511  last_update 34\n",
      "train: iter 186  trainloss 3.38143  validloss 4.75026±0.00000  bestvalidloss 4.59511  last_update 35\n",
      "train: iter 187  trainloss 3.38583  validloss 4.71170±0.00000  bestvalidloss 4.59511  last_update 36\n",
      "train: iter 188  trainloss 3.34517  validloss 4.73430±0.00000  bestvalidloss 4.59511  last_update 37\n",
      "train: iter 189  trainloss 3.36078  validloss 4.64509±0.00000  bestvalidloss 4.59511  last_update 38\n",
      "train: iter 190  trainloss 3.35879  validloss 4.60687±0.00000  bestvalidloss 4.59511  last_update 39\n",
      "train: iter 191  trainloss 3.36811  validloss 4.66369±0.00000  bestvalidloss 4.59511  last_update 40\n",
      "train: iter 192  trainloss 3.37370  validloss 4.64370±0.00000  bestvalidloss 4.59511  last_update 41\n",
      "train: iter 193  trainloss 3.35875  validloss 4.77998±0.00000  bestvalidloss 4.59511  last_update 42\n",
      "train: iter 194  trainloss 3.35270  validloss 4.71608±0.00000  bestvalidloss 4.59511  last_update 43\n",
      "train: iter 195  trainloss 3.34904  validloss 4.75825±0.00000  bestvalidloss 4.59511  last_update 44\n",
      "train: iter 196  trainloss 3.35577  validloss 4.75794±0.00000  bestvalidloss 4.59511  last_update 45\n",
      "train: iter 197  trainloss 3.36454  validloss 4.63530±0.00000  bestvalidloss 4.59511  last_update 46\n",
      "train: iter 198  trainloss 3.37133  validloss 4.74058±0.00000  bestvalidloss 4.59511  last_update 47\n",
      "train: iter 199  trainloss 3.33866  validloss 4.73018±0.00000  bestvalidloss 4.59511  last_update 48\n",
      "train: iter 200  trainloss 3.37241  validloss 4.80986±0.00000  bestvalidloss 4.59511  last_update 49\n",
      "train: iter 201  trainloss 3.35867  validloss 4.73269±0.00000  bestvalidloss 4.59511  last_update 50\n",
      "train: iter 202  trainloss 3.34701  validloss 4.69778±0.00000  bestvalidloss 4.59511  last_update 51\n",
      "train: iter 203  trainloss 3.35108  validloss 4.77940±0.00000  bestvalidloss 4.59511  last_update 52\n",
      "train: iter 204  trainloss 3.37173  validloss 4.66071±0.00000  bestvalidloss 4.59511  last_update 53\n",
      "train: iter 205  trainloss 3.35739  validloss 4.68870±0.00000  bestvalidloss 4.59511  last_update 54\n",
      "train: iter 206  trainloss 3.39227  validloss 4.69198±0.00000  bestvalidloss 4.59511  last_update 55\n",
      "train: iter 207  trainloss 3.38887  validloss 4.73105±0.00000  bestvalidloss 4.59511  last_update 56\n",
      "train: iter 208  trainloss 3.35346  validloss 4.69371±0.00000  bestvalidloss 4.59511  last_update 57\n",
      "train: iter 209  trainloss 3.36989  validloss 4.69365±0.00000  bestvalidloss 4.59511  last_update 58\n",
      "train: iter 210  trainloss 3.34191  validloss 4.69175±0.00000  bestvalidloss 4.59511  last_update 59\n",
      "train: iter 211  trainloss 3.38767  validloss 4.65920±0.00000  bestvalidloss 4.59511  last_update 60\n",
      "train: iter 212  trainloss 3.35810  validloss 4.65753±0.00000  bestvalidloss 4.59511  last_update 61\n",
      "train: iter 213  trainloss 3.35399  validloss 4.74431±0.00000  bestvalidloss 4.59511  last_update 62\n",
      "train: iter 214  trainloss 3.35835  validloss 4.71331±0.00000  bestvalidloss 4.59511  last_update 63\n",
      "train: iter 215  trainloss 3.36629  validloss 4.68047±0.00000  bestvalidloss 4.59511  last_update 64\n",
      "train: iter 216  trainloss 3.33540  validloss 4.62387±0.00000  bestvalidloss 4.59511  last_update 65\n",
      "train: iter 217  trainloss 3.36706  validloss 4.77582±0.00000  bestvalidloss 4.59511  last_update 66\n",
      "train: iter 218  trainloss 3.36202  validloss 4.73845±0.00000  bestvalidloss 4.59511  last_update 67\n",
      "train: iter 219  trainloss 3.37795  validloss 4.67390±0.00000  bestvalidloss 4.59511  last_update 68\n",
      "train: iter 220  trainloss 3.36716  validloss 4.76706±0.00000  bestvalidloss 4.59511  last_update 69\n",
      "train: iter 221  trainloss 3.33362  validloss 4.74718±0.00000  bestvalidloss 4.59511  last_update 70\n",
      "train: iter 222  trainloss 3.34491  validloss 4.74450±0.00000  bestvalidloss 4.59511  last_update 71\n",
      "train: iter 223  trainloss 3.36496  validloss 4.80963±0.00000  bestvalidloss 4.59511  last_update 72\n",
      "train: iter 224  trainloss 3.34748  validloss 4.78700±0.00000  bestvalidloss 4.59511  last_update 73\n",
      "train: iter 225  trainloss 3.35283  validloss 4.72479±0.00000  bestvalidloss 4.59511  last_update 74\n",
      "train: iter 226  trainloss 3.35579  validloss 4.67240±0.00000  bestvalidloss 4.59511  last_update 75\n",
      "train: iter 227  trainloss 3.36507  validloss 4.73659±0.00000  bestvalidloss 4.59511  last_update 76\n",
      "train: iter 228  trainloss 3.33077  validloss 4.67838±0.00000  bestvalidloss 4.59511  last_update 77\n",
      "train: iter 229  trainloss 3.35276  validloss 4.95570±0.00000  bestvalidloss 4.59511  last_update 78\n",
      "train: iter 230  trainloss 3.37094  validloss 4.70520±0.00000  bestvalidloss 4.59511  last_update 79\n",
      "train: iter 231  trainloss 3.34816  validloss 4.85867±0.00000  bestvalidloss 4.59511  last_update 80\n",
      "train: iter 232  trainloss 3.34300  validloss 4.65460±0.00000  bestvalidloss 4.59511  last_update 81\n",
      "train: iter 233  trainloss 3.36086  validloss 4.77689±0.00000  bestvalidloss 4.59511  last_update 82\n",
      "train: iter 234  trainloss 3.34630  validloss 4.73328±0.00000  bestvalidloss 4.59511  last_update 83\n",
      "train: iter 235  trainloss 3.34199  validloss 4.71839±0.00000  bestvalidloss 4.59511  last_update 84\n",
      "train: iter 236  trainloss 3.33204  validloss 4.80737±0.00000  bestvalidloss 4.59511  last_update 85\n",
      "train: iter 237  trainloss 3.33675  validloss 4.81380±0.00000  bestvalidloss 4.59511  last_update 86\n",
      "train: iter 238  trainloss 3.34079  validloss 4.67078±0.00000  bestvalidloss 4.59511  last_update 87\n",
      "train: iter 239  trainloss 3.34780  validloss 4.74297±0.00000  bestvalidloss 4.59511  last_update 88\n",
      "train: iter 240  trainloss 3.34413  validloss 4.72531±0.00000  bestvalidloss 4.59511  last_update 89\n",
      "train: iter 241  trainloss 3.33580  validloss 4.72657±0.00000  bestvalidloss 4.59511  last_update 90\n",
      "train: iter 242  trainloss 3.33524  validloss 4.80201±0.00000  bestvalidloss 4.59511  last_update 91\n",
      "train: iter 243  trainloss 3.35368  validloss 4.71727±0.00000  bestvalidloss 4.59511  last_update 92\n",
      "train: iter 244  trainloss 3.34916  validloss 4.68392±0.00000  bestvalidloss 4.59511  last_update 93\n",
      "train: iter 245  trainloss 3.31758  validloss 4.74939±0.00000  bestvalidloss 4.59511  last_update 94\n",
      "train: iter 246  trainloss 3.36115  validloss 4.80801±0.00000  bestvalidloss 4.59511  last_update 95\n",
      "train: iter 247  trainloss 3.33118  validloss 4.84305±0.00000  bestvalidloss 4.59511  last_update 96\n",
      "train: iter 248  trainloss 3.33756  validloss 4.67627±0.00000  bestvalidloss 4.59511  last_update 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 249  trainloss 3.32894  validloss 4.71952±0.00000  bestvalidloss 4.59511  last_update 98\n",
      "train: iter 250  trainloss 3.33019  validloss 4.82243±0.00000  bestvalidloss 4.59511  last_update 99\n",
      "train: iter 251  trainloss 3.34715  validloss 4.75480±0.00000  bestvalidloss 4.59511  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-11.0065)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-2.3922)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01371343466575043\n",
      "tensor([-1.3513])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
