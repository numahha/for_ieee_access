{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(2565.2026)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 48\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 764.61167  validloss 1621.20257±0.00000  bestvalidloss 1621.20257  last_update 0\n",
      "train: iter 1  trainloss 388.33119  validloss 1805.66724±0.00000  bestvalidloss 1621.20257  last_update 1\n",
      "train: iter 2  trainloss 138.66847  validloss 1754.83935±0.00000  bestvalidloss 1621.20257  last_update 2\n",
      "train: iter 3  trainloss -101.58524  validloss 2342.06739±0.00000  bestvalidloss 1621.20257  last_update 3\n",
      "train: iter 4  trainloss -298.67708  validloss 4364.44851±0.00000  bestvalidloss 1621.20257  last_update 4\n",
      "train: iter 5  trainloss -432.53903  validloss 2239.49141±0.00000  bestvalidloss 1621.20257  last_update 5\n",
      "train: iter 6  trainloss -507.06162  validloss 2462.71734±0.00000  bestvalidloss 1621.20257  last_update 6\n",
      "train: iter 7  trainloss -543.89117  validloss 3840.69872±0.00000  bestvalidloss 1621.20257  last_update 7\n",
      "train: iter 8  trainloss -690.46240  validloss 2548.48370±0.00000  bestvalidloss 1621.20257  last_update 8\n",
      "train: iter 9  trainloss -774.32268  validloss 3482.72611±0.00000  bestvalidloss 1621.20257  last_update 9\n",
      "train: iter 10  trainloss -723.66819  validloss 3729.68817±0.00000  bestvalidloss 1621.20257  last_update 10\n",
      "train: iter 11  trainloss -854.25452  validloss 3002.57630±0.00000  bestvalidloss 1621.20257  last_update 11\n",
      "train: iter 12  trainloss -924.33726  validloss 3086.69740±0.00000  bestvalidloss 1621.20257  last_update 12\n",
      "train: iter 13  trainloss -707.37186  validloss 2516.68465±0.00000  bestvalidloss 1621.20257  last_update 13\n",
      "train: iter 14  trainloss -810.39070  validloss 2320.07803±0.00000  bestvalidloss 1621.20257  last_update 14\n",
      "train: iter 15  trainloss -988.43191  validloss 1623.15743±0.00000  bestvalidloss 1621.20257  last_update 15\n",
      "train: iter 16  trainloss -1070.37686  validloss 2319.60574±0.00000  bestvalidloss 1621.20257  last_update 16\n",
      "train: iter 17  trainloss -974.39743  validloss 961.15077±0.00000  bestvalidloss 961.15077  last_update 0\n",
      "train: iter 18  trainloss -1055.44444  validloss 1234.21108±0.00000  bestvalidloss 961.15077  last_update 1\n",
      "train: iter 19  trainloss -1098.89280  validloss 671.45169±0.00000  bestvalidloss 671.45169  last_update 0\n",
      "train: iter 20  trainloss -1049.06845  validloss 381.49746±0.00000  bestvalidloss 381.49746  last_update 0\n",
      "train: iter 21  trainloss -1164.40649  validloss 462.03733±0.00000  bestvalidloss 381.49746  last_update 1\n",
      "train: iter 22  trainloss -1176.77216  validloss 749.65590±0.00000  bestvalidloss 381.49746  last_update 2\n",
      "train: iter 23  trainloss -1195.46410  validloss 1060.63192±0.00000  bestvalidloss 381.49746  last_update 3\n",
      "train: iter 24  trainloss -1120.98991  validloss 1772.00380±0.00000  bestvalidloss 381.49746  last_update 4\n",
      "train: iter 25  trainloss -1155.45402  validloss 828.51730±0.00000  bestvalidloss 381.49746  last_update 5\n",
      "train: iter 26  trainloss -1207.42019  validloss 746.14176±0.00000  bestvalidloss 381.49746  last_update 6\n",
      "train: iter 27  trainloss -1314.12469  validloss 1079.87474±0.00000  bestvalidloss 381.49746  last_update 7\n",
      "train: iter 28  trainloss -1283.73421  validloss 312.25189±0.00000  bestvalidloss 312.25189  last_update 0\n",
      "train: iter 29  trainloss -1337.38320  validloss 1105.29285±0.00000  bestvalidloss 312.25189  last_update 1\n",
      "train: iter 30  trainloss -1159.04048  validloss 1543.26066±0.00000  bestvalidloss 312.25189  last_update 2\n",
      "train: iter 31  trainloss -1280.81185  validloss 266.28638±0.00000  bestvalidloss 266.28638  last_update 0\n",
      "train: iter 32  trainloss -1295.45641  validloss 917.76890±0.00000  bestvalidloss 266.28638  last_update 1\n",
      "train: iter 33  trainloss -1358.33699  validloss 282.10278±0.00000  bestvalidloss 266.28638  last_update 2\n",
      "train: iter 34  trainloss -1354.22831  validloss 408.88654±0.00000  bestvalidloss 266.28638  last_update 3\n",
      "train: iter 35  trainloss -1231.83814  validloss 902.63689±0.00000  bestvalidloss 266.28638  last_update 4\n",
      "train: iter 36  trainloss -1318.08128  validloss 1373.80120±0.00000  bestvalidloss 266.28638  last_update 5\n",
      "train: iter 37  trainloss -1238.33561  validloss 428.47238±0.00000  bestvalidloss 266.28638  last_update 6\n",
      "train: iter 38  trainloss -1402.93124  validloss 929.31107±0.00000  bestvalidloss 266.28638  last_update 7\n",
      "train: iter 39  trainloss -1420.85546  validloss 494.31935±0.00000  bestvalidloss 266.28638  last_update 8\n",
      "train: iter 40  trainloss -1404.72347  validloss 593.88598±0.00000  bestvalidloss 266.28638  last_update 9\n",
      "train: iter 41  trainloss -1394.88119  validloss 54.99630±0.00000  bestvalidloss 54.99630  last_update 0\n",
      "train: iter 42  trainloss -1435.21221  validloss 341.34388±0.00000  bestvalidloss 54.99630  last_update 1\n",
      "train: iter 43  trainloss -1322.66890  validloss 369.94988±0.00000  bestvalidloss 54.99630  last_update 2\n",
      "train: iter 44  trainloss -1456.33462  validloss 215.78568±0.00000  bestvalidloss 54.99630  last_update 3\n",
      "train: iter 45  trainloss -1446.45236  validloss 494.38760±0.00000  bestvalidloss 54.99630  last_update 4\n",
      "train: iter 46  trainloss -1469.79357  validloss 67.25772±0.00000  bestvalidloss 54.99630  last_update 5\n",
      "train: iter 47  trainloss -1462.19473  validloss 264.54837±0.00000  bestvalidloss 54.99630  last_update 6\n",
      "train: iter 48  trainloss -1385.04594  validloss 241.40641±0.00000  bestvalidloss 54.99630  last_update 7\n",
      "train: iter 49  trainloss -1411.84303  validloss -194.92171±0.00000  bestvalidloss -194.92171  last_update 0\n",
      "train: iter 50  trainloss -1466.11905  validloss -55.67530±0.00000  bestvalidloss -194.92171  last_update 1\n",
      "train: iter 51  trainloss -1430.86042  validloss -6.26960±0.00000  bestvalidloss -194.92171  last_update 2\n",
      "train: iter 52  trainloss -1405.18269  validloss 110.86347±0.00000  bestvalidloss -194.92171  last_update 3\n",
      "train: iter 53  trainloss -1193.47297  validloss -46.07372±0.00000  bestvalidloss -194.92171  last_update 4\n",
      "train: iter 54  trainloss -1386.70295  validloss -175.60393±0.00000  bestvalidloss -194.92171  last_update 5\n",
      "train: iter 55  trainloss -1475.73597  validloss -19.07163±0.00000  bestvalidloss -194.92171  last_update 6\n",
      "train: iter 56  trainloss -1451.56369  validloss 82.19812±0.00000  bestvalidloss -194.92171  last_update 7\n",
      "train: iter 57  trainloss -1480.01888  validloss 252.00752±0.00000  bestvalidloss -194.92171  last_update 8\n",
      "train: iter 58  trainloss -1284.72675  validloss 154.52086±0.00000  bestvalidloss -194.92171  last_update 9\n",
      "train: iter 59  trainloss -1410.29356  validloss 446.40290±0.00000  bestvalidloss -194.92171  last_update 10\n",
      "train: iter 60  trainloss -1472.64152  validloss -136.20219±0.00000  bestvalidloss -194.92171  last_update 11\n",
      "train: iter 61  trainloss -1108.47563  validloss 215.82381±0.00000  bestvalidloss -194.92171  last_update 12\n",
      "train: iter 62  trainloss -1430.52427  validloss 579.44138±0.00000  bestvalidloss -194.92171  last_update 13\n",
      "train: iter 63  trainloss -1484.82229  validloss -52.69706±0.00000  bestvalidloss -194.92171  last_update 14\n",
      "train: iter 64  trainloss -1480.20775  validloss 153.44462±0.00000  bestvalidloss -194.92171  last_update 15\n",
      "train: iter 65  trainloss -1503.23726  validloss -57.94786±0.00000  bestvalidloss -194.92171  last_update 16\n",
      "train: iter 66  trainloss -1501.56047  validloss 33.71300±0.00000  bestvalidloss -194.92171  last_update 17\n",
      "train: iter 67  trainloss -1484.54680  validloss -137.82251±0.00000  bestvalidloss -194.92171  last_update 18\n",
      "train: iter 68  trainloss -1500.16432  validloss -423.58657±0.00000  bestvalidloss -423.58657  last_update 0\n",
      "train: iter 69  trainloss -1536.74354  validloss -358.53064±0.00000  bestvalidloss -423.58657  last_update 1\n",
      "train: iter 70  trainloss -1540.86998  validloss -375.42505±0.00000  bestvalidloss -423.58657  last_update 2\n",
      "train: iter 71  trainloss -1557.56245  validloss -365.69658±0.00000  bestvalidloss -423.58657  last_update 3\n",
      "train: iter 72  trainloss -1435.47022  validloss 395.94858±0.00000  bestvalidloss -423.58657  last_update 4\n",
      "train: iter 73  trainloss -1448.95253  validloss -410.65440±0.00000  bestvalidloss -423.58657  last_update 5\n",
      "train: iter 74  trainloss -1493.87341  validloss -300.46711±0.00000  bestvalidloss -423.58657  last_update 6\n",
      "train: iter 75  trainloss -1533.95000  validloss -260.08267±0.00000  bestvalidloss -423.58657  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 76  trainloss -1567.60822  validloss -47.11537±0.00000  bestvalidloss -423.58657  last_update 8\n",
      "train: iter 77  trainloss -1522.31866  validloss -74.28592±0.00000  bestvalidloss -423.58657  last_update 9\n",
      "train: iter 78  trainloss -1483.46124  validloss -587.41999±0.00000  bestvalidloss -587.41999  last_update 0\n",
      "train: iter 79  trainloss -1576.54407  validloss -661.07101±0.00000  bestvalidloss -661.07101  last_update 0\n",
      "train: iter 80  trainloss -1567.97786  validloss -320.84480±0.00000  bestvalidloss -661.07101  last_update 1\n",
      "train: iter 81  trainloss -1578.66092  validloss -357.21597±0.00000  bestvalidloss -661.07101  last_update 2\n",
      "train: iter 82  trainloss -1494.11006  validloss -477.48973±0.00000  bestvalidloss -661.07101  last_update 3\n",
      "train: iter 83  trainloss -1593.90808  validloss -669.93502±0.00000  bestvalidloss -669.93502  last_update 0\n",
      "train: iter 84  trainloss -1618.52258  validloss -670.43895±0.00000  bestvalidloss -670.43895  last_update 0\n",
      "train: iter 85  trainloss -1620.45344  validloss -740.33007±0.00000  bestvalidloss -740.33007  last_update 0\n",
      "train: iter 86  trainloss -1410.94094  validloss 56.35282±0.00000  bestvalidloss -740.33007  last_update 1\n",
      "train: iter 87  trainloss -1581.86738  validloss -817.11694±0.00000  bestvalidloss -817.11694  last_update 0\n",
      "train: iter 88  trainloss -1598.99014  validloss -847.68308±0.00000  bestvalidloss -847.68308  last_update 0\n",
      "train: iter 89  trainloss -1642.55433  validloss -1027.86739±0.00000  bestvalidloss -1027.86739  last_update 0\n",
      "train: iter 90  trainloss -1566.76502  validloss -608.36578±0.00000  bestvalidloss -1027.86739  last_update 1\n",
      "train: iter 91  trainloss -1654.33144  validloss -1071.51175±0.00000  bestvalidloss -1071.51175  last_update 0\n",
      "train: iter 92  trainloss -1536.79962  validloss -1071.93466±0.00000  bestvalidloss -1071.93466  last_update 0\n",
      "train: iter 93  trainloss -1638.70663  validloss -762.75656±0.00000  bestvalidloss -1071.93466  last_update 1\n",
      "train: iter 94  trainloss -1658.66057  validloss -1059.34716±0.00000  bestvalidloss -1071.93466  last_update 2\n",
      "train: iter 95  trainloss -1447.25549  validloss -568.49714±0.00000  bestvalidloss -1071.93466  last_update 3\n",
      "train: iter 96  trainloss -1653.16773  validloss -1069.38210±0.00000  bestvalidloss -1071.93466  last_update 4\n",
      "train: iter 97  trainloss -1665.87515  validloss -1178.08913±0.00000  bestvalidloss -1178.08913  last_update 0\n",
      "train: iter 98  trainloss -1616.53856  validloss -1058.01755±0.00000  bestvalidloss -1178.08913  last_update 1\n",
      "train: iter 99  trainloss -1650.74196  validloss -603.75393±0.00000  bestvalidloss -1178.08913  last_update 2\n",
      "train: iter 100  trainloss -1688.66728  validloss -1079.30521±0.00000  bestvalidloss -1178.08913  last_update 3\n",
      "train: iter 101  trainloss -1735.38262  validloss -1097.79130±0.00000  bestvalidloss -1178.08913  last_update 4\n",
      "train: iter 102  trainloss -1709.46668  validloss -1347.56904±0.00000  bestvalidloss -1347.56904  last_update 0\n",
      "train: iter 103  trainloss -1709.36281  validloss -1200.79774±0.00000  bestvalidloss -1347.56904  last_update 1\n",
      "train: iter 104  trainloss -1672.34926  validloss -871.01528±0.00000  bestvalidloss -1347.56904  last_update 2\n",
      "train: iter 105  trainloss -1733.56060  validloss -1300.63541±0.00000  bestvalidloss -1347.56904  last_update 3\n",
      "train: iter 106  trainloss -1744.85980  validloss -1363.79887±0.00000  bestvalidloss -1363.79887  last_update 0\n",
      "train: iter 107  trainloss -1756.61461  validloss -1203.22785±0.00000  bestvalidloss -1363.79887  last_update 1\n",
      "train: iter 108  trainloss -1692.13268  validloss -1168.50456±0.00000  bestvalidloss -1363.79887  last_update 2\n",
      "train: iter 109  trainloss -1734.18703  validloss -1360.99771±0.00000  bestvalidloss -1363.79887  last_update 3\n",
      "train: iter 110  trainloss -1702.09649  validloss -1196.75455±0.00000  bestvalidloss -1363.79887  last_update 4\n",
      "train: iter 111  trainloss -1736.22720  validloss -1387.33600±0.00000  bestvalidloss -1387.33600  last_update 0\n",
      "train: iter 112  trainloss -1499.22631  validloss -1081.72563±0.00000  bestvalidloss -1387.33600  last_update 1\n",
      "train: iter 113  trainloss -1644.23958  validloss -755.72457±0.00000  bestvalidloss -1387.33600  last_update 2\n",
      "train: iter 114  trainloss -1767.93845  validloss -1221.22984±0.00000  bestvalidloss -1387.33600  last_update 3\n",
      "train: iter 115  trainloss -1789.97207  validloss -1466.15319±0.00000  bestvalidloss -1466.15319  last_update 0\n",
      "train: iter 116  trainloss -1786.84035  validloss -1385.19497±0.00000  bestvalidloss -1466.15319  last_update 1\n",
      "train: iter 117  trainloss -1766.05411  validloss -1433.11933±0.00000  bestvalidloss -1466.15319  last_update 2\n",
      "train: iter 118  trainloss -1822.76201  validloss -1520.79466±0.00000  bestvalidloss -1520.79466  last_update 0\n",
      "train: iter 119  trainloss -1803.81300  validloss -1493.77469±0.00000  bestvalidloss -1520.79466  last_update 1\n",
      "train: iter 120  trainloss -1689.18790  validloss -1238.48512±0.00000  bestvalidloss -1520.79466  last_update 2\n",
      "train: iter 121  trainloss -1648.60654  validloss -1119.05697±0.00000  bestvalidloss -1520.79466  last_update 3\n",
      "train: iter 122  trainloss -1774.52326  validloss -1123.27747±0.00000  bestvalidloss -1520.79466  last_update 4\n",
      "train: iter 123  trainloss -1774.39474  validloss -1257.33318±0.00000  bestvalidloss -1520.79466  last_update 5\n",
      "train: iter 124  trainloss -1823.49047  validloss -1338.58846±0.00000  bestvalidloss -1520.79466  last_update 6\n",
      "train: iter 125  trainloss -1800.45255  validloss -1295.61996±0.00000  bestvalidloss -1520.79466  last_update 7\n",
      "train: iter 126  trainloss -1796.78975  validloss -1465.03685±0.00000  bestvalidloss -1520.79466  last_update 8\n",
      "train: iter 127  trainloss -1831.54517  validloss -1433.61496±0.00000  bestvalidloss -1520.79466  last_update 9\n",
      "train: iter 128  trainloss -1768.02121  validloss -1192.00325±0.00000  bestvalidloss -1520.79466  last_update 10\n",
      "train: iter 129  trainloss -1821.94198  validloss -1248.37038±0.00000  bestvalidloss -1520.79466  last_update 11\n",
      "train: iter 130  trainloss -1841.22564  validloss -1412.02916±0.00000  bestvalidloss -1520.79466  last_update 12\n",
      "train: iter 131  trainloss -1835.33510  validloss -1415.30049±0.00000  bestvalidloss -1520.79466  last_update 13\n",
      "train: iter 132  trainloss -1821.92231  validloss -1424.87553±0.00000  bestvalidloss -1520.79466  last_update 14\n",
      "train: iter 133  trainloss -1804.39933  validloss -1363.31445±0.00000  bestvalidloss -1520.79466  last_update 15\n",
      "train: iter 134  trainloss -1761.15628  validloss -1368.38125±0.00000  bestvalidloss -1520.79466  last_update 16\n",
      "train: iter 135  trainloss -1820.97441  validloss -1303.81562±0.00000  bestvalidloss -1520.79466  last_update 17\n",
      "train: iter 136  trainloss -1771.30239  validloss -1335.54389±0.00000  bestvalidloss -1520.79466  last_update 18\n",
      "train: iter 137  trainloss -1720.76012  validloss -1305.67920±0.00000  bestvalidloss -1520.79466  last_update 19\n",
      "train: iter 138  trainloss -1838.24366  validloss -1384.00085±0.00000  bestvalidloss -1520.79466  last_update 20\n",
      "train: iter 139  trainloss -1831.02091  validloss -1483.37085±0.00000  bestvalidloss -1520.79466  last_update 21\n",
      "train: iter 140  trainloss -1667.78230  validloss -1298.21848±0.00000  bestvalidloss -1520.79466  last_update 22\n",
      "train: iter 141  trainloss -1823.17924  validloss -1369.21102±0.00000  bestvalidloss -1520.79466  last_update 23\n",
      "train: iter 142  trainloss -1792.28221  validloss -1438.96699±0.00000  bestvalidloss -1520.79466  last_update 24\n",
      "train: iter 143  trainloss -1850.42825  validloss -1343.59060±0.00000  bestvalidloss -1520.79466  last_update 25\n",
      "train: iter 144  trainloss -1863.46721  validloss -1449.34406±0.00000  bestvalidloss -1520.79466  last_update 26\n",
      "train: iter 145  trainloss -1836.95821  validloss -1445.95099±0.00000  bestvalidloss -1520.79466  last_update 27\n",
      "train: iter 146  trainloss -1867.06170  validloss -1255.34522±0.00000  bestvalidloss -1520.79466  last_update 28\n",
      "train: iter 147  trainloss -1871.43325  validloss -1376.56339±0.00000  bestvalidloss -1520.79466  last_update 29\n",
      "train: iter 148  trainloss -1853.50960  validloss -1526.75634±0.00000  bestvalidloss -1526.75634  last_update 0\n",
      "train: iter 149  trainloss -1855.18364  validloss -1550.31496±0.00000  bestvalidloss -1550.31496  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 150  trainloss -1866.22767  validloss -1269.33158±0.00000  bestvalidloss -1550.31496  last_update 1\n",
      "train: iter 151  trainloss -1823.86468  validloss -1525.68290±0.00000  bestvalidloss -1550.31496  last_update 2\n",
      "train: iter 152  trainloss -1820.69199  validloss -1237.21331±0.00000  bestvalidloss -1550.31496  last_update 3\n",
      "train: iter 153  trainloss -1831.23297  validloss -1443.35555±0.00000  bestvalidloss -1550.31496  last_update 4\n",
      "train: iter 154  trainloss -1871.86594  validloss -1507.30544±0.00000  bestvalidloss -1550.31496  last_update 5\n",
      "train: iter 155  trainloss -1907.76316  validloss -1601.22940±0.00000  bestvalidloss -1601.22940  last_update 0\n",
      "train: iter 156  trainloss -1884.52187  validloss -1552.82515±0.00000  bestvalidloss -1601.22940  last_update 1\n",
      "train: iter 157  trainloss -1897.63482  validloss -1564.53286±0.00000  bestvalidloss -1601.22940  last_update 2\n",
      "train: iter 158  trainloss -1756.12153  validloss -1279.42524±0.00000  bestvalidloss -1601.22940  last_update 3\n",
      "train: iter 159  trainloss -1823.27915  validloss -1395.24015±0.00000  bestvalidloss -1601.22940  last_update 4\n",
      "train: iter 160  trainloss -1892.10394  validloss -1591.83121±0.00000  bestvalidloss -1601.22940  last_update 5\n",
      "train: iter 161  trainloss -1904.62360  validloss -1587.43793±0.00000  bestvalidloss -1601.22940  last_update 6\n",
      "train: iter 162  trainloss -1863.04904  validloss -1608.42083±0.00000  bestvalidloss -1608.42083  last_update 0\n",
      "train: iter 163  trainloss -1860.70973  validloss -1431.07627±0.00000  bestvalidloss -1608.42083  last_update 1\n",
      "train: iter 164  trainloss -1862.37820  validloss -1574.32217±0.00000  bestvalidloss -1608.42083  last_update 2\n",
      "train: iter 165  trainloss -1860.37979  validloss -1385.30739±0.00000  bestvalidloss -1608.42083  last_update 3\n",
      "train: iter 166  trainloss -1844.11351  validloss -1561.82277±0.00000  bestvalidloss -1608.42083  last_update 4\n",
      "train: iter 167  trainloss -1898.33786  validloss -1547.87617±0.00000  bestvalidloss -1608.42083  last_update 5\n",
      "train: iter 168  trainloss -1904.55907  validloss -1578.22894±0.00000  bestvalidloss -1608.42083  last_update 6\n",
      "train: iter 169  trainloss -1888.08921  validloss -1587.90326±0.00000  bestvalidloss -1608.42083  last_update 7\n",
      "train: iter 170  trainloss -1876.84919  validloss -1494.68273±0.00000  bestvalidloss -1608.42083  last_update 8\n",
      "train: iter 171  trainloss -1855.18327  validloss -971.46653±0.00000  bestvalidloss -1608.42083  last_update 9\n",
      "train: iter 172  trainloss -1886.52982  validloss -1467.10938±0.00000  bestvalidloss -1608.42083  last_update 10\n",
      "train: iter 173  trainloss -1730.01101  validloss -1372.27321±0.00000  bestvalidloss -1608.42083  last_update 11\n",
      "train: iter 174  trainloss -1906.29738  validloss -1302.25545±0.00000  bestvalidloss -1608.42083  last_update 12\n",
      "train: iter 175  trainloss -1924.54066  validloss -1499.60384±0.00000  bestvalidloss -1608.42083  last_update 13\n",
      "train: iter 176  trainloss -1900.34566  validloss -1703.43999±0.00000  bestvalidloss -1703.43999  last_update 0\n",
      "train: iter 177  trainloss -1882.77302  validloss -1568.06222±0.00000  bestvalidloss -1703.43999  last_update 1\n",
      "train: iter 178  trainloss -1933.37968  validloss -1652.24868±0.00000  bestvalidloss -1703.43999  last_update 2\n",
      "train: iter 179  trainloss -1879.82070  validloss -1464.91014±0.00000  bestvalidloss -1703.43999  last_update 3\n",
      "train: iter 180  trainloss -1902.51807  validloss -1631.83008±0.00000  bestvalidloss -1703.43999  last_update 4\n",
      "train: iter 181  trainloss -1930.57687  validloss -1636.27302±0.00000  bestvalidloss -1703.43999  last_update 5\n",
      "train: iter 182  trainloss -1924.85105  validloss -1692.11175±0.00000  bestvalidloss -1703.43999  last_update 6\n",
      "train: iter 183  trainloss -1930.21002  validloss -1705.82679±0.00000  bestvalidloss -1705.82679  last_update 0\n",
      "train: iter 184  trainloss -1885.55980  validloss -1719.69815±0.00000  bestvalidloss -1719.69815  last_update 0\n",
      "train: iter 185  trainloss -1879.20386  validloss -1643.86793±0.00000  bestvalidloss -1719.69815  last_update 1\n",
      "train: iter 186  trainloss -1768.30253  validloss -1601.38552±0.00000  bestvalidloss -1719.69815  last_update 2\n",
      "train: iter 187  trainloss -1862.41817  validloss -1085.60996±0.00000  bestvalidloss -1719.69815  last_update 3\n",
      "train: iter 188  trainloss -1861.98985  validloss -1499.71855±0.00000  bestvalidloss -1719.69815  last_update 4\n",
      "train: iter 189  trainloss -1877.83254  validloss -1447.28762±0.00000  bestvalidloss -1719.69815  last_update 5\n",
      "train: iter 190  trainloss -1932.82999  validloss -1542.26646±0.00000  bestvalidloss -1719.69815  last_update 6\n",
      "train: iter 191  trainloss -1923.85309  validloss -1639.26296±0.00000  bestvalidloss -1719.69815  last_update 7\n",
      "train: iter 192  trainloss -1948.62370  validloss -1614.71606±0.00000  bestvalidloss -1719.69815  last_update 8\n",
      "train: iter 193  trainloss -1950.18747  validloss -1704.60647±0.00000  bestvalidloss -1719.69815  last_update 9\n",
      "train: iter 194  trainloss -1922.84478  validloss -1660.52373±0.00000  bestvalidloss -1719.69815  last_update 10\n",
      "train: iter 195  trainloss -1651.08429  validloss -1384.42715±0.00000  bestvalidloss -1719.69815  last_update 11\n",
      "train: iter 196  trainloss -1859.99445  validloss -1330.63256±0.00000  bestvalidloss -1719.69815  last_update 12\n",
      "train: iter 197  trainloss -1922.07325  validloss -1631.10703±0.00000  bestvalidloss -1719.69815  last_update 13\n",
      "train: iter 198  trainloss -1932.59055  validloss -1663.06512±0.00000  bestvalidloss -1719.69815  last_update 14\n",
      "train: iter 199  trainloss -1944.64749  validloss -1701.17180±0.00000  bestvalidloss -1719.69815  last_update 15\n",
      "train: iter 200  trainloss -1926.95760  validloss -1614.51258±0.00000  bestvalidloss -1719.69815  last_update 16\n",
      "train: iter 201  trainloss -1937.87017  validloss -1548.46708±0.00000  bestvalidloss -1719.69815  last_update 17\n",
      "train: iter 202  trainloss -1751.33536  validloss -1615.15713±0.00000  bestvalidloss -1719.69815  last_update 18\n",
      "train: iter 203  trainloss -1910.77648  validloss -1516.60876±0.00000  bestvalidloss -1719.69815  last_update 19\n",
      "train: iter 204  trainloss -1957.58803  validloss -1683.27864±0.00000  bestvalidloss -1719.69815  last_update 20\n",
      "train: iter 205  trainloss -1924.04947  validloss -1678.81952±0.00000  bestvalidloss -1719.69815  last_update 21\n",
      "train: iter 206  trainloss -1946.97902  validloss -1707.21451±0.00000  bestvalidloss -1719.69815  last_update 22\n",
      "train: iter 207  trainloss -1949.48715  validloss -1694.20332±0.00000  bestvalidloss -1719.69815  last_update 23\n",
      "train: iter 208  trainloss -1939.12991  validloss -1693.81359±0.00000  bestvalidloss -1719.69815  last_update 24\n",
      "train: iter 209  trainloss -1934.02717  validloss -1624.51109±0.00000  bestvalidloss -1719.69815  last_update 25\n",
      "train: iter 210  trainloss -1931.57948  validloss -1553.62290±0.00000  bestvalidloss -1719.69815  last_update 26\n",
      "train: iter 211  trainloss -1963.84878  validloss -1717.57897±0.00000  bestvalidloss -1719.69815  last_update 27\n",
      "train: iter 212  trainloss -1961.32628  validloss -1754.73155±0.00000  bestvalidloss -1754.73155  last_update 0\n",
      "train: iter 213  trainloss -1760.40311  validloss -1518.41984±0.00000  bestvalidloss -1754.73155  last_update 1\n",
      "train: iter 214  trainloss -1930.61877  validloss -1575.24646±0.00000  bestvalidloss -1754.73155  last_update 2\n",
      "train: iter 215  trainloss -1919.56766  validloss -1684.09566±0.00000  bestvalidloss -1754.73155  last_update 3\n",
      "train: iter 216  trainloss -1958.39191  validloss -1603.77203±0.00000  bestvalidloss -1754.73155  last_update 4\n",
      "train: iter 217  trainloss -1951.20063  validloss -1724.74682±0.00000  bestvalidloss -1754.73155  last_update 5\n",
      "train: iter 218  trainloss -1938.13808  validloss -1745.28799±0.00000  bestvalidloss -1754.73155  last_update 6\n",
      "train: iter 219  trainloss -1958.91155  validloss -1633.08468±0.00000  bestvalidloss -1754.73155  last_update 7\n",
      "train: iter 220  trainloss -1879.09192  validloss -1713.76838±0.00000  bestvalidloss -1754.73155  last_update 8\n",
      "train: iter 221  trainloss -1887.41915  validloss -1551.18108±0.00000  bestvalidloss -1754.73155  last_update 9\n",
      "train: iter 222  trainloss -1959.40959  validloss -1723.10284±0.00000  bestvalidloss -1754.73155  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1941.83561  validloss -1709.43689±0.00000  bestvalidloss -1754.73155  last_update 11\n",
      "train: iter 224  trainloss -1893.15677  validloss -1605.99846±0.00000  bestvalidloss -1754.73155  last_update 12\n",
      "train: iter 225  trainloss -1927.46903  validloss -1685.96607±0.00000  bestvalidloss -1754.73155  last_update 13\n",
      "train: iter 226  trainloss -1930.56726  validloss -1561.51972±0.00000  bestvalidloss -1754.73155  last_update 14\n",
      "train: iter 227  trainloss -1909.32331  validloss -1624.03379±0.00000  bestvalidloss -1754.73155  last_update 15\n",
      "train: iter 228  trainloss -1893.79795  validloss -1492.84713±0.00000  bestvalidloss -1754.73155  last_update 16\n",
      "train: iter 229  trainloss -1956.34093  validloss -1303.46088±0.00000  bestvalidloss -1754.73155  last_update 17\n",
      "train: iter 230  trainloss -1982.93445  validloss -1747.18125±0.00000  bestvalidloss -1754.73155  last_update 18\n",
      "train: iter 231  trainloss -1975.71594  validloss -1696.23264±0.00000  bestvalidloss -1754.73155  last_update 19\n",
      "train: iter 232  trainloss -1972.18302  validloss -1680.23134±0.00000  bestvalidloss -1754.73155  last_update 20\n",
      "train: iter 233  trainloss -1902.88908  validloss -1780.72168±0.00000  bestvalidloss -1780.72168  last_update 0\n",
      "train: iter 234  trainloss -1882.44874  validloss -1652.21398±0.00000  bestvalidloss -1780.72168  last_update 1\n",
      "train: iter 235  trainloss -1901.46673  validloss -1697.23864±0.00000  bestvalidloss -1780.72168  last_update 2\n",
      "train: iter 236  trainloss -1866.22623  validloss -1223.39315±0.00000  bestvalidloss -1780.72168  last_update 3\n",
      "train: iter 237  trainloss -1961.25785  validloss -1659.74208±0.00000  bestvalidloss -1780.72168  last_update 4\n",
      "train: iter 238  trainloss -1969.99029  validloss -1714.36673±0.00000  bestvalidloss -1780.72168  last_update 5\n",
      "train: iter 239  trainloss -1967.23498  validloss -1765.88721±0.00000  bestvalidloss -1780.72168  last_update 6\n",
      "train: iter 240  trainloss -1970.83985  validloss -1771.84491±0.00000  bestvalidloss -1780.72168  last_update 7\n",
      "train: iter 241  trainloss -1960.20740  validloss -1763.51518±0.00000  bestvalidloss -1780.72168  last_update 8\n",
      "train: iter 242  trainloss -1938.35192  validloss -1343.59892±0.00000  bestvalidloss -1780.72168  last_update 9\n",
      "train: iter 243  trainloss -1774.25090  validloss -1622.79623±0.00000  bestvalidloss -1780.72168  last_update 10\n",
      "train: iter 244  trainloss -1863.85545  validloss 75.30988±0.00000  bestvalidloss -1780.72168  last_update 11\n",
      "train: iter 245  trainloss -1941.39865  validloss -1652.91111±0.00000  bestvalidloss -1780.72168  last_update 12\n",
      "train: iter 246  trainloss -1934.99757  validloss -1289.83564±0.00000  bestvalidloss -1780.72168  last_update 13\n",
      "train: iter 247  trainloss -1960.16020  validloss -1714.09494±0.00000  bestvalidloss -1780.72168  last_update 14\n",
      "train: iter 248  trainloss -1965.29072  validloss -1730.46692±0.00000  bestvalidloss -1780.72168  last_update 15\n",
      "train: iter 249  trainloss -1994.91667  validloss -1799.62253±0.00000  bestvalidloss -1799.62253  last_update 0\n",
      "train: iter 250  trainloss -1945.64546  validloss -1693.36128±0.00000  bestvalidloss -1799.62253  last_update 1\n",
      "train: iter 251  trainloss -1942.25392  validloss -1642.74260±0.00000  bestvalidloss -1799.62253  last_update 2\n",
      "train: iter 252  trainloss -1943.86631  validloss -1727.77270±0.00000  bestvalidloss -1799.62253  last_update 3\n",
      "train: iter 253  trainloss -1934.43582  validloss -1650.09813±0.00000  bestvalidloss -1799.62253  last_update 4\n",
      "train: iter 254  trainloss -1933.25294  validloss -1572.86728±0.00000  bestvalidloss -1799.62253  last_update 5\n",
      "train: iter 255  trainloss -1935.90457  validloss -1699.30242±0.00000  bestvalidloss -1799.62253  last_update 6\n",
      "train: iter 256  trainloss -1888.94141  validloss -1224.59353±0.00000  bestvalidloss -1799.62253  last_update 7\n",
      "train: iter 257  trainloss -1710.91632  validloss -514.99540±0.00000  bestvalidloss -1799.62253  last_update 8\n",
      "train: iter 258  trainloss -1835.34804  validloss -777.21830±0.00000  bestvalidloss -1799.62253  last_update 9\n",
      "train: iter 259  trainloss -1967.88247  validloss -1608.84932±0.00000  bestvalidloss -1799.62253  last_update 10\n",
      "train: iter 260  trainloss -1966.76531  validloss -1757.31397±0.00000  bestvalidloss -1799.62253  last_update 11\n",
      "train: iter 261  trainloss -1976.27786  validloss -1643.68028±0.00000  bestvalidloss -1799.62253  last_update 12\n",
      "train: iter 262  trainloss -1967.73385  validloss -1766.32988±0.00000  bestvalidloss -1799.62253  last_update 13\n",
      "train: iter 263  trainloss -1964.90582  validloss -1743.54736±0.00000  bestvalidloss -1799.62253  last_update 14\n",
      "train: iter 264  trainloss -1975.89061  validloss -1739.67499±0.00000  bestvalidloss -1799.62253  last_update 15\n",
      "train: iter 265  trainloss -1968.10686  validloss -1795.10848±0.00000  bestvalidloss -1799.62253  last_update 16\n",
      "train: iter 266  trainloss -1962.55704  validloss -1680.22135±0.00000  bestvalidloss -1799.62253  last_update 17\n",
      "train: iter 267  trainloss -1988.62387  validloss -1743.97640±0.00000  bestvalidloss -1799.62253  last_update 18\n",
      "train: iter 268  trainloss -1935.48079  validloss -1682.00489±0.00000  bestvalidloss -1799.62253  last_update 19\n",
      "train: iter 269  trainloss -1930.32025  validloss -1494.42303±0.00000  bestvalidloss -1799.62253  last_update 20\n",
      "train: iter 270  trainloss -1899.86588  validloss -1525.24739±0.00000  bestvalidloss -1799.62253  last_update 21\n",
      "train: iter 271  trainloss -1984.71368  validloss -1702.72466±0.00000  bestvalidloss -1799.62253  last_update 22\n",
      "train: iter 272  trainloss -1980.20179  validloss -1767.05219±0.00000  bestvalidloss -1799.62253  last_update 23\n",
      "train: iter 273  trainloss -1951.78781  validloss -1655.45885±0.00000  bestvalidloss -1799.62253  last_update 24\n",
      "train: iter 274  trainloss -1945.60785  validloss -1639.62387±0.00000  bestvalidloss -1799.62253  last_update 25\n",
      "train: iter 275  trainloss -1974.40789  validloss -1781.05831±0.00000  bestvalidloss -1799.62253  last_update 26\n",
      "train: iter 276  trainloss -1911.83298  validloss -1635.41272±0.00000  bestvalidloss -1799.62253  last_update 27\n",
      "train: iter 277  trainloss -1906.19478  validloss -1506.18234±0.00000  bestvalidloss -1799.62253  last_update 28\n",
      "train: iter 278  trainloss -1921.69673  validloss -1665.46797±0.00000  bestvalidloss -1799.62253  last_update 29\n",
      "train: iter 279  trainloss -1954.28026  validloss -1584.47288±0.00000  bestvalidloss -1799.62253  last_update 30\n",
      "train: iter 280  trainloss -1946.46673  validloss -1449.39284±0.00000  bestvalidloss -1799.62253  last_update 31\n",
      "train: iter 281  trainloss -1927.26944  validloss -1718.09954±0.00000  bestvalidloss -1799.62253  last_update 32\n",
      "train: iter 282  trainloss -1987.49157  validloss -1717.12360±0.00000  bestvalidloss -1799.62253  last_update 33\n",
      "train: iter 283  trainloss -1945.79646  validloss -1695.70479±0.00000  bestvalidloss -1799.62253  last_update 34\n",
      "train: iter 284  trainloss -1972.08407  validloss -1662.74355±0.00000  bestvalidloss -1799.62253  last_update 35\n",
      "train: iter 285  trainloss -1940.80461  validloss -1719.12916±0.00000  bestvalidloss -1799.62253  last_update 36\n",
      "train: iter 286  trainloss -1899.05489  validloss -1722.94747±0.00000  bestvalidloss -1799.62253  last_update 37\n",
      "train: iter 287  trainloss -1999.44632  validloss -1792.27658±0.00000  bestvalidloss -1799.62253  last_update 38\n",
      "train: iter 288  trainloss -1935.79687  validloss -1719.77325±0.00000  bestvalidloss -1799.62253  last_update 39\n",
      "train: iter 289  trainloss -1941.37031  validloss -454.21406±0.00000  bestvalidloss -1799.62253  last_update 40\n",
      "train: iter 290  trainloss -1974.06283  validloss -1777.87837±0.00000  bestvalidloss -1799.62253  last_update 41\n",
      "train: iter 291  trainloss -1986.14019  validloss -1712.68417±0.00000  bestvalidloss -1799.62253  last_update 42\n",
      "train: iter 292  trainloss -1969.81561  validloss -1781.30125±0.00000  bestvalidloss -1799.62253  last_update 43\n",
      "train: iter 293  trainloss -1980.20999  validloss -1768.49840±0.00000  bestvalidloss -1799.62253  last_update 44\n",
      "train: iter 294  trainloss -1969.36541  validloss -1704.55992±0.00000  bestvalidloss -1799.62253  last_update 45\n",
      "train: iter 295  trainloss -1974.35584  validloss -1717.57281±0.00000  bestvalidloss -1799.62253  last_update 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -1982.28926  validloss -1668.35942±0.00000  bestvalidloss -1799.62253  last_update 47\n",
      "train: iter 297  trainloss -1946.80272  validloss -1760.94679±0.00000  bestvalidloss -1799.62253  last_update 48\n",
      "train: iter 298  trainloss -1971.77022  validloss -1572.53683±0.00000  bestvalidloss -1799.62253  last_update 49\n",
      "train: iter 299  trainloss -1962.52435  validloss -1827.17887±0.00000  bestvalidloss -1827.17887  last_update 0\n",
      "train: iter 300  trainloss -1883.35713  validloss -1664.70644±0.00000  bestvalidloss -1827.17887  last_update 1\n",
      "train: iter 301  trainloss -1980.04080  validloss -1600.91150±0.00000  bestvalidloss -1827.17887  last_update 2\n",
      "train: iter 302  trainloss -1933.38986  validloss -1780.17949±0.00000  bestvalidloss -1827.17887  last_update 3\n",
      "train: iter 303  trainloss -1980.34038  validloss -1717.23057±0.00000  bestvalidloss -1827.17887  last_update 4\n",
      "train: iter 304  trainloss -1999.82143  validloss -1800.02734±0.00000  bestvalidloss -1827.17887  last_update 5\n",
      "train: iter 305  trainloss -1993.34446  validloss -1735.36106±0.00000  bestvalidloss -1827.17887  last_update 6\n",
      "train: iter 306  trainloss -1874.82094  validloss -1803.21331±0.00000  bestvalidloss -1827.17887  last_update 7\n",
      "train: iter 307  trainloss -1977.16068  validloss -1787.99519±0.00000  bestvalidloss -1827.17887  last_update 8\n",
      "train: iter 308  trainloss -1973.92438  validloss -1782.03637±0.00000  bestvalidloss -1827.17887  last_update 9\n",
      "train: iter 309  trainloss -1896.54086  validloss -1537.87138±0.00000  bestvalidloss -1827.17887  last_update 10\n",
      "train: iter 310  trainloss -1974.82440  validloss -1721.81201±0.00000  bestvalidloss -1827.17887  last_update 11\n",
      "train: iter 311  trainloss -1975.15168  validloss -1723.90124±0.00000  bestvalidloss -1827.17887  last_update 12\n",
      "train: iter 312  trainloss -1948.54506  validloss -1711.11613±0.00000  bestvalidloss -1827.17887  last_update 13\n",
      "train: iter 313  trainloss -1974.51021  validloss -1803.56379±0.00000  bestvalidloss -1827.17887  last_update 14\n",
      "train: iter 314  trainloss -1988.82985  validloss -1783.84996±0.00000  bestvalidloss -1827.17887  last_update 15\n",
      "train: iter 315  trainloss -2006.69181  validloss -1781.85548±0.00000  bestvalidloss -1827.17887  last_update 16\n",
      "train: iter 316  trainloss -2006.65918  validloss -1810.21205±0.00000  bestvalidloss -1827.17887  last_update 17\n",
      "train: iter 317  trainloss -1928.90268  validloss -1753.27550±0.00000  bestvalidloss -1827.17887  last_update 18\n",
      "train: iter 318  trainloss -1838.33704  validloss -1569.27922±0.00000  bestvalidloss -1827.17887  last_update 19\n",
      "train: iter 319  trainloss -1965.41485  validloss -1537.23304±0.00000  bestvalidloss -1827.17887  last_update 20\n",
      "train: iter 320  trainloss -1992.00721  validloss -1789.08412±0.00000  bestvalidloss -1827.17887  last_update 21\n",
      "train: iter 321  trainloss -1998.43760  validloss -1831.10197±0.00000  bestvalidloss -1831.10197  last_update 0\n",
      "train: iter 322  trainloss -2000.12465  validloss -1687.86881±0.00000  bestvalidloss -1831.10197  last_update 1\n",
      "train: iter 323  trainloss -1864.58370  validloss -1696.42973±0.00000  bestvalidloss -1831.10197  last_update 2\n",
      "train: iter 324  trainloss -1984.37246  validloss -1716.19294±0.00000  bestvalidloss -1831.10197  last_update 3\n",
      "train: iter 325  trainloss -1998.47388  validloss -1830.76953±0.00000  bestvalidloss -1831.10197  last_update 4\n",
      "train: iter 326  trainloss -2005.69301  validloss -1838.10012±0.00000  bestvalidloss -1838.10012  last_update 0\n",
      "train: iter 327  trainloss -2012.22135  validloss -1768.18204±0.00000  bestvalidloss -1838.10012  last_update 1\n",
      "train: iter 328  trainloss -1996.71510  validloss -1832.17743±0.00000  bestvalidloss -1838.10012  last_update 2\n",
      "train: iter 329  trainloss -1842.51368  validloss -1619.00381±0.00000  bestvalidloss -1838.10012  last_update 3\n",
      "train: iter 330  trainloss -1931.24226  validloss -1222.95490±0.00000  bestvalidloss -1838.10012  last_update 4\n",
      "train: iter 331  trainloss -1996.01988  validloss -1803.87302±0.00000  bestvalidloss -1838.10012  last_update 5\n",
      "train: iter 332  trainloss -2024.93638  validloss -1845.17591±0.00000  bestvalidloss -1845.17591  last_update 0\n",
      "train: iter 333  trainloss -1933.45353  validloss -1681.20530±0.00000  bestvalidloss -1845.17591  last_update 1\n",
      "train: iter 334  trainloss -1932.86204  validloss -1108.21329±0.00000  bestvalidloss -1845.17591  last_update 2\n",
      "train: iter 335  trainloss -2005.47944  validloss -1817.91127±0.00000  bestvalidloss -1845.17591  last_update 3\n",
      "train: iter 336  trainloss -2011.03858  validloss -1805.03654±0.00000  bestvalidloss -1845.17591  last_update 4\n",
      "train: iter 337  trainloss -2006.74105  validloss -1811.35285±0.00000  bestvalidloss -1845.17591  last_update 5\n",
      "train: iter 338  trainloss -1944.91939  validloss -1774.14437±0.00000  bestvalidloss -1845.17591  last_update 6\n",
      "train: iter 339  trainloss -1560.19446  validloss -1047.12993±0.00000  bestvalidloss -1845.17591  last_update 7\n",
      "train: iter 340  trainloss -1965.73503  validloss -1695.60812±0.00000  bestvalidloss -1845.17591  last_update 8\n",
      "train: iter 341  trainloss -1961.63530  validloss -1736.14047±0.00000  bestvalidloss -1845.17591  last_update 9\n",
      "train: iter 342  trainloss -1998.08466  validloss -1721.45107±0.00000  bestvalidloss -1845.17591  last_update 10\n",
      "train: iter 343  trainloss -2018.67827  validloss -1831.71322±0.00000  bestvalidloss -1845.17591  last_update 11\n",
      "train: iter 344  trainloss -1981.73640  validloss -1637.97820±0.00000  bestvalidloss -1845.17591  last_update 12\n",
      "train: iter 345  trainloss -1997.61956  validloss -1789.97299±0.00000  bestvalidloss -1845.17591  last_update 13\n",
      "train: iter 346  trainloss -1939.97449  validloss -1811.00544±0.00000  bestvalidloss -1845.17591  last_update 14\n",
      "train: iter 347  trainloss -1996.90745  validloss -1790.29826±0.00000  bestvalidloss -1845.17591  last_update 15\n",
      "train: iter 348  trainloss -1977.69853  validloss -1680.57075±0.00000  bestvalidloss -1845.17591  last_update 16\n",
      "train: iter 349  trainloss -2002.87762  validloss -1823.94196±0.00000  bestvalidloss -1845.17591  last_update 17\n",
      "train: iter 350  trainloss -1986.14322  validloss -1807.16857±0.00000  bestvalidloss -1845.17591  last_update 18\n",
      "train: iter 351  trainloss -2011.51924  validloss -1805.73600±0.00000  bestvalidloss -1845.17591  last_update 19\n",
      "train: iter 352  trainloss -1940.77759  validloss -1830.65190±0.00000  bestvalidloss -1845.17591  last_update 20\n",
      "train: iter 353  trainloss -2006.06461  validloss -1811.33658±0.00000  bestvalidloss -1845.17591  last_update 21\n",
      "train: iter 354  trainloss -1929.71067  validloss -1697.29387±0.00000  bestvalidloss -1845.17591  last_update 22\n",
      "train: iter 355  trainloss -1948.28294  validloss -1597.51434±0.00000  bestvalidloss -1845.17591  last_update 23\n",
      "train: iter 356  trainloss -1973.88773  validloss -1743.74622±0.00000  bestvalidloss -1845.17591  last_update 24\n",
      "train: iter 357  trainloss -1858.93827  validloss -1558.33016±0.00000  bestvalidloss -1845.17591  last_update 25\n",
      "train: iter 358  trainloss -1936.25193  validloss -1803.68009±0.00000  bestvalidloss -1845.17591  last_update 26\n",
      "train: iter 359  trainloss -2010.60033  validloss -1830.44502±0.00000  bestvalidloss -1845.17591  last_update 27\n",
      "train: iter 360  trainloss -1990.18964  validloss -1630.53854±0.00000  bestvalidloss -1845.17591  last_update 28\n",
      "train: iter 361  trainloss -2010.81234  validloss -1835.59249±0.00000  bestvalidloss -1845.17591  last_update 29\n",
      "train: iter 362  trainloss -2007.71536  validloss -1775.82416±0.00000  bestvalidloss -1845.17591  last_update 30\n",
      "train: iter 363  trainloss -1966.37741  validloss -1795.50303±0.00000  bestvalidloss -1845.17591  last_update 31\n",
      "train: iter 364  trainloss -2018.06841  validloss -1829.57842±0.00000  bestvalidloss -1845.17591  last_update 32\n",
      "train: iter 365  trainloss -1985.64577  validloss -1757.72688±0.00000  bestvalidloss -1845.17591  last_update 33\n",
      "train: iter 366  trainloss -1989.85060  validloss -1794.85198±0.00000  bestvalidloss -1845.17591  last_update 34\n",
      "train: iter 367  trainloss -2018.99169  validloss -1761.36817±0.00000  bestvalidloss -1845.17591  last_update 35\n",
      "train: iter 368  trainloss -1999.71748  validloss -1769.61893±0.00000  bestvalidloss -1845.17591  last_update 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -2025.13015  validloss -1850.40072±0.00000  bestvalidloss -1850.40072  last_update 0\n",
      "train: iter 370  trainloss -1989.72057  validloss -1825.97220±0.00000  bestvalidloss -1850.40072  last_update 1\n",
      "train: iter 371  trainloss -1980.37539  validloss -1831.49861±0.00000  bestvalidloss -1850.40072  last_update 2\n",
      "train: iter 372  trainloss -1880.79268  validloss -1524.44342±0.00000  bestvalidloss -1850.40072  last_update 3\n",
      "train: iter 373  trainloss -1950.31842  validloss -1592.96366±0.00000  bestvalidloss -1850.40072  last_update 4\n",
      "train: iter 374  trainloss -2031.71962  validloss -1797.82339±0.00000  bestvalidloss -1850.40072  last_update 5\n",
      "train: iter 375  trainloss -1985.99381  validloss -1787.53607±0.00000  bestvalidloss -1850.40072  last_update 6\n",
      "train: iter 376  trainloss -1990.97533  validloss -1827.72269±0.00000  bestvalidloss -1850.40072  last_update 7\n",
      "train: iter 377  trainloss -2000.22812  validloss -1765.13620±0.00000  bestvalidloss -1850.40072  last_update 8\n",
      "train: iter 378  trainloss -1992.49344  validloss -1715.07671±0.00000  bestvalidloss -1850.40072  last_update 9\n",
      "train: iter 379  trainloss -1870.06790  validloss -1752.65939±0.00000  bestvalidloss -1850.40072  last_update 10\n",
      "train: iter 380  trainloss -2000.39568  validloss -708.39877±0.00000  bestvalidloss -1850.40072  last_update 11\n",
      "train: iter 381  trainloss -1965.70542  validloss -1776.89608±0.00000  bestvalidloss -1850.40072  last_update 12\n",
      "train: iter 382  trainloss -1987.12626  validloss -1776.90717±0.00000  bestvalidloss -1850.40072  last_update 13\n",
      "train: iter 383  trainloss -2023.33308  validloss -1805.72693±0.00000  bestvalidloss -1850.40072  last_update 14\n",
      "train: iter 384  trainloss -1965.14769  validloss -1833.39719±0.00000  bestvalidloss -1850.40072  last_update 15\n",
      "train: iter 385  trainloss -1976.11187  validloss -1834.62793±0.00000  bestvalidloss -1850.40072  last_update 16\n",
      "train: iter 386  trainloss -1967.22368  validloss -1466.69296±0.00000  bestvalidloss -1850.40072  last_update 17\n",
      "train: iter 387  trainloss -2019.03134  validloss -1816.53132±0.00000  bestvalidloss -1850.40072  last_update 18\n",
      "train: iter 388  trainloss -1983.07649  validloss -1854.73190±0.00000  bestvalidloss -1854.73190  last_update 0\n",
      "train: iter 389  trainloss -1964.23536  validloss -1703.28611±0.00000  bestvalidloss -1854.73190  last_update 1\n",
      "train: iter 390  trainloss -2017.89443  validloss -1856.81890±0.00000  bestvalidloss -1856.81890  last_update 0\n",
      "train: iter 391  trainloss -2000.67497  validloss -1828.23006±0.00000  bestvalidloss -1856.81890  last_update 1\n",
      "train: iter 392  trainloss -1956.17706  validloss -1830.71969±0.00000  bestvalidloss -1856.81890  last_update 2\n",
      "train: iter 393  trainloss -1976.54855  validloss -1585.33122±0.00000  bestvalidloss -1856.81890  last_update 3\n",
      "train: iter 394  trainloss -2011.17834  validloss -1835.38803±0.00000  bestvalidloss -1856.81890  last_update 4\n",
      "train: iter 395  trainloss -1970.62292  validloss -1669.04952±0.00000  bestvalidloss -1856.81890  last_update 5\n",
      "train: iter 396  trainloss -1986.12035  validloss -1600.06851±0.00000  bestvalidloss -1856.81890  last_update 6\n",
      "train: iter 397  trainloss -1998.31360  validloss -1795.62654±0.00000  bestvalidloss -1856.81890  last_update 7\n",
      "train: iter 398  trainloss -2008.90813  validloss -1767.31608±0.00000  bestvalidloss -1856.81890  last_update 8\n",
      "train: iter 399  trainloss -2012.14759  validloss -1776.17785±0.00000  bestvalidloss -1856.81890  last_update 9\n",
      "train: iter 400  trainloss -2028.11394  validloss -1878.81863±0.00000  bestvalidloss -1878.81863  last_update 0\n",
      "train: iter 401  trainloss -2025.79573  validloss -1836.96871±0.00000  bestvalidloss -1878.81863  last_update 1\n",
      "train: iter 402  trainloss -1948.07124  validloss -1599.31566±0.00000  bestvalidloss -1878.81863  last_update 2\n",
      "train: iter 403  trainloss -2002.01247  validloss -1348.76765±0.00000  bestvalidloss -1878.81863  last_update 3\n",
      "train: iter 404  trainloss -1895.19510  validloss -1795.27182±0.00000  bestvalidloss -1878.81863  last_update 4\n",
      "train: iter 405  trainloss -1972.16721  validloss -1748.32778±0.00000  bestvalidloss -1878.81863  last_update 5\n",
      "train: iter 406  trainloss -1905.32954  validloss -875.28322±0.00000  bestvalidloss -1878.81863  last_update 6\n",
      "train: iter 407  trainloss -1954.76795  validloss -1392.29456±0.00000  bestvalidloss -1878.81863  last_update 7\n",
      "train: iter 408  trainloss -1991.53764  validloss -1713.62744±0.00000  bestvalidloss -1878.81863  last_update 8\n",
      "train: iter 409  trainloss -1983.05715  validloss -1772.19386±0.00000  bestvalidloss -1878.81863  last_update 9\n",
      "train: iter 410  trainloss -2013.78548  validloss -1777.81738±0.00000  bestvalidloss -1878.81863  last_update 10\n",
      "train: iter 411  trainloss -1998.91621  validloss -1373.30692±0.00000  bestvalidloss -1878.81863  last_update 11\n",
      "train: iter 412  trainloss -2020.13310  validloss -1823.19051±0.00000  bestvalidloss -1878.81863  last_update 12\n",
      "train: iter 413  trainloss -1997.84745  validloss -1794.24255±0.00000  bestvalidloss -1878.81863  last_update 13\n",
      "train: iter 414  trainloss -1974.30998  validloss -1779.12309±0.00000  bestvalidloss -1878.81863  last_update 14\n",
      "train: iter 415  trainloss -2031.92882  validloss -1769.95010±0.00000  bestvalidloss -1878.81863  last_update 15\n",
      "train: iter 416  trainloss -1988.51322  validloss -1615.76617±0.00000  bestvalidloss -1878.81863  last_update 16\n",
      "train: iter 417  trainloss -1997.95470  validloss -1793.32616±0.00000  bestvalidloss -1878.81863  last_update 17\n",
      "train: iter 418  trainloss -2009.55831  validloss -1818.68361±0.00000  bestvalidloss -1878.81863  last_update 18\n",
      "train: iter 419  trainloss -1964.67260  validloss -1819.88570±0.00000  bestvalidloss -1878.81863  last_update 19\n",
      "train: iter 420  trainloss -2019.72319  validloss -1845.69921±0.00000  bestvalidloss -1878.81863  last_update 20\n",
      "train: iter 421  trainloss -1990.26670  validloss -1726.65270±0.00000  bestvalidloss -1878.81863  last_update 21\n",
      "train: iter 422  trainloss -2001.27928  validloss -1718.70336±0.00000  bestvalidloss -1878.81863  last_update 22\n",
      "train: iter 423  trainloss -2028.47282  validloss -1797.31588±0.00000  bestvalidloss -1878.81863  last_update 23\n",
      "train: iter 424  trainloss -1985.61231  validloss -1717.87253±0.00000  bestvalidloss -1878.81863  last_update 24\n",
      "train: iter 425  trainloss -2034.17881  validloss -1837.00589±0.00000  bestvalidloss -1878.81863  last_update 25\n",
      "train: iter 426  trainloss -2012.80307  validloss -1847.33958±0.00000  bestvalidloss -1878.81863  last_update 26\n",
      "train: iter 427  trainloss -2017.60730  validloss -1847.91485±0.00000  bestvalidloss -1878.81863  last_update 27\n",
      "train: iter 428  trainloss -1945.34464  validloss -1637.98583±0.00000  bestvalidloss -1878.81863  last_update 28\n",
      "train: iter 429  trainloss -2001.65197  validloss -1770.09397±0.00000  bestvalidloss -1878.81863  last_update 29\n",
      "train: iter 430  trainloss -2024.95494  validloss -1795.46426±0.00000  bestvalidloss -1878.81863  last_update 30\n",
      "train: iter 431  trainloss -1682.29914  validloss -1860.38087±0.00000  bestvalidloss -1878.81863  last_update 31\n",
      "train: iter 432  trainloss -2027.80330  validloss -1775.65740±0.00000  bestvalidloss -1878.81863  last_update 32\n",
      "train: iter 433  trainloss -2025.04999  validloss -1770.77334±0.00000  bestvalidloss -1878.81863  last_update 33\n",
      "train: iter 434  trainloss -2032.09764  validloss -1844.72958±0.00000  bestvalidloss -1878.81863  last_update 34\n",
      "train: iter 435  trainloss -2010.61109  validloss -1793.52080±0.00000  bestvalidloss -1878.81863  last_update 35\n",
      "train: iter 436  trainloss -1773.64473  validloss -1281.44450±0.00000  bestvalidloss -1878.81863  last_update 36\n",
      "train: iter 437  trainloss -1975.62650  validloss -1668.80066±0.00000  bestvalidloss -1878.81863  last_update 37\n",
      "train: iter 438  trainloss -2006.63095  validloss -1771.66716±0.00000  bestvalidloss -1878.81863  last_update 38\n",
      "train: iter 439  trainloss -2013.11730  validloss -1779.82044±0.00000  bestvalidloss -1878.81863  last_update 39\n",
      "train: iter 440  trainloss -2034.60679  validloss -1833.43445±0.00000  bestvalidloss -1878.81863  last_update 40\n",
      "train: iter 441  trainloss -2034.98646  validloss -1848.20882±0.00000  bestvalidloss -1878.81863  last_update 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 442  trainloss -1957.61975  validloss -1596.78699±0.00000  bestvalidloss -1878.81863  last_update 42\n",
      "train: iter 443  trainloss -2019.72561  validloss -1801.71815±0.00000  bestvalidloss -1878.81863  last_update 43\n",
      "train: iter 444  trainloss -1938.59279  validloss -1815.70786±0.00000  bestvalidloss -1878.81863  last_update 44\n",
      "train: iter 445  trainloss -1978.54633  validloss -1353.48936±0.00000  bestvalidloss -1878.81863  last_update 45\n",
      "train: iter 446  trainloss -2026.76024  validloss -1807.06324±0.00000  bestvalidloss -1878.81863  last_update 46\n",
      "train: iter 447  trainloss -1982.32094  validloss -1828.69165±0.00000  bestvalidloss -1878.81863  last_update 47\n",
      "train: iter 448  trainloss -2040.29379  validloss -1852.38974±0.00000  bestvalidloss -1878.81863  last_update 48\n",
      "train: iter 449  trainloss -1992.83428  validloss -1741.13323±0.00000  bestvalidloss -1878.81863  last_update 49\n",
      "train: iter 450  trainloss -2003.60869  validloss -1818.15722±0.00000  bestvalidloss -1878.81863  last_update 50\n",
      "train: iter 451  trainloss -2055.42752  validloss -1822.69705±0.00000  bestvalidloss -1878.81863  last_update 51\n",
      "train: iter 452  trainloss -2045.60740  validloss -1846.88595±0.00000  bestvalidloss -1878.81863  last_update 52\n",
      "train: iter 453  trainloss -2013.59342  validloss -1782.02718±0.00000  bestvalidloss -1878.81863  last_update 53\n",
      "train: iter 454  trainloss -1931.00614  validloss -1851.65645±0.00000  bestvalidloss -1878.81863  last_update 54\n",
      "train: iter 455  trainloss -1928.83522  validloss -1658.61803±0.00000  bestvalidloss -1878.81863  last_update 55\n",
      "train: iter 456  trainloss -1978.92958  validloss -1761.72682±0.00000  bestvalidloss -1878.81863  last_update 56\n",
      "train: iter 457  trainloss -2013.43522  validloss -1768.28302±0.00000  bestvalidloss -1878.81863  last_update 57\n",
      "train: iter 458  trainloss -2007.99140  validloss -1836.96442±0.00000  bestvalidloss -1878.81863  last_update 58\n",
      "train: iter 459  trainloss -1891.24337  validloss -1382.60670±0.00000  bestvalidloss -1878.81863  last_update 59\n",
      "train: iter 460  trainloss -1993.48879  validloss -1643.99189±0.00000  bestvalidloss -1878.81863  last_update 60\n",
      "train: iter 461  trainloss -1996.69366  validloss -1646.23595±0.00000  bestvalidloss -1878.81863  last_update 61\n",
      "train: iter 462  trainloss -2031.63292  validloss -1716.85462±0.00000  bestvalidloss -1878.81863  last_update 62\n",
      "train: iter 463  trainloss -2036.78295  validloss -1823.94929±0.00000  bestvalidloss -1878.81863  last_update 63\n",
      "train: iter 464  trainloss -2034.87434  validloss -1869.52870±0.00000  bestvalidloss -1878.81863  last_update 64\n",
      "train: iter 465  trainloss -1986.51080  validloss -1846.17404±0.00000  bestvalidloss -1878.81863  last_update 65\n",
      "train: iter 466  trainloss -1976.23283  validloss -1779.23104±0.00000  bestvalidloss -1878.81863  last_update 66\n",
      "train: iter 467  trainloss -2018.26553  validloss -1747.99807±0.00000  bestvalidloss -1878.81863  last_update 67\n",
      "train: iter 468  trainloss -2022.74626  validloss -1799.16617±0.00000  bestvalidloss -1878.81863  last_update 68\n",
      "train: iter 469  trainloss -2027.49158  validloss -1799.60331±0.00000  bestvalidloss -1878.81863  last_update 69\n",
      "train: iter 470  trainloss -2016.65744  validloss -1809.66385±0.00000  bestvalidloss -1878.81863  last_update 70\n",
      "train: iter 471  trainloss -1800.48016  validloss -1626.88057±0.00000  bestvalidloss -1878.81863  last_update 71\n",
      "train: iter 472  trainloss -2014.80265  validloss -1800.67404±0.00000  bestvalidloss -1878.81863  last_update 72\n",
      "train: iter 473  trainloss -2032.96038  validloss -1695.99757±0.00000  bestvalidloss -1878.81863  last_update 73\n",
      "train: iter 474  trainloss -2022.56184  validloss -1783.78523±0.00000  bestvalidloss -1878.81863  last_update 74\n",
      "train: iter 475  trainloss -2037.62521  validloss -1849.57318±0.00000  bestvalidloss -1878.81863  last_update 75\n",
      "train: iter 476  trainloss -1973.59125  validloss -1752.62337±0.00000  bestvalidloss -1878.81863  last_update 76\n",
      "train: iter 477  trainloss -2019.86241  validloss -1278.68076±0.00000  bestvalidloss -1878.81863  last_update 77\n",
      "train: iter 478  trainloss -2018.13757  validloss -1803.58779±0.00000  bestvalidloss -1878.81863  last_update 78\n",
      "train: iter 479  trainloss -2029.32551  validloss -1712.58896±0.00000  bestvalidloss -1878.81863  last_update 79\n",
      "train: iter 480  trainloss -2007.79955  validloss -1829.62597±0.00000  bestvalidloss -1878.81863  last_update 80\n",
      "train: iter 481  trainloss -1985.90259  validloss -1656.80123±0.00000  bestvalidloss -1878.81863  last_update 81\n",
      "train: iter 482  trainloss -2038.26112  validloss -1824.88564±0.00000  bestvalidloss -1878.81863  last_update 82\n",
      "train: iter 483  trainloss -2026.80640  validloss -1760.92504±0.00000  bestvalidloss -1878.81863  last_update 83\n",
      "train: iter 484  trainloss -2019.77051  validloss -1832.73992±0.00000  bestvalidloss -1878.81863  last_update 84\n",
      "train: iter 485  trainloss -1996.08134  validloss -1770.21306±0.00000  bestvalidloss -1878.81863  last_update 85\n",
      "train: iter 486  trainloss -2038.67472  validloss -1784.35836±0.00000  bestvalidloss -1878.81863  last_update 86\n",
      "train: iter 487  trainloss -2020.53224  validloss -1714.03108±0.00000  bestvalidloss -1878.81863  last_update 87\n",
      "train: iter 488  trainloss -2012.72666  validloss -1800.48564±0.00000  bestvalidloss -1878.81863  last_update 88\n",
      "train: iter 489  trainloss -2046.92722  validloss -1758.97094±0.00000  bestvalidloss -1878.81863  last_update 89\n",
      "train: iter 490  trainloss -1958.17147  validloss -1452.62451±0.00000  bestvalidloss -1878.81863  last_update 90\n",
      "train: iter 491  trainloss -1945.14685  validloss -1598.64496±0.00000  bestvalidloss -1878.81863  last_update 91\n",
      "train: iter 492  trainloss -2030.47661  validloss -1820.80403±0.00000  bestvalidloss -1878.81863  last_update 92\n",
      "train: iter 493  trainloss -2040.30206  validloss -1810.70220±0.00000  bestvalidloss -1878.81863  last_update 93\n",
      "train: iter 494  trainloss -1986.04973  validloss -1816.08268±0.00000  bestvalidloss -1878.81863  last_update 94\n",
      "train: iter 495  trainloss -2035.32848  validloss -1858.00969±0.00000  bestvalidloss -1878.81863  last_update 95\n",
      "train: iter 496  trainloss -1993.12133  validloss -1696.09872±0.00000  bestvalidloss -1878.81863  last_update 96\n",
      "train: iter 497  trainloss -2034.21888  validloss -1832.09593±0.00000  bestvalidloss -1878.81863  last_update 97\n",
      "train: iter 498  trainloss -2025.50884  validloss -1838.78292±0.00000  bestvalidloss -1878.81863  last_update 98\n",
      "train: iter 499  trainloss -2029.84174  validloss -1783.36259±0.00000  bestvalidloss -1878.81863  last_update 99\n",
      "train: iter 500  trainloss -2020.98670  validloss -1811.87587±0.00000  bestvalidloss -1878.81863  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.2296) penalty_target_max tensor(17.3484)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 10.06809  validloss 10.47783±0.00000  bestvalidloss 10.47783  last_update 0\n",
      "train: iter 1  trainloss 9.19484  validloss 9.52402±0.00000  bestvalidloss 9.52402  last_update 0\n",
      "train: iter 2  trainloss 8.44282  validloss 8.70496±0.00000  bestvalidloss 8.70496  last_update 0\n",
      "train: iter 3  trainloss 7.82872  validloss 8.03860±0.00000  bestvalidloss 8.03860  last_update 0\n",
      "train: iter 4  trainloss 7.29458  validloss 7.49274±0.00000  bestvalidloss 7.49274  last_update 0\n",
      "train: iter 5  trainloss 6.83511  validloss 6.98787±0.00000  bestvalidloss 6.98787  last_update 0\n",
      "train: iter 6  trainloss 6.46356  validloss 6.60559±0.00000  bestvalidloss 6.60559  last_update 0\n",
      "train: iter 7  trainloss 6.11495  validloss 6.23012±0.00000  bestvalidloss 6.23012  last_update 0\n",
      "train: iter 8  trainloss 5.82148  validloss 5.93235±0.00000  bestvalidloss 5.93235  last_update 0\n",
      "train: iter 9  trainloss 5.55873  validloss 5.65660±0.00000  bestvalidloss 5.65660  last_update 0\n",
      "train: iter 10  trainloss 5.33119  validloss 5.40782±0.00000  bestvalidloss 5.40782  last_update 0\n",
      "train: iter 11  trainloss 5.11903  validloss 5.20334±0.00000  bestvalidloss 5.20334  last_update 0\n",
      "train: iter 12  trainloss 4.93500  validloss 5.00326±0.00000  bestvalidloss 5.00326  last_update 0\n",
      "train: iter 13  trainloss 4.76474  validloss 4.81806±0.00000  bestvalidloss 4.81806  last_update 0\n",
      "train: iter 14  trainloss 4.61016  validloss 4.65764±0.00000  bestvalidloss 4.65764  last_update 0\n",
      "train: iter 15  trainloss 4.46838  validloss 4.52253±0.00000  bestvalidloss 4.52253  last_update 0\n",
      "train: iter 16  trainloss 4.33372  validloss 4.38688±0.00000  bestvalidloss 4.38688  last_update 0\n",
      "train: iter 17  trainloss 4.20918  validloss 4.25186±0.00000  bestvalidloss 4.25186  last_update 0\n",
      "train: iter 18  trainloss 4.08964  validloss 4.13984±0.00000  bestvalidloss 4.13984  last_update 0\n",
      "train: iter 19  trainloss 3.98862  validloss 4.03087±0.00000  bestvalidloss 4.03087  last_update 0\n",
      "train: iter 20  trainloss 3.87546  validloss 3.93034±0.00000  bestvalidloss 3.93034  last_update 0\n",
      "train: iter 21  trainloss 3.76725  validloss 3.82847±0.00000  bestvalidloss 3.82847  last_update 0\n",
      "train: iter 22  trainloss 3.67072  validloss 3.72732±0.00000  bestvalidloss 3.72732  last_update 0\n",
      "train: iter 23  trainloss 3.58207  validloss 3.64170±0.00000  bestvalidloss 3.64170  last_update 0\n",
      "train: iter 24  trainloss 3.48935  validloss 3.54375±0.00000  bestvalidloss 3.54375  last_update 0\n",
      "train: iter 25  trainloss 3.40196  validloss 3.46263±0.00000  bestvalidloss 3.46263  last_update 0\n",
      "train: iter 26  trainloss 3.31060  validloss 3.37441±0.00000  bestvalidloss 3.37441  last_update 0\n",
      "train: iter 27  trainloss 3.23139  validloss 3.28187±0.00000  bestvalidloss 3.28187  last_update 0\n",
      "train: iter 28  trainloss 3.15750  validloss 3.20686±0.00000  bestvalidloss 3.20686  last_update 0\n",
      "train: iter 29  trainloss 3.07787  validloss 3.12502±0.00000  bestvalidloss 3.12502  last_update 0\n",
      "train: iter 30  trainloss 3.00310  validloss 3.04587±0.00000  bestvalidloss 3.04587  last_update 0\n",
      "train: iter 31  trainloss 2.92566  validloss 2.97509±0.00000  bestvalidloss 2.97509  last_update 0\n",
      "train: iter 32  trainloss 2.85846  validloss 2.92302±0.00000  bestvalidloss 2.92302  last_update 0\n",
      "train: iter 33  trainloss 2.79376  validloss 2.84592±0.00000  bestvalidloss 2.84592  last_update 0\n",
      "train: iter 34  trainloss 2.72892  validloss 2.79016±0.00000  bestvalidloss 2.79016  last_update 0\n",
      "train: iter 35  trainloss 2.67709  validloss 2.72729±0.00000  bestvalidloss 2.72729  last_update 0\n",
      "train: iter 36  trainloss 2.61996  validloss 2.67368±0.00000  bestvalidloss 2.67368  last_update 0\n",
      "train: iter 37  trainloss 2.56502  validloss 2.62053±0.00000  bestvalidloss 2.62053  last_update 0\n",
      "train: iter 38  trainloss 2.51010  validloss 2.57442±0.00000  bestvalidloss 2.57442  last_update 0\n",
      "train: iter 39  trainloss 2.46147  validloss 2.51753±0.00000  bestvalidloss 2.51753  last_update 0\n",
      "train: iter 40  trainloss 2.41982  validloss 2.48352±0.00000  bestvalidloss 2.48352  last_update 0\n",
      "train: iter 41  trainloss 2.37241  validloss 2.43808±0.00000  bestvalidloss 2.43808  last_update 0\n",
      "train: iter 42  trainloss 2.31935  validloss 2.40383±0.00000  bestvalidloss 2.40383  last_update 0\n",
      "train: iter 43  trainloss 2.28200  validloss 2.34185±0.00000  bestvalidloss 2.34185  last_update 0\n",
      "train: iter 44  trainloss 2.23412  validloss 2.31496±0.00000  bestvalidloss 2.31496  last_update 0\n",
      "train: iter 45  trainloss 2.19828  validloss 2.28141±0.00000  bestvalidloss 2.28141  last_update 0\n",
      "train: iter 46  trainloss 2.15250  validloss 2.23092±0.00000  bestvalidloss 2.23092  last_update 0\n",
      "train: iter 47  trainloss 2.11596  validloss 2.21763±0.00000  bestvalidloss 2.21763  last_update 0\n",
      "train: iter 48  trainloss 2.05945  validloss 2.16907±0.00000  bestvalidloss 2.16907  last_update 0\n",
      "train: iter 49  trainloss 2.03901  validloss 2.11004±0.00000  bestvalidloss 2.11004  last_update 0\n",
      "train: iter 50  trainloss 1.99191  validloss 2.10917±0.00000  bestvalidloss 2.10917  last_update 0\n",
      "train: iter 51  trainloss 1.95910  validloss 2.06522±0.00000  bestvalidloss 2.06522  last_update 0\n",
      "train: iter 52  trainloss 1.91562  validloss 2.03271±0.00000  bestvalidloss 2.03271  last_update 0\n",
      "train: iter 53  trainloss 1.88834  validloss 2.02665±0.00000  bestvalidloss 2.02665  last_update 0\n",
      "train: iter 54  trainloss 1.83523  validloss 1.96665±0.00000  bestvalidloss 1.96665  last_update 0\n",
      "train: iter 55  trainloss 1.79231  validloss 1.92611±0.00000  bestvalidloss 1.92611  last_update 0\n",
      "train: iter 56  trainloss 1.76564  validloss 1.87988±0.00000  bestvalidloss 1.87988  last_update 0\n",
      "train: iter 57  trainloss 1.71804  validloss 1.87775±0.00000  bestvalidloss 1.87775  last_update 0\n",
      "train: iter 58  trainloss 1.68272  validloss 1.85105±0.00000  bestvalidloss 1.85105  last_update 0\n",
      "train: iter 59  trainloss 1.64421  validloss 1.82301±0.00000  bestvalidloss 1.82301  last_update 0\n",
      "train: iter 60  trainloss 1.57378  validloss 1.75845±0.00000  bestvalidloss 1.75845  last_update 0\n",
      "train: iter 61  trainloss 1.54377  validloss 1.73381±0.00000  bestvalidloss 1.73381  last_update 0\n",
      "train: iter 62  trainloss 1.50228  validloss 1.66992±0.00000  bestvalidloss 1.66992  last_update 0\n",
      "train: iter 63  trainloss 1.46477  validloss 1.63025±0.00000  bestvalidloss 1.63025  last_update 0\n",
      "train: iter 64  trainloss 1.41827  validloss 1.61031±0.00000  bestvalidloss 1.61031  last_update 0\n",
      "train: iter 65  trainloss 1.35632  validloss 1.56867±0.00000  bestvalidloss 1.56867  last_update 0\n",
      "train: iter 66  trainloss 1.30913  validloss 1.49578±0.00000  bestvalidloss 1.49578  last_update 0\n",
      "train: iter 67  trainloss 1.28026  validloss 1.50004±0.00000  bestvalidloss 1.49578  last_update 1\n",
      "train: iter 68  trainloss 1.23874  validloss 1.42279±0.00000  bestvalidloss 1.42279  last_update 0\n",
      "train: iter 69  trainloss 1.18156  validloss 1.39936±0.00000  bestvalidloss 1.39936  last_update 0\n",
      "train: iter 70  trainloss 1.15722  validloss 1.34347±0.00000  bestvalidloss 1.34347  last_update 0\n",
      "train: iter 71  trainloss 1.11368  validloss 1.33560±0.00000  bestvalidloss 1.33560  last_update 0\n",
      "train: iter 72  trainloss 1.06125  validloss 1.27570±0.00000  bestvalidloss 1.27570  last_update 0\n",
      "train: iter 73  trainloss 1.01811  validloss 1.21964±0.00000  bestvalidloss 1.21964  last_update 0\n",
      "train: iter 74  trainloss 1.00223  validloss 1.20978±0.00000  bestvalidloss 1.20978  last_update 0\n",
      "train: iter 75  trainloss 0.94737  validloss 1.16294±0.00000  bestvalidloss 1.16294  last_update 0\n",
      "train: iter 76  trainloss 0.89619  validloss 1.17698±0.00000  bestvalidloss 1.16294  last_update 1\n",
      "train: iter 77  trainloss 0.88294  validloss 1.09228±0.00000  bestvalidloss 1.09228  last_update 0\n",
      "train: iter 78  trainloss 0.84257  validloss 1.14290±0.00000  bestvalidloss 1.09228  last_update 1\n",
      "train: iter 79  trainloss 0.80512  validloss 1.03336±0.00000  bestvalidloss 1.03336  last_update 0\n",
      "train: iter 80  trainloss 0.78293  validloss 1.02667±0.00000  bestvalidloss 1.02667  last_update 0\n",
      "train: iter 81  trainloss 0.73915  validloss 1.00716±0.00000  bestvalidloss 1.00716  last_update 0\n",
      "train: iter 82  trainloss 0.71028  validloss 0.99609±0.00000  bestvalidloss 0.99609  last_update 0\n",
      "train: iter 83  trainloss 0.69259  validloss 0.93859±0.00000  bestvalidloss 0.93859  last_update 0\n",
      "train: iter 84  trainloss 0.66232  validloss 0.91187±0.00000  bestvalidloss 0.91187  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 0.63995  validloss 0.90232±0.00000  bestvalidloss 0.90232  last_update 0\n",
      "train: iter 86  trainloss 0.60305  validloss 0.86691±0.00000  bestvalidloss 0.86691  last_update 0\n",
      "train: iter 87  trainloss 0.57748  validloss 0.82275±0.00000  bestvalidloss 0.82275  last_update 0\n",
      "train: iter 88  trainloss 0.54142  validloss 0.83560±0.00000  bestvalidloss 0.82275  last_update 1\n",
      "train: iter 89  trainloss 0.55594  validloss 0.81207±0.00000  bestvalidloss 0.81207  last_update 0\n",
      "train: iter 90  trainloss 0.52181  validloss 0.81357±0.00000  bestvalidloss 0.81207  last_update 1\n",
      "train: iter 91  trainloss 0.49362  validloss 0.77412±0.00000  bestvalidloss 0.77412  last_update 0\n",
      "train: iter 92  trainloss 0.47615  validloss 0.76856±0.00000  bestvalidloss 0.76856  last_update 0\n",
      "train: iter 93  trainloss 0.45149  validloss 0.71312±0.00000  bestvalidloss 0.71312  last_update 0\n",
      "train: iter 94  trainloss 0.44062  validloss 0.69725±0.00000  bestvalidloss 0.69725  last_update 0\n",
      "train: iter 95  trainloss 0.42384  validloss 0.72838±0.00000  bestvalidloss 0.69725  last_update 1\n",
      "train: iter 96  trainloss 0.42383  validloss 0.73469±0.00000  bestvalidloss 0.69725  last_update 2\n",
      "train: iter 97  trainloss 0.39893  validloss 0.74722±0.00000  bestvalidloss 0.69725  last_update 3\n",
      "train: iter 98  trainloss 0.36540  validloss 0.68192±0.00000  bestvalidloss 0.68192  last_update 0\n",
      "train: iter 99  trainloss 0.35525  validloss 0.63169±0.00000  bestvalidloss 0.63169  last_update 0\n",
      "train: iter 100  trainloss 0.35598  validloss 0.65037±0.00000  bestvalidloss 0.63169  last_update 1\n",
      "train: iter 101  trainloss 0.34917  validloss 0.68525±0.00000  bestvalidloss 0.63169  last_update 2\n",
      "train: iter 102  trainloss 0.34660  validloss 0.64996±0.00000  bestvalidloss 0.63169  last_update 3\n",
      "train: iter 103  trainloss 0.33234  validloss 0.70943±0.00000  bestvalidloss 0.63169  last_update 4\n",
      "train: iter 104  trainloss 0.33692  validloss 0.68974±0.00000  bestvalidloss 0.63169  last_update 5\n",
      "train: iter 105  trainloss 0.32783  validloss 0.63771±0.00000  bestvalidloss 0.63169  last_update 6\n",
      "train: iter 106  trainloss 0.31332  validloss 0.65438±0.00000  bestvalidloss 0.63169  last_update 7\n",
      "train: iter 107  trainloss 0.30981  validloss 0.67365±0.00000  bestvalidloss 0.63169  last_update 8\n",
      "train: iter 108  trainloss 0.30943  validloss 0.62547±0.00000  bestvalidloss 0.62547  last_update 0\n",
      "train: iter 109  trainloss 0.29553  validloss 0.65251±0.00000  bestvalidloss 0.62547  last_update 1\n",
      "train: iter 110  trainloss 0.31861  validloss 0.67090±0.00000  bestvalidloss 0.62547  last_update 2\n",
      "train: iter 111  trainloss 0.30798  validloss 0.65376±0.00000  bestvalidloss 0.62547  last_update 3\n",
      "train: iter 112  trainloss 0.29764  validloss 0.64360±0.00000  bestvalidloss 0.62547  last_update 4\n",
      "train: iter 113  trainloss 0.31460  validloss 0.60847±0.00000  bestvalidloss 0.60847  last_update 0\n",
      "train: iter 114  trainloss 0.27886  validloss 0.66868±0.00000  bestvalidloss 0.60847  last_update 1\n",
      "train: iter 115  trainloss 0.29691  validloss 0.62509±0.00000  bestvalidloss 0.60847  last_update 2\n",
      "train: iter 116  trainloss 0.30590  validloss 0.67960±0.00000  bestvalidloss 0.60847  last_update 3\n",
      "train: iter 117  trainloss 0.31295  validloss 0.67093±0.00000  bestvalidloss 0.60847  last_update 4\n",
      "train: iter 118  trainloss 0.28721  validloss 0.63880±0.00000  bestvalidloss 0.60847  last_update 5\n",
      "train: iter 119  trainloss 0.29621  validloss 0.64297±0.00000  bestvalidloss 0.60847  last_update 6\n",
      "train: iter 120  trainloss 0.31080  validloss 0.66711±0.00000  bestvalidloss 0.60847  last_update 7\n",
      "train: iter 121  trainloss 0.31128  validloss 0.68110±0.00000  bestvalidloss 0.60847  last_update 8\n",
      "train: iter 122  trainloss 0.29060  validloss 0.63879±0.00000  bestvalidloss 0.60847  last_update 9\n",
      "train: iter 123  trainloss 0.26489  validloss 0.69944±0.00000  bestvalidloss 0.60847  last_update 10\n",
      "train: iter 124  trainloss 0.27560  validloss 0.63494±0.00000  bestvalidloss 0.60847  last_update 11\n",
      "train: iter 125  trainloss 0.28501  validloss 0.66062±0.00000  bestvalidloss 0.60847  last_update 12\n",
      "train: iter 126  trainloss 0.30903  validloss 0.66562±0.00000  bestvalidloss 0.60847  last_update 13\n",
      "train: iter 127  trainloss 0.27958  validloss 0.66221±0.00000  bestvalidloss 0.60847  last_update 14\n",
      "train: iter 128  trainloss 0.26686  validloss 0.69618±0.00000  bestvalidloss 0.60847  last_update 15\n",
      "train: iter 129  trainloss 0.29008  validloss 0.71114±0.00000  bestvalidloss 0.60847  last_update 16\n",
      "train: iter 130  trainloss 0.27068  validloss 0.65988±0.00000  bestvalidloss 0.60847  last_update 17\n",
      "train: iter 131  trainloss 0.25982  validloss 0.69792±0.00000  bestvalidloss 0.60847  last_update 18\n",
      "train: iter 132  trainloss 0.27719  validloss 0.66894±0.00000  bestvalidloss 0.60847  last_update 19\n",
      "train: iter 133  trainloss 0.26193  validloss 0.66402±0.00000  bestvalidloss 0.60847  last_update 20\n",
      "train: iter 134  trainloss 0.27495  validloss 0.71912±0.00000  bestvalidloss 0.60847  last_update 21\n",
      "train: iter 135  trainloss 0.27570  validloss 0.66295±0.00000  bestvalidloss 0.60847  last_update 22\n",
      "train: iter 136  trainloss 0.31212  validloss 0.69234±0.00000  bestvalidloss 0.60847  last_update 23\n",
      "train: iter 137  trainloss 0.28162  validloss 0.68690±0.00000  bestvalidloss 0.60847  last_update 24\n",
      "train: iter 138  trainloss 0.28323  validloss 0.67870±0.00000  bestvalidloss 0.60847  last_update 25\n",
      "train: iter 139  trainloss 0.28715  validloss 0.69040±0.00000  bestvalidloss 0.60847  last_update 26\n",
      "train: iter 140  trainloss 0.30655  validloss 0.69524±0.00000  bestvalidloss 0.60847  last_update 27\n",
      "train: iter 141  trainloss 0.26566  validloss 0.65751±0.00000  bestvalidloss 0.60847  last_update 28\n",
      "train: iter 142  trainloss 0.28373  validloss 0.66568±0.00000  bestvalidloss 0.60847  last_update 29\n",
      "train: iter 143  trainloss 0.28491  validloss 0.64746±0.00000  bestvalidloss 0.60847  last_update 30\n",
      "train: iter 144  trainloss 0.28277  validloss 0.69982±0.00000  bestvalidloss 0.60847  last_update 31\n",
      "train: iter 145  trainloss 0.28450  validloss 0.69698±0.00000  bestvalidloss 0.60847  last_update 32\n",
      "train: iter 146  trainloss 0.28096  validloss 0.67488±0.00000  bestvalidloss 0.60847  last_update 33\n",
      "train: iter 147  trainloss 0.27742  validloss 0.68446±0.00000  bestvalidloss 0.60847  last_update 34\n",
      "train: iter 148  trainloss 0.25779  validloss 0.67349±0.00000  bestvalidloss 0.60847  last_update 35\n",
      "train: iter 149  trainloss 0.28013  validloss 0.68696±0.00000  bestvalidloss 0.60847  last_update 36\n",
      "train: iter 150  trainloss 0.29664  validloss 0.70593±0.00000  bestvalidloss 0.60847  last_update 37\n",
      "train: iter 151  trainloss 0.29485  validloss 0.71837±0.00000  bestvalidloss 0.60847  last_update 38\n",
      "train: iter 152  trainloss 0.26330  validloss 0.69216±0.00000  bestvalidloss 0.60847  last_update 39\n",
      "train: iter 153  trainloss 0.29244  validloss 0.69024±0.00000  bestvalidloss 0.60847  last_update 40\n",
      "train: iter 154  trainloss 0.25842  validloss 0.74647±0.00000  bestvalidloss 0.60847  last_update 41\n",
      "train: iter 155  trainloss 0.29899  validloss 0.70163±0.00000  bestvalidloss 0.60847  last_update 42\n",
      "train: iter 156  trainloss 0.28008  validloss 0.65845±0.00000  bestvalidloss 0.60847  last_update 43\n",
      "train: iter 157  trainloss 0.27297  validloss 0.64302±0.00000  bestvalidloss 0.60847  last_update 44\n",
      "train: iter 158  trainloss 0.27491  validloss 0.69226±0.00000  bestvalidloss 0.60847  last_update 45\n",
      "train: iter 159  trainloss 0.27070  validloss 0.73059±0.00000  bestvalidloss 0.60847  last_update 46\n",
      "train: iter 160  trainloss 0.25690  validloss 0.73417±0.00000  bestvalidloss 0.60847  last_update 47\n",
      "train: iter 161  trainloss 0.27959  validloss 0.67386±0.00000  bestvalidloss 0.60847  last_update 48\n",
      "train: iter 162  trainloss 0.31130  validloss 0.67231±0.00000  bestvalidloss 0.60847  last_update 49\n",
      "train: iter 163  trainloss 0.27598  validloss 0.65596±0.00000  bestvalidloss 0.60847  last_update 50\n",
      "train: iter 164  trainloss 0.28690  validloss 0.67458±0.00000  bestvalidloss 0.60847  last_update 51\n",
      "train: iter 165  trainloss 0.28804  validloss 0.70941±0.00000  bestvalidloss 0.60847  last_update 52\n",
      "train: iter 166  trainloss 0.29194  validloss 0.64980±0.00000  bestvalidloss 0.60847  last_update 53\n",
      "train: iter 167  trainloss 0.28244  validloss 0.71758±0.00000  bestvalidloss 0.60847  last_update 54\n",
      "train: iter 168  trainloss 0.28710  validloss 0.67569±0.00000  bestvalidloss 0.60847  last_update 55\n",
      "train: iter 169  trainloss 0.29378  validloss 0.72782±0.00000  bestvalidloss 0.60847  last_update 56\n",
      "train: iter 170  trainloss 0.25907  validloss 0.67014±0.00000  bestvalidloss 0.60847  last_update 57\n",
      "train: iter 171  trainloss 0.26700  validloss 0.69420±0.00000  bestvalidloss 0.60847  last_update 58\n",
      "train: iter 172  trainloss 0.27116  validloss 0.68033±0.00000  bestvalidloss 0.60847  last_update 59\n",
      "train: iter 173  trainloss 0.30246  validloss 0.69540±0.00000  bestvalidloss 0.60847  last_update 60\n",
      "train: iter 174  trainloss 0.29536  validloss 0.70032±0.00000  bestvalidloss 0.60847  last_update 61\n",
      "train: iter 175  trainloss 0.27880  validloss 0.68736±0.00000  bestvalidloss 0.60847  last_update 62\n",
      "train: iter 176  trainloss 0.28790  validloss 0.70265±0.00000  bestvalidloss 0.60847  last_update 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 177  trainloss 0.27038  validloss 0.68586±0.00000  bestvalidloss 0.60847  last_update 64\n",
      "train: iter 178  trainloss 0.28623  validloss 0.69238±0.00000  bestvalidloss 0.60847  last_update 65\n",
      "train: iter 179  trainloss 0.29005  validloss 0.68010±0.00000  bestvalidloss 0.60847  last_update 66\n",
      "train: iter 180  trainloss 0.25849  validloss 0.67175±0.00000  bestvalidloss 0.60847  last_update 67\n",
      "train: iter 181  trainloss 0.28638  validloss 0.76310±0.00000  bestvalidloss 0.60847  last_update 68\n",
      "train: iter 182  trainloss 0.27803  validloss 0.69222±0.00000  bestvalidloss 0.60847  last_update 69\n",
      "train: iter 183  trainloss 0.28687  validloss 0.67180±0.00000  bestvalidloss 0.60847  last_update 70\n",
      "train: iter 184  trainloss 0.30873  validloss 0.67900±0.00000  bestvalidloss 0.60847  last_update 71\n",
      "train: iter 185  trainloss 0.30159  validloss 0.73278±0.00000  bestvalidloss 0.60847  last_update 72\n",
      "train: iter 186  trainloss 0.27670  validloss 0.69137±0.00000  bestvalidloss 0.60847  last_update 73\n",
      "train: iter 187  trainloss 0.28640  validloss 0.65777±0.00000  bestvalidloss 0.60847  last_update 74\n",
      "train: iter 188  trainloss 0.26518  validloss 0.69063±0.00000  bestvalidloss 0.60847  last_update 75\n",
      "train: iter 189  trainloss 0.27822  validloss 0.66349±0.00000  bestvalidloss 0.60847  last_update 76\n",
      "train: iter 190  trainloss 0.28933  validloss 0.66567±0.00000  bestvalidloss 0.60847  last_update 77\n",
      "train: iter 191  trainloss 0.29045  validloss 0.74774±0.00000  bestvalidloss 0.60847  last_update 78\n",
      "train: iter 192  trainloss 0.28174  validloss 0.69632±0.00000  bestvalidloss 0.60847  last_update 79\n",
      "train: iter 193  trainloss 0.25861  validloss 0.68358±0.00000  bestvalidloss 0.60847  last_update 80\n",
      "train: iter 194  trainloss 0.28156  validloss 0.73589±0.00000  bestvalidloss 0.60847  last_update 81\n",
      "train: iter 195  trainloss 0.27567  validloss 0.67114±0.00000  bestvalidloss 0.60847  last_update 82\n",
      "train: iter 196  trainloss 0.26797  validloss 0.68657±0.00000  bestvalidloss 0.60847  last_update 83\n",
      "train: iter 197  trainloss 0.28841  validloss 0.66705±0.00000  bestvalidloss 0.60847  last_update 84\n",
      "train: iter 198  trainloss 0.28161  validloss 0.60215±0.00000  bestvalidloss 0.60215  last_update 0\n",
      "train: iter 199  trainloss 0.29199  validloss 0.63807±0.00000  bestvalidloss 0.60215  last_update 1\n",
      "train: iter 200  trainloss 0.26403  validloss 0.70606±0.00000  bestvalidloss 0.60215  last_update 2\n",
      "train: iter 201  trainloss 0.26543  validloss 0.64147±0.00000  bestvalidloss 0.60215  last_update 3\n",
      "train: iter 202  trainloss 0.29423  validloss 0.69734±0.00000  bestvalidloss 0.60215  last_update 4\n",
      "train: iter 203  trainloss 0.27227  validloss 0.68207±0.00000  bestvalidloss 0.60215  last_update 5\n",
      "train: iter 204  trainloss 0.30351  validloss 0.63372±0.00000  bestvalidloss 0.60215  last_update 6\n",
      "train: iter 205  trainloss 0.28952  validloss 0.66079±0.00000  bestvalidloss 0.60215  last_update 7\n",
      "train: iter 206  trainloss 0.28508  validloss 0.67078±0.00000  bestvalidloss 0.60215  last_update 8\n",
      "train: iter 207  trainloss 0.29379  validloss 0.64202±0.00000  bestvalidloss 0.60215  last_update 9\n",
      "train: iter 208  trainloss 0.28781  validloss 0.66049±0.00000  bestvalidloss 0.60215  last_update 10\n",
      "train: iter 209  trainloss 0.29854  validloss 0.66812±0.00000  bestvalidloss 0.60215  last_update 11\n",
      "train: iter 210  trainloss 0.30873  validloss 0.69133±0.00000  bestvalidloss 0.60215  last_update 12\n",
      "train: iter 211  trainloss 0.26240  validloss 0.71000±0.00000  bestvalidloss 0.60215  last_update 13\n",
      "train: iter 212  trainloss 0.27451  validloss 0.67403±0.00000  bestvalidloss 0.60215  last_update 14\n",
      "train: iter 213  trainloss 0.29179  validloss 0.68106±0.00000  bestvalidloss 0.60215  last_update 15\n",
      "train: iter 214  trainloss 0.28351  validloss 0.67513±0.00000  bestvalidloss 0.60215  last_update 16\n",
      "train: iter 215  trainloss 0.29785  validloss 0.68943±0.00000  bestvalidloss 0.60215  last_update 17\n",
      "train: iter 216  trainloss 0.25389  validloss 0.62429±0.00000  bestvalidloss 0.60215  last_update 18\n",
      "train: iter 217  trainloss 0.26657  validloss 0.65904±0.00000  bestvalidloss 0.60215  last_update 19\n",
      "train: iter 218  trainloss 0.27016  validloss 0.68426±0.00000  bestvalidloss 0.60215  last_update 20\n",
      "train: iter 219  trainloss 0.27715  validloss 0.66979±0.00000  bestvalidloss 0.60215  last_update 21\n",
      "train: iter 220  trainloss 0.27471  validloss 0.77668±0.00000  bestvalidloss 0.60215  last_update 22\n",
      "train: iter 221  trainloss 0.28926  validloss 0.68723±0.00000  bestvalidloss 0.60215  last_update 23\n",
      "train: iter 222  trainloss 0.27331  validloss 0.72953±0.00000  bestvalidloss 0.60215  last_update 24\n",
      "train: iter 223  trainloss 0.29484  validloss 0.69764±0.00000  bestvalidloss 0.60215  last_update 25\n",
      "train: iter 224  trainloss 0.26543  validloss 0.68810±0.00000  bestvalidloss 0.60215  last_update 26\n",
      "train: iter 225  trainloss 0.28759  validloss 0.72057±0.00000  bestvalidloss 0.60215  last_update 27\n",
      "train: iter 226  trainloss 0.27995  validloss 0.65334±0.00000  bestvalidloss 0.60215  last_update 28\n",
      "train: iter 227  trainloss 0.26804  validloss 0.68904±0.00000  bestvalidloss 0.60215  last_update 29\n",
      "train: iter 228  trainloss 0.27300  validloss 0.64637±0.00000  bestvalidloss 0.60215  last_update 30\n",
      "train: iter 229  trainloss 0.28956  validloss 0.68583±0.00000  bestvalidloss 0.60215  last_update 31\n",
      "train: iter 230  trainloss 0.26821  validloss 0.66913±0.00000  bestvalidloss 0.60215  last_update 32\n",
      "train: iter 231  trainloss 0.29037  validloss 0.70194±0.00000  bestvalidloss 0.60215  last_update 33\n",
      "train: iter 232  trainloss 0.26590  validloss 0.65962±0.00000  bestvalidloss 0.60215  last_update 34\n",
      "train: iter 233  trainloss 0.27736  validloss 0.71342±0.00000  bestvalidloss 0.60215  last_update 35\n",
      "train: iter 234  trainloss 0.28399  validloss 0.69509±0.00000  bestvalidloss 0.60215  last_update 36\n",
      "train: iter 235  trainloss 0.28304  validloss 0.65844±0.00000  bestvalidloss 0.60215  last_update 37\n",
      "train: iter 236  trainloss 0.29354  validloss 0.66565±0.00000  bestvalidloss 0.60215  last_update 38\n",
      "train: iter 237  trainloss 0.28867  validloss 0.61954±0.00000  bestvalidloss 0.60215  last_update 39\n",
      "train: iter 238  trainloss 0.27849  validloss 0.71760±0.00000  bestvalidloss 0.60215  last_update 40\n",
      "train: iter 239  trainloss 0.31938  validloss 0.62452±0.00000  bestvalidloss 0.60215  last_update 41\n",
      "train: iter 240  trainloss 0.26418  validloss 0.73987±0.00000  bestvalidloss 0.60215  last_update 42\n",
      "train: iter 241  trainloss 0.28880  validloss 0.71252±0.00000  bestvalidloss 0.60215  last_update 43\n",
      "train: iter 242  trainloss 0.28769  validloss 0.66785±0.00000  bestvalidloss 0.60215  last_update 44\n",
      "train: iter 243  trainloss 0.28553  validloss 0.69611±0.00000  bestvalidloss 0.60215  last_update 45\n",
      "train: iter 244  trainloss 0.29056  validloss 0.65431±0.00000  bestvalidloss 0.60215  last_update 46\n",
      "train: iter 245  trainloss 0.27446  validloss 0.68343±0.00000  bestvalidloss 0.60215  last_update 47\n",
      "train: iter 246  trainloss 0.25959  validloss 0.64442±0.00000  bestvalidloss 0.60215  last_update 48\n",
      "train: iter 247  trainloss 0.27636  validloss 0.68675±0.00000  bestvalidloss 0.60215  last_update 49\n",
      "train: iter 248  trainloss 0.28807  validloss 0.67892±0.00000  bestvalidloss 0.60215  last_update 50\n",
      "train: iter 249  trainloss 0.27892  validloss 0.67778±0.00000  bestvalidloss 0.60215  last_update 51\n",
      "train: iter 250  trainloss 0.30008  validloss 0.67672±0.00000  bestvalidloss 0.60215  last_update 52\n",
      "train: iter 251  trainloss 0.28248  validloss 0.72695±0.00000  bestvalidloss 0.60215  last_update 53\n",
      "train: iter 252  trainloss 0.27723  validloss 0.68625±0.00000  bestvalidloss 0.60215  last_update 54\n",
      "train: iter 253  trainloss 0.29484  validloss 0.65632±0.00000  bestvalidloss 0.60215  last_update 55\n",
      "train: iter 254  trainloss 0.28026  validloss 0.66459±0.00000  bestvalidloss 0.60215  last_update 56\n",
      "train: iter 255  trainloss 0.26397  validloss 0.71478±0.00000  bestvalidloss 0.60215  last_update 57\n",
      "train: iter 256  trainloss 0.28364  validloss 0.72572±0.00000  bestvalidloss 0.60215  last_update 58\n",
      "train: iter 257  trainloss 0.28818  validloss 0.65005±0.00000  bestvalidloss 0.60215  last_update 59\n",
      "train: iter 258  trainloss 0.27993  validloss 0.69722±0.00000  bestvalidloss 0.60215  last_update 60\n",
      "train: iter 259  trainloss 0.26035  validloss 0.67606±0.00000  bestvalidloss 0.60215  last_update 61\n",
      "train: iter 260  trainloss 0.27510  validloss 0.69785±0.00000  bestvalidloss 0.60215  last_update 62\n",
      "train: iter 261  trainloss 0.29710  validloss 0.68356±0.00000  bestvalidloss 0.60215  last_update 63\n",
      "train: iter 262  trainloss 0.28633  validloss 0.70114±0.00000  bestvalidloss 0.60215  last_update 64\n",
      "train: iter 263  trainloss 0.28712  validloss 0.68965±0.00000  bestvalidloss 0.60215  last_update 65\n",
      "train: iter 264  trainloss 0.28374  validloss 0.68152±0.00000  bestvalidloss 0.60215  last_update 66\n",
      "train: iter 265  trainloss 0.25540  validloss 0.65649±0.00000  bestvalidloss 0.60215  last_update 67\n",
      "train: iter 266  trainloss 0.26981  validloss 0.70414±0.00000  bestvalidloss 0.60215  last_update 68\n",
      "train: iter 267  trainloss 0.26781  validloss 0.70096±0.00000  bestvalidloss 0.60215  last_update 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 268  trainloss 0.27662  validloss 0.70091±0.00000  bestvalidloss 0.60215  last_update 70\n",
      "train: iter 269  trainloss 0.26763  validloss 0.70088±0.00000  bestvalidloss 0.60215  last_update 71\n",
      "train: iter 270  trainloss 0.25382  validloss 0.70468±0.00000  bestvalidloss 0.60215  last_update 72\n",
      "train: iter 271  trainloss 0.25653  validloss 0.68255±0.00000  bestvalidloss 0.60215  last_update 73\n",
      "train: iter 272  trainloss 0.29394  validloss 0.65934±0.00000  bestvalidloss 0.60215  last_update 74\n",
      "train: iter 273  trainloss 0.26577  validloss 0.75073±0.00000  bestvalidloss 0.60215  last_update 75\n",
      "train: iter 274  trainloss 0.29776  validloss 0.69732±0.00000  bestvalidloss 0.60215  last_update 76\n",
      "train: iter 275  trainloss 0.28318  validloss 0.68339±0.00000  bestvalidloss 0.60215  last_update 77\n",
      "train: iter 276  trainloss 0.28682  validloss 0.70202±0.00000  bestvalidloss 0.60215  last_update 78\n",
      "train: iter 277  trainloss 0.28470  validloss 0.70813±0.00000  bestvalidloss 0.60215  last_update 79\n",
      "train: iter 278  trainloss 0.26445  validloss 0.67317±0.00000  bestvalidloss 0.60215  last_update 80\n",
      "train: iter 279  trainloss 0.28477  validloss 0.64787±0.00000  bestvalidloss 0.60215  last_update 81\n",
      "train: iter 280  trainloss 0.27379  validloss 0.65499±0.00000  bestvalidloss 0.60215  last_update 82\n",
      "train: iter 281  trainloss 0.28899  validloss 0.66098±0.00000  bestvalidloss 0.60215  last_update 83\n",
      "train: iter 282  trainloss 0.26397  validloss 0.66750±0.00000  bestvalidloss 0.60215  last_update 84\n",
      "train: iter 283  trainloss 0.29053  validloss 0.67529±0.00000  bestvalidloss 0.60215  last_update 85\n",
      "train: iter 284  trainloss 0.28275  validloss 0.71635±0.00000  bestvalidloss 0.60215  last_update 86\n",
      "train: iter 285  trainloss 0.28561  validloss 0.68115±0.00000  bestvalidloss 0.60215  last_update 87\n",
      "train: iter 286  trainloss 0.28596  validloss 0.69756±0.00000  bestvalidloss 0.60215  last_update 88\n",
      "train: iter 287  trainloss 0.29276  validloss 0.71329±0.00000  bestvalidloss 0.60215  last_update 89\n",
      "train: iter 288  trainloss 0.28695  validloss 0.74994±0.00000  bestvalidloss 0.60215  last_update 90\n",
      "train: iter 289  trainloss 0.26954  validloss 0.67661±0.00000  bestvalidloss 0.60215  last_update 91\n",
      "train: iter 290  trainloss 0.28789  validloss 0.63741±0.00000  bestvalidloss 0.60215  last_update 92\n",
      "train: iter 291  trainloss 0.27464  validloss 0.66193±0.00000  bestvalidloss 0.60215  last_update 93\n",
      "train: iter 292  trainloss 0.26694  validloss 0.67020±0.00000  bestvalidloss 0.60215  last_update 94\n",
      "train: iter 293  trainloss 0.28872  validloss 0.69078±0.00000  bestvalidloss 0.60215  last_update 95\n",
      "train: iter 294  trainloss 0.29138  validloss 0.68485±0.00000  bestvalidloss 0.60215  last_update 96\n",
      "train: iter 295  trainloss 0.29112  validloss 0.66663±0.00000  bestvalidloss 0.60215  last_update 97\n",
      "train: iter 296  trainloss 0.30224  validloss 0.67137±0.00000  bestvalidloss 0.60215  last_update 98\n",
      "train: iter 297  trainloss 0.30610  validloss 0.64806±0.00000  bestvalidloss 0.60215  last_update 99\n",
      "train: iter 298  trainloss 0.27493  validloss 0.61768±0.00000  bestvalidloss 0.60215  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.9208, -3.6822, -2.3639, -2.7487], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 97.47503  validloss 96.38143±0.00000  bestvalidloss 96.38143  last_update 0\n",
      "train: iter 1  trainloss 71.89032  validloss 76.02031±0.00000  bestvalidloss 76.02031  last_update 0\n",
      "train: iter 2  trainloss 51.72721  validloss 52.97691±0.00000  bestvalidloss 52.97691  last_update 0\n",
      "train: iter 3  trainloss 39.48993  validloss 39.36514±0.00000  bestvalidloss 39.36514  last_update 0\n",
      "train: iter 4  trainloss 30.74761  validloss 30.75997±0.00000  bestvalidloss 30.75997  last_update 0\n",
      "train: iter 5  trainloss 24.11822  validloss 24.36311±0.00000  bestvalidloss 24.36311  last_update 0\n",
      "train: iter 6  trainloss 18.99544  validloss 19.49599±0.00000  bestvalidloss 19.49599  last_update 0\n",
      "train: iter 7  trainloss 14.98237  validloss 15.92467±0.00000  bestvalidloss 15.92467  last_update 0\n",
      "train: iter 8  trainloss 11.87992  validloss 13.30599±0.00000  bestvalidloss 13.30599  last_update 0\n",
      "train: iter 9  trainloss 9.46315  validloss 11.34036±0.00000  bestvalidloss 11.34036  last_update 0\n",
      "train: iter 10  trainloss 7.62624  validloss 9.80472±0.00000  bestvalidloss 9.80472  last_update 0\n",
      "train: iter 11  trainloss 6.24505  validloss 8.80021±0.00000  bestvalidloss 8.80021  last_update 0\n",
      "train: iter 12  trainloss 5.14443  validloss 8.20255±0.00000  bestvalidloss 8.20255  last_update 0\n",
      "train: iter 13  trainloss 4.40436  validloss 7.80380±0.00000  bestvalidloss 7.80380  last_update 0\n",
      "train: iter 14  trainloss 3.85661  validloss 7.45926±0.00000  bestvalidloss 7.45926  last_update 0\n",
      "train: iter 15  trainloss 3.45100  validloss 7.49192±0.00000  bestvalidloss 7.45926  last_update 1\n",
      "train: iter 16  trainloss 3.16447  validloss 7.38673±0.00000  bestvalidloss 7.38673  last_update 0\n",
      "train: iter 17  trainloss 2.98915  validloss 7.31843±0.00000  bestvalidloss 7.31843  last_update 0\n",
      "train: iter 18  trainloss 2.80308  validloss 7.69657±0.00000  bestvalidloss 7.31843  last_update 1\n",
      "train: iter 19  trainloss 2.72385  validloss 7.48471±0.00000  bestvalidloss 7.31843  last_update 2\n",
      "train: iter 20  trainloss 2.59198  validloss 7.48058±0.00000  bestvalidloss 7.31843  last_update 3\n",
      "train: iter 21  trainloss 2.52780  validloss 7.56836±0.00000  bestvalidloss 7.31843  last_update 4\n",
      "train: iter 22  trainloss 2.44678  validloss 7.69851±0.00000  bestvalidloss 7.31843  last_update 5\n",
      "train: iter 23  trainloss 2.41603  validloss 7.61172±0.00000  bestvalidloss 7.31843  last_update 6\n",
      "train: iter 24  trainloss 2.34777  validloss 7.52602±0.00000  bestvalidloss 7.31843  last_update 7\n",
      "train: iter 25  trainloss 2.26672  validloss 7.39958±0.00000  bestvalidloss 7.31843  last_update 8\n",
      "train: iter 26  trainloss 2.24209  validloss 7.33356±0.00000  bestvalidloss 7.31843  last_update 9\n",
      "train: iter 27  trainloss 2.20902  validloss 7.39177±0.00000  bestvalidloss 7.31843  last_update 10\n",
      "train: iter 28  trainloss 2.18596  validloss 7.47479±0.00000  bestvalidloss 7.31843  last_update 11\n",
      "train: iter 29  trainloss 2.15058  validloss 7.33981±0.00000  bestvalidloss 7.31843  last_update 12\n",
      "train: iter 30  trainloss 2.15997  validloss 7.43190±0.00000  bestvalidloss 7.31843  last_update 13\n",
      "train: iter 31  trainloss 2.14431  validloss 7.47297±0.00000  bestvalidloss 7.31843  last_update 14\n",
      "train: iter 32  trainloss 2.14456  validloss 7.38242±0.00000  bestvalidloss 7.31843  last_update 15\n",
      "train: iter 33  trainloss 2.09693  validloss 7.41174±0.00000  bestvalidloss 7.31843  last_update 16\n",
      "train: iter 34  trainloss 2.09603  validloss 7.37347±0.00000  bestvalidloss 7.31843  last_update 17\n",
      "train: iter 35  trainloss 2.08851  validloss 7.48192±0.00000  bestvalidloss 7.31843  last_update 18\n",
      "train: iter 36  trainloss 2.03106  validloss 7.29393±0.00000  bestvalidloss 7.29393  last_update 0\n",
      "train: iter 37  trainloss 1.98589  validloss 7.19953±0.00000  bestvalidloss 7.19953  last_update 0\n",
      "train: iter 38  trainloss 1.98857  validloss 6.69321±0.00000  bestvalidloss 6.69321  last_update 0\n",
      "train: iter 39  trainloss 1.90189  validloss 6.51125±0.00000  bestvalidloss 6.51125  last_update 0\n",
      "train: iter 40  trainloss 1.83381  validloss 5.82649±0.00000  bestvalidloss 5.82649  last_update 0\n",
      "train: iter 41  trainloss 1.77589  validloss 5.95280±0.00000  bestvalidloss 5.82649  last_update 1\n",
      "train: iter 42  trainloss 1.71803  validloss 5.64264±0.00000  bestvalidloss 5.64264  last_update 0\n",
      "train: iter 43  trainloss 1.62439  validloss 5.59239±0.00000  bestvalidloss 5.59239  last_update 0\n",
      "train: iter 44  trainloss 1.65356  validloss 5.59406±0.00000  bestvalidloss 5.59239  last_update 1\n",
      "train: iter 45  trainloss 1.57891  validloss 5.34144±0.00000  bestvalidloss 5.34144  last_update 0\n",
      "train: iter 46  trainloss 1.56664  validloss 5.20658±0.00000  bestvalidloss 5.20658  last_update 0\n",
      "train: iter 47  trainloss 1.54387  validloss 5.35002±0.00000  bestvalidloss 5.20658  last_update 1\n",
      "train: iter 48  trainloss 1.54357  validloss 4.78118±0.00000  bestvalidloss 4.78118  last_update 0\n",
      "train: iter 49  trainloss 1.48622  validloss 5.39924±0.00000  bestvalidloss 4.78118  last_update 1\n",
      "train: iter 50  trainloss 1.50417  validloss 5.15821±0.00000  bestvalidloss 4.78118  last_update 2\n",
      "train: iter 51  trainloss 1.49603  validloss 5.07352±0.00000  bestvalidloss 4.78118  last_update 3\n",
      "train: iter 52  trainloss 1.50382  validloss 4.99819±0.00000  bestvalidloss 4.78118  last_update 4\n",
      "train: iter 53  trainloss 1.50837  validloss 4.94192±0.00000  bestvalidloss 4.78118  last_update 5\n",
      "train: iter 54  trainloss 1.48712  validloss 5.27166±0.00000  bestvalidloss 4.78118  last_update 6\n",
      "train: iter 55  trainloss 1.43629  validloss 5.27225±0.00000  bestvalidloss 4.78118  last_update 7\n",
      "train: iter 56  trainloss 1.45820  validloss 5.02865±0.00000  bestvalidloss 4.78118  last_update 8\n",
      "train: iter 57  trainloss 1.43460  validloss 5.68009±0.00000  bestvalidloss 4.78118  last_update 9\n",
      "train: iter 58  trainloss 1.51603  validloss 4.74524±0.00000  bestvalidloss 4.74524  last_update 0\n",
      "train: iter 59  trainloss 1.41675  validloss 5.22460±0.00000  bestvalidloss 4.74524  last_update 1\n",
      "train: iter 60  trainloss 1.45696  validloss 5.03566±0.00000  bestvalidloss 4.74524  last_update 2\n",
      "train: iter 61  trainloss 1.43763  validloss 5.07436±0.00000  bestvalidloss 4.74524  last_update 3\n",
      "train: iter 62  trainloss 1.43847  validloss 5.04178±0.00000  bestvalidloss 4.74524  last_update 4\n",
      "train: iter 63  trainloss 1.45586  validloss 4.89299±0.00000  bestvalidloss 4.74524  last_update 5\n",
      "train: iter 64  trainloss 1.42803  validloss 4.77896±0.00000  bestvalidloss 4.74524  last_update 6\n",
      "train: iter 65  trainloss 1.45216  validloss 4.88993±0.00000  bestvalidloss 4.74524  last_update 7\n",
      "train: iter 66  trainloss 1.43994  validloss 5.21507±0.00000  bestvalidloss 4.74524  last_update 8\n",
      "train: iter 67  trainloss 1.41514  validloss 5.02928±0.00000  bestvalidloss 4.74524  last_update 9\n",
      "train: iter 68  trainloss 1.42939  validloss 4.82356±0.00000  bestvalidloss 4.74524  last_update 10\n",
      "train: iter 69  trainloss 1.42115  validloss 4.92247±0.00000  bestvalidloss 4.74524  last_update 11\n",
      "train: iter 70  trainloss 1.41561  validloss 4.95898±0.00000  bestvalidloss 4.74524  last_update 12\n",
      "train: iter 71  trainloss 1.41640  validloss 5.01277±0.00000  bestvalidloss 4.74524  last_update 13\n",
      "train: iter 72  trainloss 1.46913  validloss 5.11386±0.00000  bestvalidloss 4.74524  last_update 14\n",
      "train: iter 73  trainloss 1.45318  validloss 5.25480±0.00000  bestvalidloss 4.74524  last_update 15\n",
      "train: iter 74  trainloss 1.41980  validloss 4.86158±0.00000  bestvalidloss 4.74524  last_update 16\n",
      "train: iter 75  trainloss 1.46364  validloss 4.84707±0.00000  bestvalidloss 4.74524  last_update 17\n",
      "train: iter 76  trainloss 1.44770  validloss 5.22043±0.00000  bestvalidloss 4.74524  last_update 18\n",
      "train: iter 77  trainloss 1.44775  validloss 5.21648±0.00000  bestvalidloss 4.74524  last_update 19\n",
      "train: iter 78  trainloss 1.44507  validloss 4.90046±0.00000  bestvalidloss 4.74524  last_update 20\n",
      "train: iter 79  trainloss 1.44693  validloss 5.06431±0.00000  bestvalidloss 4.74524  last_update 21\n",
      "train: iter 80  trainloss 1.45805  validloss 5.04234±0.00000  bestvalidloss 4.74524  last_update 22\n",
      "train: iter 81  trainloss 1.44572  validloss 5.12737±0.00000  bestvalidloss 4.74524  last_update 23\n",
      "train: iter 82  trainloss 1.44431  validloss 5.00498±0.00000  bestvalidloss 4.74524  last_update 24\n",
      "train: iter 83  trainloss 1.44855  validloss 4.85882±0.00000  bestvalidloss 4.74524  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 1.44611  validloss 4.98591±0.00000  bestvalidloss 4.74524  last_update 26\n",
      "train: iter 85  trainloss 1.44091  validloss 4.81011±0.00000  bestvalidloss 4.74524  last_update 27\n",
      "train: iter 86  trainloss 1.38591  validloss 4.87490±0.00000  bestvalidloss 4.74524  last_update 28\n",
      "train: iter 87  trainloss 1.45496  validloss 5.34552±0.00000  bestvalidloss 4.74524  last_update 29\n",
      "train: iter 88  trainloss 1.42404  validloss 5.00031±0.00000  bestvalidloss 4.74524  last_update 30\n",
      "train: iter 89  trainloss 1.41773  validloss 4.82080±0.00000  bestvalidloss 4.74524  last_update 31\n",
      "train: iter 90  trainloss 1.42907  validloss 4.80439±0.00000  bestvalidloss 4.74524  last_update 32\n",
      "train: iter 91  trainloss 1.43622  validloss 5.03803±0.00000  bestvalidloss 4.74524  last_update 33\n",
      "train: iter 92  trainloss 1.42202  validloss 4.89283±0.00000  bestvalidloss 4.74524  last_update 34\n",
      "train: iter 93  trainloss 1.44766  validloss 4.87039±0.00000  bestvalidloss 4.74524  last_update 35\n",
      "train: iter 94  trainloss 1.40399  validloss 4.96409±0.00000  bestvalidloss 4.74524  last_update 36\n",
      "train: iter 95  trainloss 1.43367  validloss 4.87424±0.00000  bestvalidloss 4.74524  last_update 37\n",
      "train: iter 96  trainloss 1.42402  validloss 4.78735±0.00000  bestvalidloss 4.74524  last_update 38\n",
      "train: iter 97  trainloss 1.43238  validloss 4.90825±0.00000  bestvalidloss 4.74524  last_update 39\n",
      "train: iter 98  trainloss 1.43218  validloss 4.84635±0.00000  bestvalidloss 4.74524  last_update 40\n",
      "train: iter 99  trainloss 1.41485  validloss 4.91312±0.00000  bestvalidloss 4.74524  last_update 41\n",
      "train: iter 100  trainloss 1.41826  validloss 5.18405±0.00000  bestvalidloss 4.74524  last_update 42\n",
      "train: iter 101  trainloss 1.44000  validloss 4.94018±0.00000  bestvalidloss 4.74524  last_update 43\n",
      "train: iter 102  trainloss 1.42955  validloss 5.09379±0.00000  bestvalidloss 4.74524  last_update 44\n",
      "train: iter 103  trainloss 1.42403  validloss 5.01962±0.00000  bestvalidloss 4.74524  last_update 45\n",
      "train: iter 104  trainloss 1.43686  validloss 5.01253±0.00000  bestvalidloss 4.74524  last_update 46\n",
      "train: iter 105  trainloss 1.42796  validloss 5.07819±0.00000  bestvalidloss 4.74524  last_update 47\n",
      "train: iter 106  trainloss 1.41968  validloss 4.85453±0.00000  bestvalidloss 4.74524  last_update 48\n",
      "train: iter 107  trainloss 1.41289  validloss 5.12635±0.00000  bestvalidloss 4.74524  last_update 49\n",
      "train: iter 108  trainloss 1.40184  validloss 4.99659±0.00000  bestvalidloss 4.74524  last_update 50\n",
      "train: iter 109  trainloss 1.40525  validloss 5.39265±0.00000  bestvalidloss 4.74524  last_update 51\n",
      "train: iter 110  trainloss 1.41013  validloss 5.01906±0.00000  bestvalidloss 4.74524  last_update 52\n",
      "train: iter 111  trainloss 1.44677  validloss 4.91694±0.00000  bestvalidloss 4.74524  last_update 53\n",
      "train: iter 112  trainloss 1.41625  validloss 5.12792±0.00000  bestvalidloss 4.74524  last_update 54\n",
      "train: iter 113  trainloss 1.41148  validloss 4.85185±0.00000  bestvalidloss 4.74524  last_update 55\n",
      "train: iter 114  trainloss 1.41941  validloss 5.05334±0.00000  bestvalidloss 4.74524  last_update 56\n",
      "train: iter 115  trainloss 1.43048  validloss 5.30675±0.00000  bestvalidloss 4.74524  last_update 57\n",
      "train: iter 116  trainloss 1.43421  validloss 4.94697±0.00000  bestvalidloss 4.74524  last_update 58\n",
      "train: iter 117  trainloss 1.42435  validloss 5.27459±0.00000  bestvalidloss 4.74524  last_update 59\n",
      "train: iter 118  trainloss 1.41976  validloss 5.05770±0.00000  bestvalidloss 4.74524  last_update 60\n",
      "train: iter 119  trainloss 1.42309  validloss 4.82675±0.00000  bestvalidloss 4.74524  last_update 61\n",
      "train: iter 120  trainloss 1.39419  validloss 5.03852±0.00000  bestvalidloss 4.74524  last_update 62\n",
      "train: iter 121  trainloss 1.42286  validloss 5.27781±0.00000  bestvalidloss 4.74524  last_update 63\n",
      "train: iter 122  trainloss 1.41430  validloss 5.06770±0.00000  bestvalidloss 4.74524  last_update 64\n",
      "train: iter 123  trainloss 1.39977  validloss 5.06487±0.00000  bestvalidloss 4.74524  last_update 65\n",
      "train: iter 124  trainloss 1.42474  validloss 4.96313±0.00000  bestvalidloss 4.74524  last_update 66\n",
      "train: iter 125  trainloss 1.40862  validloss 5.11101±0.00000  bestvalidloss 4.74524  last_update 67\n",
      "train: iter 126  trainloss 1.42563  validloss 5.13406±0.00000  bestvalidloss 4.74524  last_update 68\n",
      "train: iter 127  trainloss 1.41251  validloss 4.96318±0.00000  bestvalidloss 4.74524  last_update 69\n",
      "train: iter 128  trainloss 1.40811  validloss 5.05925±0.00000  bestvalidloss 4.74524  last_update 70\n",
      "train: iter 129  trainloss 1.40207  validloss 5.10653±0.00000  bestvalidloss 4.74524  last_update 71\n",
      "train: iter 130  trainloss 1.41995  validloss 5.13933±0.00000  bestvalidloss 4.74524  last_update 72\n",
      "train: iter 131  trainloss 1.41048  validloss 5.00183±0.00000  bestvalidloss 4.74524  last_update 73\n",
      "train: iter 132  trainloss 1.41586  validloss 5.02327±0.00000  bestvalidloss 4.74524  last_update 74\n",
      "train: iter 133  trainloss 1.41643  validloss 5.01606±0.00000  bestvalidloss 4.74524  last_update 75\n",
      "train: iter 134  trainloss 1.39057  validloss 5.01903±0.00000  bestvalidloss 4.74524  last_update 76\n",
      "train: iter 135  trainloss 1.42697  validloss 5.10776±0.00000  bestvalidloss 4.74524  last_update 77\n",
      "train: iter 136  trainloss 1.43194  validloss 5.06371±0.00000  bestvalidloss 4.74524  last_update 78\n",
      "train: iter 137  trainloss 1.46313  validloss 5.11072±0.00000  bestvalidloss 4.74524  last_update 79\n",
      "train: iter 138  trainloss 1.42798  validloss 5.13987±0.00000  bestvalidloss 4.74524  last_update 80\n",
      "train: iter 139  trainloss 1.45017  validloss 4.89705±0.00000  bestvalidloss 4.74524  last_update 81\n",
      "train: iter 140  trainloss 1.42218  validloss 4.91689±0.00000  bestvalidloss 4.74524  last_update 82\n",
      "train: iter 141  trainloss 1.42926  validloss 5.12154±0.00000  bestvalidloss 4.74524  last_update 83\n",
      "train: iter 142  trainloss 1.42945  validloss 4.89862±0.00000  bestvalidloss 4.74524  last_update 84\n",
      "train: iter 143  trainloss 1.42865  validloss 5.31372±0.00000  bestvalidloss 4.74524  last_update 85\n",
      "train: iter 144  trainloss 1.41638  validloss 4.97967±0.00000  bestvalidloss 4.74524  last_update 86\n",
      "train: iter 145  trainloss 1.38423  validloss 4.98014±0.00000  bestvalidloss 4.74524  last_update 87\n",
      "train: iter 146  trainloss 1.42973  validloss 4.84799±0.00000  bestvalidloss 4.74524  last_update 88\n",
      "train: iter 147  trainloss 1.40979  validloss 5.03605±0.00000  bestvalidloss 4.74524  last_update 89\n",
      "train: iter 148  trainloss 1.43650  validloss 4.90310±0.00000  bestvalidloss 4.74524  last_update 90\n",
      "train: iter 149  trainloss 1.41072  validloss 5.18279±0.00000  bestvalidloss 4.74524  last_update 91\n",
      "train: iter 150  trainloss 1.40680  validloss 5.04673±0.00000  bestvalidloss 4.74524  last_update 92\n",
      "train: iter 151  trainloss 1.41880  validloss 4.80922±0.00000  bestvalidloss 4.74524  last_update 93\n",
      "train: iter 152  trainloss 1.41447  validloss 5.10085±0.00000  bestvalidloss 4.74524  last_update 94\n",
      "train: iter 153  trainloss 1.40184  validloss 5.08210±0.00000  bestvalidloss 4.74524  last_update 95\n",
      "train: iter 154  trainloss 1.41580  validloss 5.30102±0.00000  bestvalidloss 4.74524  last_update 96\n",
      "train: iter 155  trainloss 1.42544  validloss 5.24958±0.00000  bestvalidloss 4.74524  last_update 97\n",
      "train: iter 156  trainloss 1.41637  validloss 4.96916±0.00000  bestvalidloss 4.74524  last_update 98\n",
      "train: iter 157  trainloss 1.40191  validloss 5.00442±0.00000  bestvalidloss 4.74524  last_update 99\n",
      "train: iter 158  trainloss 1.41248  validloss 5.21086±0.00000  bestvalidloss 4.74524  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-10.7155)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(1.8864)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2536902322469011\n",
      "tensor([1.3300])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b9a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
