{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(683.5285)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 661.11735  validloss 1176.25334±0.00000  bestvalidloss 1176.25334  last_update 0\n",
      "train: iter 1  trainloss 492.67120  validloss 986.58052±0.00000  bestvalidloss 986.58052  last_update 0\n",
      "train: iter 2  trainloss 140.10912  validloss 533.37576±0.00000  bestvalidloss 533.37576  last_update 0\n",
      "train: iter 3  trainloss -98.10119  validloss 86.46772±0.00000  bestvalidloss 86.46772  last_update 0\n",
      "train: iter 4  trainloss -326.71377  validloss 98.71876±0.00000  bestvalidloss 86.46772  last_update 1\n",
      "train: iter 5  trainloss -468.95326  validloss -153.89933±0.00000  bestvalidloss -153.89933  last_update 0\n",
      "train: iter 6  trainloss -632.79355  validloss -362.88025±0.00000  bestvalidloss -362.88025  last_update 0\n",
      "train: iter 7  trainloss -673.38875  validloss -276.63409±0.00000  bestvalidloss -362.88025  last_update 1\n",
      "train: iter 8  trainloss -786.23486  validloss -434.47115±0.00000  bestvalidloss -434.47115  last_update 0\n",
      "train: iter 9  trainloss -858.12217  validloss -519.04117±0.00000  bestvalidloss -519.04117  last_update 0\n",
      "train: iter 10  trainloss -853.62119  validloss -561.95497±0.00000  bestvalidloss -561.95497  last_update 0\n",
      "train: iter 11  trainloss -901.10260  validloss -521.62137±0.00000  bestvalidloss -561.95497  last_update 1\n",
      "train: iter 12  trainloss -980.66627  validloss -638.74696±0.00000  bestvalidloss -638.74696  last_update 0\n",
      "train: iter 13  trainloss -1003.74413  validloss -814.23131±0.00000  bestvalidloss -814.23131  last_update 0\n",
      "train: iter 14  trainloss -1054.68458  validloss -633.68203±0.00000  bestvalidloss -814.23131  last_update 1\n",
      "train: iter 15  trainloss -1132.70644  validloss -865.26979±0.00000  bestvalidloss -865.26979  last_update 0\n",
      "train: iter 16  trainloss -1156.27131  validloss -853.66433±0.00000  bestvalidloss -865.26979  last_update 1\n",
      "train: iter 17  trainloss -1170.22013  validloss -810.19627±0.00000  bestvalidloss -865.26979  last_update 2\n",
      "train: iter 18  trainloss -1175.02347  validloss -759.85868±0.00000  bestvalidloss -865.26979  last_update 3\n",
      "train: iter 19  trainloss -1220.21183  validloss -874.27399±0.00000  bestvalidloss -874.27399  last_update 0\n",
      "train: iter 20  trainloss -1215.01996  validloss -701.67247±0.00000  bestvalidloss -874.27399  last_update 1\n",
      "train: iter 21  trainloss -1238.58265  validloss -858.69811±0.00000  bestvalidloss -874.27399  last_update 2\n",
      "train: iter 22  trainloss -1242.76794  validloss -811.94756±0.00000  bestvalidloss -874.27399  last_update 3\n",
      "train: iter 23  trainloss -1236.19032  validloss -926.68342±0.00000  bestvalidloss -926.68342  last_update 0\n",
      "train: iter 24  trainloss -1288.71811  validloss -862.94479±0.00000  bestvalidloss -926.68342  last_update 1\n",
      "train: iter 25  trainloss -1163.04930  validloss -1054.71512±0.00000  bestvalidloss -1054.71512  last_update 0\n",
      "train: iter 26  trainloss -1259.05828  validloss -840.41534±0.00000  bestvalidloss -1054.71512  last_update 1\n",
      "train: iter 27  trainloss -1336.80275  validloss -1093.41342±0.00000  bestvalidloss -1093.41342  last_update 0\n",
      "train: iter 28  trainloss -1363.51940  validloss -1124.21132±0.00000  bestvalidloss -1124.21132  last_update 0\n",
      "train: iter 29  trainloss -1392.62132  validloss -926.96466±0.00000  bestvalidloss -1124.21132  last_update 1\n",
      "train: iter 30  trainloss -1409.80343  validloss -1014.61810±0.00000  bestvalidloss -1124.21132  last_update 2\n",
      "train: iter 31  trainloss -1328.13938  validloss -608.42878±0.00000  bestvalidloss -1124.21132  last_update 3\n",
      "train: iter 32  trainloss -1320.88212  validloss -917.72259±0.00000  bestvalidloss -1124.21132  last_update 4\n",
      "train: iter 33  trainloss -1311.13112  validloss -1162.07968±0.00000  bestvalidloss -1162.07968  last_update 0\n",
      "train: iter 34  trainloss -1431.56643  validloss -1049.95680±0.00000  bestvalidloss -1162.07968  last_update 1\n",
      "train: iter 35  trainloss -1319.06303  validloss -938.15441±0.00000  bestvalidloss -1162.07968  last_update 2\n",
      "train: iter 36  trainloss -1413.90971  validloss -898.90595±0.00000  bestvalidloss -1162.07968  last_update 3\n",
      "train: iter 37  trainloss -1425.75547  validloss -185.50374±0.00000  bestvalidloss -1162.07968  last_update 4\n",
      "train: iter 38  trainloss -1375.00627  validloss -1197.08018±0.00000  bestvalidloss -1197.08018  last_update 0\n",
      "train: iter 39  trainloss -1446.91691  validloss -1018.74555±0.00000  bestvalidloss -1197.08018  last_update 1\n",
      "train: iter 40  trainloss -1484.56075  validloss -1119.24560±0.00000  bestvalidloss -1197.08018  last_update 2\n",
      "train: iter 41  trainloss -1473.50020  validloss -1240.83190±0.00000  bestvalidloss -1240.83190  last_update 0\n",
      "train: iter 42  trainloss -1496.33880  validloss -1188.91875±0.00000  bestvalidloss -1240.83190  last_update 1\n",
      "train: iter 43  trainloss -1416.25488  validloss -995.61325±0.00000  bestvalidloss -1240.83190  last_update 2\n",
      "train: iter 44  trainloss -1487.54931  validloss -1226.65676±0.00000  bestvalidloss -1240.83190  last_update 3\n",
      "train: iter 45  trainloss -1518.82823  validloss -1206.39579±0.00000  bestvalidloss -1240.83190  last_update 4\n",
      "train: iter 46  trainloss -1544.73365  validloss -1306.94377±0.00000  bestvalidloss -1306.94377  last_update 0\n",
      "train: iter 47  trainloss -1501.61764  validloss -1163.37413±0.00000  bestvalidloss -1306.94377  last_update 1\n",
      "train: iter 48  trainloss -1543.57491  validloss -1151.74229±0.00000  bestvalidloss -1306.94377  last_update 2\n",
      "train: iter 49  trainloss -1520.45602  validloss -1256.71566±0.00000  bestvalidloss -1306.94377  last_update 3\n",
      "train: iter 50  trainloss -1497.93428  validloss -1079.80276±0.00000  bestvalidloss -1306.94377  last_update 4\n",
      "train: iter 51  trainloss -1477.19308  validloss -1319.93312±0.00000  bestvalidloss -1319.93312  last_update 0\n",
      "train: iter 52  trainloss -1544.55859  validloss -1295.55435±0.00000  bestvalidloss -1319.93312  last_update 1\n",
      "train: iter 53  trainloss -1536.08640  validloss -1249.35380±0.00000  bestvalidloss -1319.93312  last_update 2\n",
      "train: iter 54  trainloss -1500.17159  validloss -1331.71351±0.00000  bestvalidloss -1331.71351  last_update 0\n",
      "train: iter 55  trainloss -1525.23042  validloss -1261.16083±0.00000  bestvalidloss -1331.71351  last_update 1\n",
      "train: iter 56  trainloss -1563.74710  validloss -1204.50800±0.00000  bestvalidloss -1331.71351  last_update 2\n",
      "train: iter 57  trainloss -1564.96496  validloss -1295.30753±0.00000  bestvalidloss -1331.71351  last_update 3\n",
      "train: iter 58  trainloss -1528.32736  validloss -1145.01765±0.00000  bestvalidloss -1331.71351  last_update 4\n",
      "train: iter 59  trainloss -1560.79661  validloss -1215.36863±0.00000  bestvalidloss -1331.71351  last_update 5\n",
      "train: iter 60  trainloss -1601.77092  validloss -1237.41630±0.00000  bestvalidloss -1331.71351  last_update 6\n",
      "train: iter 61  trainloss -1589.50034  validloss -1385.40758±0.00000  bestvalidloss -1385.40758  last_update 0\n",
      "train: iter 62  trainloss -1504.14869  validloss -1359.62555±0.00000  bestvalidloss -1385.40758  last_update 1\n",
      "train: iter 63  trainloss -1608.74295  validloss -1273.76500±0.00000  bestvalidloss -1385.40758  last_update 2\n",
      "train: iter 64  trainloss -1584.44067  validloss -1246.90307±0.00000  bestvalidloss -1385.40758  last_update 3\n",
      "train: iter 65  trainloss -1628.07441  validloss -1356.72475±0.00000  bestvalidloss -1385.40758  last_update 4\n",
      "train: iter 66  trainloss -1640.54446  validloss -1381.12999±0.00000  bestvalidloss -1385.40758  last_update 5\n",
      "train: iter 67  trainloss -1625.35023  validloss -1340.15470±0.00000  bestvalidloss -1385.40758  last_update 6\n",
      "train: iter 68  trainloss -1624.12521  validloss -1235.51405±0.00000  bestvalidloss -1385.40758  last_update 7\n",
      "train: iter 69  trainloss -1585.40151  validloss -950.18011±0.00000  bestvalidloss -1385.40758  last_update 8\n",
      "train: iter 70  trainloss -1623.77449  validloss -1312.21040±0.00000  bestvalidloss -1385.40758  last_update 9\n",
      "train: iter 71  trainloss -1592.25820  validloss -1454.49835±0.00000  bestvalidloss -1454.49835  last_update 0\n",
      "train: iter 72  trainloss -1600.57492  validloss -1361.31469±0.00000  bestvalidloss -1454.49835  last_update 1\n",
      "train: iter 73  trainloss -1622.98167  validloss -1341.07329±0.00000  bestvalidloss -1454.49835  last_update 2\n",
      "train: iter 74  trainloss -1665.82282  validloss -1415.73970±0.00000  bestvalidloss -1454.49835  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1627.31532  validloss -1330.57516±0.00000  bestvalidloss -1454.49835  last_update 4\n",
      "train: iter 76  trainloss -1620.89842  validloss -1357.03555±0.00000  bestvalidloss -1454.49835  last_update 5\n",
      "train: iter 77  trainloss -1645.48087  validloss -1215.83647±0.00000  bestvalidloss -1454.49835  last_update 6\n",
      "train: iter 78  trainloss -1635.64562  validloss -938.25897±0.00000  bestvalidloss -1454.49835  last_update 7\n",
      "train: iter 79  trainloss -1640.19973  validloss -903.51714±0.00000  bestvalidloss -1454.49835  last_update 8\n",
      "train: iter 80  trainloss -1657.72112  validloss -1465.30017±0.00000  bestvalidloss -1465.30017  last_update 0\n",
      "train: iter 81  trainloss -1492.33970  validloss -1350.39774±0.00000  bestvalidloss -1465.30017  last_update 1\n",
      "train: iter 82  trainloss -1620.74426  validloss -1385.20545±0.00000  bestvalidloss -1465.30017  last_update 2\n",
      "train: iter 83  trainloss -1699.04553  validloss -1306.55121±0.00000  bestvalidloss -1465.30017  last_update 3\n",
      "train: iter 84  trainloss -1694.46973  validloss -1279.33847±0.00000  bestvalidloss -1465.30017  last_update 4\n",
      "train: iter 85  trainloss -1631.61577  validloss -1253.22952±0.00000  bestvalidloss -1465.30017  last_update 5\n",
      "train: iter 86  trainloss -1690.16873  validloss -565.06967±0.00000  bestvalidloss -1465.30017  last_update 6\n",
      "train: iter 87  trainloss -1688.05108  validloss -1413.02419±0.00000  bestvalidloss -1465.30017  last_update 7\n",
      "train: iter 88  trainloss -1651.64780  validloss -1493.07186±0.00000  bestvalidloss -1493.07186  last_update 0\n",
      "train: iter 89  trainloss -1690.44193  validloss -1430.95343±0.00000  bestvalidloss -1493.07186  last_update 1\n",
      "train: iter 90  trainloss -1703.27623  validloss -1472.51404±0.00000  bestvalidloss -1493.07186  last_update 2\n",
      "train: iter 91  trainloss -1727.34455  validloss -1444.21009±0.00000  bestvalidloss -1493.07186  last_update 3\n",
      "train: iter 92  trainloss -1698.25812  validloss -1437.49931±0.00000  bestvalidloss -1493.07186  last_update 4\n",
      "train: iter 93  trainloss -1672.17510  validloss -1427.34933±0.00000  bestvalidloss -1493.07186  last_update 5\n",
      "train: iter 94  trainloss -1731.49590  validloss -1498.35893±0.00000  bestvalidloss -1498.35893  last_update 0\n",
      "train: iter 95  trainloss -1743.28555  validloss -1478.44332±0.00000  bestvalidloss -1498.35893  last_update 1\n",
      "train: iter 96  trainloss -1720.47622  validloss -1444.99576±0.00000  bestvalidloss -1498.35893  last_update 2\n",
      "train: iter 97  trainloss -1692.09945  validloss -1425.18424±0.00000  bestvalidloss -1498.35893  last_update 3\n",
      "train: iter 98  trainloss -1728.82907  validloss -1523.12208±0.00000  bestvalidloss -1523.12208  last_update 0\n",
      "train: iter 99  trainloss -1757.66590  validloss -1475.92025±0.00000  bestvalidloss -1523.12208  last_update 1\n",
      "train: iter 100  trainloss -1734.73398  validloss -1504.70153±0.00000  bestvalidloss -1523.12208  last_update 2\n",
      "train: iter 101  trainloss -1711.44352  validloss -1307.82054±0.00000  bestvalidloss -1523.12208  last_update 3\n",
      "train: iter 102  trainloss -1689.96789  validloss -1443.46989±0.00000  bestvalidloss -1523.12208  last_update 4\n",
      "train: iter 103  trainloss -1644.59954  validloss -1267.73434±0.00000  bestvalidloss -1523.12208  last_update 5\n",
      "train: iter 104  trainloss -1720.97504  validloss -1460.53463±0.00000  bestvalidloss -1523.12208  last_update 6\n",
      "train: iter 105  trainloss -1752.31722  validloss -1520.34873±0.00000  bestvalidloss -1523.12208  last_update 7\n",
      "train: iter 106  trainloss -1736.33916  validloss -1365.78039±0.00000  bestvalidloss -1523.12208  last_update 8\n",
      "train: iter 107  trainloss -1763.65383  validloss -1464.17880±0.00000  bestvalidloss -1523.12208  last_update 9\n",
      "train: iter 108  trainloss -1745.26130  validloss -1412.42722±0.00000  bestvalidloss -1523.12208  last_update 10\n",
      "train: iter 109  trainloss -1692.46049  validloss -1389.36302±0.00000  bestvalidloss -1523.12208  last_update 11\n",
      "train: iter 110  trainloss -1714.27193  validloss -1240.15305±0.00000  bestvalidloss -1523.12208  last_update 12\n",
      "train: iter 111  trainloss -1631.35326  validloss -1031.06648±0.00000  bestvalidloss -1523.12208  last_update 13\n",
      "train: iter 112  trainloss -1692.97451  validloss -1258.07664±0.00000  bestvalidloss -1523.12208  last_update 14\n",
      "train: iter 113  trainloss -1754.18701  validloss -1455.62766±0.00000  bestvalidloss -1523.12208  last_update 15\n",
      "train: iter 114  trainloss -1764.96582  validloss -1489.66481±0.00000  bestvalidloss -1523.12208  last_update 16\n",
      "train: iter 115  trainloss -1774.13509  validloss -1470.78390±0.00000  bestvalidloss -1523.12208  last_update 17\n",
      "train: iter 116  trainloss -1727.07252  validloss -1479.70037±0.00000  bestvalidloss -1523.12208  last_update 18\n",
      "train: iter 117  trainloss -1745.78988  validloss -1579.06669±0.00000  bestvalidloss -1579.06669  last_update 0\n",
      "train: iter 118  trainloss -1618.17851  validloss -1470.10158±0.00000  bestvalidloss -1579.06669  last_update 1\n",
      "train: iter 119  trainloss -1769.75648  validloss -1509.24473±0.00000  bestvalidloss -1579.06669  last_update 2\n",
      "train: iter 120  trainloss -1788.60631  validloss -1488.70938±0.00000  bestvalidloss -1579.06669  last_update 3\n",
      "train: iter 121  trainloss -1708.50712  validloss -1561.52210±0.00000  bestvalidloss -1579.06669  last_update 4\n",
      "train: iter 122  trainloss -1775.67387  validloss -1467.98178±0.00000  bestvalidloss -1579.06669  last_update 5\n",
      "train: iter 123  trainloss -1803.67810  validloss -1504.06677±0.00000  bestvalidloss -1579.06669  last_update 6\n",
      "train: iter 124  trainloss -1677.40419  validloss -1511.24753±0.00000  bestvalidloss -1579.06669  last_update 7\n",
      "train: iter 125  trainloss -1719.05002  validloss -1318.83151±0.00000  bestvalidloss -1579.06669  last_update 8\n",
      "train: iter 126  trainloss -1783.08742  validloss -1435.60639±0.00000  bestvalidloss -1579.06669  last_update 9\n",
      "train: iter 127  trainloss -1769.19345  validloss -1429.23070±0.00000  bestvalidloss -1579.06669  last_update 10\n",
      "train: iter 128  trainloss -1786.44509  validloss -1462.26999±0.00000  bestvalidloss -1579.06669  last_update 11\n",
      "train: iter 129  trainloss -1778.84599  validloss -1480.61089±0.00000  bestvalidloss -1579.06669  last_update 12\n",
      "train: iter 130  trainloss -1743.53358  validloss -1330.53825±0.00000  bestvalidloss -1579.06669  last_update 13\n",
      "train: iter 131  trainloss -1654.77819  validloss -1216.94281±0.00000  bestvalidloss -1579.06669  last_update 14\n",
      "train: iter 132  trainloss -1805.90581  validloss -1565.90684±0.00000  bestvalidloss -1579.06669  last_update 15\n",
      "train: iter 133  trainloss -1757.21462  validloss -1582.82414±0.00000  bestvalidloss -1582.82414  last_update 0\n",
      "train: iter 134  trainloss -1819.59691  validloss -1552.15000±0.00000  bestvalidloss -1582.82414  last_update 1\n",
      "train: iter 135  trainloss -1806.18117  validloss -1340.48969±0.00000  bestvalidloss -1582.82414  last_update 2\n",
      "train: iter 136  trainloss -1819.42017  validloss -1450.11049±0.00000  bestvalidloss -1582.82414  last_update 3\n",
      "train: iter 137  trainloss -1668.59515  validloss -1529.04222±0.00000  bestvalidloss -1582.82414  last_update 4\n",
      "train: iter 138  trainloss -1808.86200  validloss -1581.67440±0.00000  bestvalidloss -1582.82414  last_update 5\n",
      "train: iter 139  trainloss -1828.62788  validloss -1563.94732±0.00000  bestvalidloss -1582.82414  last_update 6\n",
      "train: iter 140  trainloss -1798.47200  validloss -1598.34880±0.00000  bestvalidloss -1598.34880  last_update 0\n",
      "train: iter 141  trainloss -1775.03003  validloss -1496.17375±0.00000  bestvalidloss -1598.34880  last_update 1\n",
      "train: iter 142  trainloss -1821.43835  validloss -1541.32667±0.00000  bestvalidloss -1598.34880  last_update 2\n",
      "train: iter 143  trainloss -1816.06764  validloss -1447.82455±0.00000  bestvalidloss -1598.34880  last_update 3\n",
      "train: iter 144  trainloss -1826.82611  validloss -1524.08544±0.00000  bestvalidloss -1598.34880  last_update 4\n",
      "train: iter 145  trainloss -1632.47278  validloss -1631.77444±0.00000  bestvalidloss -1631.77444  last_update 0\n",
      "train: iter 146  trainloss -1799.62330  validloss -1525.42304±0.00000  bestvalidloss -1631.77444  last_update 1\n",
      "train: iter 147  trainloss -1832.11465  validloss -1406.41291±0.00000  bestvalidloss -1631.77444  last_update 2\n",
      "train: iter 148  trainloss -1825.22585  validloss -1616.19531±0.00000  bestvalidloss -1631.77444  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -1841.12173  validloss -1514.68565±0.00000  bestvalidloss -1631.77444  last_update 4\n",
      "train: iter 150  trainloss -1802.17387  validloss -1657.83782±0.00000  bestvalidloss -1657.83782  last_update 0\n",
      "train: iter 151  trainloss -1579.41901  validloss -1374.40238±0.00000  bestvalidloss -1657.83782  last_update 1\n",
      "train: iter 152  trainloss -1749.37702  validloss -1427.94506±0.00000  bestvalidloss -1657.83782  last_update 2\n",
      "train: iter 153  trainloss -1822.61634  validloss -1461.78565±0.00000  bestvalidloss -1657.83782  last_update 3\n",
      "train: iter 154  trainloss -1827.17259  validloss -1353.36670±0.00000  bestvalidloss -1657.83782  last_update 4\n",
      "train: iter 155  trainloss -1818.13856  validloss -1309.48833±0.00000  bestvalidloss -1657.83782  last_update 5\n",
      "train: iter 156  trainloss -1849.87679  validloss -1462.24868±0.00000  bestvalidloss -1657.83782  last_update 6\n",
      "train: iter 157  trainloss -1831.22060  validloss -1634.77273±0.00000  bestvalidloss -1657.83782  last_update 7\n",
      "train: iter 158  trainloss -1743.84527  validloss -957.53390±0.00000  bestvalidloss -1657.83782  last_update 8\n",
      "train: iter 159  trainloss -1836.80621  validloss -1489.31554±0.00000  bestvalidloss -1657.83782  last_update 9\n",
      "train: iter 160  trainloss -1850.15676  validloss -1664.68403±0.00000  bestvalidloss -1664.68403  last_update 0\n",
      "train: iter 161  trainloss -1452.51028  validloss -1640.43031±0.00000  bestvalidloss -1664.68403  last_update 1\n",
      "train: iter 162  trainloss -1803.08320  validloss -1344.72398±0.00000  bestvalidloss -1664.68403  last_update 2\n",
      "train: iter 163  trainloss -1822.71728  validloss -735.81203±0.00000  bestvalidloss -1664.68403  last_update 3\n",
      "train: iter 164  trainloss -1833.99317  validloss -1610.21733±0.00000  bestvalidloss -1664.68403  last_update 4\n",
      "train: iter 165  trainloss -1875.81797  validloss -1670.34313±0.00000  bestvalidloss -1670.34313  last_update 0\n",
      "train: iter 166  trainloss -1865.53370  validloss -1598.91014±0.00000  bestvalidloss -1670.34313  last_update 1\n",
      "train: iter 167  trainloss -1771.57182  validloss -1548.59301±0.00000  bestvalidloss -1670.34313  last_update 2\n",
      "train: iter 168  trainloss -1852.53736  validloss -1367.77408±0.00000  bestvalidloss -1670.34313  last_update 3\n",
      "train: iter 169  trainloss -1783.93390  validloss -1503.03445±0.00000  bestvalidloss -1670.34313  last_update 4\n",
      "train: iter 170  trainloss -1874.39550  validloss -1718.20171±0.00000  bestvalidloss -1718.20171  last_update 0\n",
      "train: iter 171  trainloss -1895.11908  validloss -1619.68228±0.00000  bestvalidloss -1718.20171  last_update 1\n",
      "train: iter 172  trainloss -1888.44343  validloss -1600.79857±0.00000  bestvalidloss -1718.20171  last_update 2\n",
      "train: iter 173  trainloss -1897.00757  validloss -1537.06950±0.00000  bestvalidloss -1718.20171  last_update 3\n",
      "train: iter 174  trainloss -1746.35616  validloss -306.94846±0.00000  bestvalidloss -1718.20171  last_update 4\n",
      "train: iter 175  trainloss -1876.23472  validloss -1646.56364±0.00000  bestvalidloss -1718.20171  last_update 5\n",
      "train: iter 176  trainloss -1853.54165  validloss -1693.77786±0.00000  bestvalidloss -1718.20171  last_update 6\n",
      "train: iter 177  trainloss -1877.56879  validloss -1609.19921±0.00000  bestvalidloss -1718.20171  last_update 7\n",
      "train: iter 178  trainloss -1862.50342  validloss -1564.04857±0.00000  bestvalidloss -1718.20171  last_update 8\n",
      "train: iter 179  trainloss -1920.29736  validloss -1733.02997±0.00000  bestvalidloss -1733.02997  last_update 0\n",
      "train: iter 180  trainloss -1930.53567  validloss -1604.07089±0.00000  bestvalidloss -1733.02997  last_update 1\n",
      "train: iter 181  trainloss -1920.23836  validloss -1750.55102±0.00000  bestvalidloss -1750.55102  last_update 0\n",
      "train: iter 182  trainloss -1884.27903  validloss -1556.16266±0.00000  bestvalidloss -1750.55102  last_update 1\n",
      "train: iter 183  trainloss -1855.71329  validloss -1567.64757±0.00000  bestvalidloss -1750.55102  last_update 2\n",
      "train: iter 184  trainloss -1913.16859  validloss -1640.37903±0.00000  bestvalidloss -1750.55102  last_update 3\n",
      "train: iter 185  trainloss -1889.89439  validloss -1736.64828±0.00000  bestvalidloss -1750.55102  last_update 4\n",
      "train: iter 186  trainloss -1909.89627  validloss -1681.26418±0.00000  bestvalidloss -1750.55102  last_update 5\n",
      "train: iter 187  trainloss -1926.45579  validloss -1459.96920±0.00000  bestvalidloss -1750.55102  last_update 6\n",
      "train: iter 188  trainloss -1887.66429  validloss 148.59168±0.00000  bestvalidloss -1750.55102  last_update 7\n",
      "train: iter 189  trainloss -1775.28312  validloss -1700.83896±0.00000  bestvalidloss -1750.55102  last_update 8\n",
      "train: iter 190  trainloss -1930.27603  validloss -1642.60485±0.00000  bestvalidloss -1750.55102  last_update 9\n",
      "train: iter 191  trainloss -1955.98147  validloss -1786.72147±0.00000  bestvalidloss -1786.72147  last_update 0\n",
      "train: iter 192  trainloss -1924.69612  validloss -1620.87537±0.00000  bestvalidloss -1786.72147  last_update 1\n",
      "train: iter 193  trainloss -1919.93640  validloss -1732.03380±0.00000  bestvalidloss -1786.72147  last_update 2\n",
      "train: iter 194  trainloss -1768.27290  validloss -59.19078±0.00000  bestvalidloss -1786.72147  last_update 3\n",
      "train: iter 195  trainloss -1892.95320  validloss -1527.49554±0.00000  bestvalidloss -1786.72147  last_update 4\n",
      "train: iter 196  trainloss -1951.13293  validloss -1745.90724±0.00000  bestvalidloss -1786.72147  last_update 5\n",
      "train: iter 197  trainloss -1956.00883  validloss -1723.31933±0.00000  bestvalidloss -1786.72147  last_update 6\n",
      "train: iter 198  trainloss -1916.68028  validloss -1730.60473±0.00000  bestvalidloss -1786.72147  last_update 7\n",
      "train: iter 199  trainloss -1912.45295  validloss -1582.17703±0.00000  bestvalidloss -1786.72147  last_update 8\n",
      "train: iter 200  trainloss -1950.53873  validloss -1781.73060±0.00000  bestvalidloss -1786.72147  last_update 9\n",
      "train: iter 201  trainloss -1872.69454  validloss -1708.08813±0.00000  bestvalidloss -1786.72147  last_update 10\n",
      "train: iter 202  trainloss -1901.17849  validloss -1574.73685±0.00000  bestvalidloss -1786.72147  last_update 11\n",
      "train: iter 203  trainloss -1936.10635  validloss -1737.65067±0.00000  bestvalidloss -1786.72147  last_update 12\n",
      "train: iter 204  trainloss -1895.19874  validloss -1615.50305±0.00000  bestvalidloss -1786.72147  last_update 13\n",
      "train: iter 205  trainloss -1933.21405  validloss -1817.18261±0.00000  bestvalidloss -1817.18261  last_update 0\n",
      "train: iter 206  trainloss -1969.04661  validloss -1837.58872±0.00000  bestvalidloss -1837.58872  last_update 0\n",
      "train: iter 207  trainloss -1765.52834  validloss -185.80846±0.00000  bestvalidloss -1837.58872  last_update 1\n",
      "train: iter 208  trainloss -1919.37160  validloss -1594.92724±0.00000  bestvalidloss -1837.58872  last_update 2\n",
      "train: iter 209  trainloss -1961.22136  validloss -1675.02574±0.00000  bestvalidloss -1837.58872  last_update 3\n",
      "train: iter 210  trainloss -1974.53342  validloss -1735.85904±0.00000  bestvalidloss -1837.58872  last_update 4\n",
      "train: iter 211  trainloss -1902.16119  validloss -1735.00706±0.00000  bestvalidloss -1837.58872  last_update 5\n",
      "train: iter 212  trainloss -1940.14904  validloss -1731.75725±0.00000  bestvalidloss -1837.58872  last_update 6\n",
      "train: iter 213  trainloss -1976.58213  validloss -1721.18903±0.00000  bestvalidloss -1837.58872  last_update 7\n",
      "train: iter 214  trainloss -1983.92191  validloss -1776.09189±0.00000  bestvalidloss -1837.58872  last_update 8\n",
      "train: iter 215  trainloss -1969.93393  validloss -1737.37021±0.00000  bestvalidloss -1837.58872  last_update 9\n",
      "train: iter 216  trainloss -1977.26094  validloss -1752.95115±0.00000  bestvalidloss -1837.58872  last_update 10\n",
      "train: iter 217  trainloss -1983.96672  validloss -1689.17001±0.00000  bestvalidloss -1837.58872  last_update 11\n",
      "train: iter 218  trainloss -1984.46611  validloss -1769.45628±0.00000  bestvalidloss -1837.58872  last_update 12\n",
      "train: iter 219  trainloss -1920.11783  validloss -1309.33441±0.00000  bestvalidloss -1837.58872  last_update 13\n",
      "train: iter 220  trainloss -1877.02479  validloss -1756.58486±0.00000  bestvalidloss -1837.58872  last_update 14\n",
      "train: iter 221  trainloss -1888.64881  validloss -1254.07495±0.00000  bestvalidloss -1837.58872  last_update 15\n",
      "train: iter 222  trainloss -1976.50679  validloss -1790.26451±0.00000  bestvalidloss -1837.58872  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1997.56481  validloss -1849.24381±0.00000  bestvalidloss -1849.24381  last_update 0\n",
      "train: iter 224  trainloss -1962.41766  validloss -1838.25537±0.00000  bestvalidloss -1849.24381  last_update 1\n",
      "train: iter 225  trainloss -1921.69079  validloss -1418.13650±0.00000  bestvalidloss -1849.24381  last_update 2\n",
      "train: iter 226  trainloss -1963.52709  validloss -1647.64477±0.00000  bestvalidloss -1849.24381  last_update 3\n",
      "train: iter 227  trainloss -2016.52157  validloss -1830.63081±0.00000  bestvalidloss -1849.24381  last_update 4\n",
      "train: iter 228  trainloss -1959.73585  validloss -1664.82786±0.00000  bestvalidloss -1849.24381  last_update 5\n",
      "train: iter 229  trainloss -1956.48719  validloss -1772.47718±0.00000  bestvalidloss -1849.24381  last_update 6\n",
      "train: iter 230  trainloss -1960.40779  validloss -1766.24534±0.00000  bestvalidloss -1849.24381  last_update 7\n",
      "train: iter 231  trainloss -1961.70527  validloss -1798.86118±0.00000  bestvalidloss -1849.24381  last_update 8\n",
      "train: iter 232  trainloss -1958.81813  validloss -1839.83573±0.00000  bestvalidloss -1849.24381  last_update 9\n",
      "train: iter 233  trainloss -1996.53590  validloss -1750.72210±0.00000  bestvalidloss -1849.24381  last_update 10\n",
      "train: iter 234  trainloss -2007.90020  validloss -1808.65117±0.00000  bestvalidloss -1849.24381  last_update 11\n",
      "train: iter 235  trainloss -1970.85720  validloss -1827.44975±0.00000  bestvalidloss -1849.24381  last_update 12\n",
      "train: iter 236  trainloss -1928.40118  validloss -1638.05768±0.00000  bestvalidloss -1849.24381  last_update 13\n",
      "train: iter 237  trainloss -1859.09293  validloss -1766.41321±0.00000  bestvalidloss -1849.24381  last_update 14\n",
      "train: iter 238  trainloss -1966.90873  validloss -1804.66373±0.00000  bestvalidloss -1849.24381  last_update 15\n",
      "train: iter 239  trainloss -2008.27272  validloss -1709.02190±0.00000  bestvalidloss -1849.24381  last_update 16\n",
      "train: iter 240  trainloss -2013.56828  validloss -1766.48864±0.00000  bestvalidloss -1849.24381  last_update 17\n",
      "train: iter 241  trainloss -1956.33142  validloss -1773.37873±0.00000  bestvalidloss -1849.24381  last_update 18\n",
      "train: iter 242  trainloss -1881.61813  validloss -1547.22051±0.00000  bestvalidloss -1849.24381  last_update 19\n",
      "train: iter 243  trainloss -1998.17980  validloss -1662.20313±0.00000  bestvalidloss -1849.24381  last_update 20\n",
      "train: iter 244  trainloss -2004.90157  validloss -1862.86468±0.00000  bestvalidloss -1862.86468  last_update 0\n",
      "train: iter 245  trainloss -2014.69303  validloss -1868.82413±0.00000  bestvalidloss -1868.82413  last_update 0\n",
      "train: iter 246  trainloss -2022.16273  validloss -1867.37076±0.00000  bestvalidloss -1868.82413  last_update 1\n",
      "train: iter 247  trainloss -2016.18054  validloss -1813.88086±0.00000  bestvalidloss -1868.82413  last_update 2\n",
      "train: iter 248  trainloss -1981.47992  validloss -1814.32726±0.00000  bestvalidloss -1868.82413  last_update 3\n",
      "train: iter 249  trainloss -1914.41692  validloss -1732.87474±0.00000  bestvalidloss -1868.82413  last_update 4\n",
      "train: iter 250  trainloss -1994.21141  validloss -1718.10758±0.00000  bestvalidloss -1868.82413  last_update 5\n",
      "train: iter 251  trainloss -1987.65950  validloss -1846.16255±0.00000  bestvalidloss -1868.82413  last_update 6\n",
      "train: iter 252  trainloss -1978.90463  validloss -1470.98856±0.00000  bestvalidloss -1868.82413  last_update 7\n",
      "train: iter 253  trainloss -1936.61212  validloss -1343.59240±0.00000  bestvalidloss -1868.82413  last_update 8\n",
      "train: iter 254  trainloss -2014.00837  validloss -1795.98418±0.00000  bestvalidloss -1868.82413  last_update 9\n",
      "train: iter 255  trainloss -2012.82566  validloss -1791.47117±0.00000  bestvalidloss -1868.82413  last_update 10\n",
      "train: iter 256  trainloss -1978.90604  validloss -1826.93930±0.00000  bestvalidloss -1868.82413  last_update 11\n",
      "train: iter 257  trainloss -1929.75952  validloss -1570.10980±0.00000  bestvalidloss -1868.82413  last_update 12\n",
      "train: iter 258  trainloss -2011.91219  validloss -1871.49412±0.00000  bestvalidloss -1871.49412  last_update 0\n",
      "train: iter 259  trainloss -2007.49409  validloss -1878.10793±0.00000  bestvalidloss -1878.10793  last_update 0\n",
      "train: iter 260  trainloss -1968.43224  validloss -1594.41936±0.00000  bestvalidloss -1878.10793  last_update 1\n",
      "train: iter 261  trainloss -1978.15911  validloss -1852.11704±0.00000  bestvalidloss -1878.10793  last_update 2\n",
      "train: iter 262  trainloss -2000.99392  validloss -1803.98329±0.00000  bestvalidloss -1878.10793  last_update 3\n",
      "train: iter 263  trainloss -2013.85718  validloss -1728.89667±0.00000  bestvalidloss -1878.10793  last_update 4\n",
      "train: iter 264  trainloss -1963.10571  validloss -1847.85163±0.00000  bestvalidloss -1878.10793  last_update 5\n",
      "train: iter 265  trainloss -1938.14771  validloss -725.67243±0.00000  bestvalidloss -1878.10793  last_update 6\n",
      "train: iter 266  trainloss -1939.25673  validloss -1591.71791±0.00000  bestvalidloss -1878.10793  last_update 7\n",
      "train: iter 267  trainloss -2005.45812  validloss -1868.90738±0.00000  bestvalidloss -1878.10793  last_update 8\n",
      "train: iter 268  trainloss -2017.46692  validloss -1871.08707±0.00000  bestvalidloss -1878.10793  last_update 9\n",
      "train: iter 269  trainloss -1949.67017  validloss -1834.74784±0.00000  bestvalidloss -1878.10793  last_update 10\n",
      "train: iter 270  trainloss -2005.97744  validloss -1611.16620±0.00000  bestvalidloss -1878.10793  last_update 11\n",
      "train: iter 271  trainloss -2017.15514  validloss -1294.01227±0.00000  bestvalidloss -1878.10793  last_update 12\n",
      "train: iter 272  trainloss -1978.32602  validloss -1769.73158±0.00000  bestvalidloss -1878.10793  last_update 13\n",
      "train: iter 273  trainloss -2027.10547  validloss -1840.34490±0.00000  bestvalidloss -1878.10793  last_update 14\n",
      "train: iter 274  trainloss -2021.63804  validloss -1864.16276±0.00000  bestvalidloss -1878.10793  last_update 15\n",
      "train: iter 275  trainloss -2019.07735  validloss -1898.83264±0.00000  bestvalidloss -1898.83264  last_update 0\n",
      "train: iter 276  trainloss -2024.24382  validloss -1846.97803±0.00000  bestvalidloss -1898.83264  last_update 1\n",
      "train: iter 277  trainloss -2016.79249  validloss -1610.25951±0.00000  bestvalidloss -1898.83264  last_update 2\n",
      "train: iter 278  trainloss -1932.28711  validloss -1529.61961±0.00000  bestvalidloss -1898.83264  last_update 3\n",
      "train: iter 279  trainloss -2023.09561  validloss -1437.77688±0.00000  bestvalidloss -1898.83264  last_update 4\n",
      "train: iter 280  trainloss -2030.90350  validloss -1861.73557±0.00000  bestvalidloss -1898.83264  last_update 5\n",
      "train: iter 281  trainloss -2040.79192  validloss -1799.10835±0.00000  bestvalidloss -1898.83264  last_update 6\n",
      "train: iter 282  trainloss -2004.72598  validloss -1891.15021±0.00000  bestvalidloss -1898.83264  last_update 7\n",
      "train: iter 283  trainloss -1904.53877  validloss -609.31682±0.00000  bestvalidloss -1898.83264  last_update 8\n",
      "train: iter 284  trainloss -1997.07536  validloss -1708.07825±0.00000  bestvalidloss -1898.83264  last_update 9\n",
      "train: iter 285  trainloss -2026.04026  validloss -1825.90132±0.00000  bestvalidloss -1898.83264  last_update 10\n",
      "train: iter 286  trainloss -2023.80343  validloss -1830.19458±0.00000  bestvalidloss -1898.83264  last_update 11\n",
      "train: iter 287  trainloss -1983.92059  validloss -338.54575±0.00000  bestvalidloss -1898.83264  last_update 12\n",
      "train: iter 288  trainloss -2026.30094  validloss -1852.14403±0.00000  bestvalidloss -1898.83264  last_update 13\n",
      "train: iter 289  trainloss -2033.06422  validloss -1846.97866±0.00000  bestvalidloss -1898.83264  last_update 14\n",
      "train: iter 290  trainloss -1975.73341  validloss -1869.05955±0.00000  bestvalidloss -1898.83264  last_update 15\n",
      "train: iter 291  trainloss -2030.24749  validloss -1758.37054±0.00000  bestvalidloss -1898.83264  last_update 16\n",
      "train: iter 292  trainloss -1984.34969  validloss -1898.93976±0.00000  bestvalidloss -1898.93976  last_update 0\n",
      "train: iter 293  trainloss -1727.52146  validloss 302.42411±0.00000  bestvalidloss -1898.93976  last_update 1\n",
      "train: iter 294  trainloss -1977.39575  validloss -1618.04355±0.00000  bestvalidloss -1898.93976  last_update 2\n",
      "train: iter 295  trainloss -1999.05479  validloss -1771.40442±0.00000  bestvalidloss -1898.93976  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -1992.81697  validloss -1817.95141±0.00000  bestvalidloss -1898.93976  last_update 4\n",
      "train: iter 297  trainloss -2030.89496  validloss -1757.60415±0.00000  bestvalidloss -1898.93976  last_update 5\n",
      "train: iter 298  trainloss -1991.66522  validloss -1800.55524±0.00000  bestvalidloss -1898.93976  last_update 6\n",
      "train: iter 299  trainloss -1848.83793  validloss -1777.97381±0.00000  bestvalidloss -1898.93976  last_update 7\n",
      "train: iter 300  trainloss -1687.03840  validloss -1779.58898±0.00000  bestvalidloss -1898.93976  last_update 8\n",
      "train: iter 301  trainloss -1965.23985  validloss -1732.53917±0.00000  bestvalidloss -1898.93976  last_update 9\n",
      "train: iter 302  trainloss -2029.59439  validloss -1866.78773±0.00000  bestvalidloss -1898.93976  last_update 10\n",
      "train: iter 303  trainloss -2048.32202  validloss -1880.25254±0.00000  bestvalidloss -1898.93976  last_update 11\n",
      "train: iter 304  trainloss -2015.17623  validloss -1904.52935±0.00000  bestvalidloss -1904.52935  last_update 0\n",
      "train: iter 305  trainloss -1694.30233  validloss -1868.18344±0.00000  bestvalidloss -1904.52935  last_update 1\n",
      "train: iter 306  trainloss -1998.95691  validloss -1661.39095±0.00000  bestvalidloss -1904.52935  last_update 2\n",
      "train: iter 307  trainloss -2001.48817  validloss -1492.54221±0.00000  bestvalidloss -1904.52935  last_update 3\n",
      "train: iter 308  trainloss -2000.19314  validloss -1675.81343±0.00000  bestvalidloss -1904.52935  last_update 4\n",
      "train: iter 309  trainloss -2008.64959  validloss -1384.62291±0.00000  bestvalidloss -1904.52935  last_update 5\n",
      "train: iter 310  trainloss -2031.84719  validloss -1243.17453±0.00000  bestvalidloss -1904.52935  last_update 6\n",
      "train: iter 311  trainloss -2036.82777  validloss -1849.04807±0.00000  bestvalidloss -1904.52935  last_update 7\n",
      "train: iter 312  trainloss -2037.31425  validloss -1752.61750±0.00000  bestvalidloss -1904.52935  last_update 8\n",
      "train: iter 313  trainloss -2026.99515  validloss -1908.76058±0.00000  bestvalidloss -1908.76058  last_update 0\n",
      "train: iter 314  trainloss -2043.26274  validloss -1892.26517±0.00000  bestvalidloss -1908.76058  last_update 1\n",
      "train: iter 315  trainloss -2057.07119  validloss -1923.01167±0.00000  bestvalidloss -1923.01167  last_update 0\n",
      "train: iter 316  trainloss -2034.93502  validloss -1879.27852±0.00000  bestvalidloss -1923.01167  last_update 1\n",
      "train: iter 317  trainloss -1955.82303  validloss -1176.90658±0.00000  bestvalidloss -1923.01167  last_update 2\n",
      "train: iter 318  trainloss -2044.59592  validloss -1884.83866±0.00000  bestvalidloss -1923.01167  last_update 3\n",
      "train: iter 319  trainloss -2058.33879  validloss -1893.37194±0.00000  bestvalidloss -1923.01167  last_update 4\n",
      "train: iter 320  trainloss -2056.05230  validloss -1893.77046±0.00000  bestvalidloss -1923.01167  last_update 5\n",
      "train: iter 321  trainloss -2062.51070  validloss -1853.50339±0.00000  bestvalidloss -1923.01167  last_update 6\n",
      "train: iter 322  trainloss -2021.80204  validloss -1882.48427±0.00000  bestvalidloss -1923.01167  last_update 7\n",
      "train: iter 323  trainloss -1985.95634  validloss -1909.68575±0.00000  bestvalidloss -1923.01167  last_update 8\n",
      "train: iter 324  trainloss -2012.80824  validloss -1505.74068±0.00000  bestvalidloss -1923.01167  last_update 9\n",
      "train: iter 325  trainloss -2056.67025  validloss -1865.63542±0.00000  bestvalidloss -1923.01167  last_update 10\n",
      "train: iter 326  trainloss -1998.89377  validloss -1893.31932±0.00000  bestvalidloss -1923.01167  last_update 11\n",
      "train: iter 327  trainloss -2030.57268  validloss -1355.28286±0.00000  bestvalidloss -1923.01167  last_update 12\n",
      "train: iter 328  trainloss -2037.74209  validloss -1881.76237±0.00000  bestvalidloss -1923.01167  last_update 13\n",
      "train: iter 329  trainloss -2022.48161  validloss -1912.48103±0.00000  bestvalidloss -1923.01167  last_update 14\n",
      "train: iter 330  trainloss -1996.90343  validloss -1582.68546±0.00000  bestvalidloss -1923.01167  last_update 15\n",
      "train: iter 331  trainloss -2032.84998  validloss -1581.37449±0.00000  bestvalidloss -1923.01167  last_update 16\n",
      "train: iter 332  trainloss -2054.97633  validloss -1840.22353±0.00000  bestvalidloss -1923.01167  last_update 17\n",
      "train: iter 333  trainloss -2061.77075  validloss -1871.60194±0.00000  bestvalidloss -1923.01167  last_update 18\n",
      "train: iter 334  trainloss -2038.16940  validloss -1914.02610±0.00000  bestvalidloss -1923.01167  last_update 19\n",
      "train: iter 335  trainloss -2048.57642  validloss -1750.49224±0.00000  bestvalidloss -1923.01167  last_update 20\n",
      "train: iter 336  trainloss -1690.91213  validloss -1897.43385±0.00000  bestvalidloss -1923.01167  last_update 21\n",
      "train: iter 337  trainloss -2012.82664  validloss -1755.46028±0.00000  bestvalidloss -1923.01167  last_update 22\n",
      "train: iter 338  trainloss -2041.79780  validloss -1901.15910±0.00000  bestvalidloss -1923.01167  last_update 23\n",
      "train: iter 339  trainloss -2030.90417  validloss -1719.78692±0.00000  bestvalidloss -1923.01167  last_update 24\n",
      "train: iter 340  trainloss -2066.51573  validloss -1927.19842±0.00000  bestvalidloss -1927.19842  last_update 0\n",
      "train: iter 341  trainloss -2076.23943  validloss -1927.94507±0.00000  bestvalidloss -1927.94507  last_update 0\n",
      "train: iter 342  trainloss -2051.39921  validloss -1922.34200±0.00000  bestvalidloss -1927.94507  last_update 1\n",
      "train: iter 343  trainloss -2056.00949  validloss -1867.71345±0.00000  bestvalidloss -1927.94507  last_update 2\n",
      "train: iter 344  trainloss -2072.33062  validloss -1883.50218±0.00000  bestvalidloss -1927.94507  last_update 3\n",
      "train: iter 345  trainloss -2077.69762  validloss -1891.00385±0.00000  bestvalidloss -1927.94507  last_update 4\n",
      "train: iter 346  trainloss -1916.44955  validloss -1904.06355±0.00000  bestvalidloss -1927.94507  last_update 5\n",
      "train: iter 347  trainloss -2001.23291  validloss -784.48868±0.00000  bestvalidloss -1927.94507  last_update 6\n",
      "train: iter 348  trainloss -2063.24998  validloss -1874.16365±0.00000  bestvalidloss -1927.94507  last_update 7\n",
      "train: iter 349  trainloss -2041.86724  validloss -1876.12698±0.00000  bestvalidloss -1927.94507  last_update 8\n",
      "train: iter 350  trainloss -2050.89482  validloss -1879.32706±0.00000  bestvalidloss -1927.94507  last_update 9\n",
      "train: iter 351  trainloss -2052.24854  validloss -1754.13235±0.00000  bestvalidloss -1927.94507  last_update 10\n",
      "train: iter 352  trainloss -2057.78662  validloss -1754.04673±0.00000  bestvalidloss -1927.94507  last_update 11\n",
      "train: iter 353  trainloss -2045.77613  validloss -1797.09838±0.00000  bestvalidloss -1927.94507  last_update 12\n",
      "train: iter 354  trainloss -2005.37455  validloss -1904.57979±0.00000  bestvalidloss -1927.94507  last_update 13\n",
      "train: iter 355  trainloss -2007.88605  validloss -1668.69348±0.00000  bestvalidloss -1927.94507  last_update 14\n",
      "train: iter 356  trainloss -2072.92018  validloss -1702.48410±0.00000  bestvalidloss -1927.94507  last_update 15\n",
      "train: iter 357  trainloss -2055.11704  validloss -1928.32241±0.00000  bestvalidloss -1928.32241  last_update 0\n",
      "train: iter 358  trainloss -2035.92531  validloss -1841.41923±0.00000  bestvalidloss -1928.32241  last_update 1\n",
      "train: iter 359  trainloss -2074.79122  validloss -1743.52229±0.00000  bestvalidloss -1928.32241  last_update 2\n",
      "train: iter 360  trainloss -2016.64158  validloss -1906.74468±0.00000  bestvalidloss -1928.32241  last_update 3\n",
      "train: iter 361  trainloss -1962.46077  validloss -1508.27067±0.00000  bestvalidloss -1928.32241  last_update 4\n",
      "train: iter 362  trainloss -2018.49359  validloss -844.67174±0.00000  bestvalidloss -1928.32241  last_update 5\n",
      "train: iter 363  trainloss -2042.89095  validloss -1824.99385±0.00000  bestvalidloss -1928.32241  last_update 6\n",
      "train: iter 364  trainloss -2071.13796  validloss -1814.20121±0.00000  bestvalidloss -1928.32241  last_update 7\n",
      "train: iter 365  trainloss -2068.71889  validloss -1880.68302±0.00000  bestvalidloss -1928.32241  last_update 8\n",
      "train: iter 366  trainloss -2063.67407  validloss -1904.76630±0.00000  bestvalidloss -1928.32241  last_update 9\n",
      "train: iter 367  trainloss -1888.21905  validloss -1866.23221±0.00000  bestvalidloss -1928.32241  last_update 10\n",
      "train: iter 368  trainloss -2034.85079  validloss -1785.39038±0.00000  bestvalidloss -1928.32241  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -2076.26895  validloss -1904.95054±0.00000  bestvalidloss -1928.32241  last_update 12\n",
      "train: iter 370  trainloss -2068.22281  validloss -1863.97224±0.00000  bestvalidloss -1928.32241  last_update 13\n",
      "train: iter 371  trainloss -2010.23672  validloss -1810.95737±0.00000  bestvalidloss -1928.32241  last_update 14\n",
      "train: iter 372  trainloss -1800.03135  validloss -1639.54500±0.00000  bestvalidloss -1928.32241  last_update 15\n",
      "train: iter 373  trainloss -2041.67771  validloss -1871.51269±0.00000  bestvalidloss -1928.32241  last_update 16\n",
      "train: iter 374  trainloss -2019.74283  validloss -1622.87045±0.00000  bestvalidloss -1928.32241  last_update 17\n",
      "train: iter 375  trainloss -2067.36070  validloss -1823.01116±0.00000  bestvalidloss -1928.32241  last_update 18\n",
      "train: iter 376  trainloss -2069.33058  validloss -1886.90996±0.00000  bestvalidloss -1928.32241  last_update 19\n",
      "train: iter 377  trainloss -2060.57697  validloss -1785.50277±0.00000  bestvalidloss -1928.32241  last_update 20\n",
      "train: iter 378  trainloss -1969.15519  validloss -1912.62770±0.00000  bestvalidloss -1928.32241  last_update 21\n",
      "train: iter 379  trainloss -1958.11067  validloss -815.44275±0.00000  bestvalidloss -1928.32241  last_update 22\n",
      "train: iter 380  trainloss -1847.71973  validloss 1388.93225±0.00000  bestvalidloss -1928.32241  last_update 23\n",
      "train: iter 381  trainloss -2007.55692  validloss -1737.59355±0.00000  bestvalidloss -1928.32241  last_update 24\n",
      "train: iter 382  trainloss -2058.46276  validloss -1782.00978±0.00000  bestvalidloss -1928.32241  last_update 25\n",
      "train: iter 383  trainloss -2064.10258  validloss -1802.06231±0.00000  bestvalidloss -1928.32241  last_update 26\n",
      "train: iter 384  trainloss -2083.36857  validloss -1880.51183±0.00000  bestvalidloss -1928.32241  last_update 27\n",
      "train: iter 385  trainloss -2080.28271  validloss -1874.61378±0.00000  bestvalidloss -1928.32241  last_update 28\n",
      "train: iter 386  trainloss -2061.97813  validloss -1875.82311±0.00000  bestvalidloss -1928.32241  last_update 29\n",
      "train: iter 387  trainloss -2084.29892  validloss -1854.20805±0.00000  bestvalidloss -1928.32241  last_update 30\n",
      "train: iter 388  trainloss -2042.97544  validloss -1870.77372±0.00000  bestvalidloss -1928.32241  last_update 31\n",
      "train: iter 389  trainloss -1929.33014  validloss -1806.71366±0.00000  bestvalidloss -1928.32241  last_update 32\n",
      "train: iter 390  trainloss -1987.59608  validloss -1392.75687±0.00000  bestvalidloss -1928.32241  last_update 33\n",
      "train: iter 391  trainloss -2070.31782  validloss -1917.88656±0.00000  bestvalidloss -1928.32241  last_update 34\n",
      "train: iter 392  trainloss -2080.04146  validloss -1859.89600±0.00000  bestvalidloss -1928.32241  last_update 35\n",
      "train: iter 393  trainloss -2085.43921  validloss -1960.41571±0.00000  bestvalidloss -1960.41571  last_update 0\n",
      "train: iter 394  trainloss -2084.53649  validloss -1936.08526±0.00000  bestvalidloss -1960.41571  last_update 1\n",
      "train: iter 395  trainloss -2049.37450  validloss -1739.48598±0.00000  bestvalidloss -1960.41571  last_update 2\n",
      "train: iter 396  trainloss -2079.40896  validloss -1912.61473±0.00000  bestvalidloss -1960.41571  last_update 3\n",
      "train: iter 397  trainloss -2088.61655  validloss -1949.65679±0.00000  bestvalidloss -1960.41571  last_update 4\n",
      "train: iter 398  trainloss -2094.90970  validloss -1945.19839±0.00000  bestvalidloss -1960.41571  last_update 5\n",
      "train: iter 399  trainloss -2004.68111  validloss -1844.23223±0.00000  bestvalidloss -1960.41571  last_update 6\n",
      "train: iter 400  trainloss -1985.68024  validloss -1087.53156±0.00000  bestvalidloss -1960.41571  last_update 7\n",
      "train: iter 401  trainloss -2077.31601  validloss -1939.18876±0.00000  bestvalidloss -1960.41571  last_update 8\n",
      "train: iter 402  trainloss -2095.18295  validloss -1910.94861±0.00000  bestvalidloss -1960.41571  last_update 9\n",
      "train: iter 403  trainloss -2059.87155  validloss -1624.84565±0.00000  bestvalidloss -1960.41571  last_update 10\n",
      "train: iter 404  trainloss -2039.82258  validloss -1158.80973±0.00000  bestvalidloss -1960.41571  last_update 11\n",
      "train: iter 405  trainloss -2037.48772  validloss -1896.60238±0.00000  bestvalidloss -1960.41571  last_update 12\n",
      "train: iter 406  trainloss -2079.07227  validloss -1825.87214±0.00000  bestvalidloss -1960.41571  last_update 13\n",
      "train: iter 407  trainloss -2097.01441  validloss -1940.23436±0.00000  bestvalidloss -1960.41571  last_update 14\n",
      "train: iter 408  trainloss -1970.67204  validloss -1909.43209±0.00000  bestvalidloss -1960.41571  last_update 15\n",
      "train: iter 409  trainloss -1989.50310  validloss -1501.99576±0.00000  bestvalidloss -1960.41571  last_update 16\n",
      "train: iter 410  trainloss -2044.68265  validloss -1845.27438±0.00000  bestvalidloss -1960.41571  last_update 17\n",
      "train: iter 411  trainloss -2054.18494  validloss -1753.58614±0.00000  bestvalidloss -1960.41571  last_update 18\n",
      "train: iter 412  trainloss -2074.95874  validloss -1714.67315±0.00000  bestvalidloss -1960.41571  last_update 19\n",
      "train: iter 413  trainloss -1946.79302  validloss -1958.51693±0.00000  bestvalidloss -1960.41571  last_update 20\n",
      "train: iter 414  trainloss -2031.24134  validloss -1753.86805±0.00000  bestvalidloss -1960.41571  last_update 21\n",
      "train: iter 415  trainloss -2047.26100  validloss -1882.96510±0.00000  bestvalidloss -1960.41571  last_update 22\n",
      "train: iter 416  trainloss -2054.34155  validloss -1176.26790±0.00000  bestvalidloss -1960.41571  last_update 23\n",
      "train: iter 417  trainloss -2066.53867  validloss -1689.19359±0.00000  bestvalidloss -1960.41571  last_update 24\n",
      "train: iter 418  trainloss -2062.68010  validloss -1880.89843±0.00000  bestvalidloss -1960.41571  last_update 25\n",
      "train: iter 419  trainloss -2084.65801  validloss -1876.26709±0.00000  bestvalidloss -1960.41571  last_update 26\n",
      "train: iter 420  trainloss -2068.58512  validloss -1892.90469±0.00000  bestvalidloss -1960.41571  last_update 27\n",
      "train: iter 421  trainloss -2080.24684  validloss -1910.19989±0.00000  bestvalidloss -1960.41571  last_update 28\n",
      "train: iter 422  trainloss -2055.87695  validloss -1949.78110±0.00000  bestvalidloss -1960.41571  last_update 29\n",
      "train: iter 423  trainloss -1973.90751  validloss -1774.93847±0.00000  bestvalidloss -1960.41571  last_update 30\n",
      "train: iter 424  trainloss -2048.38788  validloss -1702.15517±0.00000  bestvalidloss -1960.41571  last_update 31\n",
      "train: iter 425  trainloss -2079.27516  validloss -1851.44382±0.00000  bestvalidloss -1960.41571  last_update 32\n",
      "train: iter 426  trainloss -2055.80354  validloss -1754.59371±0.00000  bestvalidloss -1960.41571  last_update 33\n",
      "train: iter 427  trainloss -2086.05248  validloss -1947.65611±0.00000  bestvalidloss -1960.41571  last_update 34\n",
      "train: iter 428  trainloss -1986.80636  validloss -256.62735±0.00000  bestvalidloss -1960.41571  last_update 35\n",
      "train: iter 429  trainloss -2095.62719  validloss -1830.67182±0.00000  bestvalidloss -1960.41571  last_update 36\n",
      "train: iter 430  trainloss -2095.47838  validloss -1913.95831±0.00000  bestvalidloss -1960.41571  last_update 37\n",
      "train: iter 431  trainloss -2071.54312  validloss -1848.16677±0.00000  bestvalidloss -1960.41571  last_update 38\n",
      "train: iter 432  trainloss -2079.35964  validloss -1942.40213±0.00000  bestvalidloss -1960.41571  last_update 39\n",
      "train: iter 433  trainloss -1983.16803  validloss -1872.07914±0.00000  bestvalidloss -1960.41571  last_update 40\n",
      "train: iter 434  trainloss -2076.61528  validloss -1877.01852±0.00000  bestvalidloss -1960.41571  last_update 41\n",
      "train: iter 435  trainloss -2062.53518  validloss -1875.97552±0.00000  bestvalidloss -1960.41571  last_update 42\n",
      "train: iter 436  trainloss -2075.43977  validloss -1769.84736±0.00000  bestvalidloss -1960.41571  last_update 43\n",
      "train: iter 437  trainloss -2081.65202  validloss -1914.51343±0.00000  bestvalidloss -1960.41571  last_update 44\n",
      "train: iter 438  trainloss -2101.25323  validloss -1928.93265±0.00000  bestvalidloss -1960.41571  last_update 45\n",
      "train: iter 439  trainloss -2072.94543  validloss -1949.17057±0.00000  bestvalidloss -1960.41571  last_update 46\n",
      "train: iter 440  trainloss -2049.83524  validloss -1859.59875±0.00000  bestvalidloss -1960.41571  last_update 47\n",
      "train: iter 441  trainloss -2091.42032  validloss -1815.37778±0.00000  bestvalidloss -1960.41571  last_update 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 442  trainloss -2069.04645  validloss -1880.75591±0.00000  bestvalidloss -1960.41571  last_update 49\n",
      "train: iter 443  trainloss -1936.73132  validloss -1874.94133±0.00000  bestvalidloss -1960.41571  last_update 50\n",
      "train: iter 444  trainloss -2085.70719  validloss -1846.08837±0.00000  bestvalidloss -1960.41571  last_update 51\n",
      "train: iter 445  trainloss -2080.48089  validloss -1909.64063±0.00000  bestvalidloss -1960.41571  last_update 52\n",
      "train: iter 446  trainloss -2075.24453  validloss -1928.15599±0.00000  bestvalidloss -1960.41571  last_update 53\n",
      "train: iter 447  trainloss -2090.39225  validloss -1959.98066±0.00000  bestvalidloss -1960.41571  last_update 54\n",
      "train: iter 448  trainloss -2066.41437  validloss -1899.00661±0.00000  bestvalidloss -1960.41571  last_update 55\n",
      "train: iter 449  trainloss -2008.50606  validloss -1631.27892±0.00000  bestvalidloss -1960.41571  last_update 56\n",
      "train: iter 450  trainloss -2090.22281  validloss -1798.97931±0.00000  bestvalidloss -1960.41571  last_update 57\n",
      "train: iter 451  trainloss -2083.87865  validloss -1492.26987±0.00000  bestvalidloss -1960.41571  last_update 58\n",
      "train: iter 452  trainloss -2077.29631  validloss -1919.55940±0.00000  bestvalidloss -1960.41571  last_update 59\n",
      "train: iter 453  trainloss -1945.56639  validloss -1542.08377±0.00000  bestvalidloss -1960.41571  last_update 60\n",
      "train: iter 454  trainloss -2079.92089  validloss -1824.52271±0.00000  bestvalidloss -1960.41571  last_update 61\n",
      "train: iter 455  trainloss -2073.03115  validloss -1854.08428±0.00000  bestvalidloss -1960.41571  last_update 62\n",
      "train: iter 456  trainloss -2083.10844  validloss -1898.57742±0.00000  bestvalidloss -1960.41571  last_update 63\n",
      "train: iter 457  trainloss -2078.36242  validloss -1958.21289±0.00000  bestvalidloss -1960.41571  last_update 64\n",
      "train: iter 458  trainloss -2087.85798  validloss -1570.03445±0.00000  bestvalidloss -1960.41571  last_update 65\n",
      "train: iter 459  trainloss -2081.56238  validloss -1984.96304±0.00000  bestvalidloss -1984.96304  last_update 0\n",
      "train: iter 460  trainloss -2041.97554  validloss -1637.48645±0.00000  bestvalidloss -1984.96304  last_update 1\n",
      "train: iter 461  trainloss -2094.05872  validloss -1762.59717±0.00000  bestvalidloss -1984.96304  last_update 2\n",
      "train: iter 462  trainloss -2033.51310  validloss -1862.45048±0.00000  bestvalidloss -1984.96304  last_update 3\n",
      "train: iter 463  trainloss -2036.97386  validloss -1752.81751±0.00000  bestvalidloss -1984.96304  last_update 4\n",
      "train: iter 464  trainloss -2062.91459  validloss -1860.38731±0.00000  bestvalidloss -1984.96304  last_update 5\n",
      "train: iter 465  trainloss -2039.89750  validloss -1896.63764±0.00000  bestvalidloss -1984.96304  last_update 6\n",
      "train: iter 466  trainloss -2110.60438  validloss -1898.00439±0.00000  bestvalidloss -1984.96304  last_update 7\n",
      "train: iter 467  trainloss -2055.92705  validloss -1951.79479±0.00000  bestvalidloss -1984.96304  last_update 8\n",
      "train: iter 468  trainloss -2098.64133  validloss -1670.31396±0.00000  bestvalidloss -1984.96304  last_update 9\n",
      "train: iter 469  trainloss -2028.58397  validloss -974.89672±0.00000  bestvalidloss -1984.96304  last_update 10\n",
      "train: iter 470  trainloss -1768.09147  validloss -1837.95038±0.00000  bestvalidloss -1984.96304  last_update 11\n",
      "train: iter 471  trainloss -2061.59459  validloss -1778.90752±0.00000  bestvalidloss -1984.96304  last_update 12\n",
      "train: iter 472  trainloss -2072.77374  validloss -1913.33390±0.00000  bestvalidloss -1984.96304  last_update 13\n",
      "train: iter 473  trainloss -2074.10604  validloss -1924.64028±0.00000  bestvalidloss -1984.96304  last_update 14\n",
      "train: iter 474  trainloss -2074.65654  validloss -1612.89667±0.00000  bestvalidloss -1984.96304  last_update 15\n",
      "train: iter 475  trainloss -2049.48528  validloss -1841.95626±0.00000  bestvalidloss -1984.96304  last_update 16\n",
      "train: iter 476  trainloss -2092.98362  validloss -1943.85887±0.00000  bestvalidloss -1984.96304  last_update 17\n",
      "train: iter 477  trainloss -2087.72881  validloss -1698.44861±0.00000  bestvalidloss -1984.96304  last_update 18\n",
      "train: iter 478  trainloss -2041.89744  validloss -1019.96384±0.00000  bestvalidloss -1984.96304  last_update 19\n",
      "train: iter 479  trainloss -2095.13948  validloss -1902.69958±0.00000  bestvalidloss -1984.96304  last_update 20\n",
      "train: iter 480  trainloss -2070.31545  validloss -1946.27382±0.00000  bestvalidloss -1984.96304  last_update 21\n",
      "train: iter 481  trainloss -2106.05266  validloss -1938.94625±0.00000  bestvalidloss -1984.96304  last_update 22\n",
      "train: iter 482  trainloss -2030.57833  validloss -1823.57125±0.00000  bestvalidloss -1984.96304  last_update 23\n",
      "train: iter 483  trainloss -1993.98140  validloss -1688.89100±0.00000  bestvalidloss -1984.96304  last_update 24\n",
      "train: iter 484  trainloss -2075.66939  validloss -1885.41719±0.00000  bestvalidloss -1984.96304  last_update 25\n",
      "train: iter 485  trainloss -2093.48526  validloss -1896.29647±0.00000  bestvalidloss -1984.96304  last_update 26\n",
      "train: iter 486  trainloss -2076.90728  validloss -1934.93993±0.00000  bestvalidloss -1984.96304  last_update 27\n",
      "train: iter 487  trainloss -2093.27049  validloss -1910.78073±0.00000  bestvalidloss -1984.96304  last_update 28\n",
      "train: iter 488  trainloss -2011.85027  validloss -1957.22382±0.00000  bestvalidloss -1984.96304  last_update 29\n",
      "train: iter 489  trainloss -2085.71602  validloss -1368.22355±0.00000  bestvalidloss -1984.96304  last_update 30\n",
      "train: iter 490  trainloss -2064.20883  validloss -1815.99028±0.00000  bestvalidloss -1984.96304  last_update 31\n",
      "train: iter 491  trainloss -2107.30806  validloss -1886.53195±0.00000  bestvalidloss -1984.96304  last_update 32\n",
      "train: iter 492  trainloss -2103.65173  validloss -1947.00928±0.00000  bestvalidloss -1984.96304  last_update 33\n",
      "train: iter 493  trainloss -2116.42650  validloss -1974.51351±0.00000  bestvalidloss -1984.96304  last_update 34\n",
      "train: iter 494  trainloss -2073.82864  validloss -1971.16023±0.00000  bestvalidloss -1984.96304  last_update 35\n",
      "train: iter 495  trainloss -2064.22799  validloss -1673.30998±0.00000  bestvalidloss -1984.96304  last_update 36\n",
      "train: iter 496  trainloss -1990.14546  validloss -1871.41251±0.00000  bestvalidloss -1984.96304  last_update 37\n",
      "train: iter 497  trainloss -2089.74070  validloss -1826.74922±0.00000  bestvalidloss -1984.96304  last_update 38\n",
      "train: iter 498  trainloss -2102.22674  validloss -1902.84256±0.00000  bestvalidloss -1984.96304  last_update 39\n",
      "train: iter 499  trainloss -2054.24210  validloss -1359.16867±0.00000  bestvalidloss -1984.96304  last_update 40\n",
      "train: iter 500  trainloss -2003.01326  validloss -1923.59444±0.00000  bestvalidloss -1984.96304  last_update 41\n",
      "train: iter 501  trainloss -2067.16063  validloss -1393.48985±0.00000  bestvalidloss -1984.96304  last_update 42\n",
      "train: iter 502  trainloss -2100.41726  validloss -1885.27747±0.00000  bestvalidloss -1984.96304  last_update 43\n",
      "train: iter 503  trainloss -2097.24643  validloss -1899.49510±0.00000  bestvalidloss -1984.96304  last_update 44\n",
      "train: iter 504  trainloss -2088.28784  validloss -1930.45183±0.00000  bestvalidloss -1984.96304  last_update 45\n",
      "train: iter 505  trainloss -2105.31006  validloss -1920.72275±0.00000  bestvalidloss -1984.96304  last_update 46\n",
      "train: iter 506  trainloss -1995.50129  validloss -1815.02015±0.00000  bestvalidloss -1984.96304  last_update 47\n",
      "train: iter 507  trainloss -1902.40485  validloss -671.55892±0.00000  bestvalidloss -1984.96304  last_update 48\n",
      "train: iter 508  trainloss -2076.22433  validloss -1761.64391±0.00000  bestvalidloss -1984.96304  last_update 49\n",
      "train: iter 509  trainloss -2091.47768  validloss -1824.72782±0.00000  bestvalidloss -1984.96304  last_update 50\n",
      "train: iter 510  trainloss -2061.27542  validloss -1833.94307±0.00000  bestvalidloss -1984.96304  last_update 51\n",
      "train: iter 511  trainloss -2067.60092  validloss -1865.47987±0.00000  bestvalidloss -1984.96304  last_update 52\n",
      "train: iter 512  trainloss -2087.83188  validloss -1823.80717±0.00000  bestvalidloss -1984.96304  last_update 53\n",
      "train: iter 513  trainloss -2013.05109  validloss -1851.36587±0.00000  bestvalidloss -1984.96304  last_update 54\n",
      "train: iter 514  trainloss -2032.94370  validloss -1836.98408±0.00000  bestvalidloss -1984.96304  last_update 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 515  trainloss -2098.01824  validloss -1875.41079±0.00000  bestvalidloss -1984.96304  last_update 56\n",
      "train: iter 516  trainloss -2106.61452  validloss -1937.29428±0.00000  bestvalidloss -1984.96304  last_update 57\n",
      "train: iter 517  trainloss -2111.05630  validloss -1884.61833±0.00000  bestvalidloss -1984.96304  last_update 58\n",
      "train: iter 518  trainloss -2023.74478  validloss -1909.29207±0.00000  bestvalidloss -1984.96304  last_update 59\n",
      "train: iter 519  trainloss -2075.51257  validloss -1754.97143±0.00000  bestvalidloss -1984.96304  last_update 60\n",
      "train: iter 520  trainloss -2113.74665  validloss -1823.29386±0.00000  bestvalidloss -1984.96304  last_update 61\n",
      "train: iter 521  trainloss -2104.14853  validloss -1970.90305±0.00000  bestvalidloss -1984.96304  last_update 62\n",
      "train: iter 522  trainloss -2044.21615  validloss -1468.98795±0.00000  bestvalidloss -1984.96304  last_update 63\n",
      "train: iter 523  trainloss -2043.51295  validloss -1777.82551±0.00000  bestvalidloss -1984.96304  last_update 64\n",
      "train: iter 524  trainloss -2009.30497  validloss -1892.09879±0.00000  bestvalidloss -1984.96304  last_update 65\n",
      "train: iter 525  trainloss -2041.77718  validloss -1940.37627±0.00000  bestvalidloss -1984.96304  last_update 66\n",
      "train: iter 526  trainloss -2067.64088  validloss -1904.39361±0.00000  bestvalidloss -1984.96304  last_update 67\n",
      "train: iter 527  trainloss -2055.19017  validloss -1898.13289±0.00000  bestvalidloss -1984.96304  last_update 68\n",
      "train: iter 528  trainloss -2103.81030  validloss -1934.37766±0.00000  bestvalidloss -1984.96304  last_update 69\n",
      "train: iter 529  trainloss -2092.60372  validloss -1953.22171±0.00000  bestvalidloss -1984.96304  last_update 70\n",
      "train: iter 530  trainloss -2113.89285  validloss -1978.26218±0.00000  bestvalidloss -1984.96304  last_update 71\n",
      "train: iter 531  trainloss -2063.43608  validloss -1344.08260±0.00000  bestvalidloss -1984.96304  last_update 72\n",
      "train: iter 532  trainloss -2091.00170  validloss -1948.81074±0.00000  bestvalidloss -1984.96304  last_update 73\n",
      "train: iter 533  trainloss -2060.98105  validloss -1338.74111±0.00000  bestvalidloss -1984.96304  last_update 74\n",
      "train: iter 534  trainloss -2072.52483  validloss -1889.49379±0.00000  bestvalidloss -1984.96304  last_update 75\n",
      "train: iter 535  trainloss -2097.52543  validloss -1922.30757±0.00000  bestvalidloss -1984.96304  last_update 76\n",
      "train: iter 536  trainloss -2089.56413  validloss -1943.36580±0.00000  bestvalidloss -1984.96304  last_update 77\n",
      "train: iter 537  trainloss -2102.50607  validloss -1902.25343±0.00000  bestvalidloss -1984.96304  last_update 78\n",
      "train: iter 538  trainloss -1992.96602  validloss -883.69409±0.00000  bestvalidloss -1984.96304  last_update 79\n",
      "train: iter 539  trainloss -1690.88238  validloss -1748.77136±0.00000  bestvalidloss -1984.96304  last_update 80\n",
      "train: iter 540  trainloss -2061.45476  validloss -1796.68268±0.00000  bestvalidloss -1984.96304  last_update 81\n",
      "train: iter 541  trainloss -2090.92685  validloss -1839.62370±0.00000  bestvalidloss -1984.96304  last_update 82\n",
      "train: iter 542  trainloss -2077.14300  validloss -1905.32104±0.00000  bestvalidloss -1984.96304  last_update 83\n",
      "train: iter 543  trainloss -2103.63665  validloss -1887.59017±0.00000  bestvalidloss -1984.96304  last_update 84\n",
      "train: iter 544  trainloss -2101.99348  validloss -1861.36011±0.00000  bestvalidloss -1984.96304  last_update 85\n",
      "train: iter 545  trainloss -2100.25738  validloss -1958.71728±0.00000  bestvalidloss -1984.96304  last_update 86\n",
      "train: iter 546  trainloss -2101.42523  validloss -1645.61830±0.00000  bestvalidloss -1984.96304  last_update 87\n",
      "train: iter 547  trainloss -2120.02982  validloss -1784.56651±0.00000  bestvalidloss -1984.96304  last_update 88\n",
      "train: iter 548  trainloss -2027.69842  validloss -1964.84348±0.00000  bestvalidloss -1984.96304  last_update 89\n",
      "train: iter 549  trainloss -1944.88055  validloss -1940.74155±0.00000  bestvalidloss -1984.96304  last_update 90\n",
      "train: iter 550  trainloss -2021.11721  validloss -1353.49605±0.00000  bestvalidloss -1984.96304  last_update 91\n",
      "train: iter 551  trainloss -2084.13791  validloss -1750.78270±0.00000  bestvalidloss -1984.96304  last_update 92\n",
      "train: iter 552  trainloss -2024.95113  validloss -1820.84444±0.00000  bestvalidloss -1984.96304  last_update 93\n",
      "train: iter 553  trainloss -2099.38068  validloss -1867.28568±0.00000  bestvalidloss -1984.96304  last_update 94\n",
      "train: iter 554  trainloss -2100.13407  validloss -1878.16580±0.00000  bestvalidloss -1984.96304  last_update 95\n",
      "train: iter 555  trainloss -2098.27784  validloss -1815.54300±0.00000  bestvalidloss -1984.96304  last_update 96\n",
      "train: iter 556  trainloss -2080.14710  validloss -1775.64958±0.00000  bestvalidloss -1984.96304  last_update 97\n",
      "train: iter 557  trainloss -2103.79255  validloss -1879.11367±0.00000  bestvalidloss -1984.96304  last_update 98\n",
      "train: iter 558  trainloss -2111.14574  validloss -1896.73118±0.00000  bestvalidloss -1984.96304  last_update 99\n",
      "train: iter 559  trainloss -2116.42250  validloss -1932.78977±0.00000  bestvalidloss -1984.96304  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.1694) penalty_target_max tensor(7.1089)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.08848  validloss 9.14897±0.00000  bestvalidloss 9.14897  last_update 0\n",
      "train: iter 1  trainloss 8.29356  validloss 8.31456±0.00000  bestvalidloss 8.31456  last_update 0\n",
      "train: iter 2  trainloss 7.63790  validloss 7.66182±0.00000  bestvalidloss 7.66182  last_update 0\n",
      "train: iter 3  trainloss 7.08375  validloss 7.07459±0.00000  bestvalidloss 7.07459  last_update 0\n",
      "train: iter 4  trainloss 6.61835  validloss 6.59894±0.00000  bestvalidloss 6.59894  last_update 0\n",
      "train: iter 5  trainloss 6.22557  validloss 6.18403±0.00000  bestvalidloss 6.18403  last_update 0\n",
      "train: iter 6  trainloss 5.88218  validloss 5.83783±0.00000  bestvalidloss 5.83783  last_update 0\n",
      "train: iter 7  trainloss 5.58611  validloss 5.52496±0.00000  bestvalidloss 5.52496  last_update 0\n",
      "train: iter 8  trainloss 5.31641  validloss 5.24628±0.00000  bestvalidloss 5.24628  last_update 0\n",
      "train: iter 9  trainloss 5.08695  validloss 5.01373±0.00000  bestvalidloss 5.01373  last_update 0\n",
      "train: iter 10  trainloss 4.87303  validloss 4.82441±0.00000  bestvalidloss 4.82441  last_update 0\n",
      "train: iter 11  trainloss 4.67131  validloss 4.61492±0.00000  bestvalidloss 4.61492  last_update 0\n",
      "train: iter 12  trainloss 4.50284  validloss 4.44612±0.00000  bestvalidloss 4.44612  last_update 0\n",
      "train: iter 13  trainloss 4.33087  validloss 4.27372±0.00000  bestvalidloss 4.27372  last_update 0\n",
      "train: iter 14  trainloss 4.17832  validloss 4.13395±0.00000  bestvalidloss 4.13395  last_update 0\n",
      "train: iter 15  trainloss 4.03419  validloss 3.96915±0.00000  bestvalidloss 3.96915  last_update 0\n",
      "train: iter 16  trainloss 3.88865  validloss 3.83737±0.00000  bestvalidloss 3.83737  last_update 0\n",
      "train: iter 17  trainloss 3.74979  validloss 3.70761±0.00000  bestvalidloss 3.70761  last_update 0\n",
      "train: iter 18  trainloss 3.60898  validloss 3.57279±0.00000  bestvalidloss 3.57279  last_update 0\n",
      "train: iter 19  trainloss 3.48246  validloss 3.45127±0.00000  bestvalidloss 3.45127  last_update 0\n",
      "train: iter 20  trainloss 3.35598  validloss 3.31681±0.00000  bestvalidloss 3.31681  last_update 0\n",
      "train: iter 21  trainloss 3.22688  validloss 3.19280±0.00000  bestvalidloss 3.19280  last_update 0\n",
      "train: iter 22  trainloss 3.10371  validloss 3.07969±0.00000  bestvalidloss 3.07969  last_update 0\n",
      "train: iter 23  trainloss 2.98605  validloss 2.96846±0.00000  bestvalidloss 2.96846  last_update 0\n",
      "train: iter 24  trainloss 2.87535  validloss 2.85640±0.00000  bestvalidloss 2.85640  last_update 0\n",
      "train: iter 25  trainloss 2.76778  validloss 2.74825±0.00000  bestvalidloss 2.74825  last_update 0\n",
      "train: iter 26  trainloss 2.66567  validloss 2.64713±0.00000  bestvalidloss 2.64713  last_update 0\n",
      "train: iter 27  trainloss 2.57027  validloss 2.55318±0.00000  bestvalidloss 2.55318  last_update 0\n",
      "train: iter 28  trainloss 2.47907  validloss 2.46136±0.00000  bestvalidloss 2.46136  last_update 0\n",
      "train: iter 29  trainloss 2.39861  validloss 2.38948±0.00000  bestvalidloss 2.38948  last_update 0\n",
      "train: iter 30  trainloss 2.31589  validloss 2.31072±0.00000  bestvalidloss 2.31072  last_update 0\n",
      "train: iter 31  trainloss 2.24160  validloss 2.22853±0.00000  bestvalidloss 2.22853  last_update 0\n",
      "train: iter 32  trainloss 2.16777  validloss 2.15844±0.00000  bestvalidloss 2.15844  last_update 0\n",
      "train: iter 33  trainloss 2.09618  validloss 2.09151±0.00000  bestvalidloss 2.09151  last_update 0\n",
      "train: iter 34  trainloss 2.02247  validloss 2.02729±0.00000  bestvalidloss 2.02729  last_update 0\n",
      "train: iter 35  trainloss 1.95307  validloss 1.95768±0.00000  bestvalidloss 1.95768  last_update 0\n",
      "train: iter 36  trainloss 1.88957  validloss 1.90122±0.00000  bestvalidloss 1.90122  last_update 0\n",
      "train: iter 37  trainloss 1.81319  validloss 1.83221±0.00000  bestvalidloss 1.83221  last_update 0\n",
      "train: iter 38  trainloss 1.75106  validloss 1.75854±0.00000  bestvalidloss 1.75854  last_update 0\n",
      "train: iter 39  trainloss 1.68144  validloss 1.69627±0.00000  bestvalidloss 1.69627  last_update 0\n",
      "train: iter 40  trainloss 1.61833  validloss 1.65767±0.00000  bestvalidloss 1.65767  last_update 0\n",
      "train: iter 41  trainloss 1.54929  validloss 1.57188±0.00000  bestvalidloss 1.57188  last_update 0\n",
      "train: iter 42  trainloss 1.48102  validloss 1.52031±0.00000  bestvalidloss 1.52031  last_update 0\n",
      "train: iter 43  trainloss 1.42110  validloss 1.44028±0.00000  bestvalidloss 1.44028  last_update 0\n",
      "train: iter 44  trainloss 1.35191  validloss 1.39617±0.00000  bestvalidloss 1.39617  last_update 0\n",
      "train: iter 45  trainloss 1.29057  validloss 1.32924±0.00000  bestvalidloss 1.32924  last_update 0\n",
      "train: iter 46  trainloss 1.23014  validloss 1.27762±0.00000  bestvalidloss 1.27762  last_update 0\n",
      "train: iter 47  trainloss 1.15673  validloss 1.21587±0.00000  bestvalidloss 1.21587  last_update 0\n",
      "train: iter 48  trainloss 1.07661  validloss 1.13660±0.00000  bestvalidloss 1.13660  last_update 0\n",
      "train: iter 49  trainloss 1.00593  validloss 1.07932±0.00000  bestvalidloss 1.07932  last_update 0\n",
      "train: iter 50  trainloss 0.94945  validloss 1.04233±0.00000  bestvalidloss 1.04233  last_update 0\n",
      "train: iter 51  trainloss 0.86457  validloss 0.96506±0.00000  bestvalidloss 0.96506  last_update 0\n",
      "train: iter 52  trainloss 0.80163  validloss 0.86362±0.00000  bestvalidloss 0.86362  last_update 0\n",
      "train: iter 53  trainloss 0.74494  validloss 0.78020±0.00000  bestvalidloss 0.78020  last_update 0\n",
      "train: iter 54  trainloss 0.66294  validloss 0.71479±0.00000  bestvalidloss 0.71479  last_update 0\n",
      "train: iter 55  trainloss 0.59659  validloss 0.72164±0.00000  bestvalidloss 0.71479  last_update 1\n",
      "train: iter 56  trainloss 0.50462  validloss 0.60995±0.00000  bestvalidloss 0.60995  last_update 0\n",
      "train: iter 57  trainloss 0.42692  validloss 0.51056±0.00000  bestvalidloss 0.51056  last_update 0\n",
      "train: iter 58  trainloss 0.36400  validloss 0.49907±0.00000  bestvalidloss 0.49907  last_update 0\n",
      "train: iter 59  trainloss 0.27003  validloss 0.45172±0.00000  bestvalidloss 0.45172  last_update 0\n",
      "train: iter 60  trainloss 0.20730  validloss 0.41754±0.00000  bestvalidloss 0.41754  last_update 0\n",
      "train: iter 61  trainloss 0.11603  validloss 0.33292±0.00000  bestvalidloss 0.33292  last_update 0\n",
      "train: iter 62  trainloss 0.05894  validloss 0.20248±0.00000  bestvalidloss 0.20248  last_update 0\n",
      "train: iter 63  trainloss -0.02076  validloss 0.27203±0.00000  bestvalidloss 0.20248  last_update 1\n",
      "train: iter 64  trainloss -0.09128  validloss 0.10721±0.00000  bestvalidloss 0.10721  last_update 0\n",
      "train: iter 65  trainloss -0.16844  validloss 0.02239±0.00000  bestvalidloss 0.02239  last_update 0\n",
      "train: iter 66  trainloss -0.23507  validloss 0.08110±0.00000  bestvalidloss 0.02239  last_update 1\n",
      "train: iter 67  trainloss -0.32566  validloss 0.06018±0.00000  bestvalidloss 0.02239  last_update 2\n",
      "train: iter 68  trainloss -0.35099  validloss -0.20058±0.00000  bestvalidloss -0.20058  last_update 0\n",
      "train: iter 69  trainloss -0.41230  validloss -0.09970±0.00000  bestvalidloss -0.20058  last_update 1\n",
      "train: iter 70  trainloss -0.47433  validloss -0.13518±0.00000  bestvalidloss -0.20058  last_update 2\n",
      "train: iter 71  trainloss -0.54614  validloss -0.18189±0.00000  bestvalidloss -0.20058  last_update 3\n",
      "train: iter 72  trainloss -0.60661  validloss -0.10258±0.00000  bestvalidloss -0.20058  last_update 4\n",
      "train: iter 73  trainloss -0.62701  validloss -0.23608±0.00000  bestvalidloss -0.23608  last_update 0\n",
      "train: iter 74  trainloss -0.70911  validloss -0.25225±0.00000  bestvalidloss -0.25225  last_update 0\n",
      "train: iter 75  trainloss -0.77982  validloss -0.39254±0.00000  bestvalidloss -0.39254  last_update 0\n",
      "train: iter 76  trainloss -0.83557  validloss -0.41772±0.00000  bestvalidloss -0.41772  last_update 0\n",
      "train: iter 77  trainloss -0.89335  validloss -0.18248±0.00000  bestvalidloss -0.41772  last_update 1\n",
      "train: iter 78  trainloss -0.89402  validloss -0.42143±0.00000  bestvalidloss -0.42143  last_update 0\n",
      "train: iter 79  trainloss -0.94304  validloss -0.58250±0.00000  bestvalidloss -0.58250  last_update 0\n",
      "train: iter 80  trainloss -0.97483  validloss -0.37661±0.00000  bestvalidloss -0.58250  last_update 1\n",
      "train: iter 81  trainloss -1.05187  validloss -0.36523±0.00000  bestvalidloss -0.58250  last_update 2\n",
      "train: iter 82  trainloss -1.11758  validloss -0.45167±0.00000  bestvalidloss -0.58250  last_update 3\n",
      "train: iter 83  trainloss -1.10743  validloss -0.67034±0.00000  bestvalidloss -0.67034  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss -1.14073  validloss -0.57168±0.00000  bestvalidloss -0.67034  last_update 1\n",
      "train: iter 85  trainloss -1.25270  validloss -0.38318±0.00000  bestvalidloss -0.67034  last_update 2\n",
      "train: iter 86  trainloss -1.28824  validloss -0.47657±0.00000  bestvalidloss -0.67034  last_update 3\n",
      "train: iter 87  trainloss -1.24903  validloss -0.67995±0.00000  bestvalidloss -0.67995  last_update 0\n",
      "train: iter 88  trainloss -1.29040  validloss -0.64368±0.00000  bestvalidloss -0.67995  last_update 1\n",
      "train: iter 89  trainloss -1.27145  validloss -0.74451±0.00000  bestvalidloss -0.74451  last_update 0\n",
      "train: iter 90  trainloss -1.31415  validloss -0.67460±0.00000  bestvalidloss -0.74451  last_update 1\n",
      "train: iter 91  trainloss -1.31530  validloss -0.51347±0.00000  bestvalidloss -0.74451  last_update 2\n",
      "train: iter 92  trainloss -1.47462  validloss -0.31161±0.00000  bestvalidloss -0.74451  last_update 3\n",
      "train: iter 93  trainloss -1.35753  validloss -0.87718±0.00000  bestvalidloss -0.87718  last_update 0\n",
      "train: iter 94  trainloss -1.47662  validloss -0.64453±0.00000  bestvalidloss -0.87718  last_update 1\n",
      "train: iter 95  trainloss -1.49608  validloss -0.66438±0.00000  bestvalidloss -0.87718  last_update 2\n",
      "train: iter 96  trainloss -1.59005  validloss -0.83899±0.00000  bestvalidloss -0.87718  last_update 3\n",
      "train: iter 97  trainloss -1.53272  validloss -0.73094±0.00000  bestvalidloss -0.87718  last_update 4\n",
      "train: iter 98  trainloss -1.65197  validloss -0.69332±0.00000  bestvalidloss -0.87718  last_update 5\n",
      "train: iter 99  trainloss -1.57176  validloss -0.64049±0.00000  bestvalidloss -0.87718  last_update 6\n",
      "train: iter 100  trainloss -1.52437  validloss -0.48024±0.00000  bestvalidloss -0.87718  last_update 7\n",
      "train: iter 101  trainloss -1.60675  validloss -0.83117±0.00000  bestvalidloss -0.87718  last_update 8\n",
      "train: iter 102  trainloss -1.58917  validloss -0.52492±0.00000  bestvalidloss -0.87718  last_update 9\n",
      "train: iter 103  trainloss -1.71567  validloss -0.48092±0.00000  bestvalidloss -0.87718  last_update 10\n",
      "train: iter 104  trainloss -1.75834  validloss -0.54804±0.00000  bestvalidloss -0.87718  last_update 11\n",
      "train: iter 105  trainloss -1.74068  validloss -0.16835±0.00000  bestvalidloss -0.87718  last_update 12\n",
      "train: iter 106  trainloss -1.70713  validloss -0.62111±0.00000  bestvalidloss -0.87718  last_update 13\n",
      "train: iter 107  trainloss -1.75856  validloss -0.71297±0.00000  bestvalidloss -0.87718  last_update 14\n",
      "train: iter 108  trainloss -1.72404  validloss -0.66544±0.00000  bestvalidloss -0.87718  last_update 15\n",
      "train: iter 109  trainloss -1.76549  validloss -0.62043±0.00000  bestvalidloss -0.87718  last_update 16\n",
      "train: iter 110  trainloss -1.75925  validloss -0.82276±0.00000  bestvalidloss -0.87718  last_update 17\n",
      "train: iter 111  trainloss -1.73875  validloss -0.47591±0.00000  bestvalidloss -0.87718  last_update 18\n",
      "train: iter 112  trainloss -1.84842  validloss -0.65725±0.00000  bestvalidloss -0.87718  last_update 19\n",
      "train: iter 113  trainloss -1.88545  validloss -0.33370±0.00000  bestvalidloss -0.87718  last_update 20\n",
      "train: iter 114  trainloss -1.78114  validloss -0.69604±0.00000  bestvalidloss -0.87718  last_update 21\n",
      "train: iter 115  trainloss -1.66644  validloss -0.22536±0.00000  bestvalidloss -0.87718  last_update 22\n",
      "train: iter 116  trainloss -1.91335  validloss -0.39038±0.00000  bestvalidloss -0.87718  last_update 23\n",
      "train: iter 117  trainloss -1.83315  validloss -0.26680±0.00000  bestvalidloss -0.87718  last_update 24\n",
      "train: iter 118  trainloss -1.87733  validloss -0.52604±0.00000  bestvalidloss -0.87718  last_update 25\n",
      "train: iter 119  trainloss -1.72503  validloss -0.67540±0.00000  bestvalidloss -0.87718  last_update 26\n",
      "train: iter 120  trainloss -1.86253  validloss -0.17769±0.00000  bestvalidloss -0.87718  last_update 27\n",
      "train: iter 121  trainloss -1.77870  validloss -0.21929±0.00000  bestvalidloss -0.87718  last_update 28\n",
      "train: iter 122  trainloss -1.83615  validloss -0.49988±0.00000  bestvalidloss -0.87718  last_update 29\n",
      "train: iter 123  trainloss -1.84546  validloss -0.53749±0.00000  bestvalidloss -0.87718  last_update 30\n",
      "train: iter 124  trainloss -1.88852  validloss -0.54622±0.00000  bestvalidloss -0.87718  last_update 31\n",
      "train: iter 125  trainloss -1.92219  validloss -0.60348±0.00000  bestvalidloss -0.87718  last_update 32\n",
      "train: iter 126  trainloss -1.72902  validloss -0.42510±0.00000  bestvalidloss -0.87718  last_update 33\n",
      "train: iter 127  trainloss -1.77653  validloss -0.83818±0.00000  bestvalidloss -0.87718  last_update 34\n",
      "train: iter 128  trainloss -1.81376  validloss 0.23877±0.00000  bestvalidloss -0.87718  last_update 35\n",
      "train: iter 129  trainloss -1.79967  validloss -0.36699±0.00000  bestvalidloss -0.87718  last_update 36\n",
      "train: iter 130  trainloss -1.92093  validloss -0.07379±0.00000  bestvalidloss -0.87718  last_update 37\n",
      "train: iter 131  trainloss -1.88287  validloss -0.17806±0.00000  bestvalidloss -0.87718  last_update 38\n",
      "train: iter 132  trainloss -1.84037  validloss 0.18798±0.00000  bestvalidloss -0.87718  last_update 39\n",
      "train: iter 133  trainloss -1.88707  validloss -0.27049±0.00000  bestvalidloss -0.87718  last_update 40\n",
      "train: iter 134  trainloss -1.78374  validloss 0.17037±0.00000  bestvalidloss -0.87718  last_update 41\n",
      "train: iter 135  trainloss -1.89582  validloss -0.42930±0.00000  bestvalidloss -0.87718  last_update 42\n",
      "train: iter 136  trainloss -1.93936  validloss -0.35938±0.00000  bestvalidloss -0.87718  last_update 43\n",
      "train: iter 137  trainloss -1.81306  validloss -0.40210±0.00000  bestvalidloss -0.87718  last_update 44\n",
      "train: iter 138  trainloss -1.79834  validloss -0.45433±0.00000  bestvalidloss -0.87718  last_update 45\n",
      "train: iter 139  trainloss -1.81768  validloss 0.10956±0.00000  bestvalidloss -0.87718  last_update 46\n",
      "train: iter 140  trainloss -1.88545  validloss 0.04957±0.00000  bestvalidloss -0.87718  last_update 47\n",
      "train: iter 141  trainloss -1.77501  validloss -0.43434±0.00000  bestvalidloss -0.87718  last_update 48\n",
      "train: iter 142  trainloss -1.72821  validloss -0.05314±0.00000  bestvalidloss -0.87718  last_update 49\n",
      "train: iter 143  trainloss -1.91380  validloss -0.52856±0.00000  bestvalidloss -0.87718  last_update 50\n",
      "train: iter 144  trainloss -1.80157  validloss 0.03876±0.00000  bestvalidloss -0.87718  last_update 51\n",
      "train: iter 145  trainloss -1.99036  validloss -0.18274±0.00000  bestvalidloss -0.87718  last_update 52\n",
      "train: iter 146  trainloss -1.91889  validloss -0.35339±0.00000  bestvalidloss -0.87718  last_update 53\n",
      "train: iter 147  trainloss -1.92104  validloss -0.13451±0.00000  bestvalidloss -0.87718  last_update 54\n",
      "train: iter 148  trainloss -1.84776  validloss -0.15542±0.00000  bestvalidloss -0.87718  last_update 55\n",
      "train: iter 149  trainloss -1.86316  validloss -0.44669±0.00000  bestvalidloss -0.87718  last_update 56\n",
      "train: iter 150  trainloss -1.91316  validloss -0.40669±0.00000  bestvalidloss -0.87718  last_update 57\n",
      "train: iter 151  trainloss -1.86760  validloss 0.04839±0.00000  bestvalidloss -0.87718  last_update 58\n",
      "train: iter 152  trainloss -1.97803  validloss 0.11642±0.00000  bestvalidloss -0.87718  last_update 59\n",
      "train: iter 153  trainloss -1.79825  validloss 0.08715±0.00000  bestvalidloss -0.87718  last_update 60\n",
      "train: iter 154  trainloss -1.83446  validloss -0.08855±0.00000  bestvalidloss -0.87718  last_update 61\n",
      "train: iter 155  trainloss -2.00200  validloss -0.10933±0.00000  bestvalidloss -0.87718  last_update 62\n",
      "train: iter 156  trainloss -1.91617  validloss -0.30172±0.00000  bestvalidloss -0.87718  last_update 63\n",
      "train: iter 157  trainloss -1.81194  validloss 0.21329±0.00000  bestvalidloss -0.87718  last_update 64\n",
      "train: iter 158  trainloss -1.97959  validloss -0.30982±0.00000  bestvalidloss -0.87718  last_update 65\n",
      "train: iter 159  trainloss -1.91643  validloss 0.21800±0.00000  bestvalidloss -0.87718  last_update 66\n",
      "train: iter 160  trainloss -1.72411  validloss -0.07552±0.00000  bestvalidloss -0.87718  last_update 67\n",
      "train: iter 161  trainloss -1.97577  validloss 0.00061±0.00000  bestvalidloss -0.87718  last_update 68\n",
      "train: iter 162  trainloss -1.92217  validloss 0.24313±0.00000  bestvalidloss -0.87718  last_update 69\n",
      "train: iter 163  trainloss -1.83236  validloss 0.03486±0.00000  bestvalidloss -0.87718  last_update 70\n",
      "train: iter 164  trainloss -1.97392  validloss -0.04528±0.00000  bestvalidloss -0.87718  last_update 71\n",
      "train: iter 165  trainloss -2.09715  validloss -0.07459±0.00000  bestvalidloss -0.87718  last_update 72\n",
      "train: iter 166  trainloss -1.85672  validloss 0.10263±0.00000  bestvalidloss -0.87718  last_update 73\n",
      "train: iter 167  trainloss -1.81397  validloss 0.18289±0.00000  bestvalidloss -0.87718  last_update 74\n",
      "train: iter 168  trainloss -1.66117  validloss 0.22568±0.00000  bestvalidloss -0.87718  last_update 75\n",
      "train: iter 169  trainloss -2.00395  validloss -0.19613±0.00000  bestvalidloss -0.87718  last_update 76\n",
      "train: iter 170  trainloss -2.06857  validloss -0.21568±0.00000  bestvalidloss -0.87718  last_update 77\n",
      "train: iter 171  trainloss -1.79205  validloss -0.18218±0.00000  bestvalidloss -0.87718  last_update 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 172  trainloss -1.65831  validloss 0.09640±0.00000  bestvalidloss -0.87718  last_update 79\n",
      "train: iter 173  trainloss -1.89466  validloss -0.16179±0.00000  bestvalidloss -0.87718  last_update 80\n",
      "train: iter 174  trainloss -1.74781  validloss 0.13283±0.00000  bestvalidloss -0.87718  last_update 81\n",
      "train: iter 175  trainloss -1.73588  validloss 0.09721±0.00000  bestvalidloss -0.87718  last_update 82\n",
      "train: iter 176  trainloss -1.95863  validloss -0.35390±0.00000  bestvalidloss -0.87718  last_update 83\n",
      "train: iter 177  trainloss -1.87287  validloss -0.04893±0.00000  bestvalidloss -0.87718  last_update 84\n",
      "train: iter 178  trainloss -1.87950  validloss 0.36877±0.00000  bestvalidloss -0.87718  last_update 85\n",
      "train: iter 179  trainloss -1.95939  validloss -0.02871±0.00000  bestvalidloss -0.87718  last_update 86\n",
      "train: iter 180  trainloss -1.96073  validloss 0.26835±0.00000  bestvalidloss -0.87718  last_update 87\n",
      "train: iter 181  trainloss -1.91494  validloss -0.39461±0.00000  bestvalidloss -0.87718  last_update 88\n",
      "train: iter 182  trainloss -1.88247  validloss -0.03955±0.00000  bestvalidloss -0.87718  last_update 89\n",
      "train: iter 183  trainloss -1.78612  validloss -0.18174±0.00000  bestvalidloss -0.87718  last_update 90\n",
      "train: iter 184  trainloss -1.94450  validloss -0.18199±0.00000  bestvalidloss -0.87718  last_update 91\n",
      "train: iter 185  trainloss -1.75186  validloss -0.02302±0.00000  bestvalidloss -0.87718  last_update 92\n",
      "train: iter 186  trainloss -1.99207  validloss -0.07657±0.00000  bestvalidloss -0.87718  last_update 93\n",
      "train: iter 187  trainloss -1.89527  validloss -0.06075±0.00000  bestvalidloss -0.87718  last_update 94\n",
      "train: iter 188  trainloss -1.87890  validloss 0.58490±0.00000  bestvalidloss -0.87718  last_update 95\n",
      "train: iter 189  trainloss -2.08422  validloss 0.02232±0.00000  bestvalidloss -0.87718  last_update 96\n",
      "train: iter 190  trainloss -1.89976  validloss 0.94419±0.00000  bestvalidloss -0.87718  last_update 97\n",
      "train: iter 191  trainloss -1.93973  validloss -0.42731±0.00000  bestvalidloss -0.87718  last_update 98\n",
      "train: iter 192  trainloss -1.74994  validloss -0.11458±0.00000  bestvalidloss -0.87718  last_update 99\n",
      "train: iter 193  trainloss -1.86773  validloss -0.28568±0.00000  bestvalidloss -0.87718  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.7301, -3.5216, -5.0672, -2.1888], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 103.29135  validloss 106.14939±0.00000  bestvalidloss 106.14939  last_update 0\n",
      "train: iter 1  trainloss 75.27395  validloss 82.76942±0.00000  bestvalidloss 82.76942  last_update 0\n",
      "train: iter 2  trainloss 55.55624  validloss 58.84644±0.00000  bestvalidloss 58.84644  last_update 0\n",
      "train: iter 3  trainloss 43.62379  validloss 45.76739±0.00000  bestvalidloss 45.76739  last_update 0\n",
      "train: iter 4  trainloss 35.08849  validloss 36.73812±0.00000  bestvalidloss 36.73812  last_update 0\n",
      "train: iter 5  trainloss 28.27609  validloss 29.91934±0.00000  bestvalidloss 29.91934  last_update 0\n",
      "train: iter 6  trainloss 22.75278  validloss 24.63132±0.00000  bestvalidloss 24.63132  last_update 0\n",
      "train: iter 7  trainloss 18.37703  validloss 20.41179±0.00000  bestvalidloss 20.41179  last_update 0\n",
      "train: iter 8  trainloss 14.79016  validloss 17.01852±0.00000  bestvalidloss 17.01852  last_update 0\n",
      "train: iter 9  trainloss 11.93684  validloss 14.58866±0.00000  bestvalidloss 14.58866  last_update 0\n",
      "train: iter 10  trainloss 9.61554  validloss 12.45364±0.00000  bestvalidloss 12.45364  last_update 0\n",
      "train: iter 11  trainloss 7.87407  validloss 10.92238±0.00000  bestvalidloss 10.92238  last_update 0\n",
      "train: iter 12  trainloss 6.43990  validloss 9.62778±0.00000  bestvalidloss 9.62778  last_update 0\n",
      "train: iter 13  trainloss 5.40191  validloss 8.83330±0.00000  bestvalidloss 8.83330  last_update 0\n",
      "train: iter 14  trainloss 4.54548  validloss 8.31560±0.00000  bestvalidloss 8.31560  last_update 0\n",
      "train: iter 15  trainloss 4.01496  validloss 7.89706±0.00000  bestvalidloss 7.89706  last_update 0\n",
      "train: iter 16  trainloss 3.47088  validloss 7.57459±0.00000  bestvalidloss 7.57459  last_update 0\n",
      "train: iter 17  trainloss 3.17076  validloss 7.43176±0.00000  bestvalidloss 7.43176  last_update 0\n",
      "train: iter 18  trainloss 2.97489  validloss 7.34381±0.00000  bestvalidloss 7.34381  last_update 0\n",
      "train: iter 19  trainloss 2.79667  validloss 7.35012±0.00000  bestvalidloss 7.34381  last_update 1\n",
      "train: iter 20  trainloss 2.69340  validloss 7.33513±0.00000  bestvalidloss 7.33513  last_update 0\n",
      "train: iter 21  trainloss 2.60580  validloss 7.44116±0.00000  bestvalidloss 7.33513  last_update 1\n",
      "train: iter 22  trainloss 2.53573  validloss 7.29454±0.00000  bestvalidloss 7.29454  last_update 0\n",
      "train: iter 23  trainloss 2.47105  validloss 7.57134±0.00000  bestvalidloss 7.29454  last_update 1\n",
      "train: iter 24  trainloss 2.46695  validloss 7.34915±0.00000  bestvalidloss 7.29454  last_update 2\n",
      "train: iter 25  trainloss 2.41945  validloss 7.49242±0.00000  bestvalidloss 7.29454  last_update 3\n",
      "train: iter 26  trainloss 2.40427  validloss 7.19659±0.00000  bestvalidloss 7.19659  last_update 0\n",
      "train: iter 27  trainloss 2.40913  validloss 7.42985±0.00000  bestvalidloss 7.19659  last_update 1\n",
      "train: iter 28  trainloss 2.38669  validloss 6.88639±0.00000  bestvalidloss 6.88639  last_update 0\n",
      "train: iter 29  trainloss 2.26616  validloss 8.20254±0.00000  bestvalidloss 6.88639  last_update 1\n",
      "train: iter 30  trainloss 2.26464  validloss 7.69172±0.00000  bestvalidloss 6.88639  last_update 2\n",
      "train: iter 31  trainloss 2.24511  validloss 8.60353±0.00000  bestvalidloss 6.88639  last_update 3\n",
      "train: iter 32  trainloss 2.21571  validloss 8.57668±0.00000  bestvalidloss 6.88639  last_update 4\n",
      "train: iter 33  trainloss 2.21293  validloss 7.94970±0.00000  bestvalidloss 6.88639  last_update 5\n",
      "train: iter 34  trainloss 2.15106  validloss 7.49419±0.00000  bestvalidloss 6.88639  last_update 6\n",
      "train: iter 35  trainloss 2.16436  validloss 7.59376±0.00000  bestvalidloss 6.88639  last_update 7\n",
      "train: iter 36  trainloss 2.13612  validloss 6.89208±0.00000  bestvalidloss 6.88639  last_update 8\n",
      "train: iter 37  trainloss 2.14962  validloss 6.36836±0.00000  bestvalidloss 6.36836  last_update 0\n",
      "train: iter 38  trainloss 2.09432  validloss 6.10715±0.00000  bestvalidloss 6.10715  last_update 0\n",
      "train: iter 39  trainloss 2.09446  validloss 5.78879±0.00000  bestvalidloss 5.78879  last_update 0\n",
      "train: iter 40  trainloss 2.06952  validloss 5.31018±0.00000  bestvalidloss 5.31018  last_update 0\n",
      "train: iter 41  trainloss 2.07131  validloss 5.02443±0.00000  bestvalidloss 5.02443  last_update 0\n",
      "train: iter 42  trainloss 2.04006  validloss 4.91766±0.00000  bestvalidloss 4.91766  last_update 0\n",
      "train: iter 43  trainloss 2.01446  validloss 4.79996±0.00000  bestvalidloss 4.79996  last_update 0\n",
      "train: iter 44  trainloss 1.90119  validloss 4.44942±0.00000  bestvalidloss 4.44942  last_update 0\n",
      "train: iter 45  trainloss 1.75427  validloss 4.52220±0.00000  bestvalidloss 4.44942  last_update 1\n",
      "train: iter 46  trainloss 1.67650  validloss 4.39676±0.00000  bestvalidloss 4.39676  last_update 0\n",
      "train: iter 47  trainloss 1.64371  validloss 4.34752±0.00000  bestvalidloss 4.34752  last_update 0\n",
      "train: iter 48  trainloss 1.61524  validloss 4.21304±0.00000  bestvalidloss 4.21304  last_update 0\n",
      "train: iter 49  trainloss 1.59643  validloss 4.10400±0.00000  bestvalidloss 4.10400  last_update 0\n",
      "train: iter 50  trainloss 1.63196  validloss 4.11598±0.00000  bestvalidloss 4.10400  last_update 1\n",
      "train: iter 51  trainloss 1.57862  validloss 4.19885±0.00000  bestvalidloss 4.10400  last_update 2\n",
      "train: iter 52  trainloss 1.56754  validloss 4.11281±0.00000  bestvalidloss 4.10400  last_update 3\n",
      "train: iter 53  trainloss 1.56737  validloss 4.26217±0.00000  bestvalidloss 4.10400  last_update 4\n",
      "train: iter 54  trainloss 1.57490  validloss 4.15487±0.00000  bestvalidloss 4.10400  last_update 5\n",
      "train: iter 55  trainloss 1.52255  validloss 4.14917±0.00000  bestvalidloss 4.10400  last_update 6\n",
      "train: iter 56  trainloss 1.49149  validloss 4.19472±0.00000  bestvalidloss 4.10400  last_update 7\n",
      "train: iter 57  trainloss 1.48727  validloss 4.09898±0.00000  bestvalidloss 4.09898  last_update 0\n",
      "train: iter 58  trainloss 1.47571  validloss 3.91605±0.00000  bestvalidloss 3.91605  last_update 0\n",
      "train: iter 59  trainloss 1.51082  validloss 3.83673±0.00000  bestvalidloss 3.83673  last_update 0\n",
      "train: iter 60  trainloss 1.47059  validloss 3.82786±0.00000  bestvalidloss 3.82786  last_update 0\n",
      "train: iter 61  trainloss 1.48742  validloss 3.89483±0.00000  bestvalidloss 3.82786  last_update 1\n",
      "train: iter 62  trainloss 1.48403  validloss 4.04955±0.00000  bestvalidloss 3.82786  last_update 2\n",
      "train: iter 63  trainloss 1.47575  validloss 3.79594±0.00000  bestvalidloss 3.79594  last_update 0\n",
      "train: iter 64  trainloss 1.46019  validloss 3.92490±0.00000  bestvalidloss 3.79594  last_update 1\n",
      "train: iter 65  trainloss 1.49763  validloss 3.84851±0.00000  bestvalidloss 3.79594  last_update 2\n",
      "train: iter 66  trainloss 1.48853  validloss 3.91845±0.00000  bestvalidloss 3.79594  last_update 3\n",
      "train: iter 67  trainloss 1.42523  validloss 3.86887±0.00000  bestvalidloss 3.79594  last_update 4\n",
      "train: iter 68  trainloss 1.44809  validloss 3.74123±0.00000  bestvalidloss 3.74123  last_update 0\n",
      "train: iter 69  trainloss 1.46087  validloss 4.06318±0.00000  bestvalidloss 3.74123  last_update 1\n",
      "train: iter 70  trainloss 1.44097  validloss 3.82965±0.00000  bestvalidloss 3.74123  last_update 2\n",
      "train: iter 71  trainloss 1.41774  validloss 3.68518±0.00000  bestvalidloss 3.68518  last_update 0\n",
      "train: iter 72  trainloss 1.44648  validloss 3.82659±0.00000  bestvalidloss 3.68518  last_update 1\n",
      "train: iter 73  trainloss 1.47972  validloss 3.86137±0.00000  bestvalidloss 3.68518  last_update 2\n",
      "train: iter 74  trainloss 1.44904  validloss 3.69346±0.00000  bestvalidloss 3.68518  last_update 3\n",
      "train: iter 75  trainloss 1.42275  validloss 3.81284±0.00000  bestvalidloss 3.68518  last_update 4\n",
      "train: iter 76  trainloss 1.45142  validloss 3.85803±0.00000  bestvalidloss 3.68518  last_update 5\n",
      "train: iter 77  trainloss 1.47213  validloss 3.87115±0.00000  bestvalidloss 3.68518  last_update 6\n",
      "train: iter 78  trainloss 1.42296  validloss 3.78529±0.00000  bestvalidloss 3.68518  last_update 7\n",
      "train: iter 79  trainloss 1.47249  validloss 4.01178±0.00000  bestvalidloss 3.68518  last_update 8\n",
      "train: iter 80  trainloss 1.42822  validloss 3.78328±0.00000  bestvalidloss 3.68518  last_update 9\n",
      "train: iter 81  trainloss 1.45279  validloss 3.67362±0.00000  bestvalidloss 3.67362  last_update 0\n",
      "train: iter 82  trainloss 1.42123  validloss 3.61956±0.00000  bestvalidloss 3.61956  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.44631  validloss 3.78268±0.00000  bestvalidloss 3.61956  last_update 1\n",
      "train: iter 84  trainloss 1.41156  validloss 3.82546±0.00000  bestvalidloss 3.61956  last_update 2\n",
      "train: iter 85  trainloss 1.43368  validloss 3.67372±0.00000  bestvalidloss 3.61956  last_update 3\n",
      "train: iter 86  trainloss 1.45882  validloss 3.96310±0.00000  bestvalidloss 3.61956  last_update 4\n",
      "train: iter 87  trainloss 1.46444  validloss 3.75628±0.00000  bestvalidloss 3.61956  last_update 5\n",
      "train: iter 88  trainloss 1.45391  validloss 3.55483±0.00000  bestvalidloss 3.55483  last_update 0\n",
      "train: iter 89  trainloss 1.41148  validloss 3.61378±0.00000  bestvalidloss 3.55483  last_update 1\n",
      "train: iter 90  trainloss 1.43845  validloss 3.58646±0.00000  bestvalidloss 3.55483  last_update 2\n",
      "train: iter 91  trainloss 1.42723  validloss 3.70363±0.00000  bestvalidloss 3.55483  last_update 3\n",
      "train: iter 92  trainloss 1.41578  validloss 3.81668±0.00000  bestvalidloss 3.55483  last_update 4\n",
      "train: iter 93  trainloss 1.43564  validloss 3.75251±0.00000  bestvalidloss 3.55483  last_update 5\n",
      "train: iter 94  trainloss 1.44705  validloss 3.60769±0.00000  bestvalidloss 3.55483  last_update 6\n",
      "train: iter 95  trainloss 1.41494  validloss 3.82075±0.00000  bestvalidloss 3.55483  last_update 7\n",
      "train: iter 96  trainloss 1.40997  validloss 3.66209±0.00000  bestvalidloss 3.55483  last_update 8\n",
      "train: iter 97  trainloss 1.43209  validloss 3.69282±0.00000  bestvalidloss 3.55483  last_update 9\n",
      "train: iter 98  trainloss 1.47833  validloss 3.66871±0.00000  bestvalidloss 3.55483  last_update 10\n",
      "train: iter 99  trainloss 1.43861  validloss 3.80673±0.00000  bestvalidloss 3.55483  last_update 11\n",
      "train: iter 100  trainloss 1.40518  validloss 3.61573±0.00000  bestvalidloss 3.55483  last_update 12\n",
      "train: iter 101  trainloss 1.41745  validloss 3.74986±0.00000  bestvalidloss 3.55483  last_update 13\n",
      "train: iter 102  trainloss 1.42791  validloss 3.75613±0.00000  bestvalidloss 3.55483  last_update 14\n",
      "train: iter 103  trainloss 1.40830  validloss 3.52470±0.00000  bestvalidloss 3.52470  last_update 0\n",
      "train: iter 104  trainloss 1.43205  validloss 3.62976±0.00000  bestvalidloss 3.52470  last_update 1\n",
      "train: iter 105  trainloss 1.43229  validloss 3.62711±0.00000  bestvalidloss 3.52470  last_update 2\n",
      "train: iter 106  trainloss 1.42578  validloss 3.75050±0.00000  bestvalidloss 3.52470  last_update 3\n",
      "train: iter 107  trainloss 1.40532  validloss 3.66294±0.00000  bestvalidloss 3.52470  last_update 4\n",
      "train: iter 108  trainloss 1.40278  validloss 3.70882±0.00000  bestvalidloss 3.52470  last_update 5\n",
      "train: iter 109  trainloss 1.40901  validloss 3.75298±0.00000  bestvalidloss 3.52470  last_update 6\n",
      "train: iter 110  trainloss 1.41856  validloss 3.88610±0.00000  bestvalidloss 3.52470  last_update 7\n",
      "train: iter 111  trainloss 1.42486  validloss 3.65632±0.00000  bestvalidloss 3.52470  last_update 8\n",
      "train: iter 112  trainloss 1.44477  validloss 3.60794±0.00000  bestvalidloss 3.52470  last_update 9\n",
      "train: iter 113  trainloss 1.41003  validloss 3.87070±0.00000  bestvalidloss 3.52470  last_update 10\n",
      "train: iter 114  trainloss 1.44355  validloss 3.73142±0.00000  bestvalidloss 3.52470  last_update 11\n",
      "train: iter 115  trainloss 1.37994  validloss 3.64986±0.00000  bestvalidloss 3.52470  last_update 12\n",
      "train: iter 116  trainloss 1.42245  validloss 3.62642±0.00000  bestvalidloss 3.52470  last_update 13\n",
      "train: iter 117  trainloss 1.42006  validloss 3.56933±0.00000  bestvalidloss 3.52470  last_update 14\n",
      "train: iter 118  trainloss 1.43671  validloss 3.67674±0.00000  bestvalidloss 3.52470  last_update 15\n",
      "train: iter 119  trainloss 1.39640  validloss 3.81287±0.00000  bestvalidloss 3.52470  last_update 16\n",
      "train: iter 120  trainloss 1.42528  validloss 3.62491±0.00000  bestvalidloss 3.52470  last_update 17\n",
      "train: iter 121  trainloss 1.41890  validloss 3.71803±0.00000  bestvalidloss 3.52470  last_update 18\n",
      "train: iter 122  trainloss 1.40619  validloss 3.83929±0.00000  bestvalidloss 3.52470  last_update 19\n",
      "train: iter 123  trainloss 1.43558  validloss 3.74172±0.00000  bestvalidloss 3.52470  last_update 20\n",
      "train: iter 124  trainloss 1.44339  validloss 3.73151±0.00000  bestvalidloss 3.52470  last_update 21\n",
      "train: iter 125  trainloss 1.40685  validloss 3.86939±0.00000  bestvalidloss 3.52470  last_update 22\n",
      "train: iter 126  trainloss 1.43928  validloss 3.77051±0.00000  bestvalidloss 3.52470  last_update 23\n",
      "train: iter 127  trainloss 1.41966  validloss 3.73756±0.00000  bestvalidloss 3.52470  last_update 24\n",
      "train: iter 128  trainloss 1.39532  validloss 3.68656±0.00000  bestvalidloss 3.52470  last_update 25\n",
      "train: iter 129  trainloss 1.41280  validloss 3.69133±0.00000  bestvalidloss 3.52470  last_update 26\n",
      "train: iter 130  trainloss 1.42926  validloss 3.57179±0.00000  bestvalidloss 3.52470  last_update 27\n",
      "train: iter 131  trainloss 1.38951  validloss 3.70113±0.00000  bestvalidloss 3.52470  last_update 28\n",
      "train: iter 132  trainloss 1.42661  validloss 3.82064±0.00000  bestvalidloss 3.52470  last_update 29\n",
      "train: iter 133  trainloss 1.40750  validloss 3.64710±0.00000  bestvalidloss 3.52470  last_update 30\n",
      "train: iter 134  trainloss 1.36924  validloss 3.74110±0.00000  bestvalidloss 3.52470  last_update 31\n",
      "train: iter 135  trainloss 1.42316  validloss 3.71079±0.00000  bestvalidloss 3.52470  last_update 32\n",
      "train: iter 136  trainloss 1.43969  validloss 3.73637±0.00000  bestvalidloss 3.52470  last_update 33\n",
      "train: iter 137  trainloss 1.40029  validloss 3.70378±0.00000  bestvalidloss 3.52470  last_update 34\n",
      "train: iter 138  trainloss 1.40619  validloss 3.69079±0.00000  bestvalidloss 3.52470  last_update 35\n",
      "train: iter 139  trainloss 1.42742  validloss 3.79148±0.00000  bestvalidloss 3.52470  last_update 36\n",
      "train: iter 140  trainloss 1.43531  validloss 3.71203±0.00000  bestvalidloss 3.52470  last_update 37\n",
      "train: iter 141  trainloss 1.44827  validloss 3.66959±0.00000  bestvalidloss 3.52470  last_update 38\n",
      "train: iter 142  trainloss 1.41884  validloss 3.73406±0.00000  bestvalidloss 3.52470  last_update 39\n",
      "train: iter 143  trainloss 1.36981  validloss 3.61384±0.00000  bestvalidloss 3.52470  last_update 40\n",
      "train: iter 144  trainloss 1.39120  validloss 3.81844±0.00000  bestvalidloss 3.52470  last_update 41\n",
      "train: iter 145  trainloss 1.37632  validloss 3.74571±0.00000  bestvalidloss 3.52470  last_update 42\n",
      "train: iter 146  trainloss 1.41321  validloss 3.78933±0.00000  bestvalidloss 3.52470  last_update 43\n",
      "train: iter 147  trainloss 1.39441  validloss 3.78990±0.00000  bestvalidloss 3.52470  last_update 44\n",
      "train: iter 148  trainloss 1.40873  validloss 3.75164±0.00000  bestvalidloss 3.52470  last_update 45\n",
      "train: iter 149  trainloss 1.40437  validloss 3.66579±0.00000  bestvalidloss 3.52470  last_update 46\n",
      "train: iter 150  trainloss 1.42465  validloss 3.75593±0.00000  bestvalidloss 3.52470  last_update 47\n",
      "train: iter 151  trainloss 1.37982  validloss 3.64723±0.00000  bestvalidloss 3.52470  last_update 48\n",
      "train: iter 152  trainloss 1.41882  validloss 3.78675±0.00000  bestvalidloss 3.52470  last_update 49\n",
      "train: iter 153  trainloss 1.40483  validloss 3.74879±0.00000  bestvalidloss 3.52470  last_update 50\n",
      "train: iter 154  trainloss 1.35450  validloss 3.73549±0.00000  bestvalidloss 3.52470  last_update 51\n",
      "train: iter 155  trainloss 1.42536  validloss 3.58208±0.00000  bestvalidloss 3.52470  last_update 52\n",
      "train: iter 156  trainloss 1.43810  validloss 3.64670±0.00000  bestvalidloss 3.52470  last_update 53\n",
      "train: iter 157  trainloss 1.39911  validloss 3.86597±0.00000  bestvalidloss 3.52470  last_update 54\n",
      "train: iter 158  trainloss 1.38578  validloss 3.81408±0.00000  bestvalidloss 3.52470  last_update 55\n",
      "train: iter 159  trainloss 1.41943  validloss 3.67433±0.00000  bestvalidloss 3.52470  last_update 56\n",
      "train: iter 160  trainloss 1.37813  validloss 3.68924±0.00000  bestvalidloss 3.52470  last_update 57\n",
      "train: iter 161  trainloss 1.44359  validloss 3.76179±0.00000  bestvalidloss 3.52470  last_update 58\n",
      "train: iter 162  trainloss 1.43501  validloss 3.80971±0.00000  bestvalidloss 3.52470  last_update 59\n",
      "train: iter 163  trainloss 1.39906  validloss 3.74100±0.00000  bestvalidloss 3.52470  last_update 60\n",
      "train: iter 164  trainloss 1.39172  validloss 3.65028±0.00000  bestvalidloss 3.52470  last_update 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 165  trainloss 1.43348  validloss 3.77810±0.00000  bestvalidloss 3.52470  last_update 62\n",
      "train: iter 166  trainloss 1.39329  validloss 3.71983±0.00000  bestvalidloss 3.52470  last_update 63\n",
      "train: iter 167  trainloss 1.36100  validloss 3.65167±0.00000  bestvalidloss 3.52470  last_update 64\n",
      "train: iter 168  trainloss 1.39975  validloss 3.77989±0.00000  bestvalidloss 3.52470  last_update 65\n",
      "train: iter 169  trainloss 1.39745  validloss 3.81026±0.00000  bestvalidloss 3.52470  last_update 66\n",
      "train: iter 170  trainloss 1.37336  validloss 3.78158±0.00000  bestvalidloss 3.52470  last_update 67\n",
      "train: iter 171  trainloss 1.40808  validloss 3.55251±0.00000  bestvalidloss 3.52470  last_update 68\n",
      "train: iter 172  trainloss 1.44139  validloss 3.77108±0.00000  bestvalidloss 3.52470  last_update 69\n",
      "train: iter 173  trainloss 1.40621  validloss 3.60606±0.00000  bestvalidloss 3.52470  last_update 70\n",
      "train: iter 174  trainloss 1.42289  validloss 3.78808±0.00000  bestvalidloss 3.52470  last_update 71\n",
      "train: iter 175  trainloss 1.41231  validloss 3.80590±0.00000  bestvalidloss 3.52470  last_update 72\n",
      "train: iter 176  trainloss 1.37641  validloss 3.63454±0.00000  bestvalidloss 3.52470  last_update 73\n",
      "train: iter 177  trainloss 1.41653  validloss 3.65152±0.00000  bestvalidloss 3.52470  last_update 74\n",
      "train: iter 178  trainloss 1.41798  validloss 3.76957±0.00000  bestvalidloss 3.52470  last_update 75\n",
      "train: iter 179  trainloss 1.42070  validloss 3.49562±0.00000  bestvalidloss 3.49562  last_update 0\n",
      "train: iter 180  trainloss 1.39982  validloss 3.68159±0.00000  bestvalidloss 3.49562  last_update 1\n",
      "train: iter 181  trainloss 1.34148  validloss 3.53496±0.00000  bestvalidloss 3.49562  last_update 2\n",
      "train: iter 182  trainloss 1.41247  validloss 4.03034±0.00000  bestvalidloss 3.49562  last_update 3\n",
      "train: iter 183  trainloss 1.39918  validloss 3.66570±0.00000  bestvalidloss 3.49562  last_update 4\n",
      "train: iter 184  trainloss 1.40396  validloss 3.66055±0.00000  bestvalidloss 3.49562  last_update 5\n",
      "train: iter 185  trainloss 1.37895  validloss 3.69830±0.00000  bestvalidloss 3.49562  last_update 6\n",
      "train: iter 186  trainloss 1.41411  validloss 3.77659±0.00000  bestvalidloss 3.49562  last_update 7\n",
      "train: iter 187  trainloss 1.40694  validloss 3.70222±0.00000  bestvalidloss 3.49562  last_update 8\n",
      "train: iter 188  trainloss 1.38815  validloss 3.60749±0.00000  bestvalidloss 3.49562  last_update 9\n",
      "train: iter 189  trainloss 1.41979  validloss 3.69505±0.00000  bestvalidloss 3.49562  last_update 10\n",
      "train: iter 190  trainloss 1.37822  validloss 3.66437±0.00000  bestvalidloss 3.49562  last_update 11\n",
      "train: iter 191  trainloss 1.37250  validloss 3.67386±0.00000  bestvalidloss 3.49562  last_update 12\n",
      "train: iter 192  trainloss 1.39439  validloss 3.57968±0.00000  bestvalidloss 3.49562  last_update 13\n",
      "train: iter 193  trainloss 1.39834  validloss 3.56512±0.00000  bestvalidloss 3.49562  last_update 14\n",
      "train: iter 194  trainloss 1.40937  validloss 3.64902±0.00000  bestvalidloss 3.49562  last_update 15\n",
      "train: iter 195  trainloss 1.40388  validloss 3.70383±0.00000  bestvalidloss 3.49562  last_update 16\n",
      "train: iter 196  trainloss 1.36621  validloss 3.50614±0.00000  bestvalidloss 3.49562  last_update 17\n",
      "train: iter 197  trainloss 1.41543  validloss 3.62808±0.00000  bestvalidloss 3.49562  last_update 18\n",
      "train: iter 198  trainloss 1.39473  validloss 3.79300±0.00000  bestvalidloss 3.49562  last_update 19\n",
      "train: iter 199  trainloss 1.39553  validloss 3.66434±0.00000  bestvalidloss 3.49562  last_update 20\n",
      "train: iter 200  trainloss 1.41201  validloss 3.71104±0.00000  bestvalidloss 3.49562  last_update 21\n",
      "train: iter 201  trainloss 1.37772  validloss 3.67491±0.00000  bestvalidloss 3.49562  last_update 22\n",
      "train: iter 202  trainloss 1.39838  validloss 3.65559±0.00000  bestvalidloss 3.49562  last_update 23\n",
      "train: iter 203  trainloss 1.38104  validloss 3.62790±0.00000  bestvalidloss 3.49562  last_update 24\n",
      "train: iter 204  trainloss 1.37863  validloss 3.75602±0.00000  bestvalidloss 3.49562  last_update 25\n",
      "train: iter 205  trainloss 1.44161  validloss 3.67737±0.00000  bestvalidloss 3.49562  last_update 26\n",
      "train: iter 206  trainloss 1.37899  validloss 3.58366±0.00000  bestvalidloss 3.49562  last_update 27\n",
      "train: iter 207  trainloss 1.39224  validloss 3.50060±0.00000  bestvalidloss 3.49562  last_update 28\n",
      "train: iter 208  trainloss 1.37314  validloss 3.74369±0.00000  bestvalidloss 3.49562  last_update 29\n",
      "train: iter 209  trainloss 1.38233  validloss 3.89290±0.00000  bestvalidloss 3.49562  last_update 30\n",
      "train: iter 210  trainloss 1.38411  validloss 3.52140±0.00000  bestvalidloss 3.49562  last_update 31\n",
      "train: iter 211  trainloss 1.38817  validloss 3.63151±0.00000  bestvalidloss 3.49562  last_update 32\n",
      "train: iter 212  trainloss 1.41044  validloss 3.54808±0.00000  bestvalidloss 3.49562  last_update 33\n",
      "train: iter 213  trainloss 1.39601  validloss 3.63586±0.00000  bestvalidloss 3.49562  last_update 34\n",
      "train: iter 214  trainloss 1.37385  validloss 3.59920±0.00000  bestvalidloss 3.49562  last_update 35\n",
      "train: iter 215  trainloss 1.40750  validloss 3.63950±0.00000  bestvalidloss 3.49562  last_update 36\n",
      "train: iter 216  trainloss 1.39031  validloss 3.50039±0.00000  bestvalidloss 3.49562  last_update 37\n",
      "train: iter 217  trainloss 1.35256  validloss 3.86760±0.00000  bestvalidloss 3.49562  last_update 38\n",
      "train: iter 218  trainloss 1.41401  validloss 3.75611±0.00000  bestvalidloss 3.49562  last_update 39\n",
      "train: iter 219  trainloss 1.40531  validloss 3.80101±0.00000  bestvalidloss 3.49562  last_update 40\n",
      "train: iter 220  trainloss 1.40809  validloss 3.60583±0.00000  bestvalidloss 3.49562  last_update 41\n",
      "train: iter 221  trainloss 1.39867  validloss 3.56593±0.00000  bestvalidloss 3.49562  last_update 42\n",
      "train: iter 222  trainloss 1.38857  validloss 3.65111±0.00000  bestvalidloss 3.49562  last_update 43\n",
      "train: iter 223  trainloss 1.37023  validloss 3.59633±0.00000  bestvalidloss 3.49562  last_update 44\n",
      "train: iter 224  trainloss 1.36219  validloss 3.69173±0.00000  bestvalidloss 3.49562  last_update 45\n",
      "train: iter 225  trainloss 1.39088  validloss 3.62881±0.00000  bestvalidloss 3.49562  last_update 46\n",
      "train: iter 226  trainloss 1.37781  validloss 3.54225±0.00000  bestvalidloss 3.49562  last_update 47\n",
      "train: iter 227  trainloss 1.38071  validloss 3.72566±0.00000  bestvalidloss 3.49562  last_update 48\n",
      "train: iter 228  trainloss 1.42012  validloss 3.78088±0.00000  bestvalidloss 3.49562  last_update 49\n",
      "train: iter 229  trainloss 1.38604  validloss 3.78247±0.00000  bestvalidloss 3.49562  last_update 50\n",
      "train: iter 230  trainloss 1.38444  validloss 3.56209±0.00000  bestvalidloss 3.49562  last_update 51\n",
      "train: iter 231  trainloss 1.37959  validloss 3.61415±0.00000  bestvalidloss 3.49562  last_update 52\n",
      "train: iter 232  trainloss 1.41009  validloss 3.66201±0.00000  bestvalidloss 3.49562  last_update 53\n",
      "train: iter 233  trainloss 1.37999  validloss 3.57701±0.00000  bestvalidloss 3.49562  last_update 54\n",
      "train: iter 234  trainloss 1.37183  validloss 3.81854±0.00000  bestvalidloss 3.49562  last_update 55\n",
      "train: iter 235  trainloss 1.38787  validloss 3.72592±0.00000  bestvalidloss 3.49562  last_update 56\n",
      "train: iter 236  trainloss 1.41725  validloss 3.64025±0.00000  bestvalidloss 3.49562  last_update 57\n",
      "train: iter 237  trainloss 1.39431  validloss 3.64459±0.00000  bestvalidloss 3.49562  last_update 58\n",
      "train: iter 238  trainloss 1.40088  validloss 3.53882±0.00000  bestvalidloss 3.49562  last_update 59\n",
      "train: iter 239  trainloss 1.38830  validloss 3.50319±0.00000  bestvalidloss 3.49562  last_update 60\n",
      "train: iter 240  trainloss 1.39401  validloss 3.70830±0.00000  bestvalidloss 3.49562  last_update 61\n",
      "train: iter 241  trainloss 1.38612  validloss 3.60783±0.00000  bestvalidloss 3.49562  last_update 62\n",
      "train: iter 242  trainloss 1.38032  validloss 3.48610±0.00000  bestvalidloss 3.48610  last_update 0\n",
      "train: iter 243  trainloss 1.41083  validloss 3.64347±0.00000  bestvalidloss 3.48610  last_update 1\n",
      "train: iter 244  trainloss 1.39722  validloss 3.68199±0.00000  bestvalidloss 3.48610  last_update 2\n",
      "train: iter 245  trainloss 1.38376  validloss 3.56894±0.00000  bestvalidloss 3.48610  last_update 3\n",
      "train: iter 246  trainloss 1.37091  validloss 3.63381±0.00000  bestvalidloss 3.48610  last_update 4\n",
      "train: iter 247  trainloss 1.39585  validloss 3.67611±0.00000  bestvalidloss 3.48610  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 248  trainloss 1.40935  validloss 3.75892±0.00000  bestvalidloss 3.48610  last_update 6\n",
      "train: iter 249  trainloss 1.41542  validloss 3.61329±0.00000  bestvalidloss 3.48610  last_update 7\n",
      "train: iter 250  trainloss 1.38250  validloss 3.74075±0.00000  bestvalidloss 3.48610  last_update 8\n",
      "train: iter 251  trainloss 1.40463  validloss 3.69343±0.00000  bestvalidloss 3.48610  last_update 9\n",
      "train: iter 252  trainloss 1.41436  validloss 3.57785±0.00000  bestvalidloss 3.48610  last_update 10\n",
      "train: iter 253  trainloss 1.41699  validloss 3.70159±0.00000  bestvalidloss 3.48610  last_update 11\n",
      "train: iter 254  trainloss 1.38019  validloss 3.61346±0.00000  bestvalidloss 3.48610  last_update 12\n",
      "train: iter 255  trainloss 1.38741  validloss 3.52999±0.00000  bestvalidloss 3.48610  last_update 13\n",
      "train: iter 256  trainloss 1.43864  validloss 3.68192±0.00000  bestvalidloss 3.48610  last_update 14\n",
      "train: iter 257  trainloss 1.38901  validloss 3.63369±0.00000  bestvalidloss 3.48610  last_update 15\n",
      "train: iter 258  trainloss 1.41417  validloss 3.69598±0.00000  bestvalidloss 3.48610  last_update 16\n",
      "train: iter 259  trainloss 1.39036  validloss 3.77456±0.00000  bestvalidloss 3.48610  last_update 17\n",
      "train: iter 260  trainloss 1.37725  validloss 3.47196±0.00000  bestvalidloss 3.47196  last_update 0\n",
      "train: iter 261  trainloss 1.37093  validloss 3.69740±0.00000  bestvalidloss 3.47196  last_update 1\n",
      "train: iter 262  trainloss 1.34629  validloss 3.81126±0.00000  bestvalidloss 3.47196  last_update 2\n",
      "train: iter 263  trainloss 1.41141  validloss 3.51793±0.00000  bestvalidloss 3.47196  last_update 3\n",
      "train: iter 264  trainloss 1.39511  validloss 3.61396±0.00000  bestvalidloss 3.47196  last_update 4\n",
      "train: iter 265  trainloss 1.37841  validloss 3.67293±0.00000  bestvalidloss 3.47196  last_update 5\n",
      "train: iter 266  trainloss 1.37448  validloss 3.74780±0.00000  bestvalidloss 3.47196  last_update 6\n",
      "train: iter 267  trainloss 1.40580  validloss 3.54623±0.00000  bestvalidloss 3.47196  last_update 7\n",
      "train: iter 268  trainloss 1.39236  validloss 3.61129±0.00000  bestvalidloss 3.47196  last_update 8\n",
      "train: iter 269  trainloss 1.35770  validloss 3.62579±0.00000  bestvalidloss 3.47196  last_update 9\n",
      "train: iter 270  trainloss 1.39548  validloss 3.69909±0.00000  bestvalidloss 3.47196  last_update 10\n",
      "train: iter 271  trainloss 1.41484  validloss 3.55853±0.00000  bestvalidloss 3.47196  last_update 11\n",
      "train: iter 272  trainloss 1.38956  validloss 3.69408±0.00000  bestvalidloss 3.47196  last_update 12\n",
      "train: iter 273  trainloss 1.36188  validloss 3.63860±0.00000  bestvalidloss 3.47196  last_update 13\n",
      "train: iter 274  trainloss 1.40357  validloss 3.83782±0.00000  bestvalidloss 3.47196  last_update 14\n",
      "train: iter 275  trainloss 1.39404  validloss 3.61596±0.00000  bestvalidloss 3.47196  last_update 15\n",
      "train: iter 276  trainloss 1.37314  validloss 3.60546±0.00000  bestvalidloss 3.47196  last_update 16\n",
      "train: iter 277  trainloss 1.40418  validloss 3.52377±0.00000  bestvalidloss 3.47196  last_update 17\n",
      "train: iter 278  trainloss 1.40446  validloss 3.56534±0.00000  bestvalidloss 3.47196  last_update 18\n",
      "train: iter 279  trainloss 1.39792  validloss 3.78169±0.00000  bestvalidloss 3.47196  last_update 19\n",
      "train: iter 280  trainloss 1.39243  validloss 3.79807±0.00000  bestvalidloss 3.47196  last_update 20\n",
      "train: iter 281  trainloss 1.37589  validloss 3.59205±0.00000  bestvalidloss 3.47196  last_update 21\n",
      "train: iter 282  trainloss 1.33710  validloss 3.52627±0.00000  bestvalidloss 3.47196  last_update 22\n",
      "train: iter 283  trainloss 1.38721  validloss 3.72356±0.00000  bestvalidloss 3.47196  last_update 23\n",
      "train: iter 284  trainloss 1.38688  validloss 3.64287±0.00000  bestvalidloss 3.47196  last_update 24\n",
      "train: iter 285  trainloss 1.39393  validloss 3.68004±0.00000  bestvalidloss 3.47196  last_update 25\n",
      "train: iter 286  trainloss 1.38638  validloss 3.66299±0.00000  bestvalidloss 3.47196  last_update 26\n",
      "train: iter 287  trainloss 1.41374  validloss 3.73368±0.00000  bestvalidloss 3.47196  last_update 27\n",
      "train: iter 288  trainloss 1.41355  validloss 3.71871±0.00000  bestvalidloss 3.47196  last_update 28\n",
      "train: iter 289  trainloss 1.40885  validloss 3.57361±0.00000  bestvalidloss 3.47196  last_update 29\n",
      "train: iter 290  trainloss 1.39516  validloss 3.59702±0.00000  bestvalidloss 3.47196  last_update 30\n",
      "train: iter 291  trainloss 1.39556  validloss 3.69195±0.00000  bestvalidloss 3.47196  last_update 31\n",
      "train: iter 292  trainloss 1.37615  validloss 3.62516±0.00000  bestvalidloss 3.47196  last_update 32\n",
      "train: iter 293  trainloss 1.39309  validloss 3.43971±0.00000  bestvalidloss 3.43971  last_update 0\n",
      "train: iter 294  trainloss 1.41157  validloss 3.69424±0.00000  bestvalidloss 3.43971  last_update 1\n",
      "train: iter 295  trainloss 1.38051  validloss 3.70184±0.00000  bestvalidloss 3.43971  last_update 2\n",
      "train: iter 296  trainloss 1.39113  validloss 3.62362±0.00000  bestvalidloss 3.43971  last_update 3\n",
      "train: iter 297  trainloss 1.37437  validloss 3.60170±0.00000  bestvalidloss 3.43971  last_update 4\n",
      "train: iter 298  trainloss 1.37986  validloss 3.59261±0.00000  bestvalidloss 3.43971  last_update 5\n",
      "train: iter 299  trainloss 1.41023  validloss 3.71851±0.00000  bestvalidloss 3.43971  last_update 6\n",
      "train: iter 300  trainloss 1.40253  validloss 3.55262±0.00000  bestvalidloss 3.43971  last_update 7\n",
      "train: iter 301  trainloss 1.40582  validloss 3.75333±0.00000  bestvalidloss 3.43971  last_update 8\n",
      "train: iter 302  trainloss 1.38208  validloss 3.65894±0.00000  bestvalidloss 3.43971  last_update 9\n",
      "train: iter 303  trainloss 1.37872  validloss 3.73036±0.00000  bestvalidloss 3.43971  last_update 10\n",
      "train: iter 304  trainloss 1.36497  validloss 3.72602±0.00000  bestvalidloss 3.43971  last_update 11\n",
      "train: iter 305  trainloss 1.36151  validloss 3.73924±0.00000  bestvalidloss 3.43971  last_update 12\n",
      "train: iter 306  trainloss 1.40157  validloss 3.61786±0.00000  bestvalidloss 3.43971  last_update 13\n",
      "train: iter 307  trainloss 1.36859  validloss 3.52442±0.00000  bestvalidloss 3.43971  last_update 14\n",
      "train: iter 308  trainloss 1.36171  validloss 3.66264±0.00000  bestvalidloss 3.43971  last_update 15\n",
      "train: iter 309  trainloss 1.39399  validloss 3.62556±0.00000  bestvalidloss 3.43971  last_update 16\n",
      "train: iter 310  trainloss 1.31772  validloss 3.60193±0.00000  bestvalidloss 3.43971  last_update 17\n",
      "train: iter 311  trainloss 1.37536  validloss 3.56859±0.00000  bestvalidloss 3.43971  last_update 18\n",
      "train: iter 312  trainloss 1.40941  validloss 3.58728±0.00000  bestvalidloss 3.43971  last_update 19\n",
      "train: iter 313  trainloss 1.37480  validloss 3.68765±0.00000  bestvalidloss 3.43971  last_update 20\n",
      "train: iter 314  trainloss 1.40269  validloss 3.79359±0.00000  bestvalidloss 3.43971  last_update 21\n",
      "train: iter 315  trainloss 1.40914  validloss 3.50929±0.00000  bestvalidloss 3.43971  last_update 22\n",
      "train: iter 316  trainloss 1.39645  validloss 3.81083±0.00000  bestvalidloss 3.43971  last_update 23\n",
      "train: iter 317  trainloss 1.37143  validloss 3.72428±0.00000  bestvalidloss 3.43971  last_update 24\n",
      "train: iter 318  trainloss 1.37647  validloss 3.59945±0.00000  bestvalidloss 3.43971  last_update 25\n",
      "train: iter 319  trainloss 1.38852  validloss 3.62556±0.00000  bestvalidloss 3.43971  last_update 26\n",
      "train: iter 320  trainloss 1.41359  validloss 3.51130±0.00000  bestvalidloss 3.43971  last_update 27\n",
      "train: iter 321  trainloss 1.40881  validloss 3.55480±0.00000  bestvalidloss 3.43971  last_update 28\n",
      "train: iter 322  trainloss 1.36106  validloss 3.56074±0.00000  bestvalidloss 3.43971  last_update 29\n",
      "train: iter 323  trainloss 1.36149  validloss 3.59833±0.00000  bestvalidloss 3.43971  last_update 30\n",
      "train: iter 324  trainloss 1.39619  validloss 3.73364±0.00000  bestvalidloss 3.43971  last_update 31\n",
      "train: iter 325  trainloss 1.38070  validloss 3.52237±0.00000  bestvalidloss 3.43971  last_update 32\n",
      "train: iter 326  trainloss 1.39356  validloss 3.56489±0.00000  bestvalidloss 3.43971  last_update 33\n",
      "train: iter 327  trainloss 1.40874  validloss 3.54096±0.00000  bestvalidloss 3.43971  last_update 34\n",
      "train: iter 328  trainloss 1.41017  validloss 3.50228±0.00000  bestvalidloss 3.43971  last_update 35\n",
      "train: iter 329  trainloss 1.38015  validloss 3.73602±0.00000  bestvalidloss 3.43971  last_update 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 330  trainloss 1.41231  validloss 3.65369±0.00000  bestvalidloss 3.43971  last_update 37\n",
      "train: iter 331  trainloss 1.41667  validloss 3.47497±0.00000  bestvalidloss 3.43971  last_update 38\n",
      "train: iter 332  trainloss 1.39062  validloss 3.38760±0.00000  bestvalidloss 3.38760  last_update 0\n",
      "train: iter 333  trainloss 1.39844  validloss 3.67337±0.00000  bestvalidloss 3.38760  last_update 1\n",
      "train: iter 334  trainloss 1.36451  validloss 3.77336±0.00000  bestvalidloss 3.38760  last_update 2\n",
      "train: iter 335  trainloss 1.39889  validloss 3.58080±0.00000  bestvalidloss 3.38760  last_update 3\n",
      "train: iter 336  trainloss 1.44122  validloss 3.72679±0.00000  bestvalidloss 3.38760  last_update 4\n",
      "train: iter 337  trainloss 1.38323  validloss 3.67171±0.00000  bestvalidloss 3.38760  last_update 5\n",
      "train: iter 338  trainloss 1.38340  validloss 3.70369±0.00000  bestvalidloss 3.38760  last_update 6\n",
      "train: iter 339  trainloss 1.37810  validloss 3.59462±0.00000  bestvalidloss 3.38760  last_update 7\n",
      "train: iter 340  trainloss 1.36660  validloss 3.84843±0.00000  bestvalidloss 3.38760  last_update 8\n",
      "train: iter 341  trainloss 1.38766  validloss 3.63738±0.00000  bestvalidloss 3.38760  last_update 9\n",
      "train: iter 342  trainloss 1.40650  validloss 3.66136±0.00000  bestvalidloss 3.38760  last_update 10\n",
      "train: iter 343  trainloss 1.36356  validloss 3.84601±0.00000  bestvalidloss 3.38760  last_update 11\n",
      "train: iter 344  trainloss 1.38382  validloss 3.58518±0.00000  bestvalidloss 3.38760  last_update 12\n",
      "train: iter 345  trainloss 1.36130  validloss 3.74665±0.00000  bestvalidloss 3.38760  last_update 13\n",
      "train: iter 346  trainloss 1.35866  validloss 3.53273±0.00000  bestvalidloss 3.38760  last_update 14\n",
      "train: iter 347  trainloss 1.37446  validloss 3.52692±0.00000  bestvalidloss 3.38760  last_update 15\n",
      "train: iter 348  trainloss 1.39396  validloss 3.61421±0.00000  bestvalidloss 3.38760  last_update 16\n",
      "train: iter 349  trainloss 1.38066  validloss 3.48918±0.00000  bestvalidloss 3.38760  last_update 17\n",
      "train: iter 350  trainloss 1.41165  validloss 3.64258±0.00000  bestvalidloss 3.38760  last_update 18\n",
      "train: iter 351  trainloss 1.38459  validloss 3.56971±0.00000  bestvalidloss 3.38760  last_update 19\n",
      "train: iter 352  trainloss 1.38012  validloss 3.66455±0.00000  bestvalidloss 3.38760  last_update 20\n",
      "train: iter 353  trainloss 1.35632  validloss 3.55598±0.00000  bestvalidloss 3.38760  last_update 21\n",
      "train: iter 354  trainloss 1.36457  validloss 3.75420±0.00000  bestvalidloss 3.38760  last_update 22\n",
      "train: iter 355  trainloss 1.38504  validloss 3.72137±0.00000  bestvalidloss 3.38760  last_update 23\n",
      "train: iter 356  trainloss 1.43560  validloss 3.61473±0.00000  bestvalidloss 3.38760  last_update 24\n",
      "train: iter 357  trainloss 1.34329  validloss 3.60126±0.00000  bestvalidloss 3.38760  last_update 25\n",
      "train: iter 358  trainloss 1.36872  validloss 3.53090±0.00000  bestvalidloss 3.38760  last_update 26\n",
      "train: iter 359  trainloss 1.35575  validloss 3.72857±0.00000  bestvalidloss 3.38760  last_update 27\n",
      "train: iter 360  trainloss 1.37958  validloss 3.48878±0.00000  bestvalidloss 3.38760  last_update 28\n",
      "train: iter 361  trainloss 1.36017  validloss 3.49900±0.00000  bestvalidloss 3.38760  last_update 29\n",
      "train: iter 362  trainloss 1.37793  validloss 3.78303±0.00000  bestvalidloss 3.38760  last_update 30\n",
      "train: iter 363  trainloss 1.35676  validloss 3.68661±0.00000  bestvalidloss 3.38760  last_update 31\n",
      "train: iter 364  trainloss 1.37180  validloss 3.76142±0.00000  bestvalidloss 3.38760  last_update 32\n",
      "train: iter 365  trainloss 1.36170  validloss 3.48566±0.00000  bestvalidloss 3.38760  last_update 33\n",
      "train: iter 366  trainloss 1.38117  validloss 3.70864±0.00000  bestvalidloss 3.38760  last_update 34\n",
      "train: iter 367  trainloss 1.36189  validloss 3.55203±0.00000  bestvalidloss 3.38760  last_update 35\n",
      "train: iter 368  trainloss 1.38689  validloss 3.51052±0.00000  bestvalidloss 3.38760  last_update 36\n",
      "train: iter 369  trainloss 1.35421  validloss 3.70224±0.00000  bestvalidloss 3.38760  last_update 37\n",
      "train: iter 370  trainloss 1.34943  validloss 3.63971±0.00000  bestvalidloss 3.38760  last_update 38\n",
      "train: iter 371  trainloss 1.35973  validloss 3.59205±0.00000  bestvalidloss 3.38760  last_update 39\n",
      "train: iter 372  trainloss 1.40497  validloss 3.91971±0.00000  bestvalidloss 3.38760  last_update 40\n",
      "train: iter 373  trainloss 1.35509  validloss 3.57358±0.00000  bestvalidloss 3.38760  last_update 41\n",
      "train: iter 374  trainloss 1.39705  validloss 3.77550±0.00000  bestvalidloss 3.38760  last_update 42\n",
      "train: iter 375  trainloss 1.37646  validloss 3.72500±0.00000  bestvalidloss 3.38760  last_update 43\n",
      "train: iter 376  trainloss 1.37645  validloss 3.67456±0.00000  bestvalidloss 3.38760  last_update 44\n",
      "train: iter 377  trainloss 1.40004  validloss 3.63005±0.00000  bestvalidloss 3.38760  last_update 45\n",
      "train: iter 378  trainloss 1.37959  validloss 3.46969±0.00000  bestvalidloss 3.38760  last_update 46\n",
      "train: iter 379  trainloss 1.35458  validloss 3.68384±0.00000  bestvalidloss 3.38760  last_update 47\n",
      "train: iter 380  trainloss 1.35839  validloss 3.70392±0.00000  bestvalidloss 3.38760  last_update 48\n",
      "train: iter 381  trainloss 1.35795  validloss 3.57074±0.00000  bestvalidloss 3.38760  last_update 49\n",
      "train: iter 382  trainloss 1.36508  validloss 3.44022±0.00000  bestvalidloss 3.38760  last_update 50\n",
      "train: iter 383  trainloss 1.35132  validloss 3.69423±0.00000  bestvalidloss 3.38760  last_update 51\n",
      "train: iter 384  trainloss 1.38263  validloss 3.58700±0.00000  bestvalidloss 3.38760  last_update 52\n",
      "train: iter 385  trainloss 1.36494  validloss 3.53699±0.00000  bestvalidloss 3.38760  last_update 53\n",
      "train: iter 386  trainloss 1.38910  validloss 3.71937±0.00000  bestvalidloss 3.38760  last_update 54\n",
      "train: iter 387  trainloss 1.34932  validloss 3.52355±0.00000  bestvalidloss 3.38760  last_update 55\n",
      "train: iter 388  trainloss 1.35155  validloss 3.62639±0.00000  bestvalidloss 3.38760  last_update 56\n",
      "train: iter 389  trainloss 1.38397  validloss 3.60418±0.00000  bestvalidloss 3.38760  last_update 57\n",
      "train: iter 390  trainloss 1.40811  validloss 3.65435±0.00000  bestvalidloss 3.38760  last_update 58\n",
      "train: iter 391  trainloss 1.37494  validloss 3.60263±0.00000  bestvalidloss 3.38760  last_update 59\n",
      "train: iter 392  trainloss 1.37571  validloss 3.67711±0.00000  bestvalidloss 3.38760  last_update 60\n",
      "train: iter 393  trainloss 1.37696  validloss 3.59211±0.00000  bestvalidloss 3.38760  last_update 61\n",
      "train: iter 394  trainloss 1.39278  validloss 3.68286±0.00000  bestvalidloss 3.38760  last_update 62\n",
      "train: iter 395  trainloss 1.37841  validloss 3.63952±0.00000  bestvalidloss 3.38760  last_update 63\n",
      "train: iter 396  trainloss 1.31842  validloss 3.80580±0.00000  bestvalidloss 3.38760  last_update 64\n",
      "train: iter 397  trainloss 1.36598  validloss 3.61837±0.00000  bestvalidloss 3.38760  last_update 65\n",
      "train: iter 398  trainloss 1.36970  validloss 3.53930±0.00000  bestvalidloss 3.38760  last_update 66\n",
      "train: iter 399  trainloss 1.40521  validloss 3.71202±0.00000  bestvalidloss 3.38760  last_update 67\n",
      "train: iter 400  trainloss 1.36952  validloss 3.67033±0.00000  bestvalidloss 3.38760  last_update 68\n",
      "train: iter 401  trainloss 1.36269  validloss 3.60490±0.00000  bestvalidloss 3.38760  last_update 69\n",
      "train: iter 402  trainloss 1.36203  validloss 3.76838±0.00000  bestvalidloss 3.38760  last_update 70\n",
      "train: iter 403  trainloss 1.39027  validloss 3.51527±0.00000  bestvalidloss 3.38760  last_update 71\n",
      "train: iter 404  trainloss 1.40299  validloss 3.44402±0.00000  bestvalidloss 3.38760  last_update 72\n",
      "train: iter 405  trainloss 1.39726  validloss 3.61119±0.00000  bestvalidloss 3.38760  last_update 73\n",
      "train: iter 406  trainloss 1.35221  validloss 3.58598±0.00000  bestvalidloss 3.38760  last_update 74\n",
      "train: iter 407  trainloss 1.38087  validloss 3.50331±0.00000  bestvalidloss 3.38760  last_update 75\n",
      "train: iter 408  trainloss 1.38843  validloss 3.75947±0.00000  bestvalidloss 3.38760  last_update 76\n",
      "train: iter 409  trainloss 1.40366  validloss 3.54382±0.00000  bestvalidloss 3.38760  last_update 77\n",
      "train: iter 410  trainloss 1.40686  validloss 3.61554±0.00000  bestvalidloss 3.38760  last_update 78\n",
      "train: iter 411  trainloss 1.34573  validloss 3.66655±0.00000  bestvalidloss 3.38760  last_update 79\n",
      "train: iter 412  trainloss 1.41168  validloss 3.71306±0.00000  bestvalidloss 3.38760  last_update 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 413  trainloss 1.33710  validloss 3.53992±0.00000  bestvalidloss 3.38760  last_update 81\n",
      "train: iter 414  trainloss 1.39375  validloss 3.79813±0.00000  bestvalidloss 3.38760  last_update 82\n",
      "train: iter 415  trainloss 1.38527  validloss 3.61295±0.00000  bestvalidloss 3.38760  last_update 83\n",
      "train: iter 416  trainloss 1.38275  validloss 3.71458±0.00000  bestvalidloss 3.38760  last_update 84\n",
      "train: iter 417  trainloss 1.37910  validloss 3.77391±0.00000  bestvalidloss 3.38760  last_update 85\n",
      "train: iter 418  trainloss 1.35041  validloss 3.67976±0.00000  bestvalidloss 3.38760  last_update 86\n",
      "train: iter 419  trainloss 1.37076  validloss 3.53004±0.00000  bestvalidloss 3.38760  last_update 87\n",
      "train: iter 420  trainloss 1.33641  validloss 3.57332±0.00000  bestvalidloss 3.38760  last_update 88\n",
      "train: iter 421  trainloss 1.42763  validloss 3.65707±0.00000  bestvalidloss 3.38760  last_update 89\n",
      "train: iter 422  trainloss 1.35669  validloss 3.60434±0.00000  bestvalidloss 3.38760  last_update 90\n",
      "train: iter 423  trainloss 1.32507  validloss 3.69541±0.00000  bestvalidloss 3.38760  last_update 91\n",
      "train: iter 424  trainloss 1.37089  validloss 3.83674±0.00000  bestvalidloss 3.38760  last_update 92\n",
      "train: iter 425  trainloss 1.38811  validloss 3.64466±0.00000  bestvalidloss 3.38760  last_update 93\n",
      "train: iter 426  trainloss 1.39521  validloss 3.76286±0.00000  bestvalidloss 3.38760  last_update 94\n",
      "train: iter 427  trainloss 1.37724  validloss 3.77069±0.00000  bestvalidloss 3.38760  last_update 95\n",
      "train: iter 428  trainloss 1.40189  validloss 3.74879±0.00000  bestvalidloss 3.38760  last_update 96\n",
      "train: iter 429  trainloss 1.35967  validloss 3.58777±0.00000  bestvalidloss 3.38760  last_update 97\n",
      "train: iter 430  trainloss 1.38103  validloss 3.65829±0.00000  bestvalidloss 3.38760  last_update 98\n",
      "train: iter 431  trainloss 1.40763  validloss 3.78644±0.00000  bestvalidloss 3.38760  last_update 99\n",
      "train: iter 432  trainloss 1.36818  validloss 3.55034±0.00000  bestvalidloss 3.38760  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-12.5076)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(2.6375)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2486510945220133\n",
      "tensor([2.6833])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
