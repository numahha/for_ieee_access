{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(526.4932)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 551.36279  validloss 864.62888±0.00000  bestvalidloss 864.62888  last_update 0\n",
      "train: iter 1  trainloss 228.96900  validloss 275.37786±0.00000  bestvalidloss 275.37786  last_update 0\n",
      "train: iter 2  trainloss -181.96004  validloss -3.64300±0.00000  bestvalidloss -3.64300  last_update 0\n",
      "train: iter 3  trainloss -393.42669  validloss -341.58264±0.00000  bestvalidloss -341.58264  last_update 0\n",
      "train: iter 4  trainloss -589.55358  validloss -627.14715±0.00000  bestvalidloss -627.14715  last_update 0\n",
      "train: iter 5  trainloss -707.21995  validloss -651.58288±0.00000  bestvalidloss -651.58288  last_update 0\n",
      "train: iter 6  trainloss -812.84519  validloss -791.46262±0.00000  bestvalidloss -791.46262  last_update 0\n",
      "train: iter 7  trainloss -901.49039  validloss -969.38331±0.00000  bestvalidloss -969.38331  last_update 0\n",
      "train: iter 8  trainloss -960.64626  validloss -1070.19966±0.00000  bestvalidloss -1070.19966  last_update 0\n",
      "train: iter 9  trainloss -1038.13671  validloss -1154.82611±0.00000  bestvalidloss -1154.82611  last_update 0\n",
      "train: iter 10  trainloss -1060.28984  validloss -1154.45135±0.00000  bestvalidloss -1154.82611  last_update 1\n",
      "train: iter 11  trainloss -1131.80371  validloss -1119.84955±0.00000  bestvalidloss -1154.82611  last_update 2\n",
      "train: iter 12  trainloss -1152.00080  validloss -1142.41233±0.00000  bestvalidloss -1154.82611  last_update 3\n",
      "train: iter 13  trainloss -1133.46283  validloss -1165.93529±0.00000  bestvalidloss -1165.93529  last_update 0\n",
      "train: iter 14  trainloss -1230.56917  validloss -1320.07725±0.00000  bestvalidloss -1320.07725  last_update 0\n",
      "train: iter 15  trainloss -1209.42415  validloss -1219.78380±0.00000  bestvalidloss -1320.07725  last_update 1\n",
      "train: iter 16  trainloss -1261.00546  validloss -1377.75465±0.00000  bestvalidloss -1377.75465  last_update 0\n",
      "train: iter 17  trainloss -1220.93639  validloss -1248.20414±0.00000  bestvalidloss -1377.75465  last_update 1\n",
      "train: iter 18  trainloss -1335.68390  validloss -1421.11443±0.00000  bestvalidloss -1421.11443  last_update 0\n",
      "train: iter 19  trainloss -1305.58631  validloss -1481.13352±0.00000  bestvalidloss -1481.13352  last_update 0\n",
      "train: iter 20  trainloss -1212.94803  validloss -1345.08868±0.00000  bestvalidloss -1481.13352  last_update 1\n",
      "train: iter 21  trainloss -1357.35113  validloss -1449.78855±0.00000  bestvalidloss -1481.13352  last_update 2\n",
      "train: iter 22  trainloss -1257.49900  validloss -1372.45750±0.00000  bestvalidloss -1481.13352  last_update 3\n",
      "train: iter 23  trainloss -1379.91180  validloss -1496.17672±0.00000  bestvalidloss -1496.17672  last_update 0\n",
      "train: iter 24  trainloss -1375.09507  validloss -1505.45866±0.00000  bestvalidloss -1505.45866  last_update 0\n",
      "train: iter 25  trainloss -1339.39239  validloss -1465.74508±0.00000  bestvalidloss -1505.45866  last_update 1\n",
      "train: iter 26  trainloss -1412.32776  validloss -1424.24265±0.00000  bestvalidloss -1505.45866  last_update 2\n",
      "train: iter 27  trainloss -1342.43036  validloss -1534.90229±0.00000  bestvalidloss -1534.90229  last_update 0\n",
      "train: iter 28  trainloss -1446.93512  validloss -1534.44251±0.00000  bestvalidloss -1534.90229  last_update 1\n",
      "train: iter 29  trainloss -1466.01682  validloss -1550.65872±0.00000  bestvalidloss -1550.65872  last_update 0\n",
      "train: iter 30  trainloss -1455.53630  validloss -1584.37078±0.00000  bestvalidloss -1584.37078  last_update 0\n",
      "train: iter 31  trainloss -1347.23841  validloss -1558.18380±0.00000  bestvalidloss -1584.37078  last_update 1\n",
      "train: iter 32  trainloss -1456.17329  validloss -1524.29086±0.00000  bestvalidloss -1584.37078  last_update 2\n",
      "train: iter 33  trainloss -1486.87902  validloss -1571.69852±0.00000  bestvalidloss -1584.37078  last_update 3\n",
      "train: iter 34  trainloss -1496.32177  validloss -1578.19492±0.00000  bestvalidloss -1584.37078  last_update 4\n",
      "train: iter 35  trainloss -1465.27768  validloss -1317.30085±0.00000  bestvalidloss -1584.37078  last_update 5\n",
      "train: iter 36  trainloss -1447.97390  validloss -1555.18617±0.00000  bestvalidloss -1584.37078  last_update 6\n",
      "train: iter 37  trainloss -1401.61181  validloss -1446.45167±0.00000  bestvalidloss -1584.37078  last_update 7\n",
      "train: iter 38  trainloss -1522.49728  validloss -1566.00461±0.00000  bestvalidloss -1584.37078  last_update 8\n",
      "train: iter 39  trainloss -1518.07524  validloss -1612.57421±0.00000  bestvalidloss -1612.57421  last_update 0\n",
      "train: iter 40  trainloss -1461.58643  validloss -1378.72874±0.00000  bestvalidloss -1612.57421  last_update 1\n",
      "train: iter 41  trainloss -1488.75070  validloss -1581.37790±0.00000  bestvalidloss -1612.57421  last_update 2\n",
      "train: iter 42  trainloss -1499.80004  validloss -1541.09372±0.00000  bestvalidloss -1612.57421  last_update 3\n",
      "train: iter 43  trainloss -1433.60723  validloss -1559.97286±0.00000  bestvalidloss -1612.57421  last_update 4\n",
      "train: iter 44  trainloss -1499.66082  validloss -1610.87748±0.00000  bestvalidloss -1612.57421  last_update 5\n",
      "train: iter 45  trainloss -1503.31876  validloss -1676.38936±0.00000  bestvalidloss -1676.38936  last_update 0\n",
      "train: iter 46  trainloss -1568.07597  validloss -1690.20460±0.00000  bestvalidloss -1690.20460  last_update 0\n",
      "train: iter 47  trainloss -1556.61512  validloss -1664.84601±0.00000  bestvalidloss -1690.20460  last_update 1\n",
      "train: iter 48  trainloss -1476.67284  validloss -1542.68026±0.00000  bestvalidloss -1690.20460  last_update 2\n",
      "train: iter 49  trainloss -1532.35801  validloss -1578.32417±0.00000  bestvalidloss -1690.20460  last_update 3\n",
      "train: iter 50  trainloss -1608.08602  validloss -1699.55305±0.00000  bestvalidloss -1699.55305  last_update 0\n",
      "train: iter 51  trainloss -1586.78847  validloss -1670.55379±0.00000  bestvalidloss -1699.55305  last_update 1\n",
      "train: iter 52  trainloss -1523.26929  validloss -1319.29938±0.00000  bestvalidloss -1699.55305  last_update 2\n",
      "train: iter 53  trainloss -1612.92708  validloss -1722.22874±0.00000  bestvalidloss -1722.22874  last_update 0\n",
      "train: iter 54  trainloss -1467.40970  validloss -1705.20696±0.00000  bestvalidloss -1722.22874  last_update 1\n",
      "train: iter 55  trainloss -1576.11989  validloss -1610.23975±0.00000  bestvalidloss -1722.22874  last_update 2\n",
      "train: iter 56  trainloss -1642.17257  validloss -1709.40399±0.00000  bestvalidloss -1722.22874  last_update 3\n",
      "train: iter 57  trainloss -1652.75507  validloss -1695.17342±0.00000  bestvalidloss -1722.22874  last_update 4\n",
      "train: iter 58  trainloss -1652.40453  validloss -1746.13697±0.00000  bestvalidloss -1746.13697  last_update 0\n",
      "train: iter 59  trainloss -1633.14462  validloss -1713.55572±0.00000  bestvalidloss -1746.13697  last_update 1\n",
      "train: iter 60  trainloss -1579.97904  validloss -1733.13972±0.00000  bestvalidloss -1746.13697  last_update 2\n",
      "train: iter 61  trainloss -1528.61100  validloss -1510.11919±0.00000  bestvalidloss -1746.13697  last_update 3\n",
      "train: iter 62  trainloss -1512.94330  validloss -1726.37239±0.00000  bestvalidloss -1746.13697  last_update 4\n",
      "train: iter 63  trainloss -1649.50120  validloss -1622.25565±0.00000  bestvalidloss -1746.13697  last_update 5\n",
      "train: iter 64  trainloss -1689.56045  validloss -1772.18406±0.00000  bestvalidloss -1772.18406  last_update 0\n",
      "train: iter 65  trainloss -1703.66161  validloss -1796.03200±0.00000  bestvalidloss -1796.03200  last_update 0\n",
      "train: iter 66  trainloss -1677.87303  validloss -1795.58363±0.00000  bestvalidloss -1796.03200  last_update 1\n",
      "train: iter 67  trainloss -1515.20882  validloss -1771.62732±0.00000  bestvalidloss -1796.03200  last_update 2\n",
      "train: iter 68  trainloss -1707.29325  validloss -1798.05387±0.00000  bestvalidloss -1798.05387  last_update 0\n",
      "train: iter 69  trainloss -1722.26445  validloss -1819.50484±0.00000  bestvalidloss -1819.50484  last_update 0\n",
      "train: iter 70  trainloss -1586.08814  validloss -1750.46569±0.00000  bestvalidloss -1819.50484  last_update 1\n",
      "train: iter 71  trainloss -1729.91616  validloss -1779.72210±0.00000  bestvalidloss -1819.50484  last_update 2\n",
      "train: iter 72  trainloss -1719.74168  validloss -1802.56012±0.00000  bestvalidloss -1819.50484  last_update 3\n",
      "train: iter 73  trainloss -1670.66402  validloss -1758.25353±0.00000  bestvalidloss -1819.50484  last_update 4\n",
      "train: iter 74  trainloss -1623.57947  validloss -1743.92619±0.00000  bestvalidloss -1819.50484  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1539.62077  validloss -1763.51031±0.00000  bestvalidloss -1819.50484  last_update 6\n",
      "train: iter 76  trainloss -1453.67689  validloss -1559.54752±0.00000  bestvalidloss -1819.50484  last_update 7\n",
      "train: iter 77  trainloss -1727.11617  validloss -1781.41733±0.00000  bestvalidloss -1819.50484  last_update 8\n",
      "train: iter 78  trainloss -1751.96500  validloss -1832.30306±0.00000  bestvalidloss -1832.30306  last_update 0\n",
      "train: iter 79  trainloss -1747.48000  validloss -1847.18004±0.00000  bestvalidloss -1847.18004  last_update 0\n",
      "train: iter 80  trainloss -1727.75532  validloss -1853.57812±0.00000  bestvalidloss -1853.57812  last_update 0\n",
      "train: iter 81  trainloss -1726.33644  validloss -1756.93260±0.00000  bestvalidloss -1853.57812  last_update 1\n",
      "train: iter 82  trainloss -1753.00437  validloss -1866.12921±0.00000  bestvalidloss -1866.12921  last_update 0\n",
      "train: iter 83  trainloss -1729.26043  validloss -1853.03549±0.00000  bestvalidloss -1866.12921  last_update 1\n",
      "train: iter 84  trainloss -1757.84976  validloss -1730.88425±0.00000  bestvalidloss -1866.12921  last_update 2\n",
      "train: iter 85  trainloss -1756.85281  validloss -1870.20801±0.00000  bestvalidloss -1870.20801  last_update 0\n",
      "train: iter 86  trainloss -1772.90671  validloss -1817.48186±0.00000  bestvalidloss -1870.20801  last_update 1\n",
      "train: iter 87  trainloss -1758.81253  validloss -1875.22425±0.00000  bestvalidloss -1875.22425  last_update 0\n",
      "train: iter 88  trainloss -1755.31826  validloss -1892.67465±0.00000  bestvalidloss -1892.67465  last_update 0\n",
      "train: iter 89  trainloss -1725.13481  validloss -1773.82466±0.00000  bestvalidloss -1892.67465  last_update 1\n",
      "train: iter 90  trainloss -1750.32877  validloss -1872.65848±0.00000  bestvalidloss -1892.67465  last_update 2\n",
      "train: iter 91  trainloss -1750.99529  validloss -1884.66210±0.00000  bestvalidloss -1892.67465  last_update 3\n",
      "train: iter 92  trainloss -1710.55339  validloss -1833.95763±0.00000  bestvalidloss -1892.67465  last_update 4\n",
      "train: iter 93  trainloss -1770.76907  validloss -1858.04885±0.00000  bestvalidloss -1892.67465  last_update 5\n",
      "train: iter 94  trainloss -1789.85676  validloss -1900.07006±0.00000  bestvalidloss -1900.07006  last_update 0\n",
      "train: iter 95  trainloss -1699.02880  validloss -1758.26575±0.00000  bestvalidloss -1900.07006  last_update 1\n",
      "train: iter 96  trainloss -1666.73228  validloss -1826.53602±0.00000  bestvalidloss -1900.07006  last_update 2\n",
      "train: iter 97  trainloss -1768.83764  validloss -1815.16433±0.00000  bestvalidloss -1900.07006  last_update 3\n",
      "train: iter 98  trainloss -1732.94018  validloss -1903.80013±0.00000  bestvalidloss -1903.80013  last_update 0\n",
      "train: iter 99  trainloss -1830.01990  validloss -1910.85911±0.00000  bestvalidloss -1910.85911  last_update 0\n",
      "train: iter 100  trainloss -1815.43087  validloss -1910.90922±0.00000  bestvalidloss -1910.90922  last_update 0\n",
      "train: iter 101  trainloss -1813.46387  validloss -1858.78101±0.00000  bestvalidloss -1910.90922  last_update 1\n",
      "train: iter 102  trainloss -1745.63164  validloss -1933.40857±0.00000  bestvalidloss -1933.40857  last_update 0\n",
      "train: iter 103  trainloss -1814.99541  validloss -1821.15441±0.00000  bestvalidloss -1933.40857  last_update 1\n",
      "train: iter 104  trainloss -1828.92960  validloss -1903.56873±0.00000  bestvalidloss -1933.40857  last_update 2\n",
      "train: iter 105  trainloss -1763.80401  validloss -1853.70070±0.00000  bestvalidloss -1933.40857  last_update 3\n",
      "train: iter 106  trainloss -1793.19617  validloss -1909.55901±0.00000  bestvalidloss -1933.40857  last_update 4\n",
      "train: iter 107  trainloss -1778.59206  validloss -1908.88867±0.00000  bestvalidloss -1933.40857  last_update 5\n",
      "train: iter 108  trainloss -1791.46402  validloss -1908.95986±0.00000  bestvalidloss -1933.40857  last_update 6\n",
      "train: iter 109  trainloss -1823.17190  validloss -1875.88767±0.00000  bestvalidloss -1933.40857  last_update 7\n",
      "train: iter 110  trainloss -1807.34341  validloss -1906.90554±0.00000  bestvalidloss -1933.40857  last_update 8\n",
      "train: iter 111  trainloss -1817.13236  validloss -1938.28690±0.00000  bestvalidloss -1938.28690  last_update 0\n",
      "train: iter 112  trainloss -1832.71279  validloss -1928.57800±0.00000  bestvalidloss -1938.28690  last_update 1\n",
      "train: iter 113  trainloss -1822.96925  validloss -1840.42844±0.00000  bestvalidloss -1938.28690  last_update 2\n",
      "train: iter 114  trainloss -1783.21805  validloss -1919.67697±0.00000  bestvalidloss -1938.28690  last_update 3\n",
      "train: iter 115  trainloss -1837.94726  validloss -1736.93156±0.00000  bestvalidloss -1938.28690  last_update 4\n",
      "train: iter 116  trainloss -1819.21618  validloss -1837.80825±0.00000  bestvalidloss -1938.28690  last_update 5\n",
      "train: iter 117  trainloss -1736.74026  validloss -1795.49415±0.00000  bestvalidloss -1938.28690  last_update 6\n",
      "train: iter 118  trainloss -1755.88416  validloss -1841.52148±0.00000  bestvalidloss -1938.28690  last_update 7\n",
      "train: iter 119  trainloss -1740.83280  validloss -1915.93716±0.00000  bestvalidloss -1938.28690  last_update 8\n",
      "train: iter 120  trainloss -1822.97316  validloss -1796.12543±0.00000  bestvalidloss -1938.28690  last_update 9\n",
      "train: iter 121  trainloss -1834.60724  validloss -1910.66152±0.00000  bestvalidloss -1938.28690  last_update 10\n",
      "train: iter 122  trainloss -1860.82733  validloss -1939.56402±0.00000  bestvalidloss -1939.56402  last_update 0\n",
      "train: iter 123  trainloss -1814.60801  validloss -1967.95281±0.00000  bestvalidloss -1967.95281  last_update 0\n",
      "train: iter 124  trainloss -1874.14266  validloss -1966.71385±0.00000  bestvalidloss -1967.95281  last_update 1\n",
      "train: iter 125  trainloss -1861.24100  validloss -1933.74342±0.00000  bestvalidloss -1967.95281  last_update 2\n",
      "train: iter 126  trainloss -1864.01692  validloss -1934.42297±0.00000  bestvalidloss -1967.95281  last_update 3\n",
      "train: iter 127  trainloss -1775.12289  validloss -1930.79553±0.00000  bestvalidloss -1967.95281  last_update 4\n",
      "train: iter 128  trainloss -1729.37204  validloss -1910.84284±0.00000  bestvalidloss -1967.95281  last_update 5\n",
      "train: iter 129  trainloss -1735.15025  validloss -1886.58307±0.00000  bestvalidloss -1967.95281  last_update 6\n",
      "train: iter 130  trainloss -1868.92594  validloss -1943.09644±0.00000  bestvalidloss -1967.95281  last_update 7\n",
      "train: iter 131  trainloss -1880.80214  validloss -1918.12484±0.00000  bestvalidloss -1967.95281  last_update 8\n",
      "train: iter 132  trainloss -1850.24880  validloss -1981.16287±0.00000  bestvalidloss -1981.16287  last_update 0\n",
      "train: iter 133  trainloss -1866.00819  validloss -1930.47530±0.00000  bestvalidloss -1981.16287  last_update 1\n",
      "train: iter 134  trainloss -1895.30314  validloss -1972.25871±0.00000  bestvalidloss -1981.16287  last_update 2\n",
      "train: iter 135  trainloss -1820.59976  validloss -1924.61999±0.00000  bestvalidloss -1981.16287  last_update 3\n",
      "train: iter 136  trainloss -1831.70011  validloss -1871.84987±0.00000  bestvalidloss -1981.16287  last_update 4\n",
      "train: iter 137  trainloss -1844.94242  validloss -1849.60443±0.00000  bestvalidloss -1981.16287  last_update 5\n",
      "train: iter 138  trainloss -1868.75144  validloss -1958.54477±0.00000  bestvalidloss -1981.16287  last_update 6\n",
      "train: iter 139  trainloss -1779.85691  validloss -1965.91719±0.00000  bestvalidloss -1981.16287  last_update 7\n",
      "train: iter 140  trainloss -1708.16154  validloss -1699.68445±0.00000  bestvalidloss -1981.16287  last_update 8\n",
      "train: iter 141  trainloss -1863.39831  validloss -1951.46733±0.00000  bestvalidloss -1981.16287  last_update 9\n",
      "train: iter 142  trainloss -1887.29152  validloss -1945.58004±0.00000  bestvalidloss -1981.16287  last_update 10\n",
      "train: iter 143  trainloss -1845.74320  validloss -1972.48906±0.00000  bestvalidloss -1981.16287  last_update 11\n",
      "train: iter 144  trainloss -1826.02276  validloss -1948.12705±0.00000  bestvalidloss -1981.16287  last_update 12\n",
      "train: iter 145  trainloss -1886.24024  validloss -1930.52360±0.00000  bestvalidloss -1981.16287  last_update 13\n",
      "train: iter 146  trainloss -1848.55960  validloss -1928.24918±0.00000  bestvalidloss -1981.16287  last_update 14\n",
      "train: iter 147  trainloss -1863.15062  validloss -1920.92443±0.00000  bestvalidloss -1981.16287  last_update 15\n",
      "train: iter 148  trainloss -1872.29266  validloss -1949.59066±0.00000  bestvalidloss -1981.16287  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -1627.47826  validloss -1934.37549±0.00000  bestvalidloss -1981.16287  last_update 17\n",
      "train: iter 150  trainloss -1715.93441  validloss -1858.58333±0.00000  bestvalidloss -1981.16287  last_update 18\n",
      "train: iter 151  trainloss -1822.72518  validloss -1909.61822±0.00000  bestvalidloss -1981.16287  last_update 19\n",
      "train: iter 152  trainloss -1904.60151  validloss -1977.12392±0.00000  bestvalidloss -1981.16287  last_update 20\n",
      "train: iter 153  trainloss -1885.55883  validloss -1977.63222±0.00000  bestvalidloss -1981.16287  last_update 21\n",
      "train: iter 154  trainloss -1763.25123  validloss -1862.11285±0.00000  bestvalidloss -1981.16287  last_update 22\n",
      "train: iter 155  trainloss -1764.42841  validloss -1249.17041±0.00000  bestvalidloss -1981.16287  last_update 23\n",
      "train: iter 156  trainloss -1885.15431  validloss -1883.66042±0.00000  bestvalidloss -1981.16287  last_update 24\n",
      "train: iter 157  trainloss -1888.99631  validloss -1965.26451±0.00000  bestvalidloss -1981.16287  last_update 25\n",
      "train: iter 158  trainloss -1839.83298  validloss -1966.11673±0.00000  bestvalidloss -1981.16287  last_update 26\n",
      "train: iter 159  trainloss -1866.78780  validloss -1980.56025±0.00000  bestvalidloss -1981.16287  last_update 27\n",
      "train: iter 160  trainloss -1882.17561  validloss -1949.42589±0.00000  bestvalidloss -1981.16287  last_update 28\n",
      "train: iter 161  trainloss -1896.18453  validloss -1956.82175±0.00000  bestvalidloss -1981.16287  last_update 29\n",
      "train: iter 162  trainloss -1861.41389  validloss -1952.28211±0.00000  bestvalidloss -1981.16287  last_update 30\n",
      "train: iter 163  trainloss -1847.84497  validloss -1940.98682±0.00000  bestvalidloss -1981.16287  last_update 31\n",
      "train: iter 164  trainloss -1907.31196  validloss -1983.32805±0.00000  bestvalidloss -1983.32805  last_update 0\n",
      "train: iter 165  trainloss -1895.25463  validloss -1942.81469±0.00000  bestvalidloss -1983.32805  last_update 1\n",
      "train: iter 166  trainloss -1880.61179  validloss -1938.27301±0.00000  bestvalidloss -1983.32805  last_update 2\n",
      "train: iter 167  trainloss -1895.15093  validloss -1973.99030±0.00000  bestvalidloss -1983.32805  last_update 3\n",
      "train: iter 168  trainloss -1898.34851  validloss -1975.65207±0.00000  bestvalidloss -1983.32805  last_update 4\n",
      "train: iter 169  trainloss -1906.59461  validloss -1942.70453±0.00000  bestvalidloss -1983.32805  last_update 5\n",
      "train: iter 170  trainloss -1896.40344  validloss -1987.39427±0.00000  bestvalidloss -1987.39427  last_update 0\n",
      "train: iter 171  trainloss -1736.12486  validloss -1965.56802±0.00000  bestvalidloss -1987.39427  last_update 1\n",
      "train: iter 172  trainloss -1745.25687  validloss -1925.39333±0.00000  bestvalidloss -1987.39427  last_update 2\n",
      "train: iter 173  trainloss -1899.03312  validloss -1934.43139±0.00000  bestvalidloss -1987.39427  last_update 3\n",
      "train: iter 174  trainloss -1895.55120  validloss -1983.03495±0.00000  bestvalidloss -1987.39427  last_update 4\n",
      "train: iter 175  trainloss -1819.76823  validloss -1961.00875±0.00000  bestvalidloss -1987.39427  last_update 5\n",
      "train: iter 176  trainloss -1877.54269  validloss -1920.20605±0.00000  bestvalidloss -1987.39427  last_update 6\n",
      "train: iter 177  trainloss -1897.99157  validloss -1989.62962±0.00000  bestvalidloss -1989.62962  last_update 0\n",
      "train: iter 178  trainloss -1872.39678  validloss -1965.03121±0.00000  bestvalidloss -1989.62962  last_update 1\n",
      "train: iter 179  trainloss -1860.92115  validloss -1962.84887±0.00000  bestvalidloss -1989.62962  last_update 2\n",
      "train: iter 180  trainloss -1900.63288  validloss -1966.79541±0.00000  bestvalidloss -1989.62962  last_update 3\n",
      "train: iter 181  trainloss -1895.56997  validloss -1979.35039±0.00000  bestvalidloss -1989.62962  last_update 4\n",
      "train: iter 182  trainloss -1913.99530  validloss -1986.01378±0.00000  bestvalidloss -1989.62962  last_update 5\n",
      "train: iter 183  trainloss -1906.34259  validloss -1955.08661±0.00000  bestvalidloss -1989.62962  last_update 6\n",
      "train: iter 184  trainloss -1836.00047  validloss -1973.82229±0.00000  bestvalidloss -1989.62962  last_update 7\n",
      "train: iter 185  trainloss -1835.46828  validloss -1980.26069±0.00000  bestvalidloss -1989.62962  last_update 8\n",
      "train: iter 186  trainloss -1824.06831  validloss -1972.61973±0.00000  bestvalidloss -1989.62962  last_update 9\n",
      "train: iter 187  trainloss -1918.89259  validloss -1917.98555±0.00000  bestvalidloss -1989.62962  last_update 10\n",
      "train: iter 188  trainloss -1923.92135  validloss -1995.22762±0.00000  bestvalidloss -1995.22762  last_update 0\n",
      "train: iter 189  trainloss -1870.85366  validloss -1930.48179±0.00000  bestvalidloss -1995.22762  last_update 1\n",
      "train: iter 190  trainloss -1677.99258  validloss -1994.67831±0.00000  bestvalidloss -1995.22762  last_update 2\n",
      "train: iter 191  trainloss -1892.67005  validloss -1931.83137±0.00000  bestvalidloss -1995.22762  last_update 3\n",
      "train: iter 192  trainloss -1922.50049  validloss -2004.92378±0.00000  bestvalidloss -2004.92378  last_update 0\n",
      "train: iter 193  trainloss -1841.47633  validloss -1991.65831±0.00000  bestvalidloss -2004.92378  last_update 1\n",
      "train: iter 194  trainloss -1822.13939  validloss -1937.36600±0.00000  bestvalidloss -2004.92378  last_update 2\n",
      "train: iter 195  trainloss -1923.19575  validloss -1972.56729±0.00000  bestvalidloss -2004.92378  last_update 3\n",
      "train: iter 196  trainloss -1917.38148  validloss -1954.36085±0.00000  bestvalidloss -2004.92378  last_update 4\n",
      "train: iter 197  trainloss -1903.66808  validloss -2000.70955±0.00000  bestvalidloss -2004.92378  last_update 5\n",
      "train: iter 198  trainloss -1928.07421  validloss -1981.05253±0.00000  bestvalidloss -2004.92378  last_update 6\n",
      "train: iter 199  trainloss -1921.91646  validloss -1996.68068±0.00000  bestvalidloss -2004.92378  last_update 7\n",
      "train: iter 200  trainloss -1748.83679  validloss -1975.31443±0.00000  bestvalidloss -2004.92378  last_update 8\n",
      "train: iter 201  trainloss -1915.44845  validloss -1945.86120±0.00000  bestvalidloss -2004.92378  last_update 9\n",
      "train: iter 202  trainloss -1932.90034  validloss -2016.17611±0.00000  bestvalidloss -2016.17611  last_update 0\n",
      "train: iter 203  trainloss -1866.25025  validloss -1970.33672±0.00000  bestvalidloss -2016.17611  last_update 1\n",
      "train: iter 204  trainloss -1900.18678  validloss -1901.57811±0.00000  bestvalidloss -2016.17611  last_update 2\n",
      "train: iter 205  trainloss -1922.92242  validloss -1950.47650±0.00000  bestvalidloss -2016.17611  last_update 3\n",
      "train: iter 206  trainloss -1933.26710  validloss -2017.96993±0.00000  bestvalidloss -2017.96993  last_update 0\n",
      "train: iter 207  trainloss -1730.62443  validloss -2005.09598±0.00000  bestvalidloss -2017.96993  last_update 1\n",
      "train: iter 208  trainloss -1874.64946  validloss -1978.72571±0.00000  bestvalidloss -2017.96993  last_update 2\n",
      "train: iter 209  trainloss -1901.00291  validloss -2016.44534±0.00000  bestvalidloss -2017.96993  last_update 3\n",
      "train: iter 210  trainloss -1848.37077  validloss -1914.64210±0.00000  bestvalidloss -2017.96993  last_update 4\n",
      "train: iter 211  trainloss -1847.95071  validloss -1915.40298±0.00000  bestvalidloss -2017.96993  last_update 5\n",
      "train: iter 212  trainloss -1829.36102  validloss -1690.15934±0.00000  bestvalidloss -2017.96993  last_update 6\n",
      "train: iter 213  trainloss -1924.07478  validloss -1923.43508±0.00000  bestvalidloss -2017.96993  last_update 7\n",
      "train: iter 214  trainloss -1910.68128  validloss -2008.63505±0.00000  bestvalidloss -2017.96993  last_update 8\n",
      "train: iter 215  trainloss -1896.28420  validloss -1969.04785±0.00000  bestvalidloss -2017.96993  last_update 9\n",
      "train: iter 216  trainloss -1878.86111  validloss -1898.92192±0.00000  bestvalidloss -2017.96993  last_update 10\n",
      "train: iter 217  trainloss -1931.75241  validloss -2020.94882±0.00000  bestvalidloss -2020.94882  last_update 0\n",
      "train: iter 218  trainloss -1936.83032  validloss -2004.69014±0.00000  bestvalidloss -2020.94882  last_update 1\n",
      "train: iter 219  trainloss -1869.91352  validloss -2003.59985±0.00000  bestvalidloss -2020.94882  last_update 2\n",
      "train: iter 220  trainloss -1745.04940  validloss -1925.01104±0.00000  bestvalidloss -2020.94882  last_update 3\n",
      "train: iter 221  trainloss -1923.77738  validloss -1988.21508±0.00000  bestvalidloss -2020.94882  last_update 4\n",
      "train: iter 222  trainloss -1944.38306  validloss -2017.58931±0.00000  bestvalidloss -2020.94882  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1931.76938  validloss -1978.37260±0.00000  bestvalidloss -2020.94882  last_update 6\n",
      "train: iter 224  trainloss -1894.89166  validloss -1942.53503±0.00000  bestvalidloss -2020.94882  last_update 7\n",
      "train: iter 225  trainloss -1867.75664  validloss -1994.81476±0.00000  bestvalidloss -2020.94882  last_update 8\n",
      "train: iter 226  trainloss -1834.19804  validloss -1958.48113±0.00000  bestvalidloss -2020.94882  last_update 9\n",
      "train: iter 227  trainloss -1947.06652  validloss -2008.31588±0.00000  bestvalidloss -2020.94882  last_update 10\n",
      "train: iter 228  trainloss -1934.28533  validloss -1979.27401±0.00000  bestvalidloss -2020.94882  last_update 11\n",
      "train: iter 229  trainloss -1916.85249  validloss -2022.42882±0.00000  bestvalidloss -2022.42882  last_update 0\n",
      "train: iter 230  trainloss -1947.95142  validloss -2013.37896±0.00000  bestvalidloss -2022.42882  last_update 1\n",
      "train: iter 231  trainloss -1953.29302  validloss -2020.44449±0.00000  bestvalidloss -2022.42882  last_update 2\n",
      "train: iter 232  trainloss -1825.00043  validloss -2029.08055±0.00000  bestvalidloss -2029.08055  last_update 0\n",
      "train: iter 233  trainloss -1896.01858  validloss -1787.00369±0.00000  bestvalidloss -2029.08055  last_update 1\n",
      "train: iter 234  trainloss -1898.27069  validloss -1995.66584±0.00000  bestvalidloss -2029.08055  last_update 2\n",
      "train: iter 235  trainloss -1860.54102  validloss -1852.99970±0.00000  bestvalidloss -2029.08055  last_update 3\n",
      "train: iter 236  trainloss -1937.60656  validloss -1998.56961±0.00000  bestvalidloss -2029.08055  last_update 4\n",
      "train: iter 237  trainloss -1949.36645  validloss -2001.31984±0.00000  bestvalidloss -2029.08055  last_update 5\n",
      "train: iter 238  trainloss -1951.12921  validloss -2035.67357±0.00000  bestvalidloss -2035.67357  last_update 0\n",
      "train: iter 239  trainloss -1597.39281  validloss -1930.77266±0.00000  bestvalidloss -2035.67357  last_update 1\n",
      "train: iter 240  trainloss -1908.11107  validloss -2014.53878±0.00000  bestvalidloss -2035.67357  last_update 2\n",
      "train: iter 241  trainloss -1955.66476  validloss -2020.52232±0.00000  bestvalidloss -2035.67357  last_update 3\n",
      "train: iter 242  trainloss -1922.75640  validloss -1967.58569±0.00000  bestvalidloss -2035.67357  last_update 4\n",
      "train: iter 243  trainloss -1942.86492  validloss -2003.95446±0.00000  bestvalidloss -2035.67357  last_update 5\n",
      "train: iter 244  trainloss -1908.23087  validloss -2024.14598±0.00000  bestvalidloss -2035.67357  last_update 6\n",
      "train: iter 245  trainloss -1947.94649  validloss -1975.55016±0.00000  bestvalidloss -2035.67357  last_update 7\n",
      "train: iter 246  trainloss -1894.66668  validloss -2014.53155±0.00000  bestvalidloss -2035.67357  last_update 8\n",
      "train: iter 247  trainloss -1970.42912  validloss -2001.79040±0.00000  bestvalidloss -2035.67357  last_update 9\n",
      "train: iter 248  trainloss -1914.01032  validloss -2028.90078±0.00000  bestvalidloss -2035.67357  last_update 10\n",
      "train: iter 249  trainloss -1891.35104  validloss -2029.16255±0.00000  bestvalidloss -2035.67357  last_update 11\n",
      "train: iter 250  trainloss -1876.40873  validloss -1914.07529±0.00000  bestvalidloss -2035.67357  last_update 12\n",
      "train: iter 251  trainloss -1910.45834  validloss -2006.15054±0.00000  bestvalidloss -2035.67357  last_update 13\n",
      "train: iter 252  trainloss -1926.36023  validloss -2047.69862±0.00000  bestvalidloss -2047.69862  last_update 0\n",
      "train: iter 253  trainloss -1923.91628  validloss -2042.60734±0.00000  bestvalidloss -2047.69862  last_update 1\n",
      "train: iter 254  trainloss -1865.64737  validloss -1958.11729±0.00000  bestvalidloss -2047.69862  last_update 2\n",
      "train: iter 255  trainloss -1690.90077  validloss -1360.71201±0.00000  bestvalidloss -2047.69862  last_update 3\n",
      "train: iter 256  trainloss -1931.76242  validloss -1994.53456±0.00000  bestvalidloss -2047.69862  last_update 4\n",
      "train: iter 257  trainloss -1948.72748  validloss -2016.39575±0.00000  bestvalidloss -2047.69862  last_update 5\n",
      "train: iter 258  trainloss -1920.52248  validloss -1996.40539±0.00000  bestvalidloss -2047.69862  last_update 6\n",
      "train: iter 259  trainloss -1891.62328  validloss -2020.59283±0.00000  bestvalidloss -2047.69862  last_update 7\n",
      "train: iter 260  trainloss -1950.67665  validloss -2029.58035±0.00000  bestvalidloss -2047.69862  last_update 8\n",
      "train: iter 261  trainloss -1973.36647  validloss -2005.61373±0.00000  bestvalidloss -2047.69862  last_update 9\n",
      "train: iter 262  trainloss -1975.97623  validloss -2007.87395±0.00000  bestvalidloss -2047.69862  last_update 10\n",
      "train: iter 263  trainloss -1980.04621  validloss -2025.01000±0.00000  bestvalidloss -2047.69862  last_update 11\n",
      "train: iter 264  trainloss -1688.25983  validloss -2011.17960±0.00000  bestvalidloss -2047.69862  last_update 12\n",
      "train: iter 265  trainloss -1778.38527  validloss -1175.59015±0.00000  bestvalidloss -2047.69862  last_update 13\n",
      "train: iter 266  trainloss -1942.45959  validloss -2020.47857±0.00000  bestvalidloss -2047.69862  last_update 14\n",
      "train: iter 267  trainloss -1929.56176  validloss -1944.36334±0.00000  bestvalidloss -2047.69862  last_update 15\n",
      "train: iter 268  trainloss -1939.70955  validloss -2022.96792±0.00000  bestvalidloss -2047.69862  last_update 16\n",
      "train: iter 269  trainloss -1959.06449  validloss -2031.79810±0.00000  bestvalidloss -2047.69862  last_update 17\n",
      "train: iter 270  trainloss -1926.27006  validloss -2028.26228±0.00000  bestvalidloss -2047.69862  last_update 18\n",
      "train: iter 271  trainloss -1966.32981  validloss -2023.49141±0.00000  bestvalidloss -2047.69862  last_update 19\n",
      "train: iter 272  trainloss -1984.57934  validloss -2036.26912±0.00000  bestvalidloss -2047.69862  last_update 20\n",
      "train: iter 273  trainloss -1963.13413  validloss -2046.31810±0.00000  bestvalidloss -2047.69862  last_update 21\n",
      "train: iter 274  trainloss -1856.83309  validloss -2006.53357±0.00000  bestvalidloss -2047.69862  last_update 22\n",
      "train: iter 275  trainloss -1968.91245  validloss -2022.76346±0.00000  bestvalidloss -2047.69862  last_update 23\n",
      "train: iter 276  trainloss -1970.66293  validloss -2040.40096±0.00000  bestvalidloss -2047.69862  last_update 24\n",
      "train: iter 277  trainloss -1977.84041  validloss -2027.97767±0.00000  bestvalidloss -2047.69862  last_update 25\n",
      "train: iter 278  trainloss -1941.60295  validloss -1997.95956±0.00000  bestvalidloss -2047.69862  last_update 26\n",
      "train: iter 279  trainloss -1970.44659  validloss -2051.73387±0.00000  bestvalidloss -2051.73387  last_update 0\n",
      "train: iter 280  trainloss -1917.77190  validloss -2043.93148±0.00000  bestvalidloss -2051.73387  last_update 1\n",
      "train: iter 281  trainloss -1842.43614  validloss -1960.29082±0.00000  bestvalidloss -2051.73387  last_update 2\n",
      "train: iter 282  trainloss -1899.84447  validloss -1956.38771±0.00000  bestvalidloss -2051.73387  last_update 3\n",
      "train: iter 283  trainloss -1976.68700  validloss -2040.23452±0.00000  bestvalidloss -2051.73387  last_update 4\n",
      "train: iter 284  trainloss -1980.80532  validloss -2002.04474±0.00000  bestvalidloss -2051.73387  last_update 5\n",
      "train: iter 285  trainloss -1912.59347  validloss -2023.38256±0.00000  bestvalidloss -2051.73387  last_update 6\n",
      "train: iter 286  trainloss -1939.04494  validloss -2040.63448±0.00000  bestvalidloss -2051.73387  last_update 7\n",
      "train: iter 287  trainloss -1897.93839  validloss -2052.02114±0.00000  bestvalidloss -2052.02114  last_update 0\n",
      "train: iter 288  trainloss -1923.40458  validloss -1976.20572±0.00000  bestvalidloss -2052.02114  last_update 1\n",
      "train: iter 289  trainloss -1968.06420  validloss -2033.84287±0.00000  bestvalidloss -2052.02114  last_update 2\n",
      "train: iter 290  trainloss -1966.27608  validloss -2061.64431±0.00000  bestvalidloss -2061.64431  last_update 0\n",
      "train: iter 291  trainloss -1906.58030  validloss -2019.47429±0.00000  bestvalidloss -2061.64431  last_update 1\n",
      "train: iter 292  trainloss -1962.73486  validloss -2033.95550±0.00000  bestvalidloss -2061.64431  last_update 2\n",
      "train: iter 293  trainloss -1988.89644  validloss -2012.66049±0.00000  bestvalidloss -2061.64431  last_update 3\n",
      "train: iter 294  trainloss -1984.66954  validloss -2056.59745±0.00000  bestvalidloss -2061.64431  last_update 4\n",
      "train: iter 295  trainloss -1953.69968  validloss -1975.99949±0.00000  bestvalidloss -2061.64431  last_update 5\n",
      "train: iter 296  trainloss -1949.95661  validloss -2009.86021±0.00000  bestvalidloss -2061.64431  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 297  trainloss -1978.43035  validloss -2042.81036±0.00000  bestvalidloss -2061.64431  last_update 7\n",
      "train: iter 298  trainloss -1959.34484  validloss -2031.88962±0.00000  bestvalidloss -2061.64431  last_update 8\n",
      "train: iter 299  trainloss -1806.60224  validloss -1976.59122±0.00000  bestvalidloss -2061.64431  last_update 9\n",
      "train: iter 300  trainloss -1898.53832  validloss -1978.73196±0.00000  bestvalidloss -2061.64431  last_update 10\n",
      "train: iter 301  trainloss -1986.82449  validloss -2052.79636±0.00000  bestvalidloss -2061.64431  last_update 11\n",
      "train: iter 302  trainloss -1934.78255  validloss -1983.35406±0.00000  bestvalidloss -2061.64431  last_update 12\n",
      "train: iter 303  trainloss -1961.66419  validloss -2050.28568±0.00000  bestvalidloss -2061.64431  last_update 13\n",
      "train: iter 304  trainloss -1990.51385  validloss -2029.31945±0.00000  bestvalidloss -2061.64431  last_update 14\n",
      "train: iter 305  trainloss -1964.75298  validloss -1948.13641±0.00000  bestvalidloss -2061.64431  last_update 15\n",
      "train: iter 306  trainloss -1958.91760  validloss -1986.49478±0.00000  bestvalidloss -2061.64431  last_update 16\n",
      "train: iter 307  trainloss -1979.85860  validloss -2019.43229±0.00000  bestvalidloss -2061.64431  last_update 17\n",
      "train: iter 308  trainloss -1436.45060  validloss -1929.54059±0.00000  bestvalidloss -2061.64431  last_update 18\n",
      "train: iter 309  trainloss -1861.29343  validloss -1837.11354±0.00000  bestvalidloss -2061.64431  last_update 19\n",
      "train: iter 310  trainloss -1969.70946  validloss -2033.32492±0.00000  bestvalidloss -2061.64431  last_update 20\n",
      "train: iter 311  trainloss -1944.58578  validloss -2008.12539±0.00000  bestvalidloss -2061.64431  last_update 21\n",
      "train: iter 312  trainloss -1986.48728  validloss -2062.19247±0.00000  bestvalidloss -2062.19247  last_update 0\n",
      "train: iter 313  trainloss -1967.16224  validloss -2038.84224±0.00000  bestvalidloss -2062.19247  last_update 1\n",
      "train: iter 314  trainloss -1951.59765  validloss -2021.55730±0.00000  bestvalidloss -2062.19247  last_update 2\n",
      "train: iter 315  trainloss -1982.86124  validloss -2054.79362±0.00000  bestvalidloss -2062.19247  last_update 3\n",
      "train: iter 316  trainloss -2006.82185  validloss -2052.24698±0.00000  bestvalidloss -2062.19247  last_update 4\n",
      "train: iter 317  trainloss -1993.98690  validloss -2001.21778±0.00000  bestvalidloss -2062.19247  last_update 5\n",
      "train: iter 318  trainloss -1960.62159  validloss -2027.87731±0.00000  bestvalidloss -2062.19247  last_update 6\n",
      "train: iter 319  trainloss -1968.81931  validloss -2064.51611±0.00000  bestvalidloss -2064.51611  last_update 0\n",
      "train: iter 320  trainloss -1975.28294  validloss -2006.25959±0.00000  bestvalidloss -2064.51611  last_update 1\n",
      "train: iter 321  trainloss -1988.69244  validloss -2073.55571±0.00000  bestvalidloss -2073.55571  last_update 0\n",
      "train: iter 322  trainloss -2004.90523  validloss -2073.15964±0.00000  bestvalidloss -2073.55571  last_update 1\n",
      "train: iter 323  trainloss -1982.23296  validloss -2060.22170±0.00000  bestvalidloss -2073.55571  last_update 2\n",
      "train: iter 324  trainloss -1768.41461  validloss -2049.45621±0.00000  bestvalidloss -2073.55571  last_update 3\n",
      "train: iter 325  trainloss -1690.87946  validloss -1741.80587±0.00000  bestvalidloss -2073.55571  last_update 4\n",
      "train: iter 326  trainloss -1957.38999  validloss -1940.23646±0.00000  bestvalidloss -2073.55571  last_update 5\n",
      "train: iter 327  trainloss -1990.34285  validloss -2046.14370±0.00000  bestvalidloss -2073.55571  last_update 6\n",
      "train: iter 328  trainloss -1921.19892  validloss -2063.86164±0.00000  bestvalidloss -2073.55571  last_update 7\n",
      "train: iter 329  trainloss -1901.15383  validloss -2007.38345±0.00000  bestvalidloss -2073.55571  last_update 8\n",
      "train: iter 330  trainloss -1901.27345  validloss -2008.56480±0.00000  bestvalidloss -2073.55571  last_update 9\n",
      "train: iter 331  trainloss -1977.49679  validloss -2030.74258±0.00000  bestvalidloss -2073.55571  last_update 10\n",
      "train: iter 332  trainloss -2003.67192  validloss -2051.66374±0.00000  bestvalidloss -2073.55571  last_update 11\n",
      "train: iter 333  trainloss -2005.18071  validloss -2066.69778±0.00000  bestvalidloss -2073.55571  last_update 12\n",
      "train: iter 334  trainloss -1995.58972  validloss -2015.16920±0.00000  bestvalidloss -2073.55571  last_update 13\n",
      "train: iter 335  trainloss -2003.90958  validloss -1924.24512±0.00000  bestvalidloss -2073.55571  last_update 14\n",
      "train: iter 336  trainloss -1949.41685  validloss -2035.07986±0.00000  bestvalidloss -2073.55571  last_update 15\n",
      "train: iter 337  trainloss -1950.59806  validloss -1906.68428±0.00000  bestvalidloss -2073.55571  last_update 16\n",
      "train: iter 338  trainloss -1605.64691  validloss -1982.18702±0.00000  bestvalidloss -2073.55571  last_update 17\n",
      "train: iter 339  trainloss -1800.85235  validloss -1869.66631±0.00000  bestvalidloss -2073.55571  last_update 18\n",
      "train: iter 340  trainloss -1970.61254  validloss -2022.32999±0.00000  bestvalidloss -2073.55571  last_update 19\n",
      "train: iter 341  trainloss -1990.52114  validloss -2057.62554±0.00000  bestvalidloss -2073.55571  last_update 20\n",
      "train: iter 342  trainloss -1985.81160  validloss -2072.33024±0.00000  bestvalidloss -2073.55571  last_update 21\n",
      "train: iter 343  trainloss -1990.58639  validloss -2040.05396±0.00000  bestvalidloss -2073.55571  last_update 22\n",
      "train: iter 344  trainloss -1852.04488  validloss -2053.44197±0.00000  bestvalidloss -2073.55571  last_update 23\n",
      "train: iter 345  trainloss -1956.69838  validloss -1991.19119±0.00000  bestvalidloss -2073.55571  last_update 24\n",
      "train: iter 346  trainloss -1994.33878  validloss -2059.45150±0.00000  bestvalidloss -2073.55571  last_update 25\n",
      "train: iter 347  trainloss -2005.81773  validloss -2050.94080±0.00000  bestvalidloss -2073.55571  last_update 26\n",
      "train: iter 348  trainloss -2011.40796  validloss -2032.64089±0.00000  bestvalidloss -2073.55571  last_update 27\n",
      "train: iter 349  trainloss -2018.03374  validloss -1944.40937±0.00000  bestvalidloss -2073.55571  last_update 28\n",
      "train: iter 350  trainloss -2013.81701  validloss -2064.13477±0.00000  bestvalidloss -2073.55571  last_update 29\n",
      "train: iter 351  trainloss -1963.16620  validloss -2074.06799±0.00000  bestvalidloss -2074.06799  last_update 0\n",
      "train: iter 352  trainloss -1960.79135  validloss -2045.81796±0.00000  bestvalidloss -2074.06799  last_update 1\n",
      "train: iter 353  trainloss -1927.27133  validloss -1954.01614±0.00000  bestvalidloss -2074.06799  last_update 2\n",
      "train: iter 354  trainloss -1980.51861  validloss -2002.75169±0.00000  bestvalidloss -2074.06799  last_update 3\n",
      "train: iter 355  trainloss -1983.64272  validloss -2039.72676±0.00000  bestvalidloss -2074.06799  last_update 4\n",
      "train: iter 356  trainloss -2006.82890  validloss -2036.48739±0.00000  bestvalidloss -2074.06799  last_update 5\n",
      "train: iter 357  trainloss -2017.73328  validloss -2045.70735±0.00000  bestvalidloss -2074.06799  last_update 6\n",
      "train: iter 358  trainloss -1979.79128  validloss -2020.48273±0.00000  bestvalidloss -2074.06799  last_update 7\n",
      "train: iter 359  trainloss -1963.50346  validloss -2005.46366±0.00000  bestvalidloss -2074.06799  last_update 8\n",
      "train: iter 360  trainloss -1998.65012  validloss -2000.73915±0.00000  bestvalidloss -2074.06799  last_update 9\n",
      "train: iter 361  trainloss -1803.49426  validloss -1984.91973±0.00000  bestvalidloss -2074.06799  last_update 10\n",
      "train: iter 362  trainloss -1999.03402  validloss -2077.88358±0.00000  bestvalidloss -2077.88358  last_update 0\n",
      "train: iter 363  trainloss -1955.66312  validloss -2027.83715±0.00000  bestvalidloss -2077.88358  last_update 1\n",
      "train: iter 364  trainloss -2023.00438  validloss -2072.28972±0.00000  bestvalidloss -2077.88358  last_update 2\n",
      "train: iter 365  trainloss -2011.32754  validloss -2080.21108±0.00000  bestvalidloss -2080.21108  last_update 0\n",
      "train: iter 366  trainloss -1954.68233  validloss -2062.91766±0.00000  bestvalidloss -2080.21108  last_update 1\n",
      "train: iter 367  trainloss -1980.91320  validloss -1974.70973±0.00000  bestvalidloss -2080.21108  last_update 2\n",
      "train: iter 368  trainloss -1997.20937  validloss -2017.24175±0.00000  bestvalidloss -2080.21108  last_update 3\n",
      "train: iter 369  trainloss -1940.93345  validloss -2022.51118±0.00000  bestvalidloss -2080.21108  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 370  trainloss -1996.22705  validloss -2053.80816±0.00000  bestvalidloss -2080.21108  last_update 5\n",
      "train: iter 371  trainloss -2003.76890  validloss -2050.79020±0.00000  bestvalidloss -2080.21108  last_update 6\n",
      "train: iter 372  trainloss -2031.39247  validloss -2054.59405±0.00000  bestvalidloss -2080.21108  last_update 7\n",
      "train: iter 373  trainloss -2035.44064  validloss -2093.54438±0.00000  bestvalidloss -2093.54438  last_update 0\n",
      "train: iter 374  trainloss -2018.86660  validloss -2028.04357±0.00000  bestvalidloss -2093.54438  last_update 1\n",
      "train: iter 375  trainloss -1907.86697  validloss -2060.19828±0.00000  bestvalidloss -2093.54438  last_update 2\n",
      "train: iter 376  trainloss -1981.20519  validloss -2024.22914±0.00000  bestvalidloss -2093.54438  last_update 3\n",
      "train: iter 377  trainloss -1972.38992  validloss -2051.74603±0.00000  bestvalidloss -2093.54438  last_update 4\n",
      "train: iter 378  trainloss -1983.78382  validloss -2052.52623±0.00000  bestvalidloss -2093.54438  last_update 5\n",
      "train: iter 379  trainloss -1983.30588  validloss -2060.89979±0.00000  bestvalidloss -2093.54438  last_update 6\n",
      "train: iter 380  trainloss -1999.27598  validloss -2055.23598±0.00000  bestvalidloss -2093.54438  last_update 7\n",
      "train: iter 381  trainloss -1999.83046  validloss -2037.68146±0.00000  bestvalidloss -2093.54438  last_update 8\n",
      "train: iter 382  trainloss -1989.88494  validloss -1987.43837±0.00000  bestvalidloss -2093.54438  last_update 9\n",
      "train: iter 383  trainloss -1878.84046  validloss -2039.77226±0.00000  bestvalidloss -2093.54438  last_update 10\n",
      "train: iter 384  trainloss -1945.48755  validloss -1857.10687±0.00000  bestvalidloss -2093.54438  last_update 11\n",
      "train: iter 385  trainloss -2018.47257  validloss -2009.07345±0.00000  bestvalidloss -2093.54438  last_update 12\n",
      "train: iter 386  trainloss -2014.11553  validloss -2016.03745±0.00000  bestvalidloss -2093.54438  last_update 13\n",
      "train: iter 387  trainloss -2018.54749  validloss -2015.11204±0.00000  bestvalidloss -2093.54438  last_update 14\n",
      "train: iter 388  trainloss -1983.81068  validloss -2065.62283±0.00000  bestvalidloss -2093.54438  last_update 15\n",
      "train: iter 389  trainloss -1723.47054  validloss -1996.50146±0.00000  bestvalidloss -2093.54438  last_update 16\n",
      "train: iter 390  trainloss -1978.23445  validloss -1924.42228±0.00000  bestvalidloss -2093.54438  last_update 17\n",
      "train: iter 391  trainloss -2023.19611  validloss -2031.68893±0.00000  bestvalidloss -2093.54438  last_update 18\n",
      "train: iter 392  trainloss -2006.71603  validloss -2085.65829±0.00000  bestvalidloss -2093.54438  last_update 19\n",
      "train: iter 393  trainloss -1977.89490  validloss -2065.38408±0.00000  bestvalidloss -2093.54438  last_update 20\n",
      "train: iter 394  trainloss -1859.24789  validloss -2036.43625±0.00000  bestvalidloss -2093.54438  last_update 21\n",
      "train: iter 395  trainloss -2012.77373  validloss -2062.50447±0.00000  bestvalidloss -2093.54438  last_update 22\n",
      "train: iter 396  trainloss -1983.55144  validloss -2086.86747±0.00000  bestvalidloss -2093.54438  last_update 23\n",
      "train: iter 397  trainloss -2012.54615  validloss -2076.16980±0.00000  bestvalidloss -2093.54438  last_update 24\n",
      "train: iter 398  trainloss -2016.54620  validloss -2043.84042±0.00000  bestvalidloss -2093.54438  last_update 25\n",
      "train: iter 399  trainloss -1845.83491  validloss -2057.66000±0.00000  bestvalidloss -2093.54438  last_update 26\n",
      "train: iter 400  trainloss -1992.77078  validloss -1939.64379±0.00000  bestvalidloss -2093.54438  last_update 27\n",
      "train: iter 401  trainloss -2028.84187  validloss -2082.68186±0.00000  bestvalidloss -2093.54438  last_update 28\n",
      "train: iter 402  trainloss -2020.63139  validloss -1970.62003±0.00000  bestvalidloss -2093.54438  last_update 29\n",
      "train: iter 403  trainloss -1992.40624  validloss -2081.04683±0.00000  bestvalidloss -2093.54438  last_update 30\n",
      "train: iter 404  trainloss -2003.24889  validloss -2085.04208±0.00000  bestvalidloss -2093.54438  last_update 31\n",
      "train: iter 405  trainloss -2035.59772  validloss -2081.50679±0.00000  bestvalidloss -2093.54438  last_update 32\n",
      "train: iter 406  trainloss -1995.59402  validloss -2063.13884±0.00000  bestvalidloss -2093.54438  last_update 33\n",
      "train: iter 407  trainloss -1998.85888  validloss -2019.33498±0.00000  bestvalidloss -2093.54438  last_update 34\n",
      "train: iter 408  trainloss -2031.18843  validloss -2075.74028±0.00000  bestvalidloss -2093.54438  last_update 35\n",
      "train: iter 409  trainloss -2025.14272  validloss -2034.96384±0.00000  bestvalidloss -2093.54438  last_update 36\n",
      "train: iter 410  trainloss -2035.79850  validloss -2091.85905±0.00000  bestvalidloss -2093.54438  last_update 37\n",
      "train: iter 411  trainloss -2018.24093  validloss -2072.60789±0.00000  bestvalidloss -2093.54438  last_update 38\n",
      "train: iter 412  trainloss -2042.55437  validloss -2005.10700±0.00000  bestvalidloss -2093.54438  last_update 39\n",
      "train: iter 413  trainloss -2010.16535  validloss -2057.71771±0.00000  bestvalidloss -2093.54438  last_update 40\n",
      "train: iter 414  trainloss -1987.29551  validloss -2088.93479±0.00000  bestvalidloss -2093.54438  last_update 41\n",
      "train: iter 415  trainloss -1962.49708  validloss -2035.50907±0.00000  bestvalidloss -2093.54438  last_update 42\n",
      "train: iter 416  trainloss -1738.15486  validloss -2079.05548±0.00000  bestvalidloss -2093.54438  last_update 43\n",
      "train: iter 417  trainloss -1999.43067  validloss -2024.47838±0.00000  bestvalidloss -2093.54438  last_update 44\n",
      "train: iter 418  trainloss -2023.34524  validloss -2060.84849±0.00000  bestvalidloss -2093.54438  last_update 45\n",
      "train: iter 419  trainloss -2019.48352  validloss -2061.90685±0.00000  bestvalidloss -2093.54438  last_update 46\n",
      "train: iter 420  trainloss -2022.26788  validloss -2071.78061±0.00000  bestvalidloss -2093.54438  last_update 47\n",
      "train: iter 421  trainloss -1995.25552  validloss -2080.36359±0.00000  bestvalidloss -2093.54438  last_update 48\n",
      "train: iter 422  trainloss -2036.67834  validloss -2065.81498±0.00000  bestvalidloss -2093.54438  last_update 49\n",
      "train: iter 423  trainloss -2033.41666  validloss -2009.96487±0.00000  bestvalidloss -2093.54438  last_update 50\n",
      "train: iter 424  trainloss -2038.96533  validloss -2036.32748±0.00000  bestvalidloss -2093.54438  last_update 51\n",
      "train: iter 425  trainloss -1980.10993  validloss -2036.63348±0.00000  bestvalidloss -2093.54438  last_update 52\n",
      "train: iter 426  trainloss -2024.69514  validloss -2011.54607±0.00000  bestvalidloss -2093.54438  last_update 53\n",
      "train: iter 427  trainloss -1992.80237  validloss -2066.66669±0.00000  bestvalidloss -2093.54438  last_update 54\n",
      "train: iter 428  trainloss -1914.11178  validloss -2067.16649±0.00000  bestvalidloss -2093.54438  last_update 55\n",
      "train: iter 429  trainloss -2027.82046  validloss -2068.41912±0.00000  bestvalidloss -2093.54438  last_update 56\n",
      "train: iter 430  trainloss -2044.46051  validloss -2089.07522±0.00000  bestvalidloss -2093.54438  last_update 57\n",
      "train: iter 431  trainloss -2015.47214  validloss -2025.20079±0.00000  bestvalidloss -2093.54438  last_update 58\n",
      "train: iter 432  trainloss -1911.49376  validloss -2012.85717±0.00000  bestvalidloss -2093.54438  last_update 59\n",
      "train: iter 433  trainloss -1942.82072  validloss -2058.18654±0.00000  bestvalidloss -2093.54438  last_update 60\n",
      "train: iter 434  trainloss -1979.00224  validloss -2062.45263±0.00000  bestvalidloss -2093.54438  last_update 61\n",
      "train: iter 435  trainloss -1975.59484  validloss -2022.51179±0.00000  bestvalidloss -2093.54438  last_update 62\n",
      "train: iter 436  trainloss -2031.87354  validloss -2085.83495±0.00000  bestvalidloss -2093.54438  last_update 63\n",
      "train: iter 437  trainloss -2033.69458  validloss -2081.55558±0.00000  bestvalidloss -2093.54438  last_update 64\n",
      "train: iter 438  trainloss -2008.55757  validloss -2026.93096±0.00000  bestvalidloss -2093.54438  last_update 65\n",
      "train: iter 439  trainloss -2035.85826  validloss -2044.38194±0.00000  bestvalidloss -2093.54438  last_update 66\n",
      "train: iter 440  trainloss -1901.73895  validloss -2080.27271±0.00000  bestvalidloss -2093.54438  last_update 67\n",
      "train: iter 441  trainloss -1968.39374  validloss -2066.04696±0.00000  bestvalidloss -2093.54438  last_update 68\n",
      "train: iter 442  trainloss -2033.38609  validloss -2081.25941±0.00000  bestvalidloss -2093.54438  last_update 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 443  trainloss -2039.11465  validloss -2067.87890±0.00000  bestvalidloss -2093.54438  last_update 70\n",
      "train: iter 444  trainloss -2043.69440  validloss -2078.63268±0.00000  bestvalidloss -2093.54438  last_update 71\n",
      "train: iter 445  trainloss -2042.36400  validloss -2063.48589±0.00000  bestvalidloss -2093.54438  last_update 72\n",
      "train: iter 446  trainloss -1976.07524  validloss -2071.34929±0.00000  bestvalidloss -2093.54438  last_update 73\n",
      "train: iter 447  trainloss -1912.74119  validloss -1963.73262±0.00000  bestvalidloss -2093.54438  last_update 74\n",
      "train: iter 448  trainloss -1998.80153  validloss -1993.78469±0.00000  bestvalidloss -2093.54438  last_update 75\n",
      "train: iter 449  trainloss -2024.92590  validloss -2089.13629±0.00000  bestvalidloss -2093.54438  last_update 76\n",
      "train: iter 450  trainloss -2028.40587  validloss -2071.52069±0.00000  bestvalidloss -2093.54438  last_update 77\n",
      "train: iter 451  trainloss -2020.83161  validloss -2054.07672±0.00000  bestvalidloss -2093.54438  last_update 78\n",
      "train: iter 452  trainloss -1945.54190  validloss -2042.94590±0.00000  bestvalidloss -2093.54438  last_update 79\n",
      "train: iter 453  trainloss -2009.62770  validloss -2074.64289±0.00000  bestvalidloss -2093.54438  last_update 80\n",
      "train: iter 454  trainloss -2027.17129  validloss -2014.38270±0.00000  bestvalidloss -2093.54438  last_update 81\n",
      "train: iter 455  trainloss -2020.71638  validloss -2076.52064±0.00000  bestvalidloss -2093.54438  last_update 82\n",
      "train: iter 456  trainloss -2001.82634  validloss -2024.72366±0.00000  bestvalidloss -2093.54438  last_update 83\n",
      "train: iter 457  trainloss -2059.03390  validloss -2091.11302±0.00000  bestvalidloss -2093.54438  last_update 84\n",
      "train: iter 458  trainloss -2024.46042  validloss -2056.73301±0.00000  bestvalidloss -2093.54438  last_update 85\n",
      "train: iter 459  trainloss -1979.37136  validloss -2052.84134±0.00000  bestvalidloss -2093.54438  last_update 86\n",
      "train: iter 460  trainloss -2042.59042  validloss -2093.00469±0.00000  bestvalidloss -2093.54438  last_update 87\n",
      "train: iter 461  trainloss -2005.43364  validloss -2091.73956±0.00000  bestvalidloss -2093.54438  last_update 88\n",
      "train: iter 462  trainloss -1994.21680  validloss -2037.82592±0.00000  bestvalidloss -2093.54438  last_update 89\n",
      "train: iter 463  trainloss -1915.90518  validloss -2087.28126±0.00000  bestvalidloss -2093.54438  last_update 90\n",
      "train: iter 464  trainloss -1933.57309  validloss -2001.39172±0.00000  bestvalidloss -2093.54438  last_update 91\n",
      "train: iter 465  trainloss -1889.34160  validloss -1996.92856±0.00000  bestvalidloss -2093.54438  last_update 92\n",
      "train: iter 466  trainloss -2025.52124  validloss -2074.57386±0.00000  bestvalidloss -2093.54438  last_update 93\n",
      "train: iter 467  trainloss -2025.47571  validloss -2044.47180±0.00000  bestvalidloss -2093.54438  last_update 94\n",
      "train: iter 468  trainloss -2045.48445  validloss -2076.05333±0.00000  bestvalidloss -2093.54438  last_update 95\n",
      "train: iter 469  trainloss -2042.73760  validloss -2080.04501±0.00000  bestvalidloss -2093.54438  last_update 96\n",
      "train: iter 470  trainloss -2022.16963  validloss -2094.01331±0.00000  bestvalidloss -2094.01331  last_update 0\n",
      "train: iter 471  trainloss -2037.34110  validloss -2062.14244±0.00000  bestvalidloss -2094.01331  last_update 1\n",
      "train: iter 472  trainloss -2072.28595  validloss -2083.36013±0.00000  bestvalidloss -2094.01331  last_update 2\n",
      "train: iter 473  trainloss -2060.60063  validloss -2098.94370±0.00000  bestvalidloss -2098.94370  last_update 0\n",
      "train: iter 474  trainloss -1971.76565  validloss -2061.83997±0.00000  bestvalidloss -2098.94370  last_update 1\n",
      "train: iter 475  trainloss -1825.45247  validloss -2041.00772±0.00000  bestvalidloss -2098.94370  last_update 2\n",
      "train: iter 476  trainloss -2036.24429  validloss -2083.26951±0.00000  bestvalidloss -2098.94370  last_update 3\n",
      "train: iter 477  trainloss -2054.91563  validloss -2093.25508±0.00000  bestvalidloss -2098.94370  last_update 4\n",
      "train: iter 478  trainloss -2064.80852  validloss -2070.68658±0.00000  bestvalidloss -2098.94370  last_update 5\n",
      "train: iter 479  trainloss -2050.86690  validloss -2104.38922±0.00000  bestvalidloss -2104.38922  last_update 0\n",
      "train: iter 480  trainloss -2033.20046  validloss -2064.36265±0.00000  bestvalidloss -2104.38922  last_update 1\n",
      "train: iter 481  trainloss -1990.75319  validloss -1918.39486±0.00000  bestvalidloss -2104.38922  last_update 2\n",
      "train: iter 482  trainloss -2046.14229  validloss -2021.85858±0.00000  bestvalidloss -2104.38922  last_update 3\n",
      "train: iter 483  trainloss -2059.25557  validloss -2091.89229±0.00000  bestvalidloss -2104.38922  last_update 4\n",
      "train: iter 484  trainloss -2054.66996  validloss -2091.80164±0.00000  bestvalidloss -2104.38922  last_update 5\n",
      "train: iter 485  trainloss -1806.47359  validloss -2033.78777±0.00000  bestvalidloss -2104.38922  last_update 6\n",
      "train: iter 486  trainloss -1994.61695  validloss -2035.37651±0.00000  bestvalidloss -2104.38922  last_update 7\n",
      "train: iter 487  trainloss -2057.16484  validloss -2083.06432±0.00000  bestvalidloss -2104.38922  last_update 8\n",
      "train: iter 488  trainloss -2053.98956  validloss -2077.77877±0.00000  bestvalidloss -2104.38922  last_update 9\n",
      "train: iter 489  trainloss -2050.55529  validloss -2053.90806±0.00000  bestvalidloss -2104.38922  last_update 10\n",
      "train: iter 490  trainloss -1994.51806  validloss -2088.80198±0.00000  bestvalidloss -2104.38922  last_update 11\n",
      "train: iter 491  trainloss -2051.91736  validloss -2073.84415±0.00000  bestvalidloss -2104.38922  last_update 12\n",
      "train: iter 492  trainloss -2050.41173  validloss -2075.69529±0.00000  bestvalidloss -2104.38922  last_update 13\n",
      "train: iter 493  trainloss -2012.53184  validloss -2056.77878±0.00000  bestvalidloss -2104.38922  last_update 14\n",
      "train: iter 494  trainloss -1979.63701  validloss -2046.42852±0.00000  bestvalidloss -2104.38922  last_update 15\n",
      "train: iter 495  trainloss -2056.77550  validloss -2083.55358±0.00000  bestvalidloss -2104.38922  last_update 16\n",
      "train: iter 496  trainloss -2050.99213  validloss -2063.64142±0.00000  bestvalidloss -2104.38922  last_update 17\n",
      "train: iter 497  trainloss -2018.07279  validloss -2069.26065±0.00000  bestvalidloss -2104.38922  last_update 18\n",
      "train: iter 498  trainloss -1603.42487  validloss -2070.73835±0.00000  bestvalidloss -2104.38922  last_update 19\n",
      "train: iter 499  trainloss -1939.84178  validloss -2002.63002±0.00000  bestvalidloss -2104.38922  last_update 20\n",
      "train: iter 500  trainloss -2024.67225  validloss -2093.10924±0.00000  bestvalidloss -2104.38922  last_update 21\n",
      "train: iter 501  trainloss -2036.08820  validloss -2071.02116±0.00000  bestvalidloss -2104.38922  last_update 22\n",
      "train: iter 502  trainloss -2042.79325  validloss -2082.38624±0.00000  bestvalidloss -2104.38922  last_update 23\n",
      "train: iter 503  trainloss -2058.67996  validloss -2051.84207±0.00000  bestvalidloss -2104.38922  last_update 24\n",
      "train: iter 504  trainloss -2057.88078  validloss -2073.68555±0.00000  bestvalidloss -2104.38922  last_update 25\n",
      "train: iter 505  trainloss -2059.62576  validloss -2090.48182±0.00000  bestvalidloss -2104.38922  last_update 26\n",
      "train: iter 506  trainloss -2011.86207  validloss -2049.57837±0.00000  bestvalidloss -2104.38922  last_update 27\n",
      "train: iter 507  trainloss -2025.74403  validloss -2053.45575±0.00000  bestvalidloss -2104.38922  last_update 28\n",
      "train: iter 508  trainloss -2005.29324  validloss -2091.27957±0.00000  bestvalidloss -2104.38922  last_update 29\n",
      "train: iter 509  trainloss -1929.80420  validloss -1989.51865±0.00000  bestvalidloss -2104.38922  last_update 30\n",
      "train: iter 510  trainloss -2041.91842  validloss -2086.33697±0.00000  bestvalidloss -2104.38922  last_update 31\n",
      "train: iter 511  trainloss -2062.97963  validloss -2079.28438±0.00000  bestvalidloss -2104.38922  last_update 32\n",
      "train: iter 512  trainloss -2024.44900  validloss -2080.03904±0.00000  bestvalidloss -2104.38922  last_update 33\n",
      "train: iter 513  trainloss -2051.92690  validloss -2078.16077±0.00000  bestvalidloss -2104.38922  last_update 34\n",
      "train: iter 514  trainloss -2047.26120  validloss -2090.57980±0.00000  bestvalidloss -2104.38922  last_update 35\n",
      "train: iter 515  trainloss -2062.75536  validloss -2077.93140±0.00000  bestvalidloss -2104.38922  last_update 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 516  trainloss -2061.55941  validloss -2093.26593±0.00000  bestvalidloss -2104.38922  last_update 37\n",
      "train: iter 517  trainloss -1686.37771  validloss -2048.93240±0.00000  bestvalidloss -2104.38922  last_update 38\n",
      "train: iter 518  trainloss -2001.35028  validloss -2088.09271±0.00000  bestvalidloss -2104.38922  last_update 39\n",
      "train: iter 519  trainloss -2048.07777  validloss -2060.56155±0.00000  bestvalidloss -2104.38922  last_update 40\n",
      "train: iter 520  trainloss -2064.16832  validloss -2088.43002±0.00000  bestvalidloss -2104.38922  last_update 41\n",
      "train: iter 521  trainloss -2062.00483  validloss -2058.73012±0.00000  bestvalidloss -2104.38922  last_update 42\n",
      "train: iter 522  trainloss -1976.01316  validloss -2071.84955±0.00000  bestvalidloss -2104.38922  last_update 43\n",
      "train: iter 523  trainloss -2040.83854  validloss -2070.56884±0.00000  bestvalidloss -2104.38922  last_update 44\n",
      "train: iter 524  trainloss -2060.93139  validloss -2071.67880±0.00000  bestvalidloss -2104.38922  last_update 45\n",
      "train: iter 525  trainloss -2062.91475  validloss -2086.62897±0.00000  bestvalidloss -2104.38922  last_update 46\n",
      "train: iter 526  trainloss -2060.23369  validloss -2066.99321±0.00000  bestvalidloss -2104.38922  last_update 47\n",
      "train: iter 527  trainloss -2057.00260  validloss -2066.05872±0.00000  bestvalidloss -2104.38922  last_update 48\n",
      "train: iter 528  trainloss -2044.42928  validloss -2073.45413±0.00000  bestvalidloss -2104.38922  last_update 49\n",
      "train: iter 529  trainloss -2033.52373  validloss -2037.29967±0.00000  bestvalidloss -2104.38922  last_update 50\n",
      "train: iter 530  trainloss -1944.02596  validloss -2102.61906±0.00000  bestvalidloss -2104.38922  last_update 51\n",
      "train: iter 531  trainloss -2045.18341  validloss -2085.78207±0.00000  bestvalidloss -2104.38922  last_update 52\n",
      "train: iter 532  trainloss -2060.37572  validloss -2092.44698±0.00000  bestvalidloss -2104.38922  last_update 53\n",
      "train: iter 533  trainloss -2067.48988  validloss -2079.92766±0.00000  bestvalidloss -2104.38922  last_update 54\n",
      "train: iter 534  trainloss -2053.39374  validloss -2063.86512±0.00000  bestvalidloss -2104.38922  last_update 55\n",
      "train: iter 535  trainloss -1963.57812  validloss -2067.22368±0.00000  bestvalidloss -2104.38922  last_update 56\n",
      "train: iter 536  trainloss -2025.72902  validloss -2043.29763±0.00000  bestvalidloss -2104.38922  last_update 57\n",
      "train: iter 537  trainloss -2081.68144  validloss -2092.18492±0.00000  bestvalidloss -2104.38922  last_update 58\n",
      "train: iter 538  trainloss -2064.11409  validloss -2084.11161±0.00000  bestvalidloss -2104.38922  last_update 59\n",
      "train: iter 539  trainloss -2001.66441  validloss -2100.58820±0.00000  bestvalidloss -2104.38922  last_update 60\n",
      "train: iter 540  trainloss -2064.35647  validloss -2092.55469±0.00000  bestvalidloss -2104.38922  last_update 61\n",
      "train: iter 541  trainloss -2048.20844  validloss -2085.26494±0.00000  bestvalidloss -2104.38922  last_update 62\n",
      "train: iter 542  trainloss -1934.99683  validloss -2037.75017±0.00000  bestvalidloss -2104.38922  last_update 63\n",
      "train: iter 543  trainloss -2063.77698  validloss -2087.60044±0.00000  bestvalidloss -2104.38922  last_update 64\n",
      "train: iter 544  trainloss -2067.12428  validloss -2086.99834±0.00000  bestvalidloss -2104.38922  last_update 65\n",
      "train: iter 545  trainloss -2055.94023  validloss -2088.62500±0.00000  bestvalidloss -2104.38922  last_update 66\n",
      "train: iter 546  trainloss -2012.63535  validloss -2086.21539±0.00000  bestvalidloss -2104.38922  last_update 67\n",
      "train: iter 547  trainloss -2029.41062  validloss -2069.87696±0.00000  bestvalidloss -2104.38922  last_update 68\n",
      "train: iter 548  trainloss -1997.29654  validloss -2068.68508±0.00000  bestvalidloss -2104.38922  last_update 69\n",
      "train: iter 549  trainloss -2040.93140  validloss -2014.41224±0.00000  bestvalidloss -2104.38922  last_update 70\n",
      "train: iter 550  trainloss -2067.57186  validloss -2053.24412±0.00000  bestvalidloss -2104.38922  last_update 71\n",
      "train: iter 551  trainloss -2058.32010  validloss -2065.94243±0.00000  bestvalidloss -2104.38922  last_update 72\n",
      "train: iter 552  trainloss -1762.13990  validloss -2087.58047±0.00000  bestvalidloss -2104.38922  last_update 73\n",
      "train: iter 553  trainloss -2054.80529  validloss -2095.54887±0.00000  bestvalidloss -2104.38922  last_update 74\n",
      "train: iter 554  trainloss -2067.87911  validloss -2088.21608±0.00000  bestvalidloss -2104.38922  last_update 75\n",
      "train: iter 555  trainloss -2076.52275  validloss -2044.02125±0.00000  bestvalidloss -2104.38922  last_update 76\n",
      "train: iter 556  trainloss -2067.85324  validloss -2112.56038±0.00000  bestvalidloss -2112.56038  last_update 0\n",
      "train: iter 557  trainloss -2022.38096  validloss -2034.18090±0.00000  bestvalidloss -2112.56038  last_update 1\n",
      "train: iter 558  trainloss -2061.46136  validloss -2047.59360±0.00000  bestvalidloss -2112.56038  last_update 2\n",
      "train: iter 559  trainloss -2075.60852  validloss -2102.65281±0.00000  bestvalidloss -2112.56038  last_update 3\n",
      "train: iter 560  trainloss -2067.11186  validloss -2070.40024±0.00000  bestvalidloss -2112.56038  last_update 4\n",
      "train: iter 561  trainloss -2031.62738  validloss -2070.92950±0.00000  bestvalidloss -2112.56038  last_update 5\n",
      "train: iter 562  trainloss -2029.05989  validloss -2061.33934±0.00000  bestvalidloss -2112.56038  last_update 6\n",
      "train: iter 563  trainloss -2053.41529  validloss -2036.07256±0.00000  bestvalidloss -2112.56038  last_update 7\n",
      "train: iter 564  trainloss -2045.95988  validloss -1935.39888±0.00000  bestvalidloss -2112.56038  last_update 8\n",
      "train: iter 565  trainloss -1988.36148  validloss -2085.45079±0.00000  bestvalidloss -2112.56038  last_update 9\n",
      "train: iter 566  trainloss -2046.23903  validloss -2110.47086±0.00000  bestvalidloss -2112.56038  last_update 10\n",
      "train: iter 567  trainloss -2044.04671  validloss -2095.48632±0.00000  bestvalidloss -2112.56038  last_update 11\n",
      "train: iter 568  trainloss -2071.82636  validloss -2091.35703±0.00000  bestvalidloss -2112.56038  last_update 12\n",
      "train: iter 569  trainloss -2063.21134  validloss -2086.62864±0.00000  bestvalidloss -2112.56038  last_update 13\n",
      "train: iter 570  trainloss -2066.08970  validloss -2100.82267±0.00000  bestvalidloss -2112.56038  last_update 14\n",
      "train: iter 571  trainloss -2042.12326  validloss -2078.30391±0.00000  bestvalidloss -2112.56038  last_update 15\n",
      "train: iter 572  trainloss -2001.91174  validloss -2034.49505±0.00000  bestvalidloss -2112.56038  last_update 16\n",
      "train: iter 573  trainloss -2049.16840  validloss -2111.76192±0.00000  bestvalidloss -2112.56038  last_update 17\n",
      "train: iter 574  trainloss -2054.89784  validloss -2051.05175±0.00000  bestvalidloss -2112.56038  last_update 18\n",
      "train: iter 575  trainloss -1954.90312  validloss -2080.15024±0.00000  bestvalidloss -2112.56038  last_update 19\n",
      "train: iter 576  trainloss -2063.65195  validloss -2105.45342±0.00000  bestvalidloss -2112.56038  last_update 20\n",
      "train: iter 577  trainloss -2077.83956  validloss -2099.45920±0.00000  bestvalidloss -2112.56038  last_update 21\n",
      "train: iter 578  trainloss -2092.42973  validloss -2115.06730±0.00000  bestvalidloss -2115.06730  last_update 0\n",
      "train: iter 579  trainloss -1911.86449  validloss -2057.85209±0.00000  bestvalidloss -2115.06730  last_update 1\n",
      "train: iter 580  trainloss -1992.71909  validloss -2103.77319±0.00000  bestvalidloss -2115.06730  last_update 2\n",
      "train: iter 581  trainloss -2024.98893  validloss -2092.58547±0.00000  bestvalidloss -2115.06730  last_update 3\n",
      "train: iter 582  trainloss -1974.04578  validloss -2048.20176±0.00000  bestvalidloss -2115.06730  last_update 4\n",
      "train: iter 583  trainloss -2042.15870  validloss -2014.39940±0.00000  bestvalidloss -2115.06730  last_update 5\n",
      "train: iter 584  trainloss -2042.07219  validloss -2110.27104±0.00000  bestvalidloss -2115.06730  last_update 6\n",
      "train: iter 585  trainloss -2065.59067  validloss -2108.88903±0.00000  bestvalidloss -2115.06730  last_update 7\n",
      "train: iter 586  trainloss -2066.24062  validloss -2108.13820±0.00000  bestvalidloss -2115.06730  last_update 8\n",
      "train: iter 587  trainloss -2040.03398  validloss -2116.28226±0.00000  bestvalidloss -2116.28226  last_update 0\n",
      "train: iter 588  trainloss -2074.31380  validloss -2092.79034±0.00000  bestvalidloss -2116.28226  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 589  trainloss -2078.18987  validloss -2099.59876±0.00000  bestvalidloss -2116.28226  last_update 2\n",
      "train: iter 590  trainloss -2077.28506  validloss -2092.78729±0.00000  bestvalidloss -2116.28226  last_update 3\n",
      "train: iter 591  trainloss -2073.19709  validloss -2100.17595±0.00000  bestvalidloss -2116.28226  last_update 4\n",
      "train: iter 592  trainloss -2070.36600  validloss -2091.84474±0.00000  bestvalidloss -2116.28226  last_update 5\n",
      "train: iter 593  trainloss -2091.15921  validloss -2081.23862±0.00000  bestvalidloss -2116.28226  last_update 6\n",
      "train: iter 594  trainloss -2089.43470  validloss -2081.26072±0.00000  bestvalidloss -2116.28226  last_update 7\n",
      "train: iter 595  trainloss -1800.03160  validloss -2080.72086±0.00000  bestvalidloss -2116.28226  last_update 8\n",
      "train: iter 596  trainloss -2024.18975  validloss -1947.70263±0.00000  bestvalidloss -2116.28226  last_update 9\n",
      "train: iter 597  trainloss -2087.42208  validloss -2114.14131±0.00000  bestvalidloss -2116.28226  last_update 10\n",
      "train: iter 598  trainloss -2090.24267  validloss -2120.52405±0.00000  bestvalidloss -2120.52405  last_update 0\n",
      "train: iter 599  trainloss -2080.98728  validloss -2115.52243±0.00000  bestvalidloss -2120.52405  last_update 1\n",
      "train: iter 600  trainloss -2070.21827  validloss -2067.42999±0.00000  bestvalidloss -2120.52405  last_update 2\n",
      "train: iter 601  trainloss -2093.84212  validloss -2111.70729±0.00000  bestvalidloss -2120.52405  last_update 3\n",
      "train: iter 602  trainloss -2071.00557  validloss -2122.43652±0.00000  bestvalidloss -2122.43652  last_update 0\n",
      "train: iter 603  trainloss -2017.42796  validloss -2090.93669±0.00000  bestvalidloss -2122.43652  last_update 1\n",
      "train: iter 604  trainloss -2005.66192  validloss -2106.19967±0.00000  bestvalidloss -2122.43652  last_update 2\n",
      "train: iter 605  trainloss -2081.62979  validloss -2094.20514±0.00000  bestvalidloss -2122.43652  last_update 3\n",
      "train: iter 606  trainloss -2078.17373  validloss -2098.86197±0.00000  bestvalidloss -2122.43652  last_update 4\n",
      "train: iter 607  trainloss -2085.10532  validloss -2110.11196±0.00000  bestvalidloss -2122.43652  last_update 5\n",
      "train: iter 608  trainloss -2049.76551  validloss -2045.78282±0.00000  bestvalidloss -2122.43652  last_update 6\n",
      "train: iter 609  trainloss -1991.84786  validloss -2101.54347±0.00000  bestvalidloss -2122.43652  last_update 7\n",
      "train: iter 610  trainloss -2061.18683  validloss -2061.35314±0.00000  bestvalidloss -2122.43652  last_update 8\n",
      "train: iter 611  trainloss -1989.35002  validloss -2071.04186±0.00000  bestvalidloss -2122.43652  last_update 9\n",
      "train: iter 612  trainloss -2012.37395  validloss -2073.01926±0.00000  bestvalidloss -2122.43652  last_update 10\n",
      "train: iter 613  trainloss -1994.57660  validloss -2040.26098±0.00000  bestvalidloss -2122.43652  last_update 11\n",
      "train: iter 614  trainloss -2082.87313  validloss -2122.45784±0.00000  bestvalidloss -2122.45784  last_update 0\n",
      "train: iter 615  trainloss -2074.80808  validloss -2093.79199±0.00000  bestvalidloss -2122.45784  last_update 1\n",
      "train: iter 616  trainloss -2084.09173  validloss -2083.05759±0.00000  bestvalidloss -2122.45784  last_update 2\n",
      "train: iter 617  trainloss -2081.33811  validloss -2084.89267±0.00000  bestvalidloss -2122.45784  last_update 3\n",
      "train: iter 618  trainloss -2089.66759  validloss -2103.86596±0.00000  bestvalidloss -2122.45784  last_update 4\n",
      "train: iter 619  trainloss -2048.95807  validloss -2110.05609±0.00000  bestvalidloss -2122.45784  last_update 5\n",
      "train: iter 620  trainloss -2033.14794  validloss -2072.20424±0.00000  bestvalidloss -2122.45784  last_update 6\n",
      "train: iter 621  trainloss -1888.72455  validloss -2098.77128±0.00000  bestvalidloss -2122.45784  last_update 7\n",
      "train: iter 622  trainloss -2039.29447  validloss -2063.87611±0.00000  bestvalidloss -2122.45784  last_update 8\n",
      "train: iter 623  trainloss -2070.90808  validloss -2111.95530±0.00000  bestvalidloss -2122.45784  last_update 9\n",
      "train: iter 624  trainloss -2062.77416  validloss -2092.73110±0.00000  bestvalidloss -2122.45784  last_update 10\n",
      "train: iter 625  trainloss -2077.07439  validloss -2072.40429±0.00000  bestvalidloss -2122.45784  last_update 11\n",
      "train: iter 626  trainloss -2084.61271  validloss -2117.06400±0.00000  bestvalidloss -2122.45784  last_update 12\n",
      "train: iter 627  trainloss -2036.20132  validloss -2114.11218±0.00000  bestvalidloss -2122.45784  last_update 13\n",
      "train: iter 628  trainloss -2085.09391  validloss -2094.25160±0.00000  bestvalidloss -2122.45784  last_update 14\n",
      "train: iter 629  trainloss -2039.75474  validloss -2093.52007±0.00000  bestvalidloss -2122.45784  last_update 15\n",
      "train: iter 630  trainloss -2057.58636  validloss -2083.50169±0.00000  bestvalidloss -2122.45784  last_update 16\n",
      "train: iter 631  trainloss -2069.10963  validloss -2082.07391±0.00000  bestvalidloss -2122.45784  last_update 17\n",
      "train: iter 632  trainloss -2079.90162  validloss -2088.73045±0.00000  bestvalidloss -2122.45784  last_update 18\n",
      "train: iter 633  trainloss -2062.82579  validloss -2097.64808±0.00000  bestvalidloss -2122.45784  last_update 19\n",
      "train: iter 634  trainloss -2084.86050  validloss -2074.94960±0.00000  bestvalidloss -2122.45784  last_update 20\n",
      "train: iter 635  trainloss -2071.06029  validloss -2058.71465±0.00000  bestvalidloss -2122.45784  last_update 21\n",
      "train: iter 636  trainloss -2074.30573  validloss -2099.77886±0.00000  bestvalidloss -2122.45784  last_update 22\n",
      "train: iter 637  trainloss -2087.90500  validloss -2091.00632±0.00000  bestvalidloss -2122.45784  last_update 23\n",
      "train: iter 638  trainloss -1990.40587  validloss -2087.21859±0.00000  bestvalidloss -2122.45784  last_update 24\n",
      "train: iter 639  trainloss -2072.88541  validloss -2074.58073±0.00000  bestvalidloss -2122.45784  last_update 25\n",
      "train: iter 640  trainloss -2069.55113  validloss -2109.02652±0.00000  bestvalidloss -2122.45784  last_update 26\n",
      "train: iter 641  trainloss -2074.85538  validloss -2094.39633±0.00000  bestvalidloss -2122.45784  last_update 27\n",
      "train: iter 642  trainloss -2083.68595  validloss -2079.06599±0.00000  bestvalidloss -2122.45784  last_update 28\n",
      "train: iter 643  trainloss -2083.22875  validloss -2117.61573±0.00000  bestvalidloss -2122.45784  last_update 29\n",
      "train: iter 644  trainloss -2093.20773  validloss -2078.86711±0.00000  bestvalidloss -2122.45784  last_update 30\n",
      "train: iter 645  trainloss -2093.50849  validloss -2104.09854±0.00000  bestvalidloss -2122.45784  last_update 31\n",
      "train: iter 646  trainloss -2089.85251  validloss -2063.65091±0.00000  bestvalidloss -2122.45784  last_update 32\n",
      "train: iter 647  trainloss -1986.81144  validloss -2102.46171±0.00000  bestvalidloss -2122.45784  last_update 33\n",
      "train: iter 648  trainloss -1949.05081  validloss -2057.17741±0.00000  bestvalidloss -2122.45784  last_update 34\n",
      "train: iter 649  trainloss -2071.27349  validloss -2098.94738±0.00000  bestvalidloss -2122.45784  last_update 35\n",
      "train: iter 650  trainloss -2098.94336  validloss -2101.23520±0.00000  bestvalidloss -2122.45784  last_update 36\n",
      "train: iter 651  trainloss -2055.17886  validloss -2086.64045±0.00000  bestvalidloss -2122.45784  last_update 37\n",
      "train: iter 652  trainloss -2090.46252  validloss -2080.43411±0.00000  bestvalidloss -2122.45784  last_update 38\n",
      "train: iter 653  trainloss -2078.45295  validloss -2059.15444±0.00000  bestvalidloss -2122.45784  last_update 39\n",
      "train: iter 654  trainloss -2051.58202  validloss -2121.53245±0.00000  bestvalidloss -2122.45784  last_update 40\n",
      "train: iter 655  trainloss -2093.56669  validloss -2092.41644±0.00000  bestvalidloss -2122.45784  last_update 41\n",
      "train: iter 656  trainloss -2077.02323  validloss -2114.42865±0.00000  bestvalidloss -2122.45784  last_update 42\n",
      "train: iter 657  trainloss -1957.07537  validloss -2075.45302±0.00000  bestvalidloss -2122.45784  last_update 43\n",
      "train: iter 658  trainloss -2005.56534  validloss -2087.98387±0.00000  bestvalidloss -2122.45784  last_update 44\n",
      "train: iter 659  trainloss -2069.12057  validloss -2058.91181±0.00000  bestvalidloss -2122.45784  last_update 45\n",
      "train: iter 660  trainloss -2080.52529  validloss -2123.33641±0.00000  bestvalidloss -2123.33641  last_update 0\n",
      "train: iter 661  trainloss -2099.69804  validloss -2125.64499±0.00000  bestvalidloss -2125.64499  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 662  trainloss -2094.63521  validloss -2098.53530±0.00000  bestvalidloss -2125.64499  last_update 1\n",
      "train: iter 663  trainloss -2086.76602  validloss -2091.95135±0.00000  bestvalidloss -2125.64499  last_update 2\n",
      "train: iter 664  trainloss -2053.93548  validloss -2102.78506±0.00000  bestvalidloss -2125.64499  last_update 3\n",
      "train: iter 665  trainloss -2035.69176  validloss -1923.09496±0.00000  bestvalidloss -2125.64499  last_update 4\n",
      "train: iter 666  trainloss -2094.64770  validloss -2065.96882±0.00000  bestvalidloss -2125.64499  last_update 5\n",
      "train: iter 667  trainloss -2095.70400  validloss -2091.83514±0.00000  bestvalidloss -2125.64499  last_update 6\n",
      "train: iter 668  trainloss -2088.23960  validloss -2081.11942±0.00000  bestvalidloss -2125.64499  last_update 7\n",
      "train: iter 669  trainloss -1994.96795  validloss -2011.31787±0.00000  bestvalidloss -2125.64499  last_update 8\n",
      "train: iter 670  trainloss -2072.25503  validloss -2077.00792±0.00000  bestvalidloss -2125.64499  last_update 9\n",
      "train: iter 671  trainloss -2100.81239  validloss -2103.92401±0.00000  bestvalidloss -2125.64499  last_update 10\n",
      "train: iter 672  trainloss -2092.90213  validloss -2097.31888±0.00000  bestvalidloss -2125.64499  last_update 11\n",
      "train: iter 673  trainloss -2073.95353  validloss -2103.41418±0.00000  bestvalidloss -2125.64499  last_update 12\n",
      "train: iter 674  trainloss -2064.42437  validloss -2006.89744±0.00000  bestvalidloss -2125.64499  last_update 13\n",
      "train: iter 675  trainloss -2107.42056  validloss -2125.04013±0.00000  bestvalidloss -2125.64499  last_update 14\n",
      "train: iter 676  trainloss -2088.93351  validloss -2099.83771±0.00000  bestvalidloss -2125.64499  last_update 15\n",
      "train: iter 677  trainloss -2086.94126  validloss -2092.99454±0.00000  bestvalidloss -2125.64499  last_update 16\n",
      "train: iter 678  trainloss -2058.51190  validloss -2074.48636±0.00000  bestvalidloss -2125.64499  last_update 17\n",
      "train: iter 679  trainloss -2069.54644  validloss -2094.49464±0.00000  bestvalidloss -2125.64499  last_update 18\n",
      "train: iter 680  trainloss -2063.70456  validloss -2109.43005±0.00000  bestvalidloss -2125.64499  last_update 19\n",
      "train: iter 681  trainloss -2078.57064  validloss -2080.94424±0.00000  bestvalidloss -2125.64499  last_update 20\n",
      "train: iter 682  trainloss -2100.98977  validloss -2081.11464±0.00000  bestvalidloss -2125.64499  last_update 21\n",
      "train: iter 683  trainloss -2077.32641  validloss -2099.26511±0.00000  bestvalidloss -2125.64499  last_update 22\n",
      "train: iter 684  trainloss -2080.53699  validloss -2117.19556±0.00000  bestvalidloss -2125.64499  last_update 23\n",
      "train: iter 685  trainloss -2094.18859  validloss -2119.20775±0.00000  bestvalidloss -2125.64499  last_update 24\n",
      "train: iter 686  trainloss -1915.85583  validloss -2076.21611±0.00000  bestvalidloss -2125.64499  last_update 25\n",
      "train: iter 687  trainloss -2080.55707  validloss -2113.01528±0.00000  bestvalidloss -2125.64499  last_update 26\n",
      "train: iter 688  trainloss -2093.84868  validloss -2085.66942±0.00000  bestvalidloss -2125.64499  last_update 27\n",
      "train: iter 689  trainloss -2078.80957  validloss -2101.42990±0.00000  bestvalidloss -2125.64499  last_update 28\n",
      "train: iter 690  trainloss -2067.97738  validloss -2070.47877±0.00000  bestvalidloss -2125.64499  last_update 29\n",
      "train: iter 691  trainloss -2084.53770  validloss -2107.00540±0.00000  bestvalidloss -2125.64499  last_update 30\n",
      "train: iter 692  trainloss -2091.65830  validloss -2084.02640±0.00000  bestvalidloss -2125.64499  last_update 31\n",
      "train: iter 693  trainloss -2047.49076  validloss -2098.74553±0.00000  bestvalidloss -2125.64499  last_update 32\n",
      "train: iter 694  trainloss -2076.84920  validloss -2116.34711±0.00000  bestvalidloss -2125.64499  last_update 33\n",
      "train: iter 695  trainloss -2074.64185  validloss -2017.57608±0.00000  bestvalidloss -2125.64499  last_update 34\n",
      "train: iter 696  trainloss -2041.62723  validloss -2116.42323±0.00000  bestvalidloss -2125.64499  last_update 35\n",
      "train: iter 697  trainloss -2090.25219  validloss -2093.33307±0.00000  bestvalidloss -2125.64499  last_update 36\n",
      "train: iter 698  trainloss -2094.70738  validloss -2102.66418±0.00000  bestvalidloss -2125.64499  last_update 37\n",
      "train: iter 699  trainloss -2097.34100  validloss -2082.22252±0.00000  bestvalidloss -2125.64499  last_update 38\n",
      "train: iter 700  trainloss -1697.86688  validloss -2107.71928±0.00000  bestvalidloss -2125.64499  last_update 39\n",
      "train: iter 701  trainloss -1994.11079  validloss -1832.62045±0.00000  bestvalidloss -2125.64499  last_update 40\n",
      "train: iter 702  trainloss -2056.68701  validloss -2097.66770±0.00000  bestvalidloss -2125.64499  last_update 41\n",
      "train: iter 703  trainloss -2081.40960  validloss -2122.44333±0.00000  bestvalidloss -2125.64499  last_update 42\n",
      "train: iter 704  trainloss -2070.09842  validloss -2101.83862±0.00000  bestvalidloss -2125.64499  last_update 43\n",
      "train: iter 705  trainloss -2034.88587  validloss -2113.99139±0.00000  bestvalidloss -2125.64499  last_update 44\n",
      "train: iter 706  trainloss -2081.20329  validloss -2075.77286±0.00000  bestvalidloss -2125.64499  last_update 45\n",
      "train: iter 707  trainloss -2083.96266  validloss -2127.85073±0.00000  bestvalidloss -2127.85073  last_update 0\n",
      "train: iter 708  trainloss -2100.75265  validloss -2078.94293±0.00000  bestvalidloss -2127.85073  last_update 1\n",
      "train: iter 709  trainloss -2088.18442  validloss -2114.60995±0.00000  bestvalidloss -2127.85073  last_update 2\n",
      "train: iter 710  trainloss -2085.70435  validloss -2116.45613±0.00000  bestvalidloss -2127.85073  last_update 3\n",
      "train: iter 711  trainloss -2108.32959  validloss -2124.22973±0.00000  bestvalidloss -2127.85073  last_update 4\n",
      "train: iter 712  trainloss -2095.71392  validloss -2098.96421±0.00000  bestvalidloss -2127.85073  last_update 5\n",
      "train: iter 713  trainloss -2083.78709  validloss -2128.85678±0.00000  bestvalidloss -2128.85678  last_update 0\n",
      "train: iter 714  trainloss -2099.78036  validloss -2114.15896±0.00000  bestvalidloss -2128.85678  last_update 1\n",
      "train: iter 715  trainloss -2107.12063  validloss -2097.56364±0.00000  bestvalidloss -2128.85678  last_update 2\n",
      "train: iter 716  trainloss -2108.46776  validloss -2113.29319±0.00000  bestvalidloss -2128.85678  last_update 3\n",
      "train: iter 717  trainloss -2102.21118  validloss -2086.43492±0.00000  bestvalidloss -2128.85678  last_update 4\n",
      "train: iter 718  trainloss -2039.12872  validloss -2068.24211±0.00000  bestvalidloss -2128.85678  last_update 5\n",
      "train: iter 719  trainloss -2086.34728  validloss -2104.82786±0.00000  bestvalidloss -2128.85678  last_update 6\n",
      "train: iter 720  trainloss -2098.48659  validloss -2102.05182±0.00000  bestvalidloss -2128.85678  last_update 7\n",
      "train: iter 721  trainloss -2088.09453  validloss -2062.98328±0.00000  bestvalidloss -2128.85678  last_update 8\n",
      "train: iter 722  trainloss -2075.50503  validloss -2085.44455±0.00000  bestvalidloss -2128.85678  last_update 9\n",
      "train: iter 723  trainloss -2096.92970  validloss -2119.10201±0.00000  bestvalidloss -2128.85678  last_update 10\n",
      "train: iter 724  trainloss -2070.52639  validloss -2092.32230±0.00000  bestvalidloss -2128.85678  last_update 11\n",
      "train: iter 725  trainloss -2066.33450  validloss -2056.15381±0.00000  bestvalidloss -2128.85678  last_update 12\n",
      "train: iter 726  trainloss -2088.69458  validloss -2021.87764±0.00000  bestvalidloss -2128.85678  last_update 13\n",
      "train: iter 727  trainloss -2092.09844  validloss -2110.27615±0.00000  bestvalidloss -2128.85678  last_update 14\n",
      "train: iter 728  trainloss -2089.59217  validloss -2060.83646±0.00000  bestvalidloss -2128.85678  last_update 15\n",
      "train: iter 729  trainloss -2064.70148  validloss -2114.88881±0.00000  bestvalidloss -2128.85678  last_update 16\n",
      "train: iter 730  trainloss -2091.64783  validloss -2097.85033±0.00000  bestvalidloss -2128.85678  last_update 17\n",
      "train: iter 731  trainloss -2012.32364  validloss -2047.00212±0.00000  bestvalidloss -2128.85678  last_update 18\n",
      "train: iter 732  trainloss -2059.00746  validloss -2079.80837±0.00000  bestvalidloss -2128.85678  last_update 19\n",
      "train: iter 733  trainloss -2051.45081  validloss -2091.10204±0.00000  bestvalidloss -2128.85678  last_update 20\n",
      "train: iter 734  trainloss -2093.11515  validloss -2098.98912±0.00000  bestvalidloss -2128.85678  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 735  trainloss -2040.78595  validloss -2067.59678±0.00000  bestvalidloss -2128.85678  last_update 22\n",
      "train: iter 736  trainloss -2037.29284  validloss -2105.23049±0.00000  bestvalidloss -2128.85678  last_update 23\n",
      "train: iter 737  trainloss -2094.28459  validloss -2085.62334±0.00000  bestvalidloss -2128.85678  last_update 24\n",
      "train: iter 738  trainloss -2099.47308  validloss -2110.63500±0.00000  bestvalidloss -2128.85678  last_update 25\n",
      "train: iter 739  trainloss -2092.30985  validloss -2101.57786±0.00000  bestvalidloss -2128.85678  last_update 26\n",
      "train: iter 740  trainloss -2091.02879  validloss -2098.47957±0.00000  bestvalidloss -2128.85678  last_update 27\n",
      "train: iter 741  trainloss -2098.37393  validloss -2078.98825±0.00000  bestvalidloss -2128.85678  last_update 28\n",
      "train: iter 742  trainloss -2104.96068  validloss -2094.90161±0.00000  bestvalidloss -2128.85678  last_update 29\n",
      "train: iter 743  trainloss -2009.88430  validloss -2079.43606±0.00000  bestvalidloss -2128.85678  last_update 30\n",
      "train: iter 744  trainloss -2092.17133  validloss -2114.22308±0.00000  bestvalidloss -2128.85678  last_update 31\n",
      "train: iter 745  trainloss -2095.59522  validloss -2119.58519±0.00000  bestvalidloss -2128.85678  last_update 32\n",
      "train: iter 746  trainloss -2095.10113  validloss -2105.79169±0.00000  bestvalidloss -2128.85678  last_update 33\n",
      "train: iter 747  trainloss -2049.27845  validloss -2063.12839±0.00000  bestvalidloss -2128.85678  last_update 34\n",
      "train: iter 748  trainloss -2099.16383  validloss -2135.62789±0.00000  bestvalidloss -2135.62789  last_update 0\n",
      "train: iter 749  trainloss -2090.55040  validloss -2082.61918±0.00000  bestvalidloss -2135.62789  last_update 1\n",
      "train: iter 750  trainloss -2097.18796  validloss -2124.39187±0.00000  bestvalidloss -2135.62789  last_update 2\n",
      "train: iter 751  trainloss -2087.51591  validloss -2122.84673±0.00000  bestvalidloss -2135.62789  last_update 3\n",
      "train: iter 752  trainloss -2022.96795  validloss -2081.73282±0.00000  bestvalidloss -2135.62789  last_update 4\n",
      "train: iter 753  trainloss -2100.68139  validloss -2096.42601±0.00000  bestvalidloss -2135.62789  last_update 5\n",
      "train: iter 754  trainloss -2082.41096  validloss -2100.44257±0.00000  bestvalidloss -2135.62789  last_update 6\n",
      "train: iter 755  trainloss -2025.58240  validloss -2119.63027±0.00000  bestvalidloss -2135.62789  last_update 7\n",
      "train: iter 756  trainloss -2071.35166  validloss -2036.88497±0.00000  bestvalidloss -2135.62789  last_update 8\n",
      "train: iter 757  trainloss -2092.22318  validloss -2119.42033±0.00000  bestvalidloss -2135.62789  last_update 9\n",
      "train: iter 758  trainloss -2119.00741  validloss -2084.14772±0.00000  bestvalidloss -2135.62789  last_update 10\n",
      "train: iter 759  trainloss -2077.51020  validloss -2085.40402±0.00000  bestvalidloss -2135.62789  last_update 11\n",
      "train: iter 760  trainloss -2048.55176  validloss -2091.12883±0.00000  bestvalidloss -2135.62789  last_update 12\n",
      "train: iter 761  trainloss -1954.52260  validloss -2099.38726±0.00000  bestvalidloss -2135.62789  last_update 13\n",
      "train: iter 762  trainloss -1971.38473  validloss -2067.44572±0.00000  bestvalidloss -2135.62789  last_update 14\n",
      "train: iter 763  trainloss -2086.02126  validloss -2110.95034±0.00000  bestvalidloss -2135.62789  last_update 15\n",
      "train: iter 764  trainloss -2087.94153  validloss -2115.04110±0.00000  bestvalidloss -2135.62789  last_update 16\n",
      "train: iter 765  trainloss -2054.13594  validloss -2088.03793±0.00000  bestvalidloss -2135.62789  last_update 17\n",
      "train: iter 766  trainloss -2105.11325  validloss -2123.86700±0.00000  bestvalidloss -2135.62789  last_update 18\n",
      "train: iter 767  trainloss -2109.99040  validloss -2100.53036±0.00000  bestvalidloss -2135.62789  last_update 19\n",
      "train: iter 768  trainloss -2094.79336  validloss -2118.55059±0.00000  bestvalidloss -2135.62789  last_update 20\n",
      "train: iter 769  trainloss -2092.10287  validloss -2111.80797±0.00000  bestvalidloss -2135.62789  last_update 21\n",
      "train: iter 770  trainloss -2082.89054  validloss -2098.78318±0.00000  bestvalidloss -2135.62789  last_update 22\n",
      "train: iter 771  trainloss -2078.96273  validloss -2129.07360±0.00000  bestvalidloss -2135.62789  last_update 23\n",
      "train: iter 772  trainloss -2097.08738  validloss -2074.66917±0.00000  bestvalidloss -2135.62789  last_update 24\n",
      "train: iter 773  trainloss -2025.40516  validloss -2078.50460±0.00000  bestvalidloss -2135.62789  last_update 25\n",
      "train: iter 774  trainloss -2057.58924  validloss -2087.66867±0.00000  bestvalidloss -2135.62789  last_update 26\n",
      "train: iter 775  trainloss -2082.69993  validloss -2116.97625±0.00000  bestvalidloss -2135.62789  last_update 27\n",
      "train: iter 776  trainloss -2090.30326  validloss -2104.90522±0.00000  bestvalidloss -2135.62789  last_update 28\n",
      "train: iter 777  trainloss -2107.52941  validloss -2117.41262±0.00000  bestvalidloss -2135.62789  last_update 29\n",
      "train: iter 778  trainloss -2105.84424  validloss -2091.12069±0.00000  bestvalidloss -2135.62789  last_update 30\n",
      "train: iter 779  trainloss -2086.40204  validloss -2083.08986±0.00000  bestvalidloss -2135.62789  last_update 31\n",
      "train: iter 780  trainloss -2040.07941  validloss -2114.49056±0.00000  bestvalidloss -2135.62789  last_update 32\n",
      "train: iter 781  trainloss -2062.85844  validloss -2033.09669±0.00000  bestvalidloss -2135.62789  last_update 33\n",
      "train: iter 782  trainloss -2099.45228  validloss -2118.99522±0.00000  bestvalidloss -2135.62789  last_update 34\n",
      "train: iter 783  trainloss -2088.04895  validloss -2121.41902±0.00000  bestvalidloss -2135.62789  last_update 35\n",
      "train: iter 784  trainloss -2110.32290  validloss -2111.67926±0.00000  bestvalidloss -2135.62789  last_update 36\n",
      "train: iter 785  trainloss -2099.93029  validloss -2082.78397±0.00000  bestvalidloss -2135.62789  last_update 37\n",
      "train: iter 786  trainloss -2123.35645  validloss -2109.50807±0.00000  bestvalidloss -2135.62789  last_update 38\n",
      "train: iter 787  trainloss -2117.81934  validloss -2117.65615±0.00000  bestvalidloss -2135.62789  last_update 39\n",
      "train: iter 788  trainloss -2118.67656  validloss -2087.88672±0.00000  bestvalidloss -2135.62789  last_update 40\n",
      "train: iter 789  trainloss -2100.59657  validloss -2098.25538±0.00000  bestvalidloss -2135.62789  last_update 41\n",
      "train: iter 790  trainloss -2003.02241  validloss -2073.06998±0.00000  bestvalidloss -2135.62789  last_update 42\n",
      "train: iter 791  trainloss -2064.34814  validloss -2076.99195±0.00000  bestvalidloss -2135.62789  last_update 43\n",
      "train: iter 792  trainloss -2034.98418  validloss -2084.40977±0.00000  bestvalidloss -2135.62789  last_update 44\n",
      "train: iter 793  trainloss -2107.30065  validloss -2055.81517±0.00000  bestvalidloss -2135.62789  last_update 45\n",
      "train: iter 794  trainloss -2073.37693  validloss -2034.41256±0.00000  bestvalidloss -2135.62789  last_update 46\n",
      "train: iter 795  trainloss -2110.87171  validloss -2121.95128±0.00000  bestvalidloss -2135.62789  last_update 47\n",
      "train: iter 796  trainloss -2114.55406  validloss -2114.99738±0.00000  bestvalidloss -2135.62789  last_update 48\n",
      "train: iter 797  trainloss -2071.40850  validloss -2072.84349±0.00000  bestvalidloss -2135.62789  last_update 49\n",
      "train: iter 798  trainloss -2023.70856  validloss -2032.67231±0.00000  bestvalidloss -2135.62789  last_update 50\n",
      "train: iter 799  trainloss -2083.92042  validloss -2097.96987±0.00000  bestvalidloss -2135.62789  last_update 51\n",
      "train: iter 800  trainloss -2095.59606  validloss -2077.69940±0.00000  bestvalidloss -2135.62789  last_update 52\n",
      "train: iter 801  trainloss -2102.04659  validloss -2087.64713±0.00000  bestvalidloss -2135.62789  last_update 53\n",
      "train: iter 802  trainloss -2062.85526  validloss -2069.65848±0.00000  bestvalidloss -2135.62789  last_update 54\n",
      "train: iter 803  trainloss -2097.42724  validloss -2115.01369±0.00000  bestvalidloss -2135.62789  last_update 55\n",
      "train: iter 804  trainloss -2088.26551  validloss -2107.76530±0.00000  bestvalidloss -2135.62789  last_update 56\n",
      "train: iter 805  trainloss -1941.20499  validloss -2071.77857±0.00000  bestvalidloss -2135.62789  last_update 57\n",
      "train: iter 806  trainloss -2080.24896  validloss -2057.49526±0.00000  bestvalidloss -2135.62789  last_update 58\n",
      "train: iter 807  trainloss -2091.46667  validloss -2111.00740±0.00000  bestvalidloss -2135.62789  last_update 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 808  trainloss -2094.97014  validloss -2104.18567±0.00000  bestvalidloss -2135.62789  last_update 60\n",
      "train: iter 809  trainloss -2101.18009  validloss -2130.21417±0.00000  bestvalidloss -2135.62789  last_update 61\n",
      "train: iter 810  trainloss -2102.23355  validloss -2090.38761±0.00000  bestvalidloss -2135.62789  last_update 62\n",
      "train: iter 811  trainloss -2113.12505  validloss -2093.77168±0.00000  bestvalidloss -2135.62789  last_update 63\n",
      "train: iter 812  trainloss -2079.69305  validloss -2089.98038±0.00000  bestvalidloss -2135.62789  last_update 64\n",
      "train: iter 813  trainloss -2075.78825  validloss -2099.45126±0.00000  bestvalidloss -2135.62789  last_update 65\n",
      "train: iter 814  trainloss -2112.99835  validloss -2113.54659±0.00000  bestvalidloss -2135.62789  last_update 66\n",
      "train: iter 815  trainloss -2108.37203  validloss -2121.91878±0.00000  bestvalidloss -2135.62789  last_update 67\n",
      "train: iter 816  trainloss -2120.17955  validloss -2138.89581±0.00000  bestvalidloss -2138.89581  last_update 0\n",
      "train: iter 817  trainloss -2095.86203  validloss -2116.28524±0.00000  bestvalidloss -2138.89581  last_update 1\n",
      "train: iter 818  trainloss -2087.56880  validloss -2111.78895±0.00000  bestvalidloss -2138.89581  last_update 2\n",
      "train: iter 819  trainloss -2102.12131  validloss -2115.85350±0.00000  bestvalidloss -2138.89581  last_update 3\n",
      "train: iter 820  trainloss -2103.52668  validloss -2103.37552±0.00000  bestvalidloss -2138.89581  last_update 4\n",
      "train: iter 821  trainloss -2013.27580  validloss -2131.03033±0.00000  bestvalidloss -2138.89581  last_update 5\n",
      "train: iter 822  trainloss -2097.44650  validloss -2109.46531±0.00000  bestvalidloss -2138.89581  last_update 6\n",
      "train: iter 823  trainloss -2115.75507  validloss -2125.45038±0.00000  bestvalidloss -2138.89581  last_update 7\n",
      "train: iter 824  trainloss -2098.52856  validloss -2119.82917±0.00000  bestvalidloss -2138.89581  last_update 8\n",
      "train: iter 825  trainloss -2052.22058  validloss -2090.55081±0.00000  bestvalidloss -2138.89581  last_update 9\n",
      "train: iter 826  trainloss -2013.78381  validloss -2137.99252±0.00000  bestvalidloss -2138.89581  last_update 10\n",
      "train: iter 827  trainloss -2092.42982  validloss -2096.54665±0.00000  bestvalidloss -2138.89581  last_update 11\n",
      "train: iter 828  trainloss -2114.12415  validloss -2081.12889±0.00000  bestvalidloss -2138.89581  last_update 12\n",
      "train: iter 829  trainloss -2120.54757  validloss -2107.05597±0.00000  bestvalidloss -2138.89581  last_update 13\n",
      "train: iter 830  trainloss -2081.82059  validloss -2106.94855±0.00000  bestvalidloss -2138.89581  last_update 14\n",
      "train: iter 831  trainloss -2087.55413  validloss -2124.40177±0.00000  bestvalidloss -2138.89581  last_update 15\n",
      "train: iter 832  trainloss -2073.38028  validloss -2055.41752±0.00000  bestvalidloss -2138.89581  last_update 16\n",
      "train: iter 833  trainloss -2095.39060  validloss -2026.79551±0.00000  bestvalidloss -2138.89581  last_update 17\n",
      "train: iter 834  trainloss -2117.58763  validloss -2099.95724±0.00000  bestvalidloss -2138.89581  last_update 18\n",
      "train: iter 835  trainloss -1920.06321  validloss -2109.17126±0.00000  bestvalidloss -2138.89581  last_update 19\n",
      "train: iter 836  trainloss -2080.93872  validloss -2104.96261±0.00000  bestvalidloss -2138.89581  last_update 20\n",
      "train: iter 837  trainloss -2111.38234  validloss -2111.72010±0.00000  bestvalidloss -2138.89581  last_update 21\n",
      "train: iter 838  trainloss -2118.61785  validloss -2130.89990±0.00000  bestvalidloss -2138.89581  last_update 22\n",
      "train: iter 839  trainloss -2099.39649  validloss -2101.12997±0.00000  bestvalidloss -2138.89581  last_update 23\n",
      "train: iter 840  trainloss -2101.50261  validloss -2126.59853±0.00000  bestvalidloss -2138.89581  last_update 24\n",
      "train: iter 841  trainloss -2118.50451  validloss -2089.48439±0.00000  bestvalidloss -2138.89581  last_update 25\n",
      "train: iter 842  trainloss -2101.80152  validloss -2113.99499±0.00000  bestvalidloss -2138.89581  last_update 26\n",
      "train: iter 843  trainloss -2071.50201  validloss -2079.34683±0.00000  bestvalidloss -2138.89581  last_update 27\n",
      "train: iter 844  trainloss -2115.87965  validloss -2104.39200±0.00000  bestvalidloss -2138.89581  last_update 28\n",
      "train: iter 845  trainloss -2096.65363  validloss -2068.29689±0.00000  bestvalidloss -2138.89581  last_update 29\n",
      "train: iter 846  trainloss -2112.67659  validloss -2093.86064±0.00000  bestvalidloss -2138.89581  last_update 30\n",
      "train: iter 847  trainloss -2103.87202  validloss -2099.85764±0.00000  bestvalidloss -2138.89581  last_update 31\n",
      "train: iter 848  trainloss -2072.31637  validloss -2087.51771±0.00000  bestvalidloss -2138.89581  last_update 32\n",
      "train: iter 849  trainloss -2015.91256  validloss -2096.34827±0.00000  bestvalidloss -2138.89581  last_update 33\n",
      "train: iter 850  trainloss -2017.00621  validloss -2124.14905±0.00000  bestvalidloss -2138.89581  last_update 34\n",
      "train: iter 851  trainloss -2033.31107  validloss -2123.55104±0.00000  bestvalidloss -2138.89581  last_update 35\n",
      "train: iter 852  trainloss -2119.23398  validloss -2123.29710±0.00000  bestvalidloss -2138.89581  last_update 36\n",
      "train: iter 853  trainloss -2120.09315  validloss -2082.38458±0.00000  bestvalidloss -2138.89581  last_update 37\n",
      "train: iter 854  trainloss -2099.54562  validloss -2128.09421±0.00000  bestvalidloss -2138.89581  last_update 38\n",
      "train: iter 855  trainloss -2088.44374  validloss -2130.16683±0.00000  bestvalidloss -2138.89581  last_update 39\n",
      "train: iter 856  trainloss -2105.20201  validloss -2092.85383±0.00000  bestvalidloss -2138.89581  last_update 40\n",
      "train: iter 857  trainloss -2130.01494  validloss -2125.19088±0.00000  bestvalidloss -2138.89581  last_update 41\n",
      "train: iter 858  trainloss -2122.33873  validloss -2120.39151±0.00000  bestvalidloss -2138.89581  last_update 42\n",
      "train: iter 859  trainloss -2105.82724  validloss -2140.04488±0.00000  bestvalidloss -2140.04488  last_update 0\n",
      "train: iter 860  trainloss -2029.98906  validloss -2116.26567±0.00000  bestvalidloss -2140.04488  last_update 1\n",
      "train: iter 861  trainloss -2102.96596  validloss -2102.90555±0.00000  bestvalidloss -2140.04488  last_update 2\n",
      "train: iter 862  trainloss -2109.97008  validloss -2110.55262±0.00000  bestvalidloss -2140.04488  last_update 3\n",
      "train: iter 863  trainloss -2095.96134  validloss -2102.42496±0.00000  bestvalidloss -2140.04488  last_update 4\n",
      "train: iter 864  trainloss -2105.86345  validloss -2091.81690±0.00000  bestvalidloss -2140.04488  last_update 5\n",
      "train: iter 865  trainloss -2099.43698  validloss -2097.94570±0.00000  bestvalidloss -2140.04488  last_update 6\n",
      "train: iter 866  trainloss -2106.40301  validloss -2115.82489±0.00000  bestvalidloss -2140.04488  last_update 7\n",
      "train: iter 867  trainloss -2094.86902  validloss -2118.17491±0.00000  bestvalidloss -2140.04488  last_update 8\n",
      "train: iter 868  trainloss -2103.72766  validloss -2081.37750±0.00000  bestvalidloss -2140.04488  last_update 9\n",
      "train: iter 869  trainloss -2116.03205  validloss -2120.89881±0.00000  bestvalidloss -2140.04488  last_update 10\n",
      "train: iter 870  trainloss -2098.85297  validloss -2113.54157±0.00000  bestvalidloss -2140.04488  last_update 11\n",
      "train: iter 871  trainloss -2091.93247  validloss -2108.20049±0.00000  bestvalidloss -2140.04488  last_update 12\n",
      "train: iter 872  trainloss -2068.65014  validloss -2069.28356±0.00000  bestvalidloss -2140.04488  last_update 13\n",
      "train: iter 873  trainloss -2048.29420  validloss -2116.89434±0.00000  bestvalidloss -2140.04488  last_update 14\n",
      "train: iter 874  trainloss -2088.71988  validloss -2118.00358±0.00000  bestvalidloss -2140.04488  last_update 15\n",
      "train: iter 875  trainloss -2099.87013  validloss -2129.40533±0.00000  bestvalidloss -2140.04488  last_update 16\n",
      "train: iter 876  trainloss -2081.28959  validloss -2081.44079±0.00000  bestvalidloss -2140.04488  last_update 17\n",
      "train: iter 877  trainloss -2110.10934  validloss -2036.28943±0.00000  bestvalidloss -2140.04488  last_update 18\n",
      "train: iter 878  trainloss -2039.74685  validloss -2068.27853±0.00000  bestvalidloss -2140.04488  last_update 19\n",
      "train: iter 879  trainloss -2083.73367  validloss -2085.60441±0.00000  bestvalidloss -2140.04488  last_update 20\n",
      "train: iter 880  trainloss -2127.32465  validloss -2139.61644±0.00000  bestvalidloss -2140.04488  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 881  trainloss -2125.50855  validloss -2128.12390±0.00000  bestvalidloss -2140.04488  last_update 22\n",
      "train: iter 882  trainloss -2112.70942  validloss -2111.82482±0.00000  bestvalidloss -2140.04488  last_update 23\n",
      "train: iter 883  trainloss -2113.83391  validloss -2096.31194±0.00000  bestvalidloss -2140.04488  last_update 24\n",
      "train: iter 884  trainloss -2105.26844  validloss -2121.72858±0.00000  bestvalidloss -2140.04488  last_update 25\n",
      "train: iter 885  trainloss -1964.21701  validloss -2085.40393±0.00000  bestvalidloss -2140.04488  last_update 26\n",
      "train: iter 886  trainloss -1940.52804  validloss -2049.06138±0.00000  bestvalidloss -2140.04488  last_update 27\n",
      "train: iter 887  trainloss -2105.18904  validloss -2098.90793±0.00000  bestvalidloss -2140.04488  last_update 28\n",
      "train: iter 888  trainloss -2119.17393  validloss -2115.05120±0.00000  bestvalidloss -2140.04488  last_update 29\n",
      "train: iter 889  trainloss -2106.82269  validloss -2114.33781±0.00000  bestvalidloss -2140.04488  last_update 30\n",
      "train: iter 890  trainloss -2134.95977  validloss -2074.13073±0.00000  bestvalidloss -2140.04488  last_update 31\n",
      "train: iter 891  trainloss -2119.98663  validloss -2083.53708±0.00000  bestvalidloss -2140.04488  last_update 32\n",
      "train: iter 892  trainloss -2122.42559  validloss -2106.79052±0.00000  bestvalidloss -2140.04488  last_update 33\n",
      "train: iter 893  trainloss -2117.04173  validloss -2082.53330±0.00000  bestvalidloss -2140.04488  last_update 34\n",
      "train: iter 894  trainloss -1809.62095  validloss -2119.14611±0.00000  bestvalidloss -2140.04488  last_update 35\n",
      "train: iter 895  trainloss -2072.22866  validloss -2070.45581±0.00000  bestvalidloss -2140.04488  last_update 36\n",
      "train: iter 896  trainloss -2106.97666  validloss -2110.45058±0.00000  bestvalidloss -2140.04488  last_update 37\n",
      "train: iter 897  trainloss -2127.71794  validloss -2092.38815±0.00000  bestvalidloss -2140.04488  last_update 38\n",
      "train: iter 898  trainloss -2126.04709  validloss -2114.83434±0.00000  bestvalidloss -2140.04488  last_update 39\n",
      "train: iter 899  trainloss -2107.55932  validloss -2098.89667±0.00000  bestvalidloss -2140.04488  last_update 40\n",
      "train: iter 900  trainloss -2081.26101  validloss -2107.62465±0.00000  bestvalidloss -2140.04488  last_update 41\n",
      "train: iter 901  trainloss -2033.60154  validloss -2026.74211±0.00000  bestvalidloss -2140.04488  last_update 42\n",
      "train: iter 902  trainloss -2108.07776  validloss -2087.25892±0.00000  bestvalidloss -2140.04488  last_update 43\n",
      "train: iter 903  trainloss -2109.65017  validloss -2102.73020±0.00000  bestvalidloss -2140.04488  last_update 44\n",
      "train: iter 904  trainloss -2108.22705  validloss -2107.29431±0.00000  bestvalidloss -2140.04488  last_update 45\n",
      "train: iter 905  trainloss -2123.79979  validloss -2133.41326±0.00000  bestvalidloss -2140.04488  last_update 46\n",
      "train: iter 906  trainloss -2133.67609  validloss -2115.16321±0.00000  bestvalidloss -2140.04488  last_update 47\n",
      "train: iter 907  trainloss -2013.82421  validloss -2101.44039±0.00000  bestvalidloss -2140.04488  last_update 48\n",
      "train: iter 908  trainloss -2120.86531  validloss -2085.87736±0.00000  bestvalidloss -2140.04488  last_update 49\n",
      "train: iter 909  trainloss -2112.73915  validloss -2113.73532±0.00000  bestvalidloss -2140.04488  last_update 50\n",
      "train: iter 910  trainloss -2097.67291  validloss -2093.56349±0.00000  bestvalidloss -2140.04488  last_update 51\n",
      "train: iter 911  trainloss -2125.29586  validloss -2091.12888±0.00000  bestvalidloss -2140.04488  last_update 52\n",
      "train: iter 912  trainloss -2085.23313  validloss -2115.50302±0.00000  bestvalidloss -2140.04488  last_update 53\n",
      "train: iter 913  trainloss -2070.68580  validloss -2053.28200±0.00000  bestvalidloss -2140.04488  last_update 54\n",
      "train: iter 914  trainloss -2116.52058  validloss -2110.08387±0.00000  bestvalidloss -2140.04488  last_update 55\n",
      "train: iter 915  trainloss -2129.75483  validloss -2099.19122±0.00000  bestvalidloss -2140.04488  last_update 56\n",
      "train: iter 916  trainloss -2126.91315  validloss -2125.02444±0.00000  bestvalidloss -2140.04488  last_update 57\n",
      "train: iter 917  trainloss -2126.89927  validloss -2105.04222±0.00000  bestvalidloss -2140.04488  last_update 58\n",
      "train: iter 918  trainloss -2119.29770  validloss -2084.18492±0.00000  bestvalidloss -2140.04488  last_update 59\n",
      "train: iter 919  trainloss -2131.44669  validloss -2095.45029±0.00000  bestvalidloss -2140.04488  last_update 60\n",
      "train: iter 920  trainloss -2104.59557  validloss -2078.82042±0.00000  bestvalidloss -2140.04488  last_update 61\n",
      "train: iter 921  trainloss -1993.70833  validloss -2103.17760±0.00000  bestvalidloss -2140.04488  last_update 62\n",
      "train: iter 922  trainloss -2034.02054  validloss -1866.67411±0.00000  bestvalidloss -2140.04488  last_update 63\n",
      "train: iter 923  trainloss -2032.70355  validloss -2113.22689±0.00000  bestvalidloss -2140.04488  last_update 64\n",
      "train: iter 924  trainloss -2112.52505  validloss -2129.02242±0.00000  bestvalidloss -2140.04488  last_update 65\n",
      "train: iter 925  trainloss -2097.14646  validloss -2087.39891±0.00000  bestvalidloss -2140.04488  last_update 66\n",
      "train: iter 926  trainloss -2128.68617  validloss -2125.70035±0.00000  bestvalidloss -2140.04488  last_update 67\n",
      "train: iter 927  trainloss -2121.26421  validloss -2115.14067±0.00000  bestvalidloss -2140.04488  last_update 68\n",
      "train: iter 928  trainloss -2119.36896  validloss -2127.36935±0.00000  bestvalidloss -2140.04488  last_update 69\n",
      "train: iter 929  trainloss -2092.38749  validloss -2108.26210±0.00000  bestvalidloss -2140.04488  last_update 70\n",
      "train: iter 930  trainloss -2122.32690  validloss -2114.39497±0.00000  bestvalidloss -2140.04488  last_update 71\n",
      "train: iter 931  trainloss -2092.51073  validloss -2045.87310±0.00000  bestvalidloss -2140.04488  last_update 72\n",
      "train: iter 932  trainloss -2102.27159  validloss -2067.49813±0.00000  bestvalidloss -2140.04488  last_update 73\n",
      "train: iter 933  trainloss -2090.56111  validloss -2008.25873±0.00000  bestvalidloss -2140.04488  last_update 74\n",
      "train: iter 934  trainloss -2112.11989  validloss -2115.15903±0.00000  bestvalidloss -2140.04488  last_update 75\n",
      "train: iter 935  trainloss -2093.99987  validloss -2104.87151±0.00000  bestvalidloss -2140.04488  last_update 76\n",
      "train: iter 936  trainloss -2120.60439  validloss -2111.53545±0.00000  bestvalidloss -2140.04488  last_update 77\n",
      "train: iter 937  trainloss -2140.26478  validloss -2103.90980±0.00000  bestvalidloss -2140.04488  last_update 78\n",
      "train: iter 938  trainloss -2102.53951  validloss -2103.21774±0.00000  bestvalidloss -2140.04488  last_update 79\n",
      "train: iter 939  trainloss -2097.61086  validloss -2097.84114±0.00000  bestvalidloss -2140.04488  last_update 80\n",
      "train: iter 940  trainloss -1945.54986  validloss -2113.62704±0.00000  bestvalidloss -2140.04488  last_update 81\n",
      "train: iter 941  trainloss -2093.30914  validloss -2116.97958±0.00000  bestvalidloss -2140.04488  last_update 82\n",
      "train: iter 942  trainloss -2124.72458  validloss -2134.21346±0.00000  bestvalidloss -2140.04488  last_update 83\n",
      "train: iter 943  trainloss -2119.11188  validloss -2122.78339±0.00000  bestvalidloss -2140.04488  last_update 84\n",
      "train: iter 944  trainloss -2100.22395  validloss -2106.34321±0.00000  bestvalidloss -2140.04488  last_update 85\n",
      "train: iter 945  trainloss -2122.22067  validloss -2113.21427±0.00000  bestvalidloss -2140.04488  last_update 86\n",
      "train: iter 946  trainloss -2116.62079  validloss -2107.33607±0.00000  bestvalidloss -2140.04488  last_update 87\n",
      "train: iter 947  trainloss -2123.52531  validloss -2125.40068±0.00000  bestvalidloss -2140.04488  last_update 88\n",
      "train: iter 948  trainloss -2078.91695  validloss -2074.55273±0.00000  bestvalidloss -2140.04488  last_update 89\n",
      "train: iter 949  trainloss -2085.65082  validloss -2102.35045±0.00000  bestvalidloss -2140.04488  last_update 90\n",
      "train: iter 950  trainloss -2102.94172  validloss -2108.71938±0.00000  bestvalidloss -2140.04488  last_update 91\n",
      "train: iter 951  trainloss -2082.51345  validloss -2133.95867±0.00000  bestvalidloss -2140.04488  last_update 92\n",
      "train: iter 952  trainloss -2092.80722  validloss -2106.86011±0.00000  bestvalidloss -2140.04488  last_update 93\n",
      "train: iter 953  trainloss -2115.17653  validloss -2092.89235±0.00000  bestvalidloss -2140.04488  last_update 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 954  trainloss -2116.92310  validloss -2109.71790±0.00000  bestvalidloss -2140.04488  last_update 95\n",
      "train: iter 955  trainloss -2087.38473  validloss -1989.54214±0.00000  bestvalidloss -2140.04488  last_update 96\n",
      "train: iter 956  trainloss -2097.50447  validloss -2088.26605±0.00000  bestvalidloss -2140.04488  last_update 97\n",
      "train: iter 957  trainloss -2086.87168  validloss -2114.17910±0.00000  bestvalidloss -2140.04488  last_update 98\n",
      "train: iter 958  trainloss -2101.69726  validloss -2105.63621±0.00000  bestvalidloss -2140.04488  last_update 99\n",
      "train: iter 959  trainloss -2109.78395  validloss -2127.97667±0.00000  bestvalidloss -2140.04488  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3235) penalty_target_max tensor(0.6550)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAGhCAYAAACeSJtFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAByaklEQVR4nO3dd3wT9f8H8Ndltoy2zBZkFVGGIAoI1j0qRdGvuAdfRUX9qqAyHOAAHAiCIqgo4sKBIvJTRJbUsqVsyp4yWkZboLTpzLr7/XFNctdcOqBJeuX1fDz6oLlcksu15F59f973OUGSJAlERERE5McQ7g0gIiIiqqkYlIiIiIgCYFAiIiIiCoBBiYiIiCgABiUiIiKiABiUiIiIiAJgUCIiIiIKgEGJiIiIKAAGJSIiIqIAGJSIiIiIAghqUFq5ciXuuOMONG/eHIIgYO7cuar7JUnCqFGj0KxZM0RGRiIxMRH79+9XrZOTk4P+/fsjKioKMTExGDhwIAoKClTrbNu2Dddeey0iIiLQsmVLTJgwIZhvi4iIiM4TQQ1KhYWF6Nq1K6ZOnap5/4QJE/Dxxx9j2rRpWLduHerWrYukpCSUlJR41+nfvz927tyJ5ORkzJ8/HytXrsTTTz/tvd9ms6F3795o3bo1Nm3ahIkTJ2LMmDGYPn16MN8aERERnQeEUF0UVxAE/P777+jXrx8AuZrUvHlzDB8+HC+99BIAIC8vD7GxsZgxYwYefPBB7N69G506dcKGDRvQo0cPAMDixYtx22234ejRo2jevDk+//xzvP7668jMzITFYgEAjBgxAnPnzsWePXsqtW2iKOL48eOoX78+BEGo/jdPRERE1U6SJOTn56N58+YwGIJT+zEF5Vkr4dChQ8jMzERiYqJ3WXR0NHr16oXU1FQ8+OCDSE1NRUxMjDckAUBiYiIMBgPWrVuHu+66C6mpqbjuuuu8IQkAkpKS8P777+PMmTNo0KCB32vb7XbY7Xbv7WPHjqFTp05BeqdEREQUTBkZGWjRokVQnjtsQSkzMxMAEBsbq1oeGxvrvS8zMxNNmzZV3W8ymdCwYUPVOvHx8X7P4blPKyiNGzcOb731lt/yjIwMREVFneU7IiIiolCy2Wxo2bIl6tevH7TXCFtQCqeRI0di2LBh3tueHR0VFcWgREREpDPBbJsJ2/QAcXFxAICsrCzV8qysLO99cXFxyM7OVt3vcrmQk5OjWkfrOZSvUZbVavWGIoYjIiIiCiRsQSk+Ph5xcXFISUnxLrPZbFi3bh0SEhIAAAkJCcjNzcWmTZu86yxduhSiKKJXr17edVauXAmn0+ldJzk5Ge3bt9ccdiMiIiKqrKAGpYKCAqSlpSEtLQ2A3MCdlpaG9PR0CIKAIUOG4N1338W8efOwfft2PProo2jevLn3zLiOHTuiT58+eOqpp7B+/Xr8888/GDx4MB588EE0b94cAPDwww/DYrFg4MCB2LlzJ3755RdMmTJFNbRGREREdFakIFq2bJkEwO9rwIABkiRJkiiK0ptvvinFxsZKVqtVuvnmm6W9e/eqnuP06dPSQw89JNWrV0+KioqSHn/8cSk/P1+1ztatW6VrrrlGslqt0gUXXCCNHz++StuZl5cnAZDy8vLO6f0SERFR6ITi+B2yeZRqMpvNhujoaOTl5bFfiYiISCdCcfzmtd6IiIiIAmBQIiIiIgqAQYmIiIgoAAYlIiIiogAYlIiIiIgCYFAiIiIiCoBBiYiIiCgABqVgcjuBRSOARa8CzpJwbw0RERFVEYNSMEkisO5zYN00wG0P99YQERFRFTEoBZOg2L2cAJ2IiEh3GJSCSRWUxPBtBxEREZ0VBqVgYkWJiIhI1xiUgkkQfN+zokRERKQ7DEpBVxqWGJSIiIh0h0Ep2DzDbwxKREREusOgFGzePiX2KBEREekNg1KwsaJERESkWwxKwcagREREpFsMSsHGoERERKRbDErBJvCsNyIiIr1iUAo2b0WJzdxERER6w6AUbN6KEoMSERGR3jAoBRt7lIiIiHSLQSnYGJSIiIh0i0Ep6NjMTUREpFcMSsHGihIREZFuMSgFG4MSERGRbjEoBRuv9UZERKRbDErBxooSERGRbjEoBRuDEhERkW4xKAVb6UlvnHCSiIhIfxiUgo0VJSIiIt1iUAo2BiUiIiLdYlAKNl4Ul4iISLcYlIKNFSUiIiLdYlAKNgYlIiIi3WJQCjpe642IiEivGJSCjRUlIiIi3WJQCjYGJSIiIt1iUAo2wTP0xrPeiIiI9IZBKdh4UVwiIiLdYlAKNoHN3ERERHrFoBRETreI43kO+XuXK8xbQ0RERFXFoBREoiQhM98OgEGJiIhIjxiUgsgoCBBLd7Ho5tAbERGR3oQ9KI0ZMwaCIKi+OnTo4L2/pKQEgwYNQqNGjVCvXj3cc889yMrKUj1Heno6+vbtizp16qBp06Z4+eWX4aoBFRyjQYBYOuGkKLnDvDVERERUVaZwbwAAXHLJJfj777+9t00m32YNHToUCxYswK+//oro6GgMHjwYd999N/755x8AgNvtRt++fREXF4c1a9bgxIkTePTRR2E2m/Hee++F/L0oCYIAqTQoSSLPeiMiItKbGhGUTCYT4uLi/Jbn5eXh66+/xk8//YSbbroJAPDtt9+iY8eOWLt2La688kosWbIEu3btwt9//43Y2FhcdtlleOedd/Dqq69izJgxsFgsoX47ZchByS2yokRERKQ3YR96A4D9+/ejefPmaNu2Lfr374/09HQAwKZNm+B0OpGYmOhdt0OHDmjVqhVSU1MBAKmpqejSpQtiY2O96yQlJcFms2Hnzp2ar2e322Gz2VRfwSJ5epRE9igRERHpTdiDUq9evTBjxgwsXrwYn3/+OQ4dOoRrr70W+fn5yMzMhMViQUxMjOoxsbGxyMzMBABkZmaqQpLnfs99WsaNG4fo6GjvV8uWLav/jZWSBM/QGytKREREehP2obdbb73V+/2ll16KXr16oXXr1pg9ezYiIyOD8pojR47EsGHDvLdtNlvQwpIksKJERESkV2GvKJUVExODiy++GAcOHEBcXBwcDgdyc3NV62RlZXl7muLi4vzOgvPc1up7AgCr1YqoqCjVV7D4mrkZlIiIiPSmxgWlgoIC/Pvvv2jWrBm6d+8Os9mMlJQU7/179+5Feno6EhISAAAJCQnYvn07srOzveskJycjKioKnTp1Cvn2+/FUlHgJEyIiIt0J+9DbSy+9hDvuuAOtW7fG8ePHMXr0aBiNRjz00EOIjo7GwIEDMWzYMDRs2BBRUVF4/vnnkZCQgCuvvBIA0Lt3b3Tq1AmPPPIIJkyYgMzMTLzxxhsYNGgQrFZrmN+dr6LECSeJiIj0J+xB6ejRo3jooYdw+vRpNGnSBNdccw3Wrl2LJk2aAAA++ugjGAwG3HPPPbDb7UhKSsJnn33mfbzRaMT8+fPx7LPPIiEhAXXr1sWAAQPw9ttvh+stqQkGQAIkTjhJRESkO4IkSef9TIg2mw3R0dHIy8ur9n6lVW8n4lpxA9KvHodWtzxXrc9NRER0Pgvm8dujxvUo1To8642IiEi3GJSCzDPhJOdRIiIi0h8GpWDzTDjJEU4iIiLdYVAKttKgJLKiREREpDsMSkHmG3pjjxIREZHeMCgFm4FBiYiISK8YlILMW1HizNxERES6w6AUbALPeiMiItIrBqUgEzzN3DzrjYiISHcYlILMc6039igRERHpD4NSsJUOvYE9SkRERLrDoBRs3kuYsEeJiIhIbxiUgo0VJSIiIt1iUAo271lvbOYmIiLSGwalIBO813pjRYmIiEhvGJSCTeDM3ERERHrFoBRs7FEiIiLSLQalYPNUlCSe9UZERKQ3DErB5qkoceiNiIhIdxiUgs3gGXpjRYmIiEhvGJSCTBJM8jeccJKIiEh3GJSCjRUlIiIi3WJQCrbSipIgusK8IURERFRVDEpBJhk49EZERKRXDErBVnrWm8ChNyIiIt1hUAoyT0WJQYmIiEh/GJSCzWCU/2VQIiIi0h0GpSDzTA9gYFAiIiLSHQalYPP0KLGZm4iISHcYlIKNPUpERES6xaAUZFJpjxKDEhERkf4wKAWZwKBERESkWwxKQeZp5mZQIiIi0h8GpWArrSjxrDciIiL9YVAKMsHbzC2GeUuIiIioqhiUgs3AeZSIiIj0ikEp2DzzKIFBiYiISG8YlILNyIoSERGRXjEoBZnAZm4iIiLdYlAKNjZzExER6RaDUpB5K0rsUSIiItIdBqUgk3jWGxERkW4xKAWZwKBERESkWwxKQWYweobe2KNERESkNwxKQcahNyIiIv2qVUFp6tSpaNOmDSIiItCrVy+sX78+3JsEgycosZmbiIhId2pNUPrll18wbNgwjB49Gps3b0bXrl2RlJSE7OzssG6X4Bl64/QAREREulNrgtKkSZPw1FNP4fHHH0enTp0wbdo01KlTB9988014N6x0egAjK0pERES6UyuCksPhwKZNm5CYmOhdZjAYkJiYiNTUVL/17XY7bDab6itYDAaz/C+buYmIiHSnVgSlU6dOwe12IzY2VrU8NjYWmZmZfuuPGzcO0dHR3q+WLVsGbdt8Q2+sKBEREelNrQhKVTVy5Ejk5eV5vzIyMoL2Wr6ZuVlRIiIi0htTuDegOjRu3BhGoxFZWVmq5VlZWYiLi/Nb32q1wmq1hmTbBKM89MYeJSIiIv2pFRUli8WC7t27IyUlxbtMFEWkpKQgISEhjFumrChJgMiqEhERkZ7UiooSAAwbNgwDBgxAjx490LNnT0yePBmFhYV4/PHHw7pdQmkzNwBAcqOWZFMiIqLzQq0JSg888ABOnjyJUaNGITMzE5dddhkWL17s1+Adap5LmAAARBdgNAdemYiIiGqUWhOUAGDw4MEYPHhwuDdDxWBU7GKRfUpERER6wnGgIBNUQckVvg0hIiKiKmNQCjLPtd4AALyMCRERka4wKAWZwVCmR4mIiIh0g0EpyAxGAS6pdDczKBEREekKg1KQGQQBbpRWldjMTUREpCsMSkFmNAhwgRUlIiIiPWJQCjK5olS6m9nMTUREpCsMSkFmEKAYemNFiYiISE8YlILMaFBUlNijREREpCsMSkGmGnpjRYmIiEhXGJSCzGBgUCIiItIrBqUgMwoC3FJpjxKbuYmIiHSFQSnIDAI4PQAREZFOMSgFmcEgQCzdzRKDEhERka4wKAWZ2WCAq3R6ALeLQYmIiEhPGJSCzGzyVZTcbgYlIiIiPWFQCjKTweDtUXI5nWHeGiIiIqoKBqUgMxt90wO43QxKREREesKgFGSCIEAs7VESOfRGRESkKwxKIeAW5KDkcjIoERER6QmDUghInooSpwcgIiLSFQalEBAFeTeLLvYoERER6QmDUghInqE39igRERHpCoNSCIilQUliUCIiItIVBqUQ8FSURE4PQEREpCsMSiEgeoOSO8xbQkRERFXBoBQCvooSh96IiIj0hEEpFBiUiIiIdIlBKQREA4MSERGRHjEohQJ7lIiIiHSJQSkUSitKEHnWGxERkZ4wKIWAJJgAsKJERESkNwxKoeCZcJLXeiMiItIVBqUQkAycmZuIiEiPGJRCQDDIQ2+SyKE3IiIiPWFQCgVvMzcrSkRERHrCoBQK3h4lVpSIiIj0hEEpFIyeoTdWlIiIiPSEQSkEPD1KHHojIiLSFwalUBA8PUoceiMiItITBqVQMHoqSgxKREREesKgFAIGAytKREREesSgFAKCp6IksUeJiIhITxiUQkBgRYmIiEiXGJRCwHPWm8CgREREpCthDUpt2rSBIAiqr/Hjx6vW2bZtG6699lpERESgZcuWmDBhgt/z/Prrr+jQoQMiIiLQpUsXLFy4MFRvoVI8Q28Ch96IiIh0JewVpbfffhsnTpzwfj3//PPe+2w2G3r37o3WrVtj06ZNmDhxIsaMGYPp06d711mzZg0eeughDBw4EFu2bEG/fv3Qr18/7NixIxxvR5PB26PEihIREZGemMK9AfXr10dcXJzmfTNnzoTD4cA333wDi8WCSy65BGlpaZg0aRKefvppAMCUKVPQp08fvPzyywCAd955B8nJyfj0008xbdq0kL2P8niCEofeiIiI9CXsFaXx48ejUaNGuPzyyzFx4kS4XL7hqdTUVFx33XWwWCzeZUlJSdi7dy/OnDnjXScxMVH1nElJSUhNTQ34mna7HTabTfUVTN4eJVaUiIiIdCWsFaUXXngB3bp1Q8OGDbFmzRqMHDkSJ06cwKRJkwAAmZmZiI+PVz0mNjbWe1+DBg2QmZnpXaZcJzMzM+Drjhs3Dm+99VY1v5vADCYGJSIiIj2q9orSiBEj/Bq0y37t2bMHADBs2DDccMMNuPTSS/HMM8/gww8/xCeffAK73V7dm6UycuRI5OXleb8yMjKC+nrG0ukBBEkM6usQERFR9ar2itLw4cPx2GOPlbtO27ZtNZf36tULLpcLhw8fRvv27REXF4esrCzVOp7bnr6mQOsE6nsCAKvVCqvVWtFbqTaCyQwAMLCiREREpCvVHpSaNGmCJk2anNVj09LSYDAY0LRpUwBAQkICXn/9dTidTpjNcthITk5G+/bt0aBBA+86KSkpGDJkiPd5kpOTkZCQcG5vpBoZOD0AERGRLoWtmTs1NRWTJ0/G1q1bcfDgQcycORNDhw7Ff//7X28Ievjhh2GxWDBw4EDs3LkTv/zyC6ZMmYJhw4Z5n+fFF1/E4sWL8eGHH2LPnj0YM2YMNm7ciMGDB4frrfkxlgYlA4feiIiIdCVszdxWqxWzZs3CmDFjYLfbER8fj6FDh6pCUHR0NJYsWYJBgwahe/fuaNy4MUaNGuWdGgAArrrqKvz0009444038Nprr+Giiy7C3Llz0blz53C8LU2eipIBHHojIiLSE0GSJCncGxFuNpsN0dHRyMvLQ1RUVLU//77UBbj4r4dxUGiJtqNrzkSYREREehbs4zdQA+ZROh8YS6cHMIJDb0RERHrCoBQCxtKz3jiPEhERkb4wKIWA0STPo2RkjxIREZGuMCiFgMkkX4KF8ygRERHpC4NSCFgtpRNOQgR754mIiPSDQSkEPBf1NUKE3cWGbiIiIr1gUAoBa+ms4kaIKHFy+I2IiEgvGJRCwBxZHwBQF8UoKQnuBX+JiIio+jAohUL95iiUImAR3HCd+jfcW0NERESVxKAUCgYDDgot5e+zdoZ3W4iIiKjSGJRC5KSxCQBAKswO85YQERFRZTEohYjbYJX/dZSEeUuIiIioshiUQkQ0yFMEMCgRERHpB4NSiIhGuaIkOhmUiIiI9IJBKUQkT1BycXoAIiIivWBQChHJJAcliRUlIiIi3WBQChFPRQkuBiUiIiK9YFAKEcHkCUoceiMiItILBqUQEUwR8jduBiUiIiK9YFAKFbMclARWlIiIiHSDQSlEjGZ56E1wO8K8JURERFRZDEohYrDIFSWjyIoSERGRXjAohYixdOjNwB4lIiIi3WBQChGjt6LEoTciIiK9YFAKEZMlEgBglBiUiIiI9IJBKUQ8QcnEihIREZFuMCiFiKV06M0kucK8JURERFRZDEohYomQpwcwSs4wbwkRERFVFoNSiJitpRUlsKJERESkFwxKIVInQu5RMnPojYiISDcYlEIkwhOU4ILoFsO8NURERFQZDEohUidSDkoGQUKJk2e+ERER6QGDUohElPYoAUBhUXEYt4SIiIgqi0EpRAylF8UFgOISBiUiIiI9YFAKFYPJ+20xK0pERES6wKAUKoIAB+SwVGJnUCIiItIDBqUQcsEMACguZlAiIiLSAwalEHILckXJXmIP85YQERFRZTAohZDbUFpRYjM3ERGRLjAohZBYGpQKOfRGRESkCwxKISQZLACAIgYlIiIiXWBQCiUjm7mJiIj0hEEplIxyRamkpCTMG0JERESVwaAUQoKpNChxHiUiIiJdYFAKIaNJvoyJnRUlIiIiXQhaUBo7diyuuuoq1KlTBzExMZrrpKeno2/fvqhTpw6aNm2Kl19+GS6XS7XO8uXL0a1bN1itVrRr1w4zZszwe56pU6eiTZs2iIiIQK9evbB+/fogvKNzZyitKIlOBiUiIiI9CFpQcjgcuO+++/Dss89q3u92u9G3b184HA6sWbMG3333HWbMmIFRo0Z51zl06BD69u2LG2+8EWlpaRgyZAiefPJJ/PXXX951fvnlFwwbNgyjR4/G5s2b0bVrVyQlJSE7OztYb+2sCda68r8uDr0RERHpgSBJkhTMF5gxYwaGDBmC3Nxc1fJFixbh9ttvx/HjxxEbGwsAmDZtGl599VWcPHkSFosFr776KhYsWIAdO3Z4H/fggw8iNzcXixcvBgD06tULV1xxBT799FMAgCiKaNmyJZ5//nmMGDGiUttos9kQHR2NvLw8REVFVcO71lb882OI3Ps7xroewWvvfAJBEIL2WkRERLVdKI7fYetRSk1NRZcuXbwhCQCSkpJgs9mwc+dO7zqJiYmqxyUlJSE1NRWAXLXatGmTah2DwYDExETvOlrsdjtsNpvqKxSMEfUAAFapBHaXGJLXJCIiorMXtqCUmZmpCkkAvLczMzPLXcdms6G4uBinTp2C2+3WXMfzHFrGjRuH6Oho71fLli2r4y1VyBxRHwBQVyhBfomrgrWJiIgo3KoUlEaMGAFBEMr92rNnT7C2tdqMHDkSeXl53q+MjIyQvK6nRykSdhTaGZSIiIhqOlNVVh4+fDgee+yxctdp27ZtpZ4rLi7O7+y0rKws732efz3LlOtERUUhMjISRqMRRqNRcx3Pc2ixWq2wWq2V2s5qZZGDUl2UoIBBiYiIqMarUlBq0qQJmjRpUi0vnJCQgLFjxyI7OxtNmzYFACQnJyMqKgqdOnXyrrNw4ULV45KTk5GQkAAAsFgs6N69O1JSUtCvXz8AcjN3SkoKBg8eXC3bWa3MclCqw6E3IiIiXQhaj1J6ejrS0tKQnp4Ot9uNtLQ0pKWloaCgAADQu3dvdOrUCY888gi2bt2Kv/76C2+88QYGDRrkrfY888wzOHjwIF555RXs2bMHn332GWbPno2hQ4d6X2fYsGH48ssv8d1332H37t149tlnUVhYiMcffzxYb+3slVaU6sCOTBunCCAiIqrpqlRRqopRo0bhu+++896+/PLLAQDLli3DDTfcAKPRiPnz5+PZZ59FQkIC6tatiwEDBuDtt9/2PiY+Ph4LFizA0KFDMWXKFLRo0QJfffUVkpKSvOs88MADOHnyJEaNGoXMzExcdtllWLx4sV+Dd41gqQMAqCPYsea4DXddHubtISIionIFfR4lPQjVPErYnwzMvBfbxTaY0Ho6fhjYK3ivRUREVMvV6nmUzkvm0ooS7Dhd4AjzxhAREVFFGJRCydOjJNiRb3eGeWOIiIioIgxKoWSRZ+auC571RkREpAcMSqHkaeZGCfJLnGB7GBERUc3GoBRKpUNvJkGEUXSi2OkO8wYRERFReRiUQql0wkkAGGP6DvlF9jBuDBEREVWEQSmUjCbAKE+m+bBpKUq2/BLmDSIiIqLyMCiFmsl3jbklKcnIK+bZb0RERDUVg1Ko2W3eb5sIudh9wlbOykRERBRODEph1F7IgBDujSAiIqKAGJRC7eI+3m/bCcdRXMKL4xIREdVUDEqhdtc0oP8ciDDALLghnDkc7i2i6uRyALv+AIpywr0lRERUDRiUQi2yAXDRLcg1NgQAOEsKw7xBVK1WvA/MfhT4pk/F6xIRUY3HoBQmbsEMAHDZOfRWq+z8Tf731N7wbgcREVULBqUwcRssAACnoyTMW0JERESBMCiFiWiUg9L8LUfgFiX8e7KA134jIiKqYRiUwsQz9Ha9ey2uHJeCmz9cgR/XHgnzVhEREZESg1KYFLqNAORLmZjyjwMApqTsD+cmERERURkMSmEiGEze75sIuQAAo4HTTxIREdUkDEph0rqB75pvzQR5zh2T4Tz9cRTlAE6e/UdERDXPeXpkDr8Io+/7LywfwQoHjuUWn38N3UU5wIR44MMO4d4SIiIiPwxK4SK6VDejUAQAmJt2LBxbEz4Z6+V/S3LDuhlERERaGJTCpUxQAuRK0terD4V+W4iIiEgTg1K4iG7VTTPk2wbhPGvoPt/eLxER6QqDUriUqSiZBfn2eReUiIiIajAGpXCR1BUlCzxBKRwbE0bnW/M6ERHpCoNSuJSpKHmCksCKEhERUY3BoBQuZYfeAlWUbMeBFROAgpPaz+MsBg4uB1yO6t/GUGAwJCKiGoxBKVyiW6pu+oJSmeDww93AsrHAnMe1n2fus8D3dwJL3gjGVgZfbRt6q23vh4joPMegFC79PlPdtAhOAIDDLaonnTy5W/738Crt59n5u/zv+i+qewuJiIjOewxK4dKgDaC43tvDxhREogRb0nMRP3Ihkndl4cjpwvBtXzjUhmoMhxKJiGoVU8WrUNBIovfbvsb1OCPVxxuugQCAp77fCAA4HBGWLQsPSWLQICKiGoUVpXAqU0G53bg2TBtSQyiCo278PQbY8HW4t4KIiIKEFaWwUgelGKEQJrjgOm9/LDobejueBqz+SP7+ioFh3RQiIgoOVpRqmCeMiwLfuehVYMdvoduYUNNbRakkL9xbQEREQcagFE43j/ZbdJtxXeD1100LPE1AbaC3oKSlNjSkExGRF4NSOF0zFIi7VLXo/B12g/5CBhvPiYhqPQalcBIEILazapFTOp+Dks4qSlrBjuGJiKhWYVAKN6NZddMJY5g2pAbQW1AiIqJaj0Ep3ExW1c2e5n8x1DQHJrgCPKA209nQGxER1XoMSuFmjlTdjBCL8KLpN9xtDHDJEgDTV/4Lt1gLQ4WeK0pB7K/KyClCof18DM5EROHHoBRukQ00FzcXTgd8yHsLd+P3LceCtUUhpggYemvmVgpSyDt0qhDXTliGK8elBOX5iYiofAxK4RYgKOVJdQM+xAgRu0/YyiytXBNxWkYu8oqcld260KoNFaVqDnur9p8EAOSXsKJERBQODErhFhGjudgBs+ZyADDBfVYvtWLfSfSb+g+SJq88q8cHHStKfngOHRFReDEohZu1nubiCDgCPsSi0egtQu5lKc+CbccBAJm2kspvX7ApA4buKkrKYcPSbef0AEREtUrQgtLYsWNx1VVXoU6dOoiJidFcRxAEv69Zs2ap1lm+fDm6desGq9WKdu3aYcaMGX7PM3XqVLRp0wYRERHo1asX1q9fH4R3FCSmSM3FkULg4TETXDh2phjPzdzkXSZJwIuztpT7UiXOGhhEdB2UlIJUDWPwIiIKq6AFJYfDgfvuuw/PPvtsuet9++23OHHihPerX79+3vsOHTqEvn374sYbb0RaWhqGDBmCJ598En/99Zd3nV9++QXDhg3D6NGjsXnzZnTt2hVJSUnIzs4O1lurXgF6lIZc3wJ3dG2ueZ8JbizemYmF2zNVy9MrqCiVOM9uyC6oVOGIQ29ERFSzBG0a6LfeegsANCtASjExMYiLi9O8b9q0aYiPj8eHH34IAOjYsSNWr16Njz76CElJSQCASZMm4amnnsLjjz/ufcyCBQvwzTffYMSIEdX0boKoaUegx0AgezeQvsa72OQuQbsm9YC9/g8xB+hRqmjGALurBh7MJY3hKz1ijxIRUa0U9h6lQYMGoXHjxujZsye++eYbSIoDZ2pqKhITE1XrJyUlITU1FYBctdq0aZNqHYPBgMTERO86Wux2O2w2m+orbAQBuH0ScOv76uWuYtx5mXZFySz49yhJEHxzKwVoiq7xFSVdByUdV8OIiCigsAalt99+G7Nnz0ZycjLuuecePPfcc/jkk0+892dmZiI2Nlb1mNjYWNhsNhQXF+PUqVNwu92a62RmqoellMaNG4fo6GjvV8uWLav3jZ2NMtd8g7MYbRprTxGgddabBAGiKAGn/0XJ+Hb4+8sRsJU48fuWo7CVyP1OJTWyolRbglLptldzYGKLEhFReFUpKI0YMUKzAVv5tWfPnko/35tvvomrr74al19+OV599VW88sormDhxYpXfRFWNHDkSeXl53q+MjIygv2aFDAbghS1Ak47ybWcRcDxNc9VLYrUbwEVJgrhkFCLsp5B47HPc9MEKDP1lK57/SW7yttfIipKOJ5ysLcOGREQUUJV6lIYPH47HHnus3HXatm171hvTq1cvvPPOO7Db7bBarYiLi0NWVpZqnaysLERFRSEyMhJGoxFGo1FznUB9TwBgtVphtVoD3h82DdsCCYOAeYOBoxuB6ddrrhajsekSALckwVZUgpjSZacK7ADk+ZOAGtqjpHWKvR55QlM1l4AEdikREYVVlYJSkyZN0KRJk2BtC9LS0tCgQQNviElISMDChQtV6yQnJyMhIQEAYLFY0L17d6SkpHjPlhNFESkpKRg8eHDQtjOoLKXDbbbAlyjpLO6FCVfgGsMO1XJRAgodbm9QKqvm9yjprKKkEpxt59AbEVF4Be2st/T0dOTk5CA9PR1utxtpaWkAgHbt2qFevXr4888/kZWVhSuvvBIRERFITk7Ge++9h5deesn7HM888ww+/fRTvPLKK3jiiSewdOlSzJ49GwsWLPCuM2zYMAwYMAA9evRAz549MXnyZBQWFnrPgtOdC2+scJX7T36Cw8b78Yp5tmq5JElwlFM1qpEVJV1PD1BLqmFERBRQ0ILSqFGj8N1333lvX3755QCAZcuW4YYbboDZbMbUqVMxdOhQSJKEdu3aeU/194iPj8eCBQswdOhQTJkyBS1atMBXX33lnRoAAB544AGcPHkSo0aNQmZmJi677DIsXrzYr8FbNyIbAEnvAX+9Vu5qT5oW+i1zixKc7nKCktOJewwrsUVqd86bWW303Mwdgm1XFpQkSYLAEhMRUUgFLSjNmDGj3DmU+vTpgz59+lT4PDfccAO2bCl/xunBgwfrd6hNS+P2Fa7SUChQ3ZYgQJRQbkWpt3sVPrRMK731VMD1QkrPDdEhbkQXJcDInEREFFJhn0eJNMS0OuuHOtyBD9jdhH1n/bxBU9sqSkGcHkDUdQ8XEZE+MSjVRDFnP6+TI8DQ25oDpyAoemrEiqbxDhU9N3OHuBrmrik/MyKi8wiDUk1kjgSE0h/Nlc8Bt0+uxIPk0kOgobeHv1qnuu2uKaGkhleUXG4RB7LzVTPGe2k1ogdxeoCa8iMjIjqfMCjVVC9uBZ5aCvQZB/So/Bl8lZ0CoOZUJ2p2j9KLs9KQOGklflqf7n9niENeVcPt/qx8ZFRwoWSSpf57Gl+vPqQdiInovBa0Zm46RzGtqtSrZBWc+J/xz0qv76opQUl1YKoh26SwYPsJAMC0Ff+if6/W6jtD0KOEs+xROlPowC0frQQAHB7ft3q3qRZ66Mu1AIC2TerixvZNw7w1RFSTsKKkF+bSiShjuwRcZaT5Z0iKI2ssclT3KweF3OU0fYdUDR96K1cI+quUP7Oq9JUdPVPs/Z5VkspLP80KHBGpMSjpxaC1QN9JwM1vVvohf1jV6yqbuV1ieEPJmHk78eR3GyGKiqHCGnxA1940jekBqrtHSfF8VRkuVW5Gjake6gBDJRGVxaE3vYhpBVwxEDhe/pxSRviCR5xwJuB64W7mnrHmMADgWJMieM/x09tBKgRDb8oDd1XyjtHgS0pOtwizkX8TERGdDX566k1ETLl314G9Uk9TU5q5HU6X70YNHnrTzD8hmB5A+RJV6VFSBSVXzfhZ6wH3FBGVxaCkNxHR5d5dRygvKCmG3sLYo6TstXG7a0mPUpCmBxBVFaUqDL0pvg80txYREVWMQUlvKghK9YzOSj2Nu5yD59aMXMzdcqxKm1UVTkV/lLpHSWcH9BA0oisLf1WpAiqHVsu7/h+p6W30l4iCjz1KemMwymfAOQs1724XLQC5FT+NyxU4UN059R8AQHzjuujaMuYsNrJ8ygO+SxmUznLgw+UWkXGmGPGN657jllVRCHqUlFWkqjy1ch8zKFUecxIRlcWKkh4FCEkAAHt+wLtUp5oHCErKCSszbSVV3bJKUZ6FJVbD0NszP27GjR8sx7ytx89106pG46K41X2gVTZzV6WipDypkUGpemTnl+DfkwUVr0hEtQqDkh5Zyxl+K84JeJdyegC3W7uXSTn/jtUUnF8PZX+U233uQ29/784CAHy9+lD5K+ZnAl8lAmk/V/k1tE4blyT/bc/Od1T5ucujzEZaPUpOt4hBP23GD6mHVcuVQ28ONnNXWnnTA/Qcm4KbP1yBzLzg/AFxPuO0DFSTMSjp0QPfQ10fqjrR5dJcnnHGN+FeZS+HUiG3E5j9KLD2cwDqOZxc7hDOo5Q8Gji6AZj7TLU8XcZpRWWvNCgVO7T369mqqJn7983HsGDbCbz5x07Vcg69Bc/uE7Zwb0Kt8sqcrbh+4nIU2qv3/w5RdWFQ0qO2NwAv/wv0GV+lhxnhO2C6Xf6Vj7SMXLw5d4f3dnE1BSXn9t+BXX8Ai0cAUFeUnK7qa+auMDqW5J3T85dlV05tEKTuFnUzt//92fna1Q0GJdKL2RuPIj2nCAu2nQj3phBpYlDSq7qNgF7PAI/+UemHmARfKJHc/j1K/ab+oxp6K3JUT1Da9u9R1W23GGjoLcgVpWo+dV8Z7KTSKlkwe5S0KkqBwqxyHwdreoBCuwsOV+0KYZX5FZTY8h0U3K9UUzEo6ZkgAI0uqvTqZsWs3SN/3YKrxi7GumXzUFRchD6TV/qtn1tUuakGlPZk2jB3yzHVXEllD+bKCoezGnqUPALloLxiJ9YcOAXpHJ5fc75JxVIxSJeEESto5i52aL+u8nHBmDOrwO7CJaP/wrUTllb7c4daVa6hR0TnHwYlvYtqLleWbh6tefcfz/byft8o0pckSuwleLr4a/Ra8QgyfhyEPZn+Z8tN/GsvigNVlbb9is0zR+H9xXuQW+Qbxhs+eyuG/JKGyX/v8y5zlwkRqukBXOVPD7DjWB6G/ZKGY7nFfveVFahe9OD0tXj4q3Wqalm1UPVaucrdhrN+CY3LySkVO92wwoGy+y7YQ287jsnDmFm2ys0EDwBFDhe+W3O4Uj/LUFJNwVCJqgb7joOD+5VqKgYlvRME4Nb3gWuHad7dtVkklr1wBV66rikSHKne5Sa48ZhpCQCg/bHfAj79i7O24PsyZ1QBAH57Et32T8GKFSm47O1k71/lO4/Lja7/t9k3YWXZ0Rnl9ACuCipKo+ftxG9bjqH3pBUBt1HLsdxi76ncnubbE2XOVtp5PA+Df9qMw6fKmW7Bs2maJSXlxJnB6lFSVJQ0NsJUfBJ7Ix7Dd+b3Vctr4oST4xftweh5O3Hnp6vDvSkq7krMVSWd5XxWVHks7FFNxaBUm9RtKv97xxTfspI8xP90DQavT1St2kk4EvBp2glHS6sUwJJdWRj1x86AZ8A1FuTKQpHTrVqnfoRvLlNldUMUpSpND5BVOpdTYSX6pQTF2NvV45fi5g9XqKpdZasu/ab+g/nbTuB/P2yq8Lk1KbbX8z6qv0fJ971Wj1LnnBQAwPXGbarloqpHKbhHoMqGxBX7TgIAThVU7xQK50o1HVaAdZS/wzyeE51fGJRqk6eXAfd+A1z+KCAY5WVZO4GCLL9VJ1s+03yKRMMm/G19BT9YxqmWvzJnG84Ulh7gFENOptK+p0K7C6cKfMMwyjmYyjYWK6cHyLYphmE0gkBMHbPmdpZH+XrK4bayT+8sDRD7swNP0ul9rMbhURLVQUkUpeofeisTMstyBAgpqqG3IDdca1W6tNTUSkxlJvKs7Hssz76sfDw0fS3WHTx9zs9VG7GZm2oqBqXaJLoF0PkewGAATFZ52cx7K/XQewwr8fVNLjxolJtzexr2qu6ft/U43vBMHSD6mrw9DeIFdpeqUmBXHJyVQ20Ol6tKQ29KFU1K5wkpgYeatB9vNJxdvFE2cLtFsVoOpn6vIWl/72FXnTSofYZcsIfeqjJjeE1UmaG36ujVf/r7jUg9eBoPTF977k9WC+n814hqMQal2spSr0qrf2iZhpvXPIoSWAKus2D7CRzIzkdJia9Ko6oo5fsqSgGDksOhGnpTRZQKgpKrgk9Sz8hbVU+HN2idLidWPNTnVqwjiiLcYvX/TVzRWW9uSdC8X7kLgh2UKvq5eNTUikFlToZUh6mzex9le+SISB8YlGqrJu21l0eUc/kTAHaUP9Q1Zt4uTFu6x3s7UrBDgIgCuwsFipl17Yp+JeVcO06HQzX0ZlBOgqlxABIUUaqyc/Yoh5o0Lsfmxy8oHVwBjGsBbPmx3Mcqr1PndrsqHRiqQqrgAC0q9o+qUqfYx8HuUXJVMojV2KG3Spz1pveqmS7U1F8QOu8xKNVWsZdoL2/SsdyHSUZrufcfOlWIv3dkeG9/YP4CO60DYUlfjULF5TuUFaUSpyIoOR2qA7pBcWByaVxWRXngqigoeUKVUznztyIwBPoY9ht6++W/gLMI+GNQua8nKipKblGCu2yPUjV88Ktm5q4gKKma5qs49JaZV1KlypNyUypdUaqhx0GxUkNvNa+Z2y1KmLrsADYcDnx9x5quJu5XorIYlGqrTncCpkj/5dEXlPuw2y9t7v3eDP/gciy3GGds6tPp6wh2dP3nORQpGmaUQUn5vdPphFs19KZsOvYf7lIeuys7pKaqYCnDVcCKUtkl/kNxWg8VyzRz+1UdziIZHDxZgLs/+wfL9mTLr1HB0Jso+f4LK4OmauitgoC5/WgerhyXgvu/SC13PfXrlr9dNdWYeTsxaOZmdT+XWPF7qUwfU6j9vuUYJv61F/dNq/zPraapifu1NsvIKcK3/xwKPD8eaWJQqq1aXwW8XubaSX0nAXUal/uwCIPv0+oe40oIEBEvnIAyKigvheLhdjowduFu7227yw2nW8SOY3mwKw7gjjJDb+qg5B/MHIrw9NfOTL8zv8oe2ArtLlWgUocr7U9iw1k3c7tV37tEscwrVP2Tf/ivW7E5PRePz9ggP28FQ4eKFiXV9fuU+6miStGvm+QK4Zb03Epvp3qYTz9HuBlrDmPB9hPYfcJ3pqO7EqGvoosTh8PB0nnC9Eysht4vqrykySvx1p+78OGSvRWvTF4MSrWZIAB1m8jft78NuGKg73Ygdt+FY8ebv8IbpplYZh2OgcZF3uValaaynG4JP6Qewe2frEZWrq8C9d787Vi+96T3tqGCipIy6Iz6Q5580mPNv6fQ+yPfRJTrD+eg2zvJqgOIMiSoPoYVH8rGMj1KJRrBQusz3K2qKIkQxbLN6VX/4M8pVM8xJFVwEHeLiqE3RVBSHvyD0aOk7EuqfI9SaA+Ea/49hcE/bcbJ0pMMAs1Wrj6zMEBQUrzFmhIMq/vSheEgVlzwpWrkuX7nP/9yioqqYFCq7Z74C7jyOaDvh/Ltuo3KX3/3n6qbA01yQHrNNBODb2wHALBqBCWtz+z3F8tN30ZFw/ah7DzM2uDrcVI2c9uK/SciLNuXtGi7XCU7mW/Hw1+uw78n1cOAdpeIhdtPKB7v+/hVlZsV1SCDQcDiHSfw3MxNyCt2qhrRy6McehNF9fxQsqp/9JvKVLdESUIznMZ/DGs0L2SseHtwO31nHaouExOEs970UFF6+Mt1mL/tBMb8uROAusFdDDD0Fui9uAOsH05Ctc/aFXpuSUJ7IR3LLUMRf2JhuDfnvMHqXdUwKNV2jS4E+oyTrwkHAA0vrPRDD1g6eL83ChJeSmqPeYOvxnTLpEo9vvMF8hl2FvgO8EaoQ4iyojRt+X5szchF+uki2EurS84y1RBn6UHq5/XpAV83KtJ35l7AvibRF/YMAvDMj5uxcHsmvltzGNrTRvp/sEjKoTfNHiX/1/4kZT8GztgQcDjMbFT/lxQlYJl1GD62fIrmB2f7ra98GrfTqXhccOdRcmv09ZQ43Zi9McM7m3pZ4fpoPlY66Wig2bUDhSalyoQpqjpRkjDJ/DnaGLJww47Xwr05RJoYlM43ra6s9KrtossEhuJcXNoiBhcIpyr1+E1HzuAB4zK8bv7Ju8ykCEpyNUnd2H3n1H9w3cRlmLBYHkMvW1HyDHcpZwEvq6DEF4KUjczKfijlpJnKobcCu0sVlFoLmQFfR11RcvvPo1R6AD6WW+ydOuHD5H1I2ZON5F3+s6UDgMnoX1GKEORtbZit0bSrCHyiS7uiZCtxYdDMzfgj7RiqxZkjZYbe5Nf66O99eGXONtw19R/Nh4Xrj1jPj1cZupXbohX6yip7GZ6a4Cxb62oUUZQQgZp1SRuishiUzjcmK9Dh9sqte3K3+nbym+WsrH3weN/8peq2ZxjuesNWbLcOxD1G3wVSlUHm69WHAPgHpX8OnMbLv27FmSL/YSiP3GLffUdyirS31u0LGMrnqm81qd7Jj2b5Ui7a8ygppgeQNKYHgISMnCJcPX4prn1/qarcnV+ivf0mg/q/pOqALmhMBqqcosDle07lgf33LcewYPsJvDgrTfM1q2TDV8CUS3HJ1rHeRVOXHcC1E5bip7Vyle94DZtY0TNPljoEaTdnB5pd3V2JdUKuFjQp6emMyfNacW64tyCsGJTOR/fNOLvHHV4NlORVvJ6X/4eg55In08wfoa5gh1XwHdwNZc8ZkyTNobNfNx1V9SGVlacISh+n7Ndcx+7wVV+KFT1JxU63qqLU0nASgaiHbNz+QzKSiH8OyNW3M0VO9TQJARqszRoVJQ+3YCq7umr4TyoTlK407MJ35vHlVsWqLHk0AODCQzO9ixZsP4GMnGLk28tv8g/XzNyeiqGyR0k5O7yqmVtHQ2/6j0k1KHSeZ6q02zd/D7zfGljzSdC2p6ZjUDofGc3A85uBC3pU7XE5B4HxrTTvEjQOgg3hf7FZT4+S1vplg9LsjRl+63iU95eorThAtUYx7Df4h3Wa6+QGeKzy1dYcOIVOoxZj9/Fc3/a4tYfelLfzFUOCgSbPVFaUJElS9xrBPyhBUlaUFENvkoRZlndxvXEbJpu1L4B8Ns5l+pVwD72pz3rTHm4LFIIqE6ZCrRYUlDh3kh7Me17+d8kb4d2OMGJQOl81uhB4KgUYtL5ans5kNOC+7i2w7YWLsS76NdxnXI7Ggn/1yRNWHIL/pVKUZ8ABwKv/t/2stiUvQNgxK4LS7mNntB9b5AzQzC2TJAkPf7UORQ63KuwdyMrHibwSv6E35YFAOdwWaBuVPUp2l6g6QDskraDkC1/Ks+KUB/M4ofpmbi6p5GVktATzmFhgd2HiX3uw+4TN7z7PzOuuADO2V2aOpMqEqVA7m7Pevv3nEL4pHdauCTj0Fh419bqLNRWD0vku0DXhqsgAYOJ9XRGVPAyx9sOYaJ6ORoLGQQsi6ltNqFenjt991dXUqQwhTXAG0ZDnVTIqJsp81jQPzeA/l0iuxhQFHgeyC9D93b+9t5UVsJV7s/HU9xvVD5Ak1QfSacUcSblFDny9+hBmb1BXzZTTAxTaXRAUTed2jYqSoDjg7z12Ggey5SqecsRSrMIBtbzThiXp3D5eq1o9yM4vUV0/sDzjF+3G1GX/4tYpq/zuM3iH3pRzdikb8X3rVmrCyRpycFdWlCqzTbYSJ976cxfenr8LtgA9cqHGoER6wKBEwH//D4i/Hnhhyzk8SekHXqavCnRJtH/omPlEN2x4IxEGU4TffXdfEl0twwmeXqD6KMKGiEHYGvE0AHVF6b+mFPxoec/vsblFTu3LlUgSEietUE0IqayACfCvtChn7gbgnfgQAPZm5eOd+bvwyv9tw6g/dmD+tuMA1AfzIocbJpevMVqroiQoKkrfrz6AWz5aiYycItQvOqzYdsVlTiqYKqBs79TBkwX4atVBlDjdsLvEcqtt58rlFlFUer3AM4UO9Bybgp5jfcG0vBD3z4HAE+j5ht60e8TUl2PRfo5wVZQkSfJOlVGW8ifh9JvDy59dcc3Fyl5gOtg49BYe3O9Vw6BEQLtEYMA8oGFb4L+/AdcMBeK6VO05PHMGFfuGtEb29B9eswgiIoyQ+6TK6NTIgHUjb/bebt1Irjr1vbQZ3ujbEUue6YypD3VVPaabsA8dhSOamyRfekUWg3xcbjiguv9Cg39D+M7jNmi1yeYqzoy7SDiKXyxvI8Gwy7vM8wjl54/DJaqGe5RBae1B33DY96lHMPgnOaQqG74LHS6Y3L6z9soeoCVJUpVDTIIbkgSk5xTh3h2+C/oqK0rFFUymWXbOpd4frcS7C3bjk6X7UVKm0b3qtD+dZ2/MwH+/Wod7p6XisreTcbrAXvpzkMOiJEl4Z/4uXD9xOfI0znYsdrhx6FSh33IPo0EAbMdhOrbBu0z5PtWXMNEOEO5KDM8Fw6g/dqLTqL9wWOP9Kf+ocFVi9nX1JKShPVJm55fg7T934UC2+rIrbOaWpzoJ9QSQ3OtVw6BEau1uBhLHALdPUS/vcj/Q6KLAj5NEIE89T49xhX/FBm4H8MNdwBmNPgl7PppGReCvIdfhx4G9sGTodfjy0R6Y0n4nnrQk4+IZl6LvnpGY9t9uAIAHO1rwm3UMFllHQuu/vnJG8NuNazU3e4TpZzSBul+pojDwuXkyehn24BKDL6B5qkvKR67Yl4Vle7O9t5VBSYskSaq/9Avtbpjdxd7bYpmZud2ipJrA01I6Y7rr1CFEOXzzNLkV/809QWn3CRv2ZPoPjZY9gHrC2Zp/T6PEqb6WXWfhIN4zfYXGqMqZkP5embMNqw+cQlpGLhwuEQu2n4DV7NvmQocbX68+hPScIszZfNTv8XM2BW76B0qH3iZ1RJs/7kIX4SCAMpcwUc6jVObXyFPNqcyFc4Phh7VH4BYlfL78X7/7BEVSqkzwUf5uVVtFqSAb+O4/wI7fyl1t6C9p+OafQ7jrM/UcW+f70NtfOzPR492/MeqPnSF9Xc7MXTUMSqStRXdgsKLn5vZJwP9WqtfpP0e+RIrH170rft55LwCHVmjf55D/2mwfVx/XxEfBKjlwS2wBTH8OBha9Iq+zex76dG6GVa/ciHE31vc+9HBEfzxv/A0tBV9AqC/4qjGtBe0JHp8x/YmPzVPL3eQ11sG4RPAFO63maIPg/8Hz6pxtquvaHc8t9ltHqcjhVh3A/kg7pg5KLnVQcomSKgx6GuUv++cZ1Xqi4r95iUMe3rp1yir0mbwKdpdbVSEJNJO5yy2h2OlWPdd86xt42LQUY8wzyn1fHpX9bD5d4FAFTuVZjFof8FpzaikPwMqJGXsa5LnBnJWYHmDy3/vQZfQSbD+ad1ZDb3+kHUNaRm7FK57cB+z8vdwdFHCGee82VWLoTTGE53Cfw+mLSilvyf+f5zxe7mqbj+QCUJ/5CfCAPaH0Mk8/rNWuilPNwKBEgdWL9X1vigQsigbszvcCF90iz/Td+hp5mc3/r30/hdmB77Pny1WpL64D3m0CjI2Tq08aWjasA8GlrtAMN8/BKutQfHSNhDs6N8U1hh3e+zpEBD7zK8G4C6NN36E+5GBV9qO7uZCjOsVeqznacwac8rFlm9mVF/TVcqbIoTogfp96BPYiX7Um/WSu6sDidIuqBnXPxYqj89VDjMrtFU9sxZm0+d7buUVOVTXCJYrYfjQP909LxeZ0X6XN6RZR7HBrluw7CL6KzkfmqfjT8hqgcV065WPLaz4+XWhXDUGWvVDwuoOnUaIYQqxjMfo9hzJwKisvnmCpGnoLUC2a/Pd+ONwi3pm/q9zpAfZm5mPOpqOqn83m9DN4cVYa+gWYpVxl6hXAr48B/6YEXEWrT8mzHRY4KxXelPvUXl0VpcLKXVw1UO9hbRl623Xchke+XodtR3Or9DhDkOd42J+Vj74fr/K7EkB17/VDpwpx5HTg4W+9Y1CiwCKi5CrSs6mAsbSR+OZRQMsrgT7jfes1qvz148q1fwnwUSfgxFbfstwAf2kV5QAn92jeddexCfik2SI8bVrgXXZlgwLNdT0eN/2FIab/C3h/HcHXVC1q/LfxBCXlx950s/Y18SKhPXP167/vUPVw3GdcjteyX/LeNkpyJWhXaf+Oy62uKFmhfSaTcnvbzOmDCxYOwO2GVHQQ0nG6QB3OMnKKccenq7H+cA4enO4brnSJUulknP7v3QlfULnL+A+6GA4D6RqXW1Eo78B+usChCgZHz/gqg58sPYAHpq/Fa7/7ThpQnhnXPFo+SUD5eGVFyVj6c1IGJWXA0QokJqOgqrqV3fakySvx0q9bsURxMCrbi1Mpx9NU2+H5OQPaQ2UuUcJY09fYbh0IMedwhU9vP4uht2O5xUictEJV8RBFybfPKnmgD7SWPPdY6CeE2nEsD9n51TeD/CNfr8Oq/adw7+fl/96XFey5sJ74bgN2Hrf5n5FbjUqcbtz4wXJcP3F5jTlJoLoxKFH5mnUFYjv5bl87HBj4F1CviW+ZMij1/B9w1/Tyn9OocSmOqtizEPjyRt9wXFkntgKrPlQtMudXXO0aaFqERsjT/OBWBhKtipJnqgDlmXBazeIDjH9hu/VJPG380+++FfvUs4BPNKv3o0VwY09mPm77eBXenb8LB08VqLYrQtCe2kAr2H1q+QSLrSOQm5+P3Sd8E4Pe/4Xvg175oedyi7A7tStKrtKgpHzvosZQkCT5V260Lth7Mt+uOkMrI6cYUSjAxUKGd+qH3zb7qnPKa/t5woBy25VFC09Pl2rCScUKhRozahoNgvpabwGqINuO5mLTkTNytets/mQ3+M5qHDRzC2772DfVgVYFyC1K6G9KgVVwoe6maRU+/dn0KL01bycOZBfgzblyddbpFpE0eSUe+7a0MV44t0NIOApKR04X4vZPVuOqcUur7Tk9U39UNERa1tnMhVUVGTkBhvurcb8rp2PxnLVa2wQtKB0+fBgDBw5EfHw8IiMjceGFF2L06NFwONQf5tu2bcO1116LiIgItGzZEhMmTPB7rl9//RUdOnRAREQEunTpgoULF6rulyQJo0aNQrNmzRAZGYnExETs36996QoKgkbtfN/HtALaXFP++pfcBbx0ALi4z9m93qyHgDOHq/aYktxKrfbPNVtRz+p/Gn6ccAZbe+8DoB08rm7bEEDFl5V4y/wdTIKIu4z/wGKs2n8/E3wfQl+tPoR7Pk9VBaVIaDeLe4KdGf4fYpt37fObpFHZIO5x+HSR3+VdPDwzhlsV82CJexb6r6cx4WOhxjxJx3KLVcEg40wR/rS8gSXWV1W9Yh7KipInACgf71b04xg0KkrKEKS1PWajQRWmAjVOT195EPd8vgavzNmmmj+r0n04iqD09271UMmpAoff86jOxKvEAVfdo1S5A/rRM+oD7d7MfOzPLsCKfSerVD0QApROwtHMvSdT/sPAJUrIsoX3uoShml1d6zOtuih/LWvKZKzVLWhBac+ePRBFEV988QV27tyJjz76CNOmTcNrr73mXcdms6F3795o3bo1Nm3ahIkTJ2LMmDGYPt33l/SaNWvw0EMPYeDAgdiyZQv69euHfv36YccOX//JhAkT8PHHH2PatGlYt24d6tati6SkJJSU1KyLc9ZazbvJPUwGE9A6AYiMUd9/9RCgrqIC1fgiuSJlsoZyKyslYuO0gB8q0SvHIMUyHFHwH4tvFi2/F0GjqVvzdWDHf+ruwCLrSHQSDqMJzmCRZQTeMX2D3yyjMNT0q99jTBoBRrksMsCEnZ6z3upoDPktWq8+2+Yqww7ssA7EQ0b/fpm5acfLDUrKCUNNG74ACk95b58pdKgCjbs0bMzZ5F/pO5FXournysgpQmuD3Nt2p3GNd7kkSZi57oiqYd6uEZQkRS+bUVD3KB3ILsAPqb5hJa2gZDQIqr6kZXuzccukFdii6OGSn1NeZ97W46qDR7mhRFl5M/j3WnnsPmHD2AXqi1SrqlyVCErKYKOs2JUnt0j9O2VWhPucQsc5V5TC0aOknNR1S3puyF8/HKIi1J9p1bnXlX90cOitivr06YNvv/0WvXv3Rtu2bfGf//wHL730En77zXca6cyZM+FwOPDNN9/gkksuwYMPPogXXngBkyb5ejumTJmCPn364OWXX0bHjh3xzjvvoFu3bvj0008ByB+WkydPxhtvvIE777wTl156Kb7//nscP34cc+fODdbbI6WoZvJklUN2ABd0B8yKpu/2fYFb3gJe2g/c/708zcCVz8n3NbtM/rdeLND73ZBvdkD5gS+4e6HhBCyCf2C5pFl9jbXVylZqPnC8i47CEcyMmoqnTAvR0ZCOR0x/o5vhAF40/e73eItGRcigGnoLPP2ABU60E/ybyRsLNjRGHhZZRuBp45/4wDwNkYID48xf+627Yus+NNM4488lyQf4iLI9Uoorjnv+ivc+RpSwNSMX75Y5+HusVAxDZiiqGrGCL5ysPnAKr/++A5mKqoDDLUIUJRQrhtAEt+9gX3boLXHSCqTs8Z1g4Bl6c7lFNEIeehs2wGoQVaHk0KlC7M8uwBMzNmgOHQLqA1FJeaHE6eu/OllU/ploX5W59Ij6wr5lLp4jSdibmY/52457Q54ysAUKb+mni5CR49umnDJBSVmVOlVgP+cepXCc9Vak+N3ID/MM5cFu5vYIVNGrDhWeJJC5HcjY4L9cR4JXj9OQl5eHhg0bem+npqbiuuuug8Xi61lJSkrC+++/jzNnzqBBgwZITU3FsGHDVM+TlJTkDUGHDh1CZmYmEhMTvfdHR0ejV69eSE1NxYMPPhjcN0WyqGa+7wUB6PshkHcUuHm0b1mnO+Uvj6uHyMGqYVsgqjngLAZaJQA7fwOObQIemAlM7iyvG9fFN+t3ZAN5Ysu6TYBCdV9PuESuGoutr+2C4VMjlIWdFg0i0aphHXz+8OXIW/kZUHot3voRZu960c5szYsEl+WpHhnhhgESnDDBpAhKdQIMvVngxGzL27jM4D8XT2PkYZT5e3Q0pKOjIR1HxKYBj2pvmGZqLvdUrMr2SN077R9cc6WI52+6CHvLzNn0zvxd2HREXZEJJCOnyPtJpQxKOxXNzlEowCPGv/GX2AMOt6iqXhncviDl2Ycpu7Ow6Yh/6PNUlArsLvyfZQzaGLLwf3kOiNLzfuueKXKqDrpKyr+s80uc+HVjhvZBxKluVH/7psqHB/U16tT3vbdwN75c5QlWW7BtTO8KZ+Yucbpx3cRlAIC97/aB1WT0C3nK26fLVJQe+3Y9Bt3YDle0aYjKqmJLT7VQ9tGcy7ULq0Mwc5Ly96js61RnQC23902SgGmlrRivHALqVP53oyYJWVA6cOAAPvnkE3zwwQfeZZmZmYiPj1etFxsb672vQYMGyMzM9C5TrpOZmeldT/k4rXXKstvtsNt9BxWbzX/iPTpHVzxZ8ToGA9D2et/t60ubs+Ov9S17fLE8LUGzrsC/S4H9f8sTYuYclAPWH88B2/2HqUKuJA/Rky7wW7zy5Rsh7PkTwoo3Eb3+C+/yxg7fkJMguXFpuzbA4fJf4vqIA7gwpi4m5g3HJcJhfOK6S3Xh4YfrbcbcvKv9HmeBCx0N2pMyxgpn8B+jr4G7EJGa6712Wwd0/3uf5n0WQT7wlL1WX1FhASb/vR8XNjCh3Zb3kGC4GKniJQDk4akI2GGECW4EHnICAIfL5f2kqgdfdWn8It9Zj3Msb+FiwzF0ch+G3fmEuqlUUVHy9HHtL3NW2oXCMUw3T8JU150QxSTkl7jQxiD3CXXNX4F9GkEJCNy8Onqeb0jzk5QD+GVjgEkxHb5hXLPkhMst4q7P1mivW4Zy7iR3abpdsO0ERElShCTZH2nHVUNOWkFJef03W7ELTer7/1yU0zKcLrBDmaqX7z2J5XtP4vBAi/zHTIsevgcGmh4gSD0t+SVO+Y8RDcpwWxIg6Gr558ApvLtgN8bd3QWXtYw5100EENygpOwJ9AtKlXwOUdQ6zxVyADq2GWhysbpSWfb3SjmFi+24boNSlYfeRowYAUEQyv3as0d92vaxY8fQp08f3HfffXjqqaeqbePP1rhx4xAdHe39atmyZbg3iQJpnSCHJAC48Cagz3uAyQI07SD/e+dnwJMpvlnDrx4CNOkINL0kbJusZMjaBmH2I4AiJJUlSCJ6Hf4s4P0eRmcBnrzgCLoZDsAquPCS+VckGX2n/dYpycJ86xt+j7uwgfYBAwDuNaon/8xXBSX549RqMuDe7i1RJ0DvVkRp+CgblCLggAkuWDd/hWtO/YqfLWO990WiBKusQ/BvxCNYahmGlkIWHjcuwnjzl37XzVNOeyBAQgvhJEaaZiJOcVHjiw3ysGJf43rYXW7V2Wv2El+4CtTH9Z75a1xoOIFJlmkocLhw3zRfeJQkKeABvdBe8YH2l40ZuMmwGc8Z58LvEOX0bZsFLhw8VYjtx/xnOk80bMJzxj9UnbOiokldlOSzuQb9tBnP/7zF7/ERJgPsipBj1yjlKCtOxQEChDooqStKqdbB8tmcM+8FvrpZ6+Fqpw5AcORXvF4AOYUO3P9FKmaXCaETFu9BlzFLsObAKc3HqYJSBZf0Uer/1TrsPiHPl1RVU5cdwPuL92Db0VyM+L9t3qkJyjvr7eDJAszemKF52Z7KUA6Tln2dsgWlf08WYMT/bVMNu8rPEaDitnse8NVNwLe3qX+vyk6v4VKcDCCFt3p3LqpcURo+fDgee+yxctdp27at9/vjx4/jxhtvxFVXXaVq0gaAuLg4ZGWpz+7w3I6Liyt3HeX9nmXNmjVTrXPZZZdpbt/IkSNVw3k2m41hSa9MFvkv1yf+Ak7tBVpfJfdEleQB41v5r9/zf3I16kCyennra4Ajq9XLuj0KbP7+3Lbvp+od+n1ozwtVf5Ar8IzgbQ3qqmuR5Guw7y7sww4pHo+Y/kHD3KZAlBWKbOLlGfIrO/Q22DQXVxl24mhGE++fZHfEHILDdhKnpSg0Ka2GtTVk4nXTT+hjlPsYEoSdeM01EDvEeOShnupsPgMkfGuegIsMx/A/0wJ0LPkGxfBdYLlYsmDMnzuxNcMXNs7Y8r2fdHUC9HHFwFdh2nE0T+57Kn1aW7EDezO1D+iVPR36G4tcSd8hxWOl2BVv/7kLrRvVwYBWvgOTBU6cKdQOcl9Z5OkuxPQnYGh9JQBAcinOMoSAJTu1Z58H5J6wcv/yh/o6gAUaTe2SJKmGqvKKnapSRTMhB6+Zf1Y+IHDJJHM7MO0aXB4Zi4wKKop+/l0KrPsCMyOfxfpDhVh/KAf39/B9fn9WermXt+fvwuIh1+FUgR0fp+xHt1YNcHFs/TJDb773XGh3YfWBU7j+4iaIMAfeJs/s4puO5GDdoRz877ry55FzuUVM/GsvAHgvRVNgd+HTh7uhhXgMexDhPSFCafivW7ElPRfz2h3Hj0/2qmiv+Cmvsdp7Vuap/UCDNnho+lpk59uxOf0Mlgz1VflLnG7tGvPmH+R/M7eV/3vlVJxAojEJrV5UOSg1adIETZo0qXhFyJWkG2+8Ed27d8e3334Lg0FdwEpISMDrr78Op9MJs1n+qzc5ORnt27dHgwYNvOukpKRgyJAh3sclJycjISEBABAfH4+4uDikpKR4g5HNZsO6devw7LPPam6X1WqF1Vrzzriic1C3EVD3Kt/tiGjg9snyB3X6OrmXqfHFwE1vyEN5n/aUS8F3Twc2zQBumwDkpgPf3eF7jnpxlXvttjcCB5dp35d//GzfUfWpQh/XjUbfZJ+PmpJ9Z5l9+SXQUPuAUEewY/mgLvg37Qywybf8JmMaAKCd4NsHn5S8DliAN5zqS15crZhFvbUhGzMt41AoWXGp/StVFSgCdsQbfIHgVdMsjHEN8N4WIGHhdnX4E9wO7yddT8Me3GZYi7/EK1RDfsqzB8tWdARI+HSZerZzjyKHGya44NL8KJUgjzn5/nyPFzKxEl2xeU0yViASOW0EDC29zyI4cTyvGJcIh+CECfsk+eDvmTEeAEoK8+A5VcIg+kKfW5KnVQik0O7y6yU5XWBH/QgzLCaD971413e4/PpYHG5RVYGRg1I5gxKuEsAsH2b94tIeeTJYa3EWgObexWsOnET3Ng1hNZUTnkpn678+2oEPIQ/xe6p+JsVZeZ4erpG/bUfyrix8n3oEEbCj3xW+6UyKHb59MuqPnfi/zUfx4BUtMf6eS+X52DLWAz0Gym0CpRrABveeRRj33S70MOzDvCjfmdxatObmOpBdAOxdjM/PPI0/zVfieaf/H0CeM/JWHzgFl1uEyWjA4h2Z+Gz5AUx+4DK0bVLP/8UkSb7+Xv1YVTXIVXqSg5Jzxx8wz3kUxW37IDv/UQDAviz1kHSx040GWm/KpTiBQtnMXbZSqfwjzanfmbuDdtbbsWPHcMMNN6BVq1b44IMPcPLkSWRmZqr6hh5++GFYLBYMHDgQO3fuxC+//IIpU6aoqj0vvvgiFi9ejA8//BB79uzBmDFjsHHjRgwePBiA3M0/ZMgQvPvuu5g3bx62b9+ORx99FM2bN0e/fv2C9fZID3o8DnR/DLjrc+C/c+RhO89lWJ5eBgzfA3S4Deg/G2jQBoi/Tu6Jat5Nvt06wfdcI48Bt04Ebv8IMEWoX+feb4CuD8nfX3I38PQKuRpVXR78qfqeqwqUp+IDUH04KrUQTqHNN11xMyo/+283g3qeM62pC+oKdnQQ0hGpqALFGNRh4HbjWrxh+tF7O0JweueL6iwcxCjT92gi5Hrvbyrk4jPLx3jB5Dn7VgKgnuH8k6XaoUhL7rH92GL9H940yX9hdxSO4DLhAOqiGMstw/CBeRrqK/qqrHCgm7APc62jkGJ9GfuO+IaNLHBh36EMLLC+jiXWV71DkBcIviGkySnyEA4AGNy+/eJwunBGcYaaFQ4YICLJsB4TTdNgLy70TooIAIdOFaD7u3/j4jcWeadoUFZaCuwuvzPjSpyiapglr9iJzFz1UI2KM3BwC+SRr1IxYfFe1bJDpwpxz+drkFJmbqn6oi/QJk1eiZsnrVAN/Xhynidw3G9chj0Rj6PZUd+M/cqK0v+VXnB51oYMeejxi+uAhS8BO+aoXneO5S0YZz2IOda3McI8C+Zdc8t9T1pVxzoWI7B8HADgjtILdiuDqSRJqhnlD5yUA8wzP27CtqN5GPGbb2Z6JXHJKODDi5Ey7wd1MHZLqjmOJAk4uUSuUkYeXBxw24vLDE16g3Kx76SKcpu5lRUlRzm/KzVc0IJScnIyDhw4gJSUFLRo0QLNmjXzfnlER0djyZIlOHToELp3747hw4dj1KhRePrpp73rXHXVVfjpp58wffp0dO3aFXPmzMHcuXPRuXNn7zqvvPIKnn/+eTz99NO44oorUFBQgMWLFyMioswBjcjDUhewavxF1joBePJv4IU0IP4G4LL+wPUj5HV7PQ30eAJ45SDQ7hbfY6z1gTunAq9nAvd9CzS/DLh1gjwdQnW4uA9gjar64254DajbtHq2AQBs5VyrThKBTd9W+qluaqr+69IYYP6p3vUOqXqfGkB94kVjwYYnTYtUy0abvgMgX7T3CdNiDDOpD3QA0MuwB/VQhJdNv2Cz9X/exm0AuMG5Cq+afENInuPVE8ZFeNf0NZQVosg1H6C+UIyBpkUww4VF1pGYax2Fu42r0MaQhXuNK9FA8A3btRRO4jfrGO/tB4zLvd9b4MTqDb6webNB7jWKN/nOzjt84iQ+X/4vsm0lEBRByemwe6+JVxfFWGsdjJ8t7+ILy2TcZ1qJdsfmYu1B3/PM3ug7meClX7dCkiQU2dXDUGX7lLJsJfhOMeeUrcSJPccDX0NRGayVp6eXON34eUO65kNMcOPrMtMgjPxtGzYdOYOB321UNddYxRKstr6A54xzsS+rAEfKTG2wP7sAL/+61RtUJpi/BAC8eMZ3+aWMnCJv/5lylHDOJkXfk/KSSvCfcb+xPUCjfimtMyPrWk1+lV5lkMm3u1RnMtqK1WHrVIF6CHnTkTO4f1oqDKkfAwDabXwbdpeIZjiNT81T0Mm1029G+ZNFAYbmHEVA5g5Akvx+B2zFTnmy3yxfBVgZqP16mlhRKt9jjz0GSZI0v5QuvfRSrFq1CiUlJTh69CheffVVv+e67777sHfvXtjtduzYsQO33Xab6n5BEPD2228jMzMTJSUl+Pvvv3HxxRcH661RbWcwyp+aBgPQ7zPgxpHq+y11gc53y99fOxwwmuXHmBWj+eZIeSqEO6bI80T1+9x336UPAHd8HPj1jYph4U53ys9d1QqVKRK44VUgukXgdTr1Axq3B64cVPnnNdcFXtxWtW3REHPav+FYyzNdjbizY9VC4n9NKbhM8FWFLjH4Xy/wSsNu/GN9AYNM89BQUA83fGr5BM+ayl5iRsIo8w/4rykFm6zP4AGjPNRaUuD7y1o5T1ULwXcQbAZfmLjKoJ7g8wbFUKcFLkQJvoPJV5YPcZthLT43+q5W4OkHO5ZbDIPijCKX0+GtKCUYdqGBUIBeBsVJNSV52FM6RYNVo6F9y77DaLPxbVxY+h4K7S4UO91oKWThZ/O7+I/hH0yd8h4STv8GQMLzxt/Q6cwyOOyBJ/WdlrIDf6Qd8/vMX7YnGydyfduunBrDCP+D98l8ed16KFJd+7F54U60EE7hFfNs77IzisZnA0SkbNoVcAoHAFi1/xReniP/DBrX8/2/sykui+NQnD3WCP6N9sWwAJAw0jRTc6LYIo2G/0izUR4iU1BWY3IL1f08hRX0wt3/RSrWH/b9ntUR7Ch0uPC+eTpuN67D9xjlV1FySgEO/z/cBUy7Gtif7NecXWB3+Z1lXO41BGtJRSmk8ygR1RqXPSxXeio63bX7Y/IXAMS0lueHuvI5+SLDkgjMH6Jef9AGOXgtHiFfGuaGEfJyq2JCS2s0YFd8YAtGQApwtkk99bQZKp3+A9wvV1+wdqr6vkYXAac1LgPU/TGgQevAz1lVjdoBpwMPdVk3foGnA94b2FzrqArXiRYq98EtQEKUok+okZCP981foqdhj+qsw0VWX6BuLvi63nsr1tG6/p+HRXCiSZkD8WcWdaD2NKPvOG7DloOZQOkJjZ0y5+J2Zwl24EHNWbqPlZghScBTxvl4xfQLXnU+hXniVd7eKvuPD6OdcRemm1Nws+NDrNp/CgkNbFhllTuoEoy7vM9VKEVguHkOYAOWoWvA9/P7+n+xd50Tf+/O9lZrIlGC+b//iA6C78CvPAlAa/b5egYHhpjmYIjpN2CK9muNNX2Nn9w34Uxhd++yr8wf4CZjGhLtE3BAUv/BkGDYiTsMqRjr6o/fNh/DpPsvQ4M6Zm8oU17aJKfICU+3YgeDfyWs8PAmPG/Mwv88F+Eu+Vi+oLjnfo2Q43CLgKgOQw6XCItJxIm962HZtwARuBwlkMOb34zxZQqwvbAdZoNv30XAgeO5xbja4KvOeSpn3YR9kKQLAgeljNKLYW/+DsXdu6nuKrC7gEj1Z165Q2+qihKDEtH5p6pzgrS5Wv7y6PE40LST3EyeOEY+gy+ytHXy4V/Uj+31P7nc3eV+oMPtwIcX+0r3FycBsZ2BHf8HdL4HWDkBuL60Mtv8MmBf6dDUXdMBu03uuwDU1+gr638rgfcUk4g++BNwfItcQQOAm0cBKW9X7f1rufDmcoNSTXCZ4V/8Hvs1yhYT7jGu0n4AgIsU1aWBZYYGA7HCiaaKCTW1RJb2cr05dwduMvjCmFly4hnTn1gldtacwf34qTzcaViN181yv9skyzQ8IC7HA45RMED0BqELDSfwp+U1/LzzZrTa5z87u+exHlqv5fF/ljH4wnU7Fm3riXqw4k3zr+giHMLF4jHVkUd5VuPrpploYTgFZMV7L8Y9tHgqbjAtL3e/9Del4F7jSiywJeI/hn9wEjHekwkeMi7DWFd/1fqeqSpOIQqTXPejyO7E/3ImoJ65BC87n8aWQ75qj61EDkqPRK7BO9Knfq99u3Etblf0nktFp/Hr9jys2H8S4+/u4tejZIAIsShXtUyACKdbxDtzUvH2bnnE5AXTfzDBJZ81W1Sifg5vTnK7UFKQg58s76nury8U42hOoWrYut70nnjCeDVGmX8A7MBKwRcqLXDCAfU0ImcKSlBsV1cfC+wuv15Fp+L6rXaXGyjKge2rOyF0uQf14xSfMQxKRHRWWvWSvyoS2QB4wNe0jGG75WbTnENAr2fkiTtvel2+r/Pd8mScgFy9OrJGnsSz6wOA2wVs+VGePqFx+wCv1dDX9A7Is6J36Ct/eVw7HOj2GDCxrd/Dq+TKZ+WLKM9+RL6dNA74a2T5jwmDC/PWVmn9DhoTfDqsDWCxBw5C3aILcXvBzwHvB4CrW9XB14eAFkK2d8oBpSbIg1XwPw37DbP/rOq9DHvwjHEeRphnqZZ3MRxGF4N2SCorpsywpVI9oQTDzXMwHP49YkrKoc8HPIHo8wT894K/IAnATMfySm2LVXDiytSncbdF3VM00LQoYFh9wrgYP7h646kv/sZMozw9yCkpGrmn6nqPjhcf+Bb4ZDXekSp3ofV/9+/GxN/PwIY6SO7QFIt2+E5gssCJV02z8Hj2YtWpgHVRArvThQE7B3obYp4zzcNP7psx2vQ9Llt6Gv+28L/+Imbeg4iDyzW3w3Fil2oOMuOZgxhlPui97Rbh3YZoFOJm42bYJN//++Kco7hlTkfVcxqPbQDc6r8YREXTvsMl4ljyp7ggZxuwYhtGmYfB8+fUkcxTqMZadEgxKBHpkdEMPLsGEF3y90pNFR9uEVHAgHmKx5nkZnXBqDrlGf9bKVekTu4DepaZFDZQb0HdRkDLXkCGYgK+Tv0Az1lABjMQewlwIk39uKdXAFt+kBvUG8bLZxh61GkkL7fbfJeoEYzAgD+BGaW9ibd9IPd3rJwAP2cTtAQj0PEO33YHQ4srYIm/HljlH25w0xvA0nfRvGCH/31l3GjegcMRXwa8f7Kl4olLlcqGpKrS6v+qLhkHd8rzelXhnJzmtq0Vr6RQTyjBLMs7ePHEIJSOcqG/SSOQaA1DB9Bu0UPYEAGsFTviwdlvwJNGIlGCFdZhaKo4C9OjPoohLX/fb2j2d8soeb6xEqDJ9AtxufAWtkgXoV/uDBR/8DwiC7Sb4gGgzYlFMJRzke4bBd9cHjcZt2C8+SvV/c2L9pR9CHotfRBzzX3RT7Fs28FjuEw4gJ1SGzhcIs7kF8FzjYLnHV97w9jStP2481YHGta1QG8EKRxXJaxhbDYboqOjkZeXh6ioszi7iKg2+vVx+bp7d0zx9VmVVXBSDkrRFwBZO+WzBEWXPKmnwSRfIPnTK4CWV8hN8N0GABfd4v88m74DDi4H7pomP4/b6V9pW/OpPFHhnZ8Cohv44lrglOKyKk+vkCtp4yuYPLbPeHkKiA1fyhdjNpiByBhgak95GLDvJPnU7cKTgNEC3P8D8PMDvsfHXQrc85X82lEXAF/e6Lsv8S3g79G+253vkRvrrxki357ay7+f7Mml8izHZ2G1KQHXuFIrXpGqze/uq3GX8Z9KrXu3fQyOSLF4wfQbMqSmmpU9AFjj7oSrFH1ggRRIEVgi9sDdxtUVrlsVhZIVdcu5qLbSOrGD+kSBUpOc9yJF7IZXTLNwvVH7hI8/bt+MO3uUP0FnVYXi+M2gBAYlIk0uO5C9W76EzLlclMpZApis1X9hK0mSA1VeBtAg3lchyzkoz968ZSbwn0/kM3gA4L4ZQPz1gXvLSmyAPV8OfQAgiuqqW85BORiZykxW+9UtwNH1wMOz5X6xtdOA5DflyUwvuUu97oEU4Me7fbfNdeTpJsZWcnJTpbY3yMH0t3IuC9Wip7xt5Xnkd2DrL8ChlYCjQK7mVdFPPeag3ekU9Dz0ecUrVzPXRX1g2h94LqDqtF+8AB+47sMXlsneZTYpElGC9pxRi91XeGecJ+CbOo/j8Zc/Uk0Xca5CcfwO2vQARKRzJqvcDH6uH2rmiOBc/VMQ5Ab4RheqA03DtvJFmZ9eBsR1Bp5bC/znU3lYsLwG/IgoX0gC1M/ped6yIQmQJyz93yo5JAHAlc/Ic2qVDUkA0O5m+ZqFgBx0XtwmTyXR9ga5D23oLqDzvf6Pu6dMz9CLW4FH/1CfDVnWXdOBZpf6bjfpAFg01m97I3D3F8Dw3XJoa1mmkvfMP8Br5cww/9gCPHz7Lej54Btw9S0z7UWdxv7rX1iJ68BpuUI7EJoeniWHYABS/WZY1Wu65npKz5jHVriOli+bjULzJo28t9N6fggpwHYBOOuQdKf9bXwn3lbxitXAFejst1J328dU22vdXLQYGTlVn4g03NijRES1W9OO6r6t6hbZwHe2ooehnEtw3DcDOLgCuKi3HCIBuRrlssth7c6pcp9Ys65A8mi5Ub9DXzlkpbwtDwfGlLbFxl8nX1om51/f8w/bI1/Cx1JHfYbS/1YCEOQhw91/yj1Zt7yjDrFGMzBwCbDhK2DVR8B//0++ADUgh88NpX0s9ZsB+aX9NG2ukf+11oPpigHAgtLLcTTrKr/mqf3A17fIszk/8KPcD7bjN2DO4/JlhZ74C1j6DrDxm8D7bMgOoF5TYO9CwFIPeHyR3KN24U3y9l9yF9DuFgiiC9dao4CTPwe8rFCeVAf3330vIF4A/PpY4NdUTF1hk+pgp9gGPbv3wr1t7MBnbwIAOlxzFyIMbkDKlyej/eJaAEBhZHMIdhvqiIGb3T2et47FJ/bXvbdHGZ9H4/ZX4Y54K7BsoeZjHEkTYbFYgT8rvvaj01wff5Rcjs3iRWghnMRzpnn4wZWIXNRD476jcN+SXt4L1r7r7I+OhiO42bAFMaVzem2WtOck/POisSjevQRfuW9Df+PfGGBK1lxvRp0B6H2BE833/4SW0WYYGtXRXK8m49AbOPRGRDpmzwfys4DCbHn4sH0f331upzz9RPz1QJNznITXUQjsXwK0SwRO7gUWjwQu7g1c97J6vYPLgX+myJf78TTqO4sBt0MOcFqcxfLZmMVngGXvyWdDri1tTH9yKdCi9FR2R5EcQrUqe0qiG5h5H/BvaWP2Le8A3QcAJXnIN8agfv3Sz/ndf8rXc7PUlfvSrntZbq73yN6N/DPZ+PRgU9xxaXN0vqB0+/cskENe44vUr/vdf4BDK+TX2z5b7qnT4LbGwN2uNyxd+skVPc9UHBf0KD3ZQpDPTF08EuL2/4PBXWZizxfS5BMh3C4gPRVocQUwfyiw9SfYW10Ha/pKAEBJ9/8h4vqhaD8hrXRiSAlLnr0Ud3+zGzF1zPi/Z69C5I+3Iyp7A/KkOvjxhlVYvf8Uzpw5jecLJuMP99VYIl6BzdesQ8ONvkmsFlz1C5Ju7o12r8tnE14u7MfvVrk3b1njhxFv34M2+Zvlle/5Wv6deb803I9ID/x7cBbYoxQiDEpERDWEvUC+ZJCzGCjKUQ+HVkVuOvDNrcAVA4Frh5W/rigCJ3fLw5PlVQMrUpwLpK+Vq3975ssVq3a3yBPHukqArT/LgfDOz4DLFXM7HdtUegLDldrPm7EBJw7vRLOUF+Xbo874Dw27XfJca6Lbd3LA6FxAELDu4GmMnrcT793dBd1aNfBOPmk0CJBy07Hnx5ewsfWTeOSO3gCA3CIH0nOK4HSLyLbZceslsXCfOoBM8wW4oEFd70u+MmcrZm88il5tYvBL81/ks1YTS09mWDtNDnF3fykPkWesl8NlZMzZ718NDEohwqBERETVLn2dXMnzDM26XfJwXpP2Z9e3dyBFfq4LupW/3v5k+TViWlX9Naqg0O7C7I0ZuLVzM8RFh+faqgxKIcKgREREpD88642IiIgojBiUiIiIiAJgUCIiIiIKgEGJiIiIKAAGJSIiIqIAGJSIiIiIAmBQIiIiIgqAQYmIiIgoAAYlIiIiogAYlIiIiIgCYFAiIiIiCoBBiYiIiCgABiUiIiKiAEzh3oCaQJIkAPJViImIiEgfPMdtz3E8GBiUAOTn5wMAWrZsGeYtISIioqrKz89HdHR0UJ5bkIIZw3RCFEUcP34c9evXhyAI1frcNpsNLVu2REZGBqKioqr1uSkw7vfw4H4PD+738OB+Dw/lfq9fvz7y8/PRvHlzGAzB6SZiRQmAwWBAixYtgvoaUVFR/I8UBtzv4cH9Hh7c7+HB/R4env0erEqSB5u5iYiIiAJgUCIiIiIKgEEpyKxWK0aPHg2r1RruTTmvcL+HB/d7eHC/hwf3e3iEer+zmZuIiIgoAFaUiIiIiAJgUCIiIiIKgEGJiIiIKAAGJSIiIqIAGJSCbOrUqWjTpg0iIiLQq1cvrF+/PtybpFvjxo3DFVdcgfr166Np06bo168f9u7dq1qnpKQEgwYNQqNGjVCvXj3cc889yMrKUq2Tnp6Ovn37ok6dOmjatClefvlluFyuUL4VXRs/fjwEQcCQIUO8y7jfg+PYsWP473//i0aNGiEyMhJdunTBxo0bvfdLkoRRo0ahWbNmiIyMRGJiIvbv3696jpycHPTv3x9RUVGIiYnBwIEDUVBQEOq3ohtutxtvvvkm4uPjERkZiQsvvBDvvPOO6lpi3O/nbuXKlbjjjjvQvHlzCIKAuXPnqu6vrn28bds2XHvttYiIiEDLli0xYcKEqm+sREEza9YsyWKxSN988420c+dO6amnnpJiYmKkrKyscG+aLiUlJUnffvuttGPHDiktLU267bbbpFatWkkFBQXedZ555hmpZcuWUkpKirRx40bpyiuvlK666irv/S6XS+rcubOUmJgobdmyRVq4cKHUuHFjaeTIkeF4S7qzfv16qU2bNtKll14qvfjii97l3O/VLycnR2rdurX02GOPSevWrZMOHjwo/fXXX9KBAwe864wfP16Kjo6W5s6dK23dulX6z3/+I8XHx0vFxcXedfr06SN17dpVWrt2rbRq1SqpXbt20kMPPRSOt6QLY8eOlRo1aiTNnz9fOnTokPTrr79K9erVk6ZMmeJdh/v93C1cuFB6/fXXpd9++00CIP3++++q+6tjH+fl5UmxsbFS//79pR07dkg///yzFBkZKX3xxRdV2lYGpSDq2bOnNGjQIO9tt9stNW/eXBo3blwYt6r2yM7OlgBIK1askCRJknJzcyWz2Sz9+uuv3nV2794tAZBSU1MlSZL/cxoMBikzM9O7zueffy5FRUVJdrs9tG9AZ/Lz86WLLrpISk5Olq6//npvUOJ+D45XX31VuuaaawLeL4qiFBcXJ02cONG7LDc3V7JardLPP/8sSZIk7dq1SwIgbdiwwbvOokWLJEEQpGPHjgVv43Wsb9++0hNPPKFadvfdd0v9+/eXJIn7PRjKBqXq2sefffaZ1KBBA9VnzKuvviq1b9++StvHobcgcTgc2LRpExITE73LDAYDEhMTkZqaGsYtqz3y8vIAAA0bNgQAbNq0CU6nU7XPO3TogFatWnn3eWpqKrp06YLY2FjvOklJSbDZbNi5c2cIt15/Bg0ahL59+6r2L8D9Hizz5s1Djx49cN9996Fp06a4/PLL8eWXX3rvP3ToEDIzM1X7PTo6Gr169VLt95iYGPTo0cO7TmJiIgwGA9atWxe6N6MjV111FVJSUrBv3z4AwNatW7F69WrceuutALjfQ6G69nFqaiquu+46WCwW7zpJSUnYu3cvzpw5U+nt4UVxg+TUqVNwu92qAwMAxMbGYs+ePWHaqtpDFEUMGTIEV199NTp37gwAyMzMhMViQUxMjGrd2NhYZGZmetfR+pl47iNts2bNwubNm7Fhwwa/+7jfg+PgwYP4/PPPMWzYMLz22mvYsGEDXnjhBVgsFgwYMMC737T2q3K/N23aVHW/yWRCw4YNud8DGDFiBGw2Gzp06ACj0Qi3242xY8eif//+AMD9HgLVtY8zMzMRHx/v9xye+xo0aFCp7WFQIl0aNGgQduzYgdWrV4d7U2q9jIwMvPjii0hOTkZERES4N+e8IYoievTogffeew8AcPnll2PHjh2YNm0aBgwYEOatq71mz56NmTNn4qeffsIll1yCtLQ0DBkyBM2bN+d+P09x6C1IGjduDKPR6HfmT1ZWFuLi4sK0VbXD4MGDMX/+fCxbtgwtWrTwLo+Li4PD4UBubq5qfeU+j4uL0/yZeO4jf5s2bUJ2dja6desGk8kEk8mEFStW4OOPP4bJZEJsbCz3exA0a9YMnTp1Ui3r2LEj0tPTAfj2W3mfMXFxccjOzlbd73K5kJOTw/0ewMsvv4wRI0bgwQcfRJcuXfDII49g6NChGDduHADu91Corn1cXZ87DEpBYrFY0L17d6SkpHiXiaKIlJQUJCQkhHHL9EuSJAwePBi///47li5d6ldS7d69O8xms2qf7927F+np6d59npCQgO3bt6v+gyUnJyMqKsrvoESym2++Gdu3b0daWpr3q0ePHujfv7/3e+736nf11Vf7TX+xb98+tG7dGgAQHx+PuLg41X632WxYt26dar/n5uZi06ZN3nWWLl0KURTRq1evELwL/SkqKoLBoD40Go1GiKIIgPs9FKprHyckJGDlypVwOp3edZKTk9G+fftKD7sB4PQAwTRr1izJarVKM2bMkHbt2iU9/fTTUkxMjOrMH6q8Z599VoqOjpaWL18unThxwvtVVFTkXeeZZ56RWrVqJS1dulTauHGjlJCQICUkJHjv95ym3rt3byktLU1avHix1KRJE56mXkXKs94kifs9GNavXy+ZTCZp7Nix0v79+6WZM2dKderUkX788UfvOuPHj5diYmKkP/74Q9q2bZt05513ap5Cffnll0vr1q2TVq9eLV100UU8Tb0cAwYMkC644ALv9AC//fab1LhxY+mVV17xrsP9fu7y8/OlLVu2SFu2bJEASJMmTZK2bNkiHTlyRJKk6tnHubm5UmxsrPTII49IO3bskGbNmiXVqVOH0wPUNJ988onUqlUryWKxSD179pTWrl0b7k3SLQCaX99++613neLiYum5556TGjRoINWpU0e66667pBMnTqie5/Dhw9Ktt94qRUZGSo0bN5aGDx8uOZ3OEL8bfSsblLjfg+PPP/+UOnfuLFmtVqlDhw7S9OnTVfeLoii9+eabUmxsrGS1WqWbb75Z2rt3r2qd06dPSw899JBUr149KSoqSnr88cel/Pz8UL4NXbHZbNKLL74otWrVSoqIiJDatm0rvf7666pTzLnfz92yZcs0P88HDBggSVL17eOtW7dK11xzjWS1WqULLrhAGj9+fJW3VZAkxXSjREREROTFHiUiIiKiABiUiIiIiAJgUCIiIiIKgEGJiIiIKAAGJSIiIqIAGJSIiIiIAmBQIiIiIgqAQYmIiIgoAAYlIiIiogAYlIiIiIgCYFAiIiIiCoBBiYiIiCiA/wevWZkiERRWDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.15655  validloss 4.38784±0.00000  bestvalidloss 4.38784  last_update 0\n",
      "train: iter 1  trainloss 3.84829  validloss 4.03294±0.00000  bestvalidloss 4.03294  last_update 0\n",
      "train: iter 2  trainloss 3.58129  validloss 3.74801±0.00000  bestvalidloss 3.74801  last_update 0\n",
      "train: iter 3  trainloss 3.35649  validloss 3.49683±0.00000  bestvalidloss 3.49683  last_update 0\n",
      "train: iter 4  trainloss 3.15495  validloss 3.28463±0.00000  bestvalidloss 3.28463  last_update 0\n",
      "train: iter 5  trainloss 2.97873  validloss 3.08978±0.00000  bestvalidloss 3.08978  last_update 0\n",
      "train: iter 6  trainloss 2.81893  validloss 2.91285±0.00000  bestvalidloss 2.91285  last_update 0\n",
      "train: iter 7  trainloss 2.68036  validloss 2.76117±0.00000  bestvalidloss 2.76117  last_update 0\n",
      "train: iter 8  trainloss 2.56047  validloss 2.62305±0.00000  bestvalidloss 2.62305  last_update 0\n",
      "train: iter 9  trainloss 2.44271  validloss 2.50128±0.00000  bestvalidloss 2.50128  last_update 0\n",
      "train: iter 10  trainloss 2.34115  validloss 2.37754±0.00000  bestvalidloss 2.37754  last_update 0\n",
      "train: iter 11  trainloss 2.24990  validloss 2.28131±0.00000  bestvalidloss 2.28131  last_update 0\n",
      "train: iter 12  trainloss 2.16238  validloss 2.18243±0.00000  bestvalidloss 2.18243  last_update 0\n",
      "train: iter 13  trainloss 2.08296  validloss 2.09254±0.00000  bestvalidloss 2.09254  last_update 0\n",
      "train: iter 14  trainloss 2.00478  validloss 2.01181±0.00000  bestvalidloss 2.01181  last_update 0\n",
      "train: iter 15  trainloss 1.93389  validloss 1.93107±0.00000  bestvalidloss 1.93107  last_update 0\n",
      "train: iter 16  trainloss 1.86558  validloss 1.84674±0.00000  bestvalidloss 1.84674  last_update 0\n",
      "train: iter 17  trainloss 1.79281  validloss 1.77827±0.00000  bestvalidloss 1.77827  last_update 0\n",
      "train: iter 18  trainloss 1.73251  validloss 1.70428±0.00000  bestvalidloss 1.70428  last_update 0\n",
      "train: iter 19  trainloss 1.66054  validloss 1.62768±0.00000  bestvalidloss 1.62768  last_update 0\n",
      "train: iter 20  trainloss 1.58994  validloss 1.56003±0.00000  bestvalidloss 1.56003  last_update 0\n",
      "train: iter 21  trainloss 1.52287  validloss 1.47222±0.00000  bestvalidloss 1.47222  last_update 0\n",
      "train: iter 22  trainloss 1.45734  validloss 1.39863±0.00000  bestvalidloss 1.39863  last_update 0\n",
      "train: iter 23  trainloss 1.38688  validloss 1.32130±0.00000  bestvalidloss 1.32130  last_update 0\n",
      "train: iter 24  trainloss 1.31752  validloss 1.24684±0.00000  bestvalidloss 1.24684  last_update 0\n",
      "train: iter 25  trainloss 1.25163  validloss 1.16832±0.00000  bestvalidloss 1.16832  last_update 0\n",
      "train: iter 26  trainloss 1.18021  validloss 1.09466±0.00000  bestvalidloss 1.09466  last_update 0\n",
      "train: iter 27  trainloss 1.11566  validloss 1.01000±0.00000  bestvalidloss 1.01000  last_update 0\n",
      "train: iter 28  trainloss 1.04169  validloss 0.93812±0.00000  bestvalidloss 0.93812  last_update 0\n",
      "train: iter 29  trainloss 0.98042  validloss 0.85407±0.00000  bestvalidloss 0.85407  last_update 0\n",
      "train: iter 30  trainloss 0.90242  validloss 0.77621±0.00000  bestvalidloss 0.77621  last_update 0\n",
      "train: iter 31  trainloss 0.83704  validloss 0.69830±0.00000  bestvalidloss 0.69830  last_update 0\n",
      "train: iter 32  trainloss 0.77435  validloss 0.62039±0.00000  bestvalidloss 0.62039  last_update 0\n",
      "train: iter 33  trainloss 0.71454  validloss 0.54886±0.00000  bestvalidloss 0.54886  last_update 0\n",
      "train: iter 34  trainloss 0.65190  validloss 0.47143±0.00000  bestvalidloss 0.47143  last_update 0\n",
      "train: iter 35  trainloss 0.58724  validloss 0.40081±0.00000  bestvalidloss 0.40081  last_update 0\n",
      "train: iter 36  trainloss 0.53158  validloss 0.33363±0.00000  bestvalidloss 0.33363  last_update 0\n",
      "train: iter 37  trainloss 0.48500  validloss 0.27717±0.00000  bestvalidloss 0.27717  last_update 0\n",
      "train: iter 38  trainloss 0.44302  validloss 0.21044±0.00000  bestvalidloss 0.21044  last_update 0\n",
      "train: iter 39  trainloss 0.39528  validloss 0.16205±0.00000  bestvalidloss 0.16205  last_update 0\n",
      "train: iter 40  trainloss 0.35176  validloss 0.09303±0.00000  bestvalidloss 0.09303  last_update 0\n",
      "train: iter 41  trainloss 0.32257  validloss 0.04713±0.00000  bestvalidloss 0.04713  last_update 0\n",
      "train: iter 42  trainloss 0.28597  validloss -0.00191±0.00000  bestvalidloss -0.00191  last_update 0\n",
      "train: iter 43  trainloss 0.23586  validloss -0.04800±0.00000  bestvalidloss -0.04800  last_update 0\n",
      "train: iter 44  trainloss 0.19740  validloss -0.09654±0.00000  bestvalidloss -0.09654  last_update 0\n",
      "train: iter 45  trainloss 0.16469  validloss -0.13515±0.00000  bestvalidloss -0.13515  last_update 0\n",
      "train: iter 46  trainloss 0.13936  validloss -0.17710±0.00000  bestvalidloss -0.17710  last_update 0\n",
      "train: iter 47  trainloss 0.09203  validloss -0.21846±0.00000  bestvalidloss -0.21846  last_update 0\n",
      "train: iter 48  trainloss 0.07372  validloss -0.25689±0.00000  bestvalidloss -0.25689  last_update 0\n",
      "train: iter 49  trainloss 0.03151  validloss -0.29846±0.00000  bestvalidloss -0.29846  last_update 0\n",
      "train: iter 50  trainloss 0.01116  validloss -0.32410±0.00000  bestvalidloss -0.32410  last_update 0\n",
      "train: iter 51  trainloss -0.01887  validloss -0.38467±0.00000  bestvalidloss -0.38467  last_update 0\n",
      "train: iter 52  trainloss -0.02800  validloss -0.41659±0.00000  bestvalidloss -0.41659  last_update 0\n",
      "train: iter 53  trainloss -0.07063  validloss -0.44176±0.00000  bestvalidloss -0.44176  last_update 0\n",
      "train: iter 54  trainloss -0.07936  validloss -0.47827±0.00000  bestvalidloss -0.47827  last_update 0\n",
      "train: iter 55  trainloss -0.11303  validloss -0.52287±0.00000  bestvalidloss -0.52287  last_update 0\n",
      "train: iter 56  trainloss -0.14758  validloss -0.54222±0.00000  bestvalidloss -0.54222  last_update 0\n",
      "train: iter 57  trainloss -0.14638  validloss -0.56143±0.00000  bestvalidloss -0.56143  last_update 0\n",
      "train: iter 58  trainloss -0.16923  validloss -0.59346±0.00000  bestvalidloss -0.59346  last_update 0\n",
      "train: iter 59  trainloss -0.17250  validloss -0.62344±0.00000  bestvalidloss -0.62344  last_update 0\n",
      "train: iter 60  trainloss -0.19938  validloss -0.63234±0.00000  bestvalidloss -0.63234  last_update 0\n",
      "train: iter 61  trainloss -0.22630  validloss -0.65476±0.00000  bestvalidloss -0.65476  last_update 0\n",
      "train: iter 62  trainloss -0.22425  validloss -0.67551±0.00000  bestvalidloss -0.67551  last_update 0\n",
      "train: iter 63  trainloss -0.22391  validloss -0.72215±0.00000  bestvalidloss -0.72215  last_update 0\n",
      "train: iter 64  trainloss -0.23540  validloss -0.73587±0.00000  bestvalidloss -0.73587  last_update 0\n",
      "train: iter 65  trainloss -0.25288  validloss -0.74624±0.00000  bestvalidloss -0.74624  last_update 0\n",
      "train: iter 66  trainloss -0.26728  validloss -0.78250±0.00000  bestvalidloss -0.78250  last_update 0\n",
      "train: iter 67  trainloss -0.26475  validloss -0.78085±0.00000  bestvalidloss -0.78250  last_update 1\n",
      "train: iter 68  trainloss -0.27352  validloss -0.79247±0.00000  bestvalidloss -0.79247  last_update 0\n",
      "train: iter 69  trainloss -0.27289  validloss -0.79395±0.00000  bestvalidloss -0.79395  last_update 0\n",
      "train: iter 70  trainloss -0.28631  validloss -0.82029±0.00000  bestvalidloss -0.82029  last_update 0\n",
      "train: iter 71  trainloss -0.26834  validloss -0.83384±0.00000  bestvalidloss -0.83384  last_update 0\n",
      "train: iter 72  trainloss -0.29206  validloss -0.82685±0.00000  bestvalidloss -0.83384  last_update 1\n",
      "train: iter 73  trainloss -0.29030  validloss -0.83332±0.00000  bestvalidloss -0.83384  last_update 2\n",
      "train: iter 74  trainloss -0.29667  validloss -0.85037±0.00000  bestvalidloss -0.85037  last_update 0\n",
      "train: iter 75  trainloss -0.28779  validloss -0.86641±0.00000  bestvalidloss -0.86641  last_update 0\n",
      "train: iter 76  trainloss -0.30895  validloss -0.88522±0.00000  bestvalidloss -0.88522  last_update 0\n",
      "train: iter 77  trainloss -0.29192  validloss -0.88166±0.00000  bestvalidloss -0.88522  last_update 1\n",
      "train: iter 78  trainloss -0.29014  validloss -0.88507±0.00000  bestvalidloss -0.88522  last_update 2\n",
      "train: iter 79  trainloss -0.30585  validloss -0.87558±0.00000  bestvalidloss -0.88522  last_update 3\n",
      "train: iter 80  trainloss -0.29178  validloss -0.89964±0.00000  bestvalidloss -0.89964  last_update 0\n",
      "train: iter 81  trainloss -0.28882  validloss -0.88485±0.00000  bestvalidloss -0.89964  last_update 1\n",
      "train: iter 82  trainloss -0.29479  validloss -0.87761±0.00000  bestvalidloss -0.89964  last_update 2\n",
      "train: iter 83  trainloss -0.31661  validloss -0.88247±0.00000  bestvalidloss -0.89964  last_update 3\n",
      "train: iter 84  trainloss -0.28047  validloss -0.89327±0.00000  bestvalidloss -0.89964  last_update 4\n",
      "train: iter 85  trainloss -0.28665  validloss -0.88844±0.00000  bestvalidloss -0.89964  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 86  trainloss -0.31954  validloss -0.88294±0.00000  bestvalidloss -0.89964  last_update 6\n",
      "train: iter 87  trainloss -0.29831  validloss -0.91741±0.00000  bestvalidloss -0.91741  last_update 0\n",
      "train: iter 88  trainloss -0.29119  validloss -0.88942±0.00000  bestvalidloss -0.91741  last_update 1\n",
      "train: iter 89  trainloss -0.27994  validloss -0.88859±0.00000  bestvalidloss -0.91741  last_update 2\n",
      "train: iter 90  trainloss -0.30381  validloss -0.91329±0.00000  bestvalidloss -0.91741  last_update 3\n",
      "train: iter 91  trainloss -0.31024  validloss -0.92080±0.00000  bestvalidloss -0.92080  last_update 0\n",
      "train: iter 92  trainloss -0.30510  validloss -0.90534±0.00000  bestvalidloss -0.92080  last_update 1\n",
      "train: iter 93  trainloss -0.30054  validloss -0.91252±0.00000  bestvalidloss -0.92080  last_update 2\n",
      "train: iter 94  trainloss -0.29400  validloss -0.90553±0.00000  bestvalidloss -0.92080  last_update 3\n",
      "train: iter 95  trainloss -0.28011  validloss -0.91839±0.00000  bestvalidloss -0.92080  last_update 4\n",
      "train: iter 96  trainloss -0.29210  validloss -0.90406±0.00000  bestvalidloss -0.92080  last_update 5\n",
      "train: iter 97  trainloss -0.29915  validloss -0.92021±0.00000  bestvalidloss -0.92080  last_update 6\n",
      "train: iter 98  trainloss -0.27689  validloss -0.90528±0.00000  bestvalidloss -0.92080  last_update 7\n",
      "train: iter 99  trainloss -0.32356  validloss -0.91368±0.00000  bestvalidloss -0.92080  last_update 8\n",
      "train: iter 100  trainloss -0.32485  validloss -0.92312±0.00000  bestvalidloss -0.92312  last_update 0\n",
      "train: iter 101  trainloss -0.28237  validloss -0.93346±0.00000  bestvalidloss -0.93346  last_update 0\n",
      "train: iter 102  trainloss -0.32918  validloss -0.89911±0.00000  bestvalidloss -0.93346  last_update 1\n",
      "train: iter 103  trainloss -0.31733  validloss -0.94127±0.00000  bestvalidloss -0.94127  last_update 0\n",
      "train: iter 104  trainloss -0.29135  validloss -0.93970±0.00000  bestvalidloss -0.94127  last_update 1\n",
      "train: iter 105  trainloss -0.30415  validloss -0.91360±0.00000  bestvalidloss -0.94127  last_update 2\n",
      "train: iter 106  trainloss -0.30104  validloss -0.92162±0.00000  bestvalidloss -0.94127  last_update 3\n",
      "train: iter 107  trainloss -0.29971  validloss -0.90570±0.00000  bestvalidloss -0.94127  last_update 4\n",
      "train: iter 108  trainloss -0.31722  validloss -0.94348±0.00000  bestvalidloss -0.94348  last_update 0\n",
      "train: iter 109  trainloss -0.29333  validloss -0.93434±0.00000  bestvalidloss -0.94348  last_update 1\n",
      "train: iter 110  trainloss -0.30001  validloss -0.92746±0.00000  bestvalidloss -0.94348  last_update 2\n",
      "train: iter 111  trainloss -0.27976  validloss -0.95919±0.00000  bestvalidloss -0.95919  last_update 0\n",
      "train: iter 112  trainloss -0.32816  validloss -0.93305±0.00000  bestvalidloss -0.95919  last_update 1\n",
      "train: iter 113  trainloss -0.29204  validloss -0.91350±0.00000  bestvalidloss -0.95919  last_update 2\n",
      "train: iter 114  trainloss -0.32129  validloss -0.89131±0.00000  bestvalidloss -0.95919  last_update 3\n",
      "train: iter 115  trainloss -0.30668  validloss -0.90626±0.00000  bestvalidloss -0.95919  last_update 4\n",
      "train: iter 116  trainloss -0.30544  validloss -0.89342±0.00000  bestvalidloss -0.95919  last_update 5\n",
      "train: iter 117  trainloss -0.28290  validloss -0.94666±0.00000  bestvalidloss -0.95919  last_update 6\n",
      "train: iter 118  trainloss -0.30922  validloss -0.92937±0.00000  bestvalidloss -0.95919  last_update 7\n",
      "train: iter 119  trainloss -0.30591  validloss -0.95697±0.00000  bestvalidloss -0.95919  last_update 8\n",
      "train: iter 120  trainloss -0.28047  validloss -0.93503±0.00000  bestvalidloss -0.95919  last_update 9\n",
      "train: iter 121  trainloss -0.27926  validloss -0.92679±0.00000  bestvalidloss -0.95919  last_update 10\n",
      "train: iter 122  trainloss -0.30668  validloss -0.94264±0.00000  bestvalidloss -0.95919  last_update 11\n",
      "train: iter 123  trainloss -0.28935  validloss -0.91797±0.00000  bestvalidloss -0.95919  last_update 12\n",
      "train: iter 124  trainloss -0.28931  validloss -0.92546±0.00000  bestvalidloss -0.95919  last_update 13\n",
      "train: iter 125  trainloss -0.32420  validloss -0.91756±0.00000  bestvalidloss -0.95919  last_update 14\n",
      "train: iter 126  trainloss -0.31028  validloss -0.94334±0.00000  bestvalidloss -0.95919  last_update 15\n",
      "train: iter 127  trainloss -0.31404  validloss -0.90885±0.00000  bestvalidloss -0.95919  last_update 16\n",
      "train: iter 128  trainloss -0.30368  validloss -0.92606±0.00000  bestvalidloss -0.95919  last_update 17\n",
      "train: iter 129  trainloss -0.30578  validloss -0.92447±0.00000  bestvalidloss -0.95919  last_update 18\n",
      "train: iter 130  trainloss -0.32350  validloss -0.94054±0.00000  bestvalidloss -0.95919  last_update 19\n",
      "train: iter 131  trainloss -0.29398  validloss -0.94931±0.00000  bestvalidloss -0.95919  last_update 20\n",
      "train: iter 132  trainloss -0.30222  validloss -0.92306±0.00000  bestvalidloss -0.95919  last_update 21\n",
      "train: iter 133  trainloss -0.29909  validloss -0.93463±0.00000  bestvalidloss -0.95919  last_update 22\n",
      "train: iter 134  trainloss -0.31153  validloss -0.91603±0.00000  bestvalidloss -0.95919  last_update 23\n",
      "train: iter 135  trainloss -0.28400  validloss -0.94595±0.00000  bestvalidloss -0.95919  last_update 24\n",
      "train: iter 136  trainloss -0.26922  validloss -0.92509±0.00000  bestvalidloss -0.95919  last_update 25\n",
      "train: iter 137  trainloss -0.31161  validloss -0.91322±0.00000  bestvalidloss -0.95919  last_update 26\n",
      "train: iter 138  trainloss -0.31389  validloss -0.91258±0.00000  bestvalidloss -0.95919  last_update 27\n",
      "train: iter 139  trainloss -0.30163  validloss -0.93847±0.00000  bestvalidloss -0.95919  last_update 28\n",
      "train: iter 140  trainloss -0.31783  validloss -0.95175±0.00000  bestvalidloss -0.95919  last_update 29\n",
      "train: iter 141  trainloss -0.28652  validloss -0.93433±0.00000  bestvalidloss -0.95919  last_update 30\n",
      "train: iter 142  trainloss -0.29911  validloss -0.91318±0.00000  bestvalidloss -0.95919  last_update 31\n",
      "train: iter 143  trainloss -0.29727  validloss -0.93668±0.00000  bestvalidloss -0.95919  last_update 32\n",
      "train: iter 144  trainloss -0.27934  validloss -0.92995±0.00000  bestvalidloss -0.95919  last_update 33\n",
      "train: iter 145  trainloss -0.29324  validloss -0.95941±0.00000  bestvalidloss -0.95941  last_update 0\n",
      "train: iter 146  trainloss -0.30129  validloss -0.92729±0.00000  bestvalidloss -0.95941  last_update 1\n",
      "train: iter 147  trainloss -0.31292  validloss -0.90949±0.00000  bestvalidloss -0.95941  last_update 2\n",
      "train: iter 148  trainloss -0.30531  validloss -0.93183±0.00000  bestvalidloss -0.95941  last_update 3\n",
      "train: iter 149  trainloss -0.29861  validloss -0.92072±0.00000  bestvalidloss -0.95941  last_update 4\n",
      "train: iter 150  trainloss -0.32625  validloss -0.93858±0.00000  bestvalidloss -0.95941  last_update 5\n",
      "train: iter 151  trainloss -0.29171  validloss -0.91143±0.00000  bestvalidloss -0.95941  last_update 6\n",
      "train: iter 152  trainloss -0.28623  validloss -0.93758±0.00000  bestvalidloss -0.95941  last_update 7\n",
      "train: iter 153  trainloss -0.30874  validloss -0.91597±0.00000  bestvalidloss -0.95941  last_update 8\n",
      "train: iter 154  trainloss -0.30512  validloss -0.92531±0.00000  bestvalidloss -0.95941  last_update 9\n",
      "train: iter 155  trainloss -0.32265  validloss -0.96300±0.00000  bestvalidloss -0.96300  last_update 0\n",
      "train: iter 156  trainloss -0.28239  validloss -0.94116±0.00000  bestvalidloss -0.96300  last_update 1\n",
      "train: iter 157  trainloss -0.31750  validloss -0.92334±0.00000  bestvalidloss -0.96300  last_update 2\n",
      "train: iter 158  trainloss -0.28018  validloss -0.96119±0.00000  bestvalidloss -0.96300  last_update 3\n",
      "train: iter 159  trainloss -0.30480  validloss -0.91802±0.00000  bestvalidloss -0.96300  last_update 4\n",
      "train: iter 160  trainloss -0.29440  validloss -0.92166±0.00000  bestvalidloss -0.96300  last_update 5\n",
      "train: iter 161  trainloss -0.32331  validloss -0.92389±0.00000  bestvalidloss -0.96300  last_update 6\n",
      "train: iter 162  trainloss -0.29007  validloss -0.92714±0.00000  bestvalidloss -0.96300  last_update 7\n",
      "train: iter 163  trainloss -0.30868  validloss -0.92532±0.00000  bestvalidloss -0.96300  last_update 8\n",
      "train: iter 164  trainloss -0.29239  validloss -0.96594±0.00000  bestvalidloss -0.96594  last_update 0\n",
      "train: iter 165  trainloss -0.32221  validloss -0.90580±0.00000  bestvalidloss -0.96594  last_update 1\n",
      "train: iter 166  trainloss -0.31896  validloss -0.93423±0.00000  bestvalidloss -0.96594  last_update 2\n",
      "train: iter 167  trainloss -0.30023  validloss -0.90798±0.00000  bestvalidloss -0.96594  last_update 3\n",
      "train: iter 168  trainloss -0.30255  validloss -0.89234±0.00000  bestvalidloss -0.96594  last_update 4\n",
      "train: iter 169  trainloss -0.30076  validloss -0.90361±0.00000  bestvalidloss -0.96594  last_update 5\n",
      "train: iter 170  trainloss -0.29104  validloss -0.92593±0.00000  bestvalidloss -0.96594  last_update 6\n",
      "train: iter 171  trainloss -0.28749  validloss -0.92181±0.00000  bestvalidloss -0.96594  last_update 7\n",
      "train: iter 172  trainloss -0.28464  validloss -0.93751±0.00000  bestvalidloss -0.96594  last_update 8\n",
      "train: iter 173  trainloss -0.31303  validloss -0.92186±0.00000  bestvalidloss -0.96594  last_update 9\n",
      "train: iter 174  trainloss -0.30372  validloss -0.93125±0.00000  bestvalidloss -0.96594  last_update 10\n",
      "train: iter 175  trainloss -0.29847  validloss -0.93316±0.00000  bestvalidloss -0.96594  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 176  trainloss -0.30979  validloss -0.93919±0.00000  bestvalidloss -0.96594  last_update 12\n",
      "train: iter 177  trainloss -0.30060  validloss -0.91472±0.00000  bestvalidloss -0.96594  last_update 13\n",
      "train: iter 178  trainloss -0.31078  validloss -0.91542±0.00000  bestvalidloss -0.96594  last_update 14\n",
      "train: iter 179  trainloss -0.29423  validloss -0.90297±0.00000  bestvalidloss -0.96594  last_update 15\n",
      "train: iter 180  trainloss -0.27591  validloss -0.91514±0.00000  bestvalidloss -0.96594  last_update 16\n",
      "train: iter 181  trainloss -0.29473  validloss -0.88395±0.00000  bestvalidloss -0.96594  last_update 17\n",
      "train: iter 182  trainloss -0.29679  validloss -0.93108±0.00000  bestvalidloss -0.96594  last_update 18\n",
      "train: iter 183  trainloss -0.28471  validloss -0.94007±0.00000  bestvalidloss -0.96594  last_update 19\n",
      "train: iter 184  trainloss -0.30005  validloss -0.94467±0.00000  bestvalidloss -0.96594  last_update 20\n",
      "train: iter 185  trainloss -0.30512  validloss -0.92545±0.00000  bestvalidloss -0.96594  last_update 21\n",
      "train: iter 186  trainloss -0.31494  validloss -0.90651±0.00000  bestvalidloss -0.96594  last_update 22\n",
      "train: iter 187  trainloss -0.27556  validloss -0.93138±0.00000  bestvalidloss -0.96594  last_update 23\n",
      "train: iter 188  trainloss -0.28854  validloss -0.91797±0.00000  bestvalidloss -0.96594  last_update 24\n",
      "train: iter 189  trainloss -0.31890  validloss -0.92415±0.00000  bestvalidloss -0.96594  last_update 25\n",
      "train: iter 190  trainloss -0.28887  validloss -0.96203±0.00000  bestvalidloss -0.96594  last_update 26\n",
      "train: iter 191  trainloss -0.27626  validloss -0.90728±0.00000  bestvalidloss -0.96594  last_update 27\n",
      "train: iter 192  trainloss -0.28643  validloss -0.91968±0.00000  bestvalidloss -0.96594  last_update 28\n",
      "train: iter 193  trainloss -0.28644  validloss -0.93935±0.00000  bestvalidloss -0.96594  last_update 29\n",
      "train: iter 194  trainloss -0.29034  validloss -0.92215±0.00000  bestvalidloss -0.96594  last_update 30\n",
      "train: iter 195  trainloss -0.31292  validloss -0.90858±0.00000  bestvalidloss -0.96594  last_update 31\n",
      "train: iter 196  trainloss -0.27265  validloss -0.91064±0.00000  bestvalidloss -0.96594  last_update 32\n",
      "train: iter 197  trainloss -0.30434  validloss -0.92444±0.00000  bestvalidloss -0.96594  last_update 33\n",
      "train: iter 198  trainloss -0.30380  validloss -0.92110±0.00000  bestvalidloss -0.96594  last_update 34\n",
      "train: iter 199  trainloss -0.30218  validloss -0.94409±0.00000  bestvalidloss -0.96594  last_update 35\n",
      "train: iter 200  trainloss -0.29802  validloss -0.93303±0.00000  bestvalidloss -0.96594  last_update 36\n",
      "train: iter 201  trainloss -0.29552  validloss -0.92276±0.00000  bestvalidloss -0.96594  last_update 37\n",
      "train: iter 202  trainloss -0.30957  validloss -0.89349±0.00000  bestvalidloss -0.96594  last_update 38\n",
      "train: iter 203  trainloss -0.28980  validloss -0.95336±0.00000  bestvalidloss -0.96594  last_update 39\n",
      "train: iter 204  trainloss -0.29604  validloss -0.93314±0.00000  bestvalidloss -0.96594  last_update 40\n",
      "train: iter 205  trainloss -0.29193  validloss -0.91155±0.00000  bestvalidloss -0.96594  last_update 41\n",
      "train: iter 206  trainloss -0.29380  validloss -0.91079±0.00000  bestvalidloss -0.96594  last_update 42\n",
      "train: iter 207  trainloss -0.30192  validloss -0.93732±0.00000  bestvalidloss -0.96594  last_update 43\n",
      "train: iter 208  trainloss -0.30018  validloss -0.94069±0.00000  bestvalidloss -0.96594  last_update 44\n",
      "train: iter 209  trainloss -0.27940  validloss -0.93248±0.00000  bestvalidloss -0.96594  last_update 45\n",
      "train: iter 210  trainloss -0.27487  validloss -0.95251±0.00000  bestvalidloss -0.96594  last_update 46\n",
      "train: iter 211  trainloss -0.29534  validloss -0.90852±0.00000  bestvalidloss -0.96594  last_update 47\n",
      "train: iter 212  trainloss -0.30264  validloss -0.89841±0.00000  bestvalidloss -0.96594  last_update 48\n",
      "train: iter 213  trainloss -0.31164  validloss -0.90669±0.00000  bestvalidloss -0.96594  last_update 49\n",
      "train: iter 214  trainloss -0.28752  validloss -0.91619±0.00000  bestvalidloss -0.96594  last_update 50\n",
      "train: iter 215  trainloss -0.28450  validloss -0.92397±0.00000  bestvalidloss -0.96594  last_update 51\n",
      "train: iter 216  trainloss -0.32076  validloss -0.92954±0.00000  bestvalidloss -0.96594  last_update 52\n",
      "train: iter 217  trainloss -0.30837  validloss -0.91411±0.00000  bestvalidloss -0.96594  last_update 53\n",
      "train: iter 218  trainloss -0.31489  validloss -0.92346±0.00000  bestvalidloss -0.96594  last_update 54\n",
      "train: iter 219  trainloss -0.31047  validloss -0.91054±0.00000  bestvalidloss -0.96594  last_update 55\n",
      "train: iter 220  trainloss -0.30168  validloss -0.94827±0.00000  bestvalidloss -0.96594  last_update 56\n",
      "train: iter 221  trainloss -0.29233  validloss -0.90820±0.00000  bestvalidloss -0.96594  last_update 57\n",
      "train: iter 222  trainloss -0.30766  validloss -0.93531±0.00000  bestvalidloss -0.96594  last_update 58\n",
      "train: iter 223  trainloss -0.31587  validloss -0.95438±0.00000  bestvalidloss -0.96594  last_update 59\n",
      "train: iter 224  trainloss -0.31749  validloss -0.91243±0.00000  bestvalidloss -0.96594  last_update 60\n",
      "train: iter 225  trainloss -0.31113  validloss -0.96308±0.00000  bestvalidloss -0.96594  last_update 61\n",
      "train: iter 226  trainloss -0.29584  validloss -0.94255±0.00000  bestvalidloss -0.96594  last_update 62\n",
      "train: iter 227  trainloss -0.29724  validloss -0.94860±0.00000  bestvalidloss -0.96594  last_update 63\n",
      "train: iter 228  trainloss -0.27369  validloss -0.93289±0.00000  bestvalidloss -0.96594  last_update 64\n",
      "train: iter 229  trainloss -0.30158  validloss -0.95315±0.00000  bestvalidloss -0.96594  last_update 65\n",
      "train: iter 230  trainloss -0.31405  validloss -0.90502±0.00000  bestvalidloss -0.96594  last_update 66\n",
      "train: iter 231  trainloss -0.30579  validloss -0.91459±0.00000  bestvalidloss -0.96594  last_update 67\n",
      "train: iter 232  trainloss -0.31298  validloss -0.94069±0.00000  bestvalidloss -0.96594  last_update 68\n",
      "train: iter 233  trainloss -0.32206  validloss -0.90566±0.00000  bestvalidloss -0.96594  last_update 69\n",
      "train: iter 234  trainloss -0.28897  validloss -0.91762±0.00000  bestvalidloss -0.96594  last_update 70\n",
      "train: iter 235  trainloss -0.32001  validloss -0.92804±0.00000  bestvalidloss -0.96594  last_update 71\n",
      "train: iter 236  trainloss -0.29576  validloss -0.90765±0.00000  bestvalidloss -0.96594  last_update 72\n",
      "train: iter 237  trainloss -0.31233  validloss -0.92023±0.00000  bestvalidloss -0.96594  last_update 73\n",
      "train: iter 238  trainloss -0.31963  validloss -0.94049±0.00000  bestvalidloss -0.96594  last_update 74\n",
      "train: iter 239  trainloss -0.31327  validloss -0.92856±0.00000  bestvalidloss -0.96594  last_update 75\n",
      "train: iter 240  trainloss -0.30474  validloss -0.94408±0.00000  bestvalidloss -0.96594  last_update 76\n",
      "train: iter 241  trainloss -0.30841  validloss -0.92291±0.00000  bestvalidloss -0.96594  last_update 77\n",
      "train: iter 242  trainloss -0.30303  validloss -0.94516±0.00000  bestvalidloss -0.96594  last_update 78\n",
      "train: iter 243  trainloss -0.27036  validloss -0.89340±0.00000  bestvalidloss -0.96594  last_update 79\n",
      "train: iter 244  trainloss -0.27844  validloss -0.93975±0.00000  bestvalidloss -0.96594  last_update 80\n",
      "train: iter 245  trainloss -0.30133  validloss -0.94997±0.00000  bestvalidloss -0.96594  last_update 81\n",
      "train: iter 246  trainloss -0.30792  validloss -0.92264±0.00000  bestvalidloss -0.96594  last_update 82\n",
      "train: iter 247  trainloss -0.30888  validloss -0.91248±0.00000  bestvalidloss -0.96594  last_update 83\n",
      "train: iter 248  trainloss -0.29781  validloss -0.93430±0.00000  bestvalidloss -0.96594  last_update 84\n",
      "train: iter 249  trainloss -0.28162  validloss -0.94283±0.00000  bestvalidloss -0.96594  last_update 85\n",
      "train: iter 250  trainloss -0.30269  validloss -0.93289±0.00000  bestvalidloss -0.96594  last_update 86\n",
      "train: iter 251  trainloss -0.29711  validloss -0.90289±0.00000  bestvalidloss -0.96594  last_update 87\n",
      "train: iter 252  trainloss -0.32551  validloss -0.90485±0.00000  bestvalidloss -0.96594  last_update 88\n",
      "train: iter 253  trainloss -0.31845  validloss -0.93118±0.00000  bestvalidloss -0.96594  last_update 89\n",
      "train: iter 254  trainloss -0.31020  validloss -0.93362±0.00000  bestvalidloss -0.96594  last_update 90\n",
      "train: iter 255  trainloss -0.31018  validloss -0.95115±0.00000  bestvalidloss -0.96594  last_update 91\n",
      "train: iter 256  trainloss -0.32161  validloss -0.92816±0.00000  bestvalidloss -0.96594  last_update 92\n",
      "train: iter 257  trainloss -0.29861  validloss -0.91425±0.00000  bestvalidloss -0.96594  last_update 93\n",
      "train: iter 258  trainloss -0.27799  validloss -0.95132±0.00000  bestvalidloss -0.96594  last_update 94\n",
      "train: iter 259  trainloss -0.30390  validloss -0.94329±0.00000  bestvalidloss -0.96594  last_update 95\n",
      "train: iter 260  trainloss -0.30922  validloss -0.94098±0.00000  bestvalidloss -0.96594  last_update 96\n",
      "train: iter 261  trainloss -0.28688  validloss -0.94909±0.00000  bestvalidloss -0.96594  last_update 97\n",
      "train: iter 262  trainloss -0.29055  validloss -0.92824±0.00000  bestvalidloss -0.96594  last_update 98\n",
      "train: iter 263  trainloss -0.31108  validloss -0.91994±0.00000  bestvalidloss -0.96594  last_update 99\n",
      "train: iter 264  trainloss -0.27989  validloss -0.94345±0.00000  bestvalidloss -0.96594  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.0813, -0.7511, -3.2449, -3.0334], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 102.76296  validloss 116.41215±0.00000  bestvalidloss 116.41215  last_update 0\n",
      "train: iter 1  trainloss 73.83728  validloss 87.47045±0.00000  bestvalidloss 87.47045  last_update 0\n",
      "train: iter 2  trainloss 53.95296  validloss 62.15497±0.00000  bestvalidloss 62.15497  last_update 0\n",
      "train: iter 3  trainloss 40.68923  validloss 46.49311±0.00000  bestvalidloss 46.49311  last_update 0\n",
      "train: iter 4  trainloss 31.51271  validloss 35.36548±0.00000  bestvalidloss 35.36548  last_update 0\n",
      "train: iter 5  trainloss 24.73403  validloss 27.88820±0.00000  bestvalidloss 27.88820  last_update 0\n",
      "train: iter 6  trainloss 19.59544  validloss 21.65169±0.00000  bestvalidloss 21.65169  last_update 0\n",
      "train: iter 7  trainloss 15.55096  validloss 17.42300±0.00000  bestvalidloss 17.42300  last_update 0\n",
      "train: iter 8  trainloss 12.40358  validloss 13.74531±0.00000  bestvalidloss 13.74531  last_update 0\n",
      "train: iter 9  trainloss 10.00669  validloss 10.82656±0.00000  bestvalidloss 10.82656  last_update 0\n",
      "train: iter 10  trainloss 7.99448  validloss 8.81196±0.00000  bestvalidloss 8.81196  last_update 0\n",
      "train: iter 11  trainloss 6.64544  validloss 7.32528±0.00000  bestvalidloss 7.32528  last_update 0\n",
      "train: iter 12  trainloss 5.53208  validloss 6.00504±0.00000  bestvalidloss 6.00504  last_update 0\n",
      "train: iter 13  trainloss 4.77213  validloss 4.94528±0.00000  bestvalidloss 4.94528  last_update 0\n",
      "train: iter 14  trainloss 4.15216  validloss 4.33081±0.00000  bestvalidloss 4.33081  last_update 0\n",
      "train: iter 15  trainloss 3.72271  validloss 3.68647±0.00000  bestvalidloss 3.68647  last_update 0\n",
      "train: iter 16  trainloss 3.42442  validloss 3.54488±0.00000  bestvalidloss 3.54488  last_update 0\n",
      "train: iter 17  trainloss 3.21317  validloss 3.03257±0.00000  bestvalidloss 3.03257  last_update 0\n",
      "train: iter 18  trainloss 3.10221  validloss 2.99200±0.00000  bestvalidloss 2.99200  last_update 0\n",
      "train: iter 19  trainloss 2.95837  validloss 2.55749±0.00000  bestvalidloss 2.55749  last_update 0\n",
      "train: iter 20  trainloss 2.97124  validloss 2.89574±0.00000  bestvalidloss 2.55749  last_update 1\n",
      "train: iter 21  trainloss 2.83941  validloss 2.78408±0.00000  bestvalidloss 2.55749  last_update 2\n",
      "train: iter 22  trainloss 2.81031  validloss 2.66908±0.00000  bestvalidloss 2.55749  last_update 3\n",
      "train: iter 23  trainloss 2.79391  validloss 2.54280±0.00000  bestvalidloss 2.54280  last_update 0\n",
      "train: iter 24  trainloss 2.77429  validloss 2.55363±0.00000  bestvalidloss 2.54280  last_update 1\n",
      "train: iter 25  trainloss 2.73846  validloss 2.49690±0.00000  bestvalidloss 2.49690  last_update 0\n",
      "train: iter 26  trainloss 2.71269  validloss 2.44197±0.00000  bestvalidloss 2.44197  last_update 0\n",
      "train: iter 27  trainloss 2.67339  validloss 2.73136±0.00000  bestvalidloss 2.44197  last_update 1\n",
      "train: iter 28  trainloss 2.60948  validloss 2.60711±0.00000  bestvalidloss 2.44197  last_update 2\n",
      "train: iter 29  trainloss 2.46944  validloss 2.65790±0.00000  bestvalidloss 2.44197  last_update 3\n",
      "train: iter 30  trainloss 2.27862  validloss 2.50179±0.00000  bestvalidloss 2.44197  last_update 4\n",
      "train: iter 31  trainloss 2.13002  validloss 2.81146±0.00000  bestvalidloss 2.44197  last_update 5\n",
      "train: iter 32  trainloss 2.03632  validloss 2.58269±0.00000  bestvalidloss 2.44197  last_update 6\n",
      "train: iter 33  trainloss 1.99540  validloss 2.54363±0.00000  bestvalidloss 2.44197  last_update 7\n",
      "train: iter 34  trainloss 1.96264  validloss 2.56643±0.00000  bestvalidloss 2.44197  last_update 8\n",
      "train: iter 35  trainloss 1.90483  validloss 2.61469±0.00000  bestvalidloss 2.44197  last_update 9\n",
      "train: iter 36  trainloss 1.90048  validloss 2.63645±0.00000  bestvalidloss 2.44197  last_update 10\n",
      "train: iter 37  trainloss 1.85983  validloss 2.64594±0.00000  bestvalidloss 2.44197  last_update 11\n",
      "train: iter 38  trainloss 1.81879  validloss 2.55777±0.00000  bestvalidloss 2.44197  last_update 12\n",
      "train: iter 39  trainloss 1.80834  validloss 2.40855±0.00000  bestvalidloss 2.40855  last_update 0\n",
      "train: iter 40  trainloss 1.80913  validloss 2.49430±0.00000  bestvalidloss 2.40855  last_update 1\n",
      "train: iter 41  trainloss 1.74377  validloss 2.51061±0.00000  bestvalidloss 2.40855  last_update 2\n",
      "train: iter 42  trainloss 1.76437  validloss 2.70801±0.00000  bestvalidloss 2.40855  last_update 3\n",
      "train: iter 43  trainloss 1.78486  validloss 2.61229±0.00000  bestvalidloss 2.40855  last_update 4\n",
      "train: iter 44  trainloss 1.74241  validloss 2.73743±0.00000  bestvalidloss 2.40855  last_update 5\n",
      "train: iter 45  trainloss 1.72927  validloss 2.37628±0.00000  bestvalidloss 2.37628  last_update 0\n",
      "train: iter 46  trainloss 1.71524  validloss 2.75001±0.00000  bestvalidloss 2.37628  last_update 1\n",
      "train: iter 47  trainloss 1.73825  validloss 2.57821±0.00000  bestvalidloss 2.37628  last_update 2\n",
      "train: iter 48  trainloss 1.71341  validloss 2.49154±0.00000  bestvalidloss 2.37628  last_update 3\n",
      "train: iter 49  trainloss 1.71052  validloss 2.63295±0.00000  bestvalidloss 2.37628  last_update 4\n",
      "train: iter 50  trainloss 1.73127  validloss 2.66266±0.00000  bestvalidloss 2.37628  last_update 5\n",
      "train: iter 51  trainloss 1.69742  validloss 2.78577±0.00000  bestvalidloss 2.37628  last_update 6\n",
      "train: iter 52  trainloss 1.69514  validloss 2.54807±0.00000  bestvalidloss 2.37628  last_update 7\n",
      "train: iter 53  trainloss 1.70497  validloss 2.56044±0.00000  bestvalidloss 2.37628  last_update 8\n",
      "train: iter 54  trainloss 1.67076  validloss 2.61013±0.00000  bestvalidloss 2.37628  last_update 9\n",
      "train: iter 55  trainloss 1.65433  validloss 2.49544±0.00000  bestvalidloss 2.37628  last_update 10\n",
      "train: iter 56  trainloss 1.65883  validloss 2.75324±0.00000  bestvalidloss 2.37628  last_update 11\n",
      "train: iter 57  trainloss 1.64108  validloss 2.77913±0.00000  bestvalidloss 2.37628  last_update 12\n",
      "train: iter 58  trainloss 1.60492  validloss 2.67546±0.00000  bestvalidloss 2.37628  last_update 13\n",
      "train: iter 59  trainloss 1.59581  validloss 2.57522±0.00000  bestvalidloss 2.37628  last_update 14\n",
      "train: iter 60  trainloss 1.61498  validloss 2.95700±0.00000  bestvalidloss 2.37628  last_update 15\n",
      "train: iter 61  trainloss 1.59130  validloss 2.59319±0.00000  bestvalidloss 2.37628  last_update 16\n",
      "train: iter 62  trainloss 1.60109  validloss 2.73468±0.00000  bestvalidloss 2.37628  last_update 17\n",
      "train: iter 63  trainloss 1.57988  validloss 2.58374±0.00000  bestvalidloss 2.37628  last_update 18\n",
      "train: iter 64  trainloss 1.57502  validloss 2.57016±0.00000  bestvalidloss 2.37628  last_update 19\n",
      "train: iter 65  trainloss 1.55215  validloss 2.59021±0.00000  bestvalidloss 2.37628  last_update 20\n",
      "train: iter 66  trainloss 1.55049  validloss 2.97846±0.00000  bestvalidloss 2.37628  last_update 21\n",
      "train: iter 67  trainloss 1.52322  validloss 2.57356±0.00000  bestvalidloss 2.37628  last_update 22\n",
      "train: iter 68  trainloss 1.53846  validloss 2.65338±0.00000  bestvalidloss 2.37628  last_update 23\n",
      "train: iter 69  trainloss 1.53189  validloss 2.63627±0.00000  bestvalidloss 2.37628  last_update 24\n",
      "train: iter 70  trainloss 1.51347  validloss 2.41513±0.00000  bestvalidloss 2.37628  last_update 25\n",
      "train: iter 71  trainloss 1.48690  validloss 2.52973±0.00000  bestvalidloss 2.37628  last_update 26\n",
      "train: iter 72  trainloss 1.51358  validloss 3.11063±0.00000  bestvalidloss 2.37628  last_update 27\n",
      "train: iter 73  trainloss 1.46985  validloss 2.70958±0.00000  bestvalidloss 2.37628  last_update 28\n",
      "train: iter 74  trainloss 1.48058  validloss 2.38295±0.00000  bestvalidloss 2.37628  last_update 29\n",
      "train: iter 75  trainloss 1.48838  validloss 2.65056±0.00000  bestvalidloss 2.37628  last_update 30\n",
      "train: iter 76  trainloss 1.50863  validloss 2.34463±0.00000  bestvalidloss 2.34463  last_update 0\n",
      "train: iter 77  trainloss 1.48383  validloss 2.68028±0.00000  bestvalidloss 2.34463  last_update 1\n",
      "train: iter 78  trainloss 1.51409  validloss 2.85295±0.00000  bestvalidloss 2.34463  last_update 2\n",
      "train: iter 79  trainloss 1.49613  validloss 2.61136±0.00000  bestvalidloss 2.34463  last_update 3\n",
      "train: iter 80  trainloss 1.47594  validloss 2.62894±0.00000  bestvalidloss 2.34463  last_update 4\n",
      "train: iter 81  trainloss 1.49811  validloss 2.67143±0.00000  bestvalidloss 2.34463  last_update 5\n",
      "train: iter 82  trainloss 1.47682  validloss 2.71331±0.00000  bestvalidloss 2.34463  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.46865  validloss 2.69849±0.00000  bestvalidloss 2.34463  last_update 7\n",
      "train: iter 84  trainloss 1.47933  validloss 2.86048±0.00000  bestvalidloss 2.34463  last_update 8\n",
      "train: iter 85  trainloss 1.42970  validloss 2.89094±0.00000  bestvalidloss 2.34463  last_update 9\n",
      "train: iter 86  trainloss 1.47598  validloss 2.34369±0.00000  bestvalidloss 2.34369  last_update 0\n",
      "train: iter 87  trainloss 1.49539  validloss 2.57721±0.00000  bestvalidloss 2.34369  last_update 1\n",
      "train: iter 88  trainloss 1.45328  validloss 2.68002±0.00000  bestvalidloss 2.34369  last_update 2\n",
      "train: iter 89  trainloss 1.43387  validloss 2.79778±0.00000  bestvalidloss 2.34369  last_update 3\n",
      "train: iter 90  trainloss 1.43400  validloss 2.55854±0.00000  bestvalidloss 2.34369  last_update 4\n",
      "train: iter 91  trainloss 1.47192  validloss 2.56649±0.00000  bestvalidloss 2.34369  last_update 5\n",
      "train: iter 92  trainloss 1.43770  validloss 2.74719±0.00000  bestvalidloss 2.34369  last_update 6\n",
      "train: iter 93  trainloss 1.43958  validloss 3.00699±0.00000  bestvalidloss 2.34369  last_update 7\n",
      "train: iter 94  trainloss 1.47533  validloss 2.61522±0.00000  bestvalidloss 2.34369  last_update 8\n",
      "train: iter 95  trainloss 1.47602  validloss 2.96137±0.00000  bestvalidloss 2.34369  last_update 9\n",
      "train: iter 96  trainloss 1.43581  validloss 2.81607±0.00000  bestvalidloss 2.34369  last_update 10\n",
      "train: iter 97  trainloss 1.45443  validloss 2.92539±0.00000  bestvalidloss 2.34369  last_update 11\n",
      "train: iter 98  trainloss 1.43641  validloss 2.70419±0.00000  bestvalidloss 2.34369  last_update 12\n",
      "train: iter 99  trainloss 1.44794  validloss 2.80277±0.00000  bestvalidloss 2.34369  last_update 13\n",
      "train: iter 100  trainloss 1.40953  validloss 2.58537±0.00000  bestvalidloss 2.34369  last_update 14\n",
      "train: iter 101  trainloss 1.44090  validloss 2.67211±0.00000  bestvalidloss 2.34369  last_update 15\n",
      "train: iter 102  trainloss 1.39498  validloss 2.60215±0.00000  bestvalidloss 2.34369  last_update 16\n",
      "train: iter 103  trainloss 1.42155  validloss 2.87934±0.00000  bestvalidloss 2.34369  last_update 17\n",
      "train: iter 104  trainloss 1.40945  validloss 2.77073±0.00000  bestvalidloss 2.34369  last_update 18\n",
      "train: iter 105  trainloss 1.41091  validloss 2.58859±0.00000  bestvalidloss 2.34369  last_update 19\n",
      "train: iter 106  trainloss 1.46399  validloss 2.67342±0.00000  bestvalidloss 2.34369  last_update 20\n",
      "train: iter 107  trainloss 1.40177  validloss 2.77367±0.00000  bestvalidloss 2.34369  last_update 21\n",
      "train: iter 108  trainloss 1.41874  validloss 2.81844±0.00000  bestvalidloss 2.34369  last_update 22\n",
      "train: iter 109  trainloss 1.37475  validloss 2.84041±0.00000  bestvalidloss 2.34369  last_update 23\n",
      "train: iter 110  trainloss 1.42400  validloss 2.49407±0.00000  bestvalidloss 2.34369  last_update 24\n",
      "train: iter 111  trainloss 1.43637  validloss 2.78742±0.00000  bestvalidloss 2.34369  last_update 25\n",
      "train: iter 112  trainloss 1.41496  validloss 2.69151±0.00000  bestvalidloss 2.34369  last_update 26\n",
      "train: iter 113  trainloss 1.46169  validloss 3.09495±0.00000  bestvalidloss 2.34369  last_update 27\n",
      "train: iter 114  trainloss 1.42277  validloss 2.71128±0.00000  bestvalidloss 2.34369  last_update 28\n",
      "train: iter 115  trainloss 1.43221  validloss 2.60108±0.00000  bestvalidloss 2.34369  last_update 29\n",
      "train: iter 116  trainloss 1.43493  validloss 2.59170±0.00000  bestvalidloss 2.34369  last_update 30\n",
      "train: iter 117  trainloss 1.39725  validloss 2.68541±0.00000  bestvalidloss 2.34369  last_update 31\n",
      "train: iter 118  trainloss 1.41856  validloss 2.74851±0.00000  bestvalidloss 2.34369  last_update 32\n",
      "train: iter 119  trainloss 1.39728  validloss 3.03019±0.00000  bestvalidloss 2.34369  last_update 33\n",
      "train: iter 120  trainloss 1.41936  validloss 2.87709±0.00000  bestvalidloss 2.34369  last_update 34\n",
      "train: iter 121  trainloss 1.39702  validloss 2.51760±0.00000  bestvalidloss 2.34369  last_update 35\n",
      "train: iter 122  trainloss 1.41662  validloss 2.96114±0.00000  bestvalidloss 2.34369  last_update 36\n",
      "train: iter 123  trainloss 1.39369  validloss 3.07041±0.00000  bestvalidloss 2.34369  last_update 37\n",
      "train: iter 124  trainloss 1.42329  validloss 3.06777±0.00000  bestvalidloss 2.34369  last_update 38\n",
      "train: iter 125  trainloss 1.43322  validloss 2.56690±0.00000  bestvalidloss 2.34369  last_update 39\n",
      "train: iter 126  trainloss 1.40007  validloss 2.96163±0.00000  bestvalidloss 2.34369  last_update 40\n",
      "train: iter 127  trainloss 1.42436  validloss 2.58035±0.00000  bestvalidloss 2.34369  last_update 41\n",
      "train: iter 128  trainloss 1.41796  validloss 2.65864±0.00000  bestvalidloss 2.34369  last_update 42\n",
      "train: iter 129  trainloss 1.42491  validloss 2.57419±0.00000  bestvalidloss 2.34369  last_update 43\n",
      "train: iter 130  trainloss 1.43129  validloss 2.63463±0.00000  bestvalidloss 2.34369  last_update 44\n",
      "train: iter 131  trainloss 1.40596  validloss 2.83756±0.00000  bestvalidloss 2.34369  last_update 45\n",
      "train: iter 132  trainloss 1.41064  validloss 2.75263±0.00000  bestvalidloss 2.34369  last_update 46\n",
      "train: iter 133  trainloss 1.38175  validloss 2.83251±0.00000  bestvalidloss 2.34369  last_update 47\n",
      "train: iter 134  trainloss 1.37236  validloss 2.87493±0.00000  bestvalidloss 2.34369  last_update 48\n",
      "train: iter 135  trainloss 1.44395  validloss 2.89097±0.00000  bestvalidloss 2.34369  last_update 49\n",
      "train: iter 136  trainloss 1.41298  validloss 2.79760±0.00000  bestvalidloss 2.34369  last_update 50\n",
      "train: iter 137  trainloss 1.40940  validloss 2.64045±0.00000  bestvalidloss 2.34369  last_update 51\n",
      "train: iter 138  trainloss 1.42612  validloss 2.97653±0.00000  bestvalidloss 2.34369  last_update 52\n",
      "train: iter 139  trainloss 1.41310  validloss 2.82155±0.00000  bestvalidloss 2.34369  last_update 53\n",
      "train: iter 140  trainloss 1.43701  validloss 3.10433±0.00000  bestvalidloss 2.34369  last_update 54\n",
      "train: iter 141  trainloss 1.38658  validloss 2.67489±0.00000  bestvalidloss 2.34369  last_update 55\n",
      "train: iter 142  trainloss 1.43114  validloss 2.57736±0.00000  bestvalidloss 2.34369  last_update 56\n",
      "train: iter 143  trainloss 1.40139  validloss 2.93125±0.00000  bestvalidloss 2.34369  last_update 57\n",
      "train: iter 144  trainloss 1.39189  validloss 2.58206±0.00000  bestvalidloss 2.34369  last_update 58\n",
      "train: iter 145  trainloss 1.42998  validloss 2.71786±0.00000  bestvalidloss 2.34369  last_update 59\n",
      "train: iter 146  trainloss 1.38639  validloss 2.83524±0.00000  bestvalidloss 2.34369  last_update 60\n",
      "train: iter 147  trainloss 1.37910  validloss 2.57966±0.00000  bestvalidloss 2.34369  last_update 61\n",
      "train: iter 148  trainloss 1.37453  validloss 2.61186±0.00000  bestvalidloss 2.34369  last_update 62\n",
      "train: iter 149  trainloss 1.40813  validloss 2.96539±0.00000  bestvalidloss 2.34369  last_update 63\n",
      "train: iter 150  trainloss 1.37780  validloss 2.45327±0.00000  bestvalidloss 2.34369  last_update 64\n",
      "train: iter 151  trainloss 1.40913  validloss 2.71767±0.00000  bestvalidloss 2.34369  last_update 65\n",
      "train: iter 152  trainloss 1.39428  validloss 2.79617±0.00000  bestvalidloss 2.34369  last_update 66\n",
      "train: iter 153  trainloss 1.40734  validloss 2.62280±0.00000  bestvalidloss 2.34369  last_update 67\n",
      "train: iter 154  trainloss 1.41411  validloss 2.20472±0.00000  bestvalidloss 2.20472  last_update 0\n",
      "train: iter 155  trainloss 1.39786  validloss 2.74466±0.00000  bestvalidloss 2.20472  last_update 1\n",
      "train: iter 156  trainloss 1.39727  validloss 2.80957±0.00000  bestvalidloss 2.20472  last_update 2\n",
      "train: iter 157  trainloss 1.41616  validloss 2.54571±0.00000  bestvalidloss 2.20472  last_update 3\n",
      "train: iter 158  trainloss 1.40522  validloss 2.37785±0.00000  bestvalidloss 2.20472  last_update 4\n",
      "train: iter 159  trainloss 1.39480  validloss 2.77954±0.00000  bestvalidloss 2.20472  last_update 5\n",
      "train: iter 160  trainloss 1.38571  validloss 2.54279±0.00000  bestvalidloss 2.20472  last_update 6\n",
      "train: iter 161  trainloss 1.40559  validloss 2.54182±0.00000  bestvalidloss 2.20472  last_update 7\n",
      "train: iter 162  trainloss 1.37876  validloss 2.36449±0.00000  bestvalidloss 2.20472  last_update 8\n",
      "train: iter 163  trainloss 1.39507  validloss 2.52608±0.00000  bestvalidloss 2.20472  last_update 9\n",
      "train: iter 164  trainloss 1.37435  validloss 2.54553±0.00000  bestvalidloss 2.20472  last_update 10\n",
      "train: iter 165  trainloss 1.43757  validloss 2.74397±0.00000  bestvalidloss 2.20472  last_update 11\n",
      "train: iter 166  trainloss 1.37564  validloss 2.63550±0.00000  bestvalidloss 2.20472  last_update 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 1.41173  validloss 2.82712±0.00000  bestvalidloss 2.20472  last_update 13\n",
      "train: iter 168  trainloss 1.40456  validloss 2.61753±0.00000  bestvalidloss 2.20472  last_update 14\n",
      "train: iter 169  trainloss 1.42434  validloss 2.47144±0.00000  bestvalidloss 2.20472  last_update 15\n",
      "train: iter 170  trainloss 1.40026  validloss 2.70911±0.00000  bestvalidloss 2.20472  last_update 16\n",
      "train: iter 171  trainloss 1.38865  validloss 2.79769±0.00000  bestvalidloss 2.20472  last_update 17\n",
      "train: iter 172  trainloss 1.37977  validloss 2.65935±0.00000  bestvalidloss 2.20472  last_update 18\n",
      "train: iter 173  trainloss 1.40941  validloss 2.70135±0.00000  bestvalidloss 2.20472  last_update 19\n",
      "train: iter 174  trainloss 1.38809  validloss 2.54502±0.00000  bestvalidloss 2.20472  last_update 20\n",
      "train: iter 175  trainloss 1.39660  validloss 2.70669±0.00000  bestvalidloss 2.20472  last_update 21\n",
      "train: iter 176  trainloss 1.41232  validloss 2.87801±0.00000  bestvalidloss 2.20472  last_update 22\n",
      "train: iter 177  trainloss 1.42523  validloss 2.75621±0.00000  bestvalidloss 2.20472  last_update 23\n",
      "train: iter 178  trainloss 1.39895  validloss 2.42609±0.00000  bestvalidloss 2.20472  last_update 24\n",
      "train: iter 179  trainloss 1.36857  validloss 2.50167±0.00000  bestvalidloss 2.20472  last_update 25\n",
      "train: iter 180  trainloss 1.37613  validloss 2.58272±0.00000  bestvalidloss 2.20472  last_update 26\n",
      "train: iter 181  trainloss 1.39485  validloss 2.65211±0.00000  bestvalidloss 2.20472  last_update 27\n",
      "train: iter 182  trainloss 1.40092  validloss 2.56963±0.00000  bestvalidloss 2.20472  last_update 28\n",
      "train: iter 183  trainloss 1.39145  validloss 2.59905±0.00000  bestvalidloss 2.20472  last_update 29\n",
      "train: iter 184  trainloss 1.41628  validloss 2.47269±0.00000  bestvalidloss 2.20472  last_update 30\n",
      "train: iter 185  trainloss 1.41979  validloss 2.68476±0.00000  bestvalidloss 2.20472  last_update 31\n",
      "train: iter 186  trainloss 1.37219  validloss 2.70974±0.00000  bestvalidloss 2.20472  last_update 32\n",
      "train: iter 187  trainloss 1.37909  validloss 2.72259±0.00000  bestvalidloss 2.20472  last_update 33\n",
      "train: iter 188  trainloss 1.41416  validloss 3.01641±0.00000  bestvalidloss 2.20472  last_update 34\n",
      "train: iter 189  trainloss 1.38396  validloss 2.71463±0.00000  bestvalidloss 2.20472  last_update 35\n",
      "train: iter 190  trainloss 1.39930  validloss 2.57363±0.00000  bestvalidloss 2.20472  last_update 36\n",
      "train: iter 191  trainloss 1.39989  validloss 2.71564±0.00000  bestvalidloss 2.20472  last_update 37\n",
      "train: iter 192  trainloss 1.39621  validloss 2.54587±0.00000  bestvalidloss 2.20472  last_update 38\n",
      "train: iter 193  trainloss 1.41040  validloss 2.95281±0.00000  bestvalidloss 2.20472  last_update 39\n",
      "train: iter 194  trainloss 1.37035  validloss 2.67545±0.00000  bestvalidloss 2.20472  last_update 40\n",
      "train: iter 195  trainloss 1.36511  validloss 2.76678±0.00000  bestvalidloss 2.20472  last_update 41\n",
      "train: iter 196  trainloss 1.40891  validloss 2.62770±0.00000  bestvalidloss 2.20472  last_update 42\n",
      "train: iter 197  trainloss 1.36217  validloss 2.79785±0.00000  bestvalidloss 2.20472  last_update 43\n",
      "train: iter 198  trainloss 1.39925  validloss 2.81784±0.00000  bestvalidloss 2.20472  last_update 44\n",
      "train: iter 199  trainloss 1.40796  validloss 2.54674±0.00000  bestvalidloss 2.20472  last_update 45\n",
      "train: iter 200  trainloss 1.36676  validloss 2.29893±0.00000  bestvalidloss 2.20472  last_update 46\n",
      "train: iter 201  trainloss 1.38967  validloss 2.59160±0.00000  bestvalidloss 2.20472  last_update 47\n",
      "train: iter 202  trainloss 1.40934  validloss 2.56232±0.00000  bestvalidloss 2.20472  last_update 48\n",
      "train: iter 203  trainloss 1.40162  validloss 2.73858±0.00000  bestvalidloss 2.20472  last_update 49\n",
      "train: iter 204  trainloss 1.38263  validloss 2.45430±0.00000  bestvalidloss 2.20472  last_update 50\n",
      "train: iter 205  trainloss 1.36028  validloss 2.66303±0.00000  bestvalidloss 2.20472  last_update 51\n",
      "train: iter 206  trainloss 1.37317  validloss 2.61966±0.00000  bestvalidloss 2.20472  last_update 52\n",
      "train: iter 207  trainloss 1.39957  validloss 2.70146±0.00000  bestvalidloss 2.20472  last_update 53\n",
      "train: iter 208  trainloss 1.38189  validloss 2.52266±0.00000  bestvalidloss 2.20472  last_update 54\n",
      "train: iter 209  trainloss 1.36927  validloss 2.63621±0.00000  bestvalidloss 2.20472  last_update 55\n",
      "train: iter 210  trainloss 1.37889  validloss 2.46960±0.00000  bestvalidloss 2.20472  last_update 56\n",
      "train: iter 211  trainloss 1.38480  validloss 2.69448±0.00000  bestvalidloss 2.20472  last_update 57\n",
      "train: iter 212  trainloss 1.38270  validloss 2.70448±0.00000  bestvalidloss 2.20472  last_update 58\n",
      "train: iter 213  trainloss 1.39441  validloss 2.76681±0.00000  bestvalidloss 2.20472  last_update 59\n",
      "train: iter 214  trainloss 1.37116  validloss 2.64316±0.00000  bestvalidloss 2.20472  last_update 60\n",
      "train: iter 215  trainloss 1.38026  validloss 2.42798±0.00000  bestvalidloss 2.20472  last_update 61\n",
      "train: iter 216  trainloss 1.40789  validloss 2.46335±0.00000  bestvalidloss 2.20472  last_update 62\n",
      "train: iter 217  trainloss 1.38695  validloss 2.74323±0.00000  bestvalidloss 2.20472  last_update 63\n",
      "train: iter 218  trainloss 1.43970  validloss 2.62509±0.00000  bestvalidloss 2.20472  last_update 64\n",
      "train: iter 219  trainloss 1.38497  validloss 2.96938±0.00000  bestvalidloss 2.20472  last_update 65\n",
      "train: iter 220  trainloss 1.36105  validloss 2.64183±0.00000  bestvalidloss 2.20472  last_update 66\n",
      "train: iter 221  trainloss 1.36402  validloss 2.50582±0.00000  bestvalidloss 2.20472  last_update 67\n",
      "train: iter 222  trainloss 1.38534  validloss 2.69200±0.00000  bestvalidloss 2.20472  last_update 68\n",
      "train: iter 223  trainloss 1.40984  validloss 2.73262±0.00000  bestvalidloss 2.20472  last_update 69\n",
      "train: iter 224  trainloss 1.39702  validloss 2.71161±0.00000  bestvalidloss 2.20472  last_update 70\n",
      "train: iter 225  trainloss 1.43913  validloss 2.58308±0.00000  bestvalidloss 2.20472  last_update 71\n",
      "train: iter 226  trainloss 1.42034  validloss 2.52282±0.00000  bestvalidloss 2.20472  last_update 72\n",
      "train: iter 227  trainloss 1.38193  validloss 3.03770±0.00000  bestvalidloss 2.20472  last_update 73\n",
      "train: iter 228  trainloss 1.37780  validloss 2.66534±0.00000  bestvalidloss 2.20472  last_update 74\n",
      "train: iter 229  trainloss 1.37977  validloss 2.79571±0.00000  bestvalidloss 2.20472  last_update 75\n",
      "train: iter 230  trainloss 1.38369  validloss 2.43616±0.00000  bestvalidloss 2.20472  last_update 76\n",
      "train: iter 231  trainloss 1.34763  validloss 2.52962±0.00000  bestvalidloss 2.20472  last_update 77\n",
      "train: iter 232  trainloss 1.39977  validloss 2.65978±0.00000  bestvalidloss 2.20472  last_update 78\n",
      "train: iter 233  trainloss 1.36933  validloss 2.60413±0.00000  bestvalidloss 2.20472  last_update 79\n",
      "train: iter 234  trainloss 1.35792  validloss 2.37137±0.00000  bestvalidloss 2.20472  last_update 80\n",
      "train: iter 235  trainloss 1.38538  validloss 3.04183±0.00000  bestvalidloss 2.20472  last_update 81\n",
      "train: iter 236  trainloss 1.43957  validloss 2.76361±0.00000  bestvalidloss 2.20472  last_update 82\n",
      "train: iter 237  trainloss 1.38366  validloss 2.83923±0.00000  bestvalidloss 2.20472  last_update 83\n",
      "train: iter 238  trainloss 1.35004  validloss 2.72684±0.00000  bestvalidloss 2.20472  last_update 84\n",
      "train: iter 239  trainloss 1.40480  validloss 2.91545±0.00000  bestvalidloss 2.20472  last_update 85\n",
      "train: iter 240  trainloss 1.40243  validloss 2.55452±0.00000  bestvalidloss 2.20472  last_update 86\n",
      "train: iter 241  trainloss 1.39676  validloss 2.67341±0.00000  bestvalidloss 2.20472  last_update 87\n",
      "train: iter 242  trainloss 1.39869  validloss 2.71339±0.00000  bestvalidloss 2.20472  last_update 88\n",
      "train: iter 243  trainloss 1.43609  validloss 2.75461±0.00000  bestvalidloss 2.20472  last_update 89\n",
      "train: iter 244  trainloss 1.41186  validloss 2.67095±0.00000  bestvalidloss 2.20472  last_update 90\n",
      "train: iter 245  trainloss 1.37056  validloss 2.58302±0.00000  bestvalidloss 2.20472  last_update 91\n",
      "train: iter 246  trainloss 1.40201  validloss 2.38547±0.00000  bestvalidloss 2.20472  last_update 92\n",
      "train: iter 247  trainloss 1.37204  validloss 2.77640±0.00000  bestvalidloss 2.20472  last_update 93\n",
      "train: iter 248  trainloss 1.38774  validloss 2.48508±0.00000  bestvalidloss 2.20472  last_update 94\n",
      "train: iter 249  trainloss 1.41272  validloss 2.56700±0.00000  bestvalidloss 2.20472  last_update 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 250  trainloss 1.43659  validloss 2.35587±0.00000  bestvalidloss 2.20472  last_update 96\n",
      "train: iter 251  trainloss 1.35903  validloss 2.55723±0.00000  bestvalidloss 2.20472  last_update 97\n",
      "train: iter 252  trainloss 1.41125  validloss 2.59496±0.00000  bestvalidloss 2.20472  last_update 98\n",
      "train: iter 253  trainloss 1.38023  validloss 3.08302±0.00000  bestvalidloss 2.20472  last_update 99\n",
      "train: iter 254  trainloss 1.35827  validloss 3.03047±0.00000  bestvalidloss 2.20472  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-9.1107)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(3.0174)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1617433771263636\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119615c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e044dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ef756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9c6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c593c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
