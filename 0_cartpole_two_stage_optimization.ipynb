{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-2821.2007)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 1590.11282  validloss 7768.74123±0.00000  bestvalidloss 7768.74123  last_update 0\n",
      "train: iter 1  trainloss 946.43664  validloss 1089.15839±0.00000  bestvalidloss 1089.15839  last_update 0\n",
      "train: iter 2  trainloss 782.15882  validloss 853.25373±0.00000  bestvalidloss 853.25373  last_update 0\n",
      "train: iter 3  trainloss 755.43440  validloss 763.61665±0.00000  bestvalidloss 763.61665  last_update 0\n",
      "train: iter 4  trainloss 600.63880  validloss 725.62883±0.00000  bestvalidloss 725.62883  last_update 0\n",
      "train: iter 5  trainloss 477.29947  validloss 720.28963±0.00000  bestvalidloss 720.28963  last_update 0\n",
      "train: iter 6  trainloss 323.05867  validloss 410.28943±0.00000  bestvalidloss 410.28943  last_update 0\n",
      "train: iter 7  trainloss 225.39951  validloss 269.43948±0.00000  bestvalidloss 269.43948  last_update 0\n",
      "train: iter 8  trainloss 170.68918  validloss 219.36941±0.00000  bestvalidloss 219.36941  last_update 0\n",
      "train: iter 9  trainloss 111.98515  validloss 273.34906±0.00000  bestvalidloss 219.36941  last_update 1\n",
      "train: iter 10  trainloss -1.38976  validloss 118.75501±0.00000  bestvalidloss 118.75501  last_update 0\n",
      "train: iter 11  trainloss -76.61927  validloss 15.43892±0.00000  bestvalidloss 15.43892  last_update 0\n",
      "train: iter 12  trainloss -75.59603  validloss 67.20970±0.00000  bestvalidloss 15.43892  last_update 1\n",
      "train: iter 13  trainloss -150.91776  validloss -37.46927±0.00000  bestvalidloss -37.46927  last_update 0\n",
      "train: iter 14  trainloss -179.04293  validloss -165.59633±0.00000  bestvalidloss -165.59633  last_update 0\n",
      "train: iter 15  trainloss -211.88668  validloss -133.27110±0.00000  bestvalidloss -165.59633  last_update 1\n",
      "train: iter 16  trainloss -269.16231  validloss -125.05473±0.00000  bestvalidloss -165.59633  last_update 2\n",
      "train: iter 17  trainloss -218.84910  validloss -247.63851±0.00000  bestvalidloss -247.63851  last_update 0\n",
      "train: iter 18  trainloss -282.40838  validloss -138.08951±0.00000  bestvalidloss -247.63851  last_update 1\n",
      "train: iter 19  trainloss -375.75675  validloss -263.77936±0.00000  bestvalidloss -263.77936  last_update 0\n",
      "train: iter 20  trainloss -366.12466  validloss -305.81143±0.00000  bestvalidloss -305.81143  last_update 0\n",
      "train: iter 21  trainloss -377.17216  validloss -346.21642±0.00000  bestvalidloss -346.21642  last_update 0\n",
      "train: iter 22  trainloss -343.08714  validloss -287.17956±0.00000  bestvalidloss -346.21642  last_update 1\n",
      "train: iter 23  trainloss -304.60532  validloss -246.82725±0.00000  bestvalidloss -346.21642  last_update 2\n",
      "train: iter 24  trainloss -295.66582  validloss -34.81325±0.00000  bestvalidloss -346.21642  last_update 3\n",
      "train: iter 25  trainloss -430.17588  validloss -413.79767±0.00000  bestvalidloss -413.79767  last_update 0\n",
      "train: iter 26  trainloss -471.76805  validloss -347.47653±0.00000  bestvalidloss -413.79767  last_update 1\n",
      "train: iter 27  trainloss -440.51264  validloss -380.83133±0.00000  bestvalidloss -413.79767  last_update 2\n",
      "train: iter 28  trainloss -522.88814  validloss -412.14559±0.00000  bestvalidloss -413.79767  last_update 3\n",
      "train: iter 29  trainloss -473.59854  validloss -358.01148±0.00000  bestvalidloss -413.79767  last_update 4\n",
      "train: iter 30  trainloss -506.26575  validloss -480.71139±0.00000  bestvalidloss -480.71139  last_update 0\n",
      "train: iter 31  trainloss -464.07943  validloss -487.42337±0.00000  bestvalidloss -487.42337  last_update 0\n",
      "train: iter 32  trainloss -554.14807  validloss -524.04594±0.00000  bestvalidloss -524.04594  last_update 0\n",
      "train: iter 33  trainloss -568.53077  validloss -485.43269±0.00000  bestvalidloss -524.04594  last_update 1\n",
      "train: iter 34  trainloss -497.99372  validloss -495.07053±0.00000  bestvalidloss -524.04594  last_update 2\n",
      "train: iter 35  trainloss -552.79418  validloss -499.22309±0.00000  bestvalidloss -524.04594  last_update 3\n",
      "train: iter 36  trainloss -616.66467  validloss -503.35104±0.00000  bestvalidloss -524.04594  last_update 4\n",
      "train: iter 37  trainloss -605.68943  validloss -508.26481±0.00000  bestvalidloss -524.04594  last_update 5\n",
      "train: iter 38  trainloss -559.91039  validloss -450.43878±0.00000  bestvalidloss -524.04594  last_update 6\n",
      "train: iter 39  trainloss -622.36906  validloss -557.33892±0.00000  bestvalidloss -557.33892  last_update 0\n",
      "train: iter 40  trainloss -631.51197  validloss -548.13803±0.00000  bestvalidloss -557.33892  last_update 1\n",
      "train: iter 41  trainloss -545.34158  validloss -496.48333±0.00000  bestvalidloss -557.33892  last_update 2\n",
      "train: iter 42  trainloss -581.38869  validloss -435.04696±0.00000  bestvalidloss -557.33892  last_update 3\n",
      "train: iter 43  trainloss -661.09691  validloss -544.12188±0.00000  bestvalidloss -557.33892  last_update 4\n",
      "train: iter 44  trainloss -607.77649  validloss -516.62988±0.00000  bestvalidloss -557.33892  last_update 5\n",
      "train: iter 45  trainloss -636.51388  validloss -354.02524±0.00000  bestvalidloss -557.33892  last_update 6\n",
      "train: iter 46  trainloss -680.15459  validloss -637.41631±0.00000  bestvalidloss -637.41631  last_update 0\n",
      "train: iter 47  trainloss -637.83841  validloss -506.70139±0.00000  bestvalidloss -637.41631  last_update 1\n",
      "train: iter 48  trainloss -749.97059  validloss -628.31947±0.00000  bestvalidloss -637.41631  last_update 2\n",
      "train: iter 49  trainloss -665.69512  validloss -654.77082±0.00000  bestvalidloss -654.77082  last_update 0\n",
      "train: iter 50  trainloss -657.60585  validloss -425.98403±0.00000  bestvalidloss -654.77082  last_update 1\n",
      "train: iter 51  trainloss -722.50713  validloss -705.57103±0.00000  bestvalidloss -705.57103  last_update 0\n",
      "train: iter 52  trainloss -765.50900  validloss -589.12471±0.00000  bestvalidloss -705.57103  last_update 1\n",
      "train: iter 53  trainloss -780.32289  validloss -591.24728±0.00000  bestvalidloss -705.57103  last_update 2\n",
      "train: iter 54  trainloss -724.70749  validloss -680.93068±0.00000  bestvalidloss -705.57103  last_update 3\n",
      "train: iter 55  trainloss -699.29302  validloss -357.85578±0.00000  bestvalidloss -705.57103  last_update 4\n",
      "train: iter 56  trainloss -735.92235  validloss -741.76637±0.00000  bestvalidloss -741.76637  last_update 0\n",
      "train: iter 57  trainloss -743.67152  validloss -756.15552±0.00000  bestvalidloss -756.15552  last_update 0\n",
      "train: iter 58  trainloss -783.92071  validloss -749.12650±0.00000  bestvalidloss -756.15552  last_update 1\n",
      "train: iter 59  trainloss -739.13905  validloss -653.48393±0.00000  bestvalidloss -756.15552  last_update 2\n",
      "train: iter 60  trainloss -823.15613  validloss -788.78385±0.00000  bestvalidloss -788.78385  last_update 0\n",
      "train: iter 61  trainloss -655.67513  validloss -12.33284±0.00000  bestvalidloss -788.78385  last_update 1\n",
      "train: iter 62  trainloss -768.70556  validloss -608.83060±0.00000  bestvalidloss -788.78385  last_update 2\n",
      "train: iter 63  trainloss -705.58491  validloss -743.22994±0.00000  bestvalidloss -788.78385  last_update 3\n",
      "train: iter 64  trainloss -765.79698  validloss -508.77370±0.00000  bestvalidloss -788.78385  last_update 4\n",
      "train: iter 65  trainloss -733.40618  validloss -781.83713±0.00000  bestvalidloss -788.78385  last_update 5\n",
      "train: iter 66  trainloss -814.66509  validloss -646.46023±0.00000  bestvalidloss -788.78385  last_update 6\n",
      "train: iter 67  trainloss -848.80349  validloss -813.22435±0.00000  bestvalidloss -813.22435  last_update 0\n",
      "train: iter 68  trainloss -881.16705  validloss -856.60489±0.00000  bestvalidloss -856.60489  last_update 0\n",
      "train: iter 69  trainloss -830.62947  validloss -762.58513±0.00000  bestvalidloss -856.60489  last_update 1\n",
      "train: iter 70  trainloss -836.15878  validloss -723.30526±0.00000  bestvalidloss -856.60489  last_update 2\n",
      "train: iter 71  trainloss -898.10153  validloss -724.82782±0.00000  bestvalidloss -856.60489  last_update 3\n",
      "train: iter 72  trainloss -812.00935  validloss -589.90180±0.00000  bestvalidloss -856.60489  last_update 4\n",
      "train: iter 73  trainloss -847.82296  validloss -735.07076±0.00000  bestvalidloss -856.60489  last_update 5\n",
      "train: iter 74  trainloss -809.32785  validloss -812.99177±0.00000  bestvalidloss -856.60489  last_update 6\n",
      "train: iter 75  trainloss -864.59073  validloss -770.97332±0.00000  bestvalidloss -856.60489  last_update 7\n",
      "train: iter 76  trainloss -926.71468  validloss -833.26509±0.00000  bestvalidloss -856.60489  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -908.27404  validloss -777.76615±0.00000  bestvalidloss -856.60489  last_update 9\n",
      "train: iter 78  trainloss -597.82420  validloss -835.09501±0.00000  bestvalidloss -856.60489  last_update 10\n",
      "train: iter 79  trainloss -470.81724  validloss -576.23641±0.00000  bestvalidloss -856.60489  last_update 11\n",
      "train: iter 80  trainloss -678.51134  validloss -512.84195±0.00000  bestvalidloss -856.60489  last_update 12\n",
      "train: iter 81  trainloss -778.59556  validloss -695.40399±0.00000  bestvalidloss -856.60489  last_update 13\n",
      "train: iter 82  trainloss -939.61394  validloss -844.20185±0.00000  bestvalidloss -856.60489  last_update 14\n",
      "train: iter 83  trainloss -920.16506  validloss -732.89061±0.00000  bestvalidloss -856.60489  last_update 15\n",
      "train: iter 84  trainloss -963.02896  validloss -923.12580±0.00000  bestvalidloss -923.12580  last_update 0\n",
      "train: iter 85  trainloss -805.86881  validloss -841.46540±0.00000  bestvalidloss -923.12580  last_update 1\n",
      "train: iter 86  trainloss -942.30929  validloss -877.86456±0.00000  bestvalidloss -923.12580  last_update 2\n",
      "train: iter 87  trainloss -976.20927  validloss -814.92319±0.00000  bestvalidloss -923.12580  last_update 3\n",
      "train: iter 88  trainloss -899.55494  validloss -946.36716±0.00000  bestvalidloss -946.36716  last_update 0\n",
      "train: iter 89  trainloss -572.58852  validloss -396.35364±0.00000  bestvalidloss -946.36716  last_update 1\n",
      "train: iter 90  trainloss -632.61953  validloss -377.69170±0.00000  bestvalidloss -946.36716  last_update 2\n",
      "train: iter 91  trainloss -947.05960  validloss -842.06533±0.00000  bestvalidloss -946.36716  last_update 3\n",
      "train: iter 92  trainloss -1019.95972  validloss -949.52191±0.00000  bestvalidloss -949.52191  last_update 0\n",
      "train: iter 93  trainloss -1049.48590  validloss -982.40288±0.00000  bestvalidloss -982.40288  last_update 0\n",
      "train: iter 94  trainloss -975.35796  validloss -870.02546±0.00000  bestvalidloss -982.40288  last_update 1\n",
      "train: iter 95  trainloss -938.03482  validloss -721.56164±0.00000  bestvalidloss -982.40288  last_update 2\n",
      "train: iter 96  trainloss -1028.60597  validloss -924.49592±0.00000  bestvalidloss -982.40288  last_update 3\n",
      "train: iter 97  trainloss -971.90678  validloss -838.58462±0.00000  bestvalidloss -982.40288  last_update 4\n",
      "train: iter 98  trainloss -1114.00421  validloss -978.68338±0.00000  bestvalidloss -982.40288  last_update 5\n",
      "train: iter 99  trainloss -980.34312  validloss -994.56277±0.00000  bestvalidloss -994.56277  last_update 0\n",
      "train: iter 100  trainloss -919.94052  validloss -793.76780±0.00000  bestvalidloss -994.56277  last_update 1\n",
      "train: iter 101  trainloss -670.41433  validloss -755.29464±0.00000  bestvalidloss -994.56277  last_update 2\n",
      "train: iter 102  trainloss -922.58684  validloss -966.61768±0.00000  bestvalidloss -994.56277  last_update 3\n",
      "train: iter 103  trainloss -1099.01957  validloss -996.44654±0.00000  bestvalidloss -996.44654  last_update 0\n",
      "train: iter 104  trainloss -911.80460  validloss -633.76437±0.00000  bestvalidloss -996.44654  last_update 1\n",
      "train: iter 105  trainloss -1119.09841  validloss -981.69049±0.00000  bestvalidloss -996.44654  last_update 2\n",
      "train: iter 106  trainloss -929.60005  validloss -1038.10824±0.00000  bestvalidloss -1038.10824  last_update 0\n",
      "train: iter 107  trainloss -1051.65493  validloss -925.18696±0.00000  bestvalidloss -1038.10824  last_update 1\n",
      "train: iter 108  trainloss -1086.15327  validloss -1026.64050±0.00000  bestvalidloss -1038.10824  last_update 2\n",
      "train: iter 109  trainloss -1137.58488  validloss -1015.17514±0.00000  bestvalidloss -1038.10824  last_update 3\n",
      "train: iter 110  trainloss -1058.07881  validloss -1047.04124±0.00000  bestvalidloss -1047.04124  last_update 0\n",
      "train: iter 111  trainloss -901.79187  validloss -907.42066±0.00000  bestvalidloss -1047.04124  last_update 1\n",
      "train: iter 112  trainloss -1111.98049  validloss -908.66205±0.00000  bestvalidloss -1047.04124  last_update 2\n",
      "train: iter 113  trainloss -1007.54689  validloss -892.02626±0.00000  bestvalidloss -1047.04124  last_update 3\n",
      "train: iter 114  trainloss -1108.81841  validloss -993.54993±0.00000  bestvalidloss -1047.04124  last_update 4\n",
      "train: iter 115  trainloss -952.56636  validloss -993.36954±0.00000  bestvalidloss -1047.04124  last_update 5\n",
      "train: iter 116  trainloss -1045.48633  validloss -989.86782±0.00000  bestvalidloss -1047.04124  last_update 6\n",
      "train: iter 117  trainloss -1047.49022  validloss -828.45851±0.00000  bestvalidloss -1047.04124  last_update 7\n",
      "train: iter 118  trainloss -1088.80418  validloss -1031.84984±0.00000  bestvalidloss -1047.04124  last_update 8\n",
      "train: iter 119  trainloss -829.31596  validloss -306.75593±0.00000  bestvalidloss -1047.04124  last_update 9\n",
      "train: iter 120  trainloss -1084.15312  validloss -629.40285±0.00000  bestvalidloss -1047.04124  last_update 10\n",
      "train: iter 121  trainloss -1133.72242  validloss -1109.82142±0.00000  bestvalidloss -1109.82142  last_update 0\n",
      "train: iter 122  trainloss -1167.21349  validloss -1045.20505±0.00000  bestvalidloss -1109.82142  last_update 1\n",
      "train: iter 123  trainloss -1073.22129  validloss -1102.43138±0.00000  bestvalidloss -1109.82142  last_update 2\n",
      "train: iter 124  trainloss -1136.28288  validloss -1109.76622±0.00000  bestvalidloss -1109.82142  last_update 3\n",
      "train: iter 125  trainloss -1051.86719  validloss -566.98008±0.00000  bestvalidloss -1109.82142  last_update 4\n",
      "train: iter 126  trainloss -1007.31913  validloss -1018.13070±0.00000  bestvalidloss -1109.82142  last_update 5\n",
      "train: iter 127  trainloss -972.54659  validloss -941.75560±0.00000  bestvalidloss -1109.82142  last_update 6\n",
      "train: iter 128  trainloss -972.65633  validloss -497.81651±0.00000  bestvalidloss -1109.82142  last_update 7\n",
      "train: iter 129  trainloss -1097.56566  validloss -1023.91371±0.00000  bestvalidloss -1109.82142  last_update 8\n",
      "train: iter 130  trainloss -1146.93470  validloss -1032.23855±0.00000  bestvalidloss -1109.82142  last_update 9\n",
      "train: iter 131  trainloss -1208.17812  validloss -1143.84808±0.00000  bestvalidloss -1143.84808  last_update 0\n",
      "train: iter 132  trainloss -1148.87848  validloss -1153.17350±0.00000  bestvalidloss -1153.17350  last_update 0\n",
      "train: iter 133  trainloss -1187.23775  validloss -1083.26599±0.00000  bestvalidloss -1153.17350  last_update 1\n",
      "train: iter 134  trainloss -1137.99373  validloss -1079.59033±0.00000  bestvalidloss -1153.17350  last_update 2\n",
      "train: iter 135  trainloss -1094.31656  validloss -923.45142±0.00000  bestvalidloss -1153.17350  last_update 3\n",
      "train: iter 136  trainloss -1243.72520  validloss -1139.66481±0.00000  bestvalidloss -1153.17350  last_update 4\n",
      "train: iter 137  trainloss -1045.56520  validloss -1055.16401±0.00000  bestvalidloss -1153.17350  last_update 5\n",
      "train: iter 138  trainloss -1081.97450  validloss -981.69682±0.00000  bestvalidloss -1153.17350  last_update 6\n",
      "train: iter 139  trainloss -1006.69254  validloss -1093.67531±0.00000  bestvalidloss -1153.17350  last_update 7\n",
      "train: iter 140  trainloss -1018.22489  validloss -583.42342±0.00000  bestvalidloss -1153.17350  last_update 8\n",
      "train: iter 141  trainloss -1159.75291  validloss -1049.39027±0.00000  bestvalidloss -1153.17350  last_update 9\n",
      "train: iter 142  trainloss -1053.32058  validloss -1007.54519±0.00000  bestvalidloss -1153.17350  last_update 10\n",
      "train: iter 143  trainloss -1194.77700  validloss -1050.83862±0.00000  bestvalidloss -1153.17350  last_update 11\n",
      "train: iter 144  trainloss -1170.33242  validloss -1110.74341±0.00000  bestvalidloss -1153.17350  last_update 12\n",
      "train: iter 145  trainloss -1150.37542  validloss -1022.86343±0.00000  bestvalidloss -1153.17350  last_update 13\n",
      "train: iter 146  trainloss -1201.92895  validloss -1009.14582±0.00000  bestvalidloss -1153.17350  last_update 14\n",
      "train: iter 147  trainloss -1158.02985  validloss -1191.78131±0.00000  bestvalidloss -1191.78131  last_update 0\n",
      "train: iter 148  trainloss -1046.79317  validloss -447.78226±0.00000  bestvalidloss -1191.78131  last_update 1\n",
      "train: iter 149  trainloss -1052.38094  validloss -1116.56921±0.00000  bestvalidloss -1191.78131  last_update 2\n",
      "train: iter 150  trainloss -967.86902  validloss -575.06797±0.00000  bestvalidloss -1191.78131  last_update 3\n",
      "train: iter 151  trainloss -1230.94504  validloss -1015.26373±0.00000  bestvalidloss -1191.78131  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 152  trainloss -1206.95726  validloss -1200.51146±0.00000  bestvalidloss -1200.51146  last_update 0\n",
      "train: iter 153  trainloss -1162.09787  validloss -960.99056±0.00000  bestvalidloss -1200.51146  last_update 1\n",
      "train: iter 154  trainloss -938.35635  validloss -1078.26942±0.00000  bestvalidloss -1200.51146  last_update 2\n",
      "train: iter 155  trainloss 392.99243  validloss 979.17534±0.00000  bestvalidloss -1200.51146  last_update 3\n",
      "train: iter 156  trainloss -121.16805  validloss -5.06811±0.00000  bestvalidloss -1200.51146  last_update 4\n",
      "train: iter 157  trainloss -316.38212  validloss 314.03503±0.00000  bestvalidloss -1200.51146  last_update 5\n",
      "train: iter 158  trainloss -873.53932  validloss -659.15435±0.00000  bestvalidloss -1200.51146  last_update 6\n",
      "train: iter 159  trainloss -778.56498  validloss -840.25849±0.00000  bestvalidloss -1200.51146  last_update 7\n",
      "train: iter 160  trainloss -1171.75467  validloss -968.59276±0.00000  bestvalidloss -1200.51146  last_update 8\n",
      "train: iter 161  trainloss -1132.79750  validloss -1048.99829±0.00000  bestvalidloss -1200.51146  last_update 9\n",
      "train: iter 162  trainloss -1168.11005  validloss -1098.85175±0.00000  bestvalidloss -1200.51146  last_update 10\n",
      "train: iter 163  trainloss -1216.08472  validloss -1155.16511±0.00000  bestvalidloss -1200.51146  last_update 11\n",
      "train: iter 164  trainloss -1167.51084  validloss -987.13071±0.00000  bestvalidloss -1200.51146  last_update 12\n",
      "train: iter 165  trainloss -1239.33302  validloss -1112.64779±0.00000  bestvalidloss -1200.51146  last_update 13\n",
      "train: iter 166  trainloss -1225.09388  validloss -1130.83139±0.00000  bestvalidloss -1200.51146  last_update 14\n",
      "train: iter 167  trainloss -1269.28383  validloss -1145.01557±0.00000  bestvalidloss -1200.51146  last_update 15\n",
      "train: iter 168  trainloss -1289.82854  validloss -1135.73293±0.00000  bestvalidloss -1200.51146  last_update 16\n",
      "train: iter 169  trainloss -1228.06561  validloss -1131.48893±0.00000  bestvalidloss -1200.51146  last_update 17\n",
      "train: iter 170  trainloss -1234.46863  validloss -1058.14228±0.00000  bestvalidloss -1200.51146  last_update 18\n",
      "train: iter 171  trainloss -1321.24059  validloss -1236.14217±0.00000  bestvalidloss -1236.14217  last_update 0\n",
      "train: iter 172  trainloss -1277.21458  validloss -1208.66699±0.00000  bestvalidloss -1236.14217  last_update 1\n",
      "train: iter 173  trainloss -1205.53086  validloss -1016.44060±0.00000  bestvalidloss -1236.14217  last_update 2\n",
      "train: iter 174  trainloss -911.38727  validloss -1172.27470±0.00000  bestvalidloss -1236.14217  last_update 3\n",
      "train: iter 175  trainloss -885.67658  validloss -754.33979±0.00000  bestvalidloss -1236.14217  last_update 4\n",
      "train: iter 176  trainloss -1167.69187  validloss -761.13846±0.00000  bestvalidloss -1236.14217  last_update 5\n",
      "train: iter 177  trainloss -1271.18323  validloss -1195.75777±0.00000  bestvalidloss -1236.14217  last_update 6\n",
      "train: iter 178  trainloss -1008.37965  validloss -1073.17397±0.00000  bestvalidloss -1236.14217  last_update 7\n",
      "train: iter 179  trainloss -1261.86293  validloss -1109.42806±0.00000  bestvalidloss -1236.14217  last_update 8\n",
      "train: iter 180  trainloss -1267.56366  validloss -1153.88796±0.00000  bestvalidloss -1236.14217  last_update 9\n",
      "train: iter 181  trainloss -1302.99357  validloss -1107.09047±0.00000  bestvalidloss -1236.14217  last_update 10\n",
      "train: iter 182  trainloss -1261.04166  validloss -1113.94989±0.00000  bestvalidloss -1236.14217  last_update 11\n",
      "train: iter 183  trainloss -969.57697  validloss -1240.51661±0.00000  bestvalidloss -1240.51661  last_update 0\n",
      "train: iter 184  trainloss -1243.26283  validloss -1143.25046±0.00000  bestvalidloss -1240.51661  last_update 1\n",
      "train: iter 185  trainloss -1133.92305  validloss -1074.90978±0.00000  bestvalidloss -1240.51661  last_update 2\n",
      "train: iter 186  trainloss -1301.26740  validloss -1116.32243±0.00000  bestvalidloss -1240.51661  last_update 3\n",
      "train: iter 187  trainloss -1248.07642  validloss -1123.12126±0.00000  bestvalidloss -1240.51661  last_update 4\n",
      "train: iter 188  trainloss -1082.95406  validloss -797.08684±0.00000  bestvalidloss -1240.51661  last_update 5\n",
      "train: iter 189  trainloss -1198.19908  validloss -882.66361±0.00000  bestvalidloss -1240.51661  last_update 6\n",
      "train: iter 190  trainloss -1335.85365  validloss -1219.24603±0.00000  bestvalidloss -1240.51661  last_update 7\n",
      "train: iter 191  trainloss -1331.16321  validloss -1293.10551±0.00000  bestvalidloss -1293.10551  last_update 0\n",
      "train: iter 192  trainloss -1127.06537  validloss -1223.93797±0.00000  bestvalidloss -1293.10551  last_update 1\n",
      "train: iter 193  trainloss -1352.28874  validloss -1230.78401±0.00000  bestvalidloss -1293.10551  last_update 2\n",
      "train: iter 194  trainloss -1249.94657  validloss -723.29625±0.00000  bestvalidloss -1293.10551  last_update 3\n",
      "train: iter 195  trainloss -1147.80360  validloss -1300.06769±0.00000  bestvalidloss -1300.06769  last_update 0\n",
      "train: iter 196  trainloss -1190.14459  validloss -956.89271±0.00000  bestvalidloss -1300.06769  last_update 1\n",
      "train: iter 197  trainloss -1285.09256  validloss -1203.66311±0.00000  bestvalidloss -1300.06769  last_update 2\n",
      "train: iter 198  trainloss -1311.43202  validloss -1173.33067±0.00000  bestvalidloss -1300.06769  last_update 3\n",
      "train: iter 199  trainloss -1310.12510  validloss -1241.47867±0.00000  bestvalidloss -1300.06769  last_update 4\n",
      "train: iter 200  trainloss -1228.33053  validloss -1178.19753±0.00000  bestvalidloss -1300.06769  last_update 5\n",
      "train: iter 201  trainloss -1289.63146  validloss -1162.96126±0.00000  bestvalidloss -1300.06769  last_update 6\n",
      "train: iter 202  trainloss -1123.67341  validloss -1251.80572±0.00000  bestvalidloss -1300.06769  last_update 7\n",
      "train: iter 203  trainloss -1315.46081  validloss -988.36244±0.00000  bestvalidloss -1300.06769  last_update 8\n",
      "train: iter 204  trainloss -1312.55803  validloss -1168.77520±0.00000  bestvalidloss -1300.06769  last_update 9\n",
      "train: iter 205  trainloss -1318.37914  validloss -1279.95682±0.00000  bestvalidloss -1300.06769  last_update 10\n",
      "train: iter 206  trainloss -1210.76358  validloss -1039.97694±0.00000  bestvalidloss -1300.06769  last_update 11\n",
      "train: iter 207  trainloss -1332.18383  validloss -1230.48679±0.00000  bestvalidloss -1300.06769  last_update 12\n",
      "train: iter 208  trainloss -1350.26982  validloss -1243.36347±0.00000  bestvalidloss -1300.06769  last_update 13\n",
      "train: iter 209  trainloss -1121.51603  validloss -1108.16659±0.00000  bestvalidloss -1300.06769  last_update 14\n",
      "train: iter 210  trainloss -1292.44271  validloss -1050.27192±0.00000  bestvalidloss -1300.06769  last_update 15\n",
      "train: iter 211  trainloss -1116.91981  validloss -688.39918±0.00000  bestvalidloss -1300.06769  last_update 16\n",
      "train: iter 212  trainloss -1219.76493  validloss -1198.14585±0.00000  bestvalidloss -1300.06769  last_update 17\n",
      "train: iter 213  trainloss -1158.34863  validloss -1026.03868±0.00000  bestvalidloss -1300.06769  last_update 18\n",
      "train: iter 214  trainloss -1251.69353  validloss -1087.13139±0.00000  bestvalidloss -1300.06769  last_update 19\n",
      "train: iter 215  trainloss -1250.62012  validloss -1248.86819±0.00000  bestvalidloss -1300.06769  last_update 20\n",
      "train: iter 216  trainloss -1271.86741  validloss -1016.24804±0.00000  bestvalidloss -1300.06769  last_update 21\n",
      "train: iter 217  trainloss -1373.88175  validloss -1275.34701±0.00000  bestvalidloss -1300.06769  last_update 22\n",
      "train: iter 218  trainloss -1394.37597  validloss -1277.84853±0.00000  bestvalidloss -1300.06769  last_update 23\n",
      "train: iter 219  trainloss -1056.70860  validloss -1090.55425±0.00000  bestvalidloss -1300.06769  last_update 24\n",
      "train: iter 220  trainloss -1238.07628  validloss -1081.68954±0.00000  bestvalidloss -1300.06769  last_update 25\n",
      "train: iter 221  trainloss -1281.43000  validloss -1219.98035±0.00000  bestvalidloss -1300.06769  last_update 26\n",
      "train: iter 222  trainloss -1398.61468  validloss -1258.97536±0.00000  bestvalidloss -1300.06769  last_update 27\n",
      "train: iter 223  trainloss -1326.64444  validloss -1227.44819±0.00000  bestvalidloss -1300.06769  last_update 28\n",
      "train: iter 224  trainloss -1196.66106  validloss -1061.69135±0.00000  bestvalidloss -1300.06769  last_update 29\n",
      "train: iter 225  trainloss -1247.99147  validloss -1245.72408±0.00000  bestvalidloss -1300.06769  last_update 30\n",
      "train: iter 226  trainloss -1418.81059  validloss -1243.12793±0.00000  bestvalidloss -1300.06769  last_update 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 227  trainloss -1381.32612  validloss -1262.96895±0.00000  bestvalidloss -1300.06769  last_update 32\n",
      "train: iter 228  trainloss -739.02215  validloss -1277.21188±0.00000  bestvalidloss -1300.06769  last_update 33\n",
      "train: iter 229  trainloss -1141.59665  validloss -388.66618±0.00000  bestvalidloss -1300.06769  last_update 34\n",
      "train: iter 230  trainloss -1279.75053  validloss -1176.40601±0.00000  bestvalidloss -1300.06769  last_update 35\n",
      "train: iter 231  trainloss -1313.04634  validloss -1246.35834±0.00000  bestvalidloss -1300.06769  last_update 36\n",
      "train: iter 232  trainloss -1388.72799  validloss -1344.15052±0.00000  bestvalidloss -1344.15052  last_update 0\n",
      "train: iter 233  trainloss -1351.67506  validloss -1048.54199±0.00000  bestvalidloss -1344.15052  last_update 1\n",
      "train: iter 234  trainloss -1290.68833  validloss -1332.97698±0.00000  bestvalidloss -1344.15052  last_update 2\n",
      "train: iter 235  trainloss -1448.11092  validloss -1337.99291±0.00000  bestvalidloss -1344.15052  last_update 3\n",
      "train: iter 236  trainloss -1328.16667  validloss -1186.59440±0.00000  bestvalidloss -1344.15052  last_update 4\n",
      "train: iter 237  trainloss -1328.54312  validloss -1317.90292±0.00000  bestvalidloss -1344.15052  last_update 5\n",
      "train: iter 238  trainloss -1372.31404  validloss -1289.02546±0.00000  bestvalidloss -1344.15052  last_update 6\n",
      "train: iter 239  trainloss -1188.55301  validloss -963.65026±0.00000  bestvalidloss -1344.15052  last_update 7\n",
      "train: iter 240  trainloss -1427.95530  validloss -1251.74107±0.00000  bestvalidloss -1344.15052  last_update 8\n",
      "train: iter 241  trainloss -1414.44455  validloss -1196.81349±0.00000  bestvalidloss -1344.15052  last_update 9\n",
      "train: iter 242  trainloss -1268.62308  validloss -1256.29976±0.00000  bestvalidloss -1344.15052  last_update 10\n",
      "train: iter 243  trainloss -1408.31428  validloss -1264.41318±0.00000  bestvalidloss -1344.15052  last_update 11\n",
      "train: iter 244  trainloss -1426.26809  validloss -1337.11251±0.00000  bestvalidloss -1344.15052  last_update 12\n",
      "train: iter 245  trainloss -1433.24805  validloss -1387.87153±0.00000  bestvalidloss -1387.87153  last_update 0\n",
      "train: iter 246  trainloss -1044.93202  validloss -1297.59004±0.00000  bestvalidloss -1387.87153  last_update 1\n",
      "train: iter 247  trainloss -1302.03798  validloss -1051.66649±0.00000  bestvalidloss -1387.87153  last_update 2\n",
      "train: iter 248  trainloss -1372.57763  validloss -1256.38030±0.00000  bestvalidloss -1387.87153  last_update 3\n",
      "train: iter 249  trainloss -1363.54661  validloss -1365.58938±0.00000  bestvalidloss -1387.87153  last_update 4\n",
      "train: iter 250  trainloss -1351.95635  validloss -1119.58147±0.00000  bestvalidloss -1387.87153  last_update 5\n",
      "train: iter 251  trainloss -1357.32889  validloss -1101.41711±0.00000  bestvalidloss -1387.87153  last_update 6\n",
      "train: iter 252  trainloss -1428.92478  validloss -1339.38491±0.00000  bestvalidloss -1387.87153  last_update 7\n",
      "train: iter 253  trainloss -1392.07745  validloss -1280.66966±0.00000  bestvalidloss -1387.87153  last_update 8\n",
      "train: iter 254  trainloss -1268.65473  validloss -1245.77099±0.00000  bestvalidloss -1387.87153  last_update 9\n",
      "train: iter 255  trainloss -1213.11383  validloss -699.25318±0.00000  bestvalidloss -1387.87153  last_update 10\n",
      "train: iter 256  trainloss -1461.02122  validloss -1324.88571±0.00000  bestvalidloss -1387.87153  last_update 11\n",
      "train: iter 257  trainloss -1439.77656  validloss -1363.24341±0.00000  bestvalidloss -1387.87153  last_update 12\n",
      "train: iter 258  trainloss -1208.98157  validloss -1039.72728±0.00000  bestvalidloss -1387.87153  last_update 13\n",
      "train: iter 259  trainloss -1409.00005  validloss -1223.66799±0.00000  bestvalidloss -1387.87153  last_update 14\n",
      "train: iter 260  trainloss -1370.49518  validloss -1327.87937±0.00000  bestvalidloss -1387.87153  last_update 15\n",
      "train: iter 261  trainloss -1469.61825  validloss -1342.62191±0.00000  bestvalidloss -1387.87153  last_update 16\n",
      "train: iter 262  trainloss -1331.36852  validloss -1378.92196±0.00000  bestvalidloss -1387.87153  last_update 17\n",
      "train: iter 263  trainloss -1359.40807  validloss -1304.41728±0.00000  bestvalidloss -1387.87153  last_update 18\n",
      "train: iter 264  trainloss -1379.87528  validloss -1277.63755±0.00000  bestvalidloss -1387.87153  last_update 19\n",
      "train: iter 265  trainloss -1421.16535  validloss -1358.21073±0.00000  bestvalidloss -1387.87153  last_update 20\n",
      "train: iter 266  trainloss -1186.82512  validloss -1063.05942±0.00000  bestvalidloss -1387.87153  last_update 21\n",
      "train: iter 267  trainloss -1458.27026  validloss -1342.65801±0.00000  bestvalidloss -1387.87153  last_update 22\n",
      "train: iter 268  trainloss -1459.44947  validloss -1404.65173±0.00000  bestvalidloss -1404.65173  last_update 0\n",
      "train: iter 269  trainloss -1382.84995  validloss -1307.10487±0.00000  bestvalidloss -1404.65173  last_update 1\n",
      "train: iter 270  trainloss -1366.73901  validloss -1049.36985±0.00000  bestvalidloss -1404.65173  last_update 2\n",
      "train: iter 271  trainloss -1469.31298  validloss -1256.35021±0.00000  bestvalidloss -1404.65173  last_update 3\n",
      "train: iter 272  trainloss -1452.42148  validloss -1323.87585±0.00000  bestvalidloss -1404.65173  last_update 4\n",
      "train: iter 273  trainloss -1314.50409  validloss -1272.72290±0.00000  bestvalidloss -1404.65173  last_update 5\n",
      "train: iter 274  trainloss -1409.18036  validloss -1282.84304±0.00000  bestvalidloss -1404.65173  last_update 6\n",
      "train: iter 275  trainloss -1436.39174  validloss -1298.64904±0.00000  bestvalidloss -1404.65173  last_update 7\n",
      "train: iter 276  trainloss -1423.31440  validloss -1258.90328±0.00000  bestvalidloss -1404.65173  last_update 8\n",
      "train: iter 277  trainloss -1484.14279  validloss -1301.54221±0.00000  bestvalidloss -1404.65173  last_update 9\n",
      "train: iter 278  trainloss -1443.97157  validloss -1410.05965±0.00000  bestvalidloss -1410.05965  last_update 0\n",
      "train: iter 279  trainloss -1383.79787  validloss -1371.69850±0.00000  bestvalidloss -1410.05965  last_update 1\n",
      "train: iter 280  trainloss -1476.17811  validloss -1392.25492±0.00000  bestvalidloss -1410.05965  last_update 2\n",
      "train: iter 281  trainloss -1354.44148  validloss -1132.46368±0.00000  bestvalidloss -1410.05965  last_update 3\n",
      "train: iter 282  trainloss -1404.41209  validloss -1231.01597±0.00000  bestvalidloss -1410.05965  last_update 4\n",
      "train: iter 283  trainloss -1403.12002  validloss -1380.91872±0.00000  bestvalidloss -1410.05965  last_update 5\n",
      "train: iter 284  trainloss -1087.27847  validloss -1222.42657±0.00000  bestvalidloss -1410.05965  last_update 6\n",
      "train: iter 285  trainloss -1402.61514  validloss -1092.03484±0.00000  bestvalidloss -1410.05965  last_update 7\n",
      "train: iter 286  trainloss -1325.94903  validloss -928.64522±0.00000  bestvalidloss -1410.05965  last_update 8\n",
      "train: iter 287  trainloss -1393.96613  validloss -1337.96134±0.00000  bestvalidloss -1410.05965  last_update 9\n",
      "train: iter 288  trainloss -346.79849  validloss -381.54766±0.00000  bestvalidloss -1410.05965  last_update 10\n",
      "train: iter 289  trainloss -54.47884  validloss -77.12363±0.00000  bestvalidloss -1410.05965  last_update 11\n",
      "train: iter 290  trainloss -464.56722  validloss 1023.90639±0.00000  bestvalidloss -1410.05965  last_update 12\n",
      "train: iter 291  trainloss -1082.15098  validloss -726.93311±0.00000  bestvalidloss -1410.05965  last_update 13\n",
      "train: iter 292  trainloss -1249.00457  validloss -1056.52484±0.00000  bestvalidloss -1410.05965  last_update 14\n",
      "train: iter 293  trainloss -1356.20134  validloss -1110.09506±0.00000  bestvalidloss -1410.05965  last_update 15\n",
      "train: iter 294  trainloss -1344.19077  validloss -1270.93194±0.00000  bestvalidloss -1410.05965  last_update 16\n",
      "train: iter 295  trainloss -1412.12047  validloss -1294.69375±0.00000  bestvalidloss -1410.05965  last_update 17\n",
      "train: iter 296  trainloss -1242.17991  validloss -1340.61495±0.00000  bestvalidloss -1410.05965  last_update 18\n",
      "train: iter 297  trainloss -1368.49690  validloss -1162.17475±0.00000  bestvalidloss -1410.05965  last_update 19\n",
      "train: iter 298  trainloss -1399.27420  validloss -1261.83776±0.00000  bestvalidloss -1410.05965  last_update 20\n",
      "train: iter 299  trainloss -1404.87947  validloss -1341.90182±0.00000  bestvalidloss -1410.05965  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 300  trainloss -1482.04642  validloss -1334.56676±0.00000  bestvalidloss -1410.05965  last_update 22\n",
      "train: iter 301  trainloss -1478.33273  validloss -1350.54709±0.00000  bestvalidloss -1410.05965  last_update 23\n",
      "train: iter 302  trainloss -1469.93999  validloss -1271.85665±0.00000  bestvalidloss -1410.05965  last_update 24\n",
      "train: iter 303  trainloss -1281.63276  validloss -1365.50796±0.00000  bestvalidloss -1410.05965  last_update 25\n",
      "train: iter 304  trainloss -1452.46651  validloss -1342.78671±0.00000  bestvalidloss -1410.05965  last_update 26\n",
      "train: iter 305  trainloss -1520.89916  validloss -1301.49148±0.00000  bestvalidloss -1410.05965  last_update 27\n",
      "train: iter 306  trainloss -1411.02974  validloss -1411.00836±0.00000  bestvalidloss -1411.00836  last_update 0\n",
      "train: iter 307  trainloss -1376.51203  validloss -1205.45972±0.00000  bestvalidloss -1411.00836  last_update 1\n",
      "train: iter 308  trainloss -1351.13588  validloss -1398.68952±0.00000  bestvalidloss -1411.00836  last_update 2\n",
      "train: iter 309  trainloss -1325.86181  validloss -1023.82147±0.00000  bestvalidloss -1411.00836  last_update 3\n",
      "train: iter 310  trainloss -1458.67879  validloss -1338.89695±0.00000  bestvalidloss -1411.00836  last_update 4\n",
      "train: iter 311  trainloss -1290.32766  validloss -1267.76249±0.00000  bestvalidloss -1411.00836  last_update 5\n",
      "train: iter 312  trainloss -1458.69246  validloss -1301.78953±0.00000  bestvalidloss -1411.00836  last_update 6\n",
      "train: iter 313  trainloss -1474.89246  validloss -1346.42127±0.00000  bestvalidloss -1411.00836  last_update 7\n",
      "train: iter 314  trainloss -1305.24615  validloss -1228.49353±0.00000  bestvalidloss -1411.00836  last_update 8\n",
      "train: iter 315  trainloss -1513.17818  validloss -1359.23587±0.00000  bestvalidloss -1411.00836  last_update 9\n",
      "train: iter 316  trainloss -1499.64442  validloss -1391.75735±0.00000  bestvalidloss -1411.00836  last_update 10\n",
      "train: iter 317  trainloss -1266.62344  validloss -1305.56835±0.00000  bestvalidloss -1411.00836  last_update 11\n",
      "train: iter 318  trainloss -1297.53849  validloss -927.60516±0.00000  bestvalidloss -1411.00836  last_update 12\n",
      "train: iter 319  trainloss -1516.24718  validloss -1379.89060±0.00000  bestvalidloss -1411.00836  last_update 13\n",
      "train: iter 320  trainloss -1508.90382  validloss -1381.86453±0.00000  bestvalidloss -1411.00836  last_update 14\n",
      "train: iter 321  trainloss -1508.16768  validloss -1423.93858±0.00000  bestvalidloss -1423.93858  last_update 0\n",
      "train: iter 322  trainloss -1385.96775  validloss -1379.97498±0.00000  bestvalidloss -1423.93858  last_update 1\n",
      "train: iter 323  trainloss -1491.31990  validloss -1382.15850±0.00000  bestvalidloss -1423.93858  last_update 2\n",
      "train: iter 324  trainloss -1521.14445  validloss -1421.42373±0.00000  bestvalidloss -1423.93858  last_update 3\n",
      "train: iter 325  trainloss -1452.87012  validloss -1257.24150±0.00000  bestvalidloss -1423.93858  last_update 4\n",
      "train: iter 326  trainloss -1324.99414  validloss -1301.52996±0.00000  bestvalidloss -1423.93858  last_update 5\n",
      "train: iter 327  trainloss -1508.34386  validloss -1262.55882±0.00000  bestvalidloss -1423.93858  last_update 6\n",
      "train: iter 328  trainloss -1316.68732  validloss -1434.80119±0.00000  bestvalidloss -1434.80119  last_update 0\n",
      "train: iter 329  trainloss -1488.31343  validloss -1426.61904±0.00000  bestvalidloss -1434.80119  last_update 1\n",
      "train: iter 330  trainloss -1551.09371  validloss -1326.30708±0.00000  bestvalidloss -1434.80119  last_update 2\n",
      "train: iter 331  trainloss -1234.04520  validloss -1381.37598±0.00000  bestvalidloss -1434.80119  last_update 3\n",
      "train: iter 332  trainloss -1488.94221  validloss -1376.17237±0.00000  bestvalidloss -1434.80119  last_update 4\n",
      "train: iter 333  trainloss -1389.90599  validloss -1353.03491±0.00000  bestvalidloss -1434.80119  last_update 5\n",
      "train: iter 334  trainloss -1435.70447  validloss -1399.44502±0.00000  bestvalidloss -1434.80119  last_update 6\n",
      "train: iter 335  trainloss -1406.85319  validloss -1099.41196±0.00000  bestvalidloss -1434.80119  last_update 7\n",
      "train: iter 336  trainloss -1515.53720  validloss -1399.75209±0.00000  bestvalidloss -1434.80119  last_update 8\n",
      "train: iter 337  trainloss -1429.27185  validloss -1403.38185±0.00000  bestvalidloss -1434.80119  last_update 9\n",
      "train: iter 338  trainloss -1218.78862  validloss -1111.38678±0.00000  bestvalidloss -1434.80119  last_update 10\n",
      "train: iter 339  trainloss -1450.00338  validloss -1321.94397±0.00000  bestvalidloss -1434.80119  last_update 11\n",
      "train: iter 340  trainloss -1438.24230  validloss -1359.31462±0.00000  bestvalidloss -1434.80119  last_update 12\n",
      "train: iter 341  trainloss -1482.46225  validloss -1438.27855±0.00000  bestvalidloss -1438.27855  last_update 0\n",
      "train: iter 342  trainloss -1409.80586  validloss -1156.99892±0.00000  bestvalidloss -1438.27855  last_update 1\n",
      "train: iter 343  trainloss -1437.04261  validloss -1312.38879±0.00000  bestvalidloss -1438.27855  last_update 2\n",
      "train: iter 344  trainloss -1254.95046  validloss -996.13037±0.00000  bestvalidloss -1438.27855  last_update 3\n",
      "train: iter 345  trainloss -1390.63992  validloss -1176.69162±0.00000  bestvalidloss -1438.27855  last_update 4\n",
      "train: iter 346  trainloss -1507.33240  validloss -1271.42463±0.00000  bestvalidloss -1438.27855  last_update 5\n",
      "train: iter 347  trainloss -1510.50272  validloss -1436.06486±0.00000  bestvalidloss -1438.27855  last_update 6\n",
      "train: iter 348  trainloss -1521.39922  validloss -1280.34651±0.00000  bestvalidloss -1438.27855  last_update 7\n",
      "train: iter 349  trainloss -1417.84333  validloss -1406.30255±0.00000  bestvalidloss -1438.27855  last_update 8\n",
      "train: iter 350  trainloss -1540.85941  validloss -1462.49669±0.00000  bestvalidloss -1462.49669  last_update 0\n",
      "train: iter 351  trainloss -1406.53181  validloss -1405.81438±0.00000  bestvalidloss -1462.49669  last_update 1\n",
      "train: iter 352  trainloss -1539.61663  validloss -1419.50610±0.00000  bestvalidloss -1462.49669  last_update 2\n",
      "train: iter 353  trainloss -1504.58424  validloss -1376.27384±0.00000  bestvalidloss -1462.49669  last_update 3\n",
      "train: iter 354  trainloss -1541.04598  validloss -1225.70903±0.00000  bestvalidloss -1462.49669  last_update 4\n",
      "train: iter 355  trainloss -1137.03356  validloss -1374.76325±0.00000  bestvalidloss -1462.49669  last_update 5\n",
      "train: iter 356  trainloss -1375.05169  validloss -1076.03049±0.00000  bestvalidloss -1462.49669  last_update 6\n",
      "train: iter 357  trainloss -1514.68230  validloss -1402.27715±0.00000  bestvalidloss -1462.49669  last_update 7\n",
      "train: iter 358  trainloss -1534.40040  validloss -1359.61307±0.00000  bestvalidloss -1462.49669  last_update 8\n",
      "train: iter 359  trainloss -1403.55256  validloss -1478.50977±0.00000  bestvalidloss -1478.50977  last_update 0\n",
      "train: iter 360  trainloss -1512.48436  validloss -1400.72930±0.00000  bestvalidloss -1478.50977  last_update 1\n",
      "train: iter 361  trainloss -1504.30298  validloss -1349.34154±0.00000  bestvalidloss -1478.50977  last_update 2\n",
      "train: iter 362  trainloss -1496.28460  validloss -1458.77861±0.00000  bestvalidloss -1478.50977  last_update 3\n",
      "train: iter 363  trainloss -1404.35695  validloss -1421.21850±0.00000  bestvalidloss -1478.50977  last_update 4\n",
      "train: iter 364  trainloss -1508.79792  validloss -1233.94185±0.00000  bestvalidloss -1478.50977  last_update 5\n",
      "train: iter 365  trainloss -1498.40906  validloss -1439.26774±0.00000  bestvalidloss -1478.50977  last_update 6\n",
      "train: iter 366  trainloss -1381.81525  validloss -1264.54460±0.00000  bestvalidloss -1478.50977  last_update 7\n",
      "train: iter 367  trainloss -1463.28203  validloss -1343.30304±0.00000  bestvalidloss -1478.50977  last_update 8\n",
      "train: iter 368  trainloss -1436.85520  validloss -1428.03646±0.00000  bestvalidloss -1478.50977  last_update 9\n",
      "train: iter 369  trainloss -1565.97819  validloss -1357.84351±0.00000  bestvalidloss -1478.50977  last_update 10\n",
      "train: iter 370  trainloss -1549.69271  validloss -1443.29568±0.00000  bestvalidloss -1478.50977  last_update 11\n",
      "train: iter 371  trainloss -1201.34268  validloss -1222.04994±0.00000  bestvalidloss -1478.50977  last_update 12\n",
      "train: iter 372  trainloss -1540.50178  validloss -1280.22545±0.00000  bestvalidloss -1478.50977  last_update 13\n",
      "train: iter 373  trainloss -1564.12430  validloss -1490.80752±0.00000  bestvalidloss -1490.80752  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 374  trainloss -1375.87180  validloss -1033.75819±0.00000  bestvalidloss -1490.80752  last_update 1\n",
      "train: iter 375  trainloss -1497.50874  validloss -1103.69644±0.00000  bestvalidloss -1490.80752  last_update 2\n",
      "train: iter 376  trainloss -1408.90399  validloss -1424.36769±0.00000  bestvalidloss -1490.80752  last_update 3\n",
      "train: iter 377  trainloss -1453.78034  validloss -1383.27270±0.00000  bestvalidloss -1490.80752  last_update 4\n",
      "train: iter 378  trainloss -1517.29012  validloss -1197.23513±0.00000  bestvalidloss -1490.80752  last_update 5\n",
      "train: iter 379  trainloss -1439.59667  validloss -1395.43085±0.00000  bestvalidloss -1490.80752  last_update 6\n",
      "train: iter 380  trainloss -1476.91740  validloss -910.77309±0.00000  bestvalidloss -1490.80752  last_update 7\n",
      "train: iter 381  trainloss -1518.72811  validloss -1393.27998±0.00000  bestvalidloss -1490.80752  last_update 8\n",
      "train: iter 382  trainloss -1399.44377  validloss -1363.17344±0.00000  bestvalidloss -1490.80752  last_update 9\n",
      "train: iter 383  trainloss -1505.62940  validloss -1393.82761±0.00000  bestvalidloss -1490.80752  last_update 10\n",
      "train: iter 384  trainloss -1563.48679  validloss -1411.86345±0.00000  bestvalidloss -1490.80752  last_update 11\n",
      "train: iter 385  trainloss -1499.39522  validloss -1498.07137±0.00000  bestvalidloss -1498.07137  last_update 0\n",
      "train: iter 386  trainloss -1417.10856  validloss -1361.99255±0.00000  bestvalidloss -1498.07137  last_update 1\n",
      "train: iter 387  trainloss -1448.42609  validloss -1362.12238±0.00000  bestvalidloss -1498.07137  last_update 2\n",
      "train: iter 388  trainloss -1463.89494  validloss -1309.87787±0.00000  bestvalidloss -1498.07137  last_update 3\n",
      "train: iter 389  trainloss -1193.13563  validloss -1422.79829±0.00000  bestvalidloss -1498.07137  last_update 4\n",
      "train: iter 390  trainloss -1216.59008  validloss -917.41540±0.00000  bestvalidloss -1498.07137  last_update 5\n",
      "train: iter 391  trainloss -1470.12917  validloss -1198.12965±0.00000  bestvalidloss -1498.07137  last_update 6\n",
      "train: iter 392  trainloss -1486.40424  validloss -1346.69520±0.00000  bestvalidloss -1498.07137  last_update 7\n",
      "train: iter 393  trainloss -1274.47523  validloss -578.41526±0.00000  bestvalidloss -1498.07137  last_update 8\n",
      "train: iter 394  trainloss -1468.68298  validloss -1326.58753±0.00000  bestvalidloss -1498.07137  last_update 9\n",
      "train: iter 395  trainloss -1530.86984  validloss -1366.51918±0.00000  bestvalidloss -1498.07137  last_update 10\n",
      "train: iter 396  trainloss -1522.71656  validloss -1343.07460±0.00000  bestvalidloss -1498.07137  last_update 11\n",
      "train: iter 397  trainloss -1401.11148  validloss -1337.67659±0.00000  bestvalidloss -1498.07137  last_update 12\n",
      "train: iter 398  trainloss -1111.99158  validloss -709.11979±0.00000  bestvalidloss -1498.07137  last_update 13\n",
      "train: iter 399  trainloss -1450.50657  validloss -1219.11184±0.00000  bestvalidloss -1498.07137  last_update 14\n",
      "train: iter 400  trainloss -1490.55288  validloss -1411.99214±0.00000  bestvalidloss -1498.07137  last_update 15\n",
      "train: iter 401  trainloss -1553.81950  validloss -1402.43007±0.00000  bestvalidloss -1498.07137  last_update 16\n",
      "train: iter 402  trainloss -1554.65856  validloss -1345.09531±0.00000  bestvalidloss -1498.07137  last_update 17\n",
      "train: iter 403  trainloss -1333.90904  validloss -1451.80776±0.00000  bestvalidloss -1498.07137  last_update 18\n",
      "train: iter 404  trainloss -1550.96581  validloss -1276.23834±0.00000  bestvalidloss -1498.07137  last_update 19\n",
      "train: iter 405  trainloss -1614.79128  validloss -1498.35875±0.00000  bestvalidloss -1498.35875  last_update 0\n",
      "train: iter 406  trainloss -1584.97876  validloss -1518.56267±0.00000  bestvalidloss -1518.56267  last_update 0\n",
      "train: iter 407  trainloss -1251.60104  validloss -1371.15813±0.00000  bestvalidloss -1518.56267  last_update 1\n",
      "train: iter 408  trainloss -1417.63920  validloss -1340.01978±0.00000  bestvalidloss -1518.56267  last_update 2\n",
      "train: iter 409  trainloss -1547.17650  validloss -1326.76661±0.00000  bestvalidloss -1518.56267  last_update 3\n",
      "train: iter 410  trainloss -1492.12542  validloss -1398.56895±0.00000  bestvalidloss -1518.56267  last_update 4\n",
      "train: iter 411  trainloss -1466.85397  validloss -1205.93437±0.00000  bestvalidloss -1518.56267  last_update 5\n",
      "train: iter 412  trainloss -1575.07785  validloss -1292.15154±0.00000  bestvalidloss -1518.56267  last_update 6\n",
      "train: iter 413  trainloss -1586.97863  validloss -1485.16845±0.00000  bestvalidloss -1518.56267  last_update 7\n",
      "train: iter 414  trainloss -1583.62017  validloss -1454.17646±0.00000  bestvalidloss -1518.56267  last_update 8\n",
      "train: iter 415  trainloss -1545.88124  validloss -1506.73329±0.00000  bestvalidloss -1518.56267  last_update 9\n",
      "train: iter 416  trainloss -1418.92859  validloss -1206.71534±0.00000  bestvalidloss -1518.56267  last_update 10\n",
      "train: iter 417  trainloss -1497.76199  validloss -1442.77393±0.00000  bestvalidloss -1518.56267  last_update 11\n",
      "train: iter 418  trainloss -1492.42997  validloss -1301.34398±0.00000  bestvalidloss -1518.56267  last_update 12\n",
      "train: iter 419  trainloss -1507.50401  validloss -1409.60488±0.00000  bestvalidloss -1518.56267  last_update 13\n",
      "train: iter 420  trainloss -1363.73001  validloss -976.36299±0.00000  bestvalidloss -1518.56267  last_update 14\n",
      "train: iter 421  trainloss -1525.17753  validloss -1485.11742±0.00000  bestvalidloss -1518.56267  last_update 15\n",
      "train: iter 422  trainloss -1502.97941  validloss -1407.92231±0.00000  bestvalidloss -1518.56267  last_update 16\n",
      "train: iter 423  trainloss -1447.72704  validloss -1174.81789±0.00000  bestvalidloss -1518.56267  last_update 17\n",
      "train: iter 424  trainloss -1580.28596  validloss -1465.81406±0.00000  bestvalidloss -1518.56267  last_update 18\n",
      "train: iter 425  trainloss -1533.37022  validloss -1325.44010±0.00000  bestvalidloss -1518.56267  last_update 19\n",
      "train: iter 426  trainloss -1446.44427  validloss -614.31625±0.00000  bestvalidloss -1518.56267  last_update 20\n",
      "train: iter 427  trainloss -1562.07217  validloss -1461.13861±0.00000  bestvalidloss -1518.56267  last_update 21\n",
      "train: iter 428  trainloss -1575.98713  validloss -1489.72619±0.00000  bestvalidloss -1518.56267  last_update 22\n",
      "train: iter 429  trainloss -1537.95625  validloss -1482.96068±0.00000  bestvalidloss -1518.56267  last_update 23\n",
      "train: iter 430  trainloss -1417.73457  validloss -1254.78051±0.00000  bestvalidloss -1518.56267  last_update 24\n",
      "train: iter 431  trainloss -1517.83634  validloss -1245.31594±0.00000  bestvalidloss -1518.56267  last_update 25\n",
      "train: iter 432  trainloss -1527.00756  validloss -1436.35374±0.00000  bestvalidloss -1518.56267  last_update 26\n",
      "train: iter 433  trainloss -1488.94490  validloss -1301.33563±0.00000  bestvalidloss -1518.56267  last_update 27\n",
      "train: iter 434  trainloss -1520.19501  validloss -1378.00338±0.00000  bestvalidloss -1518.56267  last_update 28\n",
      "train: iter 435  trainloss -1573.17788  validloss -1464.20427±0.00000  bestvalidloss -1518.56267  last_update 29\n",
      "train: iter 436  trainloss -1552.61984  validloss -1519.43164±0.00000  bestvalidloss -1519.43164  last_update 0\n",
      "train: iter 437  trainloss -1582.99432  validloss -1334.66242±0.00000  bestvalidloss -1519.43164  last_update 1\n",
      "train: iter 438  trainloss -1602.08409  validloss -1515.18366±0.00000  bestvalidloss -1519.43164  last_update 2\n",
      "train: iter 439  trainloss -1343.16838  validloss -1283.88506±0.00000  bestvalidloss -1519.43164  last_update 3\n",
      "train: iter 440  trainloss -1566.51668  validloss -1459.15851±0.00000  bestvalidloss -1519.43164  last_update 4\n",
      "train: iter 441  trainloss -1584.43151  validloss -1401.21441±0.00000  bestvalidloss -1519.43164  last_update 5\n",
      "train: iter 442  trainloss -1506.02497  validloss -1490.96039±0.00000  bestvalidloss -1519.43164  last_update 6\n",
      "train: iter 443  trainloss -1456.79823  validloss -1399.14888±0.00000  bestvalidloss -1519.43164  last_update 7\n",
      "train: iter 444  trainloss -1497.08010  validloss -1343.51482±0.00000  bestvalidloss -1519.43164  last_update 8\n",
      "train: iter 445  trainloss -1556.88672  validloss -1243.95648±0.00000  bestvalidloss -1519.43164  last_update 9\n",
      "train: iter 446  trainloss -1487.79676  validloss -1404.46541±0.00000  bestvalidloss -1519.43164  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 447  trainloss -1612.56875  validloss -1484.15637±0.00000  bestvalidloss -1519.43164  last_update 11\n",
      "train: iter 448  trainloss -1564.97225  validloss -1529.46589±0.00000  bestvalidloss -1529.46589  last_update 0\n",
      "train: iter 449  trainloss -1225.34354  validloss -1293.15674±0.00000  bestvalidloss -1529.46589  last_update 1\n",
      "train: iter 450  trainloss -1565.66991  validloss -1425.15126±0.00000  bestvalidloss -1529.46589  last_update 2\n",
      "train: iter 451  trainloss -1574.33181  validloss -1510.41193±0.00000  bestvalidloss -1529.46589  last_update 3\n",
      "train: iter 452  trainloss -1470.91985  validloss -1441.97491±0.00000  bestvalidloss -1529.46589  last_update 4\n",
      "train: iter 453  trainloss -1575.09502  validloss -1312.35189±0.00000  bestvalidloss -1529.46589  last_update 5\n",
      "train: iter 454  trainloss -1514.27404  validloss -1444.41895±0.00000  bestvalidloss -1529.46589  last_update 6\n",
      "train: iter 455  trainloss -1521.89748  validloss -1484.00282±0.00000  bestvalidloss -1529.46589  last_update 7\n",
      "train: iter 456  trainloss -1571.37943  validloss -1271.54421±0.00000  bestvalidloss -1529.46589  last_update 8\n",
      "train: iter 457  trainloss -1514.24340  validloss -1490.27007±0.00000  bestvalidloss -1529.46589  last_update 9\n",
      "train: iter 458  trainloss -1538.80995  validloss -1427.33547±0.00000  bestvalidloss -1529.46589  last_update 10\n",
      "train: iter 459  trainloss -1536.08378  validloss -1234.48435±0.00000  bestvalidloss -1529.46589  last_update 11\n",
      "train: iter 460  trainloss -1415.73770  validloss -1449.22446±0.00000  bestvalidloss -1529.46589  last_update 12\n",
      "train: iter 461  trainloss -1586.04173  validloss -1377.56830±0.00000  bestvalidloss -1529.46589  last_update 13\n",
      "train: iter 462  trainloss -1546.34627  validloss -1390.36475±0.00000  bestvalidloss -1529.46589  last_update 14\n",
      "train: iter 463  trainloss -1351.98241  validloss -530.03987±0.00000  bestvalidloss -1529.46589  last_update 15\n",
      "train: iter 464  trainloss -1554.97703  validloss -1385.91321±0.00000  bestvalidloss -1529.46589  last_update 16\n",
      "train: iter 465  trainloss -1560.49125  validloss -1424.42342±0.00000  bestvalidloss -1529.46589  last_update 17\n",
      "train: iter 466  trainloss -1542.47713  validloss -1442.03987±0.00000  bestvalidloss -1529.46589  last_update 18\n",
      "train: iter 467  trainloss -1575.11495  validloss -1392.02551±0.00000  bestvalidloss -1529.46589  last_update 19\n",
      "train: iter 468  trainloss -1608.19475  validloss -1499.06731±0.00000  bestvalidloss -1529.46589  last_update 20\n",
      "train: iter 469  trainloss -1517.32784  validloss -1417.20932±0.00000  bestvalidloss -1529.46589  last_update 21\n",
      "train: iter 470  trainloss -1603.40891  validloss -1427.06114±0.00000  bestvalidloss -1529.46589  last_update 22\n",
      "train: iter 471  trainloss -1567.45473  validloss -1482.72211±0.00000  bestvalidloss -1529.46589  last_update 23\n",
      "train: iter 472  trainloss -1514.16795  validloss -1481.19944±0.00000  bestvalidloss -1529.46589  last_update 24\n",
      "train: iter 473  trainloss -1545.65338  validloss -1399.84167±0.00000  bestvalidloss -1529.46589  last_update 25\n",
      "train: iter 474  trainloss -1563.18527  validloss -1394.02906±0.00000  bestvalidloss -1529.46589  last_update 26\n",
      "train: iter 475  trainloss -1450.09846  validloss -1374.35561±0.00000  bestvalidloss -1529.46589  last_update 27\n",
      "train: iter 476  trainloss -1540.14032  validloss -1488.43795±0.00000  bestvalidloss -1529.46589  last_update 28\n",
      "train: iter 477  trainloss -1553.14522  validloss -1479.32421±0.00000  bestvalidloss -1529.46589  last_update 29\n",
      "train: iter 478  trainloss -1499.87232  validloss -1293.31865±0.00000  bestvalidloss -1529.46589  last_update 30\n",
      "train: iter 479  trainloss -1494.98232  validloss -1386.96553±0.00000  bestvalidloss -1529.46589  last_update 31\n",
      "train: iter 480  trainloss -1498.35471  validloss -1503.71365±0.00000  bestvalidloss -1529.46589  last_update 32\n",
      "train: iter 481  trainloss -1435.94804  validloss -1445.20435±0.00000  bestvalidloss -1529.46589  last_update 33\n",
      "train: iter 482  trainloss -1554.67322  validloss -1238.15396±0.00000  bestvalidloss -1529.46589  last_update 34\n",
      "train: iter 483  trainloss -1598.97645  validloss -1427.72119±0.00000  bestvalidloss -1529.46589  last_update 35\n",
      "train: iter 484  trainloss -1595.85940  validloss -1466.66953±0.00000  bestvalidloss -1529.46589  last_update 36\n",
      "train: iter 485  trainloss -1586.83673  validloss -1515.53509±0.00000  bestvalidloss -1529.46589  last_update 37\n",
      "train: iter 486  trainloss -1491.33000  validloss -1336.60531±0.00000  bestvalidloss -1529.46589  last_update 38\n",
      "train: iter 487  trainloss -1572.74077  validloss -1422.59381±0.00000  bestvalidloss -1529.46589  last_update 39\n",
      "train: iter 488  trainloss -1496.75349  validloss -1412.74046±0.00000  bestvalidloss -1529.46589  last_update 40\n",
      "train: iter 489  trainloss -1577.46989  validloss -1443.87803±0.00000  bestvalidloss -1529.46589  last_update 41\n",
      "train: iter 490  trainloss -1561.18282  validloss -1498.21533±0.00000  bestvalidloss -1529.46589  last_update 42\n",
      "train: iter 491  trainloss -1522.35841  validloss -1407.42282±0.00000  bestvalidloss -1529.46589  last_update 43\n",
      "train: iter 492  trainloss -1602.55804  validloss -1401.64316±0.00000  bestvalidloss -1529.46589  last_update 44\n",
      "train: iter 493  trainloss -1555.38843  validloss -1410.91597±0.00000  bestvalidloss -1529.46589  last_update 45\n",
      "train: iter 494  trainloss -1496.78600  validloss -1354.89441±0.00000  bestvalidloss -1529.46589  last_update 46\n",
      "train: iter 495  trainloss -1563.31772  validloss -1171.65878±0.00000  bestvalidloss -1529.46589  last_update 47\n",
      "train: iter 496  trainloss -1584.89275  validloss -1448.51935±0.00000  bestvalidloss -1529.46589  last_update 48\n",
      "train: iter 497  trainloss -1539.93270  validloss -1402.26902±0.00000  bestvalidloss -1529.46589  last_update 49\n",
      "train: iter 498  trainloss -1501.01662  validloss -1392.49531±0.00000  bestvalidloss -1529.46589  last_update 50\n",
      "train: iter 499  trainloss -1558.44585  validloss -1453.23781±0.00000  bestvalidloss -1529.46589  last_update 51\n",
      "train: iter 500  trainloss -1610.64998  validloss -1492.22073±0.00000  bestvalidloss -1529.46589  last_update 52\n",
      "train: iter 501  trainloss -1266.47854  validloss -1289.44101±0.00000  bestvalidloss -1529.46589  last_update 53\n",
      "train: iter 502  trainloss -1502.45183  validloss -1245.47550±0.00000  bestvalidloss -1529.46589  last_update 54\n",
      "train: iter 503  trainloss -1562.79472  validloss -1457.12894±0.00000  bestvalidloss -1529.46589  last_update 55\n",
      "train: iter 504  trainloss -1579.08661  validloss -1352.30039±0.00000  bestvalidloss -1529.46589  last_update 56\n",
      "train: iter 505  trainloss -1623.51039  validloss -1499.80611±0.00000  bestvalidloss -1529.46589  last_update 57\n",
      "train: iter 506  trainloss -1453.47689  validloss -1502.73549±0.00000  bestvalidloss -1529.46589  last_update 58\n",
      "train: iter 507  trainloss -1597.31202  validloss -1464.78689±0.00000  bestvalidloss -1529.46589  last_update 59\n",
      "train: iter 508  trainloss -1614.51344  validloss -1403.76508±0.00000  bestvalidloss -1529.46589  last_update 60\n",
      "train: iter 509  trainloss -1600.01486  validloss -1535.59525±0.00000  bestvalidloss -1535.59525  last_update 0\n",
      "train: iter 510  trainloss -1586.60505  validloss -1419.12644±0.00000  bestvalidloss -1535.59525  last_update 1\n",
      "train: iter 511  trainloss -1477.25509  validloss -1365.56922±0.00000  bestvalidloss -1535.59525  last_update 2\n",
      "train: iter 512  trainloss -1536.62742  validloss -1446.02406±0.00000  bestvalidloss -1535.59525  last_update 3\n",
      "train: iter 513  trainloss -1507.28154  validloss -1334.78366±0.00000  bestvalidloss -1535.59525  last_update 4\n",
      "train: iter 514  trainloss -1415.58249  validloss -1356.03431±0.00000  bestvalidloss -1535.59525  last_update 5\n",
      "train: iter 515  trainloss -1566.84767  validloss -1392.34809±0.00000  bestvalidloss -1535.59525  last_update 6\n",
      "train: iter 516  trainloss -1534.31334  validloss -1481.17708±0.00000  bestvalidloss -1535.59525  last_update 7\n",
      "train: iter 517  trainloss -1576.97520  validloss -1489.88086±0.00000  bestvalidloss -1535.59525  last_update 8\n",
      "train: iter 518  trainloss -1619.85280  validloss -1528.43183±0.00000  bestvalidloss -1535.59525  last_update 9\n",
      "train: iter 519  trainloss -1536.59164  validloss -1404.52498±0.00000  bestvalidloss -1535.59525  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 520  trainloss -1489.36840  validloss -1274.62111±0.00000  bestvalidloss -1535.59525  last_update 11\n",
      "train: iter 521  trainloss -1597.45811  validloss -1487.71332±0.00000  bestvalidloss -1535.59525  last_update 12\n",
      "train: iter 522  trainloss -1552.41698  validloss -1362.49575±0.00000  bestvalidloss -1535.59525  last_update 13\n",
      "train: iter 523  trainloss -1657.75633  validloss -1528.91945±0.00000  bestvalidloss -1535.59525  last_update 14\n",
      "train: iter 524  trainloss -1644.11436  validloss -1579.07016±0.00000  bestvalidloss -1579.07016  last_update 0\n",
      "train: iter 525  trainloss -1516.60506  validloss -1443.80021±0.00000  bestvalidloss -1579.07016  last_update 1\n",
      "train: iter 526  trainloss -1435.35868  validloss -741.60954±0.00000  bestvalidloss -1579.07016  last_update 2\n",
      "train: iter 527  trainloss -1564.45565  validloss -1370.17032±0.00000  bestvalidloss -1579.07016  last_update 3\n",
      "train: iter 528  trainloss -1584.35455  validloss -1417.62906±0.00000  bestvalidloss -1579.07016  last_update 4\n",
      "train: iter 529  trainloss -1494.85050  validloss -1430.57930±0.00000  bestvalidloss -1579.07016  last_update 5\n",
      "train: iter 530  trainloss -1634.76792  validloss -1456.36286±0.00000  bestvalidloss -1579.07016  last_update 6\n",
      "train: iter 531  trainloss -1301.88720  validloss -1508.58605±0.00000  bestvalidloss -1579.07016  last_update 7\n",
      "train: iter 532  trainloss -1485.50393  validloss -1133.06353±0.00000  bestvalidloss -1579.07016  last_update 8\n",
      "train: iter 533  trainloss -1490.04750  validloss -1414.67374±0.00000  bestvalidloss -1579.07016  last_update 9\n",
      "train: iter 534  trainloss -1590.73244  validloss -1379.81353±0.00000  bestvalidloss -1579.07016  last_update 10\n",
      "train: iter 535  trainloss -1587.92152  validloss -1405.66149±0.00000  bestvalidloss -1579.07016  last_update 11\n",
      "train: iter 536  trainloss -1609.73083  validloss -1472.87699±0.00000  bestvalidloss -1579.07016  last_update 12\n",
      "train: iter 537  trainloss -1587.72978  validloss -1458.76397±0.00000  bestvalidloss -1579.07016  last_update 13\n",
      "train: iter 538  trainloss -1627.96349  validloss -1491.68057±0.00000  bestvalidloss -1579.07016  last_update 14\n",
      "train: iter 539  trainloss -1644.39249  validloss -1529.31298±0.00000  bestvalidloss -1579.07016  last_update 15\n",
      "train: iter 540  trainloss -1515.08748  validloss -1492.10515±0.00000  bestvalidloss -1579.07016  last_update 16\n",
      "train: iter 541  trainloss -1521.15861  validloss -1385.58355±0.00000  bestvalidloss -1579.07016  last_update 17\n",
      "train: iter 542  trainloss -1643.68740  validloss -1488.49660±0.00000  bestvalidloss -1579.07016  last_update 18\n",
      "train: iter 543  trainloss -1611.56963  validloss -1547.15144±0.00000  bestvalidloss -1579.07016  last_update 19\n",
      "train: iter 544  trainloss -1592.80925  validloss -1563.14512±0.00000  bestvalidloss -1579.07016  last_update 20\n",
      "train: iter 545  trainloss -1522.69599  validloss -1396.53893±0.00000  bestvalidloss -1579.07016  last_update 21\n",
      "train: iter 546  trainloss -1587.86484  validloss -1519.51456±0.00000  bestvalidloss -1579.07016  last_update 22\n",
      "train: iter 547  trainloss -1581.65830  validloss -1351.89654±0.00000  bestvalidloss -1579.07016  last_update 23\n",
      "train: iter 548  trainloss -1569.73232  validloss -1518.37233±0.00000  bestvalidloss -1579.07016  last_update 24\n",
      "train: iter 549  trainloss -1557.93034  validloss -1421.88869±0.00000  bestvalidloss -1579.07016  last_update 25\n",
      "train: iter 550  trainloss -1579.69661  validloss -1525.11868±0.00000  bestvalidloss -1579.07016  last_update 26\n",
      "train: iter 551  trainloss -1551.23172  validloss -1535.61342±0.00000  bestvalidloss -1579.07016  last_update 27\n",
      "train: iter 552  trainloss -1471.84661  validloss -1422.67489±0.00000  bestvalidloss -1579.07016  last_update 28\n",
      "train: iter 553  trainloss -1604.51583  validloss -1265.50233±0.00000  bestvalidloss -1579.07016  last_update 29\n",
      "train: iter 554  trainloss -1646.33105  validloss -1515.91166±0.00000  bestvalidloss -1579.07016  last_update 30\n",
      "train: iter 555  trainloss -1287.92793  validloss -1558.66795±0.00000  bestvalidloss -1579.07016  last_update 31\n",
      "train: iter 556  trainloss -1418.68493  validloss -1076.80106±0.00000  bestvalidloss -1579.07016  last_update 32\n",
      "train: iter 557  trainloss -1608.09378  validloss -1415.31990±0.00000  bestvalidloss -1579.07016  last_update 33\n",
      "train: iter 558  trainloss -1646.25558  validloss -1512.28230±0.00000  bestvalidloss -1579.07016  last_update 34\n",
      "train: iter 559  trainloss -1547.27547  validloss -1509.53064±0.00000  bestvalidloss -1579.07016  last_update 35\n",
      "train: iter 560  trainloss -1625.88841  validloss -1424.36014±0.00000  bestvalidloss -1579.07016  last_update 36\n",
      "train: iter 561  trainloss -1245.69126  validloss -1526.82938±0.00000  bestvalidloss -1579.07016  last_update 37\n",
      "train: iter 562  trainloss -1520.59712  validloss -1211.46620±0.00000  bestvalidloss -1579.07016  last_update 38\n",
      "train: iter 563  trainloss -1615.26501  validloss -1485.41835±0.00000  bestvalidloss -1579.07016  last_update 39\n",
      "train: iter 564  trainloss -1554.38084  validloss -1466.11247±0.00000  bestvalidloss -1579.07016  last_update 40\n",
      "train: iter 565  trainloss -1638.47070  validloss -1487.87826±0.00000  bestvalidloss -1579.07016  last_update 41\n",
      "train: iter 566  trainloss -1638.71574  validloss -1516.09070±0.00000  bestvalidloss -1579.07016  last_update 42\n",
      "train: iter 567  trainloss -1649.49131  validloss -1516.25959±0.00000  bestvalidloss -1579.07016  last_update 43\n",
      "train: iter 568  trainloss -1574.30609  validloss -1535.36307±0.00000  bestvalidloss -1579.07016  last_update 44\n",
      "train: iter 569  trainloss -1591.50537  validloss -1510.37405±0.00000  bestvalidloss -1579.07016  last_update 45\n",
      "train: iter 570  trainloss -1670.93701  validloss -1541.14295±0.00000  bestvalidloss -1579.07016  last_update 46\n",
      "train: iter 571  trainloss -1524.61224  validloss -1583.47744±0.00000  bestvalidloss -1583.47744  last_update 0\n",
      "train: iter 572  trainloss -1569.59174  validloss -1312.47912±0.00000  bestvalidloss -1583.47744  last_update 1\n",
      "train: iter 573  trainloss -1505.31274  validloss -1388.57286±0.00000  bestvalidloss -1583.47744  last_update 2\n",
      "train: iter 574  trainloss -1589.25776  validloss -1493.14305±0.00000  bestvalidloss -1583.47744  last_update 3\n",
      "train: iter 575  trainloss -1579.64451  validloss -1534.11035±0.00000  bestvalidloss -1583.47744  last_update 4\n",
      "train: iter 576  trainloss -1623.06678  validloss -1462.61922±0.00000  bestvalidloss -1583.47744  last_update 5\n",
      "train: iter 577  trainloss -1623.81726  validloss -1544.94764±0.00000  bestvalidloss -1583.47744  last_update 6\n",
      "train: iter 578  trainloss -1627.00900  validloss -1499.50609±0.00000  bestvalidloss -1583.47744  last_update 7\n",
      "train: iter 579  trainloss -1660.33837  validloss -1533.58454±0.00000  bestvalidloss -1583.47744  last_update 8\n",
      "train: iter 580  trainloss -1627.85616  validloss -1562.91099±0.00000  bestvalidloss -1583.47744  last_update 9\n",
      "train: iter 581  trainloss -1642.46416  validloss -1550.48165±0.00000  bestvalidloss -1583.47744  last_update 10\n",
      "train: iter 582  trainloss -1656.90304  validloss -1583.85091±0.00000  bestvalidloss -1583.85091  last_update 0\n",
      "train: iter 583  trainloss -1380.08591  validloss -1533.61968±0.00000  bestvalidloss -1583.85091  last_update 1\n",
      "train: iter 584  trainloss -1421.79279  validloss -1177.86124±0.00000  bestvalidloss -1583.85091  last_update 2\n",
      "train: iter 585  trainloss -1576.97524  validloss -1459.50401±0.00000  bestvalidloss -1583.85091  last_update 3\n",
      "train: iter 586  trainloss -1624.77072  validloss -1523.81665±0.00000  bestvalidloss -1583.85091  last_update 4\n",
      "train: iter 587  trainloss -1669.21448  validloss -1531.94330±0.00000  bestvalidloss -1583.85091  last_update 5\n",
      "train: iter 588  trainloss -1544.25476  validloss -1510.62650±0.00000  bestvalidloss -1583.85091  last_update 6\n",
      "train: iter 589  trainloss -1395.47735  validloss -1471.61199±0.00000  bestvalidloss -1583.85091  last_update 7\n",
      "train: iter 590  trainloss -1604.07967  validloss -1350.86485±0.00000  bestvalidloss -1583.85091  last_update 8\n",
      "train: iter 591  trainloss -1658.04229  validloss -1525.58155±0.00000  bestvalidloss -1583.85091  last_update 9\n",
      "train: iter 592  trainloss -1556.89006  validloss -1474.81708±0.00000  bestvalidloss -1583.85091  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 593  trainloss -1661.40478  validloss -1511.38839±0.00000  bestvalidloss -1583.85091  last_update 11\n",
      "train: iter 594  trainloss -1488.59027  validloss -1508.74234±0.00000  bestvalidloss -1583.85091  last_update 12\n",
      "train: iter 595  trainloss -1627.38718  validloss -1339.84198±0.00000  bestvalidloss -1583.85091  last_update 13\n",
      "train: iter 596  trainloss -1602.83476  validloss -1506.83702±0.00000  bestvalidloss -1583.85091  last_update 14\n",
      "train: iter 597  trainloss -1554.61870  validloss -965.36858±0.00000  bestvalidloss -1583.85091  last_update 15\n",
      "train: iter 598  trainloss -1629.18415  validloss -1359.96767±0.00000  bestvalidloss -1583.85091  last_update 16\n",
      "train: iter 599  trainloss -1566.95092  validloss -1479.50613±0.00000  bestvalidloss -1583.85091  last_update 17\n",
      "train: iter 600  trainloss -1611.27196  validloss -1502.98215±0.00000  bestvalidloss -1583.85091  last_update 18\n",
      "train: iter 601  trainloss -1623.34735  validloss -1554.77635±0.00000  bestvalidloss -1583.85091  last_update 19\n",
      "train: iter 602  trainloss -1592.84473  validloss -1520.65494±0.00000  bestvalidloss -1583.85091  last_update 20\n",
      "train: iter 603  trainloss -1511.51883  validloss -1325.39386±0.00000  bestvalidloss -1583.85091  last_update 21\n",
      "train: iter 604  trainloss -1628.29813  validloss -1459.72958±0.00000  bestvalidloss -1583.85091  last_update 22\n",
      "train: iter 605  trainloss -1651.59044  validloss -1483.03135±0.00000  bestvalidloss -1583.85091  last_update 23\n",
      "train: iter 606  trainloss -1672.41702  validloss -1543.24222±0.00000  bestvalidloss -1583.85091  last_update 24\n",
      "train: iter 607  trainloss -1613.34895  validloss -1585.16897±0.00000  bestvalidloss -1585.16897  last_update 0\n",
      "train: iter 608  trainloss -1421.92017  validloss -831.71348±0.00000  bestvalidloss -1585.16897  last_update 1\n",
      "train: iter 609  trainloss -1630.88837  validloss -1490.86143±0.00000  bestvalidloss -1585.16897  last_update 2\n",
      "train: iter 610  trainloss -1664.51781  validloss -1569.80565±0.00000  bestvalidloss -1585.16897  last_update 3\n",
      "train: iter 611  trainloss -1549.52120  validloss -1586.76514±0.00000  bestvalidloss -1586.76514  last_update 0\n",
      "train: iter 612  trainloss -1505.70333  validloss -1470.03217±0.00000  bestvalidloss -1586.76514  last_update 1\n",
      "train: iter 613  trainloss -1648.52418  validloss -1503.57337±0.00000  bestvalidloss -1586.76514  last_update 2\n",
      "train: iter 614  trainloss -1656.80890  validloss -1569.51928±0.00000  bestvalidloss -1586.76514  last_update 3\n",
      "train: iter 615  trainloss -1666.04958  validloss -1501.42265±0.00000  bestvalidloss -1586.76514  last_update 4\n",
      "train: iter 616  trainloss -1503.27338  validloss -1599.87977±0.00000  bestvalidloss -1599.87977  last_update 0\n",
      "train: iter 617  trainloss -1457.00925  validloss -1041.92956±0.00000  bestvalidloss -1599.87977  last_update 1\n",
      "train: iter 618  trainloss -1594.23409  validloss -1438.95617±0.00000  bestvalidloss -1599.87977  last_update 2\n",
      "train: iter 619  trainloss -1623.77231  validloss -1429.78148±0.00000  bestvalidloss -1599.87977  last_update 3\n",
      "train: iter 620  trainloss -1659.91609  validloss -1519.54896±0.00000  bestvalidloss -1599.87977  last_update 4\n",
      "train: iter 621  trainloss -1570.42714  validloss -1391.97926±0.00000  bestvalidloss -1599.87977  last_update 5\n",
      "train: iter 622  trainloss -1657.22885  validloss -1529.81994±0.00000  bestvalidloss -1599.87977  last_update 6\n",
      "train: iter 623  trainloss -1639.30736  validloss -1433.91004±0.00000  bestvalidloss -1599.87977  last_update 7\n",
      "train: iter 624  trainloss -1643.71332  validloss -1566.99140±0.00000  bestvalidloss -1599.87977  last_update 8\n",
      "train: iter 625  trainloss -1636.46915  validloss -1469.63758±0.00000  bestvalidloss -1599.87977  last_update 9\n",
      "train: iter 626  trainloss -1602.71700  validloss -1572.51340±0.00000  bestvalidloss -1599.87977  last_update 10\n",
      "train: iter 627  trainloss -1643.87826  validloss -1477.04628±0.00000  bestvalidloss -1599.87977  last_update 11\n",
      "train: iter 628  trainloss -1649.01161  validloss -1520.04288±0.00000  bestvalidloss -1599.87977  last_update 12\n",
      "train: iter 629  trainloss -1603.26899  validloss -1555.13124±0.00000  bestvalidloss -1599.87977  last_update 13\n",
      "train: iter 630  trainloss -1353.41390  validloss -1468.51713±0.00000  bestvalidloss -1599.87977  last_update 14\n",
      "train: iter 631  trainloss -1651.61006  validloss -1498.27862±0.00000  bestvalidloss -1599.87977  last_update 15\n",
      "train: iter 632  trainloss -1405.66178  validloss -1534.02738±0.00000  bestvalidloss -1599.87977  last_update 16\n",
      "train: iter 633  trainloss -1634.33798  validloss -1451.98223±0.00000  bestvalidloss -1599.87977  last_update 17\n",
      "train: iter 634  trainloss -1607.30090  validloss -1513.97578±0.00000  bestvalidloss -1599.87977  last_update 18\n",
      "train: iter 635  trainloss -1576.78942  validloss -1403.20261±0.00000  bestvalidloss -1599.87977  last_update 19\n",
      "train: iter 636  trainloss -1672.54439  validloss -1483.75014±0.00000  bestvalidloss -1599.87977  last_update 20\n",
      "train: iter 637  trainloss -1663.80013  validloss -1582.37845±0.00000  bestvalidloss -1599.87977  last_update 21\n",
      "train: iter 638  trainloss -1550.97219  validloss -1345.38413±0.00000  bestvalidloss -1599.87977  last_update 22\n",
      "train: iter 639  trainloss -1660.98150  validloss -1576.27973±0.00000  bestvalidloss -1599.87977  last_update 23\n",
      "train: iter 640  trainloss -1562.73442  validloss -1518.30109±0.00000  bestvalidloss -1599.87977  last_update 24\n",
      "train: iter 641  trainloss -1586.71054  validloss -1379.09767±0.00000  bestvalidloss -1599.87977  last_update 25\n",
      "train: iter 642  trainloss -1598.01887  validloss -1500.62863±0.00000  bestvalidloss -1599.87977  last_update 26\n",
      "train: iter 643  trainloss -1671.56089  validloss -1555.05040±0.00000  bestvalidloss -1599.87977  last_update 27\n",
      "train: iter 644  trainloss -1577.86580  validloss -1408.11684±0.00000  bestvalidloss -1599.87977  last_update 28\n",
      "train: iter 645  trainloss -1681.14391  validloss -1541.53073±0.00000  bestvalidloss -1599.87977  last_update 29\n",
      "train: iter 646  trainloss -1620.95187  validloss -1497.98224±0.00000  bestvalidloss -1599.87977  last_update 30\n",
      "train: iter 647  trainloss -1502.49209  validloss -1502.08676±0.00000  bestvalidloss -1599.87977  last_update 31\n",
      "train: iter 648  trainloss -1543.88609  validloss -1314.82893±0.00000  bestvalidloss -1599.87977  last_update 32\n",
      "train: iter 649  trainloss -1667.89828  validloss -1488.63685±0.00000  bestvalidloss -1599.87977  last_update 33\n",
      "train: iter 650  trainloss -1659.22648  validloss -1424.72249±0.00000  bestvalidloss -1599.87977  last_update 34\n",
      "train: iter 651  trainloss -1689.87125  validloss -1550.01005±0.00000  bestvalidloss -1599.87977  last_update 35\n",
      "train: iter 652  trainloss -1568.27469  validloss -1604.06719±0.00000  bestvalidloss -1604.06719  last_update 0\n",
      "train: iter 653  trainloss -1657.75594  validloss -1454.83283±0.00000  bestvalidloss -1604.06719  last_update 1\n",
      "train: iter 654  trainloss -1687.93123  validloss -1539.87159±0.00000  bestvalidloss -1604.06719  last_update 2\n",
      "train: iter 655  trainloss -1621.13977  validloss -1298.64364±0.00000  bestvalidloss -1604.06719  last_update 3\n",
      "train: iter 656  trainloss -1525.57279  validloss -1471.57174±0.00000  bestvalidloss -1604.06719  last_update 4\n",
      "train: iter 657  trainloss -1615.82165  validloss -1480.28965±0.00000  bestvalidloss -1604.06719  last_update 5\n",
      "train: iter 658  trainloss -1686.59028  validloss -1573.78452±0.00000  bestvalidloss -1604.06719  last_update 6\n",
      "train: iter 659  trainloss -1575.67339  validloss -1546.31458±0.00000  bestvalidloss -1604.06719  last_update 7\n",
      "train: iter 660  trainloss -1650.91106  validloss -1542.65282±0.00000  bestvalidloss -1604.06719  last_update 8\n",
      "train: iter 661  trainloss -1597.06434  validloss -1406.09394±0.00000  bestvalidloss -1604.06719  last_update 9\n",
      "train: iter 662  trainloss -1639.59158  validloss -1568.66436±0.00000  bestvalidloss -1604.06719  last_update 10\n",
      "train: iter 663  trainloss -1686.85261  validloss -1552.27184±0.00000  bestvalidloss -1604.06719  last_update 11\n",
      "train: iter 664  trainloss -1645.63697  validloss -1601.68226±0.00000  bestvalidloss -1604.06719  last_update 12\n",
      "train: iter 665  trainloss -1647.54454  validloss -1496.97749±0.00000  bestvalidloss -1604.06719  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 666  trainloss -1651.63275  validloss -1422.66176±0.00000  bestvalidloss -1604.06719  last_update 14\n",
      "train: iter 667  trainloss -1681.78028  validloss -1565.22130±0.00000  bestvalidloss -1604.06719  last_update 15\n",
      "train: iter 668  trainloss -1461.46442  validloss -1237.36208±0.00000  bestvalidloss -1604.06719  last_update 16\n",
      "train: iter 669  trainloss -1652.89327  validloss -1533.57737±0.00000  bestvalidloss -1604.06719  last_update 17\n",
      "train: iter 670  trainloss -1464.98911  validloss -1497.67773±0.00000  bestvalidloss -1604.06719  last_update 18\n",
      "train: iter 671  trainloss -1619.65506  validloss -1459.74488±0.00000  bestvalidloss -1604.06719  last_update 19\n",
      "train: iter 672  trainloss -1671.86786  validloss -1521.35197±0.00000  bestvalidloss -1604.06719  last_update 20\n",
      "train: iter 673  trainloss -1447.80616  validloss -1523.53426±0.00000  bestvalidloss -1604.06719  last_update 21\n",
      "train: iter 674  trainloss -1566.32145  validloss -1316.22202±0.00000  bestvalidloss -1604.06719  last_update 22\n",
      "train: iter 675  trainloss -1644.40113  validloss -1429.74505±0.00000  bestvalidloss -1604.06719  last_update 23\n",
      "train: iter 676  trainloss -1669.46750  validloss -1524.82320±0.00000  bestvalidloss -1604.06719  last_update 24\n",
      "train: iter 677  trainloss -1674.39517  validloss -1549.00507±0.00000  bestvalidloss -1604.06719  last_update 25\n",
      "train: iter 678  trainloss -1696.06591  validloss -1575.79038±0.00000  bestvalidloss -1604.06719  last_update 26\n",
      "train: iter 679  trainloss -1600.69090  validloss -1599.22262±0.00000  bestvalidloss -1604.06719  last_update 27\n",
      "train: iter 680  trainloss -1640.14697  validloss -1521.96718±0.00000  bestvalidloss -1604.06719  last_update 28\n",
      "train: iter 681  trainloss -1645.71673  validloss -1529.89090±0.00000  bestvalidloss -1604.06719  last_update 29\n",
      "train: iter 682  trainloss -1522.36891  validloss -1519.85949±0.00000  bestvalidloss -1604.06719  last_update 30\n",
      "train: iter 683  trainloss -1560.62014  validloss -1403.31136±0.00000  bestvalidloss -1604.06719  last_update 31\n",
      "train: iter 684  trainloss -1678.63295  validloss -1530.97069±0.00000  bestvalidloss -1604.06719  last_update 32\n",
      "train: iter 685  trainloss -1627.58014  validloss -1505.61912±0.00000  bestvalidloss -1604.06719  last_update 33\n",
      "train: iter 686  trainloss -1653.27427  validloss -1536.08395±0.00000  bestvalidloss -1604.06719  last_update 34\n",
      "train: iter 687  trainloss -1616.61890  validloss -1537.06552±0.00000  bestvalidloss -1604.06719  last_update 35\n",
      "train: iter 688  trainloss -1586.49568  validloss -1447.33254±0.00000  bestvalidloss -1604.06719  last_update 36\n",
      "train: iter 689  trainloss -1188.31723  validloss -1338.90192±0.00000  bestvalidloss -1604.06719  last_update 37\n",
      "train: iter 690  trainloss -1537.91832  validloss -1249.43786±0.00000  bestvalidloss -1604.06719  last_update 38\n",
      "train: iter 691  trainloss -1548.12732  validloss -1487.06146±0.00000  bestvalidloss -1604.06719  last_update 39\n",
      "train: iter 692  trainloss -1609.78066  validloss -1450.85939±0.00000  bestvalidloss -1604.06719  last_update 40\n",
      "train: iter 693  trainloss -1639.38241  validloss -1524.22502±0.00000  bestvalidloss -1604.06719  last_update 41\n",
      "train: iter 694  trainloss -1672.88000  validloss -1448.33065±0.00000  bestvalidloss -1604.06719  last_update 42\n",
      "train: iter 695  trainloss -1664.48249  validloss -1532.04957±0.00000  bestvalidloss -1604.06719  last_update 43\n",
      "train: iter 696  trainloss -1672.60718  validloss -1558.80399±0.00000  bestvalidloss -1604.06719  last_update 44\n",
      "train: iter 697  trainloss -1600.68116  validloss -1496.63057±0.00000  bestvalidloss -1604.06719  last_update 45\n",
      "train: iter 698  trainloss -1652.02766  validloss -1481.65330±0.00000  bestvalidloss -1604.06719  last_update 46\n",
      "train: iter 699  trainloss -1695.99417  validloss -1551.38430±0.00000  bestvalidloss -1604.06719  last_update 47\n",
      "train: iter 700  trainloss -1654.28629  validloss -1577.59251±0.00000  bestvalidloss -1604.06719  last_update 48\n",
      "train: iter 701  trainloss -1666.67804  validloss -1568.54157±0.00000  bestvalidloss -1604.06719  last_update 49\n",
      "train: iter 702  trainloss -1642.56478  validloss -1490.23023±0.00000  bestvalidloss -1604.06719  last_update 50\n",
      "train: iter 703  trainloss -1651.34295  validloss -1541.85823±0.00000  bestvalidloss -1604.06719  last_update 51\n",
      "train: iter 704  trainloss -1600.63848  validloss -1572.31845±0.00000  bestvalidloss -1604.06719  last_update 52\n",
      "train: iter 705  trainloss -1681.79040  validloss -1511.64864±0.00000  bestvalidloss -1604.06719  last_update 53\n",
      "train: iter 706  trainloss -1469.62218  validloss -1523.45890±0.00000  bestvalidloss -1604.06719  last_update 54\n",
      "train: iter 707  trainloss -1598.75624  validloss -1416.54593±0.00000  bestvalidloss -1604.06719  last_update 55\n",
      "train: iter 708  trainloss -1656.19840  validloss -1493.46975±0.00000  bestvalidloss -1604.06719  last_update 56\n",
      "train: iter 709  trainloss -1592.86514  validloss -1182.59766±0.00000  bestvalidloss -1604.06719  last_update 57\n",
      "train: iter 710  trainloss -1687.02278  validloss -1520.55277±0.00000  bestvalidloss -1604.06719  last_update 58\n",
      "train: iter 711  trainloss -1698.31922  validloss -1572.49492±0.00000  bestvalidloss -1604.06719  last_update 59\n",
      "train: iter 712  trainloss -1686.91530  validloss -1613.98943±0.00000  bestvalidloss -1613.98943  last_update 0\n",
      "train: iter 713  trainloss -1699.25952  validloss -1568.88636±0.00000  bestvalidloss -1613.98943  last_update 1\n",
      "train: iter 714  trainloss -1565.01018  validloss -1573.42038±0.00000  bestvalidloss -1613.98943  last_update 2\n",
      "train: iter 715  trainloss -1633.08481  validloss -1532.18763±0.00000  bestvalidloss -1613.98943  last_update 3\n",
      "train: iter 716  trainloss -1699.22773  validloss -1553.02759±0.00000  bestvalidloss -1613.98943  last_update 4\n",
      "train: iter 717  trainloss -1622.31984  validloss -1470.83724±0.00000  bestvalidloss -1613.98943  last_update 5\n",
      "train: iter 718  trainloss -1666.24526  validloss -1487.99539±0.00000  bestvalidloss -1613.98943  last_update 6\n",
      "train: iter 719  trainloss -1673.01456  validloss -1584.52918±0.00000  bestvalidloss -1613.98943  last_update 7\n",
      "train: iter 720  trainloss -1681.60603  validloss -1534.05660±0.00000  bestvalidloss -1613.98943  last_update 8\n",
      "train: iter 721  trainloss -1640.52492  validloss -1590.70018±0.00000  bestvalidloss -1613.98943  last_update 9\n",
      "train: iter 722  trainloss -1680.08028  validloss -1538.64642±0.00000  bestvalidloss -1613.98943  last_update 10\n",
      "train: iter 723  trainloss -1610.74334  validloss -1482.05072±0.00000  bestvalidloss -1613.98943  last_update 11\n",
      "train: iter 724  trainloss -1709.23647  validloss -1566.23804±0.00000  bestvalidloss -1613.98943  last_update 12\n",
      "train: iter 725  trainloss -1652.42321  validloss -1423.03740±0.00000  bestvalidloss -1613.98943  last_update 13\n",
      "train: iter 726  trainloss -1446.78758  validloss -1287.90477±0.00000  bestvalidloss -1613.98943  last_update 14\n",
      "train: iter 727  trainloss -1702.61436  validloss -1541.84572±0.00000  bestvalidloss -1613.98943  last_update 15\n",
      "train: iter 728  trainloss -1694.15954  validloss -1592.33206±0.00000  bestvalidloss -1613.98943  last_update 16\n",
      "train: iter 729  trainloss -1652.72128  validloss -1528.39602±0.00000  bestvalidloss -1613.98943  last_update 17\n",
      "train: iter 730  trainloss -1692.55992  validloss -1585.82185±0.00000  bestvalidloss -1613.98943  last_update 18\n",
      "train: iter 731  trainloss -1303.54000  validloss -1507.79816±0.00000  bestvalidloss -1613.98943  last_update 19\n",
      "train: iter 732  trainloss -1607.19393  validloss -1423.01732±0.00000  bestvalidloss -1613.98943  last_update 20\n",
      "train: iter 733  trainloss -1624.18309  validloss -1464.45255±0.00000  bestvalidloss -1613.98943  last_update 21\n",
      "train: iter 734  trainloss -1678.16201  validloss -1545.06548±0.00000  bestvalidloss -1613.98943  last_update 22\n",
      "train: iter 735  trainloss -1665.76881  validloss -1560.09117±0.00000  bestvalidloss -1613.98943  last_update 23\n",
      "train: iter 736  trainloss -1672.91605  validloss -1501.01612±0.00000  bestvalidloss -1613.98943  last_update 24\n",
      "train: iter 737  trainloss -1474.03481  validloss -1444.99042±0.00000  bestvalidloss -1613.98943  last_update 25\n",
      "train: iter 738  trainloss -1627.31956  validloss -1444.52075±0.00000  bestvalidloss -1613.98943  last_update 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 739  trainloss -1598.02482  validloss -1514.12206±0.00000  bestvalidloss -1613.98943  last_update 27\n",
      "train: iter 740  trainloss -1608.98643  validloss -1466.46756±0.00000  bestvalidloss -1613.98943  last_update 28\n",
      "train: iter 741  trainloss -1665.93458  validloss -1480.74578±0.00000  bestvalidloss -1613.98943  last_update 29\n",
      "train: iter 742  trainloss -1704.00215  validloss -1603.33666±0.00000  bestvalidloss -1613.98943  last_update 30\n",
      "train: iter 743  trainloss -1567.58454  validloss -1584.97353±0.00000  bestvalidloss -1613.98943  last_update 31\n",
      "train: iter 744  trainloss -1662.66293  validloss -1377.79215±0.00000  bestvalidloss -1613.98943  last_update 32\n",
      "train: iter 745  trainloss -1703.66364  validloss -1569.79610±0.00000  bestvalidloss -1613.98943  last_update 33\n",
      "train: iter 746  trainloss -1710.71758  validloss -1546.71503±0.00000  bestvalidloss -1613.98943  last_update 34\n",
      "train: iter 747  trainloss -1657.34457  validloss -1573.66261±0.00000  bestvalidloss -1613.98943  last_update 35\n",
      "train: iter 748  trainloss -1654.12635  validloss -1566.38286±0.00000  bestvalidloss -1613.98943  last_update 36\n",
      "train: iter 749  trainloss -1638.28995  validloss -1444.76139±0.00000  bestvalidloss -1613.98943  last_update 37\n",
      "train: iter 750  trainloss -1718.97226  validloss -1546.76666±0.00000  bestvalidloss -1613.98943  last_update 38\n",
      "train: iter 751  trainloss -1693.58727  validloss -1595.75218±0.00000  bestvalidloss -1613.98943  last_update 39\n",
      "train: iter 752  trainloss -1379.17726  validloss -1557.57468±0.00000  bestvalidloss -1613.98943  last_update 40\n",
      "train: iter 753  trainloss -1552.74681  validloss -1413.26294±0.00000  bestvalidloss -1613.98943  last_update 41\n",
      "train: iter 754  trainloss -1670.25529  validloss -1500.89127±0.00000  bestvalidloss -1613.98943  last_update 42\n",
      "train: iter 755  trainloss -1697.35928  validloss -1566.92727±0.00000  bestvalidloss -1613.98943  last_update 43\n",
      "train: iter 756  trainloss -1693.42317  validloss -1553.49414±0.00000  bestvalidloss -1613.98943  last_update 44\n",
      "train: iter 757  trainloss -1671.95110  validloss -1553.83125±0.00000  bestvalidloss -1613.98943  last_update 45\n",
      "train: iter 758  trainloss -1671.17625  validloss -1553.65311±0.00000  bestvalidloss -1613.98943  last_update 46\n",
      "train: iter 759  trainloss -1585.47317  validloss -1314.02760±0.00000  bestvalidloss -1613.98943  last_update 47\n",
      "train: iter 760  trainloss -1690.02763  validloss -1551.81441±0.00000  bestvalidloss -1613.98943  last_update 48\n",
      "train: iter 761  trainloss -1641.23666  validloss -1594.54218±0.00000  bestvalidloss -1613.98943  last_update 49\n",
      "train: iter 762  trainloss -1639.72278  validloss -1381.33526±0.00000  bestvalidloss -1613.98943  last_update 50\n",
      "train: iter 763  trainloss -1695.63816  validloss -1547.79756±0.00000  bestvalidloss -1613.98943  last_update 51\n",
      "train: iter 764  trainloss -1702.54377  validloss -1615.23011±0.00000  bestvalidloss -1615.23011  last_update 0\n",
      "train: iter 765  trainloss -1634.46655  validloss -1591.53828±0.00000  bestvalidloss -1615.23011  last_update 1\n",
      "train: iter 766  trainloss -1697.01430  validloss -1544.84659±0.00000  bestvalidloss -1615.23011  last_update 2\n",
      "train: iter 767  trainloss -1417.78905  validloss -1608.77836±0.00000  bestvalidloss -1615.23011  last_update 3\n",
      "train: iter 768  trainloss -1618.51276  validloss -1283.52200±0.00000  bestvalidloss -1615.23011  last_update 4\n",
      "train: iter 769  trainloss -1665.36430  validloss -1498.82334±0.00000  bestvalidloss -1615.23011  last_update 5\n",
      "train: iter 770  trainloss -1710.42259  validloss -1589.27487±0.00000  bestvalidloss -1615.23011  last_update 6\n",
      "train: iter 771  trainloss -1693.72544  validloss -1530.80615±0.00000  bestvalidloss -1615.23011  last_update 7\n",
      "train: iter 772  trainloss -1712.97545  validloss -1587.57372±0.00000  bestvalidloss -1615.23011  last_update 8\n",
      "train: iter 773  trainloss -1625.83872  validloss -1485.72014±0.00000  bestvalidloss -1615.23011  last_update 9\n",
      "train: iter 774  trainloss -1721.65533  validloss -1589.98891±0.00000  bestvalidloss -1615.23011  last_update 10\n",
      "train: iter 775  trainloss -1722.02701  validloss -1613.34194±0.00000  bestvalidloss -1615.23011  last_update 11\n",
      "train: iter 776  trainloss -1644.51797  validloss -1504.53057±0.00000  bestvalidloss -1615.23011  last_update 12\n",
      "train: iter 777  trainloss -1567.53327  validloss -1576.96884±0.00000  bestvalidloss -1615.23011  last_update 13\n",
      "train: iter 778  trainloss -1720.74547  validloss -1565.97058±0.00000  bestvalidloss -1615.23011  last_update 14\n",
      "train: iter 779  trainloss -1717.77308  validloss -1580.21648±0.00000  bestvalidloss -1615.23011  last_update 15\n",
      "train: iter 780  trainloss -1644.42607  validloss -1360.70999±0.00000  bestvalidloss -1615.23011  last_update 16\n",
      "train: iter 781  trainloss -1295.36836  validloss -1441.10717±0.00000  bestvalidloss -1615.23011  last_update 17\n",
      "train: iter 782  trainloss -1615.62755  validloss -1487.47087±0.00000  bestvalidloss -1615.23011  last_update 18\n",
      "train: iter 783  trainloss -1644.67599  validloss -1497.19995±0.00000  bestvalidloss -1615.23011  last_update 19\n",
      "train: iter 784  trainloss -1693.99881  validloss -1547.07660±0.00000  bestvalidloss -1615.23011  last_update 20\n",
      "train: iter 785  trainloss -1625.95295  validloss -1594.39132±0.00000  bestvalidloss -1615.23011  last_update 21\n",
      "train: iter 786  trainloss -1621.14580  validloss -1530.66688±0.00000  bestvalidloss -1615.23011  last_update 22\n",
      "train: iter 787  trainloss -1705.98214  validloss -1528.22271±0.00000  bestvalidloss -1615.23011  last_update 23\n",
      "train: iter 788  trainloss -1666.34188  validloss -1560.53273±0.00000  bestvalidloss -1615.23011  last_update 24\n",
      "train: iter 789  trainloss -1710.25574  validloss -1526.18517±0.00000  bestvalidloss -1615.23011  last_update 25\n",
      "train: iter 790  trainloss -1659.92095  validloss -1585.70224±0.00000  bestvalidloss -1615.23011  last_update 26\n",
      "train: iter 791  trainloss -1728.79426  validloss -1577.61938±0.00000  bestvalidloss -1615.23011  last_update 27\n",
      "train: iter 792  trainloss -1631.33392  validloss -1599.37751±0.00000  bestvalidloss -1615.23011  last_update 28\n",
      "train: iter 793  trainloss -1682.98812  validloss -1521.32133±0.00000  bestvalidloss -1615.23011  last_update 29\n",
      "train: iter 794  trainloss -1677.19884  validloss -1435.80672±0.00000  bestvalidloss -1615.23011  last_update 30\n",
      "train: iter 795  trainloss -1668.89874  validloss -1580.96910±0.00000  bestvalidloss -1615.23011  last_update 31\n",
      "train: iter 796  trainloss -1696.40388  validloss -1556.72828±0.00000  bestvalidloss -1615.23011  last_update 32\n",
      "train: iter 797  trainloss -1529.02101  validloss -1609.41427±0.00000  bestvalidloss -1615.23011  last_update 33\n",
      "train: iter 798  trainloss -1619.53221  validloss -1434.94379±0.00000  bestvalidloss -1615.23011  last_update 34\n",
      "train: iter 799  trainloss -1692.75915  validloss -1486.85111±0.00000  bestvalidloss -1615.23011  last_update 35\n",
      "train: iter 800  trainloss -1702.36938  validloss -1587.99694±0.00000  bestvalidloss -1615.23011  last_update 36\n",
      "train: iter 801  trainloss -1674.39270  validloss -1561.41684±0.00000  bestvalidloss -1615.23011  last_update 37\n",
      "train: iter 802  trainloss -1663.92458  validloss -1516.69338±0.00000  bestvalidloss -1615.23011  last_update 38\n",
      "train: iter 803  trainloss -1709.47097  validloss -1594.79870±0.00000  bestvalidloss -1615.23011  last_update 39\n",
      "train: iter 804  trainloss -1583.86854  validloss -1584.17524±0.00000  bestvalidloss -1615.23011  last_update 40\n",
      "train: iter 805  trainloss -1593.48241  validloss -1259.73571±0.00000  bestvalidloss -1615.23011  last_update 41\n",
      "train: iter 806  trainloss -1670.25212  validloss -1528.58410±0.00000  bestvalidloss -1615.23011  last_update 42\n",
      "train: iter 807  trainloss -1718.79609  validloss -1562.76709±0.00000  bestvalidloss -1615.23011  last_update 43\n",
      "train: iter 808  trainloss -1726.66042  validloss -1606.00072±0.00000  bestvalidloss -1615.23011  last_update 44\n",
      "train: iter 809  trainloss -1376.21412  validloss -1553.67611±0.00000  bestvalidloss -1615.23011  last_update 45\n",
      "train: iter 810  trainloss -1626.34965  validloss -1273.39588±0.00000  bestvalidloss -1615.23011  last_update 46\n",
      "train: iter 811  trainloss -1589.24851  validloss -1515.16811±0.00000  bestvalidloss -1615.23011  last_update 47\n",
      "train: iter 812  trainloss -1647.83750  validloss -1449.54288±0.00000  bestvalidloss -1615.23011  last_update 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 813  trainloss -1583.08957  validloss -1540.73299±0.00000  bestvalidloss -1615.23011  last_update 49\n",
      "train: iter 814  trainloss -1660.91342  validloss -1475.19168±0.00000  bestvalidloss -1615.23011  last_update 50\n",
      "train: iter 815  trainloss -1705.19745  validloss -1548.95869±0.00000  bestvalidloss -1615.23011  last_update 51\n",
      "train: iter 816  trainloss -1709.90410  validloss -1593.08433±0.00000  bestvalidloss -1615.23011  last_update 52\n",
      "train: iter 817  trainloss -1687.29413  validloss -1581.64841±0.00000  bestvalidloss -1615.23011  last_update 53\n",
      "train: iter 818  trainloss -1684.06483  validloss -1571.72488±0.00000  bestvalidloss -1615.23011  last_update 54\n",
      "train: iter 819  trainloss -1684.32864  validloss -1614.47143±0.00000  bestvalidloss -1615.23011  last_update 55\n",
      "train: iter 820  trainloss -1689.65857  validloss -1560.05785±0.00000  bestvalidloss -1615.23011  last_update 56\n",
      "train: iter 821  trainloss -1718.24771  validloss -1592.86013±0.00000  bestvalidloss -1615.23011  last_update 57\n",
      "train: iter 822  trainloss -1726.63114  validloss -1619.05800±0.00000  bestvalidloss -1619.05800  last_update 0\n",
      "train: iter 823  trainloss -1458.73807  validloss -1596.46743±0.00000  bestvalidloss -1619.05800  last_update 1\n",
      "train: iter 824  trainloss -1695.21114  validloss -1560.78280±0.00000  bestvalidloss -1619.05800  last_update 2\n",
      "train: iter 825  trainloss -1679.22801  validloss -1496.84051±0.00000  bestvalidloss -1619.05800  last_update 3\n",
      "train: iter 826  trainloss -1582.01581  validloss -1567.81114±0.00000  bestvalidloss -1619.05800  last_update 4\n",
      "train: iter 827  trainloss -1654.84887  validloss -1418.72846±0.00000  bestvalidloss -1619.05800  last_update 5\n",
      "train: iter 828  trainloss -1688.17036  validloss -1535.26194±0.00000  bestvalidloss -1619.05800  last_update 6\n",
      "train: iter 829  trainloss -1671.53062  validloss -1541.25664±0.00000  bestvalidloss -1619.05800  last_update 7\n",
      "train: iter 830  trainloss -1651.18571  validloss -1433.87983±0.00000  bestvalidloss -1619.05800  last_update 8\n",
      "train: iter 831  trainloss -1660.31602  validloss -1583.33181±0.00000  bestvalidloss -1619.05800  last_update 9\n",
      "train: iter 832  trainloss -1590.00497  validloss -1416.60356±0.00000  bestvalidloss -1619.05800  last_update 10\n",
      "train: iter 833  trainloss -1699.04395  validloss -1539.41964±0.00000  bestvalidloss -1619.05800  last_update 11\n",
      "train: iter 834  trainloss -1680.67400  validloss -1584.90809±0.00000  bestvalidloss -1619.05800  last_update 12\n",
      "train: iter 835  trainloss -1689.20266  validloss -1545.47111±0.00000  bestvalidloss -1619.05800  last_update 13\n",
      "train: iter 836  trainloss -1716.40484  validloss -1553.44622±0.00000  bestvalidloss -1619.05800  last_update 14\n",
      "train: iter 837  trainloss -1717.35026  validloss -1600.47788±0.00000  bestvalidloss -1619.05800  last_update 15\n",
      "train: iter 838  trainloss -1728.54975  validloss -1594.33593±0.00000  bestvalidloss -1619.05800  last_update 16\n",
      "train: iter 839  trainloss -1550.51920  validloss -1490.60478±0.00000  bestvalidloss -1619.05800  last_update 17\n",
      "train: iter 840  trainloss -1698.64436  validloss -1367.59803±0.00000  bestvalidloss -1619.05800  last_update 18\n",
      "train: iter 841  trainloss -1706.62712  validloss -1471.91254±0.00000  bestvalidloss -1619.05800  last_update 19\n",
      "train: iter 842  trainloss -1675.05122  validloss -1603.53914±0.00000  bestvalidloss -1619.05800  last_update 20\n",
      "train: iter 843  trainloss -1691.25253  validloss -1534.30251±0.00000  bestvalidloss -1619.05800  last_update 21\n",
      "train: iter 844  trainloss -1700.19543  validloss -1549.85819±0.00000  bestvalidloss -1619.05800  last_update 22\n",
      "train: iter 845  trainloss -1692.67354  validloss -1569.01721±0.00000  bestvalidloss -1619.05800  last_update 23\n",
      "train: iter 846  trainloss -1682.99246  validloss -1458.90853±0.00000  bestvalidloss -1619.05800  last_update 24\n",
      "train: iter 847  trainloss -1718.53457  validloss -1594.75236±0.00000  bestvalidloss -1619.05800  last_update 25\n",
      "train: iter 848  trainloss -1664.42897  validloss -1557.03294±0.00000  bestvalidloss -1619.05800  last_update 26\n",
      "train: iter 849  trainloss -1711.46748  validloss -1514.49241±0.00000  bestvalidloss -1619.05800  last_update 27\n",
      "train: iter 850  trainloss -1707.06952  validloss -1580.78657±0.00000  bestvalidloss -1619.05800  last_update 28\n",
      "train: iter 851  trainloss -1615.07279  validloss -1596.38586±0.00000  bestvalidloss -1619.05800  last_update 29\n",
      "train: iter 852  trainloss -1457.79441  validloss -1339.10899±0.00000  bestvalidloss -1619.05800  last_update 30\n",
      "train: iter 853  trainloss -1672.24934  validloss -1488.21558±0.00000  bestvalidloss -1619.05800  last_update 31\n",
      "train: iter 854  trainloss -1684.32785  validloss -1539.62262±0.00000  bestvalidloss -1619.05800  last_update 32\n",
      "train: iter 855  trainloss -1714.90468  validloss -1550.97473±0.00000  bestvalidloss -1619.05800  last_update 33\n",
      "train: iter 856  trainloss -1667.48214  validloss -1606.32854±0.00000  bestvalidloss -1619.05800  last_update 34\n",
      "train: iter 857  trainloss -1673.69550  validloss -1491.43463±0.00000  bestvalidloss -1619.05800  last_update 35\n",
      "train: iter 858  trainloss -1711.17472  validloss -1547.58320±0.00000  bestvalidloss -1619.05800  last_update 36\n",
      "train: iter 859  trainloss -1684.08178  validloss -1541.73646±0.00000  bestvalidloss -1619.05800  last_update 37\n",
      "train: iter 860  trainloss -1689.11124  validloss -1541.28746±0.00000  bestvalidloss -1619.05800  last_update 38\n",
      "train: iter 861  trainloss -1616.46350  validloss -1516.95318±0.00000  bestvalidloss -1619.05800  last_update 39\n",
      "train: iter 862  trainloss -1681.75411  validloss -1480.23071±0.00000  bestvalidloss -1619.05800  last_update 40\n",
      "train: iter 863  trainloss -1684.07592  validloss -1476.88760±0.00000  bestvalidloss -1619.05800  last_update 41\n",
      "train: iter 864  trainloss -1710.22670  validloss -1547.00569±0.00000  bestvalidloss -1619.05800  last_update 42\n",
      "train: iter 865  trainloss -1706.11440  validloss -1485.49970±0.00000  bestvalidloss -1619.05800  last_update 43\n",
      "train: iter 866  trainloss -1692.91674  validloss -1543.44289±0.00000  bestvalidloss -1619.05800  last_update 44\n",
      "train: iter 867  trainloss -1631.51289  validloss -1392.00991±0.00000  bestvalidloss -1619.05800  last_update 45\n",
      "train: iter 868  trainloss -1707.45727  validloss -1563.06207±0.00000  bestvalidloss -1619.05800  last_update 46\n",
      "train: iter 869  trainloss -1720.23569  validloss -1622.20208±0.00000  bestvalidloss -1622.20208  last_update 0\n",
      "train: iter 870  trainloss -1662.68094  validloss -1505.44043±0.00000  bestvalidloss -1622.20208  last_update 1\n",
      "train: iter 871  trainloss -1700.89457  validloss -1572.26735±0.00000  bestvalidloss -1622.20208  last_update 2\n",
      "train: iter 872  trainloss -1741.15279  validloss -1594.70860±0.00000  bestvalidloss -1622.20208  last_update 3\n",
      "train: iter 873  trainloss -1703.33443  validloss -1542.82355±0.00000  bestvalidloss -1622.20208  last_update 4\n",
      "train: iter 874  trainloss -1469.86002  validloss -1434.36216±0.00000  bestvalidloss -1622.20208  last_update 5\n",
      "train: iter 875  trainloss -1610.48403  validloss -1465.68577±0.00000  bestvalidloss -1622.20208  last_update 6\n",
      "train: iter 876  trainloss -1669.16369  validloss -1507.29976±0.00000  bestvalidloss -1622.20208  last_update 7\n",
      "train: iter 877  trainloss -1707.39796  validloss -1564.06068±0.00000  bestvalidloss -1622.20208  last_update 8\n",
      "train: iter 878  trainloss -1660.51966  validloss -1517.14113±0.00000  bestvalidloss -1622.20208  last_update 9\n",
      "train: iter 879  trainloss -1711.19585  validloss -1519.67504±0.00000  bestvalidloss -1622.20208  last_update 10\n",
      "train: iter 880  trainloss -1715.26095  validloss -1609.90409±0.00000  bestvalidloss -1622.20208  last_update 11\n",
      "train: iter 881  trainloss -1730.63405  validloss -1575.94649±0.00000  bestvalidloss -1622.20208  last_update 12\n",
      "train: iter 882  trainloss -1467.85179  validloss -1585.22096±0.00000  bestvalidloss -1622.20208  last_update 13\n",
      "train: iter 883  trainloss -1679.41589  validloss -1475.51627±0.00000  bestvalidloss -1622.20208  last_update 14\n",
      "train: iter 884  trainloss -1706.59839  validloss -1440.15936±0.00000  bestvalidloss -1622.20208  last_update 15\n",
      "train: iter 885  trainloss -1647.81598  validloss -1527.72005±0.00000  bestvalidloss -1622.20208  last_update 16\n",
      "train: iter 886  trainloss -1714.81836  validloss -1575.18471±0.00000  bestvalidloss -1622.20208  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 887  trainloss -1728.57638  validloss -1615.75201±0.00000  bestvalidloss -1622.20208  last_update 18\n",
      "train: iter 888  trainloss -1709.23022  validloss -1572.14815±0.00000  bestvalidloss -1622.20208  last_update 19\n",
      "train: iter 889  trainloss -1710.91369  validloss -1585.75906±0.00000  bestvalidloss -1622.20208  last_update 20\n",
      "train: iter 890  trainloss -1683.24328  validloss -1582.03535±0.00000  bestvalidloss -1622.20208  last_update 21\n",
      "train: iter 891  trainloss -1682.75786  validloss -1602.49637±0.00000  bestvalidloss -1622.20208  last_update 22\n",
      "train: iter 892  trainloss -1710.45474  validloss -1481.62223±0.00000  bestvalidloss -1622.20208  last_update 23\n",
      "train: iter 893  trainloss -1730.55441  validloss -1584.30907±0.00000  bestvalidloss -1622.20208  last_update 24\n",
      "train: iter 894  trainloss -1659.73670  validloss -1442.45122±0.00000  bestvalidloss -1622.20208  last_update 25\n",
      "train: iter 895  trainloss -1615.89602  validloss -1513.23502±0.00000  bestvalidloss -1622.20208  last_update 26\n",
      "train: iter 896  trainloss -1544.06605  validloss -1189.51684±0.00000  bestvalidloss -1622.20208  last_update 27\n",
      "train: iter 897  trainloss -1683.77323  validloss -1447.56151±0.00000  bestvalidloss -1622.20208  last_update 28\n",
      "train: iter 898  trainloss -1732.24866  validloss -1596.53273±0.00000  bestvalidloss -1622.20208  last_update 29\n",
      "train: iter 899  trainloss -1714.19762  validloss -1562.46051±0.00000  bestvalidloss -1622.20208  last_update 30\n",
      "train: iter 900  trainloss -1723.55629  validloss -1531.93020±0.00000  bestvalidloss -1622.20208  last_update 31\n",
      "train: iter 901  trainloss -1676.01794  validloss -1591.30679±0.00000  bestvalidloss -1622.20208  last_update 32\n",
      "train: iter 902  trainloss -1452.34584  validloss -1130.64944±0.00000  bestvalidloss -1622.20208  last_update 33\n",
      "train: iter 903  trainloss -1602.75131  validloss -1517.80997±0.00000  bestvalidloss -1622.20208  last_update 34\n",
      "train: iter 904  trainloss -1614.07275  validloss -1465.30210±0.00000  bestvalidloss -1622.20208  last_update 35\n",
      "train: iter 905  trainloss -1675.04189  validloss -1535.22252±0.00000  bestvalidloss -1622.20208  last_update 36\n",
      "train: iter 906  trainloss -1717.74342  validloss -1577.41771±0.00000  bestvalidloss -1622.20208  last_update 37\n",
      "train: iter 907  trainloss -1729.00250  validloss -1430.82108±0.00000  bestvalidloss -1622.20208  last_update 38\n",
      "train: iter 908  trainloss -1676.67634  validloss -1590.86077±0.00000  bestvalidloss -1622.20208  last_update 39\n",
      "train: iter 909  trainloss -1684.84344  validloss -1496.78132±0.00000  bestvalidloss -1622.20208  last_update 40\n",
      "train: iter 910  trainloss -1715.45666  validloss -1587.40122±0.00000  bestvalidloss -1622.20208  last_update 41\n",
      "train: iter 911  trainloss -1641.24966  validloss -1565.00033±0.00000  bestvalidloss -1622.20208  last_update 42\n",
      "train: iter 912  trainloss -1703.84240  validloss -1543.46424±0.00000  bestvalidloss -1622.20208  last_update 43\n",
      "train: iter 913  trainloss -1744.71342  validloss -1530.03574±0.00000  bestvalidloss -1622.20208  last_update 44\n",
      "train: iter 914  trainloss -1735.09756  validloss -1609.60002±0.00000  bestvalidloss -1622.20208  last_update 45\n",
      "train: iter 915  trainloss -1312.67473  validloss -1253.46800±0.00000  bestvalidloss -1622.20208  last_update 46\n",
      "train: iter 916  trainloss -1619.91311  validloss -1253.44955±0.00000  bestvalidloss -1622.20208  last_update 47\n",
      "train: iter 917  trainloss -1666.63854  validloss -1486.07403±0.00000  bestvalidloss -1622.20208  last_update 48\n",
      "train: iter 918  trainloss -1693.97846  validloss -1519.21001±0.00000  bestvalidloss -1622.20208  last_update 49\n",
      "train: iter 919  trainloss -1699.40236  validloss -1560.74020±0.00000  bestvalidloss -1622.20208  last_update 50\n",
      "train: iter 920  trainloss -1728.81903  validloss -1577.88398±0.00000  bestvalidloss -1622.20208  last_update 51\n",
      "train: iter 921  trainloss -1721.58605  validloss -1538.15421±0.00000  bestvalidloss -1622.20208  last_update 52\n",
      "train: iter 922  trainloss -1727.84828  validloss -1600.46386±0.00000  bestvalidloss -1622.20208  last_update 53\n",
      "train: iter 923  trainloss -1739.45144  validloss -1605.02297±0.00000  bestvalidloss -1622.20208  last_update 54\n",
      "train: iter 924  trainloss -1717.34402  validloss -1626.98792±0.00000  bestvalidloss -1626.98792  last_update 0\n",
      "train: iter 925  trainloss -1655.21216  validloss -1464.00598±0.00000  bestvalidloss -1626.98792  last_update 1\n",
      "train: iter 926  trainloss -1713.81708  validloss -1582.55140±0.00000  bestvalidloss -1626.98792  last_update 2\n",
      "train: iter 927  trainloss -1739.18553  validloss -1610.33310±0.00000  bestvalidloss -1626.98792  last_update 3\n",
      "train: iter 928  trainloss -1742.26458  validloss -1601.27678±0.00000  bestvalidloss -1626.98792  last_update 4\n",
      "train: iter 929  trainloss -1558.84540  validloss -1453.19067±0.00000  bestvalidloss -1626.98792  last_update 5\n",
      "train: iter 930  trainloss -1713.37301  validloss -1498.77886±0.00000  bestvalidloss -1626.98792  last_update 6\n",
      "train: iter 931  trainloss -1719.22487  validloss -1533.09749±0.00000  bestvalidloss -1626.98792  last_update 7\n",
      "train: iter 932  trainloss -1692.34067  validloss -1501.22790±0.00000  bestvalidloss -1626.98792  last_update 8\n",
      "train: iter 933  trainloss -1746.45090  validloss -1581.59025±0.00000  bestvalidloss -1626.98792  last_update 9\n",
      "train: iter 934  trainloss -1706.72712  validloss -1554.63281±0.00000  bestvalidloss -1626.98792  last_update 10\n",
      "train: iter 935  trainloss -1653.79619  validloss -1444.32080±0.00000  bestvalidloss -1626.98792  last_update 11\n",
      "train: iter 936  trainloss -1747.83791  validloss -1590.76407±0.00000  bestvalidloss -1626.98792  last_update 12\n",
      "train: iter 937  trainloss -1699.54170  validloss -1605.10485±0.00000  bestvalidloss -1626.98792  last_update 13\n",
      "train: iter 938  trainloss -1525.91860  validloss -547.07931±0.00000  bestvalidloss -1626.98792  last_update 14\n",
      "train: iter 939  trainloss -1722.42541  validloss -1552.85217±0.00000  bestvalidloss -1626.98792  last_update 15\n",
      "train: iter 940  trainloss -1689.62918  validloss -1579.02902±0.00000  bestvalidloss -1626.98792  last_update 16\n",
      "train: iter 941  trainloss -1716.13142  validloss -1589.06444±0.00000  bestvalidloss -1626.98792  last_update 17\n",
      "train: iter 942  trainloss -1731.10608  validloss -1558.41845±0.00000  bestvalidloss -1626.98792  last_update 18\n",
      "train: iter 943  trainloss -1722.45436  validloss -1607.74590±0.00000  bestvalidloss -1626.98792  last_update 19\n",
      "train: iter 944  trainloss -1724.12352  validloss -1628.97368±0.00000  bestvalidloss -1628.97368  last_update 0\n",
      "train: iter 945  trainloss -1649.47945  validloss -1551.89621±0.00000  bestvalidloss -1628.97368  last_update 1\n",
      "train: iter 946  trainloss -1664.92134  validloss -1468.66475±0.00000  bestvalidloss -1628.97368  last_update 2\n",
      "train: iter 947  trainloss -1680.57454  validloss -1522.97713±0.00000  bestvalidloss -1628.97368  last_update 3\n",
      "train: iter 948  trainloss -1703.19788  validloss -1587.56185±0.00000  bestvalidloss -1628.97368  last_update 4\n",
      "train: iter 949  trainloss -1578.27573  validloss -1387.11833±0.00000  bestvalidloss -1628.97368  last_update 5\n",
      "train: iter 950  trainloss -1690.52213  validloss -1505.69482±0.00000  bestvalidloss -1628.97368  last_update 6\n",
      "train: iter 951  trainloss -1735.81585  validloss -1556.39947±0.00000  bestvalidloss -1628.97368  last_update 7\n",
      "train: iter 952  trainloss -1718.24743  validloss -1623.25641±0.00000  bestvalidloss -1628.97368  last_update 8\n",
      "train: iter 953  trainloss -1677.57982  validloss -1240.05023±0.00000  bestvalidloss -1628.97368  last_update 9\n",
      "train: iter 954  trainloss -1685.23253  validloss -1587.14650±0.00000  bestvalidloss -1628.97368  last_update 10\n",
      "train: iter 955  trainloss -1709.02222  validloss -1534.66625±0.00000  bestvalidloss -1628.97368  last_update 11\n",
      "train: iter 956  trainloss -1677.31873  validloss -1493.77466±0.00000  bestvalidloss -1628.97368  last_update 12\n",
      "train: iter 957  trainloss -1745.42059  validloss -1604.89763±0.00000  bestvalidloss -1628.97368  last_update 13\n",
      "train: iter 958  trainloss -1479.70469  validloss -1603.73092±0.00000  bestvalidloss -1628.97368  last_update 14\n",
      "train: iter 959  trainloss -1667.20931  validloss -1484.73989±0.00000  bestvalidloss -1628.97368  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 960  trainloss -1665.48901  validloss -1496.98116±0.00000  bestvalidloss -1628.97368  last_update 16\n",
      "train: iter 961  trainloss -1731.49697  validloss -1441.63936±0.00000  bestvalidloss -1628.97368  last_update 17\n",
      "train: iter 962  trainloss -1763.98767  validloss -1641.51914±0.00000  bestvalidloss -1641.51914  last_update 0\n",
      "train: iter 963  trainloss -1612.58581  validloss -1647.78300±0.00000  bestvalidloss -1647.78300  last_update 0\n",
      "train: iter 964  trainloss -1726.86842  validloss -1552.37927±0.00000  bestvalidloss -1647.78300  last_update 1\n",
      "train: iter 965  trainloss -1712.42958  validloss -1604.07447±0.00000  bestvalidloss -1647.78300  last_update 2\n",
      "train: iter 966  trainloss -1735.71029  validloss -1575.44978±0.00000  bestvalidloss -1647.78300  last_update 3\n",
      "train: iter 967  trainloss -1607.49297  validloss -1576.89524±0.00000  bestvalidloss -1647.78300  last_update 4\n",
      "train: iter 968  trainloss -1691.85723  validloss -1534.06225±0.00000  bestvalidloss -1647.78300  last_update 5\n",
      "train: iter 969  trainloss -1740.29557  validloss -1494.35211±0.00000  bestvalidloss -1647.78300  last_update 6\n",
      "train: iter 970  trainloss -1735.66169  validloss -1602.02569±0.00000  bestvalidloss -1647.78300  last_update 7\n",
      "train: iter 971  trainloss -1713.64805  validloss -1591.84056±0.00000  bestvalidloss -1647.78300  last_update 8\n",
      "train: iter 972  trainloss -1687.53836  validloss -1602.91650±0.00000  bestvalidloss -1647.78300  last_update 9\n",
      "train: iter 973  trainloss -1711.71365  validloss -1558.54493±0.00000  bestvalidloss -1647.78300  last_update 10\n",
      "train: iter 974  trainloss -1646.08443  validloss -1512.01633±0.00000  bestvalidloss -1647.78300  last_update 11\n",
      "train: iter 975  trainloss -1716.64595  validloss -1498.80683±0.00000  bestvalidloss -1647.78300  last_update 12\n",
      "train: iter 976  trainloss -1636.64990  validloss -1432.78933±0.00000  bestvalidloss -1647.78300  last_update 13\n",
      "train: iter 977  trainloss -1624.59829  validloss -1299.66396±0.00000  bestvalidloss -1647.78300  last_update 14\n",
      "train: iter 978  trainloss -1742.93024  validloss -1582.44666±0.00000  bestvalidloss -1647.78300  last_update 15\n",
      "train: iter 979  trainloss -1748.13773  validloss -1612.01392±0.00000  bestvalidloss -1647.78300  last_update 16\n",
      "train: iter 980  trainloss -1744.81250  validloss -1643.09552±0.00000  bestvalidloss -1647.78300  last_update 17\n",
      "train: iter 981  trainloss -1733.79475  validloss -1596.24798±0.00000  bestvalidloss -1647.78300  last_update 18\n",
      "train: iter 982  trainloss -1651.61158  validloss -1599.87649±0.00000  bestvalidloss -1647.78300  last_update 19\n",
      "train: iter 983  trainloss -1707.29624  validloss -1428.96777±0.00000  bestvalidloss -1647.78300  last_update 20\n",
      "train: iter 984  trainloss -1661.58503  validloss -1628.82557±0.00000  bestvalidloss -1647.78300  last_update 21\n",
      "train: iter 985  trainloss -1742.18374  validloss -1608.80547±0.00000  bestvalidloss -1647.78300  last_update 22\n",
      "train: iter 986  trainloss -1505.61415  validloss -1096.59971±0.00000  bestvalidloss -1647.78300  last_update 23\n",
      "train: iter 987  trainloss -1652.05122  validloss -1460.57975±0.00000  bestvalidloss -1647.78300  last_update 24\n",
      "train: iter 988  trainloss -1708.95587  validloss -1493.28541±0.00000  bestvalidloss -1647.78300  last_update 25\n",
      "train: iter 989  trainloss -1721.97621  validloss -1557.99111±0.00000  bestvalidloss -1647.78300  last_update 26\n",
      "train: iter 990  trainloss -1675.94060  validloss -1548.74673±0.00000  bestvalidloss -1647.78300  last_update 27\n",
      "train: iter 991  trainloss -1685.66630  validloss -1529.04471±0.00000  bestvalidloss -1647.78300  last_update 28\n",
      "train: iter 992  trainloss -1673.82431  validloss -1454.02173±0.00000  bestvalidloss -1647.78300  last_update 29\n",
      "train: iter 993  trainloss -1562.95077  validloss -1440.64501±0.00000  bestvalidloss -1647.78300  last_update 30\n",
      "train: iter 994  trainloss -1729.21402  validloss -1554.53455±0.00000  bestvalidloss -1647.78300  last_update 31\n",
      "train: iter 995  trainloss -1742.80631  validloss -1576.69463±0.00000  bestvalidloss -1647.78300  last_update 32\n",
      "train: iter 996  trainloss -1694.16005  validloss -1532.94582±0.00000  bestvalidloss -1647.78300  last_update 33\n",
      "train: iter 997  trainloss -1640.33727  validloss -1441.75576±0.00000  bestvalidloss -1647.78300  last_update 34\n",
      "train: iter 998  trainloss -1739.94086  validloss -1492.81225±0.00000  bestvalidloss -1647.78300  last_update 35\n",
      "train: iter 999  trainloss -1753.72420  validloss -1595.88731±0.00000  bestvalidloss -1647.78300  last_update 36\n",
      "train: iter 1000  trainloss -1661.80492  validloss -1555.62660±0.00000  bestvalidloss -1647.78300  last_update 37\n",
      "train: iter 1001  trainloss -1564.08191  validloss -1316.64444±0.00000  bestvalidloss -1647.78300  last_update 38\n",
      "train: iter 1002  trainloss -1744.03782  validloss -1580.12883±0.00000  bestvalidloss -1647.78300  last_update 39\n",
      "train: iter 1003  trainloss -1726.07690  validloss -1515.39052±0.00000  bestvalidloss -1647.78300  last_update 40\n",
      "train: iter 1004  trainloss -1697.49023  validloss -1577.57162±0.00000  bestvalidloss -1647.78300  last_update 41\n",
      "train: iter 1005  trainloss -1721.27234  validloss -1555.60384±0.00000  bestvalidloss -1647.78300  last_update 42\n",
      "train: iter 1006  trainloss -1628.96087  validloss -1475.50302±0.00000  bestvalidloss -1647.78300  last_update 43\n",
      "train: iter 1007  trainloss -1695.83755  validloss -1491.77754±0.00000  bestvalidloss -1647.78300  last_update 44\n",
      "train: iter 1008  trainloss -1742.83001  validloss -1591.05689±0.00000  bestvalidloss -1647.78300  last_update 45\n",
      "train: iter 1009  trainloss -1651.06104  validloss -1586.92634±0.00000  bestvalidloss -1647.78300  last_update 46\n",
      "train: iter 1010  trainloss -1651.03733  validloss -1469.39087±0.00000  bestvalidloss -1647.78300  last_update 47\n",
      "train: iter 1011  trainloss -1722.51718  validloss -1556.04903±0.00000  bestvalidloss -1647.78300  last_update 48\n",
      "train: iter 1012  trainloss -1719.60342  validloss -1599.05201±0.00000  bestvalidloss -1647.78300  last_update 49\n",
      "train: iter 1013  trainloss -1725.13717  validloss -1590.32214±0.00000  bestvalidloss -1647.78300  last_update 50\n",
      "train: iter 1014  trainloss -1761.09014  validloss -1565.10744±0.00000  bestvalidloss -1647.78300  last_update 51\n",
      "train: iter 1015  trainloss -1637.79728  validloss -1442.55889±0.00000  bestvalidloss -1647.78300  last_update 52\n",
      "train: iter 1016  trainloss -1728.74763  validloss -1573.22048±0.00000  bestvalidloss -1647.78300  last_update 53\n",
      "train: iter 1017  trainloss -1698.61193  validloss -1465.49117±0.00000  bestvalidloss -1647.78300  last_update 54\n",
      "train: iter 1018  trainloss -1679.00018  validloss -1551.08901±0.00000  bestvalidloss -1647.78300  last_update 55\n",
      "train: iter 1019  trainloss -1711.21278  validloss -1609.29750±0.00000  bestvalidloss -1647.78300  last_update 56\n",
      "train: iter 1020  trainloss -1588.03963  validloss -565.05827±0.00000  bestvalidloss -1647.78300  last_update 57\n",
      "train: iter 1021  trainloss -1691.13807  validloss -1588.62770±0.00000  bestvalidloss -1647.78300  last_update 58\n",
      "train: iter 1022  trainloss -1735.69827  validloss -1558.81218±0.00000  bestvalidloss -1647.78300  last_update 59\n",
      "train: iter 1023  trainloss -1743.68177  validloss -1614.03271±0.00000  bestvalidloss -1647.78300  last_update 60\n",
      "train: iter 1024  trainloss -1490.20897  validloss -1595.66865±0.00000  bestvalidloss -1647.78300  last_update 61\n",
      "train: iter 1025  trainloss -1679.13925  validloss -1431.26215±0.00000  bestvalidloss -1647.78300  last_update 62\n",
      "train: iter 1026  trainloss -1704.79682  validloss -1547.77886±0.00000  bestvalidloss -1647.78300  last_update 63\n",
      "train: iter 1027  trainloss -1709.24147  validloss -1540.69912±0.00000  bestvalidloss -1647.78300  last_update 64\n",
      "train: iter 1028  trainloss -1721.45618  validloss -1611.80439±0.00000  bestvalidloss -1647.78300  last_update 65\n",
      "train: iter 1029  trainloss -1567.01891  validloss -828.50951±0.00000  bestvalidloss -1647.78300  last_update 66\n",
      "train: iter 1030  trainloss -1727.16564  validloss -1524.42496±0.00000  bestvalidloss -1647.78300  last_update 67\n",
      "train: iter 1031  trainloss -1724.33537  validloss -1555.60161±0.00000  bestvalidloss -1647.78300  last_update 68\n",
      "train: iter 1032  trainloss -1714.67338  validloss -1563.55684±0.00000  bestvalidloss -1647.78300  last_update 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1033  trainloss -1739.43493  validloss -1588.51048±0.00000  bestvalidloss -1647.78300  last_update 70\n",
      "train: iter 1034  trainloss -1605.51462  validloss -1605.81303±0.00000  bestvalidloss -1647.78300  last_update 71\n",
      "train: iter 1035  trainloss -1708.23395  validloss -1457.82008±0.00000  bestvalidloss -1647.78300  last_update 72\n",
      "train: iter 1036  trainloss -1682.04284  validloss -1574.20782±0.00000  bestvalidloss -1647.78300  last_update 73\n",
      "train: iter 1037  trainloss -1738.34223  validloss -1563.45480±0.00000  bestvalidloss -1647.78300  last_update 74\n",
      "train: iter 1038  trainloss -1702.90150  validloss -1586.92542±0.00000  bestvalidloss -1647.78300  last_update 75\n",
      "train: iter 1039  trainloss -1720.41429  validloss -1506.76179±0.00000  bestvalidloss -1647.78300  last_update 76\n",
      "train: iter 1040  trainloss -1615.80568  validloss -1539.14512±0.00000  bestvalidloss -1647.78300  last_update 77\n",
      "train: iter 1041  trainloss -1721.05045  validloss -1531.07558±0.00000  bestvalidloss -1647.78300  last_update 78\n",
      "train: iter 1042  trainloss -1735.34149  validloss -1604.75259±0.00000  bestvalidloss -1647.78300  last_update 79\n",
      "train: iter 1043  trainloss -1701.83226  validloss -1506.34048±0.00000  bestvalidloss -1647.78300  last_update 80\n",
      "train: iter 1044  trainloss -1742.86998  validloss -1604.50836±0.00000  bestvalidloss -1647.78300  last_update 81\n",
      "train: iter 1045  trainloss -1734.69523  validloss -1617.19971±0.00000  bestvalidloss -1647.78300  last_update 82\n",
      "train: iter 1046  trainloss -1731.80579  validloss -1600.21330±0.00000  bestvalidloss -1647.78300  last_update 83\n",
      "train: iter 1047  trainloss -1746.71470  validloss -1628.88474±0.00000  bestvalidloss -1647.78300  last_update 84\n",
      "train: iter 1048  trainloss -1637.73728  validloss -1504.66996±0.00000  bestvalidloss -1647.78300  last_update 85\n",
      "train: iter 1049  trainloss -1661.25686  validloss -1458.41872±0.00000  bestvalidloss -1647.78300  last_update 86\n",
      "train: iter 1050  trainloss -1649.51042  validloss -1415.18814±0.00000  bestvalidloss -1647.78300  last_update 87\n",
      "train: iter 1051  trainloss -1761.41219  validloss -1606.77370±0.00000  bestvalidloss -1647.78300  last_update 88\n",
      "train: iter 1052  trainloss -1741.27265  validloss -1601.29819±0.00000  bestvalidloss -1647.78300  last_update 89\n",
      "train: iter 1053  trainloss -1745.14040  validloss -1634.18078±0.00000  bestvalidloss -1647.78300  last_update 90\n",
      "train: iter 1054  trainloss -1662.73021  validloss -1608.48389±0.00000  bestvalidloss -1647.78300  last_update 91\n",
      "train: iter 1055  trainloss -1470.36935  validloss -562.83309±0.00000  bestvalidloss -1647.78300  last_update 92\n",
      "train: iter 1056  trainloss -1652.88503  validloss -1494.16542±0.00000  bestvalidloss -1647.78300  last_update 93\n",
      "train: iter 1057  trainloss -1739.55197  validloss -1517.07854±0.00000  bestvalidloss -1647.78300  last_update 94\n",
      "train: iter 1058  trainloss -1713.57944  validloss -1557.30804±0.00000  bestvalidloss -1647.78300  last_update 95\n",
      "train: iter 1059  trainloss -1719.82750  validloss -1546.26014±0.00000  bestvalidloss -1647.78300  last_update 96\n",
      "train: iter 1060  trainloss -1681.85054  validloss -1602.07814±0.00000  bestvalidloss -1647.78300  last_update 97\n",
      "train: iter 1061  trainloss -163.85357  validloss 4314.23409±0.00000  bestvalidloss -1647.78300  last_update 98\n",
      "train: iter 1062  trainloss -905.46837  validloss -860.91577±0.00000  bestvalidloss -1647.78300  last_update 99\n",
      "train: iter 1063  trainloss -1548.63107  validloss -1119.60090±0.00000  bestvalidloss -1647.78300  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.6781) penalty_target_max tensor(4.2631)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 6.93166  validloss 7.29966±0.00000  bestvalidloss 7.29966  last_update 0\n",
      "train: iter 1  trainloss 6.36043  validloss 6.64970±0.00000  bestvalidloss 6.64970  last_update 0\n",
      "train: iter 2  trainloss 5.87462  validloss 6.12206±0.00000  bestvalidloss 6.12206  last_update 0\n",
      "train: iter 3  trainloss 5.47874  validloss 5.68782±0.00000  bestvalidloss 5.68782  last_update 0\n",
      "train: iter 4  trainloss 5.15463  validloss 5.33180±0.00000  bestvalidloss 5.33180  last_update 0\n",
      "train: iter 5  trainloss 4.88352  validloss 5.01679±0.00000  bestvalidloss 5.01679  last_update 0\n",
      "train: iter 6  trainloss 4.64030  validloss 4.76092±0.00000  bestvalidloss 4.76092  last_update 0\n",
      "train: iter 7  trainloss 4.43525  validloss 4.53935±0.00000  bestvalidloss 4.53935  last_update 0\n",
      "train: iter 8  trainloss 4.25556  validloss 4.35456±0.00000  bestvalidloss 4.35456  last_update 0\n",
      "train: iter 9  trainloss 4.10474  validloss 4.17768±0.00000  bestvalidloss 4.17768  last_update 0\n",
      "train: iter 10  trainloss 3.95526  validloss 4.02432±0.00000  bestvalidloss 4.02432  last_update 0\n",
      "train: iter 11  trainloss 3.82575  validloss 3.88387±0.00000  bestvalidloss 3.88387  last_update 0\n",
      "train: iter 12  trainloss 3.69949  validloss 3.76626±0.00000  bestvalidloss 3.76626  last_update 0\n",
      "train: iter 13  trainloss 3.58512  validloss 3.63738±0.00000  bestvalidloss 3.63738  last_update 0\n",
      "train: iter 14  trainloss 3.47267  validloss 3.53047±0.00000  bestvalidloss 3.53047  last_update 0\n",
      "train: iter 15  trainloss 3.36976  validloss 3.43424±0.00000  bestvalidloss 3.43424  last_update 0\n",
      "train: iter 16  trainloss 3.26463  validloss 3.31486±0.00000  bestvalidloss 3.31486  last_update 0\n",
      "train: iter 17  trainloss 3.16184  validloss 3.20585±0.00000  bestvalidloss 3.20585  last_update 0\n",
      "train: iter 18  trainloss 3.05619  validloss 3.10868±0.00000  bestvalidloss 3.10868  last_update 0\n",
      "train: iter 19  trainloss 2.95288  validloss 3.00505±0.00000  bestvalidloss 3.00505  last_update 0\n",
      "train: iter 20  trainloss 2.85456  validloss 2.89531±0.00000  bestvalidloss 2.89531  last_update 0\n",
      "train: iter 21  trainloss 2.75022  validloss 2.79820±0.00000  bestvalidloss 2.79820  last_update 0\n",
      "train: iter 22  trainloss 2.64902  validloss 2.69614±0.00000  bestvalidloss 2.69614  last_update 0\n",
      "train: iter 23  trainloss 2.55099  validloss 2.59485±0.00000  bestvalidloss 2.59485  last_update 0\n",
      "train: iter 24  trainloss 2.45351  validloss 2.49852±0.00000  bestvalidloss 2.49852  last_update 0\n",
      "train: iter 25  trainloss 2.35868  validloss 2.39839±0.00000  bestvalidloss 2.39839  last_update 0\n",
      "train: iter 26  trainloss 2.26799  validloss 2.31083±0.00000  bestvalidloss 2.31083  last_update 0\n",
      "train: iter 27  trainloss 2.17962  validloss 2.22246±0.00000  bestvalidloss 2.22246  last_update 0\n",
      "train: iter 28  trainloss 2.09516  validloss 2.13084±0.00000  bestvalidloss 2.13084  last_update 0\n",
      "train: iter 29  trainloss 2.01341  validloss 2.05014±0.00000  bestvalidloss 2.05014  last_update 0\n",
      "train: iter 30  trainloss 1.93596  validloss 1.97042±0.00000  bestvalidloss 1.97042  last_update 0\n",
      "train: iter 31  trainloss 1.85840  validloss 1.89579±0.00000  bestvalidloss 1.89579  last_update 0\n",
      "train: iter 32  trainloss 1.78278  validloss 1.81623±0.00000  bestvalidloss 1.81623  last_update 0\n",
      "train: iter 33  trainloss 1.70789  validloss 1.73955±0.00000  bestvalidloss 1.73955  last_update 0\n",
      "train: iter 34  trainloss 1.63197  validloss 1.66338±0.00000  bestvalidloss 1.66338  last_update 0\n",
      "train: iter 35  trainloss 1.55988  validloss 1.59337±0.00000  bestvalidloss 1.59337  last_update 0\n",
      "train: iter 36  trainloss 1.48062  validloss 1.50498±0.00000  bestvalidloss 1.50498  last_update 0\n",
      "train: iter 37  trainloss 1.40217  validloss 1.43071±0.00000  bestvalidloss 1.43071  last_update 0\n",
      "train: iter 38  trainloss 1.32962  validloss 1.36017±0.00000  bestvalidloss 1.36017  last_update 0\n",
      "train: iter 39  trainloss 1.24769  validloss 1.27106±0.00000  bestvalidloss 1.27106  last_update 0\n",
      "train: iter 40  trainloss 1.16980  validloss 1.19055±0.00000  bestvalidloss 1.19055  last_update 0\n",
      "train: iter 41  trainloss 1.08860  validloss 1.10465±0.00000  bestvalidloss 1.10465  last_update 0\n",
      "train: iter 42  trainloss 1.00995  validloss 1.03878±0.00000  bestvalidloss 1.03878  last_update 0\n",
      "train: iter 43  trainloss 0.93136  validloss 0.94177±0.00000  bestvalidloss 0.94177  last_update 0\n",
      "train: iter 44  trainloss 0.84417  validloss 0.85495±0.00000  bestvalidloss 0.85495  last_update 0\n",
      "train: iter 45  trainloss 0.76774  validloss 0.77411±0.00000  bestvalidloss 0.77411  last_update 0\n",
      "train: iter 46  trainloss 0.69093  validloss 0.69380±0.00000  bestvalidloss 0.69380  last_update 0\n",
      "train: iter 47  trainloss 0.60250  validloss 0.61026±0.00000  bestvalidloss 0.61026  last_update 0\n",
      "train: iter 48  trainloss 0.53116  validloss 0.51925±0.00000  bestvalidloss 0.51925  last_update 0\n",
      "train: iter 49  trainloss 0.45100  validloss 0.43517±0.00000  bestvalidloss 0.43517  last_update 0\n",
      "train: iter 50  trainloss 0.37499  validloss 0.36713±0.00000  bestvalidloss 0.36713  last_update 0\n",
      "train: iter 51  trainloss 0.30768  validloss 0.29115±0.00000  bestvalidloss 0.29115  last_update 0\n",
      "train: iter 52  trainloss 0.24024  validloss 0.21754±0.00000  bestvalidloss 0.21754  last_update 0\n",
      "train: iter 53  trainloss 0.16288  validloss 0.13462±0.00000  bestvalidloss 0.13462  last_update 0\n",
      "train: iter 54  trainloss 0.09612  validloss 0.06310±0.00000  bestvalidloss 0.06310  last_update 0\n",
      "train: iter 55  trainloss 0.03631  validloss 0.00543±0.00000  bestvalidloss 0.00543  last_update 0\n",
      "train: iter 56  trainloss -0.01646  validloss -0.07646±0.00000  bestvalidloss -0.07646  last_update 0\n",
      "train: iter 57  trainloss -0.08738  validloss -0.13759±0.00000  bestvalidloss -0.13759  last_update 0\n",
      "train: iter 58  trainloss -0.13327  validloss -0.20144±0.00000  bestvalidloss -0.20144  last_update 0\n",
      "train: iter 59  trainloss -0.20454  validloss -0.22651±0.00000  bestvalidloss -0.22651  last_update 0\n",
      "train: iter 60  trainloss -0.25393  validloss -0.32450±0.00000  bestvalidloss -0.32450  last_update 0\n",
      "train: iter 61  trainloss -0.29944  validloss -0.36794±0.00000  bestvalidloss -0.36794  last_update 0\n",
      "train: iter 62  trainloss -0.35166  validloss -0.42674±0.00000  bestvalidloss -0.42674  last_update 0\n",
      "train: iter 63  trainloss -0.39919  validloss -0.49095±0.00000  bestvalidloss -0.49095  last_update 0\n",
      "train: iter 64  trainloss -0.46431  validloss -0.51865±0.00000  bestvalidloss -0.51865  last_update 0\n",
      "train: iter 65  trainloss -0.47889  validloss -0.56735±0.00000  bestvalidloss -0.56735  last_update 0\n",
      "train: iter 66  trainloss -0.54983  validloss -0.63587±0.00000  bestvalidloss -0.63587  last_update 0\n",
      "train: iter 67  trainloss -0.57704  validloss -0.68618±0.00000  bestvalidloss -0.68618  last_update 0\n",
      "train: iter 68  trainloss -0.63949  validloss -0.72781±0.00000  bestvalidloss -0.72781  last_update 0\n",
      "train: iter 69  trainloss -0.68203  validloss -0.79403±0.00000  bestvalidloss -0.79403  last_update 0\n",
      "train: iter 70  trainloss -0.72191  validloss -0.82620±0.00000  bestvalidloss -0.82620  last_update 0\n",
      "train: iter 71  trainloss -0.74162  validloss -0.86391±0.00000  bestvalidloss -0.86391  last_update 0\n",
      "train: iter 72  trainloss -0.79200  validloss -0.91887±0.00000  bestvalidloss -0.91887  last_update 0\n",
      "train: iter 73  trainloss -0.87015  validloss -0.95934±0.00000  bestvalidloss -0.95934  last_update 0\n",
      "train: iter 74  trainloss -0.86457  validloss -0.97933±0.00000  bestvalidloss -0.97933  last_update 0\n",
      "train: iter 75  trainloss -0.92372  validloss -1.06159±0.00000  bestvalidloss -1.06159  last_update 0\n",
      "train: iter 76  trainloss -0.94613  validloss -1.14336±0.00000  bestvalidloss -1.14336  last_update 0\n",
      "train: iter 77  trainloss -1.01751  validloss -1.10657±0.00000  bestvalidloss -1.14336  last_update 1\n",
      "train: iter 78  trainloss -1.02930  validloss -1.14071±0.00000  bestvalidloss -1.14336  last_update 2\n",
      "train: iter 79  trainloss -1.05771  validloss -1.23054±0.00000  bestvalidloss -1.23054  last_update 0\n",
      "train: iter 80  trainloss -1.11884  validloss -1.30200±0.00000  bestvalidloss -1.30200  last_update 0\n",
      "train: iter 81  trainloss -1.16353  validloss -1.30730±0.00000  bestvalidloss -1.30730  last_update 0\n",
      "train: iter 82  trainloss -1.19379  validloss -1.32383±0.00000  bestvalidloss -1.32383  last_update 0\n",
      "train: iter 83  trainloss -1.22278  validloss -1.38294±0.00000  bestvalidloss -1.38294  last_update 0\n",
      "train: iter 84  trainloss -1.24025  validloss -1.37988±0.00000  bestvalidloss -1.38294  last_update 1\n",
      "train: iter 85  trainloss -1.30496  validloss -1.44000±0.00000  bestvalidloss -1.44000  last_update 0\n",
      "train: iter 86  trainloss -1.33122  validloss -1.50356±0.00000  bestvalidloss -1.50356  last_update 0\n",
      "train: iter 87  trainloss -1.36009  validloss -1.55594±0.00000  bestvalidloss -1.55594  last_update 0\n",
      "train: iter 88  trainloss -1.38946  validloss -1.55947±0.00000  bestvalidloss -1.55947  last_update 0\n",
      "train: iter 89  trainloss -1.47973  validloss -1.59417±0.00000  bestvalidloss -1.59417  last_update 0\n",
      "train: iter 90  trainloss -1.43853  validloss -1.61676±0.00000  bestvalidloss -1.61676  last_update 0\n",
      "train: iter 91  trainloss -1.49631  validloss -1.66092±0.00000  bestvalidloss -1.66092  last_update 0\n",
      "train: iter 92  trainloss -1.54706  validloss -1.68186±0.00000  bestvalidloss -1.68186  last_update 0\n",
      "train: iter 93  trainloss -1.54010  validloss -1.73315±0.00000  bestvalidloss -1.73315  last_update 0\n",
      "train: iter 94  trainloss -1.60405  validloss -1.75585±0.00000  bestvalidloss -1.75585  last_update 0\n",
      "train: iter 95  trainloss -1.61706  validloss -1.75464±0.00000  bestvalidloss -1.75585  last_update 1\n",
      "train: iter 96  trainloss -1.65069  validloss -1.87429±0.00000  bestvalidloss -1.87429  last_update 0\n",
      "train: iter 97  trainloss -1.68539  validloss -1.87494±0.00000  bestvalidloss -1.87494  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 98  trainloss -1.69761  validloss -1.86069±0.00000  bestvalidloss -1.87494  last_update 1\n",
      "train: iter 99  trainloss -1.71484  validloss -1.88351±0.00000  bestvalidloss -1.88351  last_update 0\n",
      "train: iter 100  trainloss -1.74615  validloss -1.96227±0.00000  bestvalidloss -1.96227  last_update 0\n",
      "train: iter 101  trainloss -1.82253  validloss -1.98207±0.00000  bestvalidloss -1.98207  last_update 0\n",
      "train: iter 102  trainloss -1.83528  validloss -2.00049±0.00000  bestvalidloss -2.00049  last_update 0\n",
      "train: iter 103  trainloss -1.82822  validloss -2.08248±0.00000  bestvalidloss -2.08248  last_update 0\n",
      "train: iter 104  trainloss -1.86791  validloss -2.09415±0.00000  bestvalidloss -2.09415  last_update 0\n",
      "train: iter 105  trainloss -1.87319  validloss -2.13151±0.00000  bestvalidloss -2.13151  last_update 0\n",
      "train: iter 106  trainloss -1.88267  validloss -2.05710±0.00000  bestvalidloss -2.13151  last_update 1\n",
      "train: iter 107  trainloss -1.93222  validloss -2.19585±0.00000  bestvalidloss -2.19585  last_update 0\n",
      "train: iter 108  trainloss -1.95709  validloss -2.17144±0.00000  bestvalidloss -2.19585  last_update 1\n",
      "train: iter 109  trainloss -1.95419  validloss -2.19574±0.00000  bestvalidloss -2.19585  last_update 2\n",
      "train: iter 110  trainloss -1.94100  validloss -2.15029±0.00000  bestvalidloss -2.19585  last_update 3\n",
      "train: iter 111  trainloss -1.96955  validloss -2.13952±0.00000  bestvalidloss -2.19585  last_update 4\n",
      "train: iter 112  trainloss -1.98571  validloss -2.22345±0.00000  bestvalidloss -2.22345  last_update 0\n",
      "train: iter 113  trainloss -1.98877  validloss -2.21169±0.00000  bestvalidloss -2.22345  last_update 1\n",
      "train: iter 114  trainloss -2.00984  validloss -2.32402±0.00000  bestvalidloss -2.32402  last_update 0\n",
      "train: iter 115  trainloss -2.02628  validloss -2.32394±0.00000  bestvalidloss -2.32402  last_update 1\n",
      "train: iter 116  trainloss -2.05452  validloss -2.25993±0.00000  bestvalidloss -2.32402  last_update 2\n",
      "train: iter 117  trainloss -2.06088  validloss -2.23317±0.00000  bestvalidloss -2.32402  last_update 3\n",
      "train: iter 118  trainloss -2.04416  validloss -2.29331±0.00000  bestvalidloss -2.32402  last_update 4\n",
      "train: iter 119  trainloss -2.03705  validloss -2.31842±0.00000  bestvalidloss -2.32402  last_update 5\n",
      "train: iter 120  trainloss -2.06841  validloss -2.29627±0.00000  bestvalidloss -2.32402  last_update 6\n",
      "train: iter 121  trainloss -2.13980  validloss -2.36642±0.00000  bestvalidloss -2.36642  last_update 0\n",
      "train: iter 122  trainloss -2.09759  validloss -2.24643±0.00000  bestvalidloss -2.36642  last_update 1\n",
      "train: iter 123  trainloss -2.09878  validloss -2.34687±0.00000  bestvalidloss -2.36642  last_update 2\n",
      "train: iter 124  trainloss -2.04791  validloss -2.34398±0.00000  bestvalidloss -2.36642  last_update 3\n",
      "train: iter 125  trainloss -2.07800  validloss -2.31183±0.00000  bestvalidloss -2.36642  last_update 4\n",
      "train: iter 126  trainloss -2.02886  validloss -2.27033±0.00000  bestvalidloss -2.36642  last_update 5\n",
      "train: iter 127  trainloss -2.03765  validloss -2.40326±0.00000  bestvalidloss -2.40326  last_update 0\n",
      "train: iter 128  trainloss -2.05656  validloss -2.35080±0.00000  bestvalidloss -2.40326  last_update 1\n",
      "train: iter 129  trainloss -2.09334  validloss -2.21581±0.00000  bestvalidloss -2.40326  last_update 2\n",
      "train: iter 130  trainloss -2.09684  validloss -2.40723±0.00000  bestvalidloss -2.40723  last_update 0\n",
      "train: iter 131  trainloss -2.05032  validloss -2.32261±0.00000  bestvalidloss -2.40723  last_update 1\n",
      "train: iter 132  trainloss -2.05712  validloss -2.38896±0.00000  bestvalidloss -2.40723  last_update 2\n",
      "train: iter 133  trainloss -2.01605  validloss -2.40064±0.00000  bestvalidloss -2.40723  last_update 3\n",
      "train: iter 134  trainloss -2.11970  validloss -2.33147±0.00000  bestvalidloss -2.40723  last_update 4\n",
      "train: iter 135  trainloss -2.07348  validloss -2.45931±0.00000  bestvalidloss -2.45931  last_update 0\n",
      "train: iter 136  trainloss -2.02128  validloss -2.37269±0.00000  bestvalidloss -2.45931  last_update 1\n",
      "train: iter 137  trainloss -2.06088  validloss -2.47999±0.00000  bestvalidloss -2.47999  last_update 0\n",
      "train: iter 138  trainloss -2.10030  validloss -2.45681±0.00000  bestvalidloss -2.47999  last_update 1\n",
      "train: iter 139  trainloss -2.13929  validloss -2.44093±0.00000  bestvalidloss -2.47999  last_update 2\n",
      "train: iter 140  trainloss -2.07073  validloss -2.43417±0.00000  bestvalidloss -2.47999  last_update 3\n",
      "train: iter 141  trainloss -2.15090  validloss -2.37899±0.00000  bestvalidloss -2.47999  last_update 4\n",
      "train: iter 142  trainloss -2.02750  validloss -2.28119±0.00000  bestvalidloss -2.47999  last_update 5\n",
      "train: iter 143  trainloss -2.07094  validloss -2.40673±0.00000  bestvalidloss -2.47999  last_update 6\n",
      "train: iter 144  trainloss -2.03462  validloss -2.34607±0.00000  bestvalidloss -2.47999  last_update 7\n",
      "train: iter 145  trainloss -2.07885  validloss -2.40200±0.00000  bestvalidloss -2.47999  last_update 8\n",
      "train: iter 146  trainloss -2.13908  validloss -2.31125±0.00000  bestvalidloss -2.47999  last_update 9\n",
      "train: iter 147  trainloss -2.08855  validloss -2.32107±0.00000  bestvalidloss -2.47999  last_update 10\n",
      "train: iter 148  trainloss -2.12032  validloss -2.44886±0.00000  bestvalidloss -2.47999  last_update 11\n",
      "train: iter 149  trainloss -2.06969  validloss -2.33282±0.00000  bestvalidloss -2.47999  last_update 12\n",
      "train: iter 150  trainloss -2.03933  validloss -2.50673±0.00000  bestvalidloss -2.50673  last_update 0\n",
      "train: iter 151  trainloss -2.10047  validloss -2.39689±0.00000  bestvalidloss -2.50673  last_update 1\n",
      "train: iter 152  trainloss -2.11912  validloss -2.35094±0.00000  bestvalidloss -2.50673  last_update 2\n",
      "train: iter 153  trainloss -2.06013  validloss -2.20451±0.00000  bestvalidloss -2.50673  last_update 3\n",
      "train: iter 154  trainloss -2.06249  validloss -2.46269±0.00000  bestvalidloss -2.50673  last_update 4\n",
      "train: iter 155  trainloss -2.07942  validloss -2.44055±0.00000  bestvalidloss -2.50673  last_update 5\n",
      "train: iter 156  trainloss -2.07652  validloss -2.36029±0.00000  bestvalidloss -2.50673  last_update 6\n",
      "train: iter 157  trainloss -1.99892  validloss -2.24842±0.00000  bestvalidloss -2.50673  last_update 7\n",
      "train: iter 158  trainloss -2.10727  validloss -2.35044±0.00000  bestvalidloss -2.50673  last_update 8\n",
      "train: iter 159  trainloss -2.10176  validloss -2.39512±0.00000  bestvalidloss -2.50673  last_update 9\n",
      "train: iter 160  trainloss -2.12908  validloss -2.40909±0.00000  bestvalidloss -2.50673  last_update 10\n",
      "train: iter 161  trainloss -2.03198  validloss -2.39794±0.00000  bestvalidloss -2.50673  last_update 11\n",
      "train: iter 162  trainloss -2.13653  validloss -2.37946±0.00000  bestvalidloss -2.50673  last_update 12\n",
      "train: iter 163  trainloss -2.07555  validloss -2.37360±0.00000  bestvalidloss -2.50673  last_update 13\n",
      "train: iter 164  trainloss -2.09539  validloss -2.41131±0.00000  bestvalidloss -2.50673  last_update 14\n",
      "train: iter 165  trainloss -2.06667  validloss -2.32944±0.00000  bestvalidloss -2.50673  last_update 15\n",
      "train: iter 166  trainloss -2.09116  validloss -2.34639±0.00000  bestvalidloss -2.50673  last_update 16\n",
      "train: iter 167  trainloss -2.17122  validloss -2.44113±0.00000  bestvalidloss -2.50673  last_update 17\n",
      "train: iter 168  trainloss -2.18999  validloss -2.44027±0.00000  bestvalidloss -2.50673  last_update 18\n",
      "train: iter 169  trainloss -2.10228  validloss -2.42645±0.00000  bestvalidloss -2.50673  last_update 19\n",
      "train: iter 170  trainloss -2.03339  validloss -2.48393±0.00000  bestvalidloss -2.50673  last_update 20\n",
      "train: iter 171  trainloss -2.15985  validloss -2.40163±0.00000  bestvalidloss -2.50673  last_update 21\n",
      "train: iter 172  trainloss -2.14270  validloss -2.27498±0.00000  bestvalidloss -2.50673  last_update 22\n",
      "train: iter 173  trainloss -2.07384  validloss -2.38483±0.00000  bestvalidloss -2.50673  last_update 23\n",
      "train: iter 174  trainloss -2.12407  validloss -2.33703±0.00000  bestvalidloss -2.50673  last_update 24\n",
      "train: iter 175  trainloss -2.06733  validloss -2.44749±0.00000  bestvalidloss -2.50673  last_update 25\n",
      "train: iter 176  trainloss -2.09085  validloss -2.37538±0.00000  bestvalidloss -2.50673  last_update 26\n",
      "train: iter 177  trainloss -2.06059  validloss -2.33789±0.00000  bestvalidloss -2.50673  last_update 27\n",
      "train: iter 178  trainloss -2.08198  validloss -2.39564±0.00000  bestvalidloss -2.50673  last_update 28\n",
      "train: iter 179  trainloss -2.14043  validloss -2.47171±0.00000  bestvalidloss -2.50673  last_update 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 180  trainloss -2.11404  validloss -2.44995±0.00000  bestvalidloss -2.50673  last_update 30\n",
      "train: iter 181  trainloss -2.12223  validloss -2.35465±0.00000  bestvalidloss -2.50673  last_update 31\n",
      "train: iter 182  trainloss -2.07929  validloss -2.40492±0.00000  bestvalidloss -2.50673  last_update 32\n",
      "train: iter 183  trainloss -2.13861  validloss -2.26857±0.00000  bestvalidloss -2.50673  last_update 33\n",
      "train: iter 184  trainloss -2.08081  validloss -2.45539±0.00000  bestvalidloss -2.50673  last_update 34\n",
      "train: iter 185  trainloss -2.09516  validloss -2.50647±0.00000  bestvalidloss -2.50673  last_update 35\n",
      "train: iter 186  trainloss -2.05563  validloss -2.47938±0.00000  bestvalidloss -2.50673  last_update 36\n",
      "train: iter 187  trainloss -2.13150  validloss -2.40855±0.00000  bestvalidloss -2.50673  last_update 37\n",
      "train: iter 188  trainloss -2.12175  validloss -2.36788±0.00000  bestvalidloss -2.50673  last_update 38\n",
      "train: iter 189  trainloss -2.03012  validloss -2.34565±0.00000  bestvalidloss -2.50673  last_update 39\n",
      "train: iter 190  trainloss -2.12692  validloss -2.38101±0.00000  bestvalidloss -2.50673  last_update 40\n",
      "train: iter 191  trainloss -2.10390  validloss -2.32497±0.00000  bestvalidloss -2.50673  last_update 41\n",
      "train: iter 192  trainloss -2.14204  validloss -2.28506±0.00000  bestvalidloss -2.50673  last_update 42\n",
      "train: iter 193  trainloss -2.11469  validloss -2.50546±0.00000  bestvalidloss -2.50673  last_update 43\n",
      "train: iter 194  trainloss -2.13700  validloss -2.42247±0.00000  bestvalidloss -2.50673  last_update 44\n",
      "train: iter 195  trainloss -2.08063  validloss -2.41349±0.00000  bestvalidloss -2.50673  last_update 45\n",
      "train: iter 196  trainloss -2.17498  validloss -2.29178±0.00000  bestvalidloss -2.50673  last_update 46\n",
      "train: iter 197  trainloss -2.06437  validloss -2.42052±0.00000  bestvalidloss -2.50673  last_update 47\n",
      "train: iter 198  trainloss -2.03223  validloss -2.41631±0.00000  bestvalidloss -2.50673  last_update 48\n",
      "train: iter 199  trainloss -2.04153  validloss -2.40340±0.00000  bestvalidloss -2.50673  last_update 49\n",
      "train: iter 200  trainloss -2.02153  validloss -2.36158±0.00000  bestvalidloss -2.50673  last_update 50\n",
      "train: iter 201  trainloss -2.10902  validloss -2.41535±0.00000  bestvalidloss -2.50673  last_update 51\n",
      "train: iter 202  trainloss -2.12448  validloss -2.49370±0.00000  bestvalidloss -2.50673  last_update 52\n",
      "train: iter 203  trainloss -2.14079  validloss -2.35156±0.00000  bestvalidloss -2.50673  last_update 53\n",
      "train: iter 204  trainloss -2.07381  validloss -2.42019±0.00000  bestvalidloss -2.50673  last_update 54\n",
      "train: iter 205  trainloss -2.07444  validloss -2.43016±0.00000  bestvalidloss -2.50673  last_update 55\n",
      "train: iter 206  trainloss -2.08766  validloss -2.48089±0.00000  bestvalidloss -2.50673  last_update 56\n",
      "train: iter 207  trainloss -2.06014  validloss -2.38788±0.00000  bestvalidloss -2.50673  last_update 57\n",
      "train: iter 208  trainloss -2.06645  validloss -2.33749±0.00000  bestvalidloss -2.50673  last_update 58\n",
      "train: iter 209  trainloss -2.04558  validloss -2.50509±0.00000  bestvalidloss -2.50673  last_update 59\n",
      "train: iter 210  trainloss -2.13352  validloss -2.41901±0.00000  bestvalidloss -2.50673  last_update 60\n",
      "train: iter 211  trainloss -2.00435  validloss -2.37066±0.00000  bestvalidloss -2.50673  last_update 61\n",
      "train: iter 212  trainloss -2.10096  validloss -2.47805±0.00000  bestvalidloss -2.50673  last_update 62\n",
      "train: iter 213  trainloss -2.08442  validloss -2.32846±0.00000  bestvalidloss -2.50673  last_update 63\n",
      "train: iter 214  trainloss -2.03397  validloss -2.33998±0.00000  bestvalidloss -2.50673  last_update 64\n",
      "train: iter 215  trainloss -2.17124  validloss -2.33939±0.00000  bestvalidloss -2.50673  last_update 65\n",
      "train: iter 216  trainloss -2.09483  validloss -2.38264±0.00000  bestvalidloss -2.50673  last_update 66\n",
      "train: iter 217  trainloss -2.03991  validloss -2.41958±0.00000  bestvalidloss -2.50673  last_update 67\n",
      "train: iter 218  trainloss -2.04692  validloss -2.36818±0.00000  bestvalidloss -2.50673  last_update 68\n",
      "train: iter 219  trainloss -2.10540  validloss -2.40237±0.00000  bestvalidloss -2.50673  last_update 69\n",
      "train: iter 220  trainloss -2.12805  validloss -2.46261±0.00000  bestvalidloss -2.50673  last_update 70\n",
      "train: iter 221  trainloss -2.13015  validloss -2.41543±0.00000  bestvalidloss -2.50673  last_update 71\n",
      "train: iter 222  trainloss -2.11083  validloss -2.36275±0.00000  bestvalidloss -2.50673  last_update 72\n",
      "train: iter 223  trainloss -2.11735  validloss -2.40736±0.00000  bestvalidloss -2.50673  last_update 73\n",
      "train: iter 224  trainloss -2.10691  validloss -2.35851±0.00000  bestvalidloss -2.50673  last_update 74\n",
      "train: iter 225  trainloss -2.14625  validloss -2.45274±0.00000  bestvalidloss -2.50673  last_update 75\n",
      "train: iter 226  trainloss -2.09444  validloss -2.31630±0.00000  bestvalidloss -2.50673  last_update 76\n",
      "train: iter 227  trainloss -2.06914  validloss -2.31086±0.00000  bestvalidloss -2.50673  last_update 77\n",
      "train: iter 228  trainloss -2.10385  validloss -2.40685±0.00000  bestvalidloss -2.50673  last_update 78\n",
      "train: iter 229  trainloss -2.06186  validloss -2.36484±0.00000  bestvalidloss -2.50673  last_update 79\n",
      "train: iter 230  trainloss -2.02583  validloss -2.41756±0.00000  bestvalidloss -2.50673  last_update 80\n",
      "train: iter 231  trainloss -2.04860  validloss -2.41020±0.00000  bestvalidloss -2.50673  last_update 81\n",
      "train: iter 232  trainloss -2.11230  validloss -2.50632±0.00000  bestvalidloss -2.50673  last_update 82\n",
      "train: iter 233  trainloss -2.07210  validloss -2.42978±0.00000  bestvalidloss -2.50673  last_update 83\n",
      "train: iter 234  trainloss -2.12711  validloss -2.45425±0.00000  bestvalidloss -2.50673  last_update 84\n",
      "train: iter 235  trainloss -2.09899  validloss -2.31531±0.00000  bestvalidloss -2.50673  last_update 85\n",
      "train: iter 236  trainloss -2.12476  validloss -2.43926±0.00000  bestvalidloss -2.50673  last_update 86\n",
      "train: iter 237  trainloss -2.04960  validloss -2.40476±0.00000  bestvalidloss -2.50673  last_update 87\n",
      "train: iter 238  trainloss -2.13318  validloss -2.47810±0.00000  bestvalidloss -2.50673  last_update 88\n",
      "train: iter 239  trainloss -2.12255  validloss -2.40277±0.00000  bestvalidloss -2.50673  last_update 89\n",
      "train: iter 240  trainloss -2.11390  validloss -2.36779±0.00000  bestvalidloss -2.50673  last_update 90\n",
      "train: iter 241  trainloss -2.04805  validloss -2.37988±0.00000  bestvalidloss -2.50673  last_update 91\n",
      "train: iter 242  trainloss -2.13001  validloss -2.39104±0.00000  bestvalidloss -2.50673  last_update 92\n",
      "train: iter 243  trainloss -2.08843  validloss -2.29388±0.00000  bestvalidloss -2.50673  last_update 93\n",
      "train: iter 244  trainloss -2.13900  validloss -2.30214±0.00000  bestvalidloss -2.50673  last_update 94\n",
      "train: iter 245  trainloss -2.08153  validloss -2.38569±0.00000  bestvalidloss -2.50673  last_update 95\n",
      "train: iter 246  trainloss -2.11561  validloss -2.45303±0.00000  bestvalidloss -2.50673  last_update 96\n",
      "train: iter 247  trainloss -2.06693  validloss -2.39183±0.00000  bestvalidloss -2.50673  last_update 97\n",
      "train: iter 248  trainloss -2.06151  validloss -2.46535±0.00000  bestvalidloss -2.50673  last_update 98\n",
      "train: iter 249  trainloss -2.08470  validloss -2.36953±0.00000  bestvalidloss -2.50673  last_update 99\n",
      "train: iter 250  trainloss -2.11141  validloss -2.36801±0.00000  bestvalidloss -2.50673  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.8044, -1.7347, -5.7155, -4.0889], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 72.23606  validloss 74.82805±0.00000  bestvalidloss 74.82805  last_update 0\n",
      "train: iter 1  trainloss 50.49170  validloss 55.12262±0.00000  bestvalidloss 55.12262  last_update 0\n",
      "train: iter 2  trainloss 34.55320  validloss 37.36978±0.00000  bestvalidloss 37.36978  last_update 0\n",
      "train: iter 3  trainloss 25.48452  validloss 27.17738±0.00000  bestvalidloss 27.17738  last_update 0\n",
      "train: iter 4  trainloss 19.88814  validloss 21.56359±0.00000  bestvalidloss 21.56359  last_update 0\n",
      "train: iter 5  trainloss 15.93781  validloss 17.76919±0.00000  bestvalidloss 17.76919  last_update 0\n",
      "train: iter 6  trainloss 13.28087  validloss 15.28212±0.00000  bestvalidloss 15.28212  last_update 0\n",
      "train: iter 7  trainloss 11.25649  validloss 13.49240±0.00000  bestvalidloss 13.49240  last_update 0\n",
      "train: iter 8  trainloss 9.80703  validloss 12.33617±0.00000  bestvalidloss 12.33617  last_update 0\n",
      "train: iter 9  trainloss 8.75751  validloss 11.51128±0.00000  bestvalidloss 11.51128  last_update 0\n",
      "train: iter 10  trainloss 7.96265  validloss 10.87329±0.00000  bestvalidloss 10.87329  last_update 0\n",
      "train: iter 11  trainloss 7.35934  validloss 10.45241±0.00000  bestvalidloss 10.45241  last_update 0\n",
      "train: iter 12  trainloss 6.88027  validloss 10.15592±0.00000  bestvalidloss 10.15592  last_update 0\n",
      "train: iter 13  trainloss 6.40938  validloss 9.36900±0.00000  bestvalidloss 9.36900  last_update 0\n",
      "train: iter 14  trainloss 5.92008  validloss 8.68784±0.00000  bestvalidloss 8.68784  last_update 0\n",
      "train: iter 15  trainloss 5.55119  validloss 8.24915±0.00000  bestvalidloss 8.24915  last_update 0\n",
      "train: iter 16  trainloss 5.40477  validloss 7.98550±0.00000  bestvalidloss 7.98550  last_update 0\n",
      "train: iter 17  trainloss 5.19556  validloss 7.87569±0.00000  bestvalidloss 7.87569  last_update 0\n",
      "train: iter 18  trainloss 5.03492  validloss 7.59214±0.00000  bestvalidloss 7.59214  last_update 0\n",
      "train: iter 19  trainloss 4.94520  validloss 7.45067±0.00000  bestvalidloss 7.45067  last_update 0\n",
      "train: iter 20  trainloss 4.84685  validloss 7.37657±0.00000  bestvalidloss 7.37657  last_update 0\n",
      "train: iter 21  trainloss 4.80608  validloss 7.41097±0.00000  bestvalidloss 7.37657  last_update 1\n",
      "train: iter 22  trainloss 4.71514  validloss 7.22554±0.00000  bestvalidloss 7.22554  last_update 0\n",
      "train: iter 23  trainloss 4.62508  validloss 7.41012±0.00000  bestvalidloss 7.22554  last_update 1\n",
      "train: iter 24  trainloss 4.63236  validloss 7.33157±0.00000  bestvalidloss 7.22554  last_update 2\n",
      "train: iter 25  trainloss 4.54536  validloss 6.97737±0.00000  bestvalidloss 6.97737  last_update 0\n",
      "train: iter 26  trainloss 4.43817  validloss 6.91929±0.00000  bestvalidloss 6.91929  last_update 0\n",
      "train: iter 27  trainloss 4.42604  validloss 6.70690±0.00000  bestvalidloss 6.70690  last_update 0\n",
      "train: iter 28  trainloss 4.33990  validloss 6.70547±0.00000  bestvalidloss 6.70547  last_update 0\n",
      "train: iter 29  trainloss 4.24194  validloss 6.62562±0.00000  bestvalidloss 6.62562  last_update 0\n",
      "train: iter 30  trainloss 4.24144  validloss 6.72212±0.00000  bestvalidloss 6.62562  last_update 1\n",
      "train: iter 31  trainloss 4.16846  validloss 6.60555±0.00000  bestvalidloss 6.60555  last_update 0\n",
      "train: iter 32  trainloss 4.16494  validloss 6.51689±0.00000  bestvalidloss 6.51689  last_update 0\n",
      "train: iter 33  trainloss 4.07215  validloss 6.65415±0.00000  bestvalidloss 6.51689  last_update 1\n",
      "train: iter 34  trainloss 4.06835  validloss 6.51119±0.00000  bestvalidloss 6.51119  last_update 0\n",
      "train: iter 35  trainloss 4.01707  validloss 6.46896±0.00000  bestvalidloss 6.46896  last_update 0\n",
      "train: iter 36  trainloss 3.95026  validloss 6.46745±0.00000  bestvalidloss 6.46745  last_update 0\n",
      "train: iter 37  trainloss 3.95367  validloss 6.37672±0.00000  bestvalidloss 6.37672  last_update 0\n",
      "train: iter 38  trainloss 3.89726  validloss 6.33419±0.00000  bestvalidloss 6.33419  last_update 0\n",
      "train: iter 39  trainloss 3.88808  validloss 6.20554±0.00000  bestvalidloss 6.20554  last_update 0\n",
      "train: iter 40  trainloss 3.89418  validloss 6.32279±0.00000  bestvalidloss 6.20554  last_update 1\n",
      "train: iter 41  trainloss 3.89023  validloss 6.38754±0.00000  bestvalidloss 6.20554  last_update 2\n",
      "train: iter 42  trainloss 3.84018  validloss 6.28419±0.00000  bestvalidloss 6.20554  last_update 3\n",
      "train: iter 43  trainloss 3.79460  validloss 6.33077±0.00000  bestvalidloss 6.20554  last_update 4\n",
      "train: iter 44  trainloss 3.84721  validloss 6.45088±0.00000  bestvalidloss 6.20554  last_update 5\n",
      "train: iter 45  trainloss 3.83232  validloss 6.12808±0.00000  bestvalidloss 6.12808  last_update 0\n",
      "train: iter 46  trainloss 3.80700  validloss 6.03630±0.00000  bestvalidloss 6.03630  last_update 0\n",
      "train: iter 47  trainloss 3.81050  validloss 6.39064±0.00000  bestvalidloss 6.03630  last_update 1\n",
      "train: iter 48  trainloss 3.78554  validloss 6.33369±0.00000  bestvalidloss 6.03630  last_update 2\n",
      "train: iter 49  trainloss 3.77656  validloss 6.07746±0.00000  bestvalidloss 6.03630  last_update 3\n",
      "train: iter 50  trainloss 3.79229  validloss 6.07265±0.00000  bestvalidloss 6.03630  last_update 4\n",
      "train: iter 51  trainloss 3.76846  validloss 6.12994±0.00000  bestvalidloss 6.03630  last_update 5\n",
      "train: iter 52  trainloss 3.81626  validloss 6.32275±0.00000  bestvalidloss 6.03630  last_update 6\n",
      "train: iter 53  trainloss 3.72930  validloss 5.94452±0.00000  bestvalidloss 5.94452  last_update 0\n",
      "train: iter 54  trainloss 3.75866  validloss 5.98433±0.00000  bestvalidloss 5.94452  last_update 1\n",
      "train: iter 55  trainloss 3.69263  validloss 6.28939±0.00000  bestvalidloss 5.94452  last_update 2\n",
      "train: iter 56  trainloss 3.75795  validloss 5.98585±0.00000  bestvalidloss 5.94452  last_update 3\n",
      "train: iter 57  trainloss 3.63648  validloss 5.92868±0.00000  bestvalidloss 5.92868  last_update 0\n",
      "train: iter 58  trainloss 3.66887  validloss 6.01126±0.00000  bestvalidloss 5.92868  last_update 1\n",
      "train: iter 59  trainloss 3.64449  validloss 6.07764±0.00000  bestvalidloss 5.92868  last_update 2\n",
      "train: iter 60  trainloss 3.61613  validloss 5.93194±0.00000  bestvalidloss 5.92868  last_update 3\n",
      "train: iter 61  trainloss 3.62640  validloss 6.13570±0.00000  bestvalidloss 5.92868  last_update 4\n",
      "train: iter 62  trainloss 3.57781  validloss 6.12278±0.00000  bestvalidloss 5.92868  last_update 5\n",
      "train: iter 63  trainloss 3.67492  validloss 5.73994±0.00000  bestvalidloss 5.73994  last_update 0\n",
      "train: iter 64  trainloss 3.61968  validloss 6.12626±0.00000  bestvalidloss 5.73994  last_update 1\n",
      "train: iter 65  trainloss 3.58563  validloss 6.04838±0.00000  bestvalidloss 5.73994  last_update 2\n",
      "train: iter 66  trainloss 3.57202  validloss 6.02484±0.00000  bestvalidloss 5.73994  last_update 3\n",
      "train: iter 67  trainloss 3.62027  validloss 5.94687±0.00000  bestvalidloss 5.73994  last_update 4\n",
      "train: iter 68  trainloss 3.50365  validloss 6.06127±0.00000  bestvalidloss 5.73994  last_update 5\n",
      "train: iter 69  trainloss 3.63119  validloss 5.71735±0.00000  bestvalidloss 5.71735  last_update 0\n",
      "train: iter 70  trainloss 3.57169  validloss 5.94445±0.00000  bestvalidloss 5.71735  last_update 1\n",
      "train: iter 71  trainloss 3.53296  validloss 5.99297±0.00000  bestvalidloss 5.71735  last_update 2\n",
      "train: iter 72  trainloss 3.52773  validloss 6.07599±0.00000  bestvalidloss 5.71735  last_update 3\n",
      "train: iter 73  trainloss 3.55115  validloss 6.06262±0.00000  bestvalidloss 5.71735  last_update 4\n",
      "train: iter 74  trainloss 3.54192  validloss 6.07280±0.00000  bestvalidloss 5.71735  last_update 5\n",
      "train: iter 75  trainloss 3.50699  validloss 5.93668±0.00000  bestvalidloss 5.71735  last_update 6\n",
      "train: iter 76  trainloss 3.50115  validloss 6.36707±0.00000  bestvalidloss 5.71735  last_update 7\n",
      "train: iter 77  trainloss 3.46048  validloss 5.80985±0.00000  bestvalidloss 5.71735  last_update 8\n",
      "train: iter 78  trainloss 3.53350  validloss 6.14756±0.00000  bestvalidloss 5.71735  last_update 9\n",
      "train: iter 79  trainloss 3.49149  validloss 5.73674±0.00000  bestvalidloss 5.71735  last_update 10\n",
      "train: iter 80  trainloss 3.46928  validloss 5.60201±0.00000  bestvalidloss 5.60201  last_update 0\n",
      "train: iter 81  trainloss 3.50483  validloss 5.84263±0.00000  bestvalidloss 5.60201  last_update 1\n",
      "train: iter 82  trainloss 3.44049  validloss 5.66758±0.00000  bestvalidloss 5.60201  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 3.45766  validloss 6.07661±0.00000  bestvalidloss 5.60201  last_update 3\n",
      "train: iter 84  trainloss 3.47644  validloss 5.93316±0.00000  bestvalidloss 5.60201  last_update 4\n",
      "train: iter 85  trainloss 3.42900  validloss 6.03359±0.00000  bestvalidloss 5.60201  last_update 5\n",
      "train: iter 86  trainloss 3.41428  validloss 5.66223±0.00000  bestvalidloss 5.60201  last_update 6\n",
      "train: iter 87  trainloss 3.45155  validloss 6.31305±0.00000  bestvalidloss 5.60201  last_update 7\n",
      "train: iter 88  trainloss 3.44006  validloss 5.95645±0.00000  bestvalidloss 5.60201  last_update 8\n",
      "train: iter 89  trainloss 3.43198  validloss 5.87854±0.00000  bestvalidloss 5.60201  last_update 9\n",
      "train: iter 90  trainloss 3.44163  validloss 5.90665±0.00000  bestvalidloss 5.60201  last_update 10\n",
      "train: iter 91  trainloss 3.47229  validloss 5.79526±0.00000  bestvalidloss 5.60201  last_update 11\n",
      "train: iter 92  trainloss 3.42832  validloss 5.82764±0.00000  bestvalidloss 5.60201  last_update 12\n",
      "train: iter 93  trainloss 3.41042  validloss 5.60457±0.00000  bestvalidloss 5.60201  last_update 13\n",
      "train: iter 94  trainloss 3.40891  validloss 5.53423±0.00000  bestvalidloss 5.53423  last_update 0\n",
      "train: iter 95  trainloss 3.44726  validloss 5.93423±0.00000  bestvalidloss 5.53423  last_update 1\n",
      "train: iter 96  trainloss 3.41174  validloss 5.64776±0.00000  bestvalidloss 5.53423  last_update 2\n",
      "train: iter 97  trainloss 3.41803  validloss 5.54768±0.00000  bestvalidloss 5.53423  last_update 3\n",
      "train: iter 98  trainloss 3.42266  validloss 6.19943±0.00000  bestvalidloss 5.53423  last_update 4\n",
      "train: iter 99  trainloss 3.43275  validloss 5.64608±0.00000  bestvalidloss 5.53423  last_update 5\n",
      "train: iter 100  trainloss 3.41392  validloss 5.51897±0.00000  bestvalidloss 5.51897  last_update 0\n",
      "train: iter 101  trainloss 3.42370  validloss 5.69859±0.00000  bestvalidloss 5.51897  last_update 1\n",
      "train: iter 102  trainloss 3.40698  validloss 5.82620±0.00000  bestvalidloss 5.51897  last_update 2\n",
      "train: iter 103  trainloss 3.41557  validloss 5.43425±0.00000  bestvalidloss 5.43425  last_update 0\n",
      "train: iter 104  trainloss 3.32850  validloss 5.78209±0.00000  bestvalidloss 5.43425  last_update 1\n",
      "train: iter 105  trainloss 3.39256  validloss 5.88891±0.00000  bestvalidloss 5.43425  last_update 2\n",
      "train: iter 106  trainloss 3.41440  validloss 5.69027±0.00000  bestvalidloss 5.43425  last_update 3\n",
      "train: iter 107  trainloss 3.37524  validloss 6.00435±0.00000  bestvalidloss 5.43425  last_update 4\n",
      "train: iter 108  trainloss 3.37760  validloss 5.83277±0.00000  bestvalidloss 5.43425  last_update 5\n",
      "train: iter 109  trainloss 3.42507  validloss 5.87735±0.00000  bestvalidloss 5.43425  last_update 6\n",
      "train: iter 110  trainloss 3.43101  validloss 5.95089±0.00000  bestvalidloss 5.43425  last_update 7\n",
      "train: iter 111  trainloss 3.36883  validloss 5.51405±0.00000  bestvalidloss 5.43425  last_update 8\n",
      "train: iter 112  trainloss 3.38266  validloss 5.74032±0.00000  bestvalidloss 5.43425  last_update 9\n",
      "train: iter 113  trainloss 3.36486  validloss 5.74197±0.00000  bestvalidloss 5.43425  last_update 10\n",
      "train: iter 114  trainloss 3.38902  validloss 5.71966±0.00000  bestvalidloss 5.43425  last_update 11\n",
      "train: iter 115  trainloss 3.36423  validloss 5.87524±0.00000  bestvalidloss 5.43425  last_update 12\n",
      "train: iter 116  trainloss 3.39402  validloss 5.64365±0.00000  bestvalidloss 5.43425  last_update 13\n",
      "train: iter 117  trainloss 3.41899  validloss 5.82943±0.00000  bestvalidloss 5.43425  last_update 14\n",
      "train: iter 118  trainloss 3.45248  validloss 5.63767±0.00000  bestvalidloss 5.43425  last_update 15\n",
      "train: iter 119  trainloss 3.40500  validloss 5.78328±0.00000  bestvalidloss 5.43425  last_update 16\n",
      "train: iter 120  trainloss 3.42290  validloss 5.81195±0.00000  bestvalidloss 5.43425  last_update 17\n",
      "train: iter 121  trainloss 3.40781  validloss 5.48364±0.00000  bestvalidloss 5.43425  last_update 18\n",
      "train: iter 122  trainloss 3.38973  validloss 5.82341±0.00000  bestvalidloss 5.43425  last_update 19\n",
      "train: iter 123  trainloss 3.35296  validloss 5.83857±0.00000  bestvalidloss 5.43425  last_update 20\n",
      "train: iter 124  trainloss 3.40066  validloss 5.37332±0.00000  bestvalidloss 5.37332  last_update 0\n",
      "train: iter 125  trainloss 3.33955  validloss 5.61725±0.00000  bestvalidloss 5.37332  last_update 1\n",
      "train: iter 126  trainloss 3.40169  validloss 5.93888±0.00000  bestvalidloss 5.37332  last_update 2\n",
      "train: iter 127  trainloss 3.36968  validloss 5.58134±0.00000  bestvalidloss 5.37332  last_update 3\n",
      "train: iter 128  trainloss 3.35397  validloss 5.63172±0.00000  bestvalidloss 5.37332  last_update 4\n",
      "train: iter 129  trainloss 3.38744  validloss 5.65437±0.00000  bestvalidloss 5.37332  last_update 5\n",
      "train: iter 130  trainloss 3.41526  validloss 5.40954±0.00000  bestvalidloss 5.37332  last_update 6\n",
      "train: iter 131  trainloss 3.35680  validloss 5.70313±0.00000  bestvalidloss 5.37332  last_update 7\n",
      "train: iter 132  trainloss 3.34052  validloss 5.75378±0.00000  bestvalidloss 5.37332  last_update 8\n",
      "train: iter 133  trainloss 3.39569  validloss 5.45170±0.00000  bestvalidloss 5.37332  last_update 9\n",
      "train: iter 134  trainloss 3.37787  validloss 5.92229±0.00000  bestvalidloss 5.37332  last_update 10\n",
      "train: iter 135  trainloss 3.33916  validloss 5.65105±0.00000  bestvalidloss 5.37332  last_update 11\n",
      "train: iter 136  trainloss 3.32839  validloss 5.66579±0.00000  bestvalidloss 5.37332  last_update 12\n",
      "train: iter 137  trainloss 3.35867  validloss 5.48889±0.00000  bestvalidloss 5.37332  last_update 13\n",
      "train: iter 138  trainloss 3.34285  validloss 5.60980±0.00000  bestvalidloss 5.37332  last_update 14\n",
      "train: iter 139  trainloss 3.34832  validloss 5.69352±0.00000  bestvalidloss 5.37332  last_update 15\n",
      "train: iter 140  trainloss 3.35328  validloss 5.69798±0.00000  bestvalidloss 5.37332  last_update 16\n",
      "train: iter 141  trainloss 3.35393  validloss 5.49193±0.00000  bestvalidloss 5.37332  last_update 17\n",
      "train: iter 142  trainloss 3.32848  validloss 5.46240±0.00000  bestvalidloss 5.37332  last_update 18\n",
      "train: iter 143  trainloss 3.32553  validloss 5.57958±0.00000  bestvalidloss 5.37332  last_update 19\n",
      "train: iter 144  trainloss 3.36192  validloss 5.67827±0.00000  bestvalidloss 5.37332  last_update 20\n",
      "train: iter 145  trainloss 3.31519  validloss 5.60570±0.00000  bestvalidloss 5.37332  last_update 21\n",
      "train: iter 146  trainloss 3.33547  validloss 5.70370±0.00000  bestvalidloss 5.37332  last_update 22\n",
      "train: iter 147  trainloss 3.38105  validloss 5.95875±0.00000  bestvalidloss 5.37332  last_update 23\n",
      "train: iter 148  trainloss 3.31163  validloss 5.95633±0.00000  bestvalidloss 5.37332  last_update 24\n",
      "train: iter 149  trainloss 3.34481  validloss 5.60993±0.00000  bestvalidloss 5.37332  last_update 25\n",
      "train: iter 150  trainloss 3.32830  validloss 5.78077±0.00000  bestvalidloss 5.37332  last_update 26\n",
      "train: iter 151  trainloss 3.36635  validloss 5.80221±0.00000  bestvalidloss 5.37332  last_update 27\n",
      "train: iter 152  trainloss 3.31562  validloss 5.58589±0.00000  bestvalidloss 5.37332  last_update 28\n",
      "train: iter 153  trainloss 3.33903  validloss 5.78064±0.00000  bestvalidloss 5.37332  last_update 29\n",
      "train: iter 154  trainloss 3.35722  validloss 5.56540±0.00000  bestvalidloss 5.37332  last_update 30\n",
      "train: iter 155  trainloss 3.32480  validloss 5.73420±0.00000  bestvalidloss 5.37332  last_update 31\n",
      "train: iter 156  trainloss 3.35692  validloss 5.67371±0.00000  bestvalidloss 5.37332  last_update 32\n",
      "train: iter 157  trainloss 3.34605  validloss 5.89231±0.00000  bestvalidloss 5.37332  last_update 33\n",
      "train: iter 158  trainloss 3.35347  validloss 5.42456±0.00000  bestvalidloss 5.37332  last_update 34\n",
      "train: iter 159  trainloss 3.33438  validloss 5.43150±0.00000  bestvalidloss 5.37332  last_update 35\n",
      "train: iter 160  trainloss 3.32552  validloss 5.73008±0.00000  bestvalidloss 5.37332  last_update 36\n",
      "train: iter 161  trainloss 3.32620  validloss 5.74853±0.00000  bestvalidloss 5.37332  last_update 37\n",
      "train: iter 162  trainloss 3.34481  validloss 5.80498±0.00000  bestvalidloss 5.37332  last_update 38\n",
      "train: iter 163  trainloss 3.29904  validloss 5.66067±0.00000  bestvalidloss 5.37332  last_update 39\n",
      "train: iter 164  trainloss 3.32529  validloss 5.60376±0.00000  bestvalidloss 5.37332  last_update 40\n",
      "train: iter 165  trainloss 3.33486  validloss 5.76913±0.00000  bestvalidloss 5.37332  last_update 41\n",
      "train: iter 166  trainloss 3.33970  validloss 5.64843±0.00000  bestvalidloss 5.37332  last_update 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 3.33913  validloss 5.46870±0.00000  bestvalidloss 5.37332  last_update 43\n",
      "train: iter 168  trainloss 3.35492  validloss 5.44140±0.00000  bestvalidloss 5.37332  last_update 44\n",
      "train: iter 169  trainloss 3.30631  validloss 5.39710±0.00000  bestvalidloss 5.37332  last_update 45\n",
      "train: iter 170  trainloss 3.33609  validloss 5.32693±0.00000  bestvalidloss 5.32693  last_update 0\n",
      "train: iter 171  trainloss 3.29387  validloss 5.44255±0.00000  bestvalidloss 5.32693  last_update 1\n",
      "train: iter 172  trainloss 3.41931  validloss 5.30652±0.00000  bestvalidloss 5.30652  last_update 0\n",
      "train: iter 173  trainloss 3.37138  validloss 5.61096±0.00000  bestvalidloss 5.30652  last_update 1\n",
      "train: iter 174  trainloss 3.34756  validloss 5.69860±0.00000  bestvalidloss 5.30652  last_update 2\n",
      "train: iter 175  trainloss 3.31095  validloss 5.55547±0.00000  bestvalidloss 5.30652  last_update 3\n",
      "train: iter 176  trainloss 3.27357  validloss 6.00420±0.00000  bestvalidloss 5.30652  last_update 4\n",
      "train: iter 177  trainloss 3.32127  validloss 5.53521±0.00000  bestvalidloss 5.30652  last_update 5\n",
      "train: iter 178  trainloss 3.33263  validloss 5.79451±0.00000  bestvalidloss 5.30652  last_update 6\n",
      "train: iter 179  trainloss 3.30699  validloss 5.68931±0.00000  bestvalidloss 5.30652  last_update 7\n",
      "train: iter 180  trainloss 3.32381  validloss 5.41728±0.00000  bestvalidloss 5.30652  last_update 8\n",
      "train: iter 181  trainloss 3.30613  validloss 5.27668±0.00000  bestvalidloss 5.27668  last_update 0\n",
      "train: iter 182  trainloss 3.31065  validloss 5.35430±0.00000  bestvalidloss 5.27668  last_update 1\n",
      "train: iter 183  trainloss 3.30652  validloss 5.63450±0.00000  bestvalidloss 5.27668  last_update 2\n",
      "train: iter 184  trainloss 3.35606  validloss 6.17714±0.00000  bestvalidloss 5.27668  last_update 3\n",
      "train: iter 185  trainloss 3.35640  validloss 5.80471±0.00000  bestvalidloss 5.27668  last_update 4\n",
      "train: iter 186  trainloss 3.33051  validloss 5.72134±0.00000  bestvalidloss 5.27668  last_update 5\n",
      "train: iter 187  trainloss 3.30445  validloss 5.51579±0.00000  bestvalidloss 5.27668  last_update 6\n",
      "train: iter 188  trainloss 3.29277  validloss 5.53293±0.00000  bestvalidloss 5.27668  last_update 7\n",
      "train: iter 189  trainloss 3.32052  validloss 5.87985±0.00000  bestvalidloss 5.27668  last_update 8\n",
      "train: iter 190  trainloss 3.31106  validloss 5.71356±0.00000  bestvalidloss 5.27668  last_update 9\n",
      "train: iter 191  trainloss 3.29568  validloss 5.50025±0.00000  bestvalidloss 5.27668  last_update 10\n",
      "train: iter 192  trainloss 3.26742  validloss 5.53613±0.00000  bestvalidloss 5.27668  last_update 11\n",
      "train: iter 193  trainloss 3.29195  validloss 5.32947±0.00000  bestvalidloss 5.27668  last_update 12\n",
      "train: iter 194  trainloss 3.29456  validloss 5.31983±0.00000  bestvalidloss 5.27668  last_update 13\n",
      "train: iter 195  trainloss 3.36285  validloss 5.73326±0.00000  bestvalidloss 5.27668  last_update 14\n",
      "train: iter 196  trainloss 3.29541  validloss 5.75793±0.00000  bestvalidloss 5.27668  last_update 15\n",
      "train: iter 197  trainloss 3.29517  validloss 5.28069±0.00000  bestvalidloss 5.27668  last_update 16\n",
      "train: iter 198  trainloss 3.31644  validloss 5.75115±0.00000  bestvalidloss 5.27668  last_update 17\n",
      "train: iter 199  trainloss 3.29012  validloss 5.20369±0.00000  bestvalidloss 5.20369  last_update 0\n",
      "train: iter 200  trainloss 3.32416  validloss 5.48666±0.00000  bestvalidloss 5.20369  last_update 1\n",
      "train: iter 201  trainloss 3.30849  validloss 5.37977±0.00000  bestvalidloss 5.20369  last_update 2\n",
      "train: iter 202  trainloss 3.31800  validloss 5.77419±0.00000  bestvalidloss 5.20369  last_update 3\n",
      "train: iter 203  trainloss 3.30715  validloss 5.88960±0.00000  bestvalidloss 5.20369  last_update 4\n",
      "train: iter 204  trainloss 3.29615  validloss 5.79093±0.00000  bestvalidloss 5.20369  last_update 5\n",
      "train: iter 205  trainloss 3.27172  validloss 5.61272±0.00000  bestvalidloss 5.20369  last_update 6\n",
      "train: iter 206  trainloss 3.31310  validloss 5.42730±0.00000  bestvalidloss 5.20369  last_update 7\n",
      "train: iter 207  trainloss 3.32493  validloss 5.45535±0.00000  bestvalidloss 5.20369  last_update 8\n",
      "train: iter 208  trainloss 3.28819  validloss 5.33582±0.00000  bestvalidloss 5.20369  last_update 9\n",
      "train: iter 209  trainloss 3.28344  validloss 5.43951±0.00000  bestvalidloss 5.20369  last_update 10\n",
      "train: iter 210  trainloss 3.34374  validloss 5.96348±0.00000  bestvalidloss 5.20369  last_update 11\n",
      "train: iter 211  trainloss 3.33017  validloss 5.94097±0.00000  bestvalidloss 5.20369  last_update 12\n",
      "train: iter 212  trainloss 3.28657  validloss 5.57015±0.00000  bestvalidloss 5.20369  last_update 13\n",
      "train: iter 213  trainloss 3.30816  validloss 5.82089±0.00000  bestvalidloss 5.20369  last_update 14\n",
      "train: iter 214  trainloss 3.28031  validloss 5.55286±0.00000  bestvalidloss 5.20369  last_update 15\n",
      "train: iter 215  trainloss 3.30503  validloss 5.77974±0.00000  bestvalidloss 5.20369  last_update 16\n",
      "train: iter 216  trainloss 3.27076  validloss 5.67464±0.00000  bestvalidloss 5.20369  last_update 17\n",
      "train: iter 217  trainloss 3.32846  validloss 5.49112±0.00000  bestvalidloss 5.20369  last_update 18\n",
      "train: iter 218  trainloss 3.26904  validloss 5.58374±0.00000  bestvalidloss 5.20369  last_update 19\n",
      "train: iter 219  trainloss 3.31356  validloss 5.52150±0.00000  bestvalidloss 5.20369  last_update 20\n",
      "train: iter 220  trainloss 3.25581  validloss 5.92268±0.00000  bestvalidloss 5.20369  last_update 21\n",
      "train: iter 221  trainloss 3.28649  validloss 5.89314±0.00000  bestvalidloss 5.20369  last_update 22\n",
      "train: iter 222  trainloss 3.26992  validloss 5.35584±0.00000  bestvalidloss 5.20369  last_update 23\n",
      "train: iter 223  trainloss 3.24944  validloss 5.94343±0.00000  bestvalidloss 5.20369  last_update 24\n",
      "train: iter 224  trainloss 3.31381  validloss 5.81735±0.00000  bestvalidloss 5.20369  last_update 25\n",
      "train: iter 225  trainloss 3.27352  validloss 5.68975±0.00000  bestvalidloss 5.20369  last_update 26\n",
      "train: iter 226  trainloss 3.30181  validloss 5.45051±0.00000  bestvalidloss 5.20369  last_update 27\n",
      "train: iter 227  trainloss 3.24704  validloss 5.78839±0.00000  bestvalidloss 5.20369  last_update 28\n",
      "train: iter 228  trainloss 3.28473  validloss 5.21947±0.00000  bestvalidloss 5.20369  last_update 29\n",
      "train: iter 229  trainloss 3.34681  validloss 5.77952±0.00000  bestvalidloss 5.20369  last_update 30\n",
      "train: iter 230  trainloss 3.30200  validloss 5.55423±0.00000  bestvalidloss 5.20369  last_update 31\n",
      "train: iter 231  trainloss 3.29910  validloss 5.82916±0.00000  bestvalidloss 5.20369  last_update 32\n",
      "train: iter 232  trainloss 3.25873  validloss 5.49815±0.00000  bestvalidloss 5.20369  last_update 33\n",
      "train: iter 233  trainloss 3.25126  validloss 5.72139±0.00000  bestvalidloss 5.20369  last_update 34\n",
      "train: iter 234  trainloss 3.25832  validloss 5.64838±0.00000  bestvalidloss 5.20369  last_update 35\n",
      "train: iter 235  trainloss 3.29426  validloss 5.58736±0.00000  bestvalidloss 5.20369  last_update 36\n",
      "train: iter 236  trainloss 3.28879  validloss 5.49776±0.00000  bestvalidloss 5.20369  last_update 37\n",
      "train: iter 237  trainloss 3.32949  validloss 5.69915±0.00000  bestvalidloss 5.20369  last_update 38\n",
      "train: iter 238  trainloss 3.27633  validloss 5.50572±0.00000  bestvalidloss 5.20369  last_update 39\n",
      "train: iter 239  trainloss 3.24213  validloss 5.37965±0.00000  bestvalidloss 5.20369  last_update 40\n",
      "train: iter 240  trainloss 3.31398  validloss 5.24374±0.00000  bestvalidloss 5.20369  last_update 41\n",
      "train: iter 241  trainloss 3.27464  validloss 5.39530±0.00000  bestvalidloss 5.20369  last_update 42\n",
      "train: iter 242  trainloss 3.26822  validloss 5.56582±0.00000  bestvalidloss 5.20369  last_update 43\n",
      "train: iter 243  trainloss 3.28716  validloss 5.64262±0.00000  bestvalidloss 5.20369  last_update 44\n",
      "train: iter 244  trainloss 3.18718  validloss 5.67735±0.00000  bestvalidloss 5.20369  last_update 45\n",
      "train: iter 245  trainloss 3.29935  validloss 5.24777±0.00000  bestvalidloss 5.20369  last_update 46\n",
      "train: iter 246  trainloss 3.28275  validloss 5.70478±0.00000  bestvalidloss 5.20369  last_update 47\n",
      "train: iter 247  trainloss 3.26402  validloss 5.56808±0.00000  bestvalidloss 5.20369  last_update 48\n",
      "train: iter 248  trainloss 3.27275  validloss 5.39288±0.00000  bestvalidloss 5.20369  last_update 49\n",
      "train: iter 249  trainloss 3.25846  validloss 5.43607±0.00000  bestvalidloss 5.20369  last_update 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 250  trainloss 3.23391  validloss 5.52750±0.00000  bestvalidloss 5.20369  last_update 51\n",
      "train: iter 251  trainloss 3.26143  validloss 5.94564±0.00000  bestvalidloss 5.20369  last_update 52\n",
      "train: iter 252  trainloss 3.22896  validloss 5.78698±0.00000  bestvalidloss 5.20369  last_update 53\n",
      "train: iter 253  trainloss 3.24701  validloss 5.42227±0.00000  bestvalidloss 5.20369  last_update 54\n",
      "train: iter 254  trainloss 3.24428  validloss 5.53031±0.00000  bestvalidloss 5.20369  last_update 55\n",
      "train: iter 255  trainloss 3.23182  validloss 5.49608±0.00000  bestvalidloss 5.20369  last_update 56\n",
      "train: iter 256  trainloss 3.25374  validloss 5.47699±0.00000  bestvalidloss 5.20369  last_update 57\n",
      "train: iter 257  trainloss 3.25293  validloss 5.78220±0.00000  bestvalidloss 5.20369  last_update 58\n",
      "train: iter 258  trainloss 3.25477  validloss 5.49126±0.00000  bestvalidloss 5.20369  last_update 59\n",
      "train: iter 259  trainloss 3.23174  validloss 5.80789±0.00000  bestvalidloss 5.20369  last_update 60\n",
      "train: iter 260  trainloss 3.29443  validloss 5.19181±0.00000  bestvalidloss 5.19181  last_update 0\n",
      "train: iter 261  trainloss 3.22958  validloss 5.13901±0.00000  bestvalidloss 5.13901  last_update 0\n",
      "train: iter 262  trainloss 3.23251  validloss 5.37070±0.00000  bestvalidloss 5.13901  last_update 1\n",
      "train: iter 263  trainloss 3.28381  validloss 5.39860±0.00000  bestvalidloss 5.13901  last_update 2\n",
      "train: iter 264  trainloss 3.22659  validloss 5.65252±0.00000  bestvalidloss 5.13901  last_update 3\n",
      "train: iter 265  trainloss 3.24644  validloss 5.75145±0.00000  bestvalidloss 5.13901  last_update 4\n",
      "train: iter 266  trainloss 3.25516  validloss 5.63666±0.00000  bestvalidloss 5.13901  last_update 5\n",
      "train: iter 267  trainloss 3.24466  validloss 5.58871±0.00000  bestvalidloss 5.13901  last_update 6\n",
      "train: iter 268  trainloss 3.21859  validloss 5.41375±0.00000  bestvalidloss 5.13901  last_update 7\n",
      "train: iter 269  trainloss 3.25567  validloss 5.70552±0.00000  bestvalidloss 5.13901  last_update 8\n",
      "train: iter 270  trainloss 3.25530  validloss 5.28614±0.00000  bestvalidloss 5.13901  last_update 9\n",
      "train: iter 271  trainloss 3.21670  validloss 5.70850±0.00000  bestvalidloss 5.13901  last_update 10\n",
      "train: iter 272  trainloss 3.24491  validloss 5.45261±0.00000  bestvalidloss 5.13901  last_update 11\n",
      "train: iter 273  trainloss 3.27571  validloss 5.55486±0.00000  bestvalidloss 5.13901  last_update 12\n",
      "train: iter 274  trainloss 3.25029  validloss 5.62069±0.00000  bestvalidloss 5.13901  last_update 13\n",
      "train: iter 275  trainloss 3.19514  validloss 5.58068±0.00000  bestvalidloss 5.13901  last_update 14\n",
      "train: iter 276  trainloss 3.23939  validloss 5.16266±0.00000  bestvalidloss 5.13901  last_update 15\n",
      "train: iter 277  trainloss 3.25354  validloss 5.84528±0.00000  bestvalidloss 5.13901  last_update 16\n",
      "train: iter 278  trainloss 3.25780  validloss 5.79175±0.00000  bestvalidloss 5.13901  last_update 17\n",
      "train: iter 279  trainloss 3.23089  validloss 5.84099±0.00000  bestvalidloss 5.13901  last_update 18\n",
      "train: iter 280  trainloss 3.25217  validloss 5.74035±0.00000  bestvalidloss 5.13901  last_update 19\n",
      "train: iter 281  trainloss 3.22465  validloss 5.67843±0.00000  bestvalidloss 5.13901  last_update 20\n",
      "train: iter 282  trainloss 3.23287  validloss 5.48902±0.00000  bestvalidloss 5.13901  last_update 21\n",
      "train: iter 283  trainloss 3.22798  validloss 5.65793±0.00000  bestvalidloss 5.13901  last_update 22\n",
      "train: iter 284  trainloss 3.21564  validloss 5.53225±0.00000  bestvalidloss 5.13901  last_update 23\n",
      "train: iter 285  trainloss 3.21573  validloss 5.93261±0.00000  bestvalidloss 5.13901  last_update 24\n",
      "train: iter 286  trainloss 3.23675  validloss 5.30071±0.00000  bestvalidloss 5.13901  last_update 25\n",
      "train: iter 287  trainloss 3.24339  validloss 5.40737±0.00000  bestvalidloss 5.13901  last_update 26\n",
      "train: iter 288  trainloss 3.25555  validloss 5.68426±0.00000  bestvalidloss 5.13901  last_update 27\n",
      "train: iter 289  trainloss 3.21462  validloss 5.53927±0.00000  bestvalidloss 5.13901  last_update 28\n",
      "train: iter 290  trainloss 3.29545  validloss 5.43656±0.00000  bestvalidloss 5.13901  last_update 29\n",
      "train: iter 291  trainloss 3.24441  validloss 5.42137±0.00000  bestvalidloss 5.13901  last_update 30\n",
      "train: iter 292  trainloss 3.29143  validloss 5.57381±0.00000  bestvalidloss 5.13901  last_update 31\n",
      "train: iter 293  trainloss 3.27551  validloss 5.27085±0.00000  bestvalidloss 5.13901  last_update 32\n",
      "train: iter 294  trainloss 3.26937  validloss 5.55500±0.00000  bestvalidloss 5.13901  last_update 33\n",
      "train: iter 295  trainloss 3.20741  validloss 5.82459±0.00000  bestvalidloss 5.13901  last_update 34\n",
      "train: iter 296  trainloss 3.21125  validloss 5.27262±0.00000  bestvalidloss 5.13901  last_update 35\n",
      "train: iter 297  trainloss 3.24013  validloss 5.35852±0.00000  bestvalidloss 5.13901  last_update 36\n",
      "train: iter 298  trainloss 3.22171  validloss 5.42510±0.00000  bestvalidloss 5.13901  last_update 37\n",
      "train: iter 299  trainloss 3.23222  validloss 5.41381±0.00000  bestvalidloss 5.13901  last_update 38\n",
      "train: iter 300  trainloss 3.25005  validloss 5.43897±0.00000  bestvalidloss 5.13901  last_update 39\n",
      "train: iter 301  trainloss 3.22200  validloss 5.60071±0.00000  bestvalidloss 5.13901  last_update 40\n",
      "train: iter 302  trainloss 3.21557  validloss 5.79248±0.00000  bestvalidloss 5.13901  last_update 41\n",
      "train: iter 303  trainloss 3.19214  validloss 5.43704±0.00000  bestvalidloss 5.13901  last_update 42\n",
      "train: iter 304  trainloss 3.19389  validloss 5.85385±0.00000  bestvalidloss 5.13901  last_update 43\n",
      "train: iter 305  trainloss 3.21625  validloss 5.55552±0.00000  bestvalidloss 5.13901  last_update 44\n",
      "train: iter 306  trainloss 3.20521  validloss 5.74509±0.00000  bestvalidloss 5.13901  last_update 45\n",
      "train: iter 307  trainloss 3.23774  validloss 6.07332±0.00000  bestvalidloss 5.13901  last_update 46\n",
      "train: iter 308  trainloss 3.18219  validloss 5.58723±0.00000  bestvalidloss 5.13901  last_update 47\n",
      "train: iter 309  trainloss 3.27055  validloss 5.36229±0.00000  bestvalidloss 5.13901  last_update 48\n",
      "train: iter 310  trainloss 3.25049  validloss 5.32651±0.00000  bestvalidloss 5.13901  last_update 49\n",
      "train: iter 311  trainloss 3.18589  validloss 5.81357±0.00000  bestvalidloss 5.13901  last_update 50\n",
      "train: iter 312  trainloss 3.23895  validloss 6.27564±0.00000  bestvalidloss 5.13901  last_update 51\n",
      "train: iter 313  trainloss 3.17267  validloss 5.55511±0.00000  bestvalidloss 5.13901  last_update 52\n",
      "train: iter 314  trainloss 3.23397  validloss 5.29032±0.00000  bestvalidloss 5.13901  last_update 53\n",
      "train: iter 315  trainloss 3.24424  validloss 5.63551±0.00000  bestvalidloss 5.13901  last_update 54\n",
      "train: iter 316  trainloss 3.19469  validloss 5.57689±0.00000  bestvalidloss 5.13901  last_update 55\n",
      "train: iter 317  trainloss 3.23157  validloss 5.50664±0.00000  bestvalidloss 5.13901  last_update 56\n",
      "train: iter 318  trainloss 3.20842  validloss 5.77068±0.00000  bestvalidloss 5.13901  last_update 57\n",
      "train: iter 319  trainloss 3.20768  validloss 5.39615±0.00000  bestvalidloss 5.13901  last_update 58\n",
      "train: iter 320  trainloss 3.23006  validloss 5.48678±0.00000  bestvalidloss 5.13901  last_update 59\n",
      "train: iter 321  trainloss 3.22603  validloss 5.81156±0.00000  bestvalidloss 5.13901  last_update 60\n",
      "train: iter 322  trainloss 3.20820  validloss 5.55661±0.00000  bestvalidloss 5.13901  last_update 61\n",
      "train: iter 323  trainloss 3.21204  validloss 5.85191±0.00000  bestvalidloss 5.13901  last_update 62\n",
      "train: iter 324  trainloss 3.21623  validloss 5.31336±0.00000  bestvalidloss 5.13901  last_update 63\n",
      "train: iter 325  trainloss 3.21573  validloss 5.27276±0.00000  bestvalidloss 5.13901  last_update 64\n",
      "train: iter 326  trainloss 3.21814  validloss 5.62810±0.00000  bestvalidloss 5.13901  last_update 65\n",
      "train: iter 327  trainloss 3.20937  validloss 5.49938±0.00000  bestvalidloss 5.13901  last_update 66\n",
      "train: iter 328  trainloss 3.20643  validloss 5.55143±0.00000  bestvalidloss 5.13901  last_update 67\n",
      "train: iter 329  trainloss 3.21956  validloss 5.97600±0.00000  bestvalidloss 5.13901  last_update 68\n",
      "train: iter 330  trainloss 3.15758  validloss 5.76940±0.00000  bestvalidloss 5.13901  last_update 69\n",
      "train: iter 331  trainloss 3.13778  validloss 5.58899±0.00000  bestvalidloss 5.13901  last_update 70\n",
      "train: iter 332  trainloss 3.22565  validloss 5.55202±0.00000  bestvalidloss 5.13901  last_update 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 333  trainloss 3.19439  validloss 5.63910±0.00000  bestvalidloss 5.13901  last_update 72\n",
      "train: iter 334  trainloss 3.20809  validloss 5.37409±0.00000  bestvalidloss 5.13901  last_update 73\n",
      "train: iter 335  trainloss 3.20962  validloss 5.66854±0.00000  bestvalidloss 5.13901  last_update 74\n",
      "train: iter 336  trainloss 3.19174  validloss 5.87837±0.00000  bestvalidloss 5.13901  last_update 75\n",
      "train: iter 337  trainloss 3.23070  validloss 5.90099±0.00000  bestvalidloss 5.13901  last_update 76\n",
      "train: iter 338  trainloss 3.13653  validloss 5.57797±0.00000  bestvalidloss 5.13901  last_update 77\n",
      "train: iter 339  trainloss 3.24031  validloss 5.21992±0.00000  bestvalidloss 5.13901  last_update 78\n",
      "train: iter 340  trainloss 3.21075  validloss 5.67864±0.00000  bestvalidloss 5.13901  last_update 79\n",
      "train: iter 341  trainloss 3.19518  validloss 5.37526±0.00000  bestvalidloss 5.13901  last_update 80\n",
      "train: iter 342  trainloss 3.23158  validloss 5.25361±0.00000  bestvalidloss 5.13901  last_update 81\n",
      "train: iter 343  trainloss 3.22000  validloss 5.16810±0.00000  bestvalidloss 5.13901  last_update 82\n",
      "train: iter 344  trainloss 3.18032  validloss 5.53175±0.00000  bestvalidloss 5.13901  last_update 83\n",
      "train: iter 345  trainloss 3.18447  validloss 5.71884±0.00000  bestvalidloss 5.13901  last_update 84\n",
      "train: iter 346  trainloss 3.17684  validloss 5.47524±0.00000  bestvalidloss 5.13901  last_update 85\n",
      "train: iter 347  trainloss 3.16586  validloss 5.77830±0.00000  bestvalidloss 5.13901  last_update 86\n",
      "train: iter 348  trainloss 3.19058  validloss 5.32824±0.00000  bestvalidloss 5.13901  last_update 87\n",
      "train: iter 349  trainloss 3.20000  validloss 5.41923±0.00000  bestvalidloss 5.13901  last_update 88\n",
      "train: iter 350  trainloss 3.23921  validloss 5.60687±0.00000  bestvalidloss 5.13901  last_update 89\n",
      "train: iter 351  trainloss 3.20482  validloss 5.25149±0.00000  bestvalidloss 5.13901  last_update 90\n",
      "train: iter 352  trainloss 3.16574  validloss 5.53534±0.00000  bestvalidloss 5.13901  last_update 91\n",
      "train: iter 353  trainloss 3.16353  validloss 5.47019±0.00000  bestvalidloss 5.13901  last_update 92\n",
      "train: iter 354  trainloss 3.17375  validloss 5.11450±0.00000  bestvalidloss 5.11450  last_update 0\n",
      "train: iter 355  trainloss 3.19088  validloss 5.17169±0.00000  bestvalidloss 5.11450  last_update 1\n",
      "train: iter 356  trainloss 3.18673  validloss 5.21352±0.00000  bestvalidloss 5.11450  last_update 2\n",
      "train: iter 357  trainloss 3.17101  validloss 5.33818±0.00000  bestvalidloss 5.11450  last_update 3\n",
      "train: iter 358  trainloss 3.16888  validloss 5.26576±0.00000  bestvalidloss 5.11450  last_update 4\n",
      "train: iter 359  trainloss 3.17624  validloss 5.41809±0.00000  bestvalidloss 5.11450  last_update 5\n",
      "train: iter 360  trainloss 3.15899  validloss 5.27994±0.00000  bestvalidloss 5.11450  last_update 6\n",
      "train: iter 361  trainloss 3.19674  validloss 5.49007±0.00000  bestvalidloss 5.11450  last_update 7\n",
      "train: iter 362  trainloss 3.20750  validloss 5.69948±0.00000  bestvalidloss 5.11450  last_update 8\n",
      "train: iter 363  trainloss 3.15001  validloss 5.37042±0.00000  bestvalidloss 5.11450  last_update 9\n",
      "train: iter 364  trainloss 3.19295  validloss 5.13509±0.00000  bestvalidloss 5.11450  last_update 10\n",
      "train: iter 365  trainloss 3.19902  validloss 5.21375±0.00000  bestvalidloss 5.11450  last_update 11\n",
      "train: iter 366  trainloss 3.22748  validloss 5.58593±0.00000  bestvalidloss 5.11450  last_update 12\n",
      "train: iter 367  trainloss 3.17312  validloss 5.35485±0.00000  bestvalidloss 5.11450  last_update 13\n",
      "train: iter 368  trainloss 3.19938  validloss 5.25890±0.00000  bestvalidloss 5.11450  last_update 14\n",
      "train: iter 369  trainloss 3.21117  validloss 5.57238±0.00000  bestvalidloss 5.11450  last_update 15\n",
      "train: iter 370  trainloss 3.23724  validloss 5.76265±0.00000  bestvalidloss 5.11450  last_update 16\n",
      "train: iter 371  trainloss 3.19251  validloss 5.63527±0.00000  bestvalidloss 5.11450  last_update 17\n",
      "train: iter 372  trainloss 3.21821  validloss 5.41645±0.00000  bestvalidloss 5.11450  last_update 18\n",
      "train: iter 373  trainloss 3.22760  validloss 5.80601±0.00000  bestvalidloss 5.11450  last_update 19\n",
      "train: iter 374  trainloss 3.17959  validloss 5.45531±0.00000  bestvalidloss 5.11450  last_update 20\n",
      "train: iter 375  trainloss 3.19144  validloss 5.43175±0.00000  bestvalidloss 5.11450  last_update 21\n",
      "train: iter 376  trainloss 3.18822  validloss 5.43934±0.00000  bestvalidloss 5.11450  last_update 22\n",
      "train: iter 377  trainloss 3.18055  validloss 5.62096±0.00000  bestvalidloss 5.11450  last_update 23\n",
      "train: iter 378  trainloss 3.23451  validloss 5.38525±0.00000  bestvalidloss 5.11450  last_update 24\n",
      "train: iter 379  trainloss 3.18269  validloss 5.71785±0.00000  bestvalidloss 5.11450  last_update 25\n",
      "train: iter 380  trainloss 3.15716  validloss 5.36362±0.00000  bestvalidloss 5.11450  last_update 26\n",
      "train: iter 381  trainloss 3.18199  validloss 5.16273±0.00000  bestvalidloss 5.11450  last_update 27\n",
      "train: iter 382  trainloss 3.15412  validloss 5.68898±0.00000  bestvalidloss 5.11450  last_update 28\n",
      "train: iter 383  trainloss 3.23393  validloss 5.46980±0.00000  bestvalidloss 5.11450  last_update 29\n",
      "train: iter 384  trainloss 3.20528  validloss 5.47711±0.00000  bestvalidloss 5.11450  last_update 30\n",
      "train: iter 385  trainloss 3.20635  validloss 5.70727±0.00000  bestvalidloss 5.11450  last_update 31\n",
      "train: iter 386  trainloss 3.16573  validloss 5.58815±0.00000  bestvalidloss 5.11450  last_update 32\n",
      "train: iter 387  trainloss 3.19142  validloss 5.09821±0.00000  bestvalidloss 5.09821  last_update 0\n",
      "train: iter 388  trainloss 3.21237  validloss 5.26571±0.00000  bestvalidloss 5.09821  last_update 1\n",
      "train: iter 389  trainloss 3.16674  validloss 5.53843±0.00000  bestvalidloss 5.09821  last_update 2\n",
      "train: iter 390  trainloss 3.21447  validloss 5.60684±0.00000  bestvalidloss 5.09821  last_update 3\n",
      "train: iter 391  trainloss 3.20251  validloss 5.45939±0.00000  bestvalidloss 5.09821  last_update 4\n",
      "train: iter 392  trainloss 3.21359  validloss 5.62672±0.00000  bestvalidloss 5.09821  last_update 5\n",
      "train: iter 393  trainloss 3.20329  validloss 5.53321±0.00000  bestvalidloss 5.09821  last_update 6\n",
      "train: iter 394  trainloss 3.21256  validloss 5.38330±0.00000  bestvalidloss 5.09821  last_update 7\n",
      "train: iter 395  trainloss 3.20784  validloss 5.50703±0.00000  bestvalidloss 5.09821  last_update 8\n",
      "train: iter 396  trainloss 3.21838  validloss 5.31340±0.00000  bestvalidloss 5.09821  last_update 9\n",
      "train: iter 397  trainloss 3.19703  validloss 5.58056±0.00000  bestvalidloss 5.09821  last_update 10\n",
      "train: iter 398  trainloss 3.17925  validloss 5.39205±0.00000  bestvalidloss 5.09821  last_update 11\n",
      "train: iter 399  trainloss 3.18449  validloss 5.31191±0.00000  bestvalidloss 5.09821  last_update 12\n",
      "train: iter 400  trainloss 3.17974  validloss 5.43069±0.00000  bestvalidloss 5.09821  last_update 13\n",
      "train: iter 401  trainloss 3.16321  validloss 5.36116±0.00000  bestvalidloss 5.09821  last_update 14\n",
      "train: iter 402  trainloss 3.21681  validloss 5.80642±0.00000  bestvalidloss 5.09821  last_update 15\n",
      "train: iter 403  trainloss 3.18828  validloss 5.51370±0.00000  bestvalidloss 5.09821  last_update 16\n",
      "train: iter 404  trainloss 3.19225  validloss 5.53294±0.00000  bestvalidloss 5.09821  last_update 17\n",
      "train: iter 405  trainloss 3.21714  validloss 5.41964±0.00000  bestvalidloss 5.09821  last_update 18\n",
      "train: iter 406  trainloss 3.20034  validloss 5.70951±0.00000  bestvalidloss 5.09821  last_update 19\n",
      "train: iter 407  trainloss 3.20155  validloss 5.95023±0.00000  bestvalidloss 5.09821  last_update 20\n",
      "train: iter 408  trainloss 3.19222  validloss 5.28712±0.00000  bestvalidloss 5.09821  last_update 21\n",
      "train: iter 409  trainloss 3.16692  validloss 5.24919±0.00000  bestvalidloss 5.09821  last_update 22\n",
      "train: iter 410  trainloss 3.14378  validloss 5.73643±0.00000  bestvalidloss 5.09821  last_update 23\n",
      "train: iter 411  trainloss 3.18061  validloss 5.73939±0.00000  bestvalidloss 5.09821  last_update 24\n",
      "train: iter 412  trainloss 3.17521  validloss 5.25841±0.00000  bestvalidloss 5.09821  last_update 25\n",
      "train: iter 413  trainloss 3.13532  validloss 5.66870±0.00000  bestvalidloss 5.09821  last_update 26\n",
      "train: iter 414  trainloss 3.19341  validloss 5.64457±0.00000  bestvalidloss 5.09821  last_update 27\n",
      "train: iter 415  trainloss 3.18035  validloss 5.78221±0.00000  bestvalidloss 5.09821  last_update 28\n",
      "train: iter 416  trainloss 3.17250  validloss 5.61372±0.00000  bestvalidloss 5.09821  last_update 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 417  trainloss 3.16089  validloss 6.05658±0.00000  bestvalidloss 5.09821  last_update 30\n",
      "train: iter 418  trainloss 3.18619  validloss 5.21765±0.00000  bestvalidloss 5.09821  last_update 31\n",
      "train: iter 419  trainloss 3.16478  validloss 5.49598±0.00000  bestvalidloss 5.09821  last_update 32\n",
      "train: iter 420  trainloss 3.15060  validloss 5.29592±0.00000  bestvalidloss 5.09821  last_update 33\n",
      "train: iter 421  trainloss 3.16537  validloss 5.31402±0.00000  bestvalidloss 5.09821  last_update 34\n",
      "train: iter 422  trainloss 3.24530  validloss 5.17390±0.00000  bestvalidloss 5.09821  last_update 35\n",
      "train: iter 423  trainloss 3.18914  validloss 5.43345±0.00000  bestvalidloss 5.09821  last_update 36\n",
      "train: iter 424  trainloss 3.18980  validloss 5.69071±0.00000  bestvalidloss 5.09821  last_update 37\n",
      "train: iter 425  trainloss 3.14478  validloss 5.50747±0.00000  bestvalidloss 5.09821  last_update 38\n",
      "train: iter 426  trainloss 3.19215  validloss 5.36677±0.00000  bestvalidloss 5.09821  last_update 39\n",
      "train: iter 427  trainloss 3.19689  validloss 5.73373±0.00000  bestvalidloss 5.09821  last_update 40\n",
      "train: iter 428  trainloss 3.16554  validloss 5.61753±0.00000  bestvalidloss 5.09821  last_update 41\n",
      "train: iter 429  trainloss 3.19355  validloss 5.53715±0.00000  bestvalidloss 5.09821  last_update 42\n",
      "train: iter 430  trainloss 3.17627  validloss 5.38586±0.00000  bestvalidloss 5.09821  last_update 43\n",
      "train: iter 431  trainloss 3.16049  validloss 5.29762±0.00000  bestvalidloss 5.09821  last_update 44\n",
      "train: iter 432  trainloss 3.12808  validloss 5.42897±0.00000  bestvalidloss 5.09821  last_update 45\n",
      "train: iter 433  trainloss 3.17395  validloss 5.37580±0.00000  bestvalidloss 5.09821  last_update 46\n",
      "train: iter 434  trainloss 3.16768  validloss 5.50333±0.00000  bestvalidloss 5.09821  last_update 47\n",
      "train: iter 435  trainloss 3.20619  validloss 5.63102±0.00000  bestvalidloss 5.09821  last_update 48\n",
      "train: iter 436  trainloss 3.16891  validloss 5.57137±0.00000  bestvalidloss 5.09821  last_update 49\n",
      "train: iter 437  trainloss 3.21960  validloss 5.56925±0.00000  bestvalidloss 5.09821  last_update 50\n",
      "train: iter 438  trainloss 3.14661  validloss 5.35431±0.00000  bestvalidloss 5.09821  last_update 51\n",
      "train: iter 439  trainloss 3.18468  validloss 5.40892±0.00000  bestvalidloss 5.09821  last_update 52\n",
      "train: iter 440  trainloss 3.17783  validloss 5.24819±0.00000  bestvalidloss 5.09821  last_update 53\n",
      "train: iter 441  trainloss 3.17564  validloss 5.32621±0.00000  bestvalidloss 5.09821  last_update 54\n",
      "train: iter 442  trainloss 3.17401  validloss 5.63445±0.00000  bestvalidloss 5.09821  last_update 55\n",
      "train: iter 443  trainloss 3.14883  validloss 5.30080±0.00000  bestvalidloss 5.09821  last_update 56\n",
      "train: iter 444  trainloss 3.17718  validloss 5.33245±0.00000  bestvalidloss 5.09821  last_update 57\n",
      "train: iter 445  trainloss 3.15016  validloss 5.84944±0.00000  bestvalidloss 5.09821  last_update 58\n",
      "train: iter 446  trainloss 3.19605  validloss 5.18392±0.00000  bestvalidloss 5.09821  last_update 59\n",
      "train: iter 447  trainloss 3.17519  validloss 5.45682±0.00000  bestvalidloss 5.09821  last_update 60\n",
      "train: iter 448  trainloss 3.18065  validloss 5.68048±0.00000  bestvalidloss 5.09821  last_update 61\n",
      "train: iter 449  trainloss 3.15429  validloss 5.36963±0.00000  bestvalidloss 5.09821  last_update 62\n",
      "train: iter 450  trainloss 3.16630  validloss 5.33400±0.00000  bestvalidloss 5.09821  last_update 63\n",
      "train: iter 451  trainloss 3.15861  validloss 5.87444±0.00000  bestvalidloss 5.09821  last_update 64\n",
      "train: iter 452  trainloss 3.18672  validloss 5.63742±0.00000  bestvalidloss 5.09821  last_update 65\n",
      "train: iter 453  trainloss 3.16210  validloss 5.32250±0.00000  bestvalidloss 5.09821  last_update 66\n",
      "train: iter 454  trainloss 3.14725  validloss 5.55985±0.00000  bestvalidloss 5.09821  last_update 67\n",
      "train: iter 455  trainloss 3.15328  validloss 5.50436±0.00000  bestvalidloss 5.09821  last_update 68\n",
      "train: iter 456  trainloss 3.13479  validloss 5.40899±0.00000  bestvalidloss 5.09821  last_update 69\n",
      "train: iter 457  trainloss 3.22015  validloss 5.32768±0.00000  bestvalidloss 5.09821  last_update 70\n",
      "train: iter 458  trainloss 3.14484  validloss 5.62825±0.00000  bestvalidloss 5.09821  last_update 71\n",
      "train: iter 459  trainloss 3.17956  validloss 5.40448±0.00000  bestvalidloss 5.09821  last_update 72\n",
      "train: iter 460  trainloss 3.18810  validloss 5.59012±0.00000  bestvalidloss 5.09821  last_update 73\n",
      "train: iter 461  trainloss 3.17393  validloss 5.51441±0.00000  bestvalidloss 5.09821  last_update 74\n",
      "train: iter 462  trainloss 3.14718  validloss 5.64570±0.00000  bestvalidloss 5.09821  last_update 75\n",
      "train: iter 463  trainloss 3.14983  validloss 5.31770±0.00000  bestvalidloss 5.09821  last_update 76\n",
      "train: iter 464  trainloss 3.16947  validloss 5.47250±0.00000  bestvalidloss 5.09821  last_update 77\n",
      "train: iter 465  trainloss 3.17084  validloss 5.51468±0.00000  bestvalidloss 5.09821  last_update 78\n",
      "train: iter 466  trainloss 3.16479  validloss 5.52136±0.00000  bestvalidloss 5.09821  last_update 79\n",
      "train: iter 467  trainloss 3.15645  validloss 5.72892±0.00000  bestvalidloss 5.09821  last_update 80\n",
      "train: iter 468  trainloss 3.16336  validloss 5.61695±0.00000  bestvalidloss 5.09821  last_update 81\n",
      "train: iter 469  trainloss 3.18147  validloss 5.88317±0.00000  bestvalidloss 5.09821  last_update 82\n",
      "train: iter 470  trainloss 3.16091  validloss 5.58489±0.00000  bestvalidloss 5.09821  last_update 83\n",
      "train: iter 471  trainloss 3.14313  validloss 5.46506±0.00000  bestvalidloss 5.09821  last_update 84\n",
      "train: iter 472  trainloss 3.18009  validloss 5.51975±0.00000  bestvalidloss 5.09821  last_update 85\n",
      "train: iter 473  trainloss 3.14961  validloss 5.59571±0.00000  bestvalidloss 5.09821  last_update 86\n",
      "train: iter 474  trainloss 3.16178  validloss 5.60913±0.00000  bestvalidloss 5.09821  last_update 87\n",
      "train: iter 475  trainloss 3.18188  validloss 5.21295±0.00000  bestvalidloss 5.09821  last_update 88\n",
      "train: iter 476  trainloss 3.16911  validloss 5.54531±0.00000  bestvalidloss 5.09821  last_update 89\n",
      "train: iter 477  trainloss 3.13644  validloss 5.74615±0.00000  bestvalidloss 5.09821  last_update 90\n",
      "train: iter 478  trainloss 3.17046  validloss 5.71853±0.00000  bestvalidloss 5.09821  last_update 91\n",
      "train: iter 479  trainloss 3.17291  validloss 5.51817±0.00000  bestvalidloss 5.09821  last_update 92\n",
      "train: iter 480  trainloss 3.20219  validloss 5.61309±0.00000  bestvalidloss 5.09821  last_update 93\n",
      "train: iter 481  trainloss 3.18825  validloss 5.69334±0.00000  bestvalidloss 5.09821  last_update 94\n",
      "train: iter 482  trainloss 3.18920  validloss 5.69219±0.00000  bestvalidloss 5.09821  last_update 95\n",
      "train: iter 483  trainloss 3.14817  validloss 5.31993±0.00000  bestvalidloss 5.09821  last_update 96\n",
      "train: iter 484  trainloss 3.16428  validloss 5.39718±0.00000  bestvalidloss 5.09821  last_update 97\n",
      "train: iter 485  trainloss 3.18021  validloss 5.20879±0.00000  bestvalidloss 5.09821  last_update 98\n",
      "train: iter 486  trainloss 3.15516  validloss 5.54412±0.00000  bestvalidloss 5.09821  last_update 99\n",
      "train: iter 487  trainloss 3.20148  validloss 5.81262±0.00000  bestvalidloss 5.09821  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-14.3435)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(4.5727)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.588775341447449\n",
      "tensor([-1.4130])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0810a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be500f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3c9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84995a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7219bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
