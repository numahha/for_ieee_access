{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(1770.9811)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 48\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 698.46825  validloss 932.97366±0.00000  bestvalidloss 932.97366  last_update 0\n",
      "train: iter 1  trainloss 295.45915  validloss 503.27808±0.00000  bestvalidloss 503.27808  last_update 0\n",
      "train: iter 2  trainloss -48.24370  validloss 152.67186±0.00000  bestvalidloss 152.67186  last_update 0\n",
      "train: iter 3  trainloss -361.76585  validloss -225.08946±0.00000  bestvalidloss -225.08946  last_update 0\n",
      "train: iter 4  trainloss -552.50036  validloss -300.76335±0.00000  bestvalidloss -300.76335  last_update 0\n",
      "train: iter 5  trainloss -664.82100  validloss -549.52634±0.00000  bestvalidloss -549.52634  last_update 0\n",
      "train: iter 6  trainloss -744.25756  validloss -558.18338±0.00000  bestvalidloss -558.18338  last_update 0\n",
      "train: iter 7  trainloss -766.86860  validloss -642.89193±0.00000  bestvalidloss -642.89193  last_update 0\n",
      "train: iter 8  trainloss -937.16301  validloss -735.89196±0.00000  bestvalidloss -735.89196  last_update 0\n",
      "train: iter 9  trainloss -976.33207  validloss -843.41151±0.00000  bestvalidloss -843.41151  last_update 0\n",
      "train: iter 10  trainloss -1045.41860  validloss -810.50839±0.00000  bestvalidloss -843.41151  last_update 1\n",
      "train: iter 11  trainloss -988.63696  validloss -887.04179±0.00000  bestvalidloss -887.04179  last_update 0\n",
      "train: iter 12  trainloss -1046.04542  validloss -921.86487±0.00000  bestvalidloss -921.86487  last_update 0\n",
      "train: iter 13  trainloss -598.92631  validloss 318.07995±0.00000  bestvalidloss -921.86487  last_update 1\n",
      "train: iter 14  trainloss -1159.53754  validloss -654.19809±0.00000  bestvalidloss -921.86487  last_update 2\n",
      "train: iter 15  trainloss -1177.65912  validloss -1016.47717±0.00000  bestvalidloss -1016.47717  last_update 0\n",
      "train: iter 16  trainloss -1236.56378  validloss -907.91278±0.00000  bestvalidloss -1016.47717  last_update 1\n",
      "train: iter 17  trainloss -1266.76989  validloss -833.33301±0.00000  bestvalidloss -1016.47717  last_update 2\n",
      "train: iter 18  trainloss -1345.17359  validloss -719.07907±0.00000  bestvalidloss -1016.47717  last_update 3\n",
      "train: iter 19  trainloss -1322.29471  validloss -1093.25511±0.00000  bestvalidloss -1093.25511  last_update 0\n",
      "train: iter 20  trainloss -1315.39069  validloss -830.91015±0.00000  bestvalidloss -1093.25511  last_update 1\n",
      "train: iter 21  trainloss -1454.88672  validloss -1085.99653±0.00000  bestvalidloss -1093.25511  last_update 2\n",
      "train: iter 22  trainloss -1441.87542  validloss -1148.75607±0.00000  bestvalidloss -1148.75607  last_update 0\n",
      "train: iter 23  trainloss -1490.61635  validloss -1152.67134±0.00000  bestvalidloss -1152.67134  last_update 0\n",
      "train: iter 24  trainloss -1382.35988  validloss -1232.54272±0.00000  bestvalidloss -1232.54272  last_update 0\n",
      "train: iter 25  trainloss -1524.70598  validloss -1180.24452±0.00000  bestvalidloss -1232.54272  last_update 1\n",
      "train: iter 26  trainloss -1521.83578  validloss -1188.74753±0.00000  bestvalidloss -1232.54272  last_update 2\n",
      "train: iter 27  trainloss -1455.44105  validloss -1164.22181±0.00000  bestvalidloss -1232.54272  last_update 3\n",
      "train: iter 28  trainloss -1537.21765  validloss -1211.59597±0.00000  bestvalidloss -1232.54272  last_update 4\n",
      "train: iter 29  trainloss -1560.40427  validloss -1152.98391±0.00000  bestvalidloss -1232.54272  last_update 5\n",
      "train: iter 30  trainloss -1487.89756  validloss -1273.24495±0.00000  bestvalidloss -1273.24495  last_update 0\n",
      "train: iter 31  trainloss -1567.90790  validloss -1090.14420±0.00000  bestvalidloss -1273.24495  last_update 1\n",
      "train: iter 32  trainloss -1571.43961  validloss -1167.79607±0.00000  bestvalidloss -1273.24495  last_update 2\n",
      "train: iter 33  trainloss -1610.57315  validloss -1326.64192±0.00000  bestvalidloss -1326.64192  last_update 0\n",
      "train: iter 34  trainloss -1615.04397  validloss -1253.74484±0.00000  bestvalidloss -1326.64192  last_update 1\n",
      "train: iter 35  trainloss -1551.75114  validloss -1326.73241±0.00000  bestvalidloss -1326.73241  last_update 0\n",
      "train: iter 36  trainloss -1525.49757  validloss -1083.69415±0.00000  bestvalidloss -1326.73241  last_update 1\n",
      "train: iter 37  trainloss -1604.07299  validloss -1153.43696±0.00000  bestvalidloss -1326.73241  last_update 2\n",
      "train: iter 38  trainloss -1665.01197  validloss -1322.57678±0.00000  bestvalidloss -1326.73241  last_update 3\n",
      "train: iter 39  trainloss -1596.26693  validloss -1266.29894±0.00000  bestvalidloss -1326.73241  last_update 4\n",
      "train: iter 40  trainloss -1526.70978  validloss -1170.43225±0.00000  bestvalidloss -1326.73241  last_update 5\n",
      "train: iter 41  trainloss -1610.16891  validloss -1169.91345±0.00000  bestvalidloss -1326.73241  last_update 6\n",
      "train: iter 42  trainloss -1621.68745  validloss -1302.27431±0.00000  bestvalidloss -1326.73241  last_update 7\n",
      "train: iter 43  trainloss -1572.66894  validloss -1021.08566±0.00000  bestvalidloss -1326.73241  last_update 8\n",
      "train: iter 44  trainloss -1622.10492  validloss -1237.84635±0.00000  bestvalidloss -1326.73241  last_update 9\n",
      "train: iter 45  trainloss -1700.36873  validloss -1317.70451±0.00000  bestvalidloss -1326.73241  last_update 10\n",
      "train: iter 46  trainloss -1574.56116  validloss -1290.76719±0.00000  bestvalidloss -1326.73241  last_update 11\n",
      "train: iter 47  trainloss -1636.11108  validloss -1148.06248±0.00000  bestvalidloss -1326.73241  last_update 12\n",
      "train: iter 48  trainloss -1628.89326  validloss -1291.13743±0.00000  bestvalidloss -1326.73241  last_update 13\n",
      "train: iter 49  trainloss -1701.18733  validloss -1354.15002±0.00000  bestvalidloss -1354.15002  last_update 0\n",
      "train: iter 50  trainloss -1654.15771  validloss -1267.10303±0.00000  bestvalidloss -1354.15002  last_update 1\n",
      "train: iter 51  trainloss -1634.68415  validloss -1263.62554±0.00000  bestvalidloss -1354.15002  last_update 2\n",
      "train: iter 52  trainloss -1672.17697  validloss -1336.91255±0.00000  bestvalidloss -1354.15002  last_update 3\n",
      "train: iter 53  trainloss -1704.93996  validloss -1335.64341±0.00000  bestvalidloss -1354.15002  last_update 4\n",
      "train: iter 54  trainloss -1567.29383  validloss -1251.95865±0.00000  bestvalidloss -1354.15002  last_update 5\n",
      "train: iter 55  trainloss -1500.46471  validloss -1253.00904±0.00000  bestvalidloss -1354.15002  last_update 6\n",
      "train: iter 56  trainloss -1725.59814  validloss -1291.15187±0.00000  bestvalidloss -1354.15002  last_update 7\n",
      "train: iter 57  trainloss -1717.73032  validloss -1404.54636±0.00000  bestvalidloss -1404.54636  last_update 0\n",
      "train: iter 58  trainloss -1702.21273  validloss -1210.59226±0.00000  bestvalidloss -1404.54636  last_update 1\n",
      "train: iter 59  trainloss -1745.56297  validloss -1396.54281±0.00000  bestvalidloss -1404.54636  last_update 2\n",
      "train: iter 60  trainloss -1728.97034  validloss -1438.52480±0.00000  bestvalidloss -1438.52480  last_update 0\n",
      "train: iter 61  trainloss -1701.43131  validloss -1378.20752±0.00000  bestvalidloss -1438.52480  last_update 1\n",
      "train: iter 62  trainloss -1692.66104  validloss -1318.37487±0.00000  bestvalidloss -1438.52480  last_update 2\n",
      "train: iter 63  trainloss -1634.73243  validloss -1299.63882±0.00000  bestvalidloss -1438.52480  last_update 3\n",
      "train: iter 64  trainloss -1734.53922  validloss -1266.63340±0.00000  bestvalidloss -1438.52480  last_update 4\n",
      "train: iter 65  trainloss -1761.12704  validloss -1435.85186±0.00000  bestvalidloss -1438.52480  last_update 5\n",
      "train: iter 66  trainloss -1639.64285  validloss -1415.66173±0.00000  bestvalidloss -1438.52480  last_update 6\n",
      "train: iter 67  trainloss -1604.70727  validloss -1095.62417±0.00000  bestvalidloss -1438.52480  last_update 7\n",
      "train: iter 68  trainloss -1727.48383  validloss -1229.20419±0.00000  bestvalidloss -1438.52480  last_update 8\n",
      "train: iter 69  trainloss -1782.84828  validloss -1357.56576±0.00000  bestvalidloss -1438.52480  last_update 9\n",
      "train: iter 70  trainloss -1715.45939  validloss -1447.09189±0.00000  bestvalidloss -1447.09189  last_update 0\n",
      "train: iter 71  trainloss -1764.83331  validloss -1377.05551±0.00000  bestvalidloss -1447.09189  last_update 1\n",
      "train: iter 72  trainloss -1751.23920  validloss -1372.82413±0.00000  bestvalidloss -1447.09189  last_update 2\n",
      "train: iter 73  trainloss -1705.06961  validloss -1413.48495±0.00000  bestvalidloss -1447.09189  last_update 3\n",
      "train: iter 74  trainloss -1743.39218  validloss -1368.14733±0.00000  bestvalidloss -1447.09189  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1698.03044  validloss -1310.77477±0.00000  bestvalidloss -1447.09189  last_update 5\n",
      "train: iter 76  trainloss -1744.26869  validloss -1324.36374±0.00000  bestvalidloss -1447.09189  last_update 6\n",
      "train: iter 77  trainloss -1770.25602  validloss -1386.81379±0.00000  bestvalidloss -1447.09189  last_update 7\n",
      "train: iter 78  trainloss -1806.09680  validloss -1464.66120±0.00000  bestvalidloss -1464.66120  last_update 0\n",
      "train: iter 79  trainloss -1783.89291  validloss -1451.77826±0.00000  bestvalidloss -1464.66120  last_update 1\n",
      "train: iter 80  trainloss -1794.92796  validloss -1393.71182±0.00000  bestvalidloss -1464.66120  last_update 2\n",
      "train: iter 81  trainloss -1738.97528  validloss -1406.29045±0.00000  bestvalidloss -1464.66120  last_update 3\n",
      "train: iter 82  trainloss -1724.27354  validloss -1431.62965±0.00000  bestvalidloss -1464.66120  last_update 4\n",
      "train: iter 83  trainloss -1788.61292  validloss -1481.86811±0.00000  bestvalidloss -1481.86811  last_update 0\n",
      "train: iter 84  trainloss -1819.11644  validloss -1455.68875±0.00000  bestvalidloss -1481.86811  last_update 1\n",
      "train: iter 85  trainloss -1813.73375  validloss -1520.58840±0.00000  bestvalidloss -1520.58840  last_update 0\n",
      "train: iter 86  trainloss -1813.51112  validloss -1448.15640±0.00000  bestvalidloss -1520.58840  last_update 1\n",
      "train: iter 87  trainloss -1813.22160  validloss -1529.08525±0.00000  bestvalidloss -1529.08525  last_update 0\n",
      "train: iter 88  trainloss -1738.63109  validloss -1491.19712±0.00000  bestvalidloss -1529.08525  last_update 1\n",
      "train: iter 89  trainloss -1823.04306  validloss -1509.33885±0.00000  bestvalidloss -1529.08525  last_update 2\n",
      "train: iter 90  trainloss -1824.28262  validloss -1467.36508±0.00000  bestvalidloss -1529.08525  last_update 3\n",
      "train: iter 91  trainloss -1737.13262  validloss -1492.90586±0.00000  bestvalidloss -1529.08525  last_update 4\n",
      "train: iter 92  trainloss -1807.68229  validloss -1563.55154±0.00000  bestvalidloss -1563.55154  last_update 0\n",
      "train: iter 93  trainloss -1749.67309  validloss -1470.35722±0.00000  bestvalidloss -1563.55154  last_update 1\n",
      "train: iter 94  trainloss -1841.16444  validloss -1484.96367±0.00000  bestvalidloss -1563.55154  last_update 2\n",
      "train: iter 95  trainloss -1859.26388  validloss -1591.05755±0.00000  bestvalidloss -1591.05755  last_update 0\n",
      "train: iter 96  trainloss -1843.55438  validloss -1598.35734±0.00000  bestvalidloss -1598.35734  last_update 0\n",
      "train: iter 97  trainloss -1807.12619  validloss -1604.90454±0.00000  bestvalidloss -1604.90454  last_update 0\n",
      "train: iter 98  trainloss -1828.47670  validloss -1553.21454±0.00000  bestvalidloss -1604.90454  last_update 1\n",
      "train: iter 99  trainloss -1787.39995  validloss -1599.48181±0.00000  bestvalidloss -1604.90454  last_update 2\n",
      "train: iter 100  trainloss -1801.72621  validloss -1616.54158±0.00000  bestvalidloss -1616.54158  last_update 0\n",
      "train: iter 101  trainloss -1847.01850  validloss -1564.00634±0.00000  bestvalidloss -1616.54158  last_update 1\n",
      "train: iter 102  trainloss -1817.63056  validloss -1524.64265±0.00000  bestvalidloss -1616.54158  last_update 2\n",
      "train: iter 103  trainloss -1810.70138  validloss -1569.86358±0.00000  bestvalidloss -1616.54158  last_update 3\n",
      "train: iter 104  trainloss -1844.09436  validloss -1490.22356±0.00000  bestvalidloss -1616.54158  last_update 4\n",
      "train: iter 105  trainloss -1809.95107  validloss -1587.70186±0.00000  bestvalidloss -1616.54158  last_update 5\n",
      "train: iter 106  trainloss -1851.34406  validloss -1568.03334±0.00000  bestvalidloss -1616.54158  last_update 6\n",
      "train: iter 107  trainloss -1764.55695  validloss -1464.54433±0.00000  bestvalidloss -1616.54158  last_update 7\n",
      "train: iter 108  trainloss -1840.14216  validloss -1460.51058±0.00000  bestvalidloss -1616.54158  last_update 8\n",
      "train: iter 109  trainloss -1804.69782  validloss -1511.69271±0.00000  bestvalidloss -1616.54158  last_update 9\n",
      "train: iter 110  trainloss -1872.84684  validloss -1496.42429±0.00000  bestvalidloss -1616.54158  last_update 10\n",
      "train: iter 111  trainloss -1853.79710  validloss -1559.18844±0.00000  bestvalidloss -1616.54158  last_update 11\n",
      "train: iter 112  trainloss -1907.26331  validloss -1543.00093±0.00000  bestvalidloss -1616.54158  last_update 12\n",
      "train: iter 113  trainloss -1928.75627  validloss -1494.01620±0.00000  bestvalidloss -1616.54158  last_update 13\n",
      "train: iter 114  trainloss -1947.84213  validloss -1438.08434±0.00000  bestvalidloss -1616.54158  last_update 14\n",
      "train: iter 115  trainloss -1772.67783  validloss -1558.61708±0.00000  bestvalidloss -1616.54158  last_update 15\n",
      "train: iter 116  trainloss -1870.64968  validloss -1515.14791±0.00000  bestvalidloss -1616.54158  last_update 16\n",
      "train: iter 117  trainloss -1680.76458  validloss -1299.89865±0.00000  bestvalidloss -1616.54158  last_update 17\n",
      "train: iter 118  trainloss -1948.25087  validloss -1581.96273±0.00000  bestvalidloss -1616.54158  last_update 18\n",
      "train: iter 119  trainloss -1928.21308  validloss -1658.94561±0.00000  bestvalidloss -1658.94561  last_update 0\n",
      "train: iter 120  trainloss -1961.26057  validloss -1580.34724±0.00000  bestvalidloss -1658.94561  last_update 1\n",
      "train: iter 121  trainloss -1905.85887  validloss -1617.30368±0.00000  bestvalidloss -1658.94561  last_update 2\n",
      "train: iter 122  trainloss -1950.72132  validloss -1562.34786±0.00000  bestvalidloss -1658.94561  last_update 3\n",
      "train: iter 123  trainloss -1979.23445  validloss -1661.38018±0.00000  bestvalidloss -1661.38018  last_update 0\n",
      "train: iter 124  trainloss -1925.76831  validloss -1716.85859±0.00000  bestvalidloss -1716.85859  last_update 0\n",
      "train: iter 125  trainloss -1980.85947  validloss -1642.29000±0.00000  bestvalidloss -1716.85859  last_update 1\n",
      "train: iter 126  trainloss -1926.96955  validloss -1651.02043±0.00000  bestvalidloss -1716.85859  last_update 2\n",
      "train: iter 127  trainloss -1982.87256  validloss -1652.09257±0.00000  bestvalidloss -1716.85859  last_update 3\n",
      "train: iter 128  trainloss -1978.07336  validloss -1666.98891±0.00000  bestvalidloss -1716.85859  last_update 4\n",
      "train: iter 129  trainloss -2006.41651  validloss -1710.51289±0.00000  bestvalidloss -1716.85859  last_update 5\n",
      "train: iter 130  trainloss -1973.91261  validloss -1721.48998±0.00000  bestvalidloss -1721.48998  last_update 0\n",
      "train: iter 131  trainloss -2003.78281  validloss -1732.29597±0.00000  bestvalidloss -1732.29597  last_update 0\n",
      "train: iter 132  trainloss -1871.71104  validloss -1714.11382±0.00000  bestvalidloss -1732.29597  last_update 1\n",
      "train: iter 133  trainloss -1879.14546  validloss -1677.31245±0.00000  bestvalidloss -1732.29597  last_update 2\n",
      "train: iter 134  trainloss -1976.90429  validloss -1608.49155±0.00000  bestvalidloss -1732.29597  last_update 3\n",
      "train: iter 135  trainloss -1981.97422  validloss -1740.87457±0.00000  bestvalidloss -1740.87457  last_update 0\n",
      "train: iter 136  trainloss -1930.25377  validloss -1719.63562±0.00000  bestvalidloss -1740.87457  last_update 1\n",
      "train: iter 137  trainloss -1911.42061  validloss -1691.89619±0.00000  bestvalidloss -1740.87457  last_update 2\n",
      "train: iter 138  trainloss -1995.57473  validloss -1635.01461±0.00000  bestvalidloss -1740.87457  last_update 3\n",
      "train: iter 139  trainloss -1941.08433  validloss -1691.88668±0.00000  bestvalidloss -1740.87457  last_update 4\n",
      "train: iter 140  trainloss -1927.52181  validloss -1601.31774±0.00000  bestvalidloss -1740.87457  last_update 5\n",
      "train: iter 141  trainloss -1972.08721  validloss -1731.22733±0.00000  bestvalidloss -1740.87457  last_update 6\n",
      "train: iter 142  trainloss -1962.40523  validloss -1727.66456±0.00000  bestvalidloss -1740.87457  last_update 7\n",
      "train: iter 143  trainloss -2022.41107  validloss -1695.89296±0.00000  bestvalidloss -1740.87457  last_update 8\n",
      "train: iter 144  trainloss -2004.76940  validloss -1740.05472±0.00000  bestvalidloss -1740.87457  last_update 9\n",
      "train: iter 145  trainloss -1960.50421  validloss -1761.02538±0.00000  bestvalidloss -1761.02538  last_update 0\n",
      "train: iter 146  trainloss -1922.39602  validloss -1672.57514±0.00000  bestvalidloss -1761.02538  last_update 1\n",
      "train: iter 147  trainloss -2004.32585  validloss -1755.84543±0.00000  bestvalidloss -1761.02538  last_update 2\n",
      "train: iter 148  trainloss -1967.51848  validloss -1653.04521±0.00000  bestvalidloss -1761.02538  last_update 3\n",
      "train: iter 149  trainloss -2003.60948  validloss -1741.81890±0.00000  bestvalidloss -1761.02538  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 150  trainloss -2028.84247  validloss -1718.82027±0.00000  bestvalidloss -1761.02538  last_update 5\n",
      "train: iter 151  trainloss -1990.79065  validloss -1776.61064±0.00000  bestvalidloss -1776.61064  last_update 0\n",
      "train: iter 152  trainloss -1985.47598  validloss -1670.10007±0.00000  bestvalidloss -1776.61064  last_update 1\n",
      "train: iter 153  trainloss -2020.11017  validloss -1746.52203±0.00000  bestvalidloss -1776.61064  last_update 2\n",
      "train: iter 154  trainloss -2041.17277  validloss -1784.45464±0.00000  bestvalidloss -1784.45464  last_update 0\n",
      "train: iter 155  trainloss -2041.84691  validloss -1811.20942±0.00000  bestvalidloss -1811.20942  last_update 0\n",
      "train: iter 156  trainloss -2032.22791  validloss -1737.11434±0.00000  bestvalidloss -1811.20942  last_update 1\n",
      "train: iter 157  trainloss -1953.82858  validloss -1690.09762±0.00000  bestvalidloss -1811.20942  last_update 2\n",
      "train: iter 158  trainloss -2006.32356  validloss -1724.58605±0.00000  bestvalidloss -1811.20942  last_update 3\n",
      "train: iter 159  trainloss -2020.73144  validloss -1785.23746±0.00000  bestvalidloss -1811.20942  last_update 4\n",
      "train: iter 160  trainloss -2011.25301  validloss -1857.70327±0.00000  bestvalidloss -1857.70327  last_update 0\n",
      "train: iter 161  trainloss -2002.12457  validloss -1783.78600±0.00000  bestvalidloss -1857.70327  last_update 1\n",
      "train: iter 162  trainloss -2009.83721  validloss -1736.97578±0.00000  bestvalidloss -1857.70327  last_update 2\n",
      "train: iter 163  trainloss -1949.78026  validloss -1817.14827±0.00000  bestvalidloss -1857.70327  last_update 3\n",
      "train: iter 164  trainloss -2039.90754  validloss -1837.61823±0.00000  bestvalidloss -1857.70327  last_update 4\n",
      "train: iter 165  trainloss -1970.39203  validloss -1793.08068±0.00000  bestvalidloss -1857.70327  last_update 5\n",
      "train: iter 166  trainloss -2001.64015  validloss -1810.20146±0.00000  bestvalidloss -1857.70327  last_update 6\n",
      "train: iter 167  trainloss -2025.68580  validloss -1734.81501±0.00000  bestvalidloss -1857.70327  last_update 7\n",
      "train: iter 168  trainloss -2041.62642  validloss -1656.00142±0.00000  bestvalidloss -1857.70327  last_update 8\n",
      "train: iter 169  trainloss -2034.72366  validloss -1784.52797±0.00000  bestvalidloss -1857.70327  last_update 9\n",
      "train: iter 170  trainloss -1971.88826  validloss -1809.20843±0.00000  bestvalidloss -1857.70327  last_update 10\n",
      "train: iter 171  trainloss -1971.28335  validloss -1620.37587±0.00000  bestvalidloss -1857.70327  last_update 11\n",
      "train: iter 172  trainloss -1983.94789  validloss -1777.35609±0.00000  bestvalidloss -1857.70327  last_update 12\n",
      "train: iter 173  trainloss -2051.85681  validloss -1779.36669±0.00000  bestvalidloss -1857.70327  last_update 13\n",
      "train: iter 174  trainloss -2072.38537  validloss -1792.82396±0.00000  bestvalidloss -1857.70327  last_update 14\n",
      "train: iter 175  trainloss -2061.06003  validloss -1845.21931±0.00000  bestvalidloss -1857.70327  last_update 15\n",
      "train: iter 176  trainloss -2030.70242  validloss -1782.37977±0.00000  bestvalidloss -1857.70327  last_update 16\n",
      "train: iter 177  trainloss -2052.36032  validloss -1798.88881±0.00000  bestvalidloss -1857.70327  last_update 17\n",
      "train: iter 178  trainloss -2042.01122  validloss -1727.01892±0.00000  bestvalidloss -1857.70327  last_update 18\n",
      "train: iter 179  trainloss -1916.18912  validloss -1787.56447±0.00000  bestvalidloss -1857.70327  last_update 19\n",
      "train: iter 180  trainloss -1993.72171  validloss -1331.45082±0.00000  bestvalidloss -1857.70327  last_update 20\n",
      "train: iter 181  trainloss -2083.54623  validloss -1785.25806±0.00000  bestvalidloss -1857.70327  last_update 21\n",
      "train: iter 182  trainloss -1975.67483  validloss -1808.95178±0.00000  bestvalidloss -1857.70327  last_update 22\n",
      "train: iter 183  trainloss -2028.99753  validloss -1735.61341±0.00000  bestvalidloss -1857.70327  last_update 23\n",
      "train: iter 184  trainloss -2078.92456  validloss -1886.16929±0.00000  bestvalidloss -1886.16929  last_update 0\n",
      "train: iter 185  trainloss -2042.29834  validloss -1766.79690±0.00000  bestvalidloss -1886.16929  last_update 1\n",
      "train: iter 186  trainloss -2066.41572  validloss -1787.06021±0.00000  bestvalidloss -1886.16929  last_update 2\n",
      "train: iter 187  trainloss -1990.30857  validloss -1876.67092±0.00000  bestvalidloss -1886.16929  last_update 3\n",
      "train: iter 188  trainloss -2051.27129  validloss -1762.73474±0.00000  bestvalidloss -1886.16929  last_update 4\n",
      "train: iter 189  trainloss -2055.93803  validloss -1827.85378±0.00000  bestvalidloss -1886.16929  last_update 5\n",
      "train: iter 190  trainloss -2010.48783  validloss -1749.77972±0.00000  bestvalidloss -1886.16929  last_update 6\n",
      "train: iter 191  trainloss -2005.57342  validloss -1764.65884±0.00000  bestvalidloss -1886.16929  last_update 7\n",
      "train: iter 192  trainloss -2081.41402  validloss -1834.80255±0.00000  bestvalidloss -1886.16929  last_update 8\n",
      "train: iter 193  trainloss -2097.50077  validloss -1884.00811±0.00000  bestvalidloss -1886.16929  last_update 9\n",
      "train: iter 194  trainloss -2056.84800  validloss -1867.69604±0.00000  bestvalidloss -1886.16929  last_update 10\n",
      "train: iter 195  trainloss -2067.75794  validloss -1791.29786±0.00000  bestvalidloss -1886.16929  last_update 11\n",
      "train: iter 196  trainloss -1995.79526  validloss -1797.43307±0.00000  bestvalidloss -1886.16929  last_update 12\n",
      "train: iter 197  trainloss -2020.98954  validloss -1818.27396±0.00000  bestvalidloss -1886.16929  last_update 13\n",
      "train: iter 198  trainloss -2060.10227  validloss -1822.06772±0.00000  bestvalidloss -1886.16929  last_update 14\n",
      "train: iter 199  trainloss -2084.85680  validloss -1895.65402±0.00000  bestvalidloss -1895.65402  last_update 0\n",
      "train: iter 200  trainloss -2079.34979  validloss -1882.22983±0.00000  bestvalidloss -1895.65402  last_update 1\n",
      "train: iter 201  trainloss -1996.04481  validloss -1840.69365±0.00000  bestvalidloss -1895.65402  last_update 2\n",
      "train: iter 202  trainloss -2066.95267  validloss -1856.72189±0.00000  bestvalidloss -1895.65402  last_update 3\n",
      "train: iter 203  trainloss -2037.14687  validloss -1798.32744±0.00000  bestvalidloss -1895.65402  last_update 4\n",
      "train: iter 204  trainloss -2086.98577  validloss -1797.00009±0.00000  bestvalidloss -1895.65402  last_update 5\n",
      "train: iter 205  trainloss -2056.80884  validloss -1871.64331±0.00000  bestvalidloss -1895.65402  last_update 6\n",
      "train: iter 206  trainloss -2036.82146  validloss -1866.53350±0.00000  bestvalidloss -1895.65402  last_update 7\n",
      "train: iter 207  trainloss -2101.96885  validloss -1902.86102±0.00000  bestvalidloss -1902.86102  last_update 0\n",
      "train: iter 208  trainloss -2109.02503  validloss -1905.24672±0.00000  bestvalidloss -1905.24672  last_update 0\n",
      "train: iter 209  trainloss -2090.18346  validloss -1893.79025±0.00000  bestvalidloss -1905.24672  last_update 1\n",
      "train: iter 210  trainloss -2103.06495  validloss -1878.73197±0.00000  bestvalidloss -1905.24672  last_update 2\n",
      "train: iter 211  trainloss -2063.02136  validloss -1793.56869±0.00000  bestvalidloss -1905.24672  last_update 3\n",
      "train: iter 212  trainloss -2029.48887  validloss -1866.99719±0.00000  bestvalidloss -1905.24672  last_update 4\n",
      "train: iter 213  trainloss -1964.24445  validloss -1715.05718±0.00000  bestvalidloss -1905.24672  last_update 5\n",
      "train: iter 214  trainloss -2091.74810  validloss -1831.34294±0.00000  bestvalidloss -1905.24672  last_update 6\n",
      "train: iter 215  trainloss -2070.74682  validloss -1881.97007±0.00000  bestvalidloss -1905.24672  last_update 7\n",
      "train: iter 216  trainloss -2079.20871  validloss -1868.35126±0.00000  bestvalidloss -1905.24672  last_update 8\n",
      "train: iter 217  trainloss -2059.70952  validloss -1855.73274±0.00000  bestvalidloss -1905.24672  last_update 9\n",
      "train: iter 218  trainloss -2050.86739  validloss -1901.34543±0.00000  bestvalidloss -1905.24672  last_update 10\n",
      "train: iter 219  trainloss -2104.68159  validloss -1911.04514±0.00000  bestvalidloss -1911.04514  last_update 0\n",
      "train: iter 220  trainloss -2091.36386  validloss -1873.61508±0.00000  bestvalidloss -1911.04514  last_update 1\n",
      "train: iter 221  trainloss -2107.39493  validloss -1898.90043±0.00000  bestvalidloss -1911.04514  last_update 2\n",
      "train: iter 222  trainloss -2084.56282  validloss -1895.29543±0.00000  bestvalidloss -1911.04514  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -2035.21821  validloss -1828.45809±0.00000  bestvalidloss -1911.04514  last_update 4\n",
      "train: iter 224  trainloss -2051.18151  validloss -1901.72846±0.00000  bestvalidloss -1911.04514  last_update 5\n",
      "train: iter 225  trainloss -2083.72003  validloss -1896.08340±0.00000  bestvalidloss -1911.04514  last_update 6\n",
      "train: iter 226  trainloss -2060.05293  validloss -1909.64953±0.00000  bestvalidloss -1911.04514  last_update 7\n",
      "train: iter 227  trainloss -2100.11682  validloss -1904.59500±0.00000  bestvalidloss -1911.04514  last_update 8\n",
      "train: iter 228  trainloss -2070.84227  validloss -1883.39010±0.00000  bestvalidloss -1911.04514  last_update 9\n",
      "train: iter 229  trainloss -2112.90304  validloss -1932.91520±0.00000  bestvalidloss -1932.91520  last_update 0\n",
      "train: iter 230  trainloss -2104.41836  validloss -1926.68049±0.00000  bestvalidloss -1932.91520  last_update 1\n",
      "train: iter 231  trainloss -2097.39879  validloss -1883.35758±0.00000  bestvalidloss -1932.91520  last_update 2\n",
      "train: iter 232  trainloss -1921.79017  validloss -1917.71242±0.00000  bestvalidloss -1932.91520  last_update 3\n",
      "train: iter 233  trainloss -2044.23053  validloss -1495.28249±0.00000  bestvalidloss -1932.91520  last_update 4\n",
      "train: iter 234  trainloss -2076.13031  validloss -1855.99007±0.00000  bestvalidloss -1932.91520  last_update 5\n",
      "train: iter 235  trainloss -2096.13414  validloss -1912.88171±0.00000  bestvalidloss -1932.91520  last_update 6\n",
      "train: iter 236  trainloss -2111.38971  validloss -1896.30664±0.00000  bestvalidloss -1932.91520  last_update 7\n",
      "train: iter 237  trainloss -2112.69547  validloss -1968.01940±0.00000  bestvalidloss -1968.01940  last_update 0\n",
      "train: iter 238  trainloss -2085.98880  validloss -1927.41526±0.00000  bestvalidloss -1968.01940  last_update 1\n",
      "train: iter 239  trainloss -2058.04861  validloss -1940.82197±0.00000  bestvalidloss -1968.01940  last_update 2\n",
      "train: iter 240  trainloss -2112.48076  validloss -1928.24191±0.00000  bestvalidloss -1968.01940  last_update 3\n",
      "train: iter 241  trainloss -2108.04984  validloss -1944.94555±0.00000  bestvalidloss -1968.01940  last_update 4\n",
      "train: iter 242  trainloss -2093.01623  validloss -1938.12524±0.00000  bestvalidloss -1968.01940  last_update 5\n",
      "train: iter 243  trainloss -2111.72136  validloss -1974.27107±0.00000  bestvalidloss -1974.27107  last_update 0\n",
      "train: iter 244  trainloss -2056.12117  validloss -1949.92196±0.00000  bestvalidloss -1974.27107  last_update 1\n",
      "train: iter 245  trainloss -2113.36500  validloss -1937.34498±0.00000  bestvalidloss -1974.27107  last_update 2\n",
      "train: iter 246  trainloss -2114.50719  validloss -1959.34995±0.00000  bestvalidloss -1974.27107  last_update 3\n",
      "train: iter 247  trainloss -2064.89091  validloss -1952.34807±0.00000  bestvalidloss -1974.27107  last_update 4\n",
      "train: iter 248  trainloss -2080.27865  validloss -1944.32643±0.00000  bestvalidloss -1974.27107  last_update 5\n",
      "train: iter 249  trainloss -2102.22946  validloss -1962.21131±0.00000  bestvalidloss -1974.27107  last_update 6\n",
      "train: iter 250  trainloss -2107.66721  validloss -1884.22801±0.00000  bestvalidloss -1974.27107  last_update 7\n",
      "train: iter 251  trainloss -2027.91083  validloss -1884.26816±0.00000  bestvalidloss -1974.27107  last_update 8\n",
      "train: iter 252  trainloss -2053.74610  validloss -1883.49092±0.00000  bestvalidloss -1974.27107  last_update 9\n",
      "train: iter 253  trainloss -2100.08266  validloss -1943.28139±0.00000  bestvalidloss -1974.27107  last_update 10\n",
      "train: iter 254  trainloss -2097.59442  validloss -1804.63048±0.00000  bestvalidloss -1974.27107  last_update 11\n",
      "train: iter 255  trainloss -2001.47724  validloss -1918.02820±0.00000  bestvalidloss -1974.27107  last_update 12\n",
      "train: iter 256  trainloss -2090.27508  validloss -1916.94992±0.00000  bestvalidloss -1974.27107  last_update 13\n",
      "train: iter 257  trainloss -2107.77817  validloss -1941.49404±0.00000  bestvalidloss -1974.27107  last_update 14\n",
      "train: iter 258  trainloss -2115.25578  validloss -1928.58232±0.00000  bestvalidloss -1974.27107  last_update 15\n",
      "train: iter 259  trainloss -2118.33804  validloss -1938.57029±0.00000  bestvalidloss -1974.27107  last_update 16\n",
      "train: iter 260  trainloss -2121.62031  validloss -2014.19979±0.00000  bestvalidloss -2014.19979  last_update 0\n",
      "train: iter 261  trainloss -2118.59096  validloss -1948.80999±0.00000  bestvalidloss -2014.19979  last_update 1\n",
      "train: iter 262  trainloss -2115.41457  validloss -1960.74746±0.00000  bestvalidloss -2014.19979  last_update 2\n",
      "train: iter 263  trainloss -2064.03757  validloss -1955.78920±0.00000  bestvalidloss -2014.19979  last_update 3\n",
      "train: iter 264  trainloss -2102.35217  validloss -1963.34118±0.00000  bestvalidloss -2014.19979  last_update 4\n",
      "train: iter 265  trainloss -2030.84326  validloss -1943.29559±0.00000  bestvalidloss -2014.19979  last_update 5\n",
      "train: iter 266  trainloss -2020.60841  validloss -1837.67393±0.00000  bestvalidloss -2014.19979  last_update 6\n",
      "train: iter 267  trainloss -2078.96219  validloss -1912.16721±0.00000  bestvalidloss -2014.19979  last_update 7\n",
      "train: iter 268  trainloss -2082.53328  validloss -1945.71597±0.00000  bestvalidloss -2014.19979  last_update 8\n",
      "train: iter 269  trainloss -2119.73255  validloss -1961.16130±0.00000  bestvalidloss -2014.19979  last_update 9\n",
      "train: iter 270  trainloss -2115.28012  validloss -1948.05319±0.00000  bestvalidloss -2014.19979  last_update 10\n",
      "train: iter 271  trainloss -2117.64245  validloss -1843.83206±0.00000  bestvalidloss -2014.19979  last_update 11\n",
      "train: iter 272  trainloss -2135.24723  validloss -1975.18261±0.00000  bestvalidloss -2014.19979  last_update 12\n",
      "train: iter 273  trainloss -2098.05093  validloss -1961.88760±0.00000  bestvalidloss -2014.19979  last_update 13\n",
      "train: iter 274  trainloss -2099.88766  validloss -1926.29616±0.00000  bestvalidloss -2014.19979  last_update 14\n",
      "train: iter 275  trainloss -2115.93058  validloss -1955.60197±0.00000  bestvalidloss -2014.19979  last_update 15\n",
      "train: iter 276  trainloss -2090.94231  validloss -1986.80983±0.00000  bestvalidloss -2014.19979  last_update 16\n",
      "train: iter 277  trainloss -1856.26582  validloss -1853.54957±0.00000  bestvalidloss -2014.19979  last_update 17\n",
      "train: iter 278  trainloss -2074.62043  validloss -1703.92597±0.00000  bestvalidloss -2014.19979  last_update 18\n",
      "train: iter 279  trainloss -2112.60294  validloss -1980.29724±0.00000  bestvalidloss -2014.19979  last_update 19\n",
      "train: iter 280  trainloss -2103.21479  validloss -1976.14175±0.00000  bestvalidloss -2014.19979  last_update 20\n",
      "train: iter 281  trainloss -2114.09266  validloss -1974.07645±0.00000  bestvalidloss -2014.19979  last_update 21\n",
      "train: iter 282  trainloss -2122.65323  validloss -1991.02143±0.00000  bestvalidloss -2014.19979  last_update 22\n",
      "train: iter 283  trainloss -2117.69282  validloss -1971.55868±0.00000  bestvalidloss -2014.19979  last_update 23\n",
      "train: iter 284  trainloss -2088.65689  validloss -1972.94220±0.00000  bestvalidloss -2014.19979  last_update 24\n",
      "train: iter 285  trainloss -1914.35525  validloss -1871.71300±0.00000  bestvalidloss -2014.19979  last_update 25\n",
      "train: iter 286  trainloss -2083.92311  validloss -1899.73752±0.00000  bestvalidloss -2014.19979  last_update 26\n",
      "train: iter 287  trainloss -2126.51304  validloss -1992.01851±0.00000  bestvalidloss -2014.19979  last_update 27\n",
      "train: iter 288  trainloss -2102.33320  validloss -1953.93879±0.00000  bestvalidloss -2014.19979  last_update 28\n",
      "train: iter 289  trainloss -2087.91202  validloss -1999.37599±0.00000  bestvalidloss -2014.19979  last_update 29\n",
      "train: iter 290  trainloss -2098.11082  validloss -1971.17212±0.00000  bestvalidloss -2014.19979  last_update 30\n",
      "train: iter 291  trainloss -2127.27498  validloss -2014.57453±0.00000  bestvalidloss -2014.57453  last_update 0\n",
      "train: iter 292  trainloss -2121.44706  validloss -1987.61233±0.00000  bestvalidloss -2014.57453  last_update 1\n",
      "train: iter 293  trainloss -2039.89547  validloss -1986.89235±0.00000  bestvalidloss -2014.57453  last_update 2\n",
      "train: iter 294  trainloss -2063.61872  validloss -1890.41854±0.00000  bestvalidloss -2014.57453  last_update 3\n",
      "train: iter 295  trainloss -2104.81292  validloss -1978.79067±0.00000  bestvalidloss -2014.57453  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -2115.92213  validloss -1947.19691±0.00000  bestvalidloss -2014.57453  last_update 5\n",
      "train: iter 297  trainloss -2130.04712  validloss -1956.45712±0.00000  bestvalidloss -2014.57453  last_update 6\n",
      "train: iter 298  trainloss -2098.16747  validloss -1939.33249±0.00000  bestvalidloss -2014.57453  last_update 7\n",
      "train: iter 299  trainloss -2129.47803  validloss -1951.36026±0.00000  bestvalidloss -2014.57453  last_update 8\n",
      "train: iter 300  trainloss -2125.87693  validloss -1975.19657±0.00000  bestvalidloss -2014.57453  last_update 9\n",
      "train: iter 301  trainloss -2114.00912  validloss -2001.07090±0.00000  bestvalidloss -2014.57453  last_update 10\n",
      "train: iter 302  trainloss -2089.63558  validloss -1981.90925±0.00000  bestvalidloss -2014.57453  last_update 11\n",
      "train: iter 303  trainloss -2015.63007  validloss -1805.28245±0.00000  bestvalidloss -2014.57453  last_update 12\n",
      "train: iter 304  trainloss -2133.44464  validloss -1974.60100±0.00000  bestvalidloss -2014.57453  last_update 13\n",
      "train: iter 305  trainloss -2119.48437  validloss -1998.41004±0.00000  bestvalidloss -2014.57453  last_update 14\n",
      "train: iter 306  trainloss -2048.17033  validloss -1945.40829±0.00000  bestvalidloss -2014.57453  last_update 15\n",
      "train: iter 307  trainloss -2113.52803  validloss -1867.79417±0.00000  bestvalidloss -2014.57453  last_update 16\n",
      "train: iter 308  trainloss -2147.18587  validloss -2006.95983±0.00000  bestvalidloss -2014.57453  last_update 17\n",
      "train: iter 309  trainloss -2093.03070  validloss -1992.09326±0.00000  bestvalidloss -2014.57453  last_update 18\n",
      "train: iter 310  trainloss -2124.79706  validloss -2018.22678±0.00000  bestvalidloss -2018.22678  last_update 0\n",
      "train: iter 311  trainloss -2076.15255  validloss -1976.94011±0.00000  bestvalidloss -2018.22678  last_update 1\n",
      "train: iter 312  trainloss -2145.05195  validloss -1966.57969±0.00000  bestvalidloss -2018.22678  last_update 2\n",
      "train: iter 313  trainloss -2098.92959  validloss -1984.60944±0.00000  bestvalidloss -2018.22678  last_update 3\n",
      "train: iter 314  trainloss -2118.73361  validloss -1922.44889±0.00000  bestvalidloss -2018.22678  last_update 4\n",
      "train: iter 315  trainloss -2124.55086  validloss -1994.17023±0.00000  bestvalidloss -2018.22678  last_update 5\n",
      "train: iter 316  trainloss -2135.42728  validloss -1987.50915±0.00000  bestvalidloss -2018.22678  last_update 6\n",
      "train: iter 317  trainloss -2080.50755  validloss -1918.00846±0.00000  bestvalidloss -2018.22678  last_update 7\n",
      "train: iter 318  trainloss -1858.52195  validloss -1902.75392±0.00000  bestvalidloss -2018.22678  last_update 8\n",
      "train: iter 319  trainloss -2059.20252  validloss -1707.56877±0.00000  bestvalidloss -2018.22678  last_update 9\n",
      "train: iter 320  trainloss -2112.82643  validloss -1936.33229±0.00000  bestvalidloss -2018.22678  last_update 10\n",
      "train: iter 321  trainloss -2118.33831  validloss -1975.00274±0.00000  bestvalidloss -2018.22678  last_update 11\n",
      "train: iter 322  trainloss -2144.77946  validloss -1966.40533±0.00000  bestvalidloss -2018.22678  last_update 12\n",
      "train: iter 323  trainloss -2143.48185  validloss -1972.85532±0.00000  bestvalidloss -2018.22678  last_update 13\n",
      "train: iter 324  trainloss -2115.12387  validloss -1918.57440±0.00000  bestvalidloss -2018.22678  last_update 14\n",
      "train: iter 325  trainloss -2135.61487  validloss -1973.12215±0.00000  bestvalidloss -2018.22678  last_update 15\n",
      "train: iter 326  trainloss -2100.69123  validloss -1980.11535±0.00000  bestvalidloss -2018.22678  last_update 16\n",
      "train: iter 327  trainloss -2119.61974  validloss -2013.44263±0.00000  bestvalidloss -2018.22678  last_update 17\n",
      "train: iter 328  trainloss -2123.11486  validloss -1992.05642±0.00000  bestvalidloss -2018.22678  last_update 18\n",
      "train: iter 329  trainloss -2151.94268  validloss -1976.16987±0.00000  bestvalidloss -2018.22678  last_update 19\n",
      "train: iter 330  trainloss -2093.23032  validloss -1920.99357±0.00000  bestvalidloss -2018.22678  last_update 20\n",
      "train: iter 331  trainloss -2133.76970  validloss -1980.69525±0.00000  bestvalidloss -2018.22678  last_update 21\n",
      "train: iter 332  trainloss -2148.30580  validloss -1989.47949±0.00000  bestvalidloss -2018.22678  last_update 22\n",
      "train: iter 333  trainloss -2122.92409  validloss -1981.69867±0.00000  bestvalidloss -2018.22678  last_update 23\n",
      "train: iter 334  trainloss -2098.46912  validloss -1954.64483±0.00000  bestvalidloss -2018.22678  last_update 24\n",
      "train: iter 335  trainloss -2051.07214  validloss -1901.74027±0.00000  bestvalidloss -2018.22678  last_update 25\n",
      "train: iter 336  trainloss -2119.72137  validloss -2014.88986±0.00000  bestvalidloss -2018.22678  last_update 26\n",
      "train: iter 337  trainloss -2140.06242  validloss -1980.26213±0.00000  bestvalidloss -2018.22678  last_update 27\n",
      "train: iter 338  trainloss -2028.62214  validloss -1948.45026±0.00000  bestvalidloss -2018.22678  last_update 28\n",
      "train: iter 339  trainloss -2075.42908  validloss -1735.22231±0.00000  bestvalidloss -2018.22678  last_update 29\n",
      "train: iter 340  trainloss -2137.92899  validloss -1996.58481±0.00000  bestvalidloss -2018.22678  last_update 30\n",
      "train: iter 341  trainloss -2129.74558  validloss -1948.91609±0.00000  bestvalidloss -2018.22678  last_update 31\n",
      "train: iter 342  trainloss -2141.01170  validloss -2007.37688±0.00000  bestvalidloss -2018.22678  last_update 32\n",
      "train: iter 343  trainloss -2131.07230  validloss -1932.14900±0.00000  bestvalidloss -2018.22678  last_update 33\n",
      "train: iter 344  trainloss -2106.05894  validloss -1883.15096±0.00000  bestvalidloss -2018.22678  last_update 34\n",
      "train: iter 345  trainloss -2151.33593  validloss -1949.39807±0.00000  bestvalidloss -2018.22678  last_update 35\n",
      "train: iter 346  trainloss -2128.86805  validloss -2036.14546±0.00000  bestvalidloss -2036.14546  last_update 0\n",
      "train: iter 347  trainloss -2066.16252  validloss -2009.20535±0.00000  bestvalidloss -2036.14546  last_update 1\n",
      "train: iter 348  trainloss -2099.85409  validloss -1916.48180±0.00000  bestvalidloss -2036.14546  last_update 2\n",
      "train: iter 349  trainloss -2126.99072  validloss -1828.21794±0.00000  bestvalidloss -2036.14546  last_update 3\n",
      "train: iter 350  trainloss -2136.51022  validloss -1975.16708±0.00000  bestvalidloss -2036.14546  last_update 4\n",
      "train: iter 351  trainloss -2106.73080  validloss -1967.17188±0.00000  bestvalidloss -2036.14546  last_update 5\n",
      "train: iter 352  trainloss -2075.57101  validloss -1941.94212±0.00000  bestvalidloss -2036.14546  last_update 6\n",
      "train: iter 353  trainloss -2128.86626  validloss -1899.21333±0.00000  bestvalidloss -2036.14546  last_update 7\n",
      "train: iter 354  trainloss -2109.24622  validloss -1908.74928±0.00000  bestvalidloss -2036.14546  last_update 8\n",
      "train: iter 355  trainloss -2142.39926  validloss -1974.49017±0.00000  bestvalidloss -2036.14546  last_update 9\n",
      "train: iter 356  trainloss -2128.95740  validloss -2013.50735±0.00000  bestvalidloss -2036.14546  last_update 10\n",
      "train: iter 357  trainloss -2087.86819  validloss -1874.58948±0.00000  bestvalidloss -2036.14546  last_update 11\n",
      "train: iter 358  trainloss -2146.64562  validloss -2019.75454±0.00000  bestvalidloss -2036.14546  last_update 12\n",
      "train: iter 359  trainloss -2163.03893  validloss -1944.02068±0.00000  bestvalidloss -2036.14546  last_update 13\n",
      "train: iter 360  trainloss -2144.91775  validloss -1949.58130±0.00000  bestvalidloss -2036.14546  last_update 14\n",
      "train: iter 361  trainloss -2146.73982  validloss -1998.53649±0.00000  bestvalidloss -2036.14546  last_update 15\n",
      "train: iter 362  trainloss -2100.92859  validloss -1965.05719±0.00000  bestvalidloss -2036.14546  last_update 16\n",
      "train: iter 363  trainloss -2112.35792  validloss -1941.62002±0.00000  bestvalidloss -2036.14546  last_update 17\n",
      "train: iter 364  trainloss -2155.85944  validloss -1978.76081±0.00000  bestvalidloss -2036.14546  last_update 18\n",
      "train: iter 365  trainloss -2148.92893  validloss -1937.80488±0.00000  bestvalidloss -2036.14546  last_update 19\n",
      "train: iter 366  trainloss -2160.60334  validloss -1992.81690±0.00000  bestvalidloss -2036.14546  last_update 20\n",
      "train: iter 367  trainloss -2148.44628  validloss -1977.77050±0.00000  bestvalidloss -2036.14546  last_update 21\n",
      "train: iter 368  trainloss -2142.66966  validloss -2013.91481±0.00000  bestvalidloss -2036.14546  last_update 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -2155.51678  validloss -2004.44093±0.00000  bestvalidloss -2036.14546  last_update 23\n",
      "train: iter 370  trainloss -2141.49378  validloss -1986.27991±0.00000  bestvalidloss -2036.14546  last_update 24\n",
      "train: iter 371  trainloss -2116.66404  validloss -1965.66340±0.00000  bestvalidloss -2036.14546  last_update 25\n",
      "train: iter 372  trainloss -1912.09387  validloss -1885.17658±0.00000  bestvalidloss -2036.14546  last_update 26\n",
      "train: iter 373  trainloss -2119.32507  validloss -1639.77020±0.00000  bestvalidloss -2036.14546  last_update 27\n",
      "train: iter 374  trainloss -2155.45346  validloss -1918.37826±0.00000  bestvalidloss -2036.14546  last_update 28\n",
      "train: iter 375  trainloss -2163.98235  validloss -2029.28490±0.00000  bestvalidloss -2036.14546  last_update 29\n",
      "train: iter 376  trainloss -2137.30007  validloss -1947.24906±0.00000  bestvalidloss -2036.14546  last_update 30\n",
      "train: iter 377  trainloss -2163.19908  validloss -2051.36594±0.00000  bestvalidloss -2051.36594  last_update 0\n",
      "train: iter 378  trainloss -2155.32268  validloss -2002.57504±0.00000  bestvalidloss -2051.36594  last_update 1\n",
      "train: iter 379  trainloss -2105.28335  validloss -1969.95384±0.00000  bestvalidloss -2051.36594  last_update 2\n",
      "train: iter 380  trainloss -2159.03032  validloss -2036.81969±0.00000  bestvalidloss -2051.36594  last_update 3\n",
      "train: iter 381  trainloss -2013.75781  validloss -1882.44021±0.00000  bestvalidloss -2051.36594  last_update 4\n",
      "train: iter 382  trainloss -2130.48332  validloss -1969.56718±0.00000  bestvalidloss -2051.36594  last_update 5\n",
      "train: iter 383  trainloss -2100.77213  validloss -2025.27455±0.00000  bestvalidloss -2051.36594  last_update 6\n",
      "train: iter 384  trainloss -2141.38315  validloss -1960.41721±0.00000  bestvalidloss -2051.36594  last_update 7\n",
      "train: iter 385  trainloss -2159.72458  validloss -1992.90617±0.00000  bestvalidloss -2051.36594  last_update 8\n",
      "train: iter 386  trainloss -2170.67627  validloss -1967.84554±0.00000  bestvalidloss -2051.36594  last_update 9\n",
      "train: iter 387  trainloss -2138.92511  validloss -2001.73221±0.00000  bestvalidloss -2051.36594  last_update 10\n",
      "train: iter 388  trainloss -2135.87005  validloss -1944.09553±0.00000  bestvalidloss -2051.36594  last_update 11\n",
      "train: iter 389  trainloss -2112.25566  validloss -1801.54171±0.00000  bestvalidloss -2051.36594  last_update 12\n",
      "train: iter 390  trainloss -2133.65507  validloss -1951.45537±0.00000  bestvalidloss -2051.36594  last_update 13\n",
      "train: iter 391  trainloss -2163.16133  validloss -1910.43661±0.00000  bestvalidloss -2051.36594  last_update 14\n",
      "train: iter 392  trainloss -2116.83288  validloss -1977.65585±0.00000  bestvalidloss -2051.36594  last_update 15\n",
      "train: iter 393  trainloss -2168.57226  validloss -1975.63008±0.00000  bestvalidloss -2051.36594  last_update 16\n",
      "train: iter 394  trainloss -2170.53140  validloss -1949.88588±0.00000  bestvalidloss -2051.36594  last_update 17\n",
      "train: iter 395  trainloss -2159.30432  validloss -1950.71661±0.00000  bestvalidloss -2051.36594  last_update 18\n",
      "train: iter 396  trainloss -2150.18741  validloss -2009.25699±0.00000  bestvalidloss -2051.36594  last_update 19\n",
      "train: iter 397  trainloss -2049.95990  validloss -1963.67677±0.00000  bestvalidloss -2051.36594  last_update 20\n",
      "train: iter 398  trainloss -2073.46949  validloss -1778.01573±0.00000  bestvalidloss -2051.36594  last_update 21\n",
      "train: iter 399  trainloss -2125.05439  validloss -1917.11482±0.00000  bestvalidloss -2051.36594  last_update 22\n",
      "train: iter 400  trainloss -2170.01046  validloss -2037.24441±0.00000  bestvalidloss -2051.36594  last_update 23\n",
      "train: iter 401  trainloss -2160.75754  validloss -2033.09964±0.00000  bestvalidloss -2051.36594  last_update 24\n",
      "train: iter 402  trainloss -2155.96016  validloss -2004.33928±0.00000  bestvalidloss -2051.36594  last_update 25\n",
      "train: iter 403  trainloss -2113.16895  validloss -1908.25764±0.00000  bestvalidloss -2051.36594  last_update 26\n",
      "train: iter 404  trainloss -2115.39203  validloss -1975.09688±0.00000  bestvalidloss -2051.36594  last_update 27\n",
      "train: iter 405  trainloss -2156.71961  validloss -1941.38492±0.00000  bestvalidloss -2051.36594  last_update 28\n",
      "train: iter 406  trainloss -2147.68537  validloss -2015.16337±0.00000  bestvalidloss -2051.36594  last_update 29\n",
      "train: iter 407  trainloss -2156.56893  validloss -2004.80358±0.00000  bestvalidloss -2051.36594  last_update 30\n",
      "train: iter 408  trainloss -2132.40770  validloss -1994.85808±0.00000  bestvalidloss -2051.36594  last_update 31\n",
      "train: iter 409  trainloss -2151.68881  validloss -1994.94107±0.00000  bestvalidloss -2051.36594  last_update 32\n",
      "train: iter 410  trainloss -2153.05196  validloss -1999.29405±0.00000  bestvalidloss -2051.36594  last_update 33\n",
      "train: iter 411  trainloss -2113.11559  validloss -1812.38828±0.00000  bestvalidloss -2051.36594  last_update 34\n",
      "train: iter 412  trainloss -2086.29347  validloss -1934.91376±0.00000  bestvalidloss -2051.36594  last_update 35\n",
      "train: iter 413  trainloss -2165.43465  validloss -1863.54059±0.00000  bestvalidloss -2051.36594  last_update 36\n",
      "train: iter 414  trainloss -2179.92613  validloss -1931.82463±0.00000  bestvalidloss -2051.36594  last_update 37\n",
      "train: iter 415  trainloss -2157.16677  validloss -2035.64911±0.00000  bestvalidloss -2051.36594  last_update 38\n",
      "train: iter 416  trainloss -2183.29377  validloss -1965.97574±0.00000  bestvalidloss -2051.36594  last_update 39\n",
      "train: iter 417  trainloss -2172.00369  validloss -2033.10920±0.00000  bestvalidloss -2051.36594  last_update 40\n",
      "train: iter 418  trainloss -2174.55348  validloss -2031.67775±0.00000  bestvalidloss -2051.36594  last_update 41\n",
      "train: iter 419  trainloss -2172.42675  validloss -1933.63934±0.00000  bestvalidloss -2051.36594  last_update 42\n",
      "train: iter 420  trainloss -2160.89191  validloss -1996.62831±0.00000  bestvalidloss -2051.36594  last_update 43\n",
      "train: iter 421  trainloss -2156.47683  validloss -1888.19856±0.00000  bestvalidloss -2051.36594  last_update 44\n",
      "train: iter 422  trainloss -2165.05369  validloss -1927.91304±0.00000  bestvalidloss -2051.36594  last_update 45\n",
      "train: iter 423  trainloss -1863.69108  validloss -1940.64465±0.00000  bestvalidloss -2051.36594  last_update 46\n",
      "train: iter 424  trainloss -2090.46541  validloss -1560.16367±0.00000  bestvalidloss -2051.36594  last_update 47\n",
      "train: iter 425  trainloss -2151.27596  validloss -1834.20136±0.00000  bestvalidloss -2051.36594  last_update 48\n",
      "train: iter 426  trainloss -2138.19927  validloss -2004.21662±0.00000  bestvalidloss -2051.36594  last_update 49\n",
      "train: iter 427  trainloss -2125.09270  validloss -1982.50082±0.00000  bestvalidloss -2051.36594  last_update 50\n",
      "train: iter 428  trainloss -2138.65432  validloss -2016.63961±0.00000  bestvalidloss -2051.36594  last_update 51\n",
      "train: iter 429  trainloss -2175.52921  validloss -1970.70269±0.00000  bestvalidloss -2051.36594  last_update 52\n",
      "train: iter 430  trainloss -2177.70793  validloss -2010.84314±0.00000  bestvalidloss -2051.36594  last_update 53\n",
      "train: iter 431  trainloss -2130.26312  validloss -2020.50222±0.00000  bestvalidloss -2051.36594  last_update 54\n",
      "train: iter 432  trainloss -2179.57293  validloss -1923.73676±0.00000  bestvalidloss -2051.36594  last_update 55\n",
      "train: iter 433  trainloss -2158.77780  validloss -1932.29686±0.00000  bestvalidloss -2051.36594  last_update 56\n",
      "train: iter 434  trainloss -2161.61765  validloss -1898.08179±0.00000  bestvalidloss -2051.36594  last_update 57\n",
      "train: iter 435  trainloss -2155.62504  validloss -1978.26812±0.00000  bestvalidloss -2051.36594  last_update 58\n",
      "train: iter 436  trainloss -2175.75184  validloss -1953.98380±0.00000  bestvalidloss -2051.36594  last_update 59\n",
      "train: iter 437  trainloss -2154.40457  validloss -1942.27324±0.00000  bestvalidloss -2051.36594  last_update 60\n",
      "train: iter 438  trainloss -2133.73962  validloss -1959.36317±0.00000  bestvalidloss -2051.36594  last_update 61\n",
      "train: iter 439  trainloss -2103.13425  validloss -2004.65460±0.00000  bestvalidloss -2051.36594  last_update 62\n",
      "train: iter 440  trainloss -2134.66866  validloss -1818.15258±0.00000  bestvalidloss -2051.36594  last_update 63\n",
      "train: iter 441  trainloss -2163.08373  validloss -2008.83427±0.00000  bestvalidloss -2051.36594  last_update 64\n",
      "train: iter 442  trainloss -2151.28740  validloss -1982.69988±0.00000  bestvalidloss -2051.36594  last_update 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 443  trainloss -2180.86238  validloss -1996.51722±0.00000  bestvalidloss -2051.36594  last_update 66\n",
      "train: iter 444  trainloss -2175.94392  validloss -2028.21055±0.00000  bestvalidloss -2051.36594  last_update 67\n",
      "train: iter 445  trainloss -2163.68813  validloss -2019.05971±0.00000  bestvalidloss -2051.36594  last_update 68\n",
      "train: iter 446  trainloss -1957.64098  validloss -1946.71345±0.00000  bestvalidloss -2051.36594  last_update 69\n",
      "train: iter 447  trainloss -2067.72643  validloss -1797.11905±0.00000  bestvalidloss -2051.36594  last_update 70\n",
      "train: iter 448  trainloss -2171.41312  validloss -1790.63798±0.00000  bestvalidloss -2051.36594  last_update 71\n",
      "train: iter 449  trainloss -2183.66268  validloss -1954.59293±0.00000  bestvalidloss -2051.36594  last_update 72\n",
      "train: iter 450  trainloss -2176.48023  validloss -1993.36783±0.00000  bestvalidloss -2051.36594  last_update 73\n",
      "train: iter 451  trainloss -2169.78399  validloss -1978.86207±0.00000  bestvalidloss -2051.36594  last_update 74\n",
      "train: iter 452  trainloss -2168.65272  validloss -1902.20840±0.00000  bestvalidloss -2051.36594  last_update 75\n",
      "train: iter 453  trainloss -2145.18957  validloss -1944.37760±0.00000  bestvalidloss -2051.36594  last_update 76\n",
      "train: iter 454  trainloss -2173.33672  validloss -1949.08882±0.00000  bestvalidloss -2051.36594  last_update 77\n",
      "train: iter 455  trainloss -2171.56456  validloss -1959.46541±0.00000  bestvalidloss -2051.36594  last_update 78\n",
      "train: iter 456  trainloss -2179.36377  validloss -2047.46819±0.00000  bestvalidloss -2051.36594  last_update 79\n",
      "train: iter 457  trainloss -2154.89202  validloss -1915.90809±0.00000  bestvalidloss -2051.36594  last_update 80\n",
      "train: iter 458  trainloss -2166.10527  validloss -2016.72836±0.00000  bestvalidloss -2051.36594  last_update 81\n",
      "train: iter 459  trainloss -2083.85724  validloss -1889.41031±0.00000  bestvalidloss -2051.36594  last_update 82\n",
      "train: iter 460  trainloss -2171.98094  validloss -1918.95028±0.00000  bestvalidloss -2051.36594  last_update 83\n",
      "train: iter 461  trainloss -2136.74229  validloss -1949.00612±0.00000  bestvalidloss -2051.36594  last_update 84\n",
      "train: iter 462  trainloss -2172.43943  validloss -1964.65057±0.00000  bestvalidloss -2051.36594  last_update 85\n",
      "train: iter 463  trainloss -2177.58544  validloss -2018.10790±0.00000  bestvalidloss -2051.36594  last_update 86\n",
      "train: iter 464  trainloss -2172.06781  validloss -1998.61931±0.00000  bestvalidloss -2051.36594  last_update 87\n",
      "train: iter 465  trainloss -2176.37439  validloss -2006.48226±0.00000  bestvalidloss -2051.36594  last_update 88\n",
      "train: iter 466  trainloss -2167.21469  validloss -1950.01087±0.00000  bestvalidloss -2051.36594  last_update 89\n",
      "train: iter 467  trainloss -1726.89065  validloss -1990.46667±0.00000  bestvalidloss -2051.36594  last_update 90\n",
      "train: iter 468  trainloss -2170.46033  validloss -1932.88183±0.00000  bestvalidloss -2051.36594  last_update 91\n",
      "train: iter 469  trainloss -2171.61982  validloss -1986.95017±0.00000  bestvalidloss -2051.36594  last_update 92\n",
      "train: iter 470  trainloss -2189.82009  validloss -1999.15298±0.00000  bestvalidloss -2051.36594  last_update 93\n",
      "train: iter 471  trainloss -2187.91362  validloss -2060.40062±0.00000  bestvalidloss -2060.40062  last_update 0\n",
      "train: iter 472  trainloss -2182.39024  validloss -1971.74655±0.00000  bestvalidloss -2060.40062  last_update 1\n",
      "train: iter 473  trainloss -2182.88690  validloss -2024.36509±0.00000  bestvalidloss -2060.40062  last_update 2\n",
      "train: iter 474  trainloss -2186.49197  validloss -2012.39128±0.00000  bestvalidloss -2060.40062  last_update 3\n",
      "train: iter 475  trainloss -2177.37334  validloss -2001.12649±0.00000  bestvalidloss -2060.40062  last_update 4\n",
      "train: iter 476  trainloss -2191.88363  validloss -1922.14673±0.00000  bestvalidloss -2060.40062  last_update 5\n",
      "train: iter 477  trainloss -2187.80101  validloss -1909.02595±0.00000  bestvalidloss -2060.40062  last_update 6\n",
      "train: iter 478  trainloss -2164.91564  validloss -1875.19168±0.00000  bestvalidloss -2060.40062  last_update 7\n",
      "train: iter 479  trainloss -2159.80275  validloss -1913.90482±0.00000  bestvalidloss -2060.40062  last_update 8\n",
      "train: iter 480  trainloss -2163.37990  validloss -2052.10293±0.00000  bestvalidloss -2060.40062  last_update 9\n",
      "train: iter 481  trainloss -2123.20597  validloss -1764.20679±0.00000  bestvalidloss -2060.40062  last_update 10\n",
      "train: iter 482  trainloss -2174.93286  validloss -1986.78198±0.00000  bestvalidloss -2060.40062  last_update 11\n",
      "train: iter 483  trainloss -2181.06134  validloss -1996.59513±0.00000  bestvalidloss -2060.40062  last_update 12\n",
      "train: iter 484  trainloss -2179.28727  validloss -1965.07528±0.00000  bestvalidloss -2060.40062  last_update 13\n",
      "train: iter 485  trainloss -2182.22031  validloss -2030.79903±0.00000  bestvalidloss -2060.40062  last_update 14\n",
      "train: iter 486  trainloss -2109.87185  validloss -2042.29124±0.00000  bestvalidloss -2060.40062  last_update 15\n",
      "train: iter 487  trainloss -2180.47293  validloss -1944.06551±0.00000  bestvalidloss -2060.40062  last_update 16\n",
      "train: iter 488  trainloss -2177.42945  validloss -2037.13960±0.00000  bestvalidloss -2060.40062  last_update 17\n",
      "train: iter 489  trainloss -2160.77968  validloss -1969.10600±0.00000  bestvalidloss -2060.40062  last_update 18\n",
      "train: iter 490  trainloss -2168.06797  validloss -2035.32179±0.00000  bestvalidloss -2060.40062  last_update 19\n",
      "train: iter 491  trainloss -2171.15621  validloss -1941.91334±0.00000  bestvalidloss -2060.40062  last_update 20\n",
      "train: iter 492  trainloss -2078.30337  validloss -1880.76316±0.00000  bestvalidloss -2060.40062  last_update 21\n",
      "train: iter 493  trainloss -2186.34940  validloss -1851.80294±0.00000  bestvalidloss -2060.40062  last_update 22\n",
      "train: iter 494  trainloss -2193.14277  validloss -1919.69699±0.00000  bestvalidloss -2060.40062  last_update 23\n",
      "train: iter 495  trainloss -2147.86961  validloss -1890.08839±0.00000  bestvalidloss -2060.40062  last_update 24\n",
      "train: iter 496  trainloss -2175.42169  validloss -1994.83530±0.00000  bestvalidloss -2060.40062  last_update 25\n",
      "train: iter 497  trainloss -2177.25435  validloss -2039.88044±0.00000  bestvalidloss -2060.40062  last_update 26\n",
      "train: iter 498  trainloss -2175.16881  validloss -1984.12905±0.00000  bestvalidloss -2060.40062  last_update 27\n",
      "train: iter 499  trainloss -2186.86418  validloss -2063.19811±0.00000  bestvalidloss -2063.19811  last_update 0\n",
      "train: iter 500  trainloss -2151.94688  validloss -1926.00268±0.00000  bestvalidloss -2063.19811  last_update 1\n",
      "train: iter 501  trainloss -2178.16787  validloss -2047.07541±0.00000  bestvalidloss -2063.19811  last_update 2\n",
      "train: iter 502  trainloss -2172.38051  validloss -1879.84965±0.00000  bestvalidloss -2063.19811  last_update 3\n",
      "train: iter 503  trainloss -2049.37118  validloss -2022.36871±0.00000  bestvalidloss -2063.19811  last_update 4\n",
      "train: iter 504  trainloss -2112.40843  validloss -1744.43661±0.00000  bestvalidloss -2063.19811  last_update 5\n",
      "train: iter 505  trainloss -2149.04618  validloss -1991.81322±0.00000  bestvalidloss -2063.19811  last_update 6\n",
      "train: iter 506  trainloss -2190.73734  validloss -1979.38337±0.00000  bestvalidloss -2063.19811  last_update 7\n",
      "train: iter 507  trainloss -2170.15776  validloss -2010.88335±0.00000  bestvalidloss -2063.19811  last_update 8\n",
      "train: iter 508  trainloss -2187.26405  validloss -1994.85191±0.00000  bestvalidloss -2063.19811  last_update 9\n",
      "train: iter 509  trainloss -2197.41842  validloss -2011.86575±0.00000  bestvalidloss -2063.19811  last_update 10\n",
      "train: iter 510  trainloss -2191.13535  validloss -2003.65670±0.00000  bestvalidloss -2063.19811  last_update 11\n",
      "train: iter 511  trainloss -2201.50778  validloss -2044.24705±0.00000  bestvalidloss -2063.19811  last_update 12\n",
      "train: iter 512  trainloss -2180.45516  validloss -2004.87253±0.00000  bestvalidloss -2063.19811  last_update 13\n",
      "train: iter 513  trainloss -2125.89611  validloss -1999.71574±0.00000  bestvalidloss -2063.19811  last_update 14\n",
      "train: iter 514  trainloss -2161.70811  validloss -1844.62596±0.00000  bestvalidloss -2063.19811  last_update 15\n",
      "train: iter 515  trainloss -2170.77917  validloss -2016.49000±0.00000  bestvalidloss -2063.19811  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 516  trainloss -2152.90415  validloss -2043.62193±0.00000  bestvalidloss -2063.19811  last_update 17\n",
      "train: iter 517  trainloss -2178.81322  validloss -1912.56594±0.00000  bestvalidloss -2063.19811  last_update 18\n",
      "train: iter 518  trainloss -2178.07965  validloss -2027.09016±0.00000  bestvalidloss -2063.19811  last_update 19\n",
      "train: iter 519  trainloss -2173.44630  validloss -1907.36787±0.00000  bestvalidloss -2063.19811  last_update 20\n",
      "train: iter 520  trainloss -2172.56776  validloss -2024.30572±0.00000  bestvalidloss -2063.19811  last_update 21\n",
      "train: iter 521  trainloss -2178.02410  validloss -2033.57595±0.00000  bestvalidloss -2063.19811  last_update 22\n",
      "train: iter 522  trainloss -2173.48353  validloss -2001.27027±0.00000  bestvalidloss -2063.19811  last_update 23\n",
      "train: iter 523  trainloss -2148.06931  validloss -2066.87756±0.00000  bestvalidloss -2066.87756  last_update 0\n",
      "train: iter 524  trainloss -2163.36427  validloss -2021.31512±0.00000  bestvalidloss -2066.87756  last_update 1\n",
      "train: iter 525  trainloss -2135.40060  validloss -1840.55811±0.00000  bestvalidloss -2066.87756  last_update 2\n",
      "train: iter 526  trainloss -2200.10188  validloss -2005.07245±0.00000  bestvalidloss -2066.87756  last_update 3\n",
      "train: iter 527  trainloss -2181.62962  validloss -2036.71324±0.00000  bestvalidloss -2066.87756  last_update 4\n",
      "train: iter 528  trainloss -2113.27522  validloss -2010.59508±0.00000  bestvalidloss -2066.87756  last_update 5\n",
      "train: iter 529  trainloss -2181.93911  validloss -2039.59501±0.00000  bestvalidloss -2066.87756  last_update 6\n",
      "train: iter 530  trainloss -2155.56315  validloss -2012.04530±0.00000  bestvalidloss -2066.87756  last_update 7\n",
      "train: iter 531  trainloss -2199.60669  validloss -2018.92176±0.00000  bestvalidloss -2066.87756  last_update 8\n",
      "train: iter 532  trainloss -2171.49914  validloss -2050.82019±0.00000  bestvalidloss -2066.87756  last_update 9\n",
      "train: iter 533  trainloss -2190.89858  validloss -2053.44630±0.00000  bestvalidloss -2066.87756  last_update 10\n",
      "train: iter 534  trainloss -2213.37901  validloss -2098.14949±0.00000  bestvalidloss -2098.14949  last_update 0\n",
      "train: iter 535  trainloss -2195.71091  validloss -2052.99514±0.00000  bestvalidloss -2098.14949  last_update 1\n",
      "train: iter 536  trainloss -2193.30402  validloss -2055.76316±0.00000  bestvalidloss -2098.14949  last_update 2\n",
      "train: iter 537  trainloss -2206.18488  validloss -2093.71396±0.00000  bestvalidloss -2098.14949  last_update 3\n",
      "train: iter 538  trainloss -2159.79622  validloss -2057.39790±0.00000  bestvalidloss -2098.14949  last_update 4\n",
      "train: iter 539  trainloss -2052.05559  validloss -2031.32521±0.00000  bestvalidloss -2098.14949  last_update 5\n",
      "train: iter 540  trainloss -2069.00581  validloss -1688.76509±0.00000  bestvalidloss -2098.14949  last_update 6\n",
      "train: iter 541  trainloss -2178.81948  validloss -2029.74065±0.00000  bestvalidloss -2098.14949  last_update 7\n",
      "train: iter 542  trainloss -2192.90941  validloss -2033.43741±0.00000  bestvalidloss -2098.14949  last_update 8\n",
      "train: iter 543  trainloss -2211.06544  validloss -2053.44185±0.00000  bestvalidloss -2098.14949  last_update 9\n",
      "train: iter 544  trainloss -2199.22878  validloss -2034.52568±0.00000  bestvalidloss -2098.14949  last_update 10\n",
      "train: iter 545  trainloss -2180.98557  validloss -2021.79982±0.00000  bestvalidloss -2098.14949  last_update 11\n",
      "train: iter 546  trainloss -2189.57403  validloss -2003.49016±0.00000  bestvalidloss -2098.14949  last_update 12\n",
      "train: iter 547  trainloss -2192.41725  validloss -2066.03419±0.00000  bestvalidloss -2098.14949  last_update 13\n",
      "train: iter 548  trainloss -2200.01229  validloss -1999.28970±0.00000  bestvalidloss -2098.14949  last_update 14\n",
      "train: iter 549  trainloss -2180.45457  validloss -2074.06903±0.00000  bestvalidloss -2098.14949  last_update 15\n",
      "train: iter 550  trainloss -2211.92969  validloss -2048.95409±0.00000  bestvalidloss -2098.14949  last_update 16\n",
      "train: iter 551  trainloss -2209.47344  validloss -2049.65985±0.00000  bestvalidloss -2098.14949  last_update 17\n",
      "train: iter 552  trainloss -2212.80591  validloss -2043.54477±0.00000  bestvalidloss -2098.14949  last_update 18\n",
      "train: iter 553  trainloss -2183.30982  validloss -2023.53323±0.00000  bestvalidloss -2098.14949  last_update 19\n",
      "train: iter 554  trainloss -2019.98149  validloss -2019.45361±0.00000  bestvalidloss -2098.14949  last_update 20\n",
      "train: iter 555  trainloss -2186.31250  validloss -2006.93525±0.00000  bestvalidloss -2098.14949  last_update 21\n",
      "train: iter 556  trainloss -2191.17095  validloss -2019.23303±0.00000  bestvalidloss -2098.14949  last_update 22\n",
      "train: iter 557  trainloss -2203.25861  validloss -2086.83914±0.00000  bestvalidloss -2098.14949  last_update 23\n",
      "train: iter 558  trainloss -2186.27760  validloss -2068.38422±0.00000  bestvalidloss -2098.14949  last_update 24\n",
      "train: iter 559  trainloss -2196.69181  validloss -2091.48593±0.00000  bestvalidloss -2098.14949  last_update 25\n",
      "train: iter 560  trainloss -2211.63869  validloss -2022.30263±0.00000  bestvalidloss -2098.14949  last_update 26\n",
      "train: iter 561  trainloss -2167.89235  validloss -2076.78504±0.00000  bestvalidloss -2098.14949  last_update 27\n",
      "train: iter 562  trainloss -2186.09662  validloss -2050.50557±0.00000  bestvalidloss -2098.14949  last_update 28\n",
      "train: iter 563  trainloss -2182.07518  validloss -1998.18839±0.00000  bestvalidloss -2098.14949  last_update 29\n",
      "train: iter 564  trainloss -2193.24730  validloss -2071.31604±0.00000  bestvalidloss -2098.14949  last_update 30\n",
      "train: iter 565  trainloss -2202.12468  validloss -2044.61874±0.00000  bestvalidloss -2098.14949  last_update 31\n",
      "train: iter 566  trainloss -2140.76727  validloss -2037.17281±0.00000  bestvalidloss -2098.14949  last_update 32\n",
      "train: iter 567  trainloss -2096.15912  validloss -1894.53806±0.00000  bestvalidloss -2098.14949  last_update 33\n",
      "train: iter 568  trainloss -2176.74084  validloss -2011.87457±0.00000  bestvalidloss -2098.14949  last_update 34\n",
      "train: iter 569  trainloss -2190.69349  validloss -2045.27949±0.00000  bestvalidloss -2098.14949  last_update 35\n",
      "train: iter 570  trainloss -2208.00030  validloss -2025.86427±0.00000  bestvalidloss -2098.14949  last_update 36\n",
      "train: iter 571  trainloss -2215.17663  validloss -2091.78328±0.00000  bestvalidloss -2098.14949  last_update 37\n",
      "train: iter 572  trainloss -2186.36524  validloss -2066.22345±0.00000  bestvalidloss -2098.14949  last_update 38\n",
      "train: iter 573  trainloss -2199.86965  validloss -2088.93343±0.00000  bestvalidloss -2098.14949  last_update 39\n",
      "train: iter 574  trainloss -2168.27985  validloss -2041.16238±0.00000  bestvalidloss -2098.14949  last_update 40\n",
      "train: iter 575  trainloss -2180.00182  validloss -2088.88859±0.00000  bestvalidloss -2098.14949  last_update 41\n",
      "train: iter 576  trainloss -2210.69337  validloss -2086.82108±0.00000  bestvalidloss -2098.14949  last_update 42\n",
      "train: iter 577  trainloss -2198.49904  validloss -2028.81859±0.00000  bestvalidloss -2098.14949  last_update 43\n",
      "train: iter 578  trainloss -2192.91962  validloss -2071.93132±0.00000  bestvalidloss -2098.14949  last_update 44\n",
      "train: iter 579  trainloss -2160.71534  validloss -2084.99314±0.00000  bestvalidloss -2098.14949  last_update 45\n",
      "train: iter 580  trainloss -2183.76057  validloss -1981.06474±0.00000  bestvalidloss -2098.14949  last_update 46\n",
      "train: iter 581  trainloss -2205.21479  validloss -2046.35135±0.00000  bestvalidloss -2098.14949  last_update 47\n",
      "train: iter 582  trainloss -2212.79084  validloss -2092.85419±0.00000  bestvalidloss -2098.14949  last_update 48\n",
      "train: iter 583  trainloss -2206.72708  validloss -2083.72599±0.00000  bestvalidloss -2098.14949  last_update 49\n",
      "train: iter 584  trainloss -2181.22184  validloss -2053.02917±0.00000  bestvalidloss -2098.14949  last_update 50\n",
      "train: iter 585  trainloss -2115.29632  validloss -2044.23868±0.00000  bestvalidloss -2098.14949  last_update 51\n",
      "train: iter 586  trainloss -2134.96829  validloss -1941.49203±0.00000  bestvalidloss -2098.14949  last_update 52\n",
      "train: iter 587  trainloss -2198.53898  validloss -1978.14079±0.00000  bestvalidloss -2098.14949  last_update 53\n",
      "train: iter 588  trainloss -2171.42492  validloss -1990.60708±0.00000  bestvalidloss -2098.14949  last_update 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 589  trainloss -2203.30565  validloss -2048.33810±0.00000  bestvalidloss -2098.14949  last_update 55\n",
      "train: iter 590  trainloss -2216.21719  validloss -2075.55082±0.00000  bestvalidloss -2098.14949  last_update 56\n",
      "train: iter 591  trainloss -2215.63645  validloss -2083.47082±0.00000  bestvalidloss -2098.14949  last_update 57\n",
      "train: iter 592  trainloss -2215.29742  validloss -2091.73085±0.00000  bestvalidloss -2098.14949  last_update 58\n",
      "train: iter 593  trainloss -2225.98594  validloss -2065.69551±0.00000  bestvalidloss -2098.14949  last_update 59\n",
      "train: iter 594  trainloss -2203.86369  validloss -2065.82237±0.00000  bestvalidloss -2098.14949  last_update 60\n",
      "train: iter 595  trainloss -2094.81869  validloss -2023.42131±0.00000  bestvalidloss -2098.14949  last_update 61\n",
      "train: iter 596  trainloss -2186.22800  validloss -1944.92875±0.00000  bestvalidloss -2098.14949  last_update 62\n",
      "train: iter 597  trainloss -2190.44896  validloss -2055.15751±0.00000  bestvalidloss -2098.14949  last_update 63\n",
      "train: iter 598  trainloss -2203.24014  validloss -2070.41770±0.00000  bestvalidloss -2098.14949  last_update 64\n",
      "train: iter 599  trainloss -2203.95587  validloss -2043.63708±0.00000  bestvalidloss -2098.14949  last_update 65\n",
      "train: iter 600  trainloss -2205.81263  validloss -2019.94041±0.00000  bestvalidloss -2098.14949  last_update 66\n",
      "train: iter 601  trainloss -2157.77816  validloss -2051.12611±0.00000  bestvalidloss -2098.14949  last_update 67\n",
      "train: iter 602  trainloss -2208.19046  validloss -2055.83322±0.00000  bestvalidloss -2098.14949  last_update 68\n",
      "train: iter 603  trainloss -2197.47839  validloss -2031.98452±0.00000  bestvalidloss -2098.14949  last_update 69\n",
      "train: iter 604  trainloss -2220.82336  validloss -2103.55535±0.00000  bestvalidloss -2103.55535  last_update 0\n",
      "train: iter 605  trainloss -2205.05737  validloss -2097.45090±0.00000  bestvalidloss -2103.55535  last_update 1\n",
      "train: iter 606  trainloss -2165.54886  validloss -2062.62302±0.00000  bestvalidloss -2103.55535  last_update 2\n",
      "train: iter 607  trainloss -2198.58967  validloss -2016.95847±0.00000  bestvalidloss -2103.55535  last_update 3\n",
      "train: iter 608  trainloss -2185.30476  validloss -2048.36218±0.00000  bestvalidloss -2103.55535  last_update 4\n",
      "train: iter 609  trainloss -2201.05093  validloss -2111.10385±0.00000  bestvalidloss -2111.10385  last_update 0\n",
      "train: iter 610  trainloss -2198.35248  validloss -2086.46792±0.00000  bestvalidloss -2111.10385  last_update 1\n",
      "train: iter 611  trainloss -1900.44630  validloss -1915.04745±0.00000  bestvalidloss -2111.10385  last_update 2\n",
      "train: iter 612  trainloss -2205.98524  validloss -2082.61040±0.00000  bestvalidloss -2111.10385  last_update 3\n",
      "train: iter 613  trainloss -2221.28462  validloss -2071.28553±0.00000  bestvalidloss -2111.10385  last_update 4\n",
      "train: iter 614  trainloss -2207.25751  validloss -2074.30375±0.00000  bestvalidloss -2111.10385  last_update 5\n",
      "train: iter 615  trainloss -2220.57790  validloss -2093.22519±0.00000  bestvalidloss -2111.10385  last_update 6\n",
      "train: iter 616  trainloss -2206.67197  validloss -2106.77038±0.00000  bestvalidloss -2111.10385  last_update 7\n",
      "train: iter 617  trainloss -2208.05878  validloss -2075.30395±0.00000  bestvalidloss -2111.10385  last_update 8\n",
      "train: iter 618  trainloss -2220.92160  validloss -2084.42208±0.00000  bestvalidloss -2111.10385  last_update 9\n",
      "train: iter 619  trainloss -2222.82838  validloss -2055.85508±0.00000  bestvalidloss -2111.10385  last_update 10\n",
      "train: iter 620  trainloss -2218.30062  validloss -2089.31146±0.00000  bestvalidloss -2111.10385  last_update 11\n",
      "train: iter 621  trainloss -2173.47851  validloss -2029.05204±0.00000  bestvalidloss -2111.10385  last_update 12\n",
      "train: iter 622  trainloss -2152.58250  validloss -2000.29359±0.00000  bestvalidloss -2111.10385  last_update 13\n",
      "train: iter 623  trainloss -2183.37443  validloss -1994.54957±0.00000  bestvalidloss -2111.10385  last_update 14\n",
      "train: iter 624  trainloss -2207.59210  validloss -2090.41778±0.00000  bestvalidloss -2111.10385  last_update 15\n",
      "train: iter 625  trainloss -2215.30755  validloss -2099.09504±0.00000  bestvalidloss -2111.10385  last_update 16\n",
      "train: iter 626  trainloss -2223.55053  validloss -2085.73154±0.00000  bestvalidloss -2111.10385  last_update 17\n",
      "train: iter 627  trainloss -2209.51563  validloss -2102.44988±0.00000  bestvalidloss -2111.10385  last_update 18\n",
      "train: iter 628  trainloss -2214.78712  validloss -2105.20612±0.00000  bestvalidloss -2111.10385  last_update 19\n",
      "train: iter 629  trainloss -2179.29131  validloss -2059.29794±0.00000  bestvalidloss -2111.10385  last_update 20\n",
      "train: iter 630  trainloss -2119.30753  validloss -2041.23480±0.00000  bestvalidloss -2111.10385  last_update 21\n",
      "train: iter 631  trainloss -2214.96350  validloss -2099.35114±0.00000  bestvalidloss -2111.10385  last_update 22\n",
      "train: iter 632  trainloss -2197.48128  validloss -2108.33497±0.00000  bestvalidloss -2111.10385  last_update 23\n",
      "train: iter 633  trainloss -2217.45277  validloss -2101.65746±0.00000  bestvalidloss -2111.10385  last_update 24\n",
      "train: iter 634  trainloss -2208.84038  validloss -2046.64641±0.00000  bestvalidloss -2111.10385  last_update 25\n",
      "train: iter 635  trainloss -2208.92596  validloss -2088.78065±0.00000  bestvalidloss -2111.10385  last_update 26\n",
      "train: iter 636  trainloss -2216.17708  validloss -2092.68669±0.00000  bestvalidloss -2111.10385  last_update 27\n",
      "train: iter 637  trainloss -2169.37861  validloss -2095.84302±0.00000  bestvalidloss -2111.10385  last_update 28\n",
      "train: iter 638  trainloss -2207.25879  validloss -2092.67364±0.00000  bestvalidloss -2111.10385  last_update 29\n",
      "train: iter 639  trainloss -2215.71118  validloss -2085.95479±0.00000  bestvalidloss -2111.10385  last_update 30\n",
      "train: iter 640  trainloss -2162.34284  validloss -2086.40771±0.00000  bestvalidloss -2111.10385  last_update 31\n",
      "train: iter 641  trainloss -2160.76739  validloss -2078.79159±0.00000  bestvalidloss -2111.10385  last_update 32\n",
      "train: iter 642  trainloss -2179.98881  validloss -2058.59736±0.00000  bestvalidloss -2111.10385  last_update 33\n",
      "train: iter 643  trainloss -2186.36089  validloss -2100.27381±0.00000  bestvalidloss -2111.10385  last_update 34\n",
      "train: iter 644  trainloss -2211.94399  validloss -2088.00003±0.00000  bestvalidloss -2111.10385  last_update 35\n",
      "train: iter 645  trainloss -2135.18440  validloss -2032.80641±0.00000  bestvalidloss -2111.10385  last_update 36\n",
      "train: iter 646  trainloss -2198.73031  validloss -2082.74688±0.00000  bestvalidloss -2111.10385  last_update 37\n",
      "train: iter 647  trainloss -2220.19155  validloss -2082.58876±0.00000  bestvalidloss -2111.10385  last_update 38\n",
      "train: iter 648  trainloss -2222.41678  validloss -2079.43146±0.00000  bestvalidloss -2111.10385  last_update 39\n",
      "train: iter 649  trainloss -2215.44041  validloss -2075.53211±0.00000  bestvalidloss -2111.10385  last_update 40\n",
      "train: iter 650  trainloss -2190.83434  validloss -2066.13104±0.00000  bestvalidloss -2111.10385  last_update 41\n",
      "train: iter 651  trainloss -2164.94711  validloss -2049.55385±0.00000  bestvalidloss -2111.10385  last_update 42\n",
      "train: iter 652  trainloss -2199.70616  validloss -2061.25690±0.00000  bestvalidloss -2111.10385  last_update 43\n",
      "train: iter 653  trainloss -2224.49407  validloss -2115.35438±0.00000  bestvalidloss -2115.35438  last_update 0\n",
      "train: iter 654  trainloss -2208.19889  validloss -2009.29537±0.00000  bestvalidloss -2115.35438  last_update 1\n",
      "train: iter 655  trainloss -2219.60103  validloss -2110.43026±0.00000  bestvalidloss -2115.35438  last_update 2\n",
      "train: iter 656  trainloss -2220.41285  validloss -2119.47439±0.00000  bestvalidloss -2119.47439  last_update 0\n",
      "train: iter 657  trainloss -2216.12629  validloss -2120.81570±0.00000  bestvalidloss -2120.81570  last_update 0\n",
      "train: iter 658  trainloss -2198.45958  validloss -2106.27078±0.00000  bestvalidloss -2120.81570  last_update 1\n",
      "train: iter 659  trainloss -2207.88184  validloss -2059.54454±0.00000  bestvalidloss -2120.81570  last_update 2\n",
      "train: iter 660  trainloss -2221.96056  validloss -2108.26281±0.00000  bestvalidloss -2120.81570  last_update 3\n",
      "train: iter 661  trainloss -2215.97645  validloss -2109.49359±0.00000  bestvalidloss -2120.81570  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 662  trainloss -2155.94680  validloss -2054.59916±0.00000  bestvalidloss -2120.81570  last_update 5\n",
      "train: iter 663  trainloss -2127.14018  validloss -2070.56544±0.00000  bestvalidloss -2120.81570  last_update 6\n",
      "train: iter 664  trainloss -2198.95217  validloss -2018.34363±0.00000  bestvalidloss -2120.81570  last_update 7\n",
      "train: iter 665  trainloss -2195.93763  validloss -2104.90625±0.00000  bestvalidloss -2120.81570  last_update 8\n",
      "train: iter 666  trainloss -2109.95843  validloss -2081.02529±0.00000  bestvalidloss -2120.81570  last_update 9\n",
      "train: iter 667  trainloss -2215.00397  validloss -2107.89418±0.00000  bestvalidloss -2120.81570  last_update 10\n",
      "train: iter 668  trainloss -2230.80830  validloss -2085.23130±0.00000  bestvalidloss -2120.81570  last_update 11\n",
      "train: iter 669  trainloss -2225.23832  validloss -2067.36177±0.00000  bestvalidloss -2120.81570  last_update 12\n",
      "train: iter 670  trainloss -2234.20920  validloss -2106.64603±0.00000  bestvalidloss -2120.81570  last_update 13\n",
      "train: iter 671  trainloss -2230.68676  validloss -2098.71793±0.00000  bestvalidloss -2120.81570  last_update 14\n",
      "train: iter 672  trainloss -2232.36526  validloss -2115.36997±0.00000  bestvalidloss -2120.81570  last_update 15\n",
      "train: iter 673  trainloss -2221.38165  validloss -2115.59397±0.00000  bestvalidloss -2120.81570  last_update 16\n",
      "train: iter 674  trainloss -2221.33616  validloss -2098.73612±0.00000  bestvalidloss -2120.81570  last_update 17\n",
      "train: iter 675  trainloss -2233.19852  validloss -2095.29940±0.00000  bestvalidloss -2120.81570  last_update 18\n",
      "train: iter 676  trainloss -2215.67347  validloss -2130.43231±0.00000  bestvalidloss -2130.43231  last_update 0\n",
      "train: iter 677  trainloss -2175.46924  validloss -2059.93464±0.00000  bestvalidloss -2130.43231  last_update 1\n",
      "train: iter 678  trainloss -2073.76582  validloss -2095.65923±0.00000  bestvalidloss -2130.43231  last_update 2\n",
      "train: iter 679  trainloss -2197.21586  validloss -1962.92293±0.00000  bestvalidloss -2130.43231  last_update 3\n",
      "train: iter 680  trainloss -2208.66396  validloss -2053.38307±0.00000  bestvalidloss -2130.43231  last_update 4\n",
      "train: iter 681  trainloss -2223.36816  validloss -2071.34597±0.00000  bestvalidloss -2130.43231  last_update 5\n",
      "train: iter 682  trainloss -2211.02655  validloss -2061.22051±0.00000  bestvalidloss -2130.43231  last_update 6\n",
      "train: iter 683  trainloss -2210.48278  validloss -2071.47615±0.00000  bestvalidloss -2130.43231  last_update 7\n",
      "train: iter 684  trainloss -2220.07244  validloss -2101.11260±0.00000  bestvalidloss -2130.43231  last_update 8\n",
      "train: iter 685  trainloss -2232.84859  validloss -2099.21164±0.00000  bestvalidloss -2130.43231  last_update 9\n",
      "train: iter 686  trainloss -2205.60183  validloss -2107.47335±0.00000  bestvalidloss -2130.43231  last_update 10\n",
      "train: iter 687  trainloss -2233.74082  validloss -2108.18896±0.00000  bestvalidloss -2130.43231  last_update 11\n",
      "train: iter 688  trainloss -2240.90793  validloss -2125.18080±0.00000  bestvalidloss -2130.43231  last_update 12\n",
      "train: iter 689  trainloss -2238.02420  validloss -2112.51748±0.00000  bestvalidloss -2130.43231  last_update 13\n",
      "train: iter 690  trainloss -2196.62786  validloss -2106.43981±0.00000  bestvalidloss -2130.43231  last_update 14\n",
      "train: iter 691  trainloss -2191.10825  validloss -1980.55270±0.00000  bestvalidloss -2130.43231  last_update 15\n",
      "train: iter 692  trainloss -2160.80197  validloss -2052.74440±0.00000  bestvalidloss -2130.43231  last_update 16\n",
      "train: iter 693  trainloss -2146.18650  validloss -2034.75495±0.00000  bestvalidloss -2130.43231  last_update 17\n",
      "train: iter 694  trainloss -2207.56492  validloss -2069.23051±0.00000  bestvalidloss -2130.43231  last_update 18\n",
      "train: iter 695  trainloss -2225.43635  validloss -2086.86127±0.00000  bestvalidloss -2130.43231  last_update 19\n",
      "train: iter 696  trainloss -2223.48999  validloss -2108.28347±0.00000  bestvalidloss -2130.43231  last_update 20\n",
      "train: iter 697  trainloss -2238.27458  validloss -2097.33162±0.00000  bestvalidloss -2130.43231  last_update 21\n",
      "train: iter 698  trainloss -2241.36590  validloss -2107.67224±0.00000  bestvalidloss -2130.43231  last_update 22\n",
      "train: iter 699  trainloss -2228.70214  validloss -2106.92913±0.00000  bestvalidloss -2130.43231  last_update 23\n",
      "train: iter 700  trainloss -2234.31265  validloss -2090.56392±0.00000  bestvalidloss -2130.43231  last_update 24\n",
      "train: iter 701  trainloss -2232.83176  validloss -2116.84005±0.00000  bestvalidloss -2130.43231  last_update 25\n",
      "train: iter 702  trainloss -2224.74660  validloss -2119.93611±0.00000  bestvalidloss -2130.43231  last_update 26\n",
      "train: iter 703  trainloss -2170.96700  validloss -2061.62224±0.00000  bestvalidloss -2130.43231  last_update 27\n",
      "train: iter 704  trainloss -2082.25757  validloss -2100.84379±0.00000  bestvalidloss -2130.43231  last_update 28\n",
      "train: iter 705  trainloss -2218.78070  validloss -2085.02117±0.00000  bestvalidloss -2130.43231  last_update 29\n",
      "train: iter 706  trainloss -2223.34774  validloss -2102.25033±0.00000  bestvalidloss -2130.43231  last_update 30\n",
      "train: iter 707  trainloss -2216.20245  validloss -2083.29019±0.00000  bestvalidloss -2130.43231  last_update 31\n",
      "train: iter 708  trainloss -2190.20608  validloss -2100.42695±0.00000  bestvalidloss -2130.43231  last_update 32\n",
      "train: iter 709  trainloss -2120.76429  validloss -2059.39735±0.00000  bestvalidloss -2130.43231  last_update 33\n",
      "train: iter 710  trainloss -2230.52855  validloss -2075.97012±0.00000  bestvalidloss -2130.43231  last_update 34\n",
      "train: iter 711  trainloss -2221.71430  validloss -2102.05036±0.00000  bestvalidloss -2130.43231  last_update 35\n",
      "train: iter 712  trainloss -2241.90875  validloss -2074.56488±0.00000  bestvalidloss -2130.43231  last_update 36\n",
      "train: iter 713  trainloss -2238.72822  validloss -2112.39760±0.00000  bestvalidloss -2130.43231  last_update 37\n",
      "train: iter 714  trainloss -2242.18666  validloss -2104.02549±0.00000  bestvalidloss -2130.43231  last_update 38\n",
      "train: iter 715  trainloss -2234.49558  validloss -2105.03295±0.00000  bestvalidloss -2130.43231  last_update 39\n",
      "train: iter 716  trainloss -2219.53808  validloss -2097.50088±0.00000  bestvalidloss -2130.43231  last_update 40\n",
      "train: iter 717  trainloss -2240.50939  validloss -2122.77087±0.00000  bestvalidloss -2130.43231  last_update 41\n",
      "train: iter 718  trainloss -2234.35124  validloss -2106.50750±0.00000  bestvalidloss -2130.43231  last_update 42\n",
      "train: iter 719  trainloss -2240.71442  validloss -2110.57787±0.00000  bestvalidloss -2130.43231  last_update 43\n",
      "train: iter 720  trainloss -2225.17675  validloss -2092.22756±0.00000  bestvalidloss -2130.43231  last_update 44\n",
      "train: iter 721  trainloss -2122.14655  validloss -2134.44169±0.00000  bestvalidloss -2134.44169  last_update 0\n",
      "train: iter 722  trainloss -2205.91952  validloss -2057.14573±0.00000  bestvalidloss -2134.44169  last_update 1\n",
      "train: iter 723  trainloss -2184.11776  validloss -2061.24623±0.00000  bestvalidloss -2134.44169  last_update 2\n",
      "train: iter 724  trainloss -2232.35759  validloss -2084.14365±0.00000  bestvalidloss -2134.44169  last_update 3\n",
      "train: iter 725  trainloss -2240.36394  validloss -2135.61205±0.00000  bestvalidloss -2135.61205  last_update 0\n",
      "train: iter 726  trainloss -2205.02977  validloss -2106.18206±0.00000  bestvalidloss -2135.61205  last_update 1\n",
      "train: iter 727  trainloss -2205.50047  validloss -1982.59332±0.00000  bestvalidloss -2135.61205  last_update 2\n",
      "train: iter 728  trainloss -2227.60161  validloss -2062.31949±0.00000  bestvalidloss -2135.61205  last_update 3\n",
      "train: iter 729  trainloss -2228.98621  validloss -2080.47283±0.00000  bestvalidloss -2135.61205  last_update 4\n",
      "train: iter 730  trainloss -2226.88543  validloss -2082.55361±0.00000  bestvalidloss -2135.61205  last_update 5\n",
      "train: iter 731  trainloss -2225.04888  validloss -2098.17756±0.00000  bestvalidloss -2135.61205  last_update 6\n",
      "train: iter 732  trainloss -2246.55360  validloss -2086.37227±0.00000  bestvalidloss -2135.61205  last_update 7\n",
      "train: iter 733  trainloss -2244.67111  validloss -2129.25836±0.00000  bestvalidloss -2135.61205  last_update 8\n",
      "train: iter 734  trainloss -2237.01637  validloss -2115.16821±0.00000  bestvalidloss -2135.61205  last_update 9\n",
      "train: iter 735  trainloss -2243.84564  validloss -2100.54747±0.00000  bestvalidloss -2135.61205  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 736  trainloss -2235.99224  validloss -2118.24636±0.00000  bestvalidloss -2135.61205  last_update 11\n",
      "train: iter 737  trainloss -2218.54124  validloss -2109.39171±0.00000  bestvalidloss -2135.61205  last_update 12\n",
      "train: iter 738  trainloss -2169.64382  validloss -2096.39609±0.00000  bestvalidloss -2135.61205  last_update 13\n",
      "train: iter 739  trainloss -2213.62441  validloss -2091.05328±0.00000  bestvalidloss -2135.61205  last_update 14\n",
      "train: iter 740  trainloss -2224.24676  validloss -2071.67321±0.00000  bestvalidloss -2135.61205  last_update 15\n",
      "train: iter 741  trainloss -2242.26616  validloss -2117.31102±0.00000  bestvalidloss -2135.61205  last_update 16\n",
      "train: iter 742  trainloss -2237.17677  validloss -2109.54578±0.00000  bestvalidloss -2135.61205  last_update 17\n",
      "train: iter 743  trainloss -2248.41061  validloss -2129.73156±0.00000  bestvalidloss -2135.61205  last_update 18\n",
      "train: iter 744  trainloss -2228.78844  validloss -2124.46983±0.00000  bestvalidloss -2135.61205  last_update 19\n",
      "train: iter 745  trainloss -2221.24668  validloss -2062.37361±0.00000  bestvalidloss -2135.61205  last_update 20\n",
      "train: iter 746  trainloss -2260.58601  validloss -2110.40419±0.00000  bestvalidloss -2135.61205  last_update 21\n",
      "train: iter 747  trainloss -2240.64409  validloss -2125.66131±0.00000  bestvalidloss -2135.61205  last_update 22\n",
      "train: iter 748  trainloss -2233.86492  validloss -2089.05704±0.00000  bestvalidloss -2135.61205  last_update 23\n",
      "train: iter 749  trainloss -2247.61900  validloss -2064.17079±0.00000  bestvalidloss -2135.61205  last_update 24\n",
      "train: iter 750  trainloss -2239.67755  validloss -2107.36381±0.00000  bestvalidloss -2135.61205  last_update 25\n",
      "train: iter 751  trainloss -2204.09705  validloss -2137.01638±0.00000  bestvalidloss -2137.01638  last_update 0\n",
      "train: iter 752  trainloss -2172.82168  validloss -2113.95240±0.00000  bestvalidloss -2137.01638  last_update 1\n",
      "train: iter 753  trainloss -1949.07226  validloss -1682.83464±0.00000  bestvalidloss -2137.01638  last_update 2\n",
      "train: iter 754  trainloss -2219.48736  validloss -2027.43712±0.00000  bestvalidloss -2137.01638  last_update 3\n",
      "train: iter 755  trainloss -2246.85937  validloss -2094.65115±0.00000  bestvalidloss -2137.01638  last_update 4\n",
      "train: iter 756  trainloss -2234.48309  validloss -2100.33729±0.00000  bestvalidloss -2137.01638  last_update 5\n",
      "train: iter 757  trainloss -2244.86850  validloss -2054.44842±0.00000  bestvalidloss -2137.01638  last_update 6\n",
      "train: iter 758  trainloss -2250.70861  validloss -2113.14572±0.00000  bestvalidloss -2137.01638  last_update 7\n",
      "train: iter 759  trainloss -2249.02934  validloss -2095.26445±0.00000  bestvalidloss -2137.01638  last_update 8\n",
      "train: iter 760  trainloss -2252.38748  validloss -2102.34567±0.00000  bestvalidloss -2137.01638  last_update 9\n",
      "train: iter 761  trainloss -2255.16688  validloss -2148.95096±0.00000  bestvalidloss -2148.95096  last_update 0\n",
      "train: iter 762  trainloss -2257.92429  validloss -2113.40319±0.00000  bestvalidloss -2148.95096  last_update 1\n",
      "train: iter 763  trainloss -2257.15687  validloss -2124.03472±0.00000  bestvalidloss -2148.95096  last_update 2\n",
      "train: iter 764  trainloss -2225.59077  validloss -2105.00715±0.00000  bestvalidloss -2148.95096  last_update 3\n",
      "train: iter 765  trainloss -2250.83676  validloss -2111.29554±0.00000  bestvalidloss -2148.95096  last_update 4\n",
      "train: iter 766  trainloss -2258.82448  validloss -2132.91083±0.00000  bestvalidloss -2148.95096  last_update 5\n",
      "train: iter 767  trainloss -2253.44768  validloss -2083.66481±0.00000  bestvalidloss -2148.95096  last_update 6\n",
      "train: iter 768  trainloss -2267.55859  validloss -2123.05153±0.00000  bestvalidloss -2148.95096  last_update 7\n",
      "train: iter 769  trainloss -2259.16252  validloss -2092.81629±0.00000  bestvalidloss -2148.95096  last_update 8\n",
      "train: iter 770  trainloss -2243.96354  validloss -2054.21573±0.00000  bestvalidloss -2148.95096  last_update 9\n",
      "train: iter 771  trainloss -2216.91023  validloss -2106.58750±0.00000  bestvalidloss -2148.95096  last_update 10\n",
      "train: iter 772  trainloss -2144.28283  validloss -2040.54171±0.00000  bestvalidloss -2148.95096  last_update 11\n",
      "train: iter 773  trainloss -2239.30535  validloss -2110.53102±0.00000  bestvalidloss -2148.95096  last_update 12\n",
      "train: iter 774  trainloss -2232.05930  validloss -2100.13232±0.00000  bestvalidloss -2148.95096  last_update 13\n",
      "train: iter 775  trainloss -2249.83444  validloss -2111.70848±0.00000  bestvalidloss -2148.95096  last_update 14\n",
      "train: iter 776  trainloss -2262.02697  validloss -2112.53853±0.00000  bestvalidloss -2148.95096  last_update 15\n",
      "train: iter 777  trainloss -2261.12023  validloss -2091.73523±0.00000  bestvalidloss -2148.95096  last_update 16\n",
      "train: iter 778  trainloss -2251.64685  validloss -2108.70419±0.00000  bestvalidloss -2148.95096  last_update 17\n",
      "train: iter 779  trainloss -2235.24586  validloss -2122.44150±0.00000  bestvalidloss -2148.95096  last_update 18\n",
      "train: iter 780  trainloss -2244.83499  validloss -2098.25125±0.00000  bestvalidloss -2148.95096  last_update 19\n",
      "train: iter 781  trainloss -2247.96089  validloss -2031.18115±0.00000  bestvalidloss -2148.95096  last_update 20\n",
      "train: iter 782  trainloss -2235.45862  validloss -2110.73832±0.00000  bestvalidloss -2148.95096  last_update 21\n",
      "train: iter 783  trainloss -2173.43849  validloss -2093.29779±0.00000  bestvalidloss -2148.95096  last_update 22\n",
      "train: iter 784  trainloss -2253.02974  validloss -2055.92937±0.00000  bestvalidloss -2148.95096  last_update 23\n",
      "train: iter 785  trainloss -2249.18151  validloss -2103.27006±0.00000  bestvalidloss -2148.95096  last_update 24\n",
      "train: iter 786  trainloss -2253.26169  validloss -2061.95851±0.00000  bestvalidloss -2148.95096  last_update 25\n",
      "train: iter 787  trainloss -2249.28992  validloss -2119.41085±0.00000  bestvalidloss -2148.95096  last_update 26\n",
      "train: iter 788  trainloss -2238.00243  validloss -2080.51807±0.00000  bestvalidloss -2148.95096  last_update 27\n",
      "train: iter 789  trainloss -2228.86264  validloss -2134.82150±0.00000  bestvalidloss -2148.95096  last_update 28\n",
      "train: iter 790  trainloss -2239.00320  validloss -2073.03793±0.00000  bestvalidloss -2148.95096  last_update 29\n",
      "train: iter 791  trainloss -2255.80704  validloss -2101.52886±0.00000  bestvalidloss -2148.95096  last_update 30\n",
      "train: iter 792  trainloss -2257.19912  validloss -2109.71451±0.00000  bestvalidloss -2148.95096  last_update 31\n",
      "train: iter 793  trainloss -2257.65327  validloss -2119.27670±0.00000  bestvalidloss -2148.95096  last_update 32\n",
      "train: iter 794  trainloss -2179.20849  validloss -2109.00730±0.00000  bestvalidloss -2148.95096  last_update 33\n",
      "train: iter 795  trainloss -2234.51566  validloss -2088.65653±0.00000  bestvalidloss -2148.95096  last_update 34\n",
      "train: iter 796  trainloss -2258.75892  validloss -2106.58918±0.00000  bestvalidloss -2148.95096  last_update 35\n",
      "train: iter 797  trainloss -2249.20197  validloss -2107.15825±0.00000  bestvalidloss -2148.95096  last_update 36\n",
      "train: iter 798  trainloss -2271.32223  validloss -2129.45807±0.00000  bestvalidloss -2148.95096  last_update 37\n",
      "train: iter 799  trainloss -2244.64666  validloss -2110.64423±0.00000  bestvalidloss -2148.95096  last_update 38\n",
      "train: iter 800  trainloss -2268.80948  validloss -2105.41960±0.00000  bestvalidloss -2148.95096  last_update 39\n",
      "train: iter 801  trainloss -2237.56455  validloss -2121.42166±0.00000  bestvalidloss -2148.95096  last_update 40\n",
      "train: iter 802  trainloss -2248.72180  validloss -2092.56539±0.00000  bestvalidloss -2148.95096  last_update 41\n",
      "train: iter 803  trainloss -2198.88079  validloss -2068.42138±0.00000  bestvalidloss -2148.95096  last_update 42\n",
      "train: iter 804  trainloss -2236.40970  validloss -2067.38944±0.00000  bestvalidloss -2148.95096  last_update 43\n",
      "train: iter 805  trainloss -2182.04465  validloss -2046.38129±0.00000  bestvalidloss -2148.95096  last_update 44\n",
      "train: iter 806  trainloss -2227.78375  validloss -2144.62535±0.00000  bestvalidloss -2148.95096  last_update 45\n",
      "train: iter 807  trainloss -2250.59158  validloss -2080.17538±0.00000  bestvalidloss -2148.95096  last_update 46\n",
      "train: iter 808  trainloss -2259.83671  validloss -2103.73770±0.00000  bestvalidloss -2148.95096  last_update 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 809  trainloss -2213.79493  validloss -2101.33026±0.00000  bestvalidloss -2148.95096  last_update 48\n",
      "train: iter 810  trainloss -2246.84146  validloss -2059.70002±0.00000  bestvalidloss -2148.95096  last_update 49\n",
      "train: iter 811  trainloss -2214.74976  validloss -2085.34823±0.00000  bestvalidloss -2148.95096  last_update 50\n",
      "train: iter 812  trainloss -2268.11512  validloss -2105.52733±0.00000  bestvalidloss -2148.95096  last_update 51\n",
      "train: iter 813  trainloss -2251.97872  validloss -2111.45875±0.00000  bestvalidloss -2148.95096  last_update 52\n",
      "train: iter 814  trainloss -2233.55919  validloss -2117.05193±0.00000  bestvalidloss -2148.95096  last_update 53\n",
      "train: iter 815  trainloss -2233.29473  validloss -2025.70046±0.00000  bestvalidloss -2148.95096  last_update 54\n",
      "train: iter 816  trainloss -2257.97431  validloss -2108.67277±0.00000  bestvalidloss -2148.95096  last_update 55\n",
      "train: iter 817  trainloss -2220.28141  validloss -2093.48091±0.00000  bestvalidloss -2148.95096  last_update 56\n",
      "train: iter 818  trainloss -2243.90180  validloss -2096.44305±0.00000  bestvalidloss -2148.95096  last_update 57\n",
      "train: iter 819  trainloss -2261.69842  validloss -2102.46532±0.00000  bestvalidloss -2148.95096  last_update 58\n",
      "train: iter 820  trainloss -2253.33075  validloss -2098.07122±0.00000  bestvalidloss -2148.95096  last_update 59\n",
      "train: iter 821  trainloss -2261.98638  validloss -2080.92786±0.00000  bestvalidloss -2148.95096  last_update 60\n",
      "train: iter 822  trainloss -2262.47811  validloss -2113.30144±0.00000  bestvalidloss -2148.95096  last_update 61\n",
      "train: iter 823  trainloss -2258.35950  validloss -2123.59179±0.00000  bestvalidloss -2148.95096  last_update 62\n",
      "train: iter 824  trainloss -2225.53385  validloss -2114.98878±0.00000  bestvalidloss -2148.95096  last_update 63\n",
      "train: iter 825  trainloss -2232.57759  validloss -2081.39104±0.00000  bestvalidloss -2148.95096  last_update 64\n",
      "train: iter 826  trainloss -2250.24313  validloss -2097.18199±0.00000  bestvalidloss -2148.95096  last_update 65\n",
      "train: iter 827  trainloss -2257.01891  validloss -2130.26321±0.00000  bestvalidloss -2148.95096  last_update 66\n",
      "train: iter 828  trainloss -2269.56357  validloss -2101.41866±0.00000  bestvalidloss -2148.95096  last_update 67\n",
      "train: iter 829  trainloss -2262.84436  validloss -2123.05656±0.00000  bestvalidloss -2148.95096  last_update 68\n",
      "train: iter 830  trainloss -2219.39655  validloss -2075.54195±0.00000  bestvalidloss -2148.95096  last_update 69\n",
      "train: iter 831  trainloss -2247.14327  validloss -2049.79398±0.00000  bestvalidloss -2148.95096  last_update 70\n",
      "train: iter 832  trainloss -2250.50229  validloss -2129.05270±0.00000  bestvalidloss -2148.95096  last_update 71\n",
      "train: iter 833  trainloss -2247.80666  validloss -2027.93824±0.00000  bestvalidloss -2148.95096  last_update 72\n",
      "train: iter 834  trainloss -2237.91932  validloss -2089.60898±0.00000  bestvalidloss -2148.95096  last_update 73\n",
      "train: iter 835  trainloss -2256.18395  validloss -2055.71561±0.00000  bestvalidloss -2148.95096  last_update 74\n",
      "train: iter 836  trainloss -2205.30298  validloss -2098.94235±0.00000  bestvalidloss -2148.95096  last_update 75\n",
      "train: iter 837  trainloss -2251.00274  validloss -2085.17217±0.00000  bestvalidloss -2148.95096  last_update 76\n",
      "train: iter 838  trainloss -2260.81177  validloss -2066.58885±0.00000  bestvalidloss -2148.95096  last_update 77\n",
      "train: iter 839  trainloss -2260.21207  validloss -2112.99380±0.00000  bestvalidloss -2148.95096  last_update 78\n",
      "train: iter 840  trainloss -2255.51746  validloss -2068.40312±0.00000  bestvalidloss -2148.95096  last_update 79\n",
      "train: iter 841  trainloss -2275.57638  validloss -2121.25983±0.00000  bestvalidloss -2148.95096  last_update 80\n",
      "train: iter 842  trainloss -2263.67557  validloss -2123.09924±0.00000  bestvalidloss -2148.95096  last_update 81\n",
      "train: iter 843  trainloss -2239.08029  validloss -2076.83370±0.00000  bestvalidloss -2148.95096  last_update 82\n",
      "train: iter 844  trainloss -2227.58677  validloss -2106.86193±0.00000  bestvalidloss -2148.95096  last_update 83\n",
      "train: iter 845  trainloss -2112.56514  validloss -2052.49852±0.00000  bestvalidloss -2148.95096  last_update 84\n",
      "train: iter 846  trainloss -2262.30280  validloss -2080.02234±0.00000  bestvalidloss -2148.95096  last_update 85\n",
      "train: iter 847  trainloss -2267.75673  validloss -2067.78762±0.00000  bestvalidloss -2148.95096  last_update 86\n",
      "train: iter 848  trainloss -2255.04364  validloss -2105.15717±0.00000  bestvalidloss -2148.95096  last_update 87\n",
      "train: iter 849  trainloss -2256.41250  validloss -2096.47388±0.00000  bestvalidloss -2148.95096  last_update 88\n",
      "train: iter 850  trainloss -2271.00276  validloss -2122.15527±0.00000  bestvalidloss -2148.95096  last_update 89\n",
      "train: iter 851  trainloss -2268.59948  validloss -2109.43792±0.00000  bestvalidloss -2148.95096  last_update 90\n",
      "train: iter 852  trainloss -2270.47881  validloss -2108.16740±0.00000  bestvalidloss -2148.95096  last_update 91\n",
      "train: iter 853  trainloss -2264.86320  validloss -2109.84349±0.00000  bestvalidloss -2148.95096  last_update 92\n",
      "train: iter 854  trainloss -2261.34394  validloss -2086.97680±0.00000  bestvalidloss -2148.95096  last_update 93\n",
      "train: iter 855  trainloss -2265.36941  validloss -2081.22973±0.00000  bestvalidloss -2148.95096  last_update 94\n",
      "train: iter 856  trainloss -2276.55329  validloss -2139.57430±0.00000  bestvalidloss -2148.95096  last_update 95\n",
      "train: iter 857  trainloss -2268.95178  validloss -2145.96481±0.00000  bestvalidloss -2148.95096  last_update 96\n",
      "train: iter 858  trainloss -2260.91842  validloss -2055.38080±0.00000  bestvalidloss -2148.95096  last_update 97\n",
      "train: iter 859  trainloss -2254.18520  validloss -2083.45753±0.00000  bestvalidloss -2148.95096  last_update 98\n",
      "train: iter 860  trainloss -2181.87545  validloss -2108.30455±0.00000  bestvalidloss -2148.95096  last_update 99\n",
      "train: iter 861  trainloss -2125.85807  validloss -2024.86282±0.00000  bestvalidloss -2148.95096  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3242) penalty_target_max tensor(27.5586)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGdCAYAAAAWp6lMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACCwUlEQVR4nO3dd3hTZfsH8G+StumgA+hiFCh7b4GiqEilIA4cqIgIvKg/FFQEFw7AgfiKCxXFhegrynArCNYCskqZZZcNLaOL0qY76/z+OBnnJCddNElpv5/rytXknCcnJw3k3L2f+3kelSAIAoiIiIjqMbW3T4CIiIjI3RjwEBERUb3HgIeIiIjqPQY8REREVO8x4CEiIqJ6jwEPERER1XsMeIiIiKjeY8BDRERE9Z6Pt0+gLjCbzbhw4QKCg4OhUqm8fTpERERUBYIgoLCwEM2bN4daXXEOhwEPgAsXLiAmJsbbp0FEREQ1kJGRgZYtW1bYhgEPgODgYADiLywkJMTLZ0NERERVodPpEBMTY7uOV4QBD2DrxgoJCWHAQ0REdJWpSjkKi5aJiIio3mPAQ0RERPWeWwOeTZs24bbbbkPz5s2hUqnw66+/yvYLgoDZs2ejWbNmCAgIQHx8PI4fPy5rk5eXh3HjxiEkJARhYWGYPHkyioqKZG3279+PIUOGwN/fHzExMXj77bfd+baIiIjoKuPWgKe4uBi9evXCokWLFPe//fbb+PDDD7F48WKkpKQgKCgICQkJKCsrs7UZN24cDh06hMTERPz555/YtGkTHn30Udt+nU6H4cOHo3Xr1ti9ezcWLFiAuXPn4vPPP3fnWyMiIqKrieAhAIRffvnF9thsNgvR0dHCggULbNvy8/MFrVYr/PDDD4IgCMLhw4cFAMLOnTttbf766y9BpVIJ58+fFwRBED755BOhcePGQnl5ua3N888/L3Tq1KnK51ZQUCAAEAoKCmr69oiIiMjDqnP99loNz+nTp5GZmYn4+HjbttDQUAwcOBDJyckAgOTkZISFhaF///62NvHx8VCr1UhJSbG1uf766+Hn52drk5CQgKNHj+Ly5cuKr11eXg6dTie7ERERUf3ltYAnMzMTABAVFSXbHhUVZduXmZmJyMhI2X4fHx80adJE1kbpGNLXcDR//nyEhobabpx0kIiIqH5rkKO0Zs2ahYKCAtstIyPD26dEREREbuS1gCc6OhoAkJWVJduelZVl2xcdHY3s7GzZfqPRiLy8PFkbpWNIX8ORVqu1TTLIyQaJiIjqP68FPLGxsYiOjkZSUpJtm06nQ0pKCuLi4gAAcXFxyM/Px+7du21t1q9fD7PZjIEDB9rabNq0CQaDwdYmMTERnTp1QuPGjT30boiIiKguc2vAU1RUhNTUVKSmpgIQC5VTU1ORnp4OlUqF6dOn44033sDvv/+OAwcO4KGHHkLz5s0xevRoAECXLl0wYsQIPPLII9ixYwe2bt2KadOm4f7770fz5s0BAA888AD8/PwwefJkHDp0CCtWrMDChQsxY8YMd741IiIiupq4c7jYhg0bBABOtwkTJgiCIA5Nf+WVV4SoqChBq9UKw4YNE44ePSo7xqVLl4SxY8cKjRo1EkJCQoRJkyYJhYWFsjb79u0TrrvuOkGr1QotWrQQ3nrrrWqdJ4elExERXX2qc/1WCYIgeDHeqhN0Oh1CQ0NRUFBQu/U8Rj2QOBsQTMDNrwO+/rV3bCIiogauOtfvBjlKy3MEIOVTYMfngKnc2ydDRETUYDHgcSeVxn7fbPLeeRARETVwDHjcSc2Ah4iIqC5gwONOKhUAlXhfYMBDRETkLQx43E3tI/5khoeIiMhrGPC4m7Vby2z07nkQERE1YAx43M1auMwuLSIiIq9hwONuti4ts3fPg4iIqAFjwONuasuvmF1aREREXsOAx93YpUVEROR1DHjczVa0zICHiIjIWxjwuJu1hocZHiIiIq9hwONuKmZ4iIiIvI0Bj7vZipYZ8BAREXkLAx53Y5cWERGR1zHgcTcVZ1omIiLyNgY87sZRWkRERF7HgMfdOA8PERGR1zHgcTdbhodLSxAREXkLAx5342rpREREXseAx93YpUVEROR1DHjczbZaOgMeIiIib2HA425qZniIiIi8jQGPGwmCAEEl/ooFE2t4iIiIvIUBjxuVG83YdOIyAKBMb/Dy2RARETVcDHjcSK1SwWT5FQus4SEiIvIaBjxu5KOWBDzs0iIiIvIaBjxupFarYLb8ik2ch4eIiMhrGPC4mdk6D4+JXVpERETewoDHzawZHjMzPERERF7DgMfNOCydiIjI+xjwuJkJYpeWmV1aREREXsOAx80ESw2PIDDDQ0RE5C0MeNzM3qVl9vKZEBERNVwMeNzMOkpLMHOmZSIiIm9hwONmAqwBDzM8RERE3sKAx83MHKVFRETkdQx43M068SDn4SEiIvIaBjxuZq/h4bB0IiIib2HA42a2UVoMeIiIiLyGAY+7Wbu0BAY8RERE3sKAx81sXVosWiYiIvIarwc8c+fOhUqlkt06d+5s219WVoapU6eiadOmaNSoEe6++25kZWXJjpGeno5Ro0YhMDAQkZGRePbZZ2E01pEAQ80MDxERkbf5ePsEAKBbt274559/bI99fOyn9fTTT2P16tVYtWoVQkNDMW3aNNx1113YunUrAMBkMmHUqFGIjo7Gtm3bcPHiRTz00EPw9fXFm2++6fH34sg+Dw8DHiIiIm+pEwGPj48PoqOjnbYXFBTgq6++wvfff4+bbroJAPD111+jS5cu2L59OwYNGoS///4bhw8fxj///IOoqCj07t0br7/+Op5//nnMnTsXfn5+nn47cmoxiabisHQiIiKv8XqXFgAcP34czZs3R9u2bTFu3Dikp6cDAHbv3g2DwYD4+Hhb286dO6NVq1ZITk4GACQnJ6NHjx6IioqytUlISIBOp8OhQ4cUX6+8vBw6nU52cxezSowpOdMyERGR93g94Bk4cCCWLl2KtWvX4tNPP8Xp06cxZMgQFBYWIjMzE35+fggLC5M9JyoqCpmZmQCAzMxMWbBj3W/dp2T+/PkIDQ213WJiYmr/jVlZhqWzhoeIiMh7vN6lNXLkSNv9nj17YuDAgWjdujVWrlyJgIAAt7zmrFmzMGPGDNtjnU7nvqDHWrTMGh4iIiKv8XqGx1FYWBg6duyIEydOIDo6Gnq9Hvn5+bI2WVlZtpqf6Ohop1Fb1sdKdUEAoNVqERISIru5i8ClJYiIiLyuzgU8RUVFOHnyJJo1a4Z+/frB19cXSUlJtv1Hjx5Feno64uLiAABxcXE4cOAAsrOzbW0SExMREhKCrl27evz8nXBYOhERkdd5vUvrmWeewW233YbWrVvjwoULmDNnDjQaDcaOHYvQ0FBMnjwZM2bMQJMmTRASEoInnngCcXFxGDRoEABg+PDh6Nq1K8aPH4+3334bmZmZePnllzF16lRotVovvztIFg9lwENEROQtXg94zp07h7Fjx+LSpUuIiIjAddddh+3btyMiIgIA8P7770OtVuPuu+9GeXk5EhIS8Mknn9ier9Fo8Oeff+Kxxx5DXFwcgoKCMGHCBLz22mveektylgyPSuAoLSIiIm9RCYIgePskvE2n0yE0NBQFBQW1Xs+zdPF/MTHzTZxvMggtnlxXq8cmIiJqyKpz/a5zNTz1jcpWw8MMDxERkbcw4HE3yzw8KhYtExEReQ0DHnez1vBwWDoREZHXMOBxM5VarAtn0TIREZH3MOBxM4Hz8BAREXkdAx43U6s4LJ2IiMjbGPC4mWDr0mINDxERkbcw4HEzNSceJCIi8joGPO5mC3hYw0NEROQtDHjcjRkeIiIir2PA42ZqjbWGRyHDU5IHmAwePiMiIqKGhwGPu1lGaakdA578dODtWGDxdV44KSIiooaFAY+b2TI8cOjSSlst/sxJ8/AZERERNTwMeNzNMizdKcNDREREHsOAx83UGo7SIiIi8jYGPG6mcjlKS+X5kyEiImqgGPC4mTXgUTvW8BAREZHHMOBxM2vRMmt4iIiIvIcBj7tZi5bhEPCo2KVFRETkKQx43Eyj4UzLRERE3saAx90sXVo+jhkeIiIi8hgGPG6msXRpAQDM0iwPu7SIiIg8hQGPm1nn4QEAsHCZiIjIKxjwuJlKluFhwENEROQNDHjczDosHQBgNnrvRIiIiBowBjxuppIGPNIuLQ5LJyIi8hgGPG7mI63hYZcWERGRVzDgcTN5hodz8RAREXkDAx4389GoYRIs3Ves4SEiIvIKBjxuplGpYLL+mtmlRURE5BUMeNxMo1bBBEsdD+fhISIi8goGPG4mBjzWDI+kS4ujtIiIiDyGAY+bqdUqmG0BD4uWiYiIvIEBj5v5qFUwKmV4iIiIyGMY8LiZWlq0LKvhYZcWERGRpzDgcTMfjaRomaO0iIiIvIIBj5vJh6WzS4uIiMgbGPC4mUatglmwdmlJipY5SouIiMhjGPC4mcZV0bIgKN8nIiKiWseAx83UKumwdBc1PAx4iIiI3IoBj5v5aFQwKs20LO3S4qKiREREblWvAp5FixahTZs28Pf3x8CBA7Fjxw5vnxI0sgyPq6JlZniIiIjcqd4EPCtWrMCMGTMwZ84c7NmzB7169UJCQgKys7O9el7SpSUEdmkRERF5Rb0JeN577z088sgjmDRpErp27YrFixcjMDAQS5Ys8ep5SYuWzSZphoddWkRERJ5SLwIevV6P3bt3Iz4+3rZNrVYjPj4eycnJTu3Ly8uh0+lkN3fRSNbSkgc8UszwEBERuVO9CHhyc3NhMpkQFRUl2x4VFYXMzEyn9vPnz0doaKjtFhMT47Zzk3ZpuQx42KVFRETkVvUi4KmuWbNmoaCgwHbLyMhw22uJa2mJo7SY4SEiIvIOH2+fQG0IDw+HRqNBVlaWbHtWVhaio6Od2mu1Wmi1Wo+cm49aBZNgzfBwWDoREZE31IsMj5+fH/r164ekpCTbNrPZjKSkJMTFxXnxzBy6tFwNS2eXFhERkVvViwwPAMyYMQMTJkxA//79MWDAAHzwwQcoLi7GpEmTvHpeKsk8PAK7tIiIiLyi3gQ89913H3JycjB79mxkZmaid+/eWLt2rVMhszeYVdYaHuk8POzSIiIi8pR6E/AAwLRp0zBt2jRvn4YTe8BjUG7ALi0iIiK3qhc1PHWdubKZlomIiMitGPB4gGKXFkdpEREReQwDHg8QVApFy9JuLHZpERERuRUDHg8QrBke2bB0wcV9IiIiqm0MeDzA2qUlmF1leNilRURE5E4MeDxAsCwtIciGpbNLi4iIyFMY8HiAtYbHLB2lJbBLi4iIyFMY8HiAtYZHkM3Dwy4tIiIiT2HA4wG2gMdVhoddWkRERG7FgMcDBLU4obXriQcZ8BAREbkTAx5PsNTwwOU8POzSIiIicicGPB6g2KXFUVpEREQew4DHAwS1GPDA1Tw87NIiIiJyKwY8nmDN8AjM8BAREXkDAx4PsBYtg6O0iIiIvIIBjydYFw/lWlpERERewYDHA6wZHhUzPERERF7BgMcDDJpAAIDGUCTZymHpREREnsKAxwPKfIIBAL6GAvtGWZDDDA8REZE7MeDxAL1GDHj8DDr7RnZpEREReQwDHg8o8w0BAPgZCiVb2aVFRETkKQx4PMBgCXi0RhcZHnZpERERuRUDHg/QWzM8phLAZLBsZZcWERGRpzDg8QCjb7D9QZmlcJmLhxIREXkMAx4PUGn8UCgEiA+sAQ8nHiQiIvIYBjwe4KNRQQ/L8hLGcvGnLN5hwENERORODHg8QKNWwQjriums4SEiIvI0Bjwe4KNWwWDN8Jgs62lxlBYREZHHMODxAI1aBYPADA8REZG3MODxAB+1CkZbhscS8HCUFhERkccw4PEAjVpdcQ0Pu7SIiIjcigGPB/hqVDBYAx6lGh52aREREbkVAx4P8PORZHhMestWZniIiIg8hQGPB/hp1PZRWmbW8BAREXkaAx4P8NWo7aO0rF1aHKVFRETkMQx4PEDs0qogw8MuLSIiIrdiwOMBfj5qSdGy0jw87NIiIiJyJwY8HuCnURiWzlFaREREHsOAxwPko7QUanjYpUVERORWDHg8QOzSss60bBmWzlFaREREHsOAxwP8NGoYBIeiZVkNj8dPiYiIqEHxasDTpk0bqFQq2e2tt96Stdm/fz+GDBkCf39/xMTE4O2333Y6zqpVq9C5c2f4+/ujR48eWLNmjafeQpX4ahS6tDhKi4iIyGO8nuF57bXXcPHiRdvtiSeesO3T6XQYPnw4Wrdujd27d2PBggWYO3cuPv/8c1ubbdu2YezYsZg8eTL27t2L0aNHY/To0Th48KA33o4i2SgtW4ZHgl1aREREbuXj7RMIDg5GdHS04r5ly5ZBr9djyZIl8PPzQ7du3ZCamor33nsPjz76KABg4cKFGDFiBJ599lkAwOuvv47ExER8/PHHWLx4scfeR0W0sqJljtIiIiLyNK9neN566y00bdoUffr0wYIFC2A0Gm37kpOTcf3118PPz8+2LSEhAUePHsXly5dtbeLj42XHTEhIQHJyssvXLC8vh06nk93cSezSstbwcJQWERGRp3k1w/Pkk0+ib9++aNKkCbZt24ZZs2bh4sWLeO+99wAAmZmZiI2NlT0nKirKtq9x48bIzMy0bZO2yczMdPm68+fPx6uvvlrL78Y1aZeW2aQXo0yO0iIiIvKYWs/wvPDCC06FyI63tLQ0AMCMGTNw4403omfPnpgyZQreffddfPTRRygvL6/t05KZNWsWCgoKbLeMjAy3vp6fjxpGy1paZoPCauns0iIiInKrWs/wzJw5ExMnTqywTdu2bRW3Dxw4EEajEWfOnEGnTp0QHR2NrKwsWRvrY2vdj6s2ruqCAECr1UKr1Vb2VmqNr0Zlm4fHbORaWkRERJ5W6wFPREQEIiIiavTc1NRUqNVqREZGAgDi4uLw0ksvwWAwwNfXFwCQmJiITp06oXHjxrY2SUlJmD59uu04iYmJiIuLu7I3Uov8NPIuLQDybix2aREREbmV14qWk5OT8cEHH2Dfvn04deoUli1bhqeffhoPPvigLZh54IEH4Ofnh8mTJ+PQoUNYsWIFFi5ciBkzZtiO89RTT2Ht2rV49913kZaWhrlz52LXrl2YNm2at96aE5VKBUHtkOFhlxYREZHHeK1oWavVYvny5Zg7dy7Ky8sRGxuLp59+WhbMhIaG4u+//8bUqVPRr18/hIeHY/bs2bYh6QAwePBgfP/993j55Zfx4osvokOHDvj111/RvXt3b7wtl0xqsQtNc/mUGOCwS4uIiMhjvBbw9O3bF9u3b6+0Xc+ePbF58+YK24wZMwZjxoyprVNzi50+fWE0qqHN2Q/kHIU8w8MuLSIiInfy+jw8DUWBNhqnhWbig+JsTjxIRETkQQx4PCTIzweFCBAflBeC3VhERESew4DHQwL8NCgSLAFPmY4ZHiIiIg9iwOMhQX4+0CFQfFBeiKJyySKirOEhIiJyKwY8HiLL8JTrcP5yqWQvMzxERETuxIDHQwL9NCi0ZXh0DhMPMuAhIiJyJwY8HhLo5yPJ8BTKd7JLi4iIyK0Y8HhIoJ8GRbAXLavAiQeJiIg8hQGPhwT5aWRFy1xagoiIyHMY8HhIgGOXlsCZlomIiDyFAY+HBGnlRcuyLi3B5J2TIiIiaiAY8HhIsL+PbFi6LMNjZsBDRETkTgx4PCTE39e+tESZDrIaHgY8REREbsWAx0NCAnxRKEiLliXYpUVERORWDHg8JMTf1z4sXTDBxySZadls9M5JERERNRAMeDwkJMAHJdDCJKgAAH7GIvvOvFPA+jeAohwvnR0REVH95uPtE2goQvx9AahQhACEogRao6Rba/dS8efF/cC4ld44PSIionqNGR4PCfTTQKNW2YamyzI8VunbPXxWREREDQMDHg9RqVQIkQxNVwx4fP09fFZEREQNAwMeD2oWGoASaAEAvqZi5wYarYfPiIiIqGFgwONBfVqFoVgQszgaQWFklg8DHiIiIndgwONBPVqEogQVdFsx4CEiInILBjweFOzvi2IGPERERB7HgMeDtD5qlAgVBDU+AZ47GSIiogaEAY8HaX3VlWR4/Dx3MkRERA0IAx4P8tOoUSJUFPBwWDoREZE7MODxIK2vpuIMj4YZHiIiIndgwONBfho1zBX9yg//CqSneOx8iIiIGgoGPB6k9VUjUpVfcaOvR3rkXIiIiBoSBjwe5KdR45C5dcWNBJNnToaIiKgBYcDjQVpfNVabB+GsEOntUyEiImpQGPB4kFajgRlqLDUmePtUiIiIGhQGPB6k9RV/3QVCkJfPhIiIqGFhwONBfhpLwAMGPERERJ7EgMeD1GoVfDUq5Ahh3j4VIiKiBoUBj4dpfTQ4I0R5+zSIiIgaFAY8Hubno4YOjbx9GkRERA0KAx4P0/rwV05ERORpvPp6mJ8l4HkmaB7OCeFePhsiIqKGgQGPhwX5+QAA/tV3xkuGyV4+GyIiooaBAY+HtWgcAADIKSyHib9+IiIij+AV18NiGgfa7jPgISIi8gy3XXHnzZuHwYMHIzAwEGFhYYpt0tPTMWrUKAQGBiIyMhLPPvssjEajrM3GjRvRt29faLVatG/fHkuXLnU6zqJFi9CmTRv4+/tj4MCB2LFjhxveUe2IaRJgu28SGPAQERF5gtuuuHq9HmPGjMFjjz2muN9kMmHUqFHQ6/XYtm0bvvnmGyxduhSzZ8+2tTl9+jRGjRqFoUOHIjU1FdOnT8fDDz+MdevW2dqsWLECM2bMwJw5c7Bnzx706tULCQkJyM7OdtdbuyLNwyQBDzM8REREHqESBEFw5wssXboU06dPR35+vmz7X3/9hVtvvRUXLlxAVJQ4Ed/ixYvx/PPPIycnB35+fnj++eexevVqHDx40Pa8+++/H/n5+Vi7di0AYODAgbjmmmvw8ccfAwDMZjNiYmLwxBNP4IUXXqjSOep0OoSGhqKgoAAhISG18K5d23kmD2MWJwMABqqOYIX2dedGcwvceg5ERET1QXWu315LMSQnJ6NHjx62YAcAEhISoNPpcOjQIVub+Ph42fMSEhKQnCwGDHq9Hrt375a1UavViI+Pt7VRUl5eDp1OJ7t5SuNAX9t9rUrvsdclIiJqyLwW8GRmZsqCHQC2x5mZmRW20el0KC0tRW5uLkwmk2Ib6zGUzJ8/H6GhobZbTExMbbylKgkN8LPd18LgsdclIiJqyKoV8LzwwgtQqVQV3tLS0tx1rrVm1qxZKCgosN0yMjI89tphkgxPrhBa8wOd3gy82xlIW10LZ0VERFS/+VSn8cyZMzFx4sQK27Rt27ZKx4qOjnYaTZWVlWXbZ/1p3SZtExISgoCAAGg0Gmg0GsU21mMo0Wq10Gq1VTrP2uarsceYe4UOmGt4CBMGtkDsnvnVO9D/7gTMBmD5A6z5ISIiqkS1Ap6IiAhERETUygvHxcVh3rx5yM7ORmRkJAAgMTERISEh6Nq1q63NmjVrZM9LTExEXFwcAMDPzw/9+vVDUlISRo8eDUAsWk5KSsK0adNq5TzdbalpBEY1a4JYVDPgMbM7jIiIqKrcVsOTnp6O1NRUpKenw2QyITU1FampqSgqKgIADB8+HF27dsX48eOxb98+rFu3Di+//DKmTp1qy75MmTIFp06dwnPPPYe0tDR88sknWLlyJZ5++mnb68yYMQNffPEFvvnmGxw5cgSPPfYYiouLMWnSJHe9tVpnVmm8fQpERET1WrUyPNUxe/ZsfPPNN7bHffr0AQBs2LABN954IzQaDf7880889thjiIuLQ1BQECZMmIDXXnvN9pzY2FisXr0aTz/9NBYuXIiWLVviyy+/REJCgq3Nfffdh5ycHMyePRuZmZno3bs31q5d61TIXJesmhKHBWuPYseZPACACSovnxEREVH95vZ5eK4GnpyHR+qORVuxLyMfy+6KxLVrJMPvZ+cB6kqyPq82BgSzeJ81PERE1ABdFfPwEKCxJHbM1sDFyuSiPufEP0D2EcsDZoWIiIiqigGPF6lVYtAimE3yHdKC5MO/Az89DJzfA3x3N/DJIHG7qgYBj6EMKL1cw7MlIiK6ermthocqZw14DJog+Y4yHaANFu+vHC/+zDlq3y8IqFGG58M+QOEF4LnTQGCT6j+fiIjoKsUMjxepLb/9Uv8IYNR79h0luc6NSy7Z7+uLAFUNPrrCC+LPdNfLbhAREdVHDHi8yJrhMQsArpkMRHYTd0iDGytpXU/p5Zp1admOxTW8iIioYWHA40W2gMdsGShn7WYqVgh4yiULnJZerlmGx8pVUTQREVE9xYDHi1S2UVqWgCcoXPyplOExltnvl+Sh2jU80tkHmOEhIqIGhgGPF2nUki4tAAhsKv7MOyn+NBmVn+jYpfXHU8C53RW/mHToOzM8RETUwDDg8SKnLq0mloVXU38A9CXA0lHKTyzNk3dp7V4KfHlTxS9mlgRPDHiIiKiBYcDjRb6WmQd1ZZYApN9E8ae+EFh2D5CxXfmJGTvlNT1VIQt42KVFREQNCwMeL+oVEwYA2H7KUrPjFwSExoj3z251/cT9y6v/Ygx4iIioAWPA40XXthOLlPek59s3+oe658WkszmzS4uIiBoYBjxe1LJxAAAgr1gPo8lSVOwb4J4Xk2V4yt3zGkRERHUUAx4vCgv0sw22ulxiybrUZndTab79vjTgMZQ5NSUiIqrPGPB4kUatQpNAPwDApWJL1qW2gpHEOcB/WwNpa8THsoCnpHZeg4iI6CrBgMfLmjayBDxFlsyOsZYCnq0fiD/XzRJ/ygKe0tp5DSIioqsEAx4vaxqkBQDkFlkyPNIurQ7Dr/wFrDMsS4uWjQx4iIioYWHA42XWDE9OoSXgiX9V/DlwCqD2qd7BpMtHOGKGh4iIGrBqXlGptsWGBwEATuYUiRt63Qe0jgNCWgKrHqrewUx64Ng6IGWxZKM1w8OAh4iIGi4GPF7WPrIRAOB4VpF9Y1gr8Wd1MzyJc4CUT523m03AeclaWyxaJiKiBoYBj5d1iAwGAJzIKXLeqdJU72BKwQ4AbJwPbFpgf8wMDxERNTCs4fGyqBCxaDm/xGCffNCq7Q1X/gIC5MEOwICHiIgaHAY8XhYS4Gu7X1hmlO/s/SAwejFqHQMeIiJqYBjweJmvRo1AP7HryrZqupVaDfQee4WvoDByy90Bz+HfgR/GAiV57n0dIiKiKmLAUweEWrI8p3KLa//gBRnO26xFyxk7gX9erf0AaOV44Oga4N//1u5xiYiIaogBTx0Q4i8GPJO+3omfdp+r2pPuWVLzFzQbAJMR+N9oYMt7wJpnan6sihRlu+e4RERE1cSApw4wmO3Fyv8ey6nak7rdBTywCoCqZi9qLAX0lpFhe7+r2TEqo/LiP69LJ4E934qBHRERNXgMeOqAUzn2rqxgf4WZAq5/zn6/xxjg7q8AlQroOBx4IR1o0a/6L+qJwmVVDYOx2vBRX+D3J4DdX3vvHIiIqM7gPDx1TKnB5LzxppeAG54HIAAaX/k+/xBA7ev8nEpf6LL8sdkEqKs5709lvJnhscpIAQY84u2zICIiL6sDVyT6cGwf2/1yg1m5kcbHOdixCmxqv//8WeDm1yp/0XyHYmbHAKhWeDHDY1XR+mJERNRgMOCpA27v1Rxv3dUDAFCmlOGpTMI8oGkH4Nb3gYCwqmV8LuyVPy65VP3XrUxdyPAQERGBXVp1RoBlLp4yowl5xXo0DvSFqqo1ME1igSd22R+7ygRJbXhD/rg4F4joVMWzrSJv1vDUpXMgIiKv45/gdYTWRwx4tp64hL6vJ+Kdv4/W/GA1qcVxR4anLnRpERERgQFPneHvK/8oFm04WfOD1aSIeeV44MfJtVvzwniHiIjqCAY8dYS/by2OkHLs0vJrVLXnHfwROL/7yl5bGjDVhRoeFi0TEREY8NQZtRrwxDqssq6uRqlW2uore22ztOiaKR4iIqobGPDUEY5dWlckpBkw85hkg4ssh9oH6H6PfNvF1Ct7bZPefr8uFAzXhXMgIiKvY8BTRwTUZoYHAIKj7Pdddes8ewJo2V++7UJqzbuBBAE4s8X+uC50aREREYEBT51Rq11ajiI62++HxtjvBzQG/EPlbUvzgLxTQH569V8n7U/g+zE1O0ciIiI3YsBTR/j7OAc8VV453ZXJ/wCdbgHuXAxM+AMYuxzocrvDC4c5P++jvsAHPYCyguq93t5l8sfmGkyiWNtYtExERODEg3VGoNY54Jm5ah9aNQ3ENW2a1OygMdcAY38Q7zdtJ/5sfS1gNthrd7TBrp9/cR8Q0sL+XCV7vwOSXgOGzwPKC+X7zFypnIiI6ga3ZXjmzZuHwYMHIzAwEGFhYYptVCqV02358uWyNhs3bkTfvn2h1WrRvn17LF261Ok4ixYtQps2beDv74+BAwdix44dbnhH7uWrUWN6fAen7adyimr3hfxDgFsWAK0Gio9Dmrtu+81tYrZnXjMgeZHzfkEAfpsKFGUBqd8B5Tr5fgY8RERUR7gt4NHr9RgzZgwee+yxCtt9/fXXuHjxou02evRo277Tp09j1KhRGDp0KFJTUzF9+nQ8/PDDWLduna3NihUrMGPGDMyZMwd79uxBr169kJCQgOzsbHe9Nbe5tWczp216oxmCO7tlmrYD7v0f8MgG120MJcC6FwFjufN2q+JLzhkek6H2zrOmOEqLiIjgxoDn1VdfxdNPP40ePXpU2C4sLAzR0dG2m7+/v23f4sWLERsbi3fffRddunTBtGnTcM899+D999+3tXnvvffwyCOPYNKkSejatSsWL16MwMBALFmyxF1vzW0iQ/ydtr3y2yG88ttB975w19uBFn2B62ZU3C59u/3+2WRg0SD745w05xXXG1KGJ+8UkH3E22dBREQueL1oeerUqQgPD8eAAQOwZMkSWTYjOTkZ8fHxsvYJCQlITk4GIGaRdu/eLWujVqsRHx9va6OkvLwcOp1OdqsLgrXKJVXfba/6iCm90Yypy/bgu+1nq38CN86qeL80oPl6BFAgOS+zASjLl7evCwGPJ4qWBQH4sA/wySCgNN/9r0dERNXm1YDntddew8qVK5GYmIi7774bjz/+OD766CPb/szMTERFRcmeExUVBZ1Oh9LSUuTm5sJkMim2yczMdPm68+fPR2hoqO0WExPjsq0nqVQq7H3l5is6xo+7z2H1gYt4+dcaZIV8/Crery+u3vHqQsDjCYLZfr/Q9b87IiLynmoFPC+88IJiobH0lpaWVuXjvfLKK7j22mvRp08fPP/883juueewYMGCar+J6po1axYKCgpst4yMDLe/ZlU1DnIddOSX6FFmMMFsFlzW9VzIL3XXqdkDnqrW5tSFGh5PkAV2HAZPRFQXVWtY+syZMzFx4sQK27Rt27bGJzNw4EC8/vrrKC8vh1arRXR0NLKysmRtsrKyEBISgoCAAGg0Gmg0GsU20dHRLl9Hq9VCq9XW+DzdTa0CzA7XzcyCMgyan4Q+rcJQqjch2N8HK/8vDiqHotyi8ivMqgycAqQsVt6nt4wYW1tJ15dVQ8nw1IX5hoiIqELVCngiIiIQERHhrnNBamoqGjdubAtG4uLisGbNGlmbxMRExMXFAQD8/PzQr18/JCUl2UZ3mc1mJCUlYdq0aW47T3ebObwTFqw7Ktv2fYpYk7M3Pd+2rcxgRoCffP6eKw54bn4N0F0AjvwOdBoFHJUsJmoNeHZ+IX9OSEtApzBJYl0IeDwxSktgwENEVNe5beLB9PR05OXlIT09HSaTCampqQCA9u3bo1GjRvjjjz+QlZWFQYMGwd/fH4mJiXjzzTfxzDPP2I4xZcoUfPzxx3juuefwn//8B+vXr8fKlSuxerX9IjxjxgxMmDAB/fv3x4ABA/DBBx+guLgYkyZNctdbc7upQ9ujS7Ng/GfpLtu2QxecC6sLywxOAU/xlQY8Plrg3m/FEUdNYoF5kkxZcS5wcb/zc8JaKQc83urS8vTsyszwEBHVeW4LeGbPno1vvvnG9rhPnz4AgA0bNuDGG2+Er68vFi1ahKeffhqCIKB9+/a2IeZWsbGxWL16NZ5++mksXLgQLVu2xJdffomEhARbm/vuuw85OTmYPXs2MjMz0bt3b6xdu9apkPlq06tlmOxxWmahUxtdmcFpKPsVZ3gAMSsS1dV5+55vxJujYBe/a7NRDJy0wUBoyys/r6qSFhF7ZJSWh1+PKnf8H3FduJ73evtMiKiOcFvAs3TpUsVZka1GjBiBESNGVHqcG2+8EXv37q2wzbRp067qLiwlTRvJa4zOKxQj70nPR2x4I6gAqNVi14004BEEwanGxy38GgGB4UBJrnx7QYY4VBsA5lZzXa4r4emMi/T1pMEPec+yu8WfMQOAxm28eipEVDd4fR4ecu23qddWuP+5H/ej3YtrMPTdjSjVixdd608AMJhqIduQ8GblbQKbAA8nAv/5G3j2JDD0JXF7ySV7G09mPjxdUyN9Pdbz1C1FV9+M60TkHgx46rBeMWH4/pGBlbY7e6kE/x4Tv9hNkuFdBlMtZBvipgJjllbcJmYg0KStuD5XUDjQZohzG+kyFO7mzQwP63m8Txpcs4uRiCwY8NRxjrU8rpQaxAutNOAx1kaGB1BeUb3tjfb7reIc2jdybl9ewSKoJgNw6WSNTk2RNMvi6VFaDHi8T/YZMOAhIhEDnjouyMVyE45KLF1ZBrM9q6N3yPC8ueYIJizZAWN1Mz8xg5y3hbQAHv1XvAU2ke/zD3Vur3cIeDIPAvtWiH+Br3hQXJX9yJ/VOy9XPF1EbGaXVp0isKaKiJwx4LkKBDoMPVdird0pM9i/4KVdWgaTGZ9vOoV/j+Vg37lqFhBrGwETVwMqyXnozgPNe4s3R/5hztscV1JffC3wy6PAqQ3AsbXiNlcTHlZGEICcY/bAw+zhi5z0oloX5h5q6KSfAbu0iMiCAc9VYO7t3Spt8++xHABAmUFatGy/EJ+7bB/l5aOuQTdPm+uAZ44BUd3Fx93udN1WqQvMMcNjlS1ZikRdw0GDKYuBRdcAfz4tPvb0X/is4alb2KVFRAoY8FwF7u0fg3+fvRFP3tTeti00wFfWZvPxXIz/KgWFZfa/bq2jtD5MOo7py+1D+0sNNbwoB4UDk/4C7v8e6DPedTuluhlpDY80A3N2q/1+TQOeDZaRZNY5gjw9TFxWw8MMj0tmE5Cf7v7XYZcWESlgwHOVaN00CDFNAm2PV/yfc13N5uPyeXAMJjMKSg14L/GYrBurxgEPAPiHAJ1HAerKu9lkfrhPnAwOAMry7dvTJHU7NQ144BBgeXqYOOfhqZqfJgMf9AAO/eLe15F9HszwEJGIAc9VpIlkJfXGga5XVbcymMy4XKx32l6m91K3y7K7gbQ1QOll5f0aS8BzcT+w9FYgY2flxzz2N1DuUJMkq6lhhqfOsAY6W9537+uY+XkQkTMGPFcRPx/7x+XYpaXEYBJwqbjcaXuJtwIeANj2keuAx5rhWTYGOLMZ+OrmigOW8kLg+zHO2z09aoo1PNXk5qkCpEEOAx4ismDAcxVpJenS8vetvEvJYDIjp9A5w3NFXVpVNeYboPW14orrUunJQN4p5eeoNMCFVKAo07JBAP7bGtjxhXL70nzl7bIMjwfeK0dp1S3MuBGRAgY8V5HWTYPw+fh++HGKONFfZYOtDCazYoanzM0Bz/+2n8WIxCbIuvtnhWHrAnDBxdpopnJgqUOAVK4D1jyj3L7ceQV5AF7O8PACWyl3TwYp/TxMBve+Vl1i1LNm6WqVsQP4bSpQnFt5W6oxBjxXmeHdotG/jTjRn6+m4o/PaBKQq5DhsXZpCYKA4tpYXd3BK78eRFpmId5ZdxQIinBucHab8hMzdrgevr5pAfDxAKAox77NZYbHi6O0WLRcBR4MeBpKAFqUA8xvCax8yNtnQjXx1c3A3u+A1TO9fSb1GgOeq5i0pkfJrJ8P4Oe955y2lxpMyNKVIeGDTej92t84ctFFpuQKlRnNQKNI+4aIzuLPi6nKTyjKcn2w9W8AuUeBbR9KXsDFBIqe7tJy9wVWXwzs/BIoOF+7xzUZAUNZ7R6zKtyd4WmIXVr7fhAzpEd+9/aZ0JXIPebtM6jXGPBcxV61TEjYPlJh7SoAmboynL3kvGjnrjN5iH/3XxzLKoLBJOCDf9zzn0ytgjzDE1X5BIqVKpZkeKTD26Vqa5i4yQic2QIYSitu5+61tBLniH/5LRlRu8ddfB3w3zaA3oMLu3pCQ+3SIqIK1XTiE6oD7urbEte2D0dksBZHswrRsnEgPkg8hi+3nK7weTvPyEdJWbv9j2UVwlejRmx4UK2cn0alAvwkwVjMIODgT84Nu9wGHPmjagfVF9vvu8zw1FIAsult4N//iud333eu27k7w5O2WvxZUMuT9uUcEX9eTAVaD67dY3uTbJRW7Qc85UYTtD7VnIfK3TyxSC65H2uw3IoZnqtcVIg/VCoVOkeHoJHWBy/f2hVtqxmwqFTAhfxSDH9/E0Z8sAlmyYrrwpX8B1RB7MbqOBLoPQ7oPVa5XczAqh9Td94+VN1VDc8f0+33S3IBo3PhdpUkfyL+rCwYky1W6oYMjzuCKNlw/0ouloIA5J2uxS9jT3Zp1e7nseFoNjq9vBafbzpZq8clEjHgcScGPPXQS6O6yB6H+FecyCsqN2LNgYsAgHKjGboyA95em4ah72xEr1f/xmf/1uzLXa1SAWo18MByYPQn4hpb/SY6N+w4suoHzTsFLOwJ/PSw6y4taY3QpRPA5zdW/fhSqir+93D3PDxuyFLAJClmryw7sP1T4MPewNpZtfPabh+lJQnmarlL69lV+wAAb65Jq6RlFekucmQO2THD41YMeOqhYV2i8OcT19keT7w2tsL2F/PLcPC8vXsor1iPTzaexOncYujKjJj/V5ptcdLqUBw2P+K/lttblka+QHh74MGfgVZxlR+09DJQkAEcWKXcpaV0gcs+LP7MzwB+f1LMVlTpDVTxv4e7a3jccUxpwFNZxuXvl8SfKZ/W0ot7cuLB2g14avV6VF4EvNcZWNCOFzoiD2ANTz3VpVkI4rtEoVmoP4Z3jcKHScddtj1zqVi2bMXFAueROxOW7MCZt0Y5bS83mmAyCwj0c/6npFb6S97XHxg0RfwrPKQF0LyPuL39MDGQSU+uwruzUJqx2VWBsaFMLNItyxeHf87Jq/z4NcrwuKP7yQ3HNDlPV+DS1XYx9uYordLLgI8/4BtQeVudZNSdyQD4VL5cDNV3V9n/tasMA556SqNW4csJ/QGIQYmSMf1aYsPRHOQWlWPXWXvwcOZSsWJ7JTe98y8uFZcjdfZw+PtqoCuz/0WtqqjrQq0Gut4u39banpVCeMfKh2gqDdMucdE9MC/Kfl8wiYFRZRclVRULU919gXXHSCNpXVOl51zLX8Ju79KSvB9T7X4eFZ56WYE46s0vGHjReToIhaPZ75oNABjwNHhX2x8XVxl2aTUAWh8Nvp50Dd4Z00u2fdYtXdC1eYhT+zO5VQt4yo0mnM8vRZnBjONZ4oSBIz/YbNtf2UzQTsLbA2OWAmNXAI9VIdOTf9Z5W9qaqr1WYWblbWqS4blaipalGZ7qZHtqRTX+YVzcB6ya5Ho5EiWyjJsHh6VnHhB/6gur/1wOnydyOwY8DcTQTpG4p19L2+NPxvVFkyA/xRFdp10EPGazgLm/H8KyFDHQKCyzX4iNlkLR8/n2LiXFLq3KdLsT6DRCXDm9cZuK2yotLWGtN6lM1kHXS1xYGas4KZ/bJzp0w1990iCnLk/O98Uw4NDPwPIHq/6cmmTcTEZxNN6VFBBLA+Tq/qVem58BswRXMX527sSAp4F5eVQXjOgWjZu7il08bZoGOrU5lqW8vMPu9MtYuu0MXvrlIPJL9CiSBDzS4Mfqinsupu4A7vryCg/iwooHxdFb+5aLj8/vFrftXSY+PvCj61Fgjq7G1dI9neGRjpyq6B9G1mGxmNf2PEvmI/tQNV6rBhMPrhwvfv5Jr1b9dZxIu6iqEMAINTjPquDyJlcvBqtuxYCngXl4SFssHt/Ptg5X00Zapzbpecoz7z6+bI/t/pebT2PV7gzb44eW7IDeKP+irVGGR8pHC7S5turtNc7vpVKJs8Wff0wX/8L/7XHx8U+T5e0q+iKqbkZh5QTg2zsc5sKpZYWZwBc3iQXaSoyeDniqcEE/vQn4NA74YmjVjikIyiP1alJEftTSFXrwl6q1VyL9916V36ms1qgWP4O6nLEj8iIGPA3cwLZN4KdRo03TQPz0WMXDwnMK7YWuH284gUUb5PPzpGbkyx6bzLXw10pwM/t9n0qKjAPC7Pen7qza8YuyxAkMCyRFpkrBTUWTF1anhseoBw7/CpzaCOS5cfK6pNfErNVvU5X3yzI8HrhAyjIYLgLh/SvFn1VdT2jVROCtVkCWQ/anKgGo7gKw9UPnkX7Std+qrZoBj/R3UptBCgOeqxgzPO7EgKeBiwz2x+bnh+K3adehfWTwFR3LMcAx1kYGQ6UCbv0A6Doa6Dveef+gqcC9/wPuWOSwUGlHsUusKta/Ib9I6BVqmAySrNehX4BsycRz1ZmHxygZNu/OC5OrZTesTJIAribZBUEQuwOzDletfZUmOqzml/3hX8Wf2x3mB5JlTlxklr69A0h8Bfhtmvwzq60RZFUJIt215hcDnqsXu7TcisPSCVEh/rb774zphcIyA7q3CMWDX6bAT6OGWRBQrK+8NiW/RH7hNJhq6T9v/0nibcN8533XPwMENhHv73So94noVLXjp2+XF0Ar1e7oi8XXOblezCwAwFxLUFGdGh7pPEGOF7m802Lmp/c498/JIu3SqslIpqNrgF/+T7w/t5LgCpBfhGv7S93xd16VLi1rFun43w7Zu4oDngpPXVaTU5UuLYPyfVdK8wG1D6BVXizYfqyrpI6MyMMY8JCMdCTXrpfj4aNW485PtiIts/KhtpdL5F/atdKlJaVWmBcnoLFkfxX+OfuHOQc0WQfkj5UmNCzJBcJigHO7nPdVp2ZEGvAYHGqlPh0sbivNEzNIwVHA8DcqPl5Nybq0ahDwZFQxe6b0Gq5+RzX95+LYjSgt2q1K4FHV0XiVkb5HpdcVBIc6H4Py/dQfgJNJwB2f2ANfQynw39YAVMCcy86ZKLePFCTPYIbHndilRS4F+/siwE+D1pKRXG+M7u6y/Yu/yAMHg6mWi3KlX/L3fA1M+FO+re8E8WeL/q6PMXia/b6rmiClRUlXzxS7b2QLhVq+nKpTtCy9uDp2nVkDoK0fAgdWAts+cluK22y8wi6t6nabVDebcSXnIn1clYVjpZ/JlXQHVdSVtvoZ4L2u8mHvrtr/OkVcOiVVUnCen265IygHqO6e7Zs8g11absWAhyrVO8aeRbm3fwzeu7cXvv3PALx6ezc0DfJDZLDy6ChjbXVpWTWWrAnW/S4gdojDiY4DHvodePAn18do0k5yvDbKbU4mwalr4/xuYOVD8oDHGrCYq9GVIc3wKNUKAUC5JJvmaqmM6sjYARRlyzat3Zduf1CTDE91nyOtaantC/LBn4AS+1IhOQWSzFlVgjlZN+MVjJZytYaXIAA7vwAKL4j1X5W1tyq5pPw6Shkpby6nQXSVYMBDlRof1xojukXjrbt6wM9Hjbv6tsT1HSMwYXAb7Ho5Hh2jlIudXRUtv/VXGu7+dBtyi6rw17dUtzuBa6eLMzErUauBtjfIR2s5aioJeJq4WFR1y/vKxauXjgP//tf+2Nr1Jb3YVDZxXUVdWlbS4yl1ryUvAj4eIK60XRVf3QwslM+yvTXtgv1BjQIehcBg1xL7PEYVtXdZ0CsJkKvbLbP+ddvdb7dJRr9VpbtKmgWqafdWzlFg41v2x9L3K10zS7qcifTzV/wMXNQTKWWt3D3bN3kIMzzuxICHKtVI64PF4/vh/gGtnPapVCpMHNxG8XmuipYX/3sSu89extMrUqt3ImoNcPOr4kzMNSXNEkX3lO+74Xn7/apM3nZqI/Dz/wH/zLVvK65gVfnti4Fl99gfu8rwSAil9syFYJ3Jd92LQO5RcZRRVTkEV76qGq4ovm+5uOK8NDAQBKAoB/jzaXEeI8ULskINT3Ya8O1o5XqgqnRFSVmnFRAEBBXb54eqWpeWJAhVam+sQtbnsxuAC/Z5qmQBTPYR+33rpIqGMnvxO6CclXE1r49J6fcr/TwZ8Fy1GO+4FQMeumLxXaMwqG0Tp+2VFS2fyqn6IqW1YvRiwD/EvgRAt9H2ff6hwNAXxaJmq7BWwPgKJqL7fRqwf7l824U98i4pq6JsYO3z8sDDVYZHwlgkWdXdsX/fOv+MIIjDrL+7x96mkuHVfqikwNaVX/4P2PMNcPBnyUmWyUe5KWVJTAo1PCvHA6c2iBko6/uo6BgVsT53+yeY4vOH5DjSRVLNYmAmo6o4w7N9MfBmc3FSRFTwazU6dD1Kf6f5ku7Dtc+Li96ecwjyKsuySYMuxYDyCroMD/4MHFtXveeQmzDicScGPFQrBrVt6rTtcokem47lwCgpXhYkF7VaH8WlZMpWIG4a8NxpoPdYcdvjKcDDSUBkF3u7AY+KP6MkRdldRwPtbgJmSObcqYq/FTIvSpkfaYbHxV/lpmJ7HYcKgnx25suWxVN158Vs04nEyuffsfBDFeaqObcbWHav8j5pluG9LsB3d9kfGxSCFel5Wbu08jPkbaRBglLAYzbZL/auusXWvSh/LA0Ofp0CvNMeOL9H3sbgMDfSTw/bF6Fd+7wYoH1/n/LrAcoZIOl7cazFSV3mvDCtNQiUvS+VGCgby+W/b1e/G+l7qKrCLODHScD399b6zN+CIODxZbvx+LLdsv/3RN7CgIdqRYRC4fKhCzo8tGQHvt56xrZNLwl+dGUGPL5sN37de97puVfqeFYhisqNQHR3IGGefa4eQJyUsKVlJNektcBNrwA3vCA+lgZB/SaKP0Mksz1Xxe6vnbcpBSLS2g4X3VtCscPFUto1ZLA8R3px1Suvg+YoRiUpYjYZlC92X94EHK/CX/6ll4HLZ+yPHbMdAMylkvdvvSBrHOYakl7IN73j/DpfDQc+6CEGKE7dOpYLquPyItJ2+y21X8mLHF7X4VgHVgHLx8o/E0s2TvG6rbSSuzRwcazr8g+DU32ONeiUnm/Sq8A7HcTussrqjGq6npt0igaFz+1K5JcYcPZgMs4eTHaasoJcYGDoVgx4qFZ0qGCW5nlrjiAjrwRlBhPK9PYLa4nehDUHMjF9Raot25ORV4J5qw/jYkHNv3x3n83Dze9vwq0fbq68ces4cfJCjWUOn5teBm58Ebjzc3mB8/3fA1CJI8FeyhILqF3R+Dl/cSkNdd/zrX27q3qe87vlj5WyMdLFNpW606zMJnFyw79fwX3qJPv27MPAgrbAvwvEC/UvU8QC5JpS6HI5dErSrWMN2hwnV5RmWnZ95Xzc87vEpUAu7HV+DWvQF+iQabS2yzlq3xYU7tDGxb81V9ktR2l/OG+TZXgcAh61Wr6UCWD/XJWyYzlHHAIehYzSlXRpWekr72KtDpO+BKu1L2G19iUItXzs+osBjzsx4KFa0SsmtML9Q97egOvf3oAivfKXcZdX1uLIRR3Gf5WCLzafxsyV+2p8LmsOZAIAzlyqwZdsQBhw4/NAL4cujM6jgKdSgVHvAr7+wJilwKS/ZE2SVIPEOyY98GoYsPG/YuDjapFLQJxMriTPZcATcOgH+QalgEaa1Smz1NIodfkYSoH/jQa2fSjffmazmKXZ8AZw5Ddg3w9iAXJNSQMXS+CnL5aMNrNevCvK8ACuu1hMeue6o9LL4u+x8IJ8u/W1/ifpcvMLUm7j6OwW+WPL73ag6gjuVEuC6VP/Kp+jlWOGJ+cY8Muj8m3WINBV7VKlXVo1LFqWHstQuzV1KsnxVFXMPBK5E2daplqh9VGYBdlBdmE5zl5S/lLVm8z4PiXdFqTsOJ2n2K4qfDS1tB6SI8d5e8I72u7eV/4K8hCMYdrt9v0b3xRvvkFAVFfXx932EdD1jqqdg+Ms0cZyeRC0eoa4pIbSBcZYJu96UlLZsPqqOL9bPM6yu4HQVsCUzfAzSM5RXyQGQo4Bj+OcQ64yL0mvA/c4ZKBK8+WjnmzHsAQKOklGZYfDEiRVnevIkiVaobUMgc8cB0T3UJ46wGQAck+IXWHWGp6AJuIs2icSldsDrgOeyoqWazoPjzSjVFkWZttHQGhLeXaz9LJ4a9LW+ZSM9vMwe2KB2vqAXVpuxYCHak235iE4dEFXYZsL+a5H30gDlWB/+T/NvGI9TucWo1/rxth+6hK+2XYGc27rhuhQf8fDwFftocRlUDhw77eY+N1BpAhdEAGFCx8g/uV8roLV27e8V/UVwh27xi6dkAc8WQfFm+J5VOHCXhtDmlfPsN8vSAcO/wZfg0Nm6pvbKg94Ph+qfPzzu5yHsuuLgNNKmRZLcBDc3J79KXfItlV1CHzOEUw0SwLay2fEgEcpe2c2AB/3E+9b32eznmJxuVJgYQ1SXJ2LNICtLMNTnXl4pEFlRaMGs9OAv18W73e5Q+yWA4D3uon/vp/aDzRuLT+0JJgyKXXVkROT2YzK/3SkmmKXFtWad+/tBT8fNW7v1dxlm4w811+q0uLmYH9f2b5RH27G3Z9uw9YTubj/8+3462AmZv+mfGH31dj/WZcba34BFwQBJ7ILKx5N1vUObDT3BgDoEOS6nVV4J3HyxKf2AT3vt29P+7NqJ+WYTfh0cJULlas01Dv/bNWOVU1+RodzPLNZHvBsfMt5NFPuUbjk2NYh6PjSOFK8YywT/2p29TtSqZCVW8HcSVKnNuIJQTKxojU4UQp4pJk0a/dWsOX/hVJgYcvwuAhKpZk9pWkEajpKS5bhqaBLS7qvUDLhpbXbKn07HJn19mObDdWcV8kdTAbg6FrlejpvknTdFpSxuNud3BbwnDlzBpMnT0ZsbCwCAgLQrl07zJkzB3q9/D/r/v37MWTIEPj7+yMmJgZvv/2207FWrVqFzp07w9/fHz169MCaNWtk+wVBwOzZs9GsWTMEBAQgPj4ex48fd9dbIxc6R4dg/5zhWHh/b3z7nwGKbQ5frDgDZJWeV4Itx+3dKxcLxC/PNQfsX7Z/H85CXrEeu8/mYdGGE8jSiW0k8Q4KrmB0yJKtZxD/3ia89sehKrUvh+QCfuv7yo3aDRUnT2zcRlwB3pF1ZJgrRxQKZI+urdL5IeUz2cPT5ijnNllVe6/Voi+Cn0EhKJAu2rpxPlCc7dzGFeuEjH6WYnmHiSITTZL11DbOl88T5GDLgSp+Vxx0WLLk7FbgwI/Kx960wHlbcLT4UzHgsXwvusrwSAPdSmt4qhHwVDXDI33Ny6fFn9JuKo1zZ4FZkrEz14UMz9YPgB/uA76729tnIifJyAmemKqjAXNbwJOWlgaz2YzPPvsMhw4dwvvvv4/FixfjxRft82TodDoMHz4crVu3xu7du7FgwQLMnTsXn3/+ua3Ntm3bMHbsWEyePBl79+7F6NGjMXr0aBw8aP/r/u2338aHH36IxYsXIyUlBUFBQUhISEBZWR34T9bA+PtqoFKpcH3HCCy8v7fT/sTDWVU+1oNfpTjN31FulF/YZqxMxYQlO7Fg3VG8+LN4AS0z2NsMeDMJR6oYZDl6c404Q+43yRVnPWST0UVYhrV3HGnf1mYIMDkRGPIMcP1z9u3SSQ4BoPeDQMKbrpfOAIB93ztvO/aXwwYXNUw7v5A/TYhxbnOmCiPbqmvdi4jMT616+1CF83JUZPl3FNhYcfdlNLI/kC4H4shYhkZGhWBM7eu8zdGuJcBPkytvZ2UNeJQCkp1f2s5HUalC0bdUTYelV5ThEQQg9Xuxdkm6L88S8EgzWyrnjhjpArVmfe0Oea+RfZZJQs/vct6X+oNy8XlNnNslW9utUpLPS8VRWm7ltoBnxIgR+PrrrzF8+HC0bdsWt99+O5555hn8/LN9htZly5ZBr9djyZIl6NatG+6//348+eSTeO+992xtFi5ciBEjRuDZZ59Fly5d8Prrr6Nv3774+OOPAYjZnQ8++AAvv/wy7rjjDvTs2RPffvstLly4gF9//dVdb4+q4I7eLTCsc+QVHaP3a4n4NvmM7XGZQf5lvvFojjjfDoCktGzkl+hR6tDmlV8PYu3Bi9h8vIpdFxZVnRjRRy0JMB5ZDzxzXJy7587PgXbDgHu/BWIGAMNeAYIkw6ala37d8AIwepE4gqjTCODBn+ULnVZV3wlAeIcqNb0kBOMr48jKG1YkojMw+Z9Km/mZilEq+FXaDoC4HlplrMO6fZW7EfOFRorblSSYxVmUiwXJHD6SgnQAihd0Gd/Ayl/Icci8lO68OAt0rWR4alrD4xCUHPkd+PUxYNEAeZfgyfXiT9kcPs7nLevSUnpfNVnD7UqoXZSsZh8RJ6X89vYrf41TG4Evh4ldzVXFtc88xqM1PAUFBWjSxD4BXHJyMq6//nr4+dm/CBMSEnD06FFcvnzZ1iY+Pl52nISEBCQnJwMATp8+jczMTFmb0NBQDBw40NaGvOeD+3tj/l09cEdv57qeSde2qfT5BaUGfLT+hO1xZQuOns8vdQp4TuYUYcp3ezD+qx0wW4KYUzlFGPrORixLOYtvk89gxAebkK2rWUZQLU3x+AUCjSxBXq/7gPE/yyc9BGAwmbH1RC5KNZK5ixznpGk/DHhyD44Pmg8A+MM0CPmBbQAAJsFFBqfPeOCWBUCActbD0RkhGq8bxwNzC4CpFRRVuxLcDJiaAsRcU6XmO82dqnbcUe8D0xT+Cpc6YQmyipQzhsVwLmaHb5D4PofPU3zOBUEyP0+b6+Q7HUfoOXLM1inRup6rCoA4C7S0PkZK2pVZaYbHKGZuDvwo3pQIgjgj+J5v7dscu7SkM1JLA560P8XXk2Z4FIa0C5KRZYK0hsdsBn78D/BWa+DSSafnuY2rgKcw037/SoMw6wzdrj5HJczweIzHAp4TJ07go48+wv/93//ZtmVmZiIqSl5HYH2cmZlZYRvpfunzlNo4Ki8vh06nk93IPYL9fTF2QCssvL+PPBMCYM5t3fDo9W2h9VFjerzrrEROof3LcvupilPF+SUGlOnlAY90ltf7Pk/Gf5buxKINJ3E6txgv/XIQs387hLTMQrz/T83qvjTq6g2DX/jPcYz7MgVP/yRZssJFBuF87D24puwTPGF4Asv7L4fx+hdwu/4NjNW/5Nz4jo8BHy3QsoIApP3NQKdR2CT0wTemBPt26QW95TXAA6vEuYYq4uoCYvWY/A+ObeZuFbe38vGrcpYKzXsrbi6B88zfMBSLs2w7Zm8s3jfeLXY/3v2VfFVzwHlEmSNpts5lG+f15pxUZf6jw78CF1Ll8xRJMzzlOmBhT7G77afJYmBSlA2sGG+v9zrxjzgf04W99uc5dmn5aJX3mfRixkma4VEoeDZLskdmaVbq9L9iPZShWOz+qYmSPGDbx+L7qipX/16ln20Vl2ZxSVOFrlBHgjTgIXeqdsDzwgsvQKVSVXhLS5OvPXT+/HmMGDECY8aMwSOPPFJrJ19T8+fPR2hoqO0WE1OFmgG6Yv+92746+fv39QIAvHhLF+ybMxwDYqtwMaiCywpdWlI7z1zG+rRs5ChkinQ1HCGhqWShTkdfbhGXIlh7SBKQa3xRXG5EyqlLsrolg0lADsIAqFBu9kHJ4GdwSIhFsrkbXm2/0v58bYj9/tAXUdLv//Bsk4+wZcBieT1RWQEw9ntMVc2yFVkLgiDPMDXtAHQcDrSKs297TCFbWtH7nrRWnHvoFvsSEf+Y+7puDwA9xgAPSgqDm1YS9Fz/nOz4VneoP4IANf40DVJ+Xuz19hFTEqeE5sDEP4Ee9zhfHCUjxl43jEO6OUK+v/2wis8VAEJcj16slswDwOc3yCcvlHaLHFsrz3yVFaDw9+fFLqof7hOzGBdTnY/rOJJNGgg4rgVXnCMPDnKPASc3WM5FANa9hIgDkvmOpAGP9LVrOiHhz48Af78ErHjQvs1sAja/C2S4yFa6Cnikkzpe6QiumgQ8sgk2meFxp2oHPDNnzsSRI0cqvLVta5+E6sKFCxg6dCgGDx4sK0YGgOjoaGRlyVPS1sfR0dEVtpHulz5PqY2jWbNmoaCgwHbLyMhQbEe1666+LbDhmRtx8s1bcGeflrbt/r4ahAbYvyhSXqzCxcOFs5dKqlSkbFKYxddcwxESmipOdHg+vxTvJx6TFVWj70NAo2ig11jc9vEW3Pf5dmw9YR9yLV141WAyQy8p2r7sEwmMXCAW2EqzMX5BeKV0HFZdaIoHN4UA90iWaehyq9N52WqVhs8DIrsBw2aLjwPDgSbtUBLSFv/khAEzjgBTJLMPS4OG+76z34/oIi7ZAQCdbgGCm2NPy/E4Idg/c0V3fwm0l3Rfj/8FSJgvn5Rx0OPiz7hpwE0vyZf/sMhVicHzNMOT4nuwsnY7+foDTx8Cxsm7ey4JkqDR8cLVXyxOTkMbfG0aCT0c9l8j+UPO38Ws440URsUBYmARe73yvoocWGXvEpJmeE4kydsd/xvBxySr238SB6x/w/l4m98VF4wFgMyD4vGtpCu+A2LAIw0O9nwrzuJ96Bdx4snkjxGSlWLbLevSyj5iv1/RUihSJoN8Uj5rl2aG/TWw5xsg6TXgK3kJhI30M5UeS1q7pDSJZHVIi92rOjJNuMIurZK86mW6lJgMwMqHgO2LK253fo/476S6E0kWXwLmxwDvd6/1RWqro9oTD0ZERCAiIqLyhhAzO0OHDkW/fv3w9ddfQ+0wIVxcXBxeeuklGAwG+PqK/1ASExPRqVMnNG7c2NYmKSkJ06dPtz0vMTERcXHiF2psbCyio6ORlJSE3r17AxBHf6WkpOCxxx5TPC+tVgutViHlTW6lUqkQG65cZNo5OgQju0ejeVgAokL8MapHM6w+4NwPfm//lrihYySmfr9H4SjAgnUVzN0ika4wH9BfBzPxzrqj6BDVCKN62BcM1frY/93qjWbMXLUPg9o2wbiB4kRr0gyP0WSGj0b574gZK1KR4jiD9O0fAWYzjmYX41SO2C2w4/QlXNdBvFDrKwh49CYzMPBRlPd6EHvOl6K/yWybgyi7UPJl6xckBisn14tZFMhT5waTAB8NgMHTxJuVxgfG/9uKHnMSYfpuL3a+FI+IaEmQE9bKfr/LbWIQkfKZfeV5AAhtAcw8go1/HwVOnIBOCECISmHETtw0521hMUDc40COJGPc9yFg6IuAn+ui5HJoAVjqR6amiKOKDv4EdJR04anVQIebgaEvARvm4aw50pJJs+6XfDU+c1wsSm41CJN+CYAZgEH61dlvknzSPW2octeIwtBtAMDD/wDNegEfD6h47iEl2UfEoE9ae+JYi+M4s/SlCrpuf/k/4KHfgMXXyrcrBTxKF9lVExW7/wRphke6rpk1w1OmEwMSx65EQHydRQPETOWdn7o+d2uw5or0MzWW2V9LGvD88STw+BXUfqolXdNlBWJwXRlJDY8vKskyGyyzpUd0EjOsZjPwdqy478WLYg1hTRz6FTj8m3gbNMV1uy8sk4H6BlXczlFZvtjVKgj2SSu9wG2vfP78edx4441o1aoV3nnnHeTk5CAzM1NWV/PAAw/Az88PkydPxqFDh7BixQosXLgQM2bYZ2p96qmnsHbtWrz77rtIS0vD3LlzsWvXLkybJn5BqlQqTJ8+HW+88QZ+//13HDhwAA899BCaN2+O0aNHu+vtUS3TqFX49MF+eOVWcQmGeXd2x/T4Dri3vz0rMOnaNnj7nl5o0dj5S7GaZTTIyFMeJvvxhhN4anmqbEboIK0Pyo0mFJQakHg4C3/su4CXfjloGzGmkgQ8FXWnOQU7tpNX49xl+0XKJPnr02iSd29Jh+Vbg58F/5zB2C+24x1JsCcNjH7dex7mRs2APg/a6jKk56w3uv6L63yRGSbL3K/n8y2/M+vosb7j5Y1DWwLDXxcDFQd6y/u4U/+a07748reB4QoZB4gTVRb7WzK1Pv5iN5c2WN6d1mG4/X7/yVBL/zEEhYtF1SPfEudAcjRwCr5tPBV36MXlImy/C2k2oFEkoG0E9LgHepV4MS+XBjyj7KNKxfNUqPfprjz3S2lwaxgie1geKfx1X9kQfWuAdOmE6zY5R1zvc3TpOPC+wjIojsXFRTlAgYvMuMLEiNICZlmgVF4kBgYf9QO+jAf2r7QP0bdKXSZmXqxTMrgqdK5sLTCV5HInzSxJA8Tsw1XPOimeg+R7par1QJIMT6BQWnHh9A/3A58MFLstAXkdVVULpYsvAWuek8+55Tj7uBJp9ktpaH9Fy2JYfxf+Ia7beIDbAp7ExEScOHECSUlJaNmyJZo1a2a7WYWGhuLvv//G6dOn0a9fP8ycOROzZ8/Go4/a/0IcPHgwvv/+e3z++efo1asXfvzxR/z666/o3r27rc1zzz2HJ554Ao8++iiuueYaFBUVYe3atfD3r0J0TXVSWKAfpsd3xBM3dUDn6GB0jg7GYzeKF9peLUPx8HWxeO2ObhjVoxniu0ThqWHKhag1dTzb/qVXojfigS9SMGDePziVY685WLlL/MKXXntzCstxKqcISUeyYDYLeC/xmG04fHgj11nFfElh9aUi+8XBaHad4bEGP19uEedF+WzTKVlbq+krUvHL3vOy1zNLvpykWSSpLzadwg0LNtoeXy62nNd/1onzClWjG8Z6PieFFrLtd5a/KnZ1KdQDFZYZMOTtDRi0vgPMd3wiZqmUsiT3/g/4v03AnHzg1vdko+YqnVrAPwT/ht6JfIgjqEqsi9tGda/gSQ4ZHqe/WFViliQoAuh+j1jPdKdl0kdpjRKAZZe7YqG1WD7hTfFn3DSgx71igDfhd/m8THd9AQx8TMwiAWIXztxQoCjL9eg9AEWCPxJNldRQVcS64nuw5fu78KLrgEeByprhOfqXfIHX8kLg2Dpx0smsg2JtzuqZwGXL3FdF2fJlRAozgc8c/t2V5AEX94vdaVaOF19BkF/gpTN1Ow7Hzzslf2zNwOiLxSU2lJxNBvb8z2Eh3yoGPI7TCHwxVN7tZ5X6A3DKUidlDQqlQcgfT4ldkZX56T/Ajs+A5Q+IAWfuCchyvq4CrsVD7PcPrJIHhqc2ipkmpVGB6dvF7jLAdXevh7htLa2JEydi4sSJlbbr2bMnNm+ueLKzMWPGYMyYMS73q1QqvPbaa3jtNee/HunqFtMkEGuny7/gVCoVXrZkgh6KawMA+Euh++tK7MvIt90vM5ix+6z4xbL+qP2v09m/HUJksFYWhJzMKcYj34p//Tx8XawtGBk7oBX8fZX/vigqN2LmKvvq8LmSgEcvy/AoBzyNA31tI9EEQYBKpXIKYraeyMXd/ezZMmnmyNXyG/PWyL90My3D9o0BTfHZzgJch3z0iglTfK4jaQCWdtNX6LxvPsbmTMBewfVcQ9YsWyECcablSLQNdNGN5esvdglZSGMng8kMjbSbQYE0o1asNyEsEEC7m4DbPwYilRd9zRQUiuxv/xj4Zw5w12dAi37AswpZl/by+pJ3jPeibMMJPJPQSexim5Em1vqoVID+fTGzpLsof37Pe4G4qcAH8qDstNAMm/1vwqTyZXDMFk0xPI2h6lTXv4Q7PgF+e9z1fkDMNg1+AvjrOeD0JuCCcreyEsE6lP6H++U79IXK68zpLojdhIuvkxdg7/nWudD54/7OS43oLgDpyeJCp2oNsPc7e9AGAJ8MAp7cKy566tgFeOmk/d/Tr48Dx/8GHt8OrH8d2L1UnFfLcbHfnx8V142TclzoV2rtLLEOKW4qkCKvbUXmAbFrcGqKfPuv0i4kyz9y6QSHZzaLXZEj3gIGKZdzwGQQgxNA7BpbPlb8LPtJZn0vL3SaSgNGvXOA+8VNwMAp4v+V358Qg6+fJov/RqWjFpdIupK19TTDQ+RJ10hGeT04qBWeGuY8wueaNo3Rq2XV/sLYKwl4pBwLoqd8twcFpfa/iPafsz/vr4P27tsfdqTj3GXnbjRBEPDNtjOybdK5hqRFy3qTWRacWAOemCb2fntrpsixm0oA8POec0g+KV4YpAHI5eKqjU7LtCzv8fOe81iw7ijuWLQVx7IK8V7iMdvkj65Izye32Y3AE7txQFXxvDzSSSZTXXweSuT1SZUXSErblFjfh0oldtm17Kf4nHmGcTA37ydOLmnVdzzw7Ekx2JEQBAH7MvJRbD12H7ErcJx+Fsoch8+HNBMzRiqVGOwA8mJn6xxLYTFAjHwU2imhGV4rGAG8kC7v5gOwxdwDl11NxhjcDIiuOKMFQAwCoi0jLZWCnaEKUyVYdDi0EFinsL+8SL7umJXuvFgU7TjP0gaFOZQcgx1AzAL9NBnYYfl8Emc7t9n0rvjTcTHXXEmNU+oysV5p7//EYAcQsxV7/mdvIwjOwQ7gPBIufTvwbmfg8O/A9k/EkW1/PAVkKyzn4thF6Zixskb1pXlwsvYF4OtR4kzgjqTdhX6NxGAHAHZ/bd+uFKgpdYvmHhMXCv6wt7zGK0mSeHA87/rapUXkSeGNtBjSIRxNgvzw2I3tFefGWTLxGlzf0V5wHxHsuovJ1QVWNsJKwa+p9q4jYxVGI5ToTcgrltc8pGbk2xZZlV6Mi8qMssBBV2rAvox82TZrnY3BJP+iOXC+ADNW7sPYL7ZDEAQYJV09lU3maGUthD6Va6+VGP7+JnyYdBwfrT+Os5eKXS4O61h8DVQ8qh2APUAAcDzbefiyIAj4LfU8TmTLay6k9UmOvwclBqM8wyO1N/0ynl6RalunzdoyE01RPjFRnFxS/uJOx/9j/0XcsWgrHvzK8hf77R8Bz57EVnMPp7aKwtuLGZhxP8mP7zDM+pIQAgFq8aJy1+e2Yf3lPcdbzl3hF+4fKnYJVmWOoIhOQFQ3+ZxRHUcANzwvTmEwcIrYjedK8sfO204miRkUR5dOiJMT1pQ1m3P4N/Gn0mScGZYFT60ZHh9LbWD6NvGntKvpn7ny5/4+zX4xd7UG2fo3gM3v2Uc0LUkQuwJXjlduLyUt/C7NF0fAyShkeKTObhHndDIZ5MGIdJFXV1MClOQBX94MfHsH8NMjwJKR8vmaKrPLMir04n5xPiip+tqlReRpSycNgN5oRoCfBjd1jsR7iccAANe1D8f8u3og2N8XrSTZkP/e3QMfJp1AakY+erUMxb5z9j73wrJqDru0kBZDZ+kqDyR0ZQanCRkB4M/9F3HfNTGy4527XIoySYbndG4x7li0Vfa8Ixd1Tt1sAHBCEjA4npd0YkeTWcDLvx5AnxjnC4S1tqiR1rmLKPnkJXz2r1j7cGLeSKeRatLAwxr8qCuJeKTBR1aB8xDfNQcy8dTyVADAmbdG2bbL5zGqPOjUK2V4LO78RLz45Zfo8fUk+YK4poqKNCVW7BQvOHvT88UNKpVYTF0dfcZV2kQW0AQ0Frthzu/G5aDOwI4tuAyHmZ4n/AG0GYLtp/MQmFcOh0uTs+ieYjA14BEgRRy+vMr/HvTrPhJth1rWSFQaZVUTG+crbw8MBzqNFDMuVWG94OfZC52P3LQEXdb/Rwyq9CX2Gp6OCeKkjqc2il1gv02t+NjndokZuQ0uzhUAkl4VM3SdR7luo8RQIhaGN4oQh4Fbu6GszAZxIskjv1d8nL+eEzM9434Uu0wzD1TcHhCXxnBUweK7ioovAUtvdS6G1nh3dDQzPFRvaNQqBPiJF+PuLUKxdvoQpM6+Gd89PNDW7TNUsrZX87AALLy/NxY/2Bc/P34tpg1t73TMYK0PAnw1mDi4jWz71KE1WOdKwb6MfKcMDyAGKLcs3Iz/bbcvXHr4og6rdp2r8HjP/rgfA95Mso+oUjBovnyelpyicuQWlWPEB5tw96fb8MOODDz3036n5+UV63Emtxh/7neul9JJuvV2nM7DTe9uxB/77MWpBofRZQUlBllX4G+p8qJqQJ7hySpUCHgOKtdtGSTZK6XAVRAELFiXhv9Z1miTBkWOGR6rY1nOfw1XVhBtDbzcNu2Iw2i4v8wDZK8LjQ/QaqBtRNlPpiE4G3GjuK/n/UDs9cgp0uP+z7fj9s/3QIjobD9Y62uBu74UC6lVGiCstf2iPfQloEk7FPiE45UdGtzyoaQGs8D5c3zTMFa+IaSFmBWqrvu/B57aB/S6v/K2Vud3AR/IM2nlobH2WpIPe9sLf5v3tl+QKwt2AHG+n/e7AanfOe/rdIv9/m+PA/9t7dymMl+PANJTxBmxHZ1cX3mwA9i7tZbdAxz8WRb4VUtWFYqhpVaOVx75pav4+8vdmOGheqtztHN/cXgjLebc1hWZujJ0igqGSqVC66bi3EDPJHSCSRDw6Ub7l8LWWTdBBWDz8VwsldTaTBvaAYs22Ntd3zECapW4mGllfDUqW8Zj5a5zsu6l+/rHYMWuDPy0R/mLQVoXVFsy8krw4JcpSMuseDhuXokeN76zUXHfmUv2tP68NUdwKqcYT/ywFyO6R8NXo3bq0nrmx32y5z+1PBXDu0Zjzu8HcX3HCLSLaCSrC8osKMPyHek4fakYjw5pi6aNtDivUBMFyAMRpWDy0AWd7bO795oYWTbMNkrLgVIyqqKJKreeyMWTP+zFG6O7y0bESalVQHXnurxYUIrPN53ChLg2aDNsDqA7D3Pn2zDut3wkW5buKDea4e9rz8JZa73K4Ye13d/D/w2KtC26mp5n7Z5UoeihvxHsp3Ze86vjCFxCCDbvz8aons3g6x8CTNmCsR9tQVmRAZB28/YYA+xfLtYxnRfnxfnb3B+PND6KiMt7xGzHjMNi28Bw4K9nnd/kwMfE+WTa32wpXB4CdL/LHnBV1G1WidWmAQgLaiV2xR1YKdYIHbJMyqgNFrvtMp2D/WrrMx44uubKjnHpBLBkeOXtqurHSZW3qarYG8QlQlw5u1V5e2XL0bgZMzzU4Ey6NhazRnaR1XpYPXZjO/RtFYbO0cHY+MyNCPH3RbC/L0Z0i8bLo7qgV0wYFt7fGwF+GqTOvtk28mre6O64s08Lp+NZNdL6YHTv5pg6tB2OvTESa54cAo1ahfVp2dh0TAyS5tzWFfdI5h2Squ56XdWxfGdGpcEOIHahVYV0WP1Ry3GlBch6oxmJh50X/fxy8yms3HUO077fi5ELN+PP/fYM0YX8Mrzw8wF89u8pvLFaLKDMkiz2Ki3ult5fvjMd+SXyoEc66eTp3GJ5hqdcOcNj/aci7S5T6tL6NvkM/jpwEZO/2YlLxXo8tmyPy7lzg/zsX/7WQEsQBOw6k+dymZMnf9iLr7eewUNLdojdKRP+QHGvSbZgRzyW/D2USwKScqNZvLBbhtJLPyudyU95gdOm7TDz99OYviIV7/xtmffHLxBGtUL3RMI8cR22CX+gzLcxsoQwnBWi8G/vd4He48QsjdXAR4GXMmG6eR7eCH4JOwOGAJ1vBW5+VZztu3WcuBzHsyeAkW9LfnHKAY/QOBZLOy1Girkztpm6OhWPA8Bi4+0o1ZvEaQIcF5HtfKtlTiX5/7Wj5pa4ofw9rL51F+6P/B2lHR1GaCmJ7Azco1A0XIFzQjgmRv9ceUNXBlUyyk5Jh+HAmG/k2x78Geg7oeLnTfgdaCfv+vrZdB2eMM90+ZTCwBhsb/905VNFuBEzPEQSIf6++Pnxa522q9UqPDykLR4eYl82JSzQDz89Nhj+vhrENAlETJNAtGoSCF+NGmUGE2KaBOLc5VKknL6EgbFN0a+1vS6ma/MQ/Pfunpjz20EU600Y3bs5JsS1QYnBhIhgrayu5uVRXTCqZzMs3ngS3ySfRWSwFtmFVSs0rki35iG4XKzHBYX6GCVVLFmxDV8HgAv5pejWPETWJZTpYlX6o1nyoEu6UKx0QsdTOUVYsC4NFyXnrSszokmQWOgp/UL9ec95pF8qgUoF3NW3JcYOaCWrZzqWVSSrL3KV4bHWPUmP7ZjhOZpZiNm/OY+4cZUJ8pEsSXLucik6RgVjzYFMTP1+D/q2CnP6d3giuxA7z4jdL9KgzTHAKdHbfxcAoDdJR/bJ20o/C12pAS3ClGtwrJnLz/49hVkjuwBwUYMVFC6uwwbgx8G/Yd66ExCgRrFvE2D0J87tfQNwuPV4fPnHFnyJbjj+zEjbbOE2KhV2n72Mlo3FWdgR2AS47UMgbbXYteMXCEzbhQeXn8LWfZcAiCOyzjwyCtj2kdjm5HoAQDH8UWIwiQHf4GniqC9Dibh0SHC0eJubL77ulvdh/udV/G3uj7NCNKb+KNYEzmn8ON6ePE2cU2iLw6STVmFt5KuwA8BDv4szfu/5RvEpRUIAytSBwJStzjNdWz2wEmg7VJwrKPMA8PPDYoHzjDTx91KSJ2bYrPyCgeumi0PqreJfFadPAMQZ0ruNBgyLxUzX6MVAUFNxuP7e7+RrtDm6Zwnw7e3AxX3QCQF43vAoDPDBR7G9xRFqk/8BvrnVto5az7z5UP+uw/EBrg/pbgx4iK5At+byUQd9WsmLfaNC/GWBjtQ9/Vriho4RyNKVoXsL8TiNtD7Y+vxN6P3a3yjRm3BT50hbkDX39m4Y3D4cvWPCkJqRj+9T0jGqZzMs234WL97SBVmF5XjyB3E0RXyXSOw4nQddBcXXzcMC0DEq2GlSwtp0OrcYr/5xWDYS7AMXq9Ir1QYp2XeuQFZgDogXa+tF3uAQYOyyzKG088xljB3QSja1wImsQll3W3G5OKN2lq4MHaPs2Q690Yxf956XBX2OGR7pbNlS0i4ts1mwzQQtDVQy8krQMSoYq3aLc53ssRY4W1wu1iP+vU2Kxy92KLSuKMPjWMwunVFcWodVFUoZUtl5aBqhFOLkrxUVj0uD2eJyI8IC5TNVp2bk4+5Pt8FXo8LxeZbamH4TxFtRNqDSQAhsgq0nFObzGfwEMGgqTPOaw2g04LwQjjLp72fCH+KEhTfOQkGJAb4+KgRaM2/XPY2xqT2Qck4eoOfpNeLs3dE9geZ9sOmnj3G9yWHOHLVa3B/aSlz6Y/wvYpqw7Q3isPesg+ISLIYScYg6gBNCC3F+rOju4sSSjjUw105HTvQN2HfsMoZ27gRNZGexrUotBikAcOdie8Bz+0fiUiz6YnH+okaRwG0LgYjO9oDHWrPUe6x4s2oSC4z/WSz63vCmOA3B9c+KS8f0tUwiGBAGPLIBOPoXHvj2tH0yzrHLxaH8zXqKM7sbrSMc1WgS5CefCd3DGPAQeVFEsNZpeLyfjxqrnxyCRRtOYOZw+wzSKpUKCd3EZRYSukXb7t/b3168el37cPj5qNFI64O0TB0OX9Bhxkp5vUxUiBaD24XjiZvaY31ati3g6Rwd7NS19ciQWHyx+bTiub93by+s2nUOs2/ripELlScPnf+Xi5lpa5m0C6iipTKydGXYfNw+Ad2H6+XznZTojXjk213YcToPSyddI9s3Y2WqrDbGMTWf4yLrJm3WY+46rHv6evx1IFO2TIh1jqYgrf0r+ec953BnnxYoN5rR5/VE5+NagifnDI9DwKMwWaVVtk6eJXMlwFdjC0wMljXbXCwZZyOtTZP+rgRBwKrd59CrZRg6RQfLitcLy5wDnq0nci2vq5ApayQOQrigUKRvW9dOrcbG2zZj5vLdKIeffPmXlv2Blv2RV6zHsHc3IDLYH2unD7EFc0VmLQD55+pnXVvP1x/oejveXa3CkYJwJJr64ce+B4GelqkKtI2A6fvF1Kg0OJzwB2AstXUfXgrpgtNrP8LrhgcRbf09SZfnmLJVXEKk+924Y34SLhSU4a27euD+Aa2AyC7yN61SiSOyTm0Eej1gOeEgcZJFQL7WFyBmtFxpe6P4s811YtAUFA7c8IJ8tnO1BuhyKw4Kq+3bQpqJN0AM+s7Yvxsqmm3eExjwENVBseFBeGdMr8obOpB2ZXSODkHn6BAUlBrw1ZbTeGZ4J/xzJAuzbuli67po2kiLtMxCtG4SiGk3tUevV/+2XfiGdorArJFdMG5ga7RuGojswnJ8n5KOhUnH0apJIO7q2xJ39RVrjr5/ZCD+2HcRP+xQmIDNYkBsE+xQWE9sUNsmsu6rmrj9461Y8+QQ2xBwVwa+mVTh/oJSg+0cJ37tnDGQd2nZt+vKDHjhZ+Uhv9I5nYr1Jvxn6U6nUV/W+Yt8JX/9zli5D4F+GoQGKKzNBeCDpOOYcXNH54DHIeMjm6zSYR6pS5KibscMz9YTudhyIhczb+4oy1JdLtEjMthf1qWVrSvDnZ9sw519WmDm8I7ILdLDJAlQpMHPL3vP47kfxcLgM2+NQl6xPaAolnQp7km/jFW7zsmCMrNZQG5ROXw1ajSW/Fs/luVcg1ZiMCHEEpUVmAMky4c4d9P8svc8LpcYcLnEgBK9yRZ4GhWCLMcut2JNCOYbLdMGjHGoYVGpnCveNT6Axp49zO9wF+75XczQRFj/Ud31mTjBYcJ8MYtjmRjS2v389+EsMeBR0uFm8SblGOjc+Zm4fEVVlofxDbBPN+BqAVxXxnwD/P4E9mq6A3uA8EbK/5Y9hQEPUT036dpYTLpWXFF5tENhdWiAryywWvPUEKScysNtvZrb/pJtY1nhPirEH08N64DuLULRK0belTe4XTjaRTSyBTzfPzIQD3xhT/Pf2CkC/727p2LAcVfflraAp3/rxrYuKED8ggz297UVTLcIC7ANuX/4ulj8sCPdNpRcNjwawAf39UbK6TzFICzE30cxo7F8p+v1ocyCPENyMqcIrZqK0x3Md1iGoyJKQ9y/3HIaDw5qjbwSedDhqvsPAD5MOo77rolxKsp2HFovW3DWZEaJ3oiJX+9EXNumslFsujID0i+VYNoPezDlhnZ4fJk4m3Kgr0Z2jJU7MzDtpg6yLq2P1p/A+fxSfLxBzJh9vOGEbFZzaaCYdMS+PIveaJYtpVJUZsSF/FLM+f2QYmH7+fxSDH1nI5o28sP2WcNs56A0T1NJuQkh/r5OvxOlBX73pNv/zeUV620Bj0FhTgE/h4CnKj00J7IL8X7icTw5rAM6RcsLww2ygnvL76nrHcBzp52XeLBwHMSQfqkEheUGpy52l6oztP9KBDUFxn6P7RtPAkhDBDM8RFRXtGwciJb9Al3uV6tVuLlrlOK+qBB/LLy/N/RGMwa3C8fp+bdg28lL6NosxPbX+C+PD8brfx5GqyaBmHZTB0Q00kLrq7b9xf/Gnd3x+b+n8LOlm+3R68X6pTfXpGFUz2ZY9IB8AczLJQbFIfwTB7fB6D4tZN0lUn1aNUarJoGyeY6qa87vh3DoQgG+ST7rsjurOh78KsV2gbaqbPTc3Z9sc5oT6lROERZtKMRtPZtj5a4MexcMxGxP4uEs7Did55RtKyg14JONJ7D/XIEt2AGAxCPywOOdv4/hkevbykasSUfMWYMeaZ2VNMNzocDe/XQiu0gWdBWVGzHXRbADAP8cyYLRLCBLV47swnKxiBnyTJWVNFskrXMqUwh4TkiC0LxivW3eLseMGOBcrC19bOtGc/Dot7txKrcYu87mIeVF+Xpq0tnbZbVOLoIdQJzaQur6BeKiojtfird1kVsnEe3bqjHGSLq9ywwm/HXwIoZ0iPBYF9MlSw1feAWz23sCAx4iqjV39LZnkFQqFa5tL59RuE+rxoqj4DY+cyMu5Jeic3QI3ruvN6be1B7HswoxvGs09CYzujUPxaC2TZ2eN3ZAjCzg6dsqDF9OuMbWtXd9xwiEN/KzZRFu7hqFUzlFmHNbV0SH+mPlrgyUG814bkQnvL1WHHJ9XftwFJQacOB8AXq2DMX4Qa3x2aZTttFd8V2i8M+RLKTnleCdv4/JzufdMb1kC8Faj7flRC6U3Nmnha2GSqzjEYOBkd2jZXMutQgLgMksOI1wy9SVOc39ZK2bWrDuqNPrrTmQiTUHlOdy+mTjScX6p/0OBeIAcPZSiaxryLHI2pF0qgDpmnJpmTrZeyouN8mWLnG07aR93azTucX2gKdIIeCRTlwpeQ3HkXhGkxknc+QBDyDWGiktu1LiEDBJsy2v/HYI8+9yXjLE+p6UZl+XjriraMi2dLSfNMgqlXwOZy8V2wKexMNZ+GFHBn7YkSELeD5MOo5PNp5Ez5ah+H3adS5frzZZA9KmQezSIqIGrk14kK3rDADaRTRCuwhxsUt/tcYpcLLq36YJVk2Jw5ItpzG4fTjGD5LPaBsbHoQtz9+Ec5dLkFOoR1w7edC0ZOI1KDOYMKxLFAJ8Ndh/rgCvj+6ORlofHLpQgIhGWkSG+GNM/xgUlBoQ4i9+ZV6/YINs2Q8A6NosBHf3a4lAPw02Hc9BucGMW3o0w7AukUj4YBOOZRWhaZAfbuvVHEu3ncHiB/viho6RiqPkPhrbB6dzi6FRqxAW6IcgrQY95yqsOQUgKU3sInJcHqW6Kir2dnQiu0hWK1TZemzWC7nYhWVve+SiDumSSStf+Gk/WjZxnWHcfNwe3J3JLUa7iEaYt/qwrBvUSjqnknSSSscanmUp6bIMlPXiXFhudCryBpxrpKTBxw870vH6Hd0UszyunM6xB3gVrf0mnTVcuhxNnqRLUxovSWuyrAXu5/NL8YllYlWlQLaqBEGodJSe1GXLOTYOZMBDRFRj17RpgmvauE7/+/tq0D4yGO0jnfdJAylrnZOVYz1EaIC9u2nppAE4llmIoZ0jsTc9H4mHszDlRrH7bWSPZhjZo5nsud9NHojXVx/BqB7NkNAtCi+M7Gwb8bXs4YFYlnLWlnnpENkIPho1OkTJaz1u79Ucq3afw5AO4bKRZla39GhWrYBHWsfUs2VotS6ARy7qUFjuelSXo882ncJnm04hvkukbGj/6v0XZfNAFZYbZdMGOJJ2/7zw8wEMbndBlvWRkmZypFmln/ecR+foYJy5VIKUU5ecuqisRdSuuikdAybHmqAOL/+FKTe0w/MjOqMqTuXas0sVLTgs7Z6VTqWQJ8luFUpGK0ozT5dL9GjaSIvnHGY4Lyo3IshPU63gRVdmwC0LN2NIh3DMv6vSFdhk5x4a6FtJS/fiTMtERNXULqIRRvZoBn9fDeLaNcXs27oiMtjfZfvIEH98NLYPRnSPhkqlkg1vv7Z9OD4Z1w8/Pz4Yk6+LxcL7+yge4+VRXfHmnT3w+fj++GPadbLuAT8fNUZ2b4ZYS5ZseNcofDZePtPwVxP648ZO9lmKnxzWAU/c1B5v390TN3ex12VJR/o9MNA+Euiz8f1wV1+xy/Kj9SdsGYcnh3VAY4UL2cybO6JdRJBs2z+SgmUAVZ700hXHYGfydbG2EYhF5UaUGUxYdygThx2CqDfXpOH7lHSczCnGcUtXZe+YMADAgfNiW1cBT/KpSxAEARuPZmPz8RynjI8gAJ9uPGmrcRIc5mvKL9Ejp7Ac+8/lA5DPYK40Ksz2vFJpYGN/zUuSUW7S6RmkAV+OJau22yET1n3OOsTOWoO314rdoNtPXcJxhRFveqMZX24+hRPZhfhj3wWcu1yKH3a4LvB3VGApxg8L8G7AwwwPEVEd0LdVY/R1mLhSKjTQ1xaA9GgZij+fvA6PL9uDsQNa4fZezeHvq8HiB/th5a4MPHFTe4QF+uHZhE5YsTMD3VuE4IaOERjWJQrbTuZizYGLeHBQa1vgVVxuxF8HM1FqMOH3adfii02ncEvPZogO8Ud+iR49W4YhoVs0hnQIx5bjubKZvmfc3BFPDeuAglID+lrmCxo7oBWeGNYBd/VriWvfWu/0XoZ1joTWV+2ynsjq8RvboW+rxnjtz8O2WhcftUrWBSU1+bpYFJUZsWJXBp5anuq0//qOEbalXBzd2z8GqRn5+GPfBZjNQoUL8H615bRtiRNXOr+yFhMGt3HqZv1i8yl8vfUMSg0mJM24QdalVaI3ySanfD/xGI5c1OHjB/rK5hqSFrNfLpFOLWDEvox87D+Xj3zJiL/cQj0QDWh9NLIsmdUnG09iRPdo3P/5dgDA6fm34OB5HZ7/aT+eiu+A85dL8cbqI3hj9RG8dod9GZPiciMC/TROx3OUb8nwOM6x5GkqwTH8bIB0Oh1CQ0NRUFCAkBDnBSeJiOo7o8kMtUpV6Uy4BaUGLNpwAp9vOoWZN3fEE8M62PZZA4YZN3e0De3+eutpfJ+SjpE9muFYZiGyCsvw7pheCPb3xX+W7kT3FqGYf1cPlBlM2H+uAF2aBUOAWBtj7W4RBAEfrT+BLcdzMef2rnjpl4NIzcjH+EGtMbRzBL5NPou7+7bEbb2aI/FwFh75dpfTeYcF+uKnxwbj//63W7a8iNXBVxPQfc46p+0D2jSBrsyAmCaBLkeP1abuLULwx7TrYDILaP/SXwCAT8b1RVpmIT5Msk9T8NWE/li9/6JtRCMgBohLt51Bid6EYK2Prdvxg/t6Y1Dbphg0v+J5qKw2PnMjPlx/HD/vEY8t7UZtGuRnq3NKmnkD9EazbOLR0/NvkXWRCYL4PkxmAdtnDUN0qOtMaE1U5/rNgAcMeIiIquvc5RI0Cw1w68K2NWE0mfHUilSstixV0iIsAGZBwJt39sDQzmIhV5auDHd8vNU2QqxN00BsfHYoLhaUIm6+PSPVvUUI/vefgWgc5AdBEHDnJ9tkE0la9W/dGALELiOVCnh+RGe85TDL+KRr2+DrrWcUzzks0FeWkbm1ZzNMGNwGYxYnAxCPt/vsZfwjmSIgOsTf5bp0V+qD+3rjpz3nbEFOkJ/GaX4nQKw/23g0WzYbe9rrI2RdtoVlBvSwFNw77qsNDHiqiQEPEVH9YjILlQZjaw9m4sfd4kSK1hqedYcy8b/ks3j0+rYY0iFclq0oN5oweekubDmRi54tQ1GqN6HUYMJHY/ugTdMgvL3uKEb1aIbrOoTj2VX7sGq3OGVCbHgQ/npqCKYvT8XaQ87deDNv7oiconJ8m1z5vFDhjbSVjoqrzE2dI7E+LbvyhjXQKyYMs2/tgt4xjVFUZkR+qR43LNgIrY8aR98YWeuvx4CnmhjwEBFRbdKVGbDn7GX0jglDsL+vLfjadjIX05en2uqg3ru3F+7o3QLFeiO2ncjF+rRsrD2YqTgTeNMgP2x/cRiuf3sDLloKvu+/JgbhjbS2CR9v6RGN3EI9dpxRXq5l4uA2eCiuNW56999qvydfjarCofNSYYG+KCwz2qYk6N4iBH8+MaTar1kZBjzVxICHiIg8paDEgOkr9uKefjEY1bOZ036zWcAf+y/gVI44ueKLv4jrtFlrplbsTMcbq4/gtl7NMW90d6hUKpjMAsyCAF+NGrlF5fjrYCaMJjPWp2XLpjHYN2c4QgN8sXxHOvafL8D3KeLSK7f2bIZ2EY2w7lAm0jIL4atR4YmbOuBigX1E1s6X4uGrUWFvej6+TT6DDZJJL7s2C3EaDSf145Q49K9g+oiaYsBTTQx4iIiortqbfhl70/PxUFzrak1qCIhDyid/sxObj+di3p3dMW6gfNTY3vTL2HbyEv7v+rayY1u7BDMLyvDyrwdw3zWtnJaVee2Pw1iy9TQmXdsGU4e2x7fbzuBYVhH2pF9GTJNAHM0sRFG5Ef+5Nhazb+ta819ABRjwVBMDHiIiouopLjdi8/FcxHeJVAzETuUUYdvJS7i3f4xsTbfaVJ3rN+fhISIiomoL0vpgRPdol/vbRjRCW8sSMXUBZ1omIiKieo8BDxEREdV7DHiIiIio3mPAQ0RERPUeAx4iIiKq9xjwEBERUb3HgIeIiIjqPQY8REREVO8x4CEiIqJ6jwEPERER1XsMeIiIiKjeY8BDRERE9R4DHiIiIqr3uFo6AEEQAIjLzBMREdHVwXrdtl7HK8KAB0BhYSEAICYmxstnQkRERNVVWFiI0NDQCtuohKqERfWc2WzGhQsXEBwcDJVKVavH1ul0iImJQUZGBkJCQmr12FQ7+BnVbfx86j5+RnVfff2MBEFAYWEhmjdvDrW64iodZngAqNVqtGzZ0q2vERISUq/+kdVH/IzqNn4+dR8/o7qvPn5GlWV2rFi0TERERPUeAx4iIiKq9xjwuJlWq8WcOXOg1Wq9fSrkAj+juo2fT93Hz6ju42fEomUiIiJqAJjhISIionqPAQ8RERHVewx4iIiIqN5jwENERET1HgMeN1u0aBHatGkDf39/DBw4EDt27PD2KTUI8+fPxzXXXIPg4GBERkZi9OjROHr0qKxNWVkZpk6diqZNm6JRo0a4++67kZWVJWuTnp6OUaNGITAwEJGRkXj22WdhNBo9+VYahLfeegsqlQrTp0+3bePn433nz5/Hgw8+iKZNmyIgIAA9evTArl27bPsFQcDs2bPRrFkzBAQEID4+HsePH5cdIy8vD+PGjUNISAjCwsIwefJkFBUVefqt1EsmkwmvvPIKYmNjERAQgHbt2uH111+XrSvFz0hCILdZvny54OfnJyxZskQ4dOiQ8MgjjwhhYWFCVlaWt0+t3ktISBC+/vpr4eDBg0Jqaqpwyy23CK1atRKKiopsbaZMmSLExMQISUlJwq5du4RBgwYJgwcPtu03Go1C9+7dhfj4eGHv3r3CmjVrhPDwcGHWrFneeEv11o4dO4Q2bdoIPXv2FJ566inbdn4+3pWXlye0bt1amDhxopCSkiKcOnVKWLdunXDixAlbm7feeksIDQ0Vfv31V2Hfvn3C7bffLsTGxgqlpaW2NiNGjBB69eolbN++Xdi8ebPQvn17YezYsd54S/XOvHnzhKZNmwp//vmncPr0aWHVqlVCo0aNhIULF9ra8DOyY8DjRgMGDBCmTp1qe2wymYTmzZsL8+fP9+JZNUzZ2dkCAOHff/8VBEEQ8vPzBV9fX2HVqlW2NkeOHBEACMnJyYIgCMKaNWsEtVotZGZm2tp8+umnQkhIiFBeXu7ZN1BPFRYWCh06dBASExOFG264wRbw8PPxvueff1647rrrXO43m81CdHS0sGDBAtu2/Px8QavVCj/88IMgCIJw+PBhAYCwc+dOW5u//vpLUKlUwvnz59138g3EqFGjhP/85z+ybXfddZcwbtw4QRD4GTlil5ab6PV67N69G/Hx8bZtarUa8fHxSE5O9uKZNUwFBQUAgCZNmgAAdu/eDYPBIPt8OnfujFatWtk+n+TkZPTo0QNRUVG2NgkJCdDpdDh06JAHz77+mjp1KkaNGiX7HAB+PnXB77//jv79+2PMmDGIjIxEnz598MUXX9j2nz59GpmZmbLPKDQ0FAMHDpR9RmFhYejfv7+tTXx8PNRqNVJSUjz3ZuqpwYMHIykpCceOHQMA7Nu3D1u2bMHIkSMB8DNyxMVD3SQ3Nxcmk0n2ZQwAUVFRSEtL89JZNUxmsxnTp0/Htddei+7duwMAMjMz4efnh7CwMFnbqKgoZGZm2toofX7WfXRlli9fjj179mDnzp1O+/j5eN+pU6fw6aefYsaMGXjxxRexc+dOPPnkk/Dz88OECRNsv2Olz0D6GUVGRsr2+/j4oEmTJvyMasELL7wAnU6Hzp07Q6PRwGQyYd68eRg3bhwA8DNywICH6r2pU6fi4MGD2LJli7dPhSwyMjLw1FNPITExEf7+/t4+HVJgNpvRv39/vPnmmwCAPn364ODBg1i8eDEmTJjg5bMjAFi5ciWWLVuG77//Ht26dUNqaiqmT5+O5s2b8zNSwC4tNwkPD4dGo3EaVZKVlYXo6GgvnVXDM23aNPz555/YsGEDWrZsadseHR0NvV6P/Px8WXvp5xMdHa34+Vn3Uc3t3r0b2dnZ6Nu3L3x8fODj44N///0XH374IXx8fBAVFcXPx8uaNWuGrl27yrZ16dIF6enpAOy/44q+46Kjo5GdnS3bbzQakZeXx8+oFjz77LN44YUXcP/996NHjx4YP348nn76acyfPx8APyNHDHjcxM/PD/369UNSUpJtm9lsRlJSEuLi4rx4Zg2DIAiYNm0afvnlF6xfvx6xsbGy/f369YOvr6/s8zl69CjS09Ntn09cXBwOHDgg+zJITExESEiI04WAqmfYsGE4cOAAUlNTbbf+/ftj3Lhxtvv8fLzr2muvdZrK4dixY2jdujUAIDY2FtHR0bLPSKfTISUlRfYZ5efnY/fu3bY269evh9lsxsCBAz3wLuq3kpISqNXyy7hGo4HZbAbAz8iJt6um67Ply5cLWq1WWLp0qXD48GHh0UcfFcLCwmSjSsg9HnvsMSE0NFTYuHGjcPHiRdutpKTE1mbKlClCq1athPXr1wu7du0S4uLihLi4ONt+67Dn4cOHC6mpqcLatWuFiIgIDnt2E+koLUHg5+NtO3bsEHx8fIR58+YJx48fF5YtWyYEBgYK3333na3NW2+9JYSFhQm//fabsH//fuGOO+5QHPLcp08fISUlRdiyZYvQoUOHejnk2RsmTJggtGjRwjYs/eeffxbCw8OF5557ztaGn5EdAx43++ijj4RWrVoJfn5+woABA4Tt27d7+5QaBACKt6+//trWprS0VHj88ceFxo0bC4GBgcKdd94pXLx4UXacM2fOCCNHjhQCAgKE8PBwYebMmYLBYPDwu2kYHAMefj7e98cffwjdu3cXtFqt0LlzZ+Hzzz+X7TebzcIrr7wiREVFCVqtVhg2bJhw9OhRWZtLly4JY8eOFRo1aiSEhIQIkyZNEgoLCz35NuotnU4nPPXUU0KrVq0Ef39/oW3btsJLL70km5aBn5GdShAkUzISERER1UOs4SEiIqJ6jwEPERER1XsMeIiIiKjeY8BDRERE9R4DHiIiIqr3GPAQERFRvceAh4iIiOo9BjxERERU7zHgISIionqPAQ8RERHVewx4iIiIqN5jwENERET13v8DunmGFDCFVosAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.91532  validloss 5.09031±0.00000  bestvalidloss 5.09031  last_update 0\n",
      "train: iter 1  trainloss 4.53139  validloss 4.68259±0.00000  bestvalidloss 4.68259  last_update 0\n",
      "train: iter 2  trainloss 4.20627  validloss 4.32994±0.00000  bestvalidloss 4.32994  last_update 0\n",
      "train: iter 3  trainloss 3.92780  validloss 4.01329±0.00000  bestvalidloss 4.01329  last_update 0\n",
      "train: iter 4  trainloss 3.67680  validloss 3.76236±0.00000  bestvalidloss 3.76236  last_update 0\n",
      "train: iter 5  trainloss 3.45268  validloss 3.52459±0.00000  bestvalidloss 3.52459  last_update 0\n",
      "train: iter 6  trainloss 3.25671  validloss 3.33858±0.00000  bestvalidloss 3.33858  last_update 0\n",
      "train: iter 7  trainloss 3.06866  validloss 3.12936±0.00000  bestvalidloss 3.12936  last_update 0\n",
      "train: iter 8  trainloss 2.90011  validloss 2.94008±0.00000  bestvalidloss 2.94008  last_update 0\n",
      "train: iter 9  trainloss 2.74219  validloss 2.78395±0.00000  bestvalidloss 2.78395  last_update 0\n",
      "train: iter 10  trainloss 2.60202  validloss 2.63667±0.00000  bestvalidloss 2.63667  last_update 0\n",
      "train: iter 11  trainloss 2.47577  validloss 2.49841±0.00000  bestvalidloss 2.49841  last_update 0\n",
      "train: iter 12  trainloss 2.35559  validloss 2.37712±0.00000  bestvalidloss 2.37712  last_update 0\n",
      "train: iter 13  trainloss 2.25103  validloss 2.26891±0.00000  bestvalidloss 2.26891  last_update 0\n",
      "train: iter 14  trainloss 2.14961  validloss 2.16964±0.00000  bestvalidloss 2.16964  last_update 0\n",
      "train: iter 15  trainloss 2.06184  validloss 2.07635±0.00000  bestvalidloss 2.07635  last_update 0\n",
      "train: iter 16  trainloss 1.97723  validloss 1.99609±0.00000  bestvalidloss 1.99609  last_update 0\n",
      "train: iter 17  trainloss 1.89933  validloss 1.91256±0.00000  bestvalidloss 1.91256  last_update 0\n",
      "train: iter 18  trainloss 1.82707  validloss 1.83933±0.00000  bestvalidloss 1.83933  last_update 0\n",
      "train: iter 19  trainloss 1.75202  validloss 1.76806±0.00000  bestvalidloss 1.76806  last_update 0\n",
      "train: iter 20  trainloss 1.67947  validloss 1.69044±0.00000  bestvalidloss 1.69044  last_update 0\n",
      "train: iter 21  trainloss 1.61231  validloss 1.61904±0.00000  bestvalidloss 1.61904  last_update 0\n",
      "train: iter 22  trainloss 1.54284  validloss 1.53526±0.00000  bestvalidloss 1.53526  last_update 0\n",
      "train: iter 23  trainloss 1.47451  validloss 1.46943±0.00000  bestvalidloss 1.46943  last_update 0\n",
      "train: iter 24  trainloss 1.40073  validloss 1.39976±0.00000  bestvalidloss 1.39976  last_update 0\n",
      "train: iter 25  trainloss 1.33141  validloss 1.32590±0.00000  bestvalidloss 1.32590  last_update 0\n",
      "train: iter 26  trainloss 1.26192  validloss 1.24121±0.00000  bestvalidloss 1.24121  last_update 0\n",
      "train: iter 27  trainloss 1.19668  validloss 1.18059±0.00000  bestvalidloss 1.18059  last_update 0\n",
      "train: iter 28  trainloss 1.12117  validloss 1.10184±0.00000  bestvalidloss 1.10184  last_update 0\n",
      "train: iter 29  trainloss 1.04802  validloss 1.02561±0.00000  bestvalidloss 1.02561  last_update 0\n",
      "train: iter 30  trainloss 0.97824  validloss 0.94947±0.00000  bestvalidloss 0.94947  last_update 0\n",
      "train: iter 31  trainloss 0.91253  validloss 0.86009±0.00000  bestvalidloss 0.86009  last_update 0\n",
      "train: iter 32  trainloss 0.83945  validloss 0.78540±0.00000  bestvalidloss 0.78540  last_update 0\n",
      "train: iter 33  trainloss 0.75820  validloss 0.71239±0.00000  bestvalidloss 0.71239  last_update 0\n",
      "train: iter 34  trainloss 0.69487  validloss 0.63006±0.00000  bestvalidloss 0.63006  last_update 0\n",
      "train: iter 35  trainloss 0.62174  validloss 0.55597±0.00000  bestvalidloss 0.55597  last_update 0\n",
      "train: iter 36  trainloss 0.54632  validloss 0.47380±0.00000  bestvalidloss 0.47380  last_update 0\n",
      "train: iter 37  trainloss 0.47303  validloss 0.40608±0.00000  bestvalidloss 0.40608  last_update 0\n",
      "train: iter 38  trainloss 0.39090  validloss 0.31106±0.00000  bestvalidloss 0.31106  last_update 0\n",
      "train: iter 39  trainloss 0.33511  validloss 0.25477±0.00000  bestvalidloss 0.25477  last_update 0\n",
      "train: iter 40  trainloss 0.27560  validloss 0.16901±0.00000  bestvalidloss 0.16901  last_update 0\n",
      "train: iter 41  trainloss 0.21209  validloss 0.08948±0.00000  bestvalidloss 0.08948  last_update 0\n",
      "train: iter 42  trainloss 0.15006  validloss 0.02637±0.00000  bestvalidloss 0.02637  last_update 0\n",
      "train: iter 43  trainloss 0.09454  validloss -0.01973±0.00000  bestvalidloss -0.01973  last_update 0\n",
      "train: iter 44  trainloss 0.02190  validloss -0.09603±0.00000  bestvalidloss -0.09603  last_update 0\n",
      "train: iter 45  trainloss -0.01354  validloss -0.15983±0.00000  bestvalidloss -0.15983  last_update 0\n",
      "train: iter 46  trainloss -0.06363  validloss -0.22284±0.00000  bestvalidloss -0.22284  last_update 0\n",
      "train: iter 47  trainloss -0.11674  validloss -0.28278±0.00000  bestvalidloss -0.28278  last_update 0\n",
      "train: iter 48  trainloss -0.13385  validloss -0.32094±0.00000  bestvalidloss -0.32094  last_update 0\n",
      "train: iter 49  trainloss -0.20151  validloss -0.38136±0.00000  bestvalidloss -0.38136  last_update 0\n",
      "train: iter 50  trainloss -0.25135  validloss -0.41234±0.00000  bestvalidloss -0.41234  last_update 0\n",
      "train: iter 51  trainloss -0.30005  validloss -0.48709±0.00000  bestvalidloss -0.48709  last_update 0\n",
      "train: iter 52  trainloss -0.33812  validloss -0.49360±0.00000  bestvalidloss -0.49360  last_update 0\n",
      "train: iter 53  trainloss -0.37600  validloss -0.58915±0.00000  bestvalidloss -0.58915  last_update 0\n",
      "train: iter 54  trainloss -0.41974  validloss -0.60843±0.00000  bestvalidloss -0.60843  last_update 0\n",
      "train: iter 55  trainloss -0.48633  validloss -0.64741±0.00000  bestvalidloss -0.64741  last_update 0\n",
      "train: iter 56  trainloss -0.48943  validloss -0.70404±0.00000  bestvalidloss -0.70404  last_update 0\n",
      "train: iter 57  trainloss -0.52686  validloss -0.76684±0.00000  bestvalidloss -0.76684  last_update 0\n",
      "train: iter 58  trainloss -0.57213  validloss -0.78989±0.00000  bestvalidloss -0.78989  last_update 0\n",
      "train: iter 59  trainloss -0.61394  validloss -0.84703±0.00000  bestvalidloss -0.84703  last_update 0\n",
      "train: iter 60  trainloss -0.63506  validloss -0.85035±0.00000  bestvalidloss -0.85035  last_update 0\n",
      "train: iter 61  trainloss -0.66982  validloss -0.89604±0.00000  bestvalidloss -0.89604  last_update 0\n",
      "train: iter 62  trainloss -0.72846  validloss -0.95609±0.00000  bestvalidloss -0.95609  last_update 0\n",
      "train: iter 63  trainloss -0.76709  validloss -0.99020±0.00000  bestvalidloss -0.99020  last_update 0\n",
      "train: iter 64  trainloss -0.79626  validloss -1.01747±0.00000  bestvalidloss -1.01747  last_update 0\n",
      "train: iter 65  trainloss -0.82202  validloss -1.06840±0.00000  bestvalidloss -1.06840  last_update 0\n",
      "train: iter 66  trainloss -0.89387  validloss -1.11113±0.00000  bestvalidloss -1.11113  last_update 0\n",
      "train: iter 67  trainloss -0.91900  validloss -1.15275±0.00000  bestvalidloss -1.15275  last_update 0\n",
      "train: iter 68  trainloss -0.94438  validloss -1.21255±0.00000  bestvalidloss -1.21255  last_update 0\n",
      "train: iter 69  trainloss -0.95801  validloss -1.20024±0.00000  bestvalidloss -1.21255  last_update 1\n",
      "train: iter 70  trainloss -1.00515  validloss -1.28971±0.00000  bestvalidloss -1.28971  last_update 0\n",
      "train: iter 71  trainloss -1.05821  validloss -1.30881±0.00000  bestvalidloss -1.30881  last_update 0\n",
      "train: iter 72  trainloss -1.07997  validloss -1.32645±0.00000  bestvalidloss -1.32645  last_update 0\n",
      "train: iter 73  trainloss -1.11173  validloss -1.39492±0.00000  bestvalidloss -1.39492  last_update 0\n",
      "train: iter 74  trainloss -1.12135  validloss -1.42349±0.00000  bestvalidloss -1.42349  last_update 0\n",
      "train: iter 75  trainloss -1.15384  validloss -1.40808±0.00000  bestvalidloss -1.42349  last_update 1\n",
      "train: iter 76  trainloss -1.17885  validloss -1.49098±0.00000  bestvalidloss -1.49098  last_update 0\n",
      "train: iter 77  trainloss -1.22664  validloss -1.53674±0.00000  bestvalidloss -1.53674  last_update 0\n",
      "train: iter 78  trainloss -1.24717  validloss -1.54164±0.00000  bestvalidloss -1.54164  last_update 0\n",
      "train: iter 79  trainloss -1.27197  validloss -1.56333±0.00000  bestvalidloss -1.56333  last_update 0\n",
      "train: iter 80  trainloss -1.30959  validloss -1.57621±0.00000  bestvalidloss -1.57621  last_update 0\n",
      "train: iter 81  trainloss -1.32764  validloss -1.54779±0.00000  bestvalidloss -1.57621  last_update 1\n",
      "train: iter 82  trainloss -1.37422  validloss -1.63580±0.00000  bestvalidloss -1.63580  last_update 0\n",
      "train: iter 83  trainloss -1.37222  validloss -1.69345±0.00000  bestvalidloss -1.69345  last_update 0\n",
      "train: iter 84  trainloss -1.37835  validloss -1.65995±0.00000  bestvalidloss -1.69345  last_update 1\n",
      "train: iter 85  trainloss -1.39491  validloss -1.71306±0.00000  bestvalidloss -1.71306  last_update 0\n",
      "train: iter 86  trainloss -1.41811  validloss -1.72416±0.00000  bestvalidloss -1.72416  last_update 0\n",
      "train: iter 87  trainloss -1.47427  validloss -1.78013±0.00000  bestvalidloss -1.78013  last_update 0\n",
      "train: iter 88  trainloss -1.43995  validloss -1.79899±0.00000  bestvalidloss -1.79899  last_update 0\n",
      "train: iter 89  trainloss -1.46324  validloss -1.78900±0.00000  bestvalidloss -1.79899  last_update 1\n",
      "train: iter 90  trainloss -1.48180  validloss -1.83949±0.00000  bestvalidloss -1.83949  last_update 0\n",
      "train: iter 91  trainloss -1.48404  validloss -1.86628±0.00000  bestvalidloss -1.86628  last_update 0\n",
      "train: iter 92  trainloss -1.50385  validloss -1.87893±0.00000  bestvalidloss -1.87893  last_update 0\n",
      "train: iter 93  trainloss -1.50413  validloss -1.88738±0.00000  bestvalidloss -1.88738  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 94  trainloss -1.47987  validloss -1.90433±0.00000  bestvalidloss -1.90433  last_update 0\n",
      "train: iter 95  trainloss -1.50402  validloss -1.90635±0.00000  bestvalidloss -1.90635  last_update 0\n",
      "train: iter 96  trainloss -1.51270  validloss -1.85656±0.00000  bestvalidloss -1.90635  last_update 1\n",
      "train: iter 97  trainloss -1.53737  validloss -1.94487±0.00000  bestvalidloss -1.94487  last_update 0\n",
      "train: iter 98  trainloss -1.53765  validloss -1.93978±0.00000  bestvalidloss -1.94487  last_update 1\n",
      "train: iter 99  trainloss -1.57184  validloss -1.92462±0.00000  bestvalidloss -1.94487  last_update 2\n",
      "train: iter 100  trainloss -1.56029  validloss -1.99579±0.00000  bestvalidloss -1.99579  last_update 0\n",
      "train: iter 101  trainloss -1.59778  validloss -2.00026±0.00000  bestvalidloss -2.00026  last_update 0\n",
      "train: iter 102  trainloss -1.58438  validloss -1.95986±0.00000  bestvalidloss -2.00026  last_update 1\n",
      "train: iter 103  trainloss -1.57100  validloss -1.97085±0.00000  bestvalidloss -2.00026  last_update 2\n",
      "train: iter 104  trainloss -1.57799  validloss -1.98438±0.00000  bestvalidloss -2.00026  last_update 3\n",
      "train: iter 105  trainloss -1.58158  validloss -2.01406±0.00000  bestvalidloss -2.01406  last_update 0\n",
      "train: iter 106  trainloss -1.65149  validloss -2.01542±0.00000  bestvalidloss -2.01542  last_update 0\n",
      "train: iter 107  trainloss -1.57823  validloss -2.01938±0.00000  bestvalidloss -2.01938  last_update 0\n",
      "train: iter 108  trainloss -1.60311  validloss -2.00529±0.00000  bestvalidloss -2.01938  last_update 1\n",
      "train: iter 109  trainloss -1.58197  validloss -2.02325±0.00000  bestvalidloss -2.02325  last_update 0\n",
      "train: iter 110  trainloss -1.59215  validloss -1.99634±0.00000  bestvalidloss -2.02325  last_update 1\n",
      "train: iter 111  trainloss -1.56060  validloss -2.05056±0.00000  bestvalidloss -2.05056  last_update 0\n",
      "train: iter 112  trainloss -1.56624  validloss -2.00251±0.00000  bestvalidloss -2.05056  last_update 1\n",
      "train: iter 113  trainloss -1.55078  validloss -2.03324±0.00000  bestvalidloss -2.05056  last_update 2\n",
      "train: iter 114  trainloss -1.59864  validloss -1.99167±0.00000  bestvalidloss -2.05056  last_update 3\n",
      "train: iter 115  trainloss -1.61188  validloss -2.02454±0.00000  bestvalidloss -2.05056  last_update 4\n",
      "train: iter 116  trainloss -1.60950  validloss -2.04958±0.00000  bestvalidloss -2.05056  last_update 5\n",
      "train: iter 117  trainloss -1.58712  validloss -2.01290±0.00000  bestvalidloss -2.05056  last_update 6\n",
      "train: iter 118  trainloss -1.55128  validloss -2.08764±0.00000  bestvalidloss -2.08764  last_update 0\n",
      "train: iter 119  trainloss -1.60980  validloss -1.98954±0.00000  bestvalidloss -2.08764  last_update 1\n",
      "train: iter 120  trainloss -1.57758  validloss -2.07684±0.00000  bestvalidloss -2.08764  last_update 2\n",
      "train: iter 121  trainloss -1.63611  validloss -2.02281±0.00000  bestvalidloss -2.08764  last_update 3\n",
      "train: iter 122  trainloss -1.59550  validloss -2.00840±0.00000  bestvalidloss -2.08764  last_update 4\n",
      "train: iter 123  trainloss -1.60311  validloss -2.00707±0.00000  bestvalidloss -2.08764  last_update 5\n",
      "train: iter 124  trainloss -1.61355  validloss -2.00799±0.00000  bestvalidloss -2.08764  last_update 6\n",
      "train: iter 125  trainloss -1.55842  validloss -2.01590±0.00000  bestvalidloss -2.08764  last_update 7\n",
      "train: iter 126  trainloss -1.62647  validloss -2.00515±0.00000  bestvalidloss -2.08764  last_update 8\n",
      "train: iter 127  trainloss -1.58127  validloss -2.04435±0.00000  bestvalidloss -2.08764  last_update 9\n",
      "train: iter 128  trainloss -1.55054  validloss -2.01894±0.00000  bestvalidloss -2.08764  last_update 10\n",
      "train: iter 129  trainloss -1.58258  validloss -2.04753±0.00000  bestvalidloss -2.08764  last_update 11\n",
      "train: iter 130  trainloss -1.62690  validloss -2.04502±0.00000  bestvalidloss -2.08764  last_update 12\n",
      "train: iter 131  trainloss -1.58935  validloss -2.04556±0.00000  bestvalidloss -2.08764  last_update 13\n",
      "train: iter 132  trainloss -1.57211  validloss -2.09626±0.00000  bestvalidloss -2.09626  last_update 0\n",
      "train: iter 133  trainloss -1.62146  validloss -2.10283±0.00000  bestvalidloss -2.10283  last_update 0\n",
      "train: iter 134  trainloss -1.56237  validloss -2.07489±0.00000  bestvalidloss -2.10283  last_update 1\n",
      "train: iter 135  trainloss -1.56185  validloss -2.10228±0.00000  bestvalidloss -2.10283  last_update 2\n",
      "train: iter 136  trainloss -1.54939  validloss -2.03817±0.00000  bestvalidloss -2.10283  last_update 3\n",
      "train: iter 137  trainloss -1.58521  validloss -1.97111±0.00000  bestvalidloss -2.10283  last_update 4\n",
      "train: iter 138  trainloss -1.60009  validloss -2.07716±0.00000  bestvalidloss -2.10283  last_update 5\n",
      "train: iter 139  trainloss -1.57903  validloss -2.06733±0.00000  bestvalidloss -2.10283  last_update 6\n",
      "train: iter 140  trainloss -1.55682  validloss -2.01230±0.00000  bestvalidloss -2.10283  last_update 7\n",
      "train: iter 141  trainloss -1.59551  validloss -2.10876±0.00000  bestvalidloss -2.10876  last_update 0\n",
      "train: iter 142  trainloss -1.62239  validloss -2.07973±0.00000  bestvalidloss -2.10876  last_update 1\n",
      "train: iter 143  trainloss -1.57700  validloss -2.07557±0.00000  bestvalidloss -2.10876  last_update 2\n",
      "train: iter 144  trainloss -1.59750  validloss -2.05095±0.00000  bestvalidloss -2.10876  last_update 3\n",
      "train: iter 145  trainloss -1.62150  validloss -2.05603±0.00000  bestvalidloss -2.10876  last_update 4\n",
      "train: iter 146  trainloss -1.60681  validloss -1.98201±0.00000  bestvalidloss -2.10876  last_update 5\n",
      "train: iter 147  trainloss -1.57323  validloss -2.04722±0.00000  bestvalidloss -2.10876  last_update 6\n",
      "train: iter 148  trainloss -1.61113  validloss -1.94461±0.00000  bestvalidloss -2.10876  last_update 7\n",
      "train: iter 149  trainloss -1.58457  validloss -2.04415±0.00000  bestvalidloss -2.10876  last_update 8\n",
      "train: iter 150  trainloss -1.55056  validloss -2.12708±0.00000  bestvalidloss -2.12708  last_update 0\n",
      "train: iter 151  trainloss -1.56741  validloss -1.98498±0.00000  bestvalidloss -2.12708  last_update 1\n",
      "train: iter 152  trainloss -1.61147  validloss -2.09864±0.00000  bestvalidloss -2.12708  last_update 2\n",
      "train: iter 153  trainloss -1.56801  validloss -2.04071±0.00000  bestvalidloss -2.12708  last_update 3\n",
      "train: iter 154  trainloss -1.60502  validloss -2.04231±0.00000  bestvalidloss -2.12708  last_update 4\n",
      "train: iter 155  trainloss -1.60294  validloss -2.08669±0.00000  bestvalidloss -2.12708  last_update 5\n",
      "train: iter 156  trainloss -1.61680  validloss -2.08126±0.00000  bestvalidloss -2.12708  last_update 6\n",
      "train: iter 157  trainloss -1.57889  validloss -2.09362±0.00000  bestvalidloss -2.12708  last_update 7\n",
      "train: iter 158  trainloss -1.59817  validloss -2.06564±0.00000  bestvalidloss -2.12708  last_update 8\n",
      "train: iter 159  trainloss -1.57155  validloss -2.05145±0.00000  bestvalidloss -2.12708  last_update 9\n",
      "train: iter 160  trainloss -1.60649  validloss -1.99397±0.00000  bestvalidloss -2.12708  last_update 10\n",
      "train: iter 161  trainloss -1.58114  validloss -2.11508±0.00000  bestvalidloss -2.12708  last_update 11\n",
      "train: iter 162  trainloss -1.64545  validloss -2.15520±0.00000  bestvalidloss -2.15520  last_update 0\n",
      "train: iter 163  trainloss -1.59698  validloss -2.14457±0.00000  bestvalidloss -2.15520  last_update 1\n",
      "train: iter 164  trainloss -1.59717  validloss -2.09204±0.00000  bestvalidloss -2.15520  last_update 2\n",
      "train: iter 165  trainloss -1.60127  validloss -2.02434±0.00000  bestvalidloss -2.15520  last_update 3\n",
      "train: iter 166  trainloss -1.59222  validloss -2.09974±0.00000  bestvalidloss -2.15520  last_update 4\n",
      "train: iter 167  trainloss -1.58359  validloss -2.08404±0.00000  bestvalidloss -2.15520  last_update 5\n",
      "train: iter 168  trainloss -1.58509  validloss -2.06304±0.00000  bestvalidloss -2.15520  last_update 6\n",
      "train: iter 169  trainloss -1.62572  validloss -2.11770±0.00000  bestvalidloss -2.15520  last_update 7\n",
      "train: iter 170  trainloss -1.56921  validloss -2.06450±0.00000  bestvalidloss -2.15520  last_update 8\n",
      "train: iter 171  trainloss -1.56597  validloss -2.12632±0.00000  bestvalidloss -2.15520  last_update 9\n",
      "train: iter 172  trainloss -1.62423  validloss -2.07528±0.00000  bestvalidloss -2.15520  last_update 10\n",
      "train: iter 173  trainloss -1.56090  validloss -2.05481±0.00000  bestvalidloss -2.15520  last_update 11\n",
      "train: iter 174  trainloss -1.55813  validloss -2.05549±0.00000  bestvalidloss -2.15520  last_update 12\n",
      "train: iter 175  trainloss -1.57757  validloss -2.11034±0.00000  bestvalidloss -2.15520  last_update 13\n",
      "train: iter 176  trainloss -1.56283  validloss -2.05785±0.00000  bestvalidloss -2.15520  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 177  trainloss -1.57015  validloss -2.07935±0.00000  bestvalidloss -2.15520  last_update 15\n",
      "train: iter 178  trainloss -1.57887  validloss -2.09160±0.00000  bestvalidloss -2.15520  last_update 16\n",
      "train: iter 179  trainloss -1.54685  validloss -2.10355±0.00000  bestvalidloss -2.15520  last_update 17\n",
      "train: iter 180  trainloss -1.60957  validloss -2.06987±0.00000  bestvalidloss -2.15520  last_update 18\n",
      "train: iter 181  trainloss -1.56411  validloss -2.11834±0.00000  bestvalidloss -2.15520  last_update 19\n",
      "train: iter 182  trainloss -1.56057  validloss -2.08133±0.00000  bestvalidloss -2.15520  last_update 20\n",
      "train: iter 183  trainloss -1.58449  validloss -2.10412±0.00000  bestvalidloss -2.15520  last_update 21\n",
      "train: iter 184  trainloss -1.56535  validloss -2.10136±0.00000  bestvalidloss -2.15520  last_update 22\n",
      "train: iter 185  trainloss -1.56163  validloss -2.11408±0.00000  bestvalidloss -2.15520  last_update 23\n",
      "train: iter 186  trainloss -1.65247  validloss -2.07721±0.00000  bestvalidloss -2.15520  last_update 24\n",
      "train: iter 187  trainloss -1.58223  validloss -2.01096±0.00000  bestvalidloss -2.15520  last_update 25\n",
      "train: iter 188  trainloss -1.56605  validloss -2.11847±0.00000  bestvalidloss -2.15520  last_update 26\n",
      "train: iter 189  trainloss -1.66756  validloss -2.12102±0.00000  bestvalidloss -2.15520  last_update 27\n",
      "train: iter 190  trainloss -1.55679  validloss -2.09082±0.00000  bestvalidloss -2.15520  last_update 28\n",
      "train: iter 191  trainloss -1.59399  validloss -1.97600±0.00000  bestvalidloss -2.15520  last_update 29\n",
      "train: iter 192  trainloss -1.57373  validloss -2.04007±0.00000  bestvalidloss -2.15520  last_update 30\n",
      "train: iter 193  trainloss -1.57053  validloss -1.99137±0.00000  bestvalidloss -2.15520  last_update 31\n",
      "train: iter 194  trainloss -1.52019  validloss -2.03422±0.00000  bestvalidloss -2.15520  last_update 32\n",
      "train: iter 195  trainloss -1.54079  validloss -2.05689±0.00000  bestvalidloss -2.15520  last_update 33\n",
      "train: iter 196  trainloss -1.61645  validloss -2.07086±0.00000  bestvalidloss -2.15520  last_update 34\n",
      "train: iter 197  trainloss -1.54438  validloss -2.10493±0.00000  bestvalidloss -2.15520  last_update 35\n",
      "train: iter 198  trainloss -1.59610  validloss -2.00828±0.00000  bestvalidloss -2.15520  last_update 36\n",
      "train: iter 199  trainloss -1.56161  validloss -2.03400±0.00000  bestvalidloss -2.15520  last_update 37\n",
      "train: iter 200  trainloss -1.61213  validloss -2.07632±0.00000  bestvalidloss -2.15520  last_update 38\n",
      "train: iter 201  trainloss -1.54965  validloss -2.08907±0.00000  bestvalidloss -2.15520  last_update 39\n",
      "train: iter 202  trainloss -1.56326  validloss -2.01521±0.00000  bestvalidloss -2.15520  last_update 40\n",
      "train: iter 203  trainloss -1.61972  validloss -1.97096±0.00000  bestvalidloss -2.15520  last_update 41\n",
      "train: iter 204  trainloss -1.57022  validloss -2.10079±0.00000  bestvalidloss -2.15520  last_update 42\n",
      "train: iter 205  trainloss -1.61711  validloss -2.03213±0.00000  bestvalidloss -2.15520  last_update 43\n",
      "train: iter 206  trainloss -1.60932  validloss -2.08203±0.00000  bestvalidloss -2.15520  last_update 44\n",
      "train: iter 207  trainloss -1.61747  validloss -2.05623±0.00000  bestvalidloss -2.15520  last_update 45\n",
      "train: iter 208  trainloss -1.57996  validloss -1.94833±0.00000  bestvalidloss -2.15520  last_update 46\n",
      "train: iter 209  trainloss -1.63267  validloss -2.06171±0.00000  bestvalidloss -2.15520  last_update 47\n",
      "train: iter 210  trainloss -1.57534  validloss -2.00689±0.00000  bestvalidloss -2.15520  last_update 48\n",
      "train: iter 211  trainloss -1.60374  validloss -2.09737±0.00000  bestvalidloss -2.15520  last_update 49\n",
      "train: iter 212  trainloss -1.55797  validloss -2.09489±0.00000  bestvalidloss -2.15520  last_update 50\n",
      "train: iter 213  trainloss -1.57758  validloss -2.06110±0.00000  bestvalidloss -2.15520  last_update 51\n",
      "train: iter 214  trainloss -1.52461  validloss -2.05046±0.00000  bestvalidloss -2.15520  last_update 52\n",
      "train: iter 215  trainloss -1.55411  validloss -2.10010±0.00000  bestvalidloss -2.15520  last_update 53\n",
      "train: iter 216  trainloss -1.59953  validloss -2.01416±0.00000  bestvalidloss -2.15520  last_update 54\n",
      "train: iter 217  trainloss -1.57213  validloss -2.10603±0.00000  bestvalidloss -2.15520  last_update 55\n",
      "train: iter 218  trainloss -1.54522  validloss -2.11037±0.00000  bestvalidloss -2.15520  last_update 56\n",
      "train: iter 219  trainloss -1.57772  validloss -2.03357±0.00000  bestvalidloss -2.15520  last_update 57\n",
      "train: iter 220  trainloss -1.57390  validloss -2.10781±0.00000  bestvalidloss -2.15520  last_update 58\n",
      "train: iter 221  trainloss -1.55686  validloss -2.08177±0.00000  bestvalidloss -2.15520  last_update 59\n",
      "train: iter 222  trainloss -1.56409  validloss -2.00983±0.00000  bestvalidloss -2.15520  last_update 60\n",
      "train: iter 223  trainloss -1.55264  validloss -2.08110±0.00000  bestvalidloss -2.15520  last_update 61\n",
      "train: iter 224  trainloss -1.55247  validloss -2.04544±0.00000  bestvalidloss -2.15520  last_update 62\n",
      "train: iter 225  trainloss -1.60075  validloss -2.00767±0.00000  bestvalidloss -2.15520  last_update 63\n",
      "train: iter 226  trainloss -1.60166  validloss -2.02566±0.00000  bestvalidloss -2.15520  last_update 64\n",
      "train: iter 227  trainloss -1.57205  validloss -2.09904±0.00000  bestvalidloss -2.15520  last_update 65\n",
      "train: iter 228  trainloss -1.59666  validloss -2.03465±0.00000  bestvalidloss -2.15520  last_update 66\n",
      "train: iter 229  trainloss -1.61057  validloss -2.07039±0.00000  bestvalidloss -2.15520  last_update 67\n",
      "train: iter 230  trainloss -1.60447  validloss -2.04488±0.00000  bestvalidloss -2.15520  last_update 68\n",
      "train: iter 231  trainloss -1.58779  validloss -2.08337±0.00000  bestvalidloss -2.15520  last_update 69\n",
      "train: iter 232  trainloss -1.55915  validloss -1.95691±0.00000  bestvalidloss -2.15520  last_update 70\n",
      "train: iter 233  trainloss -1.63064  validloss -2.08472±0.00000  bestvalidloss -2.15520  last_update 71\n",
      "train: iter 234  trainloss -1.54632  validloss -2.07115±0.00000  bestvalidloss -2.15520  last_update 72\n",
      "train: iter 235  trainloss -1.55855  validloss -2.08418±0.00000  bestvalidloss -2.15520  last_update 73\n",
      "train: iter 236  trainloss -1.48658  validloss -1.99988±0.00000  bestvalidloss -2.15520  last_update 74\n",
      "train: iter 237  trainloss -1.62268  validloss -2.02511±0.00000  bestvalidloss -2.15520  last_update 75\n",
      "train: iter 238  trainloss -1.57326  validloss -2.05514±0.00000  bestvalidloss -2.15520  last_update 76\n",
      "train: iter 239  trainloss -1.55716  validloss -2.01275±0.00000  bestvalidloss -2.15520  last_update 77\n",
      "train: iter 240  trainloss -1.60068  validloss -2.01402±0.00000  bestvalidloss -2.15520  last_update 78\n",
      "train: iter 241  trainloss -1.53678  validloss -2.04383±0.00000  bestvalidloss -2.15520  last_update 79\n",
      "train: iter 242  trainloss -1.55989  validloss -2.04918±0.00000  bestvalidloss -2.15520  last_update 80\n",
      "train: iter 243  trainloss -1.59296  validloss -2.08975±0.00000  bestvalidloss -2.15520  last_update 81\n",
      "train: iter 244  trainloss -1.62076  validloss -2.08688±0.00000  bestvalidloss -2.15520  last_update 82\n",
      "train: iter 245  trainloss -1.62456  validloss -2.10418±0.00000  bestvalidloss -2.15520  last_update 83\n",
      "train: iter 246  trainloss -1.51579  validloss -2.04986±0.00000  bestvalidloss -2.15520  last_update 84\n",
      "train: iter 247  trainloss -1.58202  validloss -2.06811±0.00000  bestvalidloss -2.15520  last_update 85\n",
      "train: iter 248  trainloss -1.60203  validloss -2.07336±0.00000  bestvalidloss -2.15520  last_update 86\n",
      "train: iter 249  trainloss -1.61837  validloss -2.06559±0.00000  bestvalidloss -2.15520  last_update 87\n",
      "train: iter 250  trainloss -1.63948  validloss -2.05221±0.00000  bestvalidloss -2.15520  last_update 88\n",
      "train: iter 251  trainloss -1.60938  validloss -2.09784±0.00000  bestvalidloss -2.15520  last_update 89\n",
      "train: iter 252  trainloss -1.56989  validloss -2.03642±0.00000  bestvalidloss -2.15520  last_update 90\n",
      "train: iter 253  trainloss -1.60962  validloss -2.15110±0.00000  bestvalidloss -2.15520  last_update 91\n",
      "train: iter 254  trainloss -1.61030  validloss -1.97487±0.00000  bestvalidloss -2.15520  last_update 92\n",
      "train: iter 255  trainloss -1.58691  validloss -2.02493±0.00000  bestvalidloss -2.15520  last_update 93\n",
      "train: iter 256  trainloss -1.59301  validloss -1.98038±0.00000  bestvalidloss -2.15520  last_update 94\n",
      "train: iter 257  trainloss -1.53002  validloss -2.11820±0.00000  bestvalidloss -2.15520  last_update 95\n",
      "train: iter 258  trainloss -1.56660  validloss -2.07298±0.00000  bestvalidloss -2.15520  last_update 96\n",
      "train: iter 259  trainloss -1.57455  validloss -2.05969±0.00000  bestvalidloss -2.15520  last_update 97\n",
      "train: iter 260  trainloss -1.57328  validloss -2.03234±0.00000  bestvalidloss -2.15520  last_update 98\n",
      "train: iter 261  trainloss -1.57938  validloss -2.04776±0.00000  bestvalidloss -2.15520  last_update 99\n",
      "train: iter 262  trainloss -1.57914  validloss -2.01643±0.00000  bestvalidloss -2.15520  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.9801, -2.3627, -3.7935, -5.0436], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 118.78485  validloss 118.78117±0.00000  bestvalidloss 118.78117  last_update 0\n",
      "train: iter 1  trainloss 88.86262  validloss 95.03108±0.00000  bestvalidloss 95.03108  last_update 0\n",
      "train: iter 2  trainloss 66.13117  validloss 67.36862±0.00000  bestvalidloss 67.36862  last_update 0\n",
      "train: iter 3  trainloss 52.71120  validloss 51.72132±0.00000  bestvalidloss 51.72132  last_update 0\n",
      "train: iter 4  trainloss 42.33957  validloss 40.98774±0.00000  bestvalidloss 40.98774  last_update 0\n",
      "train: iter 5  trainloss 33.76975  validloss 32.82085±0.00000  bestvalidloss 32.82085  last_update 0\n",
      "train: iter 6  trainloss 26.88930  validloss 25.55366±0.00000  bestvalidloss 25.55366  last_update 0\n",
      "train: iter 7  trainloss 21.51798  validloss 20.69515±0.00000  bestvalidloss 20.69515  last_update 0\n",
      "train: iter 8  trainloss 17.24816  validloss 16.50000±0.00000  bestvalidloss 16.50000  last_update 0\n",
      "train: iter 9  trainloss 13.69832  validloss 12.96482±0.00000  bestvalidloss 12.96482  last_update 0\n",
      "train: iter 10  trainloss 10.90595  validloss 10.76118±0.00000  bestvalidloss 10.76118  last_update 0\n",
      "train: iter 11  trainloss 8.74878  validloss 8.93418±0.00000  bestvalidloss 8.93418  last_update 0\n",
      "train: iter 12  trainloss 7.00149  validloss 7.21727±0.00000  bestvalidloss 7.21727  last_update 0\n",
      "train: iter 13  trainloss 5.64273  validloss 6.18402±0.00000  bestvalidloss 6.18402  last_update 0\n",
      "train: iter 14  trainloss 4.62262  validloss 5.59637±0.00000  bestvalidloss 5.59637  last_update 0\n",
      "train: iter 15  trainloss 3.86807  validloss 4.93542±0.00000  bestvalidloss 4.93542  last_update 0\n",
      "train: iter 16  trainloss 3.28036  validloss 4.30425±0.00000  bestvalidloss 4.30425  last_update 0\n",
      "train: iter 17  trainloss 2.85984  validloss 4.07703±0.00000  bestvalidloss 4.07703  last_update 0\n",
      "train: iter 18  trainloss 2.56093  validloss 4.21302±0.00000  bestvalidloss 4.07703  last_update 1\n",
      "train: iter 19  trainloss 2.37245  validloss 4.04899±0.00000  bestvalidloss 4.04899  last_update 0\n",
      "train: iter 20  trainloss 2.19940  validloss 3.72137±0.00000  bestvalidloss 3.72137  last_update 0\n",
      "train: iter 21  trainloss 2.10056  validloss 4.12523±0.00000  bestvalidloss 3.72137  last_update 1\n",
      "train: iter 22  trainloss 2.04677  validloss 4.12055±0.00000  bestvalidloss 3.72137  last_update 2\n",
      "train: iter 23  trainloss 2.00423  validloss 4.17148±0.00000  bestvalidloss 3.72137  last_update 3\n",
      "train: iter 24  trainloss 1.96580  validloss 4.18890±0.00000  bestvalidloss 3.72137  last_update 4\n",
      "train: iter 25  trainloss 1.96581  validloss 4.36467±0.00000  bestvalidloss 3.72137  last_update 5\n",
      "train: iter 26  trainloss 1.94267  validloss 4.32118±0.00000  bestvalidloss 3.72137  last_update 6\n",
      "train: iter 27  trainloss 1.92112  validloss 4.11240±0.00000  bestvalidloss 3.72137  last_update 7\n",
      "train: iter 28  trainloss 1.91345  validloss 4.10238±0.00000  bestvalidloss 3.72137  last_update 8\n",
      "train: iter 29  trainloss 1.92015  validloss 4.19647±0.00000  bestvalidloss 3.72137  last_update 9\n",
      "train: iter 30  trainloss 1.85326  validloss 4.09069±0.00000  bestvalidloss 3.72137  last_update 10\n",
      "train: iter 31  trainloss 1.87738  validloss 4.16343±0.00000  bestvalidloss 3.72137  last_update 11\n",
      "train: iter 32  trainloss 1.82049  validloss 4.35611±0.00000  bestvalidloss 3.72137  last_update 12\n",
      "train: iter 33  trainloss 1.79505  validloss 4.61082±0.00000  bestvalidloss 3.72137  last_update 13\n",
      "train: iter 34  trainloss 1.75215  validloss 3.94033±0.00000  bestvalidloss 3.72137  last_update 14\n",
      "train: iter 35  trainloss 1.74655  validloss 3.90621±0.00000  bestvalidloss 3.72137  last_update 15\n",
      "train: iter 36  trainloss 1.70941  validloss 3.71233±0.00000  bestvalidloss 3.71233  last_update 0\n",
      "train: iter 37  trainloss 1.64275  validloss 4.14979±0.00000  bestvalidloss 3.71233  last_update 1\n",
      "train: iter 38  trainloss 1.62428  validloss 4.09978±0.00000  bestvalidloss 3.71233  last_update 2\n",
      "train: iter 39  trainloss 1.63074  validloss 3.95006±0.00000  bestvalidloss 3.71233  last_update 3\n",
      "train: iter 40  trainloss 1.64621  validloss 3.99205±0.00000  bestvalidloss 3.71233  last_update 4\n",
      "train: iter 41  trainloss 1.62232  validloss 3.70886±0.00000  bestvalidloss 3.70886  last_update 0\n",
      "train: iter 42  trainloss 1.61259  validloss 3.63140±0.00000  bestvalidloss 3.63140  last_update 0\n",
      "train: iter 43  trainloss 1.60622  validloss 3.99070±0.00000  bestvalidloss 3.63140  last_update 1\n",
      "train: iter 44  trainloss 1.59380  validloss 3.75301±0.00000  bestvalidloss 3.63140  last_update 2\n",
      "train: iter 45  trainloss 1.55073  validloss 3.55143±0.00000  bestvalidloss 3.55143  last_update 0\n",
      "train: iter 46  trainloss 1.57005  validloss 4.12380±0.00000  bestvalidloss 3.55143  last_update 1\n",
      "train: iter 47  trainloss 1.55807  validloss 3.82561±0.00000  bestvalidloss 3.55143  last_update 2\n",
      "train: iter 48  trainloss 1.53882  validloss 3.80500±0.00000  bestvalidloss 3.55143  last_update 3\n",
      "train: iter 49  trainloss 1.53564  validloss 3.90711±0.00000  bestvalidloss 3.55143  last_update 4\n",
      "train: iter 50  trainloss 1.53684  validloss 3.94372±0.00000  bestvalidloss 3.55143  last_update 5\n",
      "train: iter 51  trainloss 1.42249  validloss 3.70610±0.00000  bestvalidloss 3.55143  last_update 6\n",
      "train: iter 52  trainloss 1.37805  validloss 3.98000±0.00000  bestvalidloss 3.55143  last_update 7\n",
      "train: iter 53  trainloss 1.35060  validloss 3.48966±0.00000  bestvalidloss 3.48966  last_update 0\n",
      "train: iter 54  trainloss 1.32673  validloss 3.61765±0.00000  bestvalidloss 3.48966  last_update 1\n",
      "train: iter 55  trainloss 1.30272  validloss 3.36822±0.00000  bestvalidloss 3.36822  last_update 0\n",
      "train: iter 56  trainloss 1.30148  validloss 3.80006±0.00000  bestvalidloss 3.36822  last_update 1\n",
      "train: iter 57  trainloss 1.31386  validloss 3.82077±0.00000  bestvalidloss 3.36822  last_update 2\n",
      "train: iter 58  trainloss 1.28221  validloss 3.65280±0.00000  bestvalidloss 3.36822  last_update 3\n",
      "train: iter 59  trainloss 1.28265  validloss 3.65721±0.00000  bestvalidloss 3.36822  last_update 4\n",
      "train: iter 60  trainloss 1.28028  validloss 3.36441±0.00000  bestvalidloss 3.36441  last_update 0\n",
      "train: iter 61  trainloss 1.27926  validloss 3.57959±0.00000  bestvalidloss 3.36441  last_update 1\n",
      "train: iter 62  trainloss 1.31020  validloss 3.62585±0.00000  bestvalidloss 3.36441  last_update 2\n",
      "train: iter 63  trainloss 1.24250  validloss 3.54039±0.00000  bestvalidloss 3.36441  last_update 3\n",
      "train: iter 64  trainloss 1.25817  validloss 3.76387±0.00000  bestvalidloss 3.36441  last_update 4\n",
      "train: iter 65  trainloss 1.25460  validloss 3.75319±0.00000  bestvalidloss 3.36441  last_update 5\n",
      "train: iter 66  trainloss 1.25505  validloss 3.56640±0.00000  bestvalidloss 3.36441  last_update 6\n",
      "train: iter 67  trainloss 1.24732  validloss 3.76727±0.00000  bestvalidloss 3.36441  last_update 7\n",
      "train: iter 68  trainloss 1.25531  validloss 3.67301±0.00000  bestvalidloss 3.36441  last_update 8\n",
      "train: iter 69  trainloss 1.24829  validloss 3.51907±0.00000  bestvalidloss 3.36441  last_update 9\n",
      "train: iter 70  trainloss 1.22405  validloss 3.70334±0.00000  bestvalidloss 3.36441  last_update 10\n",
      "train: iter 71  trainloss 1.24462  validloss 3.56645±0.00000  bestvalidloss 3.36441  last_update 11\n",
      "train: iter 72  trainloss 1.25132  validloss 3.51528±0.00000  bestvalidloss 3.36441  last_update 12\n",
      "train: iter 73  trainloss 1.24487  validloss 3.51026±0.00000  bestvalidloss 3.36441  last_update 13\n",
      "train: iter 74  trainloss 1.23295  validloss 3.56273±0.00000  bestvalidloss 3.36441  last_update 14\n",
      "train: iter 75  trainloss 1.25589  validloss 3.40460±0.00000  bestvalidloss 3.36441  last_update 15\n",
      "train: iter 76  trainloss 1.25133  validloss 4.07734±0.00000  bestvalidloss 3.36441  last_update 16\n",
      "train: iter 77  trainloss 1.23320  validloss 3.54613±0.00000  bestvalidloss 3.36441  last_update 17\n",
      "train: iter 78  trainloss 1.20589  validloss 3.50686±0.00000  bestvalidloss 3.36441  last_update 18\n",
      "train: iter 79  trainloss 1.22544  validloss 3.50342±0.00000  bestvalidloss 3.36441  last_update 19\n",
      "train: iter 80  trainloss 1.20769  validloss 3.89368±0.00000  bestvalidloss 3.36441  last_update 20\n",
      "train: iter 81  trainloss 1.24447  validloss 3.37689±0.00000  bestvalidloss 3.36441  last_update 21\n",
      "train: iter 82  trainloss 1.19899  validloss 3.47254±0.00000  bestvalidloss 3.36441  last_update 22\n",
      "train: iter 83  trainloss 1.20379  validloss 3.82774±0.00000  bestvalidloss 3.36441  last_update 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 1.20860  validloss 3.59824±0.00000  bestvalidloss 3.36441  last_update 24\n",
      "train: iter 85  trainloss 1.21268  validloss 3.68300±0.00000  bestvalidloss 3.36441  last_update 25\n",
      "train: iter 86  trainloss 1.20820  validloss 3.57515±0.00000  bestvalidloss 3.36441  last_update 26\n",
      "train: iter 87  trainloss 1.19269  validloss 3.72783±0.00000  bestvalidloss 3.36441  last_update 27\n",
      "train: iter 88  trainloss 1.21494  validloss 3.87455±0.00000  bestvalidloss 3.36441  last_update 28\n",
      "train: iter 89  trainloss 1.20347  validloss 3.37695±0.00000  bestvalidloss 3.36441  last_update 29\n",
      "train: iter 90  trainloss 1.17408  validloss 3.54998±0.00000  bestvalidloss 3.36441  last_update 30\n",
      "train: iter 91  trainloss 1.21167  validloss 3.49677±0.00000  bestvalidloss 3.36441  last_update 31\n",
      "train: iter 92  trainloss 1.15090  validloss 3.51403±0.00000  bestvalidloss 3.36441  last_update 32\n",
      "train: iter 93  trainloss 1.18244  validloss 3.32126±0.00000  bestvalidloss 3.32126  last_update 0\n",
      "train: iter 94  trainloss 1.19701  validloss 3.46741±0.00000  bestvalidloss 3.32126  last_update 1\n",
      "train: iter 95  trainloss 1.17590  validloss 3.34756±0.00000  bestvalidloss 3.32126  last_update 2\n",
      "train: iter 96  trainloss 1.15107  validloss 3.25635±0.00000  bestvalidloss 3.25635  last_update 0\n",
      "train: iter 97  trainloss 1.19110  validloss 3.43476±0.00000  bestvalidloss 3.25635  last_update 1\n",
      "train: iter 98  trainloss 1.18615  validloss 3.48112±0.00000  bestvalidloss 3.25635  last_update 2\n",
      "train: iter 99  trainloss 1.21861  validloss 3.42684±0.00000  bestvalidloss 3.25635  last_update 3\n",
      "train: iter 100  trainloss 1.17118  validloss 3.41692±0.00000  bestvalidloss 3.25635  last_update 4\n",
      "train: iter 101  trainloss 1.15529  validloss 3.23390±0.00000  bestvalidloss 3.23390  last_update 0\n",
      "train: iter 102  trainloss 1.16410  validloss 3.76920±0.00000  bestvalidloss 3.23390  last_update 1\n",
      "train: iter 103  trainloss 1.14360  validloss 3.50191±0.00000  bestvalidloss 3.23390  last_update 2\n",
      "train: iter 104  trainloss 1.16679  validloss 3.22065±0.00000  bestvalidloss 3.22065  last_update 0\n",
      "train: iter 105  trainloss 1.15326  validloss 3.68957±0.00000  bestvalidloss 3.22065  last_update 1\n",
      "train: iter 106  trainloss 1.15640  validloss 3.68693±0.00000  bestvalidloss 3.22065  last_update 2\n",
      "train: iter 107  trainloss 1.18951  validloss 3.33616±0.00000  bestvalidloss 3.22065  last_update 3\n",
      "train: iter 108  trainloss 1.15044  validloss 3.56021±0.00000  bestvalidloss 3.22065  last_update 4\n",
      "train: iter 109  trainloss 1.13284  validloss 3.33930±0.00000  bestvalidloss 3.22065  last_update 5\n",
      "train: iter 110  trainloss 1.14323  validloss 3.61323±0.00000  bestvalidloss 3.22065  last_update 6\n",
      "train: iter 111  trainloss 1.17463  validloss 3.61258±0.00000  bestvalidloss 3.22065  last_update 7\n",
      "train: iter 112  trainloss 1.15806  validloss 3.17578±0.00000  bestvalidloss 3.17578  last_update 0\n",
      "train: iter 113  trainloss 1.15149  validloss 3.31005±0.00000  bestvalidloss 3.17578  last_update 1\n",
      "train: iter 114  trainloss 1.15481  validloss 3.38676±0.00000  bestvalidloss 3.17578  last_update 2\n",
      "train: iter 115  trainloss 1.15516  validloss 3.43843±0.00000  bestvalidloss 3.17578  last_update 3\n",
      "train: iter 116  trainloss 1.16009  validloss 3.83090±0.00000  bestvalidloss 3.17578  last_update 4\n",
      "train: iter 117  trainloss 1.14680  validloss 3.29978±0.00000  bestvalidloss 3.17578  last_update 5\n",
      "train: iter 118  trainloss 1.13687  validloss 3.38358±0.00000  bestvalidloss 3.17578  last_update 6\n",
      "train: iter 119  trainloss 1.14816  validloss 3.21758±0.00000  bestvalidloss 3.17578  last_update 7\n",
      "train: iter 120  trainloss 1.13894  validloss 3.38102±0.00000  bestvalidloss 3.17578  last_update 8\n",
      "train: iter 121  trainloss 1.12620  validloss 3.47732±0.00000  bestvalidloss 3.17578  last_update 9\n",
      "train: iter 122  trainloss 1.17019  validloss 3.48908±0.00000  bestvalidloss 3.17578  last_update 10\n",
      "train: iter 123  trainloss 1.18233  validloss 3.50136±0.00000  bestvalidloss 3.17578  last_update 11\n",
      "train: iter 124  trainloss 1.13256  validloss 3.43720±0.00000  bestvalidloss 3.17578  last_update 12\n",
      "train: iter 125  trainloss 1.12394  validloss 3.69331±0.00000  bestvalidloss 3.17578  last_update 13\n",
      "train: iter 126  trainloss 1.12045  validloss 3.24779±0.00000  bestvalidloss 3.17578  last_update 14\n",
      "train: iter 127  trainloss 1.12204  validloss 3.32931±0.00000  bestvalidloss 3.17578  last_update 15\n",
      "train: iter 128  trainloss 1.15182  validloss 3.77376±0.00000  bestvalidloss 3.17578  last_update 16\n",
      "train: iter 129  trainloss 1.13403  validloss 3.31211±0.00000  bestvalidloss 3.17578  last_update 17\n",
      "train: iter 130  trainloss 1.14062  validloss 3.49215±0.00000  bestvalidloss 3.17578  last_update 18\n",
      "train: iter 131  trainloss 1.15279  validloss 3.29593±0.00000  bestvalidloss 3.17578  last_update 19\n",
      "train: iter 132  trainloss 1.11546  validloss 3.18173±0.00000  bestvalidloss 3.17578  last_update 20\n",
      "train: iter 133  trainloss 1.11547  validloss 3.50053±0.00000  bestvalidloss 3.17578  last_update 21\n",
      "train: iter 134  trainloss 1.09469  validloss 3.61319±0.00000  bestvalidloss 3.17578  last_update 22\n",
      "train: iter 135  trainloss 1.13718  validloss 3.29656±0.00000  bestvalidloss 3.17578  last_update 23\n",
      "train: iter 136  trainloss 1.10322  validloss 3.99319±0.00000  bestvalidloss 3.17578  last_update 24\n",
      "train: iter 137  trainloss 1.13295  validloss 3.51441±0.00000  bestvalidloss 3.17578  last_update 25\n",
      "train: iter 138  trainloss 1.14741  validloss 3.50434±0.00000  bestvalidloss 3.17578  last_update 26\n",
      "train: iter 139  trainloss 1.14208  validloss 3.68156±0.00000  bestvalidloss 3.17578  last_update 27\n",
      "train: iter 140  trainloss 1.11563  validloss 3.45736±0.00000  bestvalidloss 3.17578  last_update 28\n",
      "train: iter 141  trainloss 1.10710  validloss 3.33414±0.00000  bestvalidloss 3.17578  last_update 29\n",
      "train: iter 142  trainloss 1.11631  validloss 3.22418±0.00000  bestvalidloss 3.17578  last_update 30\n",
      "train: iter 143  trainloss 1.14796  validloss 3.45866±0.00000  bestvalidloss 3.17578  last_update 31\n",
      "train: iter 144  trainloss 1.12564  validloss 3.32711±0.00000  bestvalidloss 3.17578  last_update 32\n",
      "train: iter 145  trainloss 1.13295  validloss 3.65566±0.00000  bestvalidloss 3.17578  last_update 33\n",
      "train: iter 146  trainloss 1.12402  validloss 3.40421±0.00000  bestvalidloss 3.17578  last_update 34\n",
      "train: iter 147  trainloss 1.11069  validloss 3.40380±0.00000  bestvalidloss 3.17578  last_update 35\n",
      "train: iter 148  trainloss 1.12690  validloss 3.45084±0.00000  bestvalidloss 3.17578  last_update 36\n",
      "train: iter 149  trainloss 1.12543  validloss 3.80592±0.00000  bestvalidloss 3.17578  last_update 37\n",
      "train: iter 150  trainloss 1.12151  validloss 3.16995±0.00000  bestvalidloss 3.16995  last_update 0\n",
      "train: iter 151  trainloss 1.13565  validloss 3.30030±0.00000  bestvalidloss 3.16995  last_update 1\n",
      "train: iter 152  trainloss 1.10765  validloss 3.36371±0.00000  bestvalidloss 3.16995  last_update 2\n",
      "train: iter 153  trainloss 1.12229  validloss 3.53709±0.00000  bestvalidloss 3.16995  last_update 3\n",
      "train: iter 154  trainloss 1.10765  validloss 3.54092±0.00000  bestvalidloss 3.16995  last_update 4\n",
      "train: iter 155  trainloss 1.10093  validloss 3.98509±0.00000  bestvalidloss 3.16995  last_update 5\n",
      "train: iter 156  trainloss 1.14074  validloss 3.43042±0.00000  bestvalidloss 3.16995  last_update 6\n",
      "train: iter 157  trainloss 1.17562  validloss 3.61745±0.00000  bestvalidloss 3.16995  last_update 7\n",
      "train: iter 158  trainloss 1.13109  validloss 3.14066±0.00000  bestvalidloss 3.14066  last_update 0\n",
      "train: iter 159  trainloss 1.14481  validloss 3.51615±0.00000  bestvalidloss 3.14066  last_update 1\n",
      "train: iter 160  trainloss 1.11565  validloss 3.37108±0.00000  bestvalidloss 3.14066  last_update 2\n",
      "train: iter 161  trainloss 1.13693  validloss 3.35259±0.00000  bestvalidloss 3.14066  last_update 3\n",
      "train: iter 162  trainloss 1.10246  validloss 3.61390±0.00000  bestvalidloss 3.14066  last_update 4\n",
      "train: iter 163  trainloss 1.10183  validloss 3.68994±0.00000  bestvalidloss 3.14066  last_update 5\n",
      "train: iter 164  trainloss 1.12728  validloss 3.46516±0.00000  bestvalidloss 3.14066  last_update 6\n",
      "train: iter 165  trainloss 1.14790  validloss 3.40544±0.00000  bestvalidloss 3.14066  last_update 7\n",
      "train: iter 166  trainloss 1.10175  validloss 3.56188±0.00000  bestvalidloss 3.14066  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 1.10750  validloss 3.73249±0.00000  bestvalidloss 3.14066  last_update 9\n",
      "train: iter 168  trainloss 1.13000  validloss 3.53908±0.00000  bestvalidloss 3.14066  last_update 10\n",
      "train: iter 169  trainloss 1.11825  validloss 3.52442±0.00000  bestvalidloss 3.14066  last_update 11\n",
      "train: iter 170  trainloss 1.12571  validloss 3.36252±0.00000  bestvalidloss 3.14066  last_update 12\n",
      "train: iter 171  trainloss 1.10214  validloss 3.45380±0.00000  bestvalidloss 3.14066  last_update 13\n",
      "train: iter 172  trainloss 1.11911  validloss 3.32041±0.00000  bestvalidloss 3.14066  last_update 14\n",
      "train: iter 173  trainloss 1.12406  validloss 3.50972±0.00000  bestvalidloss 3.14066  last_update 15\n",
      "train: iter 174  trainloss 1.10059  validloss 3.42684±0.00000  bestvalidloss 3.14066  last_update 16\n",
      "train: iter 175  trainloss 1.10756  validloss 3.50505±0.00000  bestvalidloss 3.14066  last_update 17\n",
      "train: iter 176  trainloss 1.12176  validloss 3.39526±0.00000  bestvalidloss 3.14066  last_update 18\n",
      "train: iter 177  trainloss 1.14616  validloss 3.45735±0.00000  bestvalidloss 3.14066  last_update 19\n",
      "train: iter 178  trainloss 1.12563  validloss 3.50598±0.00000  bestvalidloss 3.14066  last_update 20\n",
      "train: iter 179  trainloss 1.11425  validloss 3.58951±0.00000  bestvalidloss 3.14066  last_update 21\n",
      "train: iter 180  trainloss 1.11380  validloss 3.45714±0.00000  bestvalidloss 3.14066  last_update 22\n",
      "train: iter 181  trainloss 1.10344  validloss 3.25090±0.00000  bestvalidloss 3.14066  last_update 23\n",
      "train: iter 182  trainloss 1.09580  validloss 3.33076±0.00000  bestvalidloss 3.14066  last_update 24\n",
      "train: iter 183  trainloss 1.10820  validloss 3.50329±0.00000  bestvalidloss 3.14066  last_update 25\n",
      "train: iter 184  trainloss 1.11872  validloss 3.75461±0.00000  bestvalidloss 3.14066  last_update 26\n",
      "train: iter 185  trainloss 1.14081  validloss 3.72618±0.00000  bestvalidloss 3.14066  last_update 27\n",
      "train: iter 186  trainloss 1.11755  validloss 3.64251±0.00000  bestvalidloss 3.14066  last_update 28\n",
      "train: iter 187  trainloss 1.08160  validloss 3.87009±0.00000  bestvalidloss 3.14066  last_update 29\n",
      "train: iter 188  trainloss 1.09694  validloss 3.66948±0.00000  bestvalidloss 3.14066  last_update 30\n",
      "train: iter 189  trainloss 1.13022  validloss 3.41852±0.00000  bestvalidloss 3.14066  last_update 31\n",
      "train: iter 190  trainloss 1.09618  validloss 3.60800±0.00000  bestvalidloss 3.14066  last_update 32\n",
      "train: iter 191  trainloss 1.11043  validloss 3.56371±0.00000  bestvalidloss 3.14066  last_update 33\n",
      "train: iter 192  trainloss 1.13076  validloss 3.65486±0.00000  bestvalidloss 3.14066  last_update 34\n",
      "train: iter 193  trainloss 1.11630  validloss 3.49775±0.00000  bestvalidloss 3.14066  last_update 35\n",
      "train: iter 194  trainloss 1.10234  validloss 3.57619±0.00000  bestvalidloss 3.14066  last_update 36\n",
      "train: iter 195  trainloss 1.12125  validloss 3.41807±0.00000  bestvalidloss 3.14066  last_update 37\n",
      "train: iter 196  trainloss 1.11021  validloss 3.31620±0.00000  bestvalidloss 3.14066  last_update 38\n",
      "train: iter 197  trainloss 1.10622  validloss 3.66578±0.00000  bestvalidloss 3.14066  last_update 39\n",
      "train: iter 198  trainloss 1.13439  validloss 3.24027±0.00000  bestvalidloss 3.14066  last_update 40\n",
      "train: iter 199  trainloss 1.10122  validloss 3.70755±0.00000  bestvalidloss 3.14066  last_update 41\n",
      "train: iter 200  trainloss 1.12119  validloss 3.61253±0.00000  bestvalidloss 3.14066  last_update 42\n",
      "train: iter 201  trainloss 1.09608  validloss 3.25488±0.00000  bestvalidloss 3.14066  last_update 43\n",
      "train: iter 202  trainloss 1.09483  validloss 3.27397±0.00000  bestvalidloss 3.14066  last_update 44\n",
      "train: iter 203  trainloss 1.11166  validloss 3.44679±0.00000  bestvalidloss 3.14066  last_update 45\n",
      "train: iter 204  trainloss 1.09013  validloss 3.26274±0.00000  bestvalidloss 3.14066  last_update 46\n",
      "train: iter 205  trainloss 1.10679  validloss 3.46618±0.00000  bestvalidloss 3.14066  last_update 47\n",
      "train: iter 206  trainloss 1.12677  validloss 3.26659±0.00000  bestvalidloss 3.14066  last_update 48\n",
      "train: iter 207  trainloss 1.11911  validloss 3.73569±0.00000  bestvalidloss 3.14066  last_update 49\n",
      "train: iter 208  trainloss 1.09576  validloss 3.73610±0.00000  bestvalidloss 3.14066  last_update 50\n",
      "train: iter 209  trainloss 1.11091  validloss 3.61428±0.00000  bestvalidloss 3.14066  last_update 51\n",
      "train: iter 210  trainloss 1.09572  validloss 3.38821±0.00000  bestvalidloss 3.14066  last_update 52\n",
      "train: iter 211  trainloss 1.07738  validloss 3.43145±0.00000  bestvalidloss 3.14066  last_update 53\n",
      "train: iter 212  trainloss 1.07539  validloss 3.34210±0.00000  bestvalidloss 3.14066  last_update 54\n",
      "train: iter 213  trainloss 1.12771  validloss 3.47491±0.00000  bestvalidloss 3.14066  last_update 55\n",
      "train: iter 214  trainloss 1.09870  validloss 3.58040±0.00000  bestvalidloss 3.14066  last_update 56\n",
      "train: iter 215  trainloss 1.06164  validloss 3.39759±0.00000  bestvalidloss 3.14066  last_update 57\n",
      "train: iter 216  trainloss 1.10549  validloss 3.20943±0.00000  bestvalidloss 3.14066  last_update 58\n",
      "train: iter 217  trainloss 1.09136  validloss 3.35813±0.00000  bestvalidloss 3.14066  last_update 59\n",
      "train: iter 218  trainloss 1.10854  validloss 3.66967±0.00000  bestvalidloss 3.14066  last_update 60\n",
      "train: iter 219  trainloss 1.08681  validloss 3.50692±0.00000  bestvalidloss 3.14066  last_update 61\n",
      "train: iter 220  trainloss 1.09201  validloss 3.53521±0.00000  bestvalidloss 3.14066  last_update 62\n",
      "train: iter 221  trainloss 1.09488  validloss 3.42703±0.00000  bestvalidloss 3.14066  last_update 63\n",
      "train: iter 222  trainloss 1.09707  validloss 3.66288±0.00000  bestvalidloss 3.14066  last_update 64\n",
      "train: iter 223  trainloss 1.08800  validloss 3.60895±0.00000  bestvalidloss 3.14066  last_update 65\n",
      "train: iter 224  trainloss 1.13341  validloss 3.47680±0.00000  bestvalidloss 3.14066  last_update 66\n",
      "train: iter 225  trainloss 1.10371  validloss 3.50013±0.00000  bestvalidloss 3.14066  last_update 67\n",
      "train: iter 226  trainloss 1.07774  validloss 3.37430±0.00000  bestvalidloss 3.14066  last_update 68\n",
      "train: iter 227  trainloss 1.09376  validloss 3.20148±0.00000  bestvalidloss 3.14066  last_update 69\n",
      "train: iter 228  trainloss 1.06479  validloss 3.42636±0.00000  bestvalidloss 3.14066  last_update 70\n",
      "train: iter 229  trainloss 1.10846  validloss 3.41178±0.00000  bestvalidloss 3.14066  last_update 71\n",
      "train: iter 230  trainloss 1.06664  validloss 3.39367±0.00000  bestvalidloss 3.14066  last_update 72\n",
      "train: iter 231  trainloss 1.09240  validloss 3.35684±0.00000  bestvalidloss 3.14066  last_update 73\n",
      "train: iter 232  trainloss 1.09566  validloss 3.43116±0.00000  bestvalidloss 3.14066  last_update 74\n",
      "train: iter 233  trainloss 1.13699  validloss 3.96046±0.00000  bestvalidloss 3.14066  last_update 75\n",
      "train: iter 234  trainloss 1.09757  validloss 3.37744±0.00000  bestvalidloss 3.14066  last_update 76\n",
      "train: iter 235  trainloss 1.08374  validloss 3.32911±0.00000  bestvalidloss 3.14066  last_update 77\n",
      "train: iter 236  trainloss 1.14134  validloss 3.45914±0.00000  bestvalidloss 3.14066  last_update 78\n",
      "train: iter 237  trainloss 1.13138  validloss 3.56718±0.00000  bestvalidloss 3.14066  last_update 79\n",
      "train: iter 238  trainloss 1.08664  validloss 3.24309±0.00000  bestvalidloss 3.14066  last_update 80\n",
      "train: iter 239  trainloss 1.09307  validloss 3.41825±0.00000  bestvalidloss 3.14066  last_update 81\n",
      "train: iter 240  trainloss 1.11925  validloss 3.41223±0.00000  bestvalidloss 3.14066  last_update 82\n",
      "train: iter 241  trainloss 1.11773  validloss 3.52006±0.00000  bestvalidloss 3.14066  last_update 83\n",
      "train: iter 242  trainloss 1.09512  validloss 3.46185±0.00000  bestvalidloss 3.14066  last_update 84\n",
      "train: iter 243  trainloss 1.11403  validloss 3.77586±0.00000  bestvalidloss 3.14066  last_update 85\n",
      "train: iter 244  trainloss 1.07976  validloss 3.50832±0.00000  bestvalidloss 3.14066  last_update 86\n",
      "train: iter 245  trainloss 1.09818  validloss 3.34209±0.00000  bestvalidloss 3.14066  last_update 87\n",
      "train: iter 246  trainloss 1.09350  validloss 3.50065±0.00000  bestvalidloss 3.14066  last_update 88\n",
      "train: iter 247  trainloss 1.11446  validloss 3.74788±0.00000  bestvalidloss 3.14066  last_update 89\n",
      "train: iter 248  trainloss 1.09177  validloss 3.38994±0.00000  bestvalidloss 3.14066  last_update 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 249  trainloss 1.10532  validloss 3.29264±0.00000  bestvalidloss 3.14066  last_update 91\n",
      "train: iter 250  trainloss 1.05702  validloss 3.52045±0.00000  bestvalidloss 3.14066  last_update 92\n",
      "train: iter 251  trainloss 1.08060  validloss 3.66802±0.00000  bestvalidloss 3.14066  last_update 93\n",
      "train: iter 252  trainloss 1.09175  validloss 3.29927±0.00000  bestvalidloss 3.14066  last_update 94\n",
      "train: iter 253  trainloss 1.13414  validloss 3.37113±0.00000  bestvalidloss 3.14066  last_update 95\n",
      "train: iter 254  trainloss 1.12476  validloss 3.37157±0.00000  bestvalidloss 3.14066  last_update 96\n",
      "train: iter 255  trainloss 1.10765  validloss 3.33453±0.00000  bestvalidloss 3.14066  last_update 97\n",
      "train: iter 256  trainloss 1.08338  validloss 3.72254±0.00000  bestvalidloss 3.14066  last_update 98\n",
      "train: iter 257  trainloss 1.07783  validloss 3.43563±0.00000  bestvalidloss 3.14066  last_update 99\n",
      "train: iter 258  trainloss 1.08007  validloss 3.85338±0.00000  bestvalidloss 3.14066  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-12.1799)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(3.3692)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6745290708725278\n",
      "tensor([1.3300])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a6778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
