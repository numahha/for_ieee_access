{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(2003.4369)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 120446.10454  validloss 333688.47966±0.00000  bestvalidloss 333688.47966  last_update 0\n",
      "train: iter 1  trainloss 47316.11111  validloss 71848.58031±0.00000  bestvalidloss 71848.58031  last_update 0\n",
      "train: iter 2  trainloss 987.96304  validloss 39002.79390±0.00000  bestvalidloss 39002.79390  last_update 0\n",
      "train: iter 3  trainloss 942.25081  validloss 1863.87497±0.00000  bestvalidloss 1863.87497  last_update 0\n",
      "train: iter 4  trainloss 835.08734  validloss 1508.16915±0.00000  bestvalidloss 1508.16915  last_update 0\n",
      "train: iter 5  trainloss 735.98476  validloss 1016.28469±0.00000  bestvalidloss 1016.28469  last_update 0\n",
      "train: iter 6  trainloss 703.44594  validloss 946.81656±0.00000  bestvalidloss 946.81656  last_update 0\n",
      "train: iter 7  trainloss 669.94877  validloss 886.71554±0.00000  bestvalidloss 886.71554  last_update 0\n",
      "train: iter 8  trainloss 626.55396  validloss 1159.53416±0.00000  bestvalidloss 886.71554  last_update 1\n",
      "train: iter 9  trainloss 580.49305  validloss 816.60894±0.00000  bestvalidloss 816.60894  last_update 0\n",
      "train: iter 10  trainloss 511.36160  validloss 874.30691±0.00000  bestvalidloss 816.60894  last_update 1\n",
      "train: iter 11  trainloss 469.22467  validloss 816.68178±0.00000  bestvalidloss 816.60894  last_update 2\n",
      "train: iter 12  trainloss 373.34763  validloss 636.19358±0.00000  bestvalidloss 636.19358  last_update 0\n",
      "train: iter 13  trainloss 310.52159  validloss 547.37645±0.00000  bestvalidloss 547.37645  last_update 0\n",
      "train: iter 14  trainloss 250.25771  validloss 544.43520±0.00000  bestvalidloss 544.43520  last_update 0\n",
      "train: iter 15  trainloss 211.38659  validloss 395.57539±0.00000  bestvalidloss 395.57539  last_update 0\n",
      "train: iter 16  trainloss 177.16797  validloss 321.75422±0.00000  bestvalidloss 321.75422  last_update 0\n",
      "train: iter 17  trainloss 163.54416  validloss 326.99596±0.00000  bestvalidloss 321.75422  last_update 1\n",
      "train: iter 18  trainloss 118.35092  validloss 240.83138±0.00000  bestvalidloss 240.83138  last_update 0\n",
      "train: iter 19  trainloss 110.59422  validloss 337.97777±0.00000  bestvalidloss 240.83138  last_update 1\n",
      "train: iter 20  trainloss 57.57828  validloss 151.04176±0.00000  bestvalidloss 151.04176  last_update 0\n",
      "train: iter 21  trainloss 49.01116  validloss 240.19018±0.00000  bestvalidloss 151.04176  last_update 1\n",
      "train: iter 22  trainloss 24.98917  validloss 216.89695±0.00000  bestvalidloss 151.04176  last_update 2\n",
      "train: iter 23  trainloss -17.59341  validloss 140.59107±0.00000  bestvalidloss 140.59107  last_update 0\n",
      "train: iter 24  trainloss -36.65908  validloss 146.74378±0.00000  bestvalidloss 140.59107  last_update 1\n",
      "train: iter 25  trainloss -5.20331  validloss 175.50903±0.00000  bestvalidloss 140.59107  last_update 2\n",
      "train: iter 26  trainloss -21.18741  validloss 191.96000±0.00000  bestvalidloss 140.59107  last_update 3\n",
      "train: iter 27  trainloss -77.13098  validloss -4.67393±0.00000  bestvalidloss -4.67393  last_update 0\n",
      "train: iter 28  trainloss -93.62494  validloss -1.12144±0.00000  bestvalidloss -4.67393  last_update 1\n",
      "train: iter 29  trainloss -105.83405  validloss 36.76010±0.00000  bestvalidloss -4.67393  last_update 2\n",
      "train: iter 30  trainloss -121.87261  validloss 67.96612±0.00000  bestvalidloss -4.67393  last_update 3\n",
      "train: iter 31  trainloss -142.62513  validloss 125.54637±0.00000  bestvalidloss -4.67393  last_update 4\n",
      "train: iter 32  trainloss -162.01345  validloss 139.88209±0.00000  bestvalidloss -4.67393  last_update 5\n",
      "train: iter 33  trainloss -185.24924  validloss 31.70819±0.00000  bestvalidloss -4.67393  last_update 6\n",
      "train: iter 34  trainloss -183.26482  validloss 15.81516±0.00000  bestvalidloss -4.67393  last_update 7\n",
      "train: iter 35  trainloss -159.71639  validloss 213.74451±0.00000  bestvalidloss -4.67393  last_update 8\n",
      "train: iter 36  trainloss -181.27675  validloss -28.48050±0.00000  bestvalidloss -28.48050  last_update 0\n",
      "train: iter 37  trainloss -215.78815  validloss -49.68822±0.00000  bestvalidloss -49.68822  last_update 0\n",
      "train: iter 38  trainloss -191.27916  validloss -109.72166±0.00000  bestvalidloss -109.72166  last_update 0\n",
      "train: iter 39  trainloss -232.94764  validloss -71.22865±0.00000  bestvalidloss -109.72166  last_update 1\n",
      "train: iter 40  trainloss -246.78899  validloss -72.59827±0.00000  bestvalidloss -109.72166  last_update 2\n",
      "train: iter 41  trainloss -263.25450  validloss -112.52092±0.00000  bestvalidloss -112.52092  last_update 0\n",
      "train: iter 42  trainloss -238.25569  validloss 310.31019±0.00000  bestvalidloss -112.52092  last_update 1\n",
      "train: iter 43  trainloss -277.59825  validloss -137.92370±0.00000  bestvalidloss -137.92370  last_update 0\n",
      "train: iter 44  trainloss -256.55664  validloss -71.74740±0.00000  bestvalidloss -137.92370  last_update 1\n",
      "train: iter 45  trainloss -293.39441  validloss -161.05817±0.00000  bestvalidloss -161.05817  last_update 0\n",
      "train: iter 46  trainloss -308.71993  validloss -237.57291±0.00000  bestvalidloss -237.57291  last_update 0\n",
      "train: iter 47  trainloss -318.57950  validloss -167.03624±0.00000  bestvalidloss -237.57291  last_update 1\n",
      "train: iter 48  trainloss -301.57528  validloss -211.76816±0.00000  bestvalidloss -237.57291  last_update 2\n",
      "train: iter 49  trainloss -307.83130  validloss -138.58234±0.00000  bestvalidloss -237.57291  last_update 3\n",
      "train: iter 50  trainloss -277.04332  validloss -220.20650±0.00000  bestvalidloss -237.57291  last_update 4\n",
      "train: iter 51  trainloss -277.36871  validloss -131.43140±0.00000  bestvalidloss -237.57291  last_update 5\n",
      "train: iter 52  trainloss -324.11146  validloss -274.41577±0.00000  bestvalidloss -274.41577  last_update 0\n",
      "train: iter 53  trainloss -337.75852  validloss -283.37321±0.00000  bestvalidloss -283.37321  last_update 0\n",
      "train: iter 54  trainloss -338.47390  validloss -356.03658±0.00000  bestvalidloss -356.03658  last_update 0\n",
      "train: iter 55  trainloss -349.92026  validloss -226.03215±0.00000  bestvalidloss -356.03658  last_update 1\n",
      "train: iter 56  trainloss -381.25142  validloss -338.97431±0.00000  bestvalidloss -356.03658  last_update 2\n",
      "train: iter 57  trainloss -352.03705  validloss -272.58493±0.00000  bestvalidloss -356.03658  last_update 3\n",
      "train: iter 58  trainloss -359.98860  validloss -232.31023±0.00000  bestvalidloss -356.03658  last_update 4\n",
      "train: iter 59  trainloss -358.40520  validloss -297.50402±0.00000  bestvalidloss -356.03658  last_update 5\n",
      "train: iter 60  trainloss -407.32012  validloss -394.58108±0.00000  bestvalidloss -394.58108  last_update 0\n",
      "train: iter 61  trainloss -407.18667  validloss -417.75413±0.00000  bestvalidloss -417.75413  last_update 0\n",
      "train: iter 62  trainloss -421.08234  validloss -389.46494±0.00000  bestvalidloss -417.75413  last_update 1\n",
      "train: iter 63  trainloss -373.33792  validloss -346.78947±0.00000  bestvalidloss -417.75413  last_update 2\n",
      "train: iter 64  trainloss -442.41279  validloss -398.55733±0.00000  bestvalidloss -417.75413  last_update 3\n",
      "train: iter 65  trainloss -445.10505  validloss -432.21211±0.00000  bestvalidloss -432.21211  last_update 0\n",
      "train: iter 66  trainloss -411.85327  validloss -469.24541±0.00000  bestvalidloss -469.24541  last_update 0\n",
      "train: iter 67  trainloss -450.53503  validloss -451.31488±0.00000  bestvalidloss -469.24541  last_update 1\n",
      "train: iter 68  trainloss -461.61857  validloss -437.75080±0.00000  bestvalidloss -469.24541  last_update 2\n",
      "train: iter 69  trainloss -456.15464  validloss -457.77803±0.00000  bestvalidloss -469.24541  last_update 3\n",
      "train: iter 70  trainloss -427.69233  validloss -246.14477±0.00000  bestvalidloss -469.24541  last_update 4\n",
      "train: iter 71  trainloss -453.49328  validloss -461.97706±0.00000  bestvalidloss -469.24541  last_update 5\n",
      "train: iter 72  trainloss -410.18651  validloss -527.49940±0.00000  bestvalidloss -527.49940  last_update 0\n",
      "train: iter 73  trainloss -464.89401  validloss -454.11860±0.00000  bestvalidloss -527.49940  last_update 1\n",
      "train: iter 74  trainloss -511.70819  validloss -545.33725±0.00000  bestvalidloss -545.33725  last_update 0\n",
      "train: iter 75  trainloss -516.34047  validloss -558.39190±0.00000  bestvalidloss -558.39190  last_update 0\n",
      "train: iter 76  trainloss -489.74144  validloss -432.11901±0.00000  bestvalidloss -558.39190  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -436.36894  validloss -414.87126±0.00000  bestvalidloss -558.39190  last_update 2\n",
      "train: iter 78  trainloss -521.76364  validloss -498.48801±0.00000  bestvalidloss -558.39190  last_update 3\n",
      "train: iter 79  trainloss -508.86293  validloss -553.62995±0.00000  bestvalidloss -558.39190  last_update 4\n",
      "train: iter 80  trainloss -496.24194  validloss -539.35321±0.00000  bestvalidloss -558.39190  last_update 5\n",
      "train: iter 81  trainloss -477.08315  validloss -486.87085±0.00000  bestvalidloss -558.39190  last_update 6\n",
      "train: iter 82  trainloss -506.10949  validloss -469.94720±0.00000  bestvalidloss -558.39190  last_update 7\n",
      "train: iter 83  trainloss -518.70114  validloss -519.51673±0.00000  bestvalidloss -558.39190  last_update 8\n",
      "train: iter 84  trainloss -558.60543  validloss -602.66474±0.00000  bestvalidloss -602.66474  last_update 0\n",
      "train: iter 85  trainloss -471.60275  validloss -548.73065±0.00000  bestvalidloss -602.66474  last_update 1\n",
      "train: iter 86  trainloss -459.80434  validloss -479.58272±0.00000  bestvalidloss -602.66474  last_update 2\n",
      "train: iter 87  trainloss -532.55548  validloss -486.57617±0.00000  bestvalidloss -602.66474  last_update 3\n",
      "train: iter 88  trainloss -554.67428  validloss -546.22687±0.00000  bestvalidloss -602.66474  last_update 4\n",
      "train: iter 89  trainloss -537.21033  validloss -613.82527±0.00000  bestvalidloss -613.82527  last_update 0\n",
      "train: iter 90  trainloss -533.86993  validloss -532.67198±0.00000  bestvalidloss -613.82527  last_update 1\n",
      "train: iter 91  trainloss -488.55968  validloss -617.36892±0.00000  bestvalidloss -617.36892  last_update 0\n",
      "train: iter 92  trainloss -499.22991  validloss -521.74412±0.00000  bestvalidloss -617.36892  last_update 1\n",
      "train: iter 93  trainloss -486.11021  validloss -609.19641±0.00000  bestvalidloss -617.36892  last_update 2\n",
      "train: iter 94  trainloss -409.80898  validloss -493.52814±0.00000  bestvalidloss -617.36892  last_update 3\n",
      "train: iter 95  trainloss -548.38365  validloss -551.30823±0.00000  bestvalidloss -617.36892  last_update 4\n",
      "train: iter 96  trainloss -573.37655  validloss -549.45250±0.00000  bestvalidloss -617.36892  last_update 5\n",
      "train: iter 97  trainloss -533.24502  validloss -599.34533±0.00000  bestvalidloss -617.36892  last_update 6\n",
      "train: iter 98  trainloss -568.92821  validloss -595.75022±0.00000  bestvalidloss -617.36892  last_update 7\n",
      "train: iter 99  trainloss -613.95583  validloss -632.05315±0.00000  bestvalidloss -632.05315  last_update 0\n",
      "train: iter 100  trainloss -617.43207  validloss -607.45575±0.00000  bestvalidloss -632.05315  last_update 1\n",
      "train: iter 101  trainloss -592.32163  validloss -573.17128±0.00000  bestvalidloss -632.05315  last_update 2\n",
      "train: iter 102  trainloss -605.31132  validloss -636.24180±0.00000  bestvalidloss -636.24180  last_update 0\n",
      "train: iter 103  trainloss -592.26046  validloss -648.97129±0.00000  bestvalidloss -648.97129  last_update 0\n",
      "train: iter 104  trainloss -569.16903  validloss -463.02972±0.00000  bestvalidloss -648.97129  last_update 1\n",
      "train: iter 105  trainloss -615.42120  validloss -610.50617±0.00000  bestvalidloss -648.97129  last_update 2\n",
      "train: iter 106  trainloss -594.63379  validloss -716.55000±0.00000  bestvalidloss -716.55000  last_update 0\n",
      "train: iter 107  trainloss -544.43610  validloss -244.34014±0.00000  bestvalidloss -716.55000  last_update 1\n",
      "train: iter 108  trainloss -603.88580  validloss -620.95282±0.00000  bestvalidloss -716.55000  last_update 2\n",
      "train: iter 109  trainloss -635.07054  validloss -665.12910±0.00000  bestvalidloss -716.55000  last_update 3\n",
      "train: iter 110  trainloss -632.61200  validloss -593.61834±0.00000  bestvalidloss -716.55000  last_update 4\n",
      "train: iter 111  trainloss -656.97502  validloss -656.55459±0.00000  bestvalidloss -716.55000  last_update 5\n",
      "train: iter 112  trainloss -662.16879  validloss -568.81777±0.00000  bestvalidloss -716.55000  last_update 6\n",
      "train: iter 113  trainloss -608.32538  validloss -617.38867±0.00000  bestvalidloss -716.55000  last_update 7\n",
      "train: iter 114  trainloss -660.59012  validloss -703.52800±0.00000  bestvalidloss -716.55000  last_update 8\n",
      "train: iter 115  trainloss -631.06438  validloss -672.55394±0.00000  bestvalidloss -716.55000  last_update 9\n",
      "train: iter 116  trainloss -662.19218  validloss -540.35377±0.00000  bestvalidloss -716.55000  last_update 10\n",
      "train: iter 117  trainloss -666.71055  validloss -703.31999±0.00000  bestvalidloss -716.55000  last_update 11\n",
      "train: iter 118  trainloss -659.52007  validloss -531.86761±0.00000  bestvalidloss -716.55000  last_update 12\n",
      "train: iter 119  trainloss -599.41699  validloss -676.87248±0.00000  bestvalidloss -716.55000  last_update 13\n",
      "train: iter 120  trainloss -576.49318  validloss -642.83894±0.00000  bestvalidloss -716.55000  last_update 14\n",
      "train: iter 121  trainloss -605.92628  validloss -327.02611±0.00000  bestvalidloss -716.55000  last_update 15\n",
      "train: iter 122  trainloss -688.90348  validloss -712.80930±0.00000  bestvalidloss -716.55000  last_update 16\n",
      "train: iter 123  trainloss -639.94713  validloss -684.73129±0.00000  bestvalidloss -716.55000  last_update 17\n",
      "train: iter 124  trainloss -670.11353  validloss -693.26741±0.00000  bestvalidloss -716.55000  last_update 18\n",
      "train: iter 125  trainloss -655.85964  validloss -544.31438±0.00000  bestvalidloss -716.55000  last_update 19\n",
      "train: iter 126  trainloss -720.85904  validloss -687.03491±0.00000  bestvalidloss -716.55000  last_update 20\n",
      "train: iter 127  trainloss -701.76083  validloss -724.47391±0.00000  bestvalidloss -724.47391  last_update 0\n",
      "train: iter 128  trainloss -746.88934  validloss -598.39321±0.00000  bestvalidloss -724.47391  last_update 1\n",
      "train: iter 129  trainloss -680.38641  validloss -588.84135±0.00000  bestvalidloss -724.47391  last_update 2\n",
      "train: iter 130  trainloss -630.70281  validloss -615.07016±0.00000  bestvalidloss -724.47391  last_update 3\n",
      "train: iter 131  trainloss -704.31319  validloss -741.58848±0.00000  bestvalidloss -741.58848  last_update 0\n",
      "train: iter 132  trainloss -670.43225  validloss -618.05108±0.00000  bestvalidloss -741.58848  last_update 1\n",
      "train: iter 133  trainloss -733.95285  validloss -749.75536±0.00000  bestvalidloss -749.75536  last_update 0\n",
      "train: iter 134  trainloss -743.43577  validloss -705.80308±0.00000  bestvalidloss -749.75536  last_update 1\n",
      "train: iter 135  trainloss -627.27360  validloss -545.20499±0.00000  bestvalidloss -749.75536  last_update 2\n",
      "train: iter 136  trainloss -734.88641  validloss -839.80368±0.00000  bestvalidloss -839.80368  last_update 0\n",
      "train: iter 137  trainloss -776.38231  validloss -653.97460±0.00000  bestvalidloss -839.80368  last_update 1\n",
      "train: iter 138  trainloss -751.54479  validloss -807.41601±0.00000  bestvalidloss -839.80368  last_update 2\n",
      "train: iter 139  trainloss -744.74824  validloss -832.00484±0.00000  bestvalidloss -839.80368  last_update 3\n",
      "train: iter 140  trainloss -768.54352  validloss -783.87886±0.00000  bestvalidloss -839.80368  last_update 4\n",
      "train: iter 141  trainloss -693.37545  validloss -794.21328±0.00000  bestvalidloss -839.80368  last_update 5\n",
      "train: iter 142  trainloss -800.26154  validloss -818.62715±0.00000  bestvalidloss -839.80368  last_update 6\n",
      "train: iter 143  trainloss -820.09193  validloss -846.64414±0.00000  bestvalidloss -846.64414  last_update 0\n",
      "train: iter 144  trainloss -768.44957  validloss -862.97700±0.00000  bestvalidloss -862.97700  last_update 0\n",
      "train: iter 145  trainloss -774.06684  validloss -808.75534±0.00000  bestvalidloss -862.97700  last_update 1\n",
      "train: iter 146  trainloss -794.37457  validloss -894.53877±0.00000  bestvalidloss -894.53877  last_update 0\n",
      "train: iter 147  trainloss -752.83626  validloss -768.43362±0.00000  bestvalidloss -894.53877  last_update 1\n",
      "train: iter 148  trainloss -640.39395  validloss -605.73070±0.00000  bestvalidloss -894.53877  last_update 2\n",
      "train: iter 149  trainloss -825.65120  validloss -875.57327±0.00000  bestvalidloss -894.53877  last_update 3\n",
      "train: iter 150  trainloss -748.13513  validloss -749.56821±0.00000  bestvalidloss -894.53877  last_update 4\n",
      "train: iter 151  trainloss -757.10090  validloss -813.19760±0.00000  bestvalidloss -894.53877  last_update 5\n",
      "train: iter 152  trainloss -719.89664  validloss -824.12587±0.00000  bestvalidloss -894.53877  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -854.65646  validloss -856.45031±0.00000  bestvalidloss -894.53877  last_update 7\n",
      "train: iter 154  trainloss -820.68121  validloss -788.45257±0.00000  bestvalidloss -894.53877  last_update 8\n",
      "train: iter 155  trainloss -642.49916  validloss -589.83952±0.00000  bestvalidloss -894.53877  last_update 9\n",
      "train: iter 156  trainloss -822.47238  validloss -699.71912±0.00000  bestvalidloss -894.53877  last_update 10\n",
      "train: iter 157  trainloss -867.73864  validloss -863.97212±0.00000  bestvalidloss -894.53877  last_update 11\n",
      "train: iter 158  trainloss -839.51359  validloss -881.11601±0.00000  bestvalidloss -894.53877  last_update 12\n",
      "train: iter 159  trainloss -772.01697  validloss -797.67419±0.00000  bestvalidloss -894.53877  last_update 13\n",
      "train: iter 160  trainloss -782.61418  validloss -838.76117±0.00000  bestvalidloss -894.53877  last_update 14\n",
      "train: iter 161  trainloss -828.19688  validloss -771.73169±0.00000  bestvalidloss -894.53877  last_update 15\n",
      "train: iter 162  trainloss -893.03421  validloss -790.63141±0.00000  bestvalidloss -894.53877  last_update 16\n",
      "train: iter 163  trainloss -875.85802  validloss -940.85910±0.00000  bestvalidloss -940.85910  last_update 0\n",
      "train: iter 164  trainloss -873.23045  validloss -839.92237±0.00000  bestvalidloss -940.85910  last_update 1\n",
      "train: iter 165  trainloss -880.05589  validloss -765.99917±0.00000  bestvalidloss -940.85910  last_update 2\n",
      "train: iter 166  trainloss -737.15469  validloss -717.51876±0.00000  bestvalidloss -940.85910  last_update 3\n",
      "train: iter 167  trainloss -903.62703  validloss -920.93873±0.00000  bestvalidloss -940.85910  last_update 4\n",
      "train: iter 168  trainloss -864.85935  validloss -974.00912±0.00000  bestvalidloss -974.00912  last_update 0\n",
      "train: iter 169  trainloss -898.98950  validloss -871.66501±0.00000  bestvalidloss -974.00912  last_update 1\n",
      "train: iter 170  trainloss -938.41281  validloss -852.18777±0.00000  bestvalidloss -974.00912  last_update 2\n",
      "train: iter 171  trainloss -564.83285  validloss -345.56379±0.00000  bestvalidloss -974.00912  last_update 3\n",
      "train: iter 172  trainloss -724.82746  validloss -523.95069±0.00000  bestvalidloss -974.00912  last_update 4\n",
      "train: iter 173  trainloss -864.76092  validloss -896.03815±0.00000  bestvalidloss -974.00912  last_update 5\n",
      "train: iter 174  trainloss -767.63705  validloss -968.68839±0.00000  bestvalidloss -974.00912  last_update 6\n",
      "train: iter 175  trainloss 224.26632  validloss -563.26364±0.00000  bestvalidloss -974.00912  last_update 7\n",
      "train: iter 176  trainloss -60.50664  validloss 217.39974±0.00000  bestvalidloss -974.00912  last_update 8\n",
      "train: iter 177  trainloss -465.01267  validloss -392.08498±0.00000  bestvalidloss -974.00912  last_update 9\n",
      "train: iter 178  trainloss -564.83332  validloss -450.13741±0.00000  bestvalidloss -974.00912  last_update 10\n",
      "train: iter 179  trainloss -683.50701  validloss -710.90566±0.00000  bestvalidloss -974.00912  last_update 11\n",
      "train: iter 180  trainloss -522.18931  validloss -763.63047±0.00000  bestvalidloss -974.00912  last_update 12\n",
      "train: iter 181  trainloss -781.81261  validloss -744.14306±0.00000  bestvalidloss -974.00912  last_update 13\n",
      "train: iter 182  trainloss -860.37051  validloss -877.45614±0.00000  bestvalidloss -974.00912  last_update 14\n",
      "train: iter 183  trainloss -824.36180  validloss -855.43622±0.00000  bestvalidloss -974.00912  last_update 15\n",
      "train: iter 184  trainloss -828.05673  validloss -916.38920±0.00000  bestvalidloss -974.00912  last_update 16\n",
      "train: iter 185  trainloss -956.52385  validloss -895.21126±0.00000  bestvalidloss -974.00912  last_update 17\n",
      "train: iter 186  trainloss -986.19113  validloss -982.45169±0.00000  bestvalidloss -982.45169  last_update 0\n",
      "train: iter 187  trainloss -855.81634  validloss -986.21320±0.00000  bestvalidloss -986.21320  last_update 0\n",
      "train: iter 188  trainloss -1000.83196  validloss -1014.04050±0.00000  bestvalidloss -1014.04050  last_update 0\n",
      "train: iter 189  trainloss -916.16207  validloss -931.05753±0.00000  bestvalidloss -1014.04050  last_update 1\n",
      "train: iter 190  trainloss -930.11340  validloss -893.29196±0.00000  bestvalidloss -1014.04050  last_update 2\n",
      "train: iter 191  trainloss -967.96436  validloss -1013.37852±0.00000  bestvalidloss -1014.04050  last_update 3\n",
      "train: iter 192  trainloss -923.21320  validloss -944.40463±0.00000  bestvalidloss -1014.04050  last_update 4\n",
      "train: iter 193  trainloss -972.23658  validloss -1005.99685±0.00000  bestvalidloss -1014.04050  last_update 5\n",
      "train: iter 194  trainloss -901.50931  validloss -1008.32069±0.00000  bestvalidloss -1014.04050  last_update 6\n",
      "train: iter 195  trainloss -1022.08245  validloss -1027.51299±0.00000  bestvalidloss -1027.51299  last_update 0\n",
      "train: iter 196  trainloss -941.22831  validloss -1063.43502±0.00000  bestvalidloss -1063.43502  last_update 0\n",
      "train: iter 197  trainloss -914.34511  validloss -508.74321±0.00000  bestvalidloss -1063.43502  last_update 1\n",
      "train: iter 198  trainloss -981.12773  validloss -1012.43217±0.00000  bestvalidloss -1063.43502  last_update 2\n",
      "train: iter 199  trainloss -1026.78007  validloss -1040.56501±0.00000  bestvalidloss -1063.43502  last_update 3\n",
      "train: iter 200  trainloss -966.67036  validloss -857.43137±0.00000  bestvalidloss -1063.43502  last_update 4\n",
      "train: iter 201  trainloss -989.68913  validloss -851.15776±0.00000  bestvalidloss -1063.43502  last_update 5\n",
      "train: iter 202  trainloss -982.60546  validloss -1065.47799±0.00000  bestvalidloss -1065.47799  last_update 0\n",
      "train: iter 203  trainloss -1002.11732  validloss -971.25027±0.00000  bestvalidloss -1065.47799  last_update 1\n",
      "train: iter 204  trainloss -1019.51661  validloss -969.87222±0.00000  bestvalidloss -1065.47799  last_update 2\n",
      "train: iter 205  trainloss -1016.17295  validloss -1085.50069±0.00000  bestvalidloss -1085.50069  last_update 0\n",
      "train: iter 206  trainloss -1050.91954  validloss -1052.38045±0.00000  bestvalidloss -1085.50069  last_update 1\n",
      "train: iter 207  trainloss -1073.62935  validloss -1115.84875±0.00000  bestvalidloss -1115.84875  last_update 0\n",
      "train: iter 208  trainloss -1051.85896  validloss -1045.51991±0.00000  bestvalidloss -1115.84875  last_update 1\n",
      "train: iter 209  trainloss -986.41396  validloss -1053.67992±0.00000  bestvalidloss -1115.84875  last_update 2\n",
      "train: iter 210  trainloss -998.56842  validloss -1064.80663±0.00000  bestvalidloss -1115.84875  last_update 3\n",
      "train: iter 211  trainloss -1040.50105  validloss -976.71780±0.00000  bestvalidloss -1115.84875  last_update 4\n",
      "train: iter 212  trainloss -1021.54962  validloss -1109.96434±0.00000  bestvalidloss -1115.84875  last_update 5\n",
      "train: iter 213  trainloss -884.41345  validloss -81.45062±0.00000  bestvalidloss -1115.84875  last_update 6\n",
      "train: iter 214  trainloss -1034.11776  validloss -1062.98925±0.00000  bestvalidloss -1115.84875  last_update 7\n",
      "train: iter 215  trainloss -1081.26170  validloss -1125.33588±0.00000  bestvalidloss -1125.33588  last_update 0\n",
      "train: iter 216  trainloss -1039.57373  validloss -1039.58511±0.00000  bestvalidloss -1125.33588  last_update 1\n",
      "train: iter 217  trainloss -943.04277  validloss -1121.56103±0.00000  bestvalidloss -1125.33588  last_update 2\n",
      "train: iter 218  trainloss -970.85522  validloss -823.47590±0.00000  bestvalidloss -1125.33588  last_update 3\n",
      "train: iter 219  trainloss -1095.03547  validloss -1123.20466±0.00000  bestvalidloss -1125.33588  last_update 4\n",
      "train: iter 220  trainloss -1072.17008  validloss -1079.03889±0.00000  bestvalidloss -1125.33588  last_update 5\n",
      "train: iter 221  trainloss -983.37108  validloss -1083.69501±0.00000  bestvalidloss -1125.33588  last_update 6\n",
      "train: iter 222  trainloss -1098.52953  validloss -1078.23303±0.00000  bestvalidloss -1125.33588  last_update 7\n",
      "train: iter 223  trainloss -1079.10035  validloss -1091.86258±0.00000  bestvalidloss -1125.33588  last_update 8\n",
      "train: iter 224  trainloss -1049.45658  validloss -1038.53851±0.00000  bestvalidloss -1125.33588  last_update 9\n",
      "train: iter 225  trainloss -1110.66708  validloss -1128.06484±0.00000  bestvalidloss -1128.06484  last_update 0\n",
      "train: iter 226  trainloss -1042.94513  validloss -1028.66907±0.00000  bestvalidloss -1128.06484  last_update 1\n",
      "train: iter 227  trainloss -956.77807  validloss -1081.70290±0.00000  bestvalidloss -1128.06484  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1050.28277  validloss -1052.85261±0.00000  bestvalidloss -1128.06484  last_update 3\n",
      "train: iter 229  trainloss -1025.02822  validloss -1060.72319±0.00000  bestvalidloss -1128.06484  last_update 4\n",
      "train: iter 230  trainloss -1008.96983  validloss -884.93203±0.00000  bestvalidloss -1128.06484  last_update 5\n",
      "train: iter 231  trainloss -1020.33276  validloss -1041.76978±0.00000  bestvalidloss -1128.06484  last_update 6\n",
      "train: iter 232  trainloss -1074.70858  validloss -1091.58470±0.00000  bestvalidloss -1128.06484  last_update 7\n",
      "train: iter 233  trainloss -1106.41714  validloss -1093.49059±0.00000  bestvalidloss -1128.06484  last_update 8\n",
      "train: iter 234  trainloss -978.13333  validloss -1123.23520±0.00000  bestvalidloss -1128.06484  last_update 9\n",
      "train: iter 235  trainloss -1062.16747  validloss -762.84576±0.00000  bestvalidloss -1128.06484  last_update 10\n",
      "train: iter 236  trainloss -1051.46562  validloss -1179.25728±0.00000  bestvalidloss -1179.25728  last_update 0\n",
      "train: iter 237  trainloss -1045.44875  validloss -1109.37822±0.00000  bestvalidloss -1179.25728  last_update 1\n",
      "train: iter 238  trainloss -1064.11689  validloss -1124.00709±0.00000  bestvalidloss -1179.25728  last_update 2\n",
      "train: iter 239  trainloss -1034.68332  validloss -1076.26721±0.00000  bestvalidloss -1179.25728  last_update 3\n",
      "train: iter 240  trainloss -1061.77657  validloss -1120.07392±0.00000  bestvalidloss -1179.25728  last_update 4\n",
      "train: iter 241  trainloss -991.78798  validloss -1135.87838±0.00000  bestvalidloss -1179.25728  last_update 5\n",
      "train: iter 242  trainloss -1073.54984  validloss -1147.82790±0.00000  bestvalidloss -1179.25728  last_update 6\n",
      "train: iter 243  trainloss -1129.84497  validloss -1109.99083±0.00000  bestvalidloss -1179.25728  last_update 7\n",
      "train: iter 244  trainloss -1062.05237  validloss -1186.83552±0.00000  bestvalidloss -1186.83552  last_update 0\n",
      "train: iter 245  trainloss -1064.34507  validloss -932.10923±0.00000  bestvalidloss -1186.83552  last_update 1\n",
      "train: iter 246  trainloss -1062.31032  validloss -1189.42545±0.00000  bestvalidloss -1189.42545  last_update 0\n",
      "train: iter 247  trainloss -1111.77617  validloss -1146.33815±0.00000  bestvalidloss -1189.42545  last_update 1\n",
      "train: iter 248  trainloss -1094.83147  validloss -1055.52721±0.00000  bestvalidloss -1189.42545  last_update 2\n",
      "train: iter 249  trainloss -1057.75969  validloss -929.41002±0.00000  bestvalidloss -1189.42545  last_update 3\n",
      "train: iter 250  trainloss -1054.65535  validloss -1178.62697±0.00000  bestvalidloss -1189.42545  last_update 4\n",
      "train: iter 251  trainloss -1127.86504  validloss -945.86414±0.00000  bestvalidloss -1189.42545  last_update 5\n",
      "train: iter 252  trainloss -867.12290  validloss -798.04152±0.00000  bestvalidloss -1189.42545  last_update 6\n",
      "train: iter 253  trainloss -882.08418  validloss -690.36685±0.00000  bestvalidloss -1189.42545  last_update 7\n",
      "train: iter 254  trainloss -1164.17327  validloss -1148.74398±0.00000  bestvalidloss -1189.42545  last_update 8\n",
      "train: iter 255  trainloss -1054.28190  validloss -1195.70351±0.00000  bestvalidloss -1195.70351  last_update 0\n",
      "train: iter 256  trainloss -1071.37638  validloss -905.80740±0.00000  bestvalidloss -1195.70351  last_update 1\n",
      "train: iter 257  trainloss -1078.78921  validloss -1081.98976±0.00000  bestvalidloss -1195.70351  last_update 2\n",
      "train: iter 258  trainloss -1178.27249  validloss -1164.86640±0.00000  bestvalidloss -1195.70351  last_update 3\n",
      "train: iter 259  trainloss -1138.95195  validloss -1201.81032±0.00000  bestvalidloss -1201.81032  last_update 0\n",
      "train: iter 260  trainloss -1090.12529  validloss -1019.45464±0.00000  bestvalidloss -1201.81032  last_update 1\n",
      "train: iter 261  trainloss -1121.26588  validloss -1169.30439±0.00000  bestvalidloss -1201.81032  last_update 2\n",
      "train: iter 262  trainloss -1149.90734  validloss -985.42781±0.00000  bestvalidloss -1201.81032  last_update 3\n",
      "train: iter 263  trainloss -1126.07475  validloss -1143.63420±0.00000  bestvalidloss -1201.81032  last_update 4\n",
      "train: iter 264  trainloss -1127.36967  validloss -1095.46158±0.00000  bestvalidloss -1201.81032  last_update 5\n",
      "train: iter 265  trainloss -1199.53730  validloss -1174.42192±0.00000  bestvalidloss -1201.81032  last_update 6\n",
      "train: iter 266  trainloss -1181.49450  validloss -1248.31833±0.00000  bestvalidloss -1248.31833  last_update 0\n",
      "train: iter 267  trainloss -762.30287  validloss -940.27920±0.00000  bestvalidloss -1248.31833  last_update 1\n",
      "train: iter 268  trainloss -1030.11298  validloss -1035.35486±0.00000  bestvalidloss -1248.31833  last_update 2\n",
      "train: iter 269  trainloss -1055.61861  validloss -1110.18976±0.00000  bestvalidloss -1248.31833  last_update 3\n",
      "train: iter 270  trainloss -967.67279  validloss -974.74992±0.00000  bestvalidloss -1248.31833  last_update 4\n",
      "train: iter 271  trainloss -909.37390  validloss -879.45502±0.00000  bestvalidloss -1248.31833  last_update 5\n",
      "train: iter 272  trainloss -1191.34587  validloss -1147.77265±0.00000  bestvalidloss -1248.31833  last_update 6\n",
      "train: iter 273  trainloss -1070.74716  validloss -1256.57716±0.00000  bestvalidloss -1256.57716  last_update 0\n",
      "train: iter 274  trainloss -1065.13654  validloss -759.05387±0.00000  bestvalidloss -1256.57716  last_update 1\n",
      "train: iter 275  trainloss -1137.50750  validloss -1081.04831±0.00000  bestvalidloss -1256.57716  last_update 2\n",
      "train: iter 276  trainloss -1175.43591  validloss -1226.95034±0.00000  bestvalidloss -1256.57716  last_update 3\n",
      "train: iter 277  trainloss -1153.82101  validloss -1196.34556±0.00000  bestvalidloss -1256.57716  last_update 4\n",
      "train: iter 278  trainloss -1144.50039  validloss -1224.41037±0.00000  bestvalidloss -1256.57716  last_update 5\n",
      "train: iter 279  trainloss -1130.69494  validloss -1205.43594±0.00000  bestvalidloss -1256.57716  last_update 6\n",
      "train: iter 280  trainloss -1094.44729  validloss -1195.67114±0.00000  bestvalidloss -1256.57716  last_update 7\n",
      "train: iter 281  trainloss -1185.77737  validloss -1194.48930±0.00000  bestvalidloss -1256.57716  last_update 8\n",
      "train: iter 282  trainloss -1191.53120  validloss -1220.60366±0.00000  bestvalidloss -1256.57716  last_update 9\n",
      "train: iter 283  trainloss -1170.63735  validloss -1207.44734±0.00000  bestvalidloss -1256.57716  last_update 10\n",
      "train: iter 284  trainloss -1201.91581  validloss -1256.63754±0.00000  bestvalidloss -1256.63754  last_update 0\n",
      "train: iter 285  trainloss -1104.93822  validloss -1308.88345±0.00000  bestvalidloss -1308.88345  last_update 0\n",
      "train: iter 286  trainloss -1199.73840  validloss -1204.01240±0.00000  bestvalidloss -1308.88345  last_update 1\n",
      "train: iter 287  trainloss -1089.68735  validloss -1016.05719±0.00000  bestvalidloss -1308.88345  last_update 2\n",
      "train: iter 288  trainloss -1203.60493  validloss -1222.53023±0.00000  bestvalidloss -1308.88345  last_update 3\n",
      "train: iter 289  trainloss -1212.93411  validloss -1253.72846±0.00000  bestvalidloss -1308.88345  last_update 4\n",
      "train: iter 290  trainloss -1020.28835  validloss -1267.09731±0.00000  bestvalidloss -1308.88345  last_update 5\n",
      "train: iter 291  trainloss -1076.32289  validloss -960.06180±0.00000  bestvalidloss -1308.88345  last_update 6\n",
      "train: iter 292  trainloss -1247.12176  validloss -1224.04148±0.00000  bestvalidloss -1308.88345  last_update 7\n",
      "train: iter 293  trainloss -1277.04054  validloss -1287.58502±0.00000  bestvalidloss -1308.88345  last_update 8\n",
      "train: iter 294  trainloss -1107.57729  validloss -1023.95242±0.00000  bestvalidloss -1308.88345  last_update 9\n",
      "train: iter 295  trainloss -910.83261  validloss -1080.17218±0.00000  bestvalidloss -1308.88345  last_update 10\n",
      "train: iter 296  trainloss -1152.48699  validloss -1105.00978±0.00000  bestvalidloss -1308.88345  last_update 11\n",
      "train: iter 297  trainloss -1217.86057  validloss -1228.85527±0.00000  bestvalidloss -1308.88345  last_update 12\n",
      "train: iter 298  trainloss -1162.77931  validloss -1128.79967±0.00000  bestvalidloss -1308.88345  last_update 13\n",
      "train: iter 299  trainloss -1253.24682  validloss -1277.14712±0.00000  bestvalidloss -1308.88345  last_update 14\n",
      "train: iter 300  trainloss -1268.62563  validloss -1235.25390±0.00000  bestvalidloss -1308.88345  last_update 15\n",
      "train: iter 301  trainloss -1164.17936  validloss -1317.17735±0.00000  bestvalidloss -1317.17735  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 302  trainloss -1167.07081  validloss -1007.11840±0.00000  bestvalidloss -1317.17735  last_update 1\n",
      "train: iter 303  trainloss -1181.11453  validloss -1338.81557±0.00000  bestvalidloss -1338.81557  last_update 0\n",
      "train: iter 304  trainloss -1274.36064  validloss -1240.78512±0.00000  bestvalidloss -1338.81557  last_update 1\n",
      "train: iter 305  trainloss -1223.54317  validloss -1301.41601±0.00000  bestvalidloss -1338.81557  last_update 2\n",
      "train: iter 306  trainloss -1274.06018  validloss -1313.36755±0.00000  bestvalidloss -1338.81557  last_update 3\n",
      "train: iter 307  trainloss -1181.55453  validloss -1277.01270±0.00000  bestvalidloss -1338.81557  last_update 4\n",
      "train: iter 308  trainloss -1239.99847  validloss -1273.27642±0.00000  bestvalidloss -1338.81557  last_update 5\n",
      "train: iter 309  trainloss -1194.16548  validloss -1302.88399±0.00000  bestvalidloss -1338.81557  last_update 6\n",
      "train: iter 310  trainloss -1143.01347  validloss -1000.94432±0.00000  bestvalidloss -1338.81557  last_update 7\n",
      "train: iter 311  trainloss -1289.57527  validloss -1327.71932±0.00000  bestvalidloss -1338.81557  last_update 8\n",
      "train: iter 312  trainloss -1285.91486  validloss -1342.31575±0.00000  bestvalidloss -1342.31575  last_update 0\n",
      "train: iter 313  trainloss -1233.09739  validloss -1302.01355±0.00000  bestvalidloss -1342.31575  last_update 1\n",
      "train: iter 314  trainloss -1042.02814  validloss -1200.23518±0.00000  bestvalidloss -1342.31575  last_update 2\n",
      "train: iter 315  trainloss -1206.81697  validloss -1218.42598±0.00000  bestvalidloss -1342.31575  last_update 3\n",
      "train: iter 316  trainloss -1189.64155  validloss -1283.14994±0.00000  bestvalidloss -1342.31575  last_update 4\n",
      "train: iter 317  trainloss -1301.47441  validloss -1299.79356±0.00000  bestvalidloss -1342.31575  last_update 5\n",
      "train: iter 318  trainloss -1216.51756  validloss -1351.50407±0.00000  bestvalidloss -1351.50407  last_update 0\n",
      "train: iter 319  trainloss -1110.18750  validloss -1304.10750±0.00000  bestvalidloss -1351.50407  last_update 1\n",
      "train: iter 320  trainloss -1253.34915  validloss -1223.87826±0.00000  bestvalidloss -1351.50407  last_update 2\n",
      "train: iter 321  trainloss -1305.61763  validloss -1317.25111±0.00000  bestvalidloss -1351.50407  last_update 3\n",
      "train: iter 322  trainloss -1059.04190  validloss -1308.77711±0.00000  bestvalidloss -1351.50407  last_update 4\n",
      "train: iter 323  trainloss -1220.10911  validloss -1084.24401±0.00000  bestvalidloss -1351.50407  last_update 5\n",
      "train: iter 324  trainloss -1125.77778  validloss -1265.93886±0.00000  bestvalidloss -1351.50407  last_update 6\n",
      "train: iter 325  trainloss -1213.54238  validloss -1190.93819±0.00000  bestvalidloss -1351.50407  last_update 7\n",
      "train: iter 326  trainloss -1302.96840  validloss -1275.97397±0.00000  bestvalidloss -1351.50407  last_update 8\n",
      "train: iter 327  trainloss -1289.79149  validloss -1321.26588±0.00000  bestvalidloss -1351.50407  last_update 9\n",
      "train: iter 328  trainloss -1146.08168  validloss -1311.18089±0.00000  bestvalidloss -1351.50407  last_update 10\n",
      "train: iter 329  trainloss -1244.92651  validloss -1280.47516±0.00000  bestvalidloss -1351.50407  last_update 11\n",
      "train: iter 330  trainloss -1236.36318  validloss -1313.07977±0.00000  bestvalidloss -1351.50407  last_update 12\n",
      "train: iter 331  trainloss -1010.90393  validloss -1282.77613±0.00000  bestvalidloss -1351.50407  last_update 13\n",
      "train: iter 332  trainloss -1076.79872  validloss -1000.68239±0.00000  bestvalidloss -1351.50407  last_update 14\n",
      "train: iter 333  trainloss -1195.74335  validloss -1169.60975±0.00000  bestvalidloss -1351.50407  last_update 15\n",
      "train: iter 334  trainloss -1269.73299  validloss -1254.43944±0.00000  bestvalidloss -1351.50407  last_update 16\n",
      "train: iter 335  trainloss -1130.33597  validloss -1266.72360±0.00000  bestvalidloss -1351.50407  last_update 17\n",
      "train: iter 336  trainloss -1282.34998  validloss -1281.25221±0.00000  bestvalidloss -1351.50407  last_update 18\n",
      "train: iter 337  trainloss -1317.17014  validloss -1320.20203±0.00000  bestvalidloss -1351.50407  last_update 19\n",
      "train: iter 338  trainloss -1146.90157  validloss -1326.04178±0.00000  bestvalidloss -1351.50407  last_update 20\n",
      "train: iter 339  trainloss -1293.19101  validloss -1206.88945±0.00000  bestvalidloss -1351.50407  last_update 21\n",
      "train: iter 340  trainloss -1308.57587  validloss -1293.20525±0.00000  bestvalidloss -1351.50407  last_update 22\n",
      "train: iter 341  trainloss -1250.35160  validloss -1318.89454±0.00000  bestvalidloss -1351.50407  last_update 23\n",
      "train: iter 342  trainloss -753.56022  validloss -1054.81039±0.00000  bestvalidloss -1351.50407  last_update 24\n",
      "train: iter 343  trainloss -1146.60777  validloss -818.42835±0.00000  bestvalidloss -1351.50407  last_update 25\n",
      "train: iter 344  trainloss -1304.61542  validloss -1223.98054±0.00000  bestvalidloss -1351.50407  last_update 26\n",
      "train: iter 345  trainloss -1247.19504  validloss -1362.31849±0.00000  bestvalidloss -1362.31849  last_update 0\n",
      "train: iter 346  trainloss -1042.09285  validloss -1041.18640±0.00000  bestvalidloss -1362.31849  last_update 1\n",
      "train: iter 347  trainloss -1249.11407  validloss -1189.93258±0.00000  bestvalidloss -1362.31849  last_update 2\n",
      "train: iter 348  trainloss -1299.68157  validloss -1316.93376±0.00000  bestvalidloss -1362.31849  last_update 3\n",
      "train: iter 349  trainloss -1277.77995  validloss -1102.42738±0.00000  bestvalidloss -1362.31849  last_update 4\n",
      "train: iter 350  trainloss -1195.23272  validloss -1303.01586±0.00000  bestvalidloss -1362.31849  last_update 5\n",
      "train: iter 351  trainloss -1264.19168  validloss -1334.31509±0.00000  bestvalidloss -1362.31849  last_update 6\n",
      "train: iter 352  trainloss -1236.09860  validloss -1255.68903±0.00000  bestvalidloss -1362.31849  last_update 7\n",
      "train: iter 353  trainloss -1260.82841  validloss -1152.03728±0.00000  bestvalidloss -1362.31849  last_update 8\n",
      "train: iter 354  trainloss -1248.63139  validloss -1376.72407±0.00000  bestvalidloss -1376.72407  last_update 0\n",
      "train: iter 355  trainloss -1310.49290  validloss -1291.39319±0.00000  bestvalidloss -1376.72407  last_update 1\n",
      "train: iter 356  trainloss -1219.63752  validloss -1372.89338±0.00000  bestvalidloss -1376.72407  last_update 2\n",
      "train: iter 357  trainloss -1366.66977  validloss -1361.12593±0.00000  bestvalidloss -1376.72407  last_update 3\n",
      "train: iter 358  trainloss -1296.00898  validloss -1392.99297±0.00000  bestvalidloss -1392.99297  last_update 0\n",
      "train: iter 359  trainloss -1289.00572  validloss -1235.15713±0.00000  bestvalidloss -1392.99297  last_update 1\n",
      "train: iter 360  trainloss -1293.24486  validloss -1327.02816±0.00000  bestvalidloss -1392.99297  last_update 2\n",
      "train: iter 361  trainloss -1273.77388  validloss -1309.05235±0.00000  bestvalidloss -1392.99297  last_update 3\n",
      "train: iter 362  trainloss -1327.33331  validloss -1309.07032±0.00000  bestvalidloss -1392.99297  last_update 4\n",
      "train: iter 363  trainloss -1255.72606  validloss -1376.29622±0.00000  bestvalidloss -1392.99297  last_update 5\n",
      "train: iter 364  trainloss -1231.39923  validloss -1259.83051±0.00000  bestvalidloss -1392.99297  last_update 6\n",
      "train: iter 365  trainloss -1253.54049  validloss -1271.45483±0.00000  bestvalidloss -1392.99297  last_update 7\n",
      "train: iter 366  trainloss -1328.27841  validloss -1330.87404±0.00000  bestvalidloss -1392.99297  last_update 8\n",
      "train: iter 367  trainloss -1309.70530  validloss -1391.74484±0.00000  bestvalidloss -1392.99297  last_update 9\n",
      "train: iter 368  trainloss -1190.94901  validloss -669.05328±0.00000  bestvalidloss -1392.99297  last_update 10\n",
      "train: iter 369  trainloss -1359.45178  validloss -1318.27089±0.00000  bestvalidloss -1392.99297  last_update 11\n",
      "train: iter 370  trainloss -1151.31598  validloss -1332.62935±0.00000  bestvalidloss -1392.99297  last_update 12\n",
      "train: iter 371  trainloss -1353.26900  validloss -1316.80912±0.00000  bestvalidloss -1392.99297  last_update 13\n",
      "train: iter 372  trainloss -1314.95735  validloss -1382.70414±0.00000  bestvalidloss -1392.99297  last_update 14\n",
      "train: iter 373  trainloss -1358.31246  validloss -1354.61416±0.00000  bestvalidloss -1392.99297  last_update 15\n",
      "train: iter 374  trainloss -1228.29247  validloss -1258.07487±0.00000  bestvalidloss -1392.99297  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 375  trainloss -1326.38396  validloss -1316.75375±0.00000  bestvalidloss -1392.99297  last_update 17\n",
      "train: iter 376  trainloss -1336.47629  validloss -1374.79687±0.00000  bestvalidloss -1392.99297  last_update 18\n",
      "train: iter 377  trainloss -1081.82947  validloss -1187.79435±0.00000  bestvalidloss -1392.99297  last_update 19\n",
      "train: iter 378  trainloss -1297.74912  validloss -1212.92881±0.00000  bestvalidloss -1392.99297  last_update 20\n",
      "train: iter 379  trainloss -1308.96300  validloss -1346.98030±0.00000  bestvalidloss -1392.99297  last_update 21\n",
      "train: iter 380  trainloss -1293.78160  validloss -1406.91974±0.00000  bestvalidloss -1406.91974  last_update 0\n",
      "train: iter 381  trainloss -1319.35740  validloss -1280.91203±0.00000  bestvalidloss -1406.91974  last_update 1\n",
      "train: iter 382  trainloss -1363.16685  validloss -1405.81283±0.00000  bestvalidloss -1406.91974  last_update 2\n",
      "train: iter 383  trainloss -1259.79012  validloss -1364.35285±0.00000  bestvalidloss -1406.91974  last_update 3\n",
      "train: iter 384  trainloss -1341.23588  validloss -1354.91552±0.00000  bestvalidloss -1406.91974  last_update 4\n",
      "train: iter 385  trainloss -1296.60600  validloss -1193.93080±0.00000  bestvalidloss -1406.91974  last_update 5\n",
      "train: iter 386  trainloss -1408.97301  validloss -1397.52150±0.00000  bestvalidloss -1406.91974  last_update 6\n",
      "train: iter 387  trainloss -1218.26696  validloss -1440.51591±0.00000  bestvalidloss -1440.51591  last_update 0\n",
      "train: iter 388  trainloss -1278.57121  validloss -1237.23009±0.00000  bestvalidloss -1440.51591  last_update 1\n",
      "train: iter 389  trainloss -1312.08542  validloss -1309.25693±0.00000  bestvalidloss -1440.51591  last_update 2\n",
      "train: iter 390  trainloss -1278.55243  validloss -1230.94383±0.00000  bestvalidloss -1440.51591  last_update 3\n",
      "train: iter 391  trainloss -1322.41727  validloss -1381.16237±0.00000  bestvalidloss -1440.51591  last_update 4\n",
      "train: iter 392  trainloss -1323.02572  validloss -1238.37230±0.00000  bestvalidloss -1440.51591  last_update 5\n",
      "train: iter 393  trainloss -1381.72357  validloss -1384.32987±0.00000  bestvalidloss -1440.51591  last_update 6\n",
      "train: iter 394  trainloss -1341.16614  validloss -1439.36598±0.00000  bestvalidloss -1440.51591  last_update 7\n",
      "train: iter 395  trainloss -1074.58128  validloss -1084.71634±0.00000  bestvalidloss -1440.51591  last_update 8\n",
      "train: iter 396  trainloss -1297.57143  validloss -1316.77640±0.00000  bestvalidloss -1440.51591  last_update 9\n",
      "train: iter 397  trainloss -1316.41934  validloss -1264.52003±0.00000  bestvalidloss -1440.51591  last_update 10\n",
      "train: iter 398  trainloss -1073.53841  validloss -1373.63279±0.00000  bestvalidloss -1440.51591  last_update 11\n",
      "train: iter 399  trainloss -476.06150  validloss -75.18260±0.00000  bestvalidloss -1440.51591  last_update 12\n",
      "train: iter 400  trainloss -1147.18380  validloss -1084.42140±0.00000  bestvalidloss -1440.51591  last_update 13\n",
      "train: iter 401  trainloss -1141.52290  validloss -860.86186±0.00000  bestvalidloss -1440.51591  last_update 14\n",
      "train: iter 402  trainloss -1295.37028  validloss -1285.05708±0.00000  bestvalidloss -1440.51591  last_update 15\n",
      "train: iter 403  trainloss -1329.27486  validloss -1289.42882±0.00000  bestvalidloss -1440.51591  last_update 16\n",
      "train: iter 404  trainloss -1318.96240  validloss -1356.51932±0.00000  bestvalidloss -1440.51591  last_update 17\n",
      "train: iter 405  trainloss -1347.79210  validloss -1379.93133±0.00000  bestvalidloss -1440.51591  last_update 18\n",
      "train: iter 406  trainloss -1227.77577  validloss -1388.40709±0.00000  bestvalidloss -1440.51591  last_update 19\n",
      "train: iter 407  trainloss -1297.96925  validloss -1153.72212±0.00000  bestvalidloss -1440.51591  last_update 20\n",
      "train: iter 408  trainloss -1238.92762  validloss -1322.17865±0.00000  bestvalidloss -1440.51591  last_update 21\n",
      "train: iter 409  trainloss -1271.60037  validloss -1082.74336±0.00000  bestvalidloss -1440.51591  last_update 22\n",
      "train: iter 410  trainloss -1388.45821  validloss -1390.69223±0.00000  bestvalidloss -1440.51591  last_update 23\n",
      "train: iter 411  trainloss -1343.47480  validloss -1372.88468±0.00000  bestvalidloss -1440.51591  last_update 24\n",
      "train: iter 412  trainloss -786.36129  validloss -1370.56721±0.00000  bestvalidloss -1440.51591  last_update 25\n",
      "train: iter 413  trainloss -923.95652  validloss -701.09824±0.00000  bestvalidloss -1440.51591  last_update 26\n",
      "train: iter 414  trainloss -1191.97010  validloss -1042.07174±0.00000  bestvalidloss -1440.51591  last_update 27\n",
      "train: iter 415  trainloss -1308.70677  validloss -1275.56981±0.00000  bestvalidloss -1440.51591  last_update 28\n",
      "train: iter 416  trainloss -1344.36222  validloss -1331.00399±0.00000  bestvalidloss -1440.51591  last_update 29\n",
      "train: iter 417  trainloss -1333.04708  validloss -1339.22576±0.00000  bestvalidloss -1440.51591  last_update 30\n",
      "train: iter 418  trainloss -1273.45994  validloss -1286.49658±0.00000  bestvalidloss -1440.51591  last_update 31\n",
      "train: iter 419  trainloss -1333.93077  validloss -1362.79714±0.00000  bestvalidloss -1440.51591  last_update 32\n",
      "train: iter 420  trainloss -1096.09304  validloss -1281.57101±0.00000  bestvalidloss -1440.51591  last_update 33\n",
      "train: iter 421  trainloss -1339.46610  validloss -1320.68967±0.00000  bestvalidloss -1440.51591  last_update 34\n",
      "train: iter 422  trainloss -1302.51317  validloss -1310.00012±0.00000  bestvalidloss -1440.51591  last_update 35\n",
      "train: iter 423  trainloss -1388.28289  validloss -1358.04995±0.00000  bestvalidloss -1440.51591  last_update 36\n",
      "train: iter 424  trainloss -1267.85811  validloss -1395.32215±0.00000  bestvalidloss -1440.51591  last_update 37\n",
      "train: iter 425  trainloss -1367.05032  validloss -1319.04953±0.00000  bestvalidloss -1440.51591  last_update 38\n",
      "train: iter 426  trainloss -1416.86459  validloss -1411.49337±0.00000  bestvalidloss -1440.51591  last_update 39\n",
      "train: iter 427  trainloss -1363.33151  validloss -1444.81088±0.00000  bestvalidloss -1444.81088  last_update 0\n",
      "train: iter 428  trainloss -1315.50889  validloss -1112.04356±0.00000  bestvalidloss -1444.81088  last_update 1\n",
      "train: iter 429  trainloss -1341.05817  validloss -1346.30192±0.00000  bestvalidloss -1444.81088  last_update 2\n",
      "train: iter 430  trainloss -1384.00643  validloss -1338.79859±0.00000  bestvalidloss -1444.81088  last_update 3\n",
      "train: iter 431  trainloss -1324.78113  validloss -1446.08354±0.00000  bestvalidloss -1446.08354  last_update 0\n",
      "train: iter 432  trainloss -1315.63354  validloss -1252.52289±0.00000  bestvalidloss -1446.08354  last_update 1\n",
      "train: iter 433  trainloss -1375.65555  validloss -1380.96603±0.00000  bestvalidloss -1446.08354  last_update 2\n",
      "train: iter 434  trainloss -1289.74162  validloss -1353.96198±0.00000  bestvalidloss -1446.08354  last_update 3\n",
      "train: iter 435  trainloss -1389.97970  validloss -1403.82150±0.00000  bestvalidloss -1446.08354  last_update 4\n",
      "train: iter 436  trainloss -1310.06780  validloss -1309.50668±0.00000  bestvalidloss -1446.08354  last_update 5\n",
      "train: iter 437  trainloss -1243.45927  validloss -1268.68312±0.00000  bestvalidloss -1446.08354  last_update 6\n",
      "train: iter 438  trainloss -1356.35077  validloss -1302.21401±0.00000  bestvalidloss -1446.08354  last_update 7\n",
      "train: iter 439  trainloss -1335.41523  validloss -1399.10578±0.00000  bestvalidloss -1446.08354  last_update 8\n",
      "train: iter 440  trainloss -1430.16408  validloss -1414.67564±0.00000  bestvalidloss -1446.08354  last_update 9\n",
      "train: iter 441  trainloss -1230.96179  validloss -1449.77928±0.00000  bestvalidloss -1449.77928  last_update 0\n",
      "train: iter 442  trainloss -1326.54171  validloss -1056.43158±0.00000  bestvalidloss -1449.77928  last_update 1\n",
      "train: iter 443  trainloss -1251.40319  validloss -1216.85058±0.00000  bestvalidloss -1449.77928  last_update 2\n",
      "train: iter 444  trainloss -1393.09835  validloss -1357.45373±0.00000  bestvalidloss -1449.77928  last_update 3\n",
      "train: iter 445  trainloss -1392.46017  validloss -1395.13271±0.00000  bestvalidloss -1449.77928  last_update 4\n",
      "train: iter 446  trainloss -1388.80852  validloss -1345.15476±0.00000  bestvalidloss -1449.77928  last_update 5\n",
      "train: iter 447  trainloss -1405.90785  validloss -1450.13160±0.00000  bestvalidloss -1450.13160  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 448  trainloss -1279.33746  validloss -1423.25374±0.00000  bestvalidloss -1450.13160  last_update 1\n",
      "train: iter 449  trainloss -1306.73851  validloss -1034.62930±0.00000  bestvalidloss -1450.13160  last_update 2\n",
      "train: iter 450  trainloss -1246.08474  validloss -1429.12471±0.00000  bestvalidloss -1450.13160  last_update 3\n",
      "train: iter 451  trainloss -1355.97292  validloss -1174.95231±0.00000  bestvalidloss -1450.13160  last_update 4\n",
      "train: iter 452  trainloss -1146.98205  validloss -1310.43428±0.00000  bestvalidloss -1450.13160  last_update 5\n",
      "train: iter 453  trainloss -1204.34381  validloss -1055.26439±0.00000  bestvalidloss -1450.13160  last_update 6\n",
      "train: iter 454  trainloss -1350.32740  validloss -1345.08742±0.00000  bestvalidloss -1450.13160  last_update 7\n",
      "train: iter 455  trainloss -1379.91715  validloss -1381.35147±0.00000  bestvalidloss -1450.13160  last_update 8\n",
      "train: iter 456  trainloss -1361.11147  validloss -1350.97122±0.00000  bestvalidloss -1450.13160  last_update 9\n",
      "train: iter 457  trainloss -1236.39867  validloss -1397.94370±0.00000  bestvalidloss -1450.13160  last_update 10\n",
      "train: iter 458  trainloss -1334.22810  validloss -1272.17318±0.00000  bestvalidloss -1450.13160  last_update 11\n",
      "train: iter 459  trainloss -1387.71599  validloss -1341.59498±0.00000  bestvalidloss -1450.13160  last_update 12\n",
      "train: iter 460  trainloss -1376.36663  validloss -1383.09697±0.00000  bestvalidloss -1450.13160  last_update 13\n",
      "train: iter 461  trainloss -1424.48440  validloss -1418.63083±0.00000  bestvalidloss -1450.13160  last_update 14\n",
      "train: iter 462  trainloss -1406.78782  validloss -1414.34468±0.00000  bestvalidloss -1450.13160  last_update 15\n",
      "train: iter 463  trainloss -1409.74596  validloss -1400.60911±0.00000  bestvalidloss -1450.13160  last_update 16\n",
      "train: iter 464  trainloss -1405.19238  validloss -1446.71841±0.00000  bestvalidloss -1450.13160  last_update 17\n",
      "train: iter 465  trainloss -1345.84320  validloss -1465.22589±0.00000  bestvalidloss -1465.22589  last_update 0\n",
      "train: iter 466  trainloss -1390.79120  validloss -1405.08352±0.00000  bestvalidloss -1465.22589  last_update 1\n",
      "train: iter 467  trainloss -1399.72193  validloss -1353.59194±0.00000  bestvalidloss -1465.22589  last_update 2\n",
      "train: iter 468  trainloss -1313.58641  validloss -1364.03907±0.00000  bestvalidloss -1465.22589  last_update 3\n",
      "train: iter 469  trainloss -1417.06733  validloss -1404.77675±0.00000  bestvalidloss -1465.22589  last_update 4\n",
      "train: iter 470  trainloss -1404.24880  validloss -1461.39601±0.00000  bestvalidloss -1465.22589  last_update 5\n",
      "train: iter 471  trainloss -1349.88310  validloss -1333.90997±0.00000  bestvalidloss -1465.22589  last_update 6\n",
      "train: iter 472  trainloss -1302.94756  validloss -1456.59948±0.00000  bestvalidloss -1465.22589  last_update 7\n",
      "train: iter 473  trainloss -1339.67815  validloss -1256.40378±0.00000  bestvalidloss -1465.22589  last_update 8\n",
      "train: iter 474  trainloss -1339.14462  validloss -974.02098±0.00000  bestvalidloss -1465.22589  last_update 9\n",
      "train: iter 475  trainloss -1401.35929  validloss -1333.43100±0.00000  bestvalidloss -1465.22589  last_update 10\n",
      "train: iter 476  trainloss -1346.97920  validloss -1432.36997±0.00000  bestvalidloss -1465.22589  last_update 11\n",
      "train: iter 477  trainloss -1355.32833  validloss -1303.94290±0.00000  bestvalidloss -1465.22589  last_update 12\n",
      "train: iter 478  trainloss -1402.09760  validloss -1292.33314±0.00000  bestvalidloss -1465.22589  last_update 13\n",
      "train: iter 479  trainloss -1445.12112  validloss -1406.67337±0.00000  bestvalidloss -1465.22589  last_update 14\n",
      "train: iter 480  trainloss -1434.67102  validloss -1459.21546±0.00000  bestvalidloss -1465.22589  last_update 15\n",
      "train: iter 481  trainloss -1254.80945  validloss -1390.08157±0.00000  bestvalidloss -1465.22589  last_update 16\n",
      "train: iter 482  trainloss -1352.86590  validloss -1084.47114±0.00000  bestvalidloss -1465.22589  last_update 17\n",
      "train: iter 483  trainloss -1458.32378  validloss -1437.81370±0.00000  bestvalidloss -1465.22589  last_update 18\n",
      "train: iter 484  trainloss -1406.50375  validloss -1475.99277±0.00000  bestvalidloss -1475.99277  last_update 0\n",
      "train: iter 485  trainloss -1254.98408  validloss -1366.39872±0.00000  bestvalidloss -1475.99277  last_update 1\n",
      "train: iter 486  trainloss -1359.45359  validloss -1328.01829±0.00000  bestvalidloss -1475.99277  last_update 2\n",
      "train: iter 487  trainloss -1449.37769  validloss -1442.84905±0.00000  bestvalidloss -1475.99277  last_update 3\n",
      "train: iter 488  trainloss -1372.26428  validloss -1418.30482±0.00000  bestvalidloss -1475.99277  last_update 4\n",
      "train: iter 489  trainloss -1251.50848  validloss -1322.56197±0.00000  bestvalidloss -1475.99277  last_update 5\n",
      "train: iter 490  trainloss -1430.98381  validloss -1388.17996±0.00000  bestvalidloss -1475.99277  last_update 6\n",
      "train: iter 491  trainloss -1414.81021  validloss -1440.50569±0.00000  bestvalidloss -1475.99277  last_update 7\n",
      "train: iter 492  trainloss -1431.78562  validloss -1462.39123±0.00000  bestvalidloss -1475.99277  last_update 8\n",
      "train: iter 493  trainloss -1386.51325  validloss -1416.95939±0.00000  bestvalidloss -1475.99277  last_update 9\n",
      "train: iter 494  trainloss -1424.85093  validloss -1425.56473±0.00000  bestvalidloss -1475.99277  last_update 10\n",
      "train: iter 495  trainloss -1434.94659  validloss -1416.53020±0.00000  bestvalidloss -1475.99277  last_update 11\n",
      "train: iter 496  trainloss -1416.12253  validloss -1484.96544±0.00000  bestvalidloss -1484.96544  last_update 0\n",
      "train: iter 497  trainloss -1314.97587  validloss -1458.12331±0.00000  bestvalidloss -1484.96544  last_update 1\n",
      "train: iter 498  trainloss -1375.36325  validloss -1348.17162±0.00000  bestvalidloss -1484.96544  last_update 2\n",
      "train: iter 499  trainloss -1352.56795  validloss -1363.32330±0.00000  bestvalidloss -1484.96544  last_update 3\n",
      "train: iter 500  trainloss -1442.69276  validloss -1382.06086±0.00000  bestvalidloss -1484.96544  last_update 4\n",
      "train: iter 501  trainloss -1452.23959  validloss -1439.16674±0.00000  bestvalidloss -1484.96544  last_update 5\n",
      "train: iter 502  trainloss -1434.83895  validloss -1476.37308±0.00000  bestvalidloss -1484.96544  last_update 6\n",
      "train: iter 503  trainloss -1450.24691  validloss -1496.69924±0.00000  bestvalidloss -1496.69924  last_update 0\n",
      "train: iter 504  trainloss -916.51057  validloss 466.28388±0.00000  bestvalidloss -1496.69924  last_update 1\n",
      "train: iter 505  trainloss -1174.71595  validloss -1132.77868±0.00000  bestvalidloss -1496.69924  last_update 2\n",
      "train: iter 506  trainloss -1317.14131  validloss -1281.28070±0.00000  bestvalidloss -1496.69924  last_update 3\n",
      "train: iter 507  trainloss -1283.97517  validloss -1355.68258±0.00000  bestvalidloss -1496.69924  last_update 4\n",
      "train: iter 508  trainloss -1255.08675  validloss -1047.41275±0.00000  bestvalidloss -1496.69924  last_update 5\n",
      "train: iter 509  trainloss -1214.00282  validloss -1369.17400±0.00000  bestvalidloss -1496.69924  last_update 6\n",
      "train: iter 510  trainloss -1358.53309  validloss -1291.80452±0.00000  bestvalidloss -1496.69924  last_update 7\n",
      "train: iter 511  trainloss -1407.91783  validloss -1376.62215±0.00000  bestvalidloss -1496.69924  last_update 8\n",
      "train: iter 512  trainloss -1428.38538  validloss -1422.16489±0.00000  bestvalidloss -1496.69924  last_update 9\n",
      "train: iter 513  trainloss -1423.51631  validloss -1437.19881±0.00000  bestvalidloss -1496.69924  last_update 10\n",
      "train: iter 514  trainloss -1427.17739  validloss -1454.36839±0.00000  bestvalidloss -1496.69924  last_update 11\n",
      "train: iter 515  trainloss -1411.25082  validloss -1411.38772±0.00000  bestvalidloss -1496.69924  last_update 12\n",
      "train: iter 516  trainloss -1445.20385  validloss -1434.31992±0.00000  bestvalidloss -1496.69924  last_update 13\n",
      "train: iter 517  trainloss -1399.66195  validloss -1490.13051±0.00000  bestvalidloss -1496.69924  last_update 14\n",
      "train: iter 518  trainloss -1389.60104  validloss -1366.05162±0.00000  bestvalidloss -1496.69924  last_update 15\n",
      "train: iter 519  trainloss -1329.47299  validloss -1193.57408±0.00000  bestvalidloss -1496.69924  last_update 16\n",
      "train: iter 520  trainloss -1312.53945  validloss -1434.94642±0.00000  bestvalidloss -1496.69924  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 521  trainloss -1358.18689  validloss -1148.98571±0.00000  bestvalidloss -1496.69924  last_update 18\n",
      "train: iter 522  trainloss -1443.82387  validloss -1391.93887±0.00000  bestvalidloss -1496.69924  last_update 19\n",
      "train: iter 523  trainloss -1406.05874  validloss -1431.79289±0.00000  bestvalidloss -1496.69924  last_update 20\n",
      "train: iter 524  trainloss -1439.30207  validloss -1395.61512±0.00000  bestvalidloss -1496.69924  last_update 21\n",
      "train: iter 525  trainloss -1428.18017  validloss -1414.84212±0.00000  bestvalidloss -1496.69924  last_update 22\n",
      "train: iter 526  trainloss -1434.47211  validloss -1406.55155±0.00000  bestvalidloss -1496.69924  last_update 23\n",
      "train: iter 527  trainloss -1383.93797  validloss -1468.86128±0.00000  bestvalidloss -1496.69924  last_update 24\n",
      "train: iter 528  trainloss -1315.85232  validloss -1427.35034±0.00000  bestvalidloss -1496.69924  last_update 25\n",
      "train: iter 529  trainloss -1452.87887  validloss -1388.70145±0.00000  bestvalidloss -1496.69924  last_update 26\n",
      "train: iter 530  trainloss -1446.55483  validloss -1483.22010±0.00000  bestvalidloss -1496.69924  last_update 27\n",
      "train: iter 531  trainloss -1434.48763  validloss -1468.82994±0.00000  bestvalidloss -1496.69924  last_update 28\n",
      "train: iter 532  trainloss -1371.56611  validloss -1409.70079±0.00000  bestvalidloss -1496.69924  last_update 29\n",
      "train: iter 533  trainloss -1375.04917  validloss -1385.84514±0.00000  bestvalidloss -1496.69924  last_update 30\n",
      "train: iter 534  trainloss -1457.86834  validloss -1462.59579±0.00000  bestvalidloss -1496.69924  last_update 31\n",
      "train: iter 535  trainloss -1442.93799  validloss -1404.33340±0.00000  bestvalidloss -1496.69924  last_update 32\n",
      "train: iter 536  trainloss -1404.12967  validloss -1474.13265±0.00000  bestvalidloss -1496.69924  last_update 33\n",
      "train: iter 537  trainloss -1441.78203  validloss -1419.03913±0.00000  bestvalidloss -1496.69924  last_update 34\n",
      "train: iter 538  trainloss -1425.96572  validloss -1469.59610±0.00000  bestvalidloss -1496.69924  last_update 35\n",
      "train: iter 539  trainloss -1097.41203  validloss -1298.87401±0.00000  bestvalidloss -1496.69924  last_update 36\n",
      "train: iter 540  trainloss -1239.22838  validloss -803.27023±0.00000  bestvalidloss -1496.69924  last_update 37\n",
      "train: iter 541  trainloss -1428.29163  validloss -1401.43203±0.00000  bestvalidloss -1496.69924  last_update 38\n",
      "train: iter 542  trainloss -1463.73308  validloss -1434.34759±0.00000  bestvalidloss -1496.69924  last_update 39\n",
      "train: iter 543  trainloss -1364.08935  validloss -1430.95059±0.00000  bestvalidloss -1496.69924  last_update 40\n",
      "train: iter 544  trainloss -1430.40039  validloss -1398.52925±0.00000  bestvalidloss -1496.69924  last_update 41\n",
      "train: iter 545  trainloss -1436.70032  validloss -1420.20168±0.00000  bestvalidloss -1496.69924  last_update 42\n",
      "train: iter 546  trainloss -1461.13281  validloss -1445.28557±0.00000  bestvalidloss -1496.69924  last_update 43\n",
      "train: iter 547  trainloss -1481.93745  validloss -1463.57978±0.00000  bestvalidloss -1496.69924  last_update 44\n",
      "train: iter 548  trainloss -629.83403  validloss -1474.93415±0.00000  bestvalidloss -1496.69924  last_update 45\n",
      "train: iter 549  trainloss -973.24380  validloss -961.09017±0.00000  bestvalidloss -1496.69924  last_update 46\n",
      "train: iter 550  trainloss -1286.46137  validloss -1156.13684±0.00000  bestvalidloss -1496.69924  last_update 47\n",
      "train: iter 551  trainloss -981.55335  validloss -1336.74734±0.00000  bestvalidloss -1496.69924  last_update 48\n",
      "train: iter 552  trainloss -1219.00786  validloss -991.06699±0.00000  bestvalidloss -1496.69924  last_update 49\n",
      "train: iter 553  trainloss -1342.64700  validloss -1211.11913±0.00000  bestvalidloss -1496.69924  last_update 50\n",
      "train: iter 554  trainloss -1356.00768  validloss -1341.82590±0.00000  bestvalidloss -1496.69924  last_update 51\n",
      "train: iter 555  trainloss -1398.22920  validloss -1338.93456±0.00000  bestvalidloss -1496.69924  last_update 52\n",
      "train: iter 556  trainloss -1414.41314  validloss -1375.96799±0.00000  bestvalidloss -1496.69924  last_update 53\n",
      "train: iter 557  trainloss -1440.29749  validloss -1405.51139±0.00000  bestvalidloss -1496.69924  last_update 54\n",
      "train: iter 558  trainloss -1266.15611  validloss -1435.10208±0.00000  bestvalidloss -1496.69924  last_update 55\n",
      "train: iter 559  trainloss -1279.27895  validloss -1132.08740±0.00000  bestvalidloss -1496.69924  last_update 56\n",
      "train: iter 560  trainloss -1415.50046  validloss -1331.53875±0.00000  bestvalidloss -1496.69924  last_update 57\n",
      "train: iter 561  trainloss -1444.94635  validloss -1407.55710±0.00000  bestvalidloss -1496.69924  last_update 58\n",
      "train: iter 562  trainloss -1441.42460  validloss -1420.84563±0.00000  bestvalidloss -1496.69924  last_update 59\n",
      "train: iter 563  trainloss -1452.52525  validloss -1411.53282±0.00000  bestvalidloss -1496.69924  last_update 60\n",
      "train: iter 564  trainloss -1443.08156  validloss -1422.40341±0.00000  bestvalidloss -1496.69924  last_update 61\n",
      "train: iter 565  trainloss -1401.65005  validloss -1436.69710±0.00000  bestvalidloss -1496.69924  last_update 62\n",
      "train: iter 566  trainloss -1396.81342  validloss -1452.89901±0.00000  bestvalidloss -1496.69924  last_update 63\n",
      "train: iter 567  trainloss -1447.41660  validloss -1408.45078±0.00000  bestvalidloss -1496.69924  last_update 64\n",
      "train: iter 568  trainloss -1138.43458  validloss -1155.09022±0.00000  bestvalidloss -1496.69924  last_update 65\n",
      "train: iter 569  trainloss -1358.03248  validloss -1326.73249±0.00000  bestvalidloss -1496.69924  last_update 66\n",
      "train: iter 570  trainloss -1197.50620  validloss -1323.75934±0.00000  bestvalidloss -1496.69924  last_update 67\n",
      "train: iter 571  trainloss -1095.84978  validloss -796.01807±0.00000  bestvalidloss -1496.69924  last_update 68\n",
      "train: iter 572  trainloss -1295.19963  validloss -1295.47034±0.00000  bestvalidloss -1496.69924  last_update 69\n",
      "train: iter 573  trainloss -1343.91484  validloss -1312.01174±0.00000  bestvalidloss -1496.69924  last_update 70\n",
      "train: iter 574  trainloss -1417.07716  validloss -1341.25579±0.00000  bestvalidloss -1496.69924  last_update 71\n",
      "train: iter 575  trainloss -1431.83247  validloss -1350.51199±0.00000  bestvalidloss -1496.69924  last_update 72\n",
      "train: iter 576  trainloss -1461.15885  validloss -1445.67392±0.00000  bestvalidloss -1496.69924  last_update 73\n",
      "train: iter 577  trainloss -1453.09043  validloss -1449.14567±0.00000  bestvalidloss -1496.69924  last_update 74\n",
      "train: iter 578  trainloss -1443.42512  validloss -1453.46804±0.00000  bestvalidloss -1496.69924  last_update 75\n",
      "train: iter 579  trainloss -1460.17364  validloss -1434.59574±0.00000  bestvalidloss -1496.69924  last_update 76\n",
      "train: iter 580  trainloss -1450.80429  validloss -1444.45515±0.00000  bestvalidloss -1496.69924  last_update 77\n",
      "train: iter 581  trainloss -1405.97494  validloss -1440.07769±0.00000  bestvalidloss -1496.69924  last_update 78\n",
      "train: iter 582  trainloss -1136.88364  validloss -1468.55706±0.00000  bestvalidloss -1496.69924  last_update 79\n",
      "train: iter 583  trainloss -1373.57609  validloss -1297.20731±0.00000  bestvalidloss -1496.69924  last_update 80\n",
      "train: iter 584  trainloss -1367.82112  validloss -1432.36564±0.00000  bestvalidloss -1496.69924  last_update 81\n",
      "train: iter 585  trainloss -1451.63991  validloss -1405.97879±0.00000  bestvalidloss -1496.69924  last_update 82\n",
      "train: iter 586  trainloss -1450.65825  validloss -1469.73109±0.00000  bestvalidloss -1496.69924  last_update 83\n",
      "train: iter 587  trainloss -1468.05950  validloss -1450.06663±0.00000  bestvalidloss -1496.69924  last_update 84\n",
      "train: iter 588  trainloss -1455.25374  validloss -1483.63902±0.00000  bestvalidloss -1496.69924  last_update 85\n",
      "train: iter 589  trainloss -1308.35659  validloss -1385.16678±0.00000  bestvalidloss -1496.69924  last_update 86\n",
      "train: iter 590  trainloss -1400.32596  validloss -1295.69730±0.00000  bestvalidloss -1496.69924  last_update 87\n",
      "train: iter 591  trainloss -1491.56773  validloss -1489.73115±0.00000  bestvalidloss -1496.69924  last_update 88\n",
      "train: iter 592  trainloss -1495.86293  validloss -1503.81851±0.00000  bestvalidloss -1503.81851  last_update 0\n",
      "train: iter 593  trainloss -1420.95942  validloss -1499.88455±0.00000  bestvalidloss -1503.81851  last_update 1\n",
      "train: iter 594  trainloss -1436.66440  validloss -1133.23469±0.00000  bestvalidloss -1503.81851  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 595  trainloss -1400.55723  validloss -1420.36284±0.00000  bestvalidloss -1503.81851  last_update 3\n",
      "train: iter 596  trainloss -1430.37909  validloss -1462.70714±0.00000  bestvalidloss -1503.81851  last_update 4\n",
      "train: iter 597  trainloss -1443.06841  validloss -1385.01097±0.00000  bestvalidloss -1503.81851  last_update 5\n",
      "train: iter 598  trainloss -1492.55418  validloss -1474.67743±0.00000  bestvalidloss -1503.81851  last_update 6\n",
      "train: iter 599  trainloss -1477.96065  validloss -1479.93046±0.00000  bestvalidloss -1503.81851  last_update 7\n",
      "train: iter 600  trainloss -1320.08265  validloss -1467.92639±0.00000  bestvalidloss -1503.81851  last_update 8\n",
      "train: iter 601  trainloss -1435.92415  validloss -1403.73200±0.00000  bestvalidloss -1503.81851  last_update 9\n",
      "train: iter 602  trainloss -1405.16410  validloss -1322.80461±0.00000  bestvalidloss -1503.81851  last_update 10\n",
      "train: iter 603  trainloss -1429.07535  validloss -1394.38601±0.00000  bestvalidloss -1503.81851  last_update 11\n",
      "train: iter 604  trainloss -1430.57968  validloss -1483.32666±0.00000  bestvalidloss -1503.81851  last_update 12\n",
      "train: iter 605  trainloss -1453.94474  validloss -1450.52198±0.00000  bestvalidloss -1503.81851  last_update 13\n",
      "train: iter 606  trainloss -1488.02866  validloss -1477.80342±0.00000  bestvalidloss -1503.81851  last_update 14\n",
      "train: iter 607  trainloss -1471.71974  validloss -1488.38476±0.00000  bestvalidloss -1503.81851  last_update 15\n",
      "train: iter 608  trainloss -1402.66600  validloss -1505.59013±0.00000  bestvalidloss -1505.59013  last_update 0\n",
      "train: iter 609  trainloss -1342.68290  validloss -1344.15520±0.00000  bestvalidloss -1505.59013  last_update 1\n",
      "train: iter 610  trainloss -1462.96467  validloss -1437.11259±0.00000  bestvalidloss -1505.59013  last_update 2\n",
      "train: iter 611  trainloss -1490.40912  validloss -1456.53687±0.00000  bestvalidloss -1505.59013  last_update 3\n",
      "train: iter 612  trainloss -1467.67077  validloss -1488.81892±0.00000  bestvalidloss -1505.59013  last_update 4\n",
      "train: iter 613  trainloss -1438.57587  validloss -1460.98592±0.00000  bestvalidloss -1505.59013  last_update 5\n",
      "train: iter 614  trainloss -1436.11038  validloss -1481.42720±0.00000  bestvalidloss -1505.59013  last_update 6\n",
      "train: iter 615  trainloss -935.54322  validloss -1395.41224±0.00000  bestvalidloss -1505.59013  last_update 7\n",
      "train: iter 616  trainloss -1386.02387  validloss -1257.05581±0.00000  bestvalidloss -1505.59013  last_update 8\n",
      "train: iter 617  trainloss -1417.90697  validloss -1317.53320±0.00000  bestvalidloss -1505.59013  last_update 9\n",
      "train: iter 618  trainloss -1432.93897  validloss -1347.75141±0.00000  bestvalidloss -1505.59013  last_update 10\n",
      "train: iter 619  trainloss -1476.63459  validloss -1458.36710±0.00000  bestvalidloss -1505.59013  last_update 11\n",
      "train: iter 620  trainloss -1458.15207  validloss -1443.27084±0.00000  bestvalidloss -1505.59013  last_update 12\n",
      "train: iter 621  trainloss -1484.00060  validloss -1428.14221±0.00000  bestvalidloss -1505.59013  last_update 13\n",
      "train: iter 622  trainloss -1480.70396  validloss -1383.97166±0.00000  bestvalidloss -1505.59013  last_update 14\n",
      "train: iter 623  trainloss -1435.57057  validloss -1136.33497±0.00000  bestvalidloss -1505.59013  last_update 15\n",
      "train: iter 624  trainloss -1446.28520  validloss -1446.54423±0.00000  bestvalidloss -1505.59013  last_update 16\n",
      "train: iter 625  trainloss -1486.02784  validloss -1467.53949±0.00000  bestvalidloss -1505.59013  last_update 17\n",
      "train: iter 626  trainloss -1100.34845  validloss -1492.91711±0.00000  bestvalidloss -1505.59013  last_update 18\n",
      "train: iter 627  trainloss -439.23658  validloss -785.18005±0.00000  bestvalidloss -1505.59013  last_update 19\n",
      "train: iter 628  trainloss -979.22230  validloss -352.53689±0.00000  bestvalidloss -1505.59013  last_update 20\n",
      "train: iter 629  trainloss -1288.25028  validloss -1176.81710±0.00000  bestvalidloss -1505.59013  last_update 21\n",
      "train: iter 630  trainloss -1364.18177  validloss -1235.65699±0.00000  bestvalidloss -1505.59013  last_update 22\n",
      "train: iter 631  trainloss -1305.46628  validloss -1236.18006±0.00000  bestvalidloss -1505.59013  last_update 23\n",
      "train: iter 632  trainloss -1394.24795  validloss -1285.45820±0.00000  bestvalidloss -1505.59013  last_update 24\n",
      "train: iter 633  trainloss -1398.52611  validloss -1343.92108±0.00000  bestvalidloss -1505.59013  last_update 25\n",
      "train: iter 634  trainloss -1421.32513  validloss -1293.88959±0.00000  bestvalidloss -1505.59013  last_update 26\n",
      "train: iter 635  trainloss -1370.84623  validloss -1435.63362±0.00000  bestvalidloss -1505.59013  last_update 27\n",
      "train: iter 636  trainloss -1477.42079  validloss -1422.64393±0.00000  bestvalidloss -1505.59013  last_update 28\n",
      "train: iter 637  trainloss -1399.18728  validloss -1420.85907±0.00000  bestvalidloss -1505.59013  last_update 29\n",
      "train: iter 638  trainloss -1439.31333  validloss -1441.93589±0.00000  bestvalidloss -1505.59013  last_update 30\n",
      "train: iter 639  trainloss -1485.61689  validloss -1443.51169±0.00000  bestvalidloss -1505.59013  last_update 31\n",
      "train: iter 640  trainloss -1273.92897  validloss -1476.94637±0.00000  bestvalidloss -1505.59013  last_update 32\n",
      "train: iter 641  trainloss -1418.21659  validloss -1350.75172±0.00000  bestvalidloss -1505.59013  last_update 33\n",
      "train: iter 642  trainloss -1457.70065  validloss -1426.44642±0.00000  bestvalidloss -1505.59013  last_update 34\n",
      "train: iter 643  trainloss -1452.08484  validloss -1446.59281±0.00000  bestvalidloss -1505.59013  last_update 35\n",
      "train: iter 644  trainloss -1387.50852  validloss -1224.83368±0.00000  bestvalidloss -1505.59013  last_update 36\n",
      "train: iter 645  trainloss -1338.51409  validloss -1347.15518±0.00000  bestvalidloss -1505.59013  last_update 37\n",
      "train: iter 646  trainloss -1266.09210  validloss 1.75291±0.00000  bestvalidloss -1505.59013  last_update 38\n",
      "train: iter 647  trainloss -1452.16513  validloss -1422.12943±0.00000  bestvalidloss -1505.59013  last_update 39\n",
      "train: iter 648  trainloss -1468.87235  validloss -1430.63163±0.00000  bestvalidloss -1505.59013  last_update 40\n",
      "train: iter 649  trainloss -1499.48569  validloss -1456.64358±0.00000  bestvalidloss -1505.59013  last_update 41\n",
      "train: iter 650  trainloss -1400.03530  validloss -1506.93357±0.00000  bestvalidloss -1506.93357  last_update 0\n",
      "train: iter 651  trainloss -1469.78154  validloss -1427.24526±0.00000  bestvalidloss -1506.93357  last_update 1\n",
      "train: iter 652  trainloss -1443.25524  validloss -1450.87990±0.00000  bestvalidloss -1506.93357  last_update 2\n",
      "train: iter 653  trainloss -1421.73394  validloss -1399.37202±0.00000  bestvalidloss -1506.93357  last_update 3\n",
      "train: iter 654  trainloss -1412.02923  validloss -1419.58276±0.00000  bestvalidloss -1506.93357  last_update 4\n",
      "train: iter 655  trainloss -1440.73432  validloss -1411.57492±0.00000  bestvalidloss -1506.93357  last_update 5\n",
      "train: iter 656  trainloss -1379.32225  validloss -1266.00130±0.00000  bestvalidloss -1506.93357  last_update 6\n",
      "train: iter 657  trainloss -1377.72292  validloss -1138.07133±0.00000  bestvalidloss -1506.93357  last_update 7\n",
      "train: iter 658  trainloss -1483.55130  validloss -1447.75590±0.00000  bestvalidloss -1506.93357  last_update 8\n",
      "train: iter 659  trainloss -1497.13863  validloss -1489.35535±0.00000  bestvalidloss -1506.93357  last_update 9\n",
      "train: iter 660  trainloss -1402.58475  validloss -1481.82587±0.00000  bestvalidloss -1506.93357  last_update 10\n",
      "train: iter 661  trainloss -1444.61002  validloss -1386.32387±0.00000  bestvalidloss -1506.93357  last_update 11\n",
      "train: iter 662  trainloss -1476.08761  validloss -1480.59140±0.00000  bestvalidloss -1506.93357  last_update 12\n",
      "train: iter 663  trainloss -1378.35643  validloss -1430.51524±0.00000  bestvalidloss -1506.93357  last_update 13\n",
      "train: iter 664  trainloss -1493.07953  validloss -1477.84105±0.00000  bestvalidloss -1506.93357  last_update 14\n",
      "train: iter 665  trainloss -1426.27390  validloss -1505.15937±0.00000  bestvalidloss -1506.93357  last_update 15\n",
      "train: iter 666  trainloss -1487.43537  validloss -1431.55433±0.00000  bestvalidloss -1506.93357  last_update 16\n",
      "train: iter 667  trainloss -1461.48978  validloss -1481.84282±0.00000  bestvalidloss -1506.93357  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 668  trainloss -1365.43983  validloss -1482.15350±0.00000  bestvalidloss -1506.93357  last_update 18\n",
      "train: iter 669  trainloss -1474.45705  validloss -1394.51525±0.00000  bestvalidloss -1506.93357  last_update 19\n",
      "train: iter 670  trainloss -1519.54428  validloss -1506.04999±0.00000  bestvalidloss -1506.93357  last_update 20\n",
      "train: iter 671  trainloss -1520.85268  validloss -1528.04306±0.00000  bestvalidloss -1528.04306  last_update 0\n",
      "train: iter 672  trainloss -1380.01143  validloss -1519.07973±0.00000  bestvalidloss -1528.04306  last_update 1\n",
      "train: iter 673  trainloss -1240.59486  validloss -1286.43712±0.00000  bestvalidloss -1528.04306  last_update 2\n",
      "train: iter 674  trainloss -1421.95831  validloss -1375.76136±0.00000  bestvalidloss -1528.04306  last_update 3\n",
      "train: iter 675  trainloss -1467.65214  validloss -1447.71149±0.00000  bestvalidloss -1528.04306  last_update 4\n",
      "train: iter 676  trainloss -1489.37313  validloss -1453.90018±0.00000  bestvalidloss -1528.04306  last_update 5\n",
      "train: iter 677  trainloss -1432.80460  validloss -1495.96169±0.00000  bestvalidloss -1528.04306  last_update 6\n",
      "train: iter 678  trainloss -1396.99902  validloss -1388.15294±0.00000  bestvalidloss -1528.04306  last_update 7\n",
      "train: iter 679  trainloss -1474.38564  validloss -1442.00653±0.00000  bestvalidloss -1528.04306  last_update 8\n",
      "train: iter 680  trainloss -1494.66646  validloss -1475.22984±0.00000  bestvalidloss -1528.04306  last_update 9\n",
      "train: iter 681  trainloss -1411.45773  validloss -1462.72461±0.00000  bestvalidloss -1528.04306  last_update 10\n",
      "train: iter 682  trainloss -1503.53130  validloss -1403.28969±0.00000  bestvalidloss -1528.04306  last_update 11\n",
      "train: iter 683  trainloss -1505.85715  validloss -1515.07574±0.00000  bestvalidloss -1528.04306  last_update 12\n",
      "train: iter 684  trainloss -1468.86854  validloss -1438.42596±0.00000  bestvalidloss -1528.04306  last_update 13\n",
      "train: iter 685  trainloss -1388.27347  validloss -1455.89149±0.00000  bestvalidloss -1528.04306  last_update 14\n",
      "train: iter 686  trainloss -1426.09779  validloss -1299.69465±0.00000  bestvalidloss -1528.04306  last_update 15\n",
      "train: iter 687  trainloss -1505.27445  validloss -1427.57352±0.00000  bestvalidloss -1528.04306  last_update 16\n",
      "train: iter 688  trainloss -1508.64540  validloss -1516.66215±0.00000  bestvalidloss -1528.04306  last_update 17\n",
      "train: iter 689  trainloss -1468.90382  validloss -1495.57926±0.00000  bestvalidloss -1528.04306  last_update 18\n",
      "train: iter 690  trainloss -1399.03869  validloss -1202.86082±0.00000  bestvalidloss -1528.04306  last_update 19\n",
      "train: iter 691  trainloss -1454.99033  validloss -1428.35517±0.00000  bestvalidloss -1528.04306  last_update 20\n",
      "train: iter 692  trainloss -1432.63405  validloss -1467.22919±0.00000  bestvalidloss -1528.04306  last_update 21\n",
      "train: iter 693  trainloss -1423.57603  validloss -418.31979±0.00000  bestvalidloss -1528.04306  last_update 22\n",
      "train: iter 694  trainloss -1518.05087  validloss -1512.11899±0.00000  bestvalidloss -1528.04306  last_update 23\n",
      "train: iter 695  trainloss -1412.44265  validloss -1491.26575±0.00000  bestvalidloss -1528.04306  last_update 24\n",
      "train: iter 696  trainloss -1424.76659  validloss -1423.24124±0.00000  bestvalidloss -1528.04306  last_update 25\n",
      "train: iter 697  trainloss -1388.10538  validloss -1432.29297±0.00000  bestvalidloss -1528.04306  last_update 26\n",
      "train: iter 698  trainloss -1471.31148  validloss -1445.79012±0.00000  bestvalidloss -1528.04306  last_update 27\n",
      "train: iter 699  trainloss -1486.76144  validloss -1415.85680±0.00000  bestvalidloss -1528.04306  last_update 28\n",
      "train: iter 700  trainloss -1511.25312  validloss -1490.10618±0.00000  bestvalidloss -1528.04306  last_update 29\n",
      "train: iter 701  trainloss -1522.03307  validloss -1485.33579±0.00000  bestvalidloss -1528.04306  last_update 30\n",
      "train: iter 702  trainloss -1378.83791  validloss -1499.48889±0.00000  bestvalidloss -1528.04306  last_update 31\n",
      "train: iter 703  trainloss -1327.92921  validloss -1056.60807±0.00000  bestvalidloss -1528.04306  last_update 32\n",
      "train: iter 704  trainloss -1482.52336  validloss -1467.60324±0.00000  bestvalidloss -1528.04306  last_update 33\n",
      "train: iter 705  trainloss -1486.39086  validloss -1483.99159±0.00000  bestvalidloss -1528.04306  last_update 34\n",
      "train: iter 706  trainloss -1428.32507  validloss -1326.75488±0.00000  bestvalidloss -1528.04306  last_update 35\n",
      "train: iter 707  trainloss -1463.56212  validloss -1418.67176±0.00000  bestvalidloss -1528.04306  last_update 36\n",
      "train: iter 708  trainloss -1491.23797  validloss -1517.90545±0.00000  bestvalidloss -1528.04306  last_update 37\n",
      "train: iter 709  trainloss -1510.10427  validloss -1436.00230±0.00000  bestvalidloss -1528.04306  last_update 38\n",
      "train: iter 710  trainloss -1493.06743  validloss -1441.68026±0.00000  bestvalidloss -1528.04306  last_update 39\n",
      "train: iter 711  trainloss -1522.00104  validloss -1505.90952±0.00000  bestvalidloss -1528.04306  last_update 40\n",
      "train: iter 712  trainloss -1466.95286  validloss -1522.37934±0.00000  bestvalidloss -1528.04306  last_update 41\n",
      "train: iter 713  trainloss -1491.01149  validloss -1495.79562±0.00000  bestvalidloss -1528.04306  last_update 42\n",
      "train: iter 714  trainloss -1475.37901  validloss -1437.67701±0.00000  bestvalidloss -1528.04306  last_update 43\n",
      "train: iter 715  trainloss -1504.64040  validloss -1494.08871±0.00000  bestvalidloss -1528.04306  last_update 44\n",
      "train: iter 716  trainloss -1414.48228  validloss -1539.49625±0.00000  bestvalidloss -1539.49625  last_update 0\n",
      "train: iter 717  trainloss -1379.28686  validloss -1285.85861±0.00000  bestvalidloss -1539.49625  last_update 1\n",
      "train: iter 718  trainloss -1472.03254  validloss -1477.54096±0.00000  bestvalidloss -1539.49625  last_update 2\n",
      "train: iter 719  trainloss -1488.72653  validloss -1489.37157±0.00000  bestvalidloss -1539.49625  last_update 3\n",
      "train: iter 720  trainloss -1516.42094  validloss -1523.37837±0.00000  bestvalidloss -1539.49625  last_update 4\n",
      "train: iter 721  trainloss -1410.67834  validloss -1475.77321±0.00000  bestvalidloss -1539.49625  last_update 5\n",
      "train: iter 722  trainloss -1477.42062  validloss -1408.90797±0.00000  bestvalidloss -1539.49625  last_update 6\n",
      "train: iter 723  trainloss -1417.89718  validloss -1495.14239±0.00000  bestvalidloss -1539.49625  last_update 7\n",
      "train: iter 724  trainloss -1354.33000  validloss -1403.88145±0.00000  bestvalidloss -1539.49625  last_update 8\n",
      "train: iter 725  trainloss -1480.33077  validloss -1418.68057±0.00000  bestvalidloss -1539.49625  last_update 9\n",
      "train: iter 726  trainloss -1496.27350  validloss -1468.17445±0.00000  bestvalidloss -1539.49625  last_update 10\n",
      "train: iter 727  trainloss -1506.84301  validloss -1444.32433±0.00000  bestvalidloss -1539.49625  last_update 11\n",
      "train: iter 728  trainloss -1518.79172  validloss -1489.34033±0.00000  bestvalidloss -1539.49625  last_update 12\n",
      "train: iter 729  trainloss -1474.01883  validloss -1453.14663±0.00000  bestvalidloss -1539.49625  last_update 13\n",
      "train: iter 730  trainloss -1384.65814  validloss -1422.73234±0.00000  bestvalidloss -1539.49625  last_update 14\n",
      "train: iter 731  trainloss -1501.90201  validloss -1428.96825±0.00000  bestvalidloss -1539.49625  last_update 15\n",
      "train: iter 732  trainloss -1525.59534  validloss -1508.64214±0.00000  bestvalidloss -1539.49625  last_update 16\n",
      "train: iter 733  trainloss -1478.74570  validloss -1492.64534±0.00000  bestvalidloss -1539.49625  last_update 17\n",
      "train: iter 734  trainloss -1112.46542  validloss -1181.65319±0.00000  bestvalidloss -1539.49625  last_update 18\n",
      "train: iter 735  trainloss -1440.72911  validloss -1327.12167±0.00000  bestvalidloss -1539.49625  last_update 19\n",
      "train: iter 736  trainloss -1492.81845  validloss -1445.25720±0.00000  bestvalidloss -1539.49625  last_update 20\n",
      "train: iter 737  trainloss -1517.35371  validloss -1490.03774±0.00000  bestvalidloss -1539.49625  last_update 21\n",
      "train: iter 738  trainloss -1501.31057  validloss -1487.62432±0.00000  bestvalidloss -1539.49625  last_update 22\n",
      "train: iter 739  trainloss -426.83948  validloss -710.31381±0.00000  bestvalidloss -1539.49625  last_update 23\n",
      "train: iter 740  trainloss -663.09663  validloss 3557.50251±0.00000  bestvalidloss -1539.49625  last_update 24\n",
      "train: iter 741  trainloss -1209.26621  validloss -1114.16317±0.00000  bestvalidloss -1539.49625  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 742  trainloss -1329.75049  validloss -1289.40708±0.00000  bestvalidloss -1539.49625  last_update 26\n",
      "train: iter 743  trainloss -1365.65748  validloss -1338.63896±0.00000  bestvalidloss -1539.49625  last_update 27\n",
      "train: iter 744  trainloss -1324.64196  validloss -1341.53939±0.00000  bestvalidloss -1539.49625  last_update 28\n",
      "train: iter 745  trainloss -1394.95163  validloss -1309.06614±0.00000  bestvalidloss -1539.49625  last_update 29\n",
      "train: iter 746  trainloss -1466.21061  validloss -1417.98259±0.00000  bestvalidloss -1539.49625  last_update 30\n",
      "train: iter 747  trainloss -1461.27859  validloss -1460.32207±0.00000  bestvalidloss -1539.49625  last_update 31\n",
      "train: iter 748  trainloss -1316.92700  validloss -978.51792±0.00000  bestvalidloss -1539.49625  last_update 32\n",
      "train: iter 749  trainloss -1254.45647  validloss -1004.59752±0.00000  bestvalidloss -1539.49625  last_update 33\n",
      "train: iter 750  trainloss -1392.86053  validloss -1292.41751±0.00000  bestvalidloss -1539.49625  last_update 34\n",
      "train: iter 751  trainloss -1465.56440  validloss -1395.79825±0.00000  bestvalidloss -1539.49625  last_update 35\n",
      "train: iter 752  trainloss -1472.15859  validloss -1422.34781±0.00000  bestvalidloss -1539.49625  last_update 36\n",
      "train: iter 753  trainloss -1487.96372  validloss -1416.89926±0.00000  bestvalidloss -1539.49625  last_update 37\n",
      "train: iter 754  trainloss -1502.01317  validloss -1449.73483±0.00000  bestvalidloss -1539.49625  last_update 38\n",
      "train: iter 755  trainloss -1512.10694  validloss -1476.94023±0.00000  bestvalidloss -1539.49625  last_update 39\n",
      "train: iter 756  trainloss -1462.95258  validloss -1483.79961±0.00000  bestvalidloss -1539.49625  last_update 40\n",
      "train: iter 757  trainloss -1415.87962  validloss -1428.75350±0.00000  bestvalidloss -1539.49625  last_update 41\n",
      "train: iter 758  trainloss -1490.75521  validloss -1424.99690±0.00000  bestvalidloss -1539.49625  last_update 42\n",
      "train: iter 759  trainloss -1513.76641  validloss -1482.11542±0.00000  bestvalidloss -1539.49625  last_update 43\n",
      "train: iter 760  trainloss -1501.10937  validloss -1477.43050±0.00000  bestvalidloss -1539.49625  last_update 44\n",
      "train: iter 761  trainloss -1498.50481  validloss -1483.86344±0.00000  bestvalidloss -1539.49625  last_update 45\n",
      "train: iter 762  trainloss -1486.95464  validloss -1490.47290±0.00000  bestvalidloss -1539.49625  last_update 46\n",
      "train: iter 763  trainloss -1495.90193  validloss -1438.98241±0.00000  bestvalidloss -1539.49625  last_update 47\n",
      "train: iter 764  trainloss -1458.31188  validloss -1449.29161±0.00000  bestvalidloss -1539.49625  last_update 48\n",
      "train: iter 765  trainloss -1434.22572  validloss -1412.75535±0.00000  bestvalidloss -1539.49625  last_update 49\n",
      "train: iter 766  trainloss -1508.17433  validloss -1447.15577±0.00000  bestvalidloss -1539.49625  last_update 50\n",
      "train: iter 767  trainloss -1517.07848  validloss -1500.30858±0.00000  bestvalidloss -1539.49625  last_update 51\n",
      "train: iter 768  trainloss -1475.40329  validloss -1495.23076±0.00000  bestvalidloss -1539.49625  last_update 52\n",
      "train: iter 769  trainloss -1415.87093  validloss -1362.77828±0.00000  bestvalidloss -1539.49625  last_update 53\n",
      "train: iter 770  trainloss -1514.34062  validloss -1476.55298±0.00000  bestvalidloss -1539.49625  last_update 54\n",
      "train: iter 771  trainloss -1527.65854  validloss -1506.64828±0.00000  bestvalidloss -1539.49625  last_update 55\n",
      "train: iter 772  trainloss -1426.35586  validloss -1517.91122±0.00000  bestvalidloss -1539.49625  last_update 56\n",
      "train: iter 773  trainloss -1475.97255  validloss -1428.41156±0.00000  bestvalidloss -1539.49625  last_update 57\n",
      "train: iter 774  trainloss -1431.28647  validloss -1398.11909±0.00000  bestvalidloss -1539.49625  last_update 58\n",
      "train: iter 775  trainloss -1450.96890  validloss -1230.13455±0.00000  bestvalidloss -1539.49625  last_update 59\n",
      "train: iter 776  trainloss -1527.30448  validloss -1508.60993±0.00000  bestvalidloss -1539.49625  last_update 60\n",
      "train: iter 777  trainloss -1532.47974  validloss -1516.33454±0.00000  bestvalidloss -1539.49625  last_update 61\n",
      "train: iter 778  trainloss -1499.99078  validloss -1499.77557±0.00000  bestvalidloss -1539.49625  last_update 62\n",
      "train: iter 779  trainloss -1504.85631  validloss -1449.80854±0.00000  bestvalidloss -1539.49625  last_update 63\n",
      "train: iter 780  trainloss -1459.56517  validloss -1491.14746±0.00000  bestvalidloss -1539.49625  last_update 64\n",
      "train: iter 781  trainloss -1477.17655  validloss -1455.15080±0.00000  bestvalidloss -1539.49625  last_update 65\n",
      "train: iter 782  trainloss -1503.19414  validloss -1475.97077±0.00000  bestvalidloss -1539.49625  last_update 66\n",
      "train: iter 783  trainloss -1509.30416  validloss -1519.89872±0.00000  bestvalidloss -1539.49625  last_update 67\n",
      "train: iter 784  trainloss -1485.73478  validloss -1450.04295±0.00000  bestvalidloss -1539.49625  last_update 68\n",
      "train: iter 785  trainloss -1442.89396  validloss -1475.57618±0.00000  bestvalidloss -1539.49625  last_update 69\n",
      "train: iter 786  trainloss -1497.19466  validloss -1473.42612±0.00000  bestvalidloss -1539.49625  last_update 70\n",
      "train: iter 787  trainloss -1426.82939  validloss -1395.06683±0.00000  bestvalidloss -1539.49625  last_update 71\n",
      "train: iter 788  trainloss -1497.75284  validloss -1491.84090±0.00000  bestvalidloss -1539.49625  last_update 72\n",
      "train: iter 789  trainloss -1509.94243  validloss -1527.68255±0.00000  bestvalidloss -1539.49625  last_update 73\n",
      "train: iter 790  trainloss -1472.36191  validloss -1486.83034±0.00000  bestvalidloss -1539.49625  last_update 74\n",
      "train: iter 791  trainloss -1522.55985  validloss -1498.40206±0.00000  bestvalidloss -1539.49625  last_update 75\n",
      "train: iter 792  trainloss -1527.81164  validloss -1494.35330±0.00000  bestvalidloss -1539.49625  last_update 76\n",
      "train: iter 793  trainloss -1067.11596  validloss -1348.04797±0.00000  bestvalidloss -1539.49625  last_update 77\n",
      "train: iter 794  trainloss -1390.52610  validloss -1095.36977±0.00000  bestvalidloss -1539.49625  last_update 78\n",
      "train: iter 795  trainloss -1474.33485  validloss -1459.53997±0.00000  bestvalidloss -1539.49625  last_update 79\n",
      "train: iter 796  trainloss -1476.81350  validloss -1463.22445±0.00000  bestvalidloss -1539.49625  last_update 80\n",
      "train: iter 797  trainloss -1478.23175  validloss -1412.74220±0.00000  bestvalidloss -1539.49625  last_update 81\n",
      "train: iter 798  trainloss -1510.13172  validloss -1493.45774±0.00000  bestvalidloss -1539.49625  last_update 82\n",
      "train: iter 799  trainloss -1492.75969  validloss -1507.29452±0.00000  bestvalidloss -1539.49625  last_update 83\n",
      "train: iter 800  trainloss -1478.33298  validloss -1472.07293±0.00000  bestvalidloss -1539.49625  last_update 84\n",
      "train: iter 801  trainloss -1436.60771  validloss -1355.15638±0.00000  bestvalidloss -1539.49625  last_update 85\n",
      "train: iter 802  trainloss -1478.59448  validloss -1283.55508±0.00000  bestvalidloss -1539.49625  last_update 86\n",
      "train: iter 803  trainloss -1510.72520  validloss -1495.16864±0.00000  bestvalidloss -1539.49625  last_update 87\n",
      "train: iter 804  trainloss -1535.85077  validloss -1505.43466±0.00000  bestvalidloss -1539.49625  last_update 88\n",
      "train: iter 805  trainloss -1445.77215  validloss -1520.18837±0.00000  bestvalidloss -1539.49625  last_update 89\n",
      "train: iter 806  trainloss -1418.19500  validloss -1377.79825±0.00000  bestvalidloss -1539.49625  last_update 90\n",
      "train: iter 807  trainloss -1049.53757  validloss -932.93226±0.00000  bestvalidloss -1539.49625  last_update 91\n",
      "train: iter 808  trainloss -1482.15444  validloss -1389.01899±0.00000  bestvalidloss -1539.49625  last_update 92\n",
      "train: iter 809  trainloss -1474.40555  validloss -1424.65742±0.00000  bestvalidloss -1539.49625  last_update 93\n",
      "train: iter 810  trainloss -1525.07913  validloss -1466.24637±0.00000  bestvalidloss -1539.49625  last_update 94\n",
      "train: iter 811  trainloss -1530.90509  validloss -1503.55211±0.00000  bestvalidloss -1539.49625  last_update 95\n",
      "train: iter 812  trainloss -1541.94096  validloss -1512.56087±0.00000  bestvalidloss -1539.49625  last_update 96\n",
      "train: iter 813  trainloss -1508.72645  validloss -1555.46526±0.00000  bestvalidloss -1555.46526  last_update 0\n",
      "train: iter 814  trainloss -1480.05152  validloss -1531.03462±0.00000  bestvalidloss -1555.46526  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 815  trainloss -1502.66740  validloss -1426.95055±0.00000  bestvalidloss -1555.46526  last_update 2\n",
      "train: iter 816  trainloss -1523.57915  validloss -1527.17272±0.00000  bestvalidloss -1555.46526  last_update 3\n",
      "train: iter 817  trainloss -1334.44041  validloss -1489.23784±0.00000  bestvalidloss -1555.46526  last_update 4\n",
      "train: iter 818  trainloss -1465.26774  validloss -1375.02261±0.00000  bestvalidloss -1555.46526  last_update 5\n",
      "train: iter 819  trainloss -1517.71293  validloss -1466.58840±0.00000  bestvalidloss -1555.46526  last_update 6\n",
      "train: iter 820  trainloss -1507.60277  validloss -1473.92276±0.00000  bestvalidloss -1555.46526  last_update 7\n",
      "train: iter 821  trainloss -1450.12632  validloss -1385.39665±0.00000  bestvalidloss -1555.46526  last_update 8\n",
      "train: iter 822  trainloss -1510.66377  validloss -1499.93399±0.00000  bestvalidloss -1555.46526  last_update 9\n",
      "train: iter 823  trainloss -1514.46343  validloss -1480.56754±0.00000  bestvalidloss -1555.46526  last_update 10\n",
      "train: iter 824  trainloss -1466.43436  validloss -1495.62173±0.00000  bestvalidloss -1555.46526  last_update 11\n",
      "train: iter 825  trainloss -1445.31774  validloss -1360.01957±0.00000  bestvalidloss -1555.46526  last_update 12\n",
      "train: iter 826  trainloss -1508.75070  validloss -1498.47141±0.00000  bestvalidloss -1555.46526  last_update 13\n",
      "train: iter 827  trainloss -1459.44507  validloss -1430.52607±0.00000  bestvalidloss -1555.46526  last_update 14\n",
      "train: iter 828  trainloss -1520.47431  validloss -1392.22934±0.00000  bestvalidloss -1555.46526  last_update 15\n",
      "train: iter 829  trainloss -1442.28925  validloss -1550.22157±0.00000  bestvalidloss -1555.46526  last_update 16\n",
      "train: iter 830  trainloss -1458.58324  validloss -1352.82267±0.00000  bestvalidloss -1555.46526  last_update 17\n",
      "train: iter 831  trainloss -1539.95830  validloss -1509.74340±0.00000  bestvalidloss -1555.46526  last_update 18\n",
      "train: iter 832  trainloss -1528.85892  validloss -1542.17487±0.00000  bestvalidloss -1555.46526  last_update 19\n",
      "train: iter 833  trainloss -1529.22127  validloss -1545.10654±0.00000  bestvalidloss -1555.46526  last_update 20\n",
      "train: iter 834  trainloss -1514.92034  validloss -1504.06765±0.00000  bestvalidloss -1555.46526  last_update 21\n",
      "train: iter 835  trainloss -1368.31652  validloss -1479.31906±0.00000  bestvalidloss -1555.46526  last_update 22\n",
      "train: iter 836  trainloss -1501.75723  validloss -1442.67896±0.00000  bestvalidloss -1555.46526  last_update 23\n",
      "train: iter 837  trainloss -1451.17294  validloss -1513.00372±0.00000  bestvalidloss -1555.46526  last_update 24\n",
      "train: iter 838  trainloss -1523.79244  validloss -1482.18879±0.00000  bestvalidloss -1555.46526  last_update 25\n",
      "train: iter 839  trainloss -1483.91695  validloss -1498.27586±0.00000  bestvalidloss -1555.46526  last_update 26\n",
      "train: iter 840  trainloss -1436.90801  validloss -1496.12416±0.00000  bestvalidloss -1555.46526  last_update 27\n",
      "train: iter 841  trainloss -1454.04192  validloss -1361.21930±0.00000  bestvalidloss -1555.46526  last_update 28\n",
      "train: iter 842  trainloss -1516.82425  validloss -1463.27894±0.00000  bestvalidloss -1555.46526  last_update 29\n",
      "train: iter 843  trainloss -1544.76204  validloss -1493.48155±0.00000  bestvalidloss -1555.46526  last_update 30\n",
      "train: iter 844  trainloss -1520.92660  validloss -1554.32458±0.00000  bestvalidloss -1555.46526  last_update 31\n",
      "train: iter 845  trainloss -1487.53235  validloss -1439.93560±0.00000  bestvalidloss -1555.46526  last_update 32\n",
      "train: iter 846  trainloss -1526.09127  validloss -1498.48149±0.00000  bestvalidloss -1555.46526  last_update 33\n",
      "train: iter 847  trainloss -1505.18912  validloss -1471.45455±0.00000  bestvalidloss -1555.46526  last_update 34\n",
      "train: iter 848  trainloss -1507.31578  validloss -1497.85643±0.00000  bestvalidloss -1555.46526  last_update 35\n",
      "train: iter 849  trainloss -1496.82343  validloss -1446.44480±0.00000  bestvalidloss -1555.46526  last_update 36\n",
      "train: iter 850  trainloss -1506.33557  validloss -1489.38137±0.00000  bestvalidloss -1555.46526  last_update 37\n",
      "train: iter 851  trainloss -1548.53104  validloss -1542.29594±0.00000  bestvalidloss -1555.46526  last_update 38\n",
      "train: iter 852  trainloss -1466.91956  validloss -1510.58629±0.00000  bestvalidloss -1555.46526  last_update 39\n",
      "train: iter 853  trainloss -1529.39944  validloss -1428.06494±0.00000  bestvalidloss -1555.46526  last_update 40\n",
      "train: iter 854  trainloss -1551.71386  validloss -1536.16891±0.00000  bestvalidloss -1555.46526  last_update 41\n",
      "train: iter 855  trainloss -1509.68441  validloss -1528.09463±0.00000  bestvalidloss -1555.46526  last_update 42\n",
      "train: iter 856  trainloss -1493.07879  validloss -1388.29601±0.00000  bestvalidloss -1555.46526  last_update 43\n",
      "train: iter 857  trainloss -1192.52372  validloss -1502.25147±0.00000  bestvalidloss -1555.46526  last_update 44\n",
      "train: iter 858  trainloss -1346.46797  validloss -1175.71463±0.00000  bestvalidloss -1555.46526  last_update 45\n",
      "train: iter 859  trainloss -1469.03754  validloss -1397.39333±0.00000  bestvalidloss -1555.46526  last_update 46\n",
      "train: iter 860  trainloss -1175.24023  validloss -1461.48951±0.00000  bestvalidloss -1555.46526  last_update 47\n",
      "train: iter 861  trainloss -1440.64691  validloss -1334.20426±0.00000  bestvalidloss -1555.46526  last_update 48\n",
      "train: iter 862  trainloss -1173.29551  validloss -1384.07225±0.00000  bestvalidloss -1555.46526  last_update 49\n",
      "train: iter 863  trainloss -1351.49383  validloss -1202.28943±0.00000  bestvalidloss -1555.46526  last_update 50\n",
      "train: iter 864  trainloss -1448.80996  validloss -1364.18322±0.00000  bestvalidloss -1555.46526  last_update 51\n",
      "train: iter 865  trainloss -1472.87026  validloss -1418.92728±0.00000  bestvalidloss -1555.46526  last_update 52\n",
      "train: iter 866  trainloss -1510.84695  validloss -1450.24971±0.00000  bestvalidloss -1555.46526  last_update 53\n",
      "train: iter 867  trainloss -1518.50025  validloss -1481.15976±0.00000  bestvalidloss -1555.46526  last_update 54\n",
      "train: iter 868  trainloss -1524.14776  validloss -1477.94637±0.00000  bestvalidloss -1555.46526  last_update 55\n",
      "train: iter 869  trainloss -1535.93689  validloss -1502.34483±0.00000  bestvalidloss -1555.46526  last_update 56\n",
      "train: iter 870  trainloss -1533.60907  validloss -1523.30420±0.00000  bestvalidloss -1555.46526  last_update 57\n",
      "train: iter 871  trainloss -1559.44642  validloss -1523.68537±0.00000  bestvalidloss -1555.46526  last_update 58\n",
      "train: iter 872  trainloss -1552.04754  validloss -1510.15807±0.00000  bestvalidloss -1555.46526  last_update 59\n",
      "train: iter 873  trainloss -1557.66830  validloss -1535.81064±0.00000  bestvalidloss -1555.46526  last_update 60\n",
      "train: iter 874  trainloss -1449.02881  validloss -1560.53651±0.00000  bestvalidloss -1560.53651  last_update 0\n",
      "train: iter 875  trainloss -1536.35715  validloss -1422.11091±0.00000  bestvalidloss -1560.53651  last_update 1\n",
      "train: iter 876  trainloss -1513.98413  validloss -1482.50615±0.00000  bestvalidloss -1560.53651  last_update 2\n",
      "train: iter 877  trainloss -1523.57854  validloss -1512.31875±0.00000  bestvalidloss -1560.53651  last_update 3\n",
      "train: iter 878  trainloss -1529.83624  validloss -1454.55168±0.00000  bestvalidloss -1560.53651  last_update 4\n",
      "train: iter 879  trainloss -1496.90954  validloss -1462.31528±0.00000  bestvalidloss -1560.53651  last_update 5\n",
      "train: iter 880  trainloss -1536.90217  validloss -1543.31522±0.00000  bestvalidloss -1560.53651  last_update 6\n",
      "train: iter 881  trainloss -1491.39026  validloss -1513.87173±0.00000  bestvalidloss -1560.53651  last_update 7\n",
      "train: iter 882  trainloss -1538.69222  validloss -1485.52928±0.00000  bestvalidloss -1560.53651  last_update 8\n",
      "train: iter 883  trainloss -1563.25363  validloss -1538.31786±0.00000  bestvalidloss -1560.53651  last_update 9\n",
      "train: iter 884  trainloss -1543.35333  validloss -1533.28769±0.00000  bestvalidloss -1560.53651  last_update 10\n",
      "train: iter 885  trainloss -1110.76983  validloss -1499.84607±0.00000  bestvalidloss -1560.53651  last_update 11\n",
      "train: iter 886  trainloss -1246.28911  validloss -1016.65015±0.00000  bestvalidloss -1560.53651  last_update 12\n",
      "train: iter 887  trainloss -1435.28872  validloss -1353.80004±0.00000  bestvalidloss -1560.53651  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 888  trainloss -1486.52168  validloss -1429.03638±0.00000  bestvalidloss -1560.53651  last_update 14\n",
      "train: iter 889  trainloss -1510.95323  validloss -1441.81920±0.00000  bestvalidloss -1560.53651  last_update 15\n",
      "train: iter 890  trainloss -1454.34030  validloss -1466.53458±0.00000  bestvalidloss -1560.53651  last_update 16\n",
      "train: iter 891  trainloss -1503.01082  validloss -1464.85982±0.00000  bestvalidloss -1560.53651  last_update 17\n",
      "train: iter 892  trainloss -1539.69805  validloss -1491.40302±0.00000  bestvalidloss -1560.53651  last_update 18\n",
      "train: iter 893  trainloss -1508.38313  validloss -1498.87607±0.00000  bestvalidloss -1560.53651  last_update 19\n",
      "train: iter 894  trainloss -1512.38020  validloss -1491.15188±0.00000  bestvalidloss -1560.53651  last_update 20\n",
      "train: iter 895  trainloss -1551.21826  validloss -1523.15017±0.00000  bestvalidloss -1560.53651  last_update 21\n",
      "train: iter 896  trainloss -1521.28041  validloss -1502.49144±0.00000  bestvalidloss -1560.53651  last_update 22\n",
      "train: iter 897  trainloss -1528.83102  validloss -1457.74443±0.00000  bestvalidloss -1560.53651  last_update 23\n",
      "train: iter 898  trainloss -1517.93957  validloss -1519.44826±0.00000  bestvalidloss -1560.53651  last_update 24\n",
      "train: iter 899  trainloss -1480.29933  validloss -1516.02452±0.00000  bestvalidloss -1560.53651  last_update 25\n",
      "train: iter 900  trainloss -1420.00822  validloss -1480.92124±0.00000  bestvalidloss -1560.53651  last_update 26\n",
      "train: iter 901  trainloss -1517.86286  validloss -1419.19870±0.00000  bestvalidloss -1560.53651  last_update 27\n",
      "train: iter 902  trainloss -1521.02076  validloss -1495.69954±0.00000  bestvalidloss -1560.53651  last_update 28\n",
      "train: iter 903  trainloss -1527.09104  validloss -1497.56209±0.00000  bestvalidloss -1560.53651  last_update 29\n",
      "train: iter 904  trainloss -1459.79806  validloss -1463.06002±0.00000  bestvalidloss -1560.53651  last_update 30\n",
      "train: iter 905  trainloss -1525.91900  validloss -1444.22310±0.00000  bestvalidloss -1560.53651  last_update 31\n",
      "train: iter 906  trainloss -1549.51389  validloss -1512.03836±0.00000  bestvalidloss -1560.53651  last_update 32\n",
      "train: iter 907  trainloss -1563.29465  validloss -1533.44107±0.00000  bestvalidloss -1560.53651  last_update 33\n",
      "train: iter 908  trainloss -1549.97295  validloss -1543.49202±0.00000  bestvalidloss -1560.53651  last_update 34\n",
      "train: iter 909  trainloss -1530.07798  validloss -1501.42517±0.00000  bestvalidloss -1560.53651  last_update 35\n",
      "train: iter 910  trainloss -1486.28674  validloss -1484.54874±0.00000  bestvalidloss -1560.53651  last_update 36\n",
      "train: iter 911  trainloss -1501.13651  validloss -1442.42753±0.00000  bestvalidloss -1560.53651  last_update 37\n",
      "train: iter 912  trainloss -1458.96395  validloss -1498.34319±0.00000  bestvalidloss -1560.53651  last_update 38\n",
      "train: iter 913  trainloss -1516.74510  validloss -1450.85385±0.00000  bestvalidloss -1560.53651  last_update 39\n",
      "train: iter 914  trainloss -1547.91762  validloss -1501.62000±0.00000  bestvalidloss -1560.53651  last_update 40\n",
      "train: iter 915  trainloss -1548.35864  validloss -1516.74250±0.00000  bestvalidloss -1560.53651  last_update 41\n",
      "train: iter 916  trainloss -1320.58164  validloss -1174.39356±0.00000  bestvalidloss -1560.53651  last_update 42\n",
      "train: iter 917  trainloss -1543.59033  validloss -1410.76882±0.00000  bestvalidloss -1560.53651  last_update 43\n",
      "train: iter 918  trainloss -1472.14853  validloss -1299.13327±0.00000  bestvalidloss -1560.53651  last_update 44\n",
      "train: iter 919  trainloss -1550.45199  validloss -1485.02028±0.00000  bestvalidloss -1560.53651  last_update 45\n",
      "train: iter 920  trainloss -1486.83256  validloss -1483.83642±0.00000  bestvalidloss -1560.53651  last_update 46\n",
      "train: iter 921  trainloss -1556.12488  validloss -1478.40925±0.00000  bestvalidloss -1560.53651  last_update 47\n",
      "train: iter 922  trainloss -1325.57593  validloss -1430.74642±0.00000  bestvalidloss -1560.53651  last_update 48\n",
      "train: iter 923  trainloss -1465.94773  validloss -1437.82047±0.00000  bestvalidloss -1560.53651  last_update 49\n",
      "train: iter 924  trainloss -1543.85460  validloss -1429.33348±0.00000  bestvalidloss -1560.53651  last_update 50\n",
      "train: iter 925  trainloss -1566.08114  validloss -1532.60810±0.00000  bestvalidloss -1560.53651  last_update 51\n",
      "train: iter 926  trainloss -1452.38539  validloss -1525.62448±0.00000  bestvalidloss -1560.53651  last_update 52\n",
      "train: iter 927  trainloss -1525.37021  validloss -1424.93806±0.00000  bestvalidloss -1560.53651  last_update 53\n",
      "train: iter 928  trainloss -1527.97875  validloss -1528.46186±0.00000  bestvalidloss -1560.53651  last_update 54\n",
      "train: iter 929  trainloss -1448.55972  validloss -1429.67279±0.00000  bestvalidloss -1560.53651  last_update 55\n",
      "train: iter 930  trainloss -1558.95000  validloss -1486.88045±0.00000  bestvalidloss -1560.53651  last_update 56\n",
      "train: iter 931  trainloss -1546.15312  validloss -1535.26944±0.00000  bestvalidloss -1560.53651  last_update 57\n",
      "train: iter 932  trainloss -1473.93415  validloss -1271.05479±0.00000  bestvalidloss -1560.53651  last_update 58\n",
      "train: iter 933  trainloss -1534.41611  validloss -1527.83623±0.00000  bestvalidloss -1560.53651  last_update 59\n",
      "train: iter 934  trainloss -1354.49918  validloss -1482.47775±0.00000  bestvalidloss -1560.53651  last_update 60\n",
      "train: iter 935  trainloss -1457.53307  validloss -1403.20553±0.00000  bestvalidloss -1560.53651  last_update 61\n",
      "train: iter 936  trainloss -1554.02538  validloss -1493.04911±0.00000  bestvalidloss -1560.53651  last_update 62\n",
      "train: iter 937  trainloss -1561.21536  validloss -1516.44123±0.00000  bestvalidloss -1560.53651  last_update 63\n",
      "train: iter 938  trainloss -1523.09527  validloss -1515.30552±0.00000  bestvalidloss -1560.53651  last_update 64\n",
      "train: iter 939  trainloss -1526.63270  validloss -1354.30615±0.00000  bestvalidloss -1560.53651  last_update 65\n",
      "train: iter 940  trainloss -1514.98987  validloss -1518.50787±0.00000  bestvalidloss -1560.53651  last_update 66\n",
      "train: iter 941  trainloss -1539.37440  validloss -1495.60591±0.00000  bestvalidloss -1560.53651  last_update 67\n",
      "train: iter 942  trainloss -1538.08820  validloss -1495.98801±0.00000  bestvalidloss -1560.53651  last_update 68\n",
      "train: iter 943  trainloss -1558.87718  validloss -1515.41391±0.00000  bestvalidloss -1560.53651  last_update 69\n",
      "train: iter 944  trainloss -1517.16679  validloss -1482.88602±0.00000  bestvalidloss -1560.53651  last_update 70\n",
      "train: iter 945  trainloss -1448.34991  validloss -1326.42624±0.00000  bestvalidloss -1560.53651  last_update 71\n",
      "train: iter 946  trainloss -1546.61064  validloss -1377.08546±0.00000  bestvalidloss -1560.53651  last_update 72\n",
      "train: iter 947  trainloss -1508.82452  validloss -1485.62590±0.00000  bestvalidloss -1560.53651  last_update 73\n",
      "train: iter 948  trainloss -1552.46123  validloss -1439.79639±0.00000  bestvalidloss -1560.53651  last_update 74\n",
      "train: iter 949  trainloss -1566.48312  validloss -1499.92988±0.00000  bestvalidloss -1560.53651  last_update 75\n",
      "train: iter 950  trainloss -1324.09466  validloss -1365.87938±0.00000  bestvalidloss -1560.53651  last_update 76\n",
      "train: iter 951  trainloss -1517.77651  validloss -1434.36648±0.00000  bestvalidloss -1560.53651  last_update 77\n",
      "train: iter 952  trainloss -1521.78989  validloss -1411.55964±0.00000  bestvalidloss -1560.53651  last_update 78\n",
      "train: iter 953  trainloss -1491.73384  validloss -1459.74849±0.00000  bestvalidloss -1560.53651  last_update 79\n",
      "train: iter 954  trainloss -1561.58978  validloss -1419.49787±0.00000  bestvalidloss -1560.53651  last_update 80\n",
      "train: iter 955  trainloss -1549.32083  validloss -1443.56002±0.00000  bestvalidloss -1560.53651  last_update 81\n",
      "train: iter 956  trainloss -1507.05628  validloss -1510.12776±0.00000  bestvalidloss -1560.53651  last_update 82\n",
      "train: iter 957  trainloss -1250.21959  validloss -1403.76638±0.00000  bestvalidloss -1560.53651  last_update 83\n",
      "train: iter 958  trainloss -1551.64696  validloss -1441.70346±0.00000  bestvalidloss -1560.53651  last_update 84\n",
      "train: iter 959  trainloss -1555.69400  validloss -1475.95540±0.00000  bestvalidloss -1560.53651  last_update 85\n",
      "train: iter 960  trainloss -1587.81208  validloss -1484.15011±0.00000  bestvalidloss -1560.53651  last_update 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 961  trainloss -1440.94265  validloss -1481.67845±0.00000  bestvalidloss -1560.53651  last_update 87\n",
      "train: iter 962  trainloss -1547.86784  validloss -1455.22877±0.00000  bestvalidloss -1560.53651  last_update 88\n",
      "train: iter 963  trainloss -1556.84498  validloss -1481.81123±0.00000  bestvalidloss -1560.53651  last_update 89\n",
      "train: iter 964  trainloss -1550.16002  validloss -1497.36114±0.00000  bestvalidloss -1560.53651  last_update 90\n",
      "train: iter 965  trainloss -1571.86865  validloss -1515.92849±0.00000  bestvalidloss -1560.53651  last_update 91\n",
      "train: iter 966  trainloss -1522.45282  validloss -1484.52716±0.00000  bestvalidloss -1560.53651  last_update 92\n",
      "train: iter 967  trainloss -1594.61178  validloss -1506.29850±0.00000  bestvalidloss -1560.53651  last_update 93\n",
      "train: iter 968  trainloss -1439.78758  validloss -1500.30397±0.00000  bestvalidloss -1560.53651  last_update 94\n",
      "train: iter 969  trainloss -1291.80598  validloss -1059.73871±0.00000  bestvalidloss -1560.53651  last_update 95\n",
      "train: iter 970  trainloss -1473.65041  validloss -1286.96728±0.00000  bestvalidloss -1560.53651  last_update 96\n",
      "train: iter 971  trainloss -1536.01780  validloss -1473.67486±0.00000  bestvalidloss -1560.53651  last_update 97\n",
      "train: iter 972  trainloss -1204.51504  validloss -1147.93958±0.00000  bestvalidloss -1560.53651  last_update 98\n",
      "train: iter 973  trainloss -1377.67121  validloss -1060.28838±0.00000  bestvalidloss -1560.53651  last_update 99\n",
      "train: iter 974  trainloss -1230.25373  validloss -1426.38507±0.00000  bestvalidloss -1560.53651  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.4129) penalty_target_max tensor(6.9196)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 7.94473  validloss 8.43080±0.00000  bestvalidloss 8.43080  last_update 0\n",
      "train: iter 1  trainloss 7.29269  validloss 7.65983±0.00000  bestvalidloss 7.65983  last_update 0\n",
      "train: iter 2  trainloss 6.69499  validloss 7.05778±0.00000  bestvalidloss 7.05778  last_update 0\n",
      "train: iter 3  trainloss 6.21161  validloss 6.52168±0.00000  bestvalidloss 6.52168  last_update 0\n",
      "train: iter 4  trainloss 5.78408  validloss 6.05338±0.00000  bestvalidloss 6.05338  last_update 0\n",
      "train: iter 5  trainloss 5.41843  validloss 5.66841±0.00000  bestvalidloss 5.66841  last_update 0\n",
      "train: iter 6  trainloss 5.10254  validloss 5.29425±0.00000  bestvalidloss 5.29425  last_update 0\n",
      "train: iter 7  trainloss 4.81904  validloss 4.98461±0.00000  bestvalidloss 4.98461  last_update 0\n",
      "train: iter 8  trainloss 4.57064  validloss 4.71513±0.00000  bestvalidloss 4.71513  last_update 0\n",
      "train: iter 9  trainloss 4.35776  validloss 4.47620±0.00000  bestvalidloss 4.47620  last_update 0\n",
      "train: iter 10  trainloss 4.15991  validloss 4.27007±0.00000  bestvalidloss 4.27007  last_update 0\n",
      "train: iter 11  trainloss 3.99176  validloss 4.07148±0.00000  bestvalidloss 4.07148  last_update 0\n",
      "train: iter 12  trainloss 3.83212  validloss 3.89937±0.00000  bestvalidloss 3.89937  last_update 0\n",
      "train: iter 13  trainloss 3.67707  validloss 3.75550±0.00000  bestvalidloss 3.75550  last_update 0\n",
      "train: iter 14  trainloss 3.56572  validloss 3.60869±0.00000  bestvalidloss 3.60869  last_update 0\n",
      "train: iter 15  trainloss 3.43891  validloss 3.48907±0.00000  bestvalidloss 3.48907  last_update 0\n",
      "train: iter 16  trainloss 3.34403  validloss 3.37382±0.00000  bestvalidloss 3.37382  last_update 0\n",
      "train: iter 17  trainloss 3.24094  validloss 3.26453±0.00000  bestvalidloss 3.26453  last_update 0\n",
      "train: iter 18  trainloss 3.17067  validloss 3.16123±0.00000  bestvalidloss 3.16123  last_update 0\n",
      "train: iter 19  trainloss 3.08231  validloss 3.08170±0.00000  bestvalidloss 3.08170  last_update 0\n",
      "train: iter 20  trainloss 3.01118  validloss 3.01303±0.00000  bestvalidloss 3.01303  last_update 0\n",
      "train: iter 21  trainloss 2.95214  validloss 2.90216±0.00000  bestvalidloss 2.90216  last_update 0\n",
      "train: iter 22  trainloss 2.89450  validloss 2.85345±0.00000  bestvalidloss 2.85345  last_update 0\n",
      "train: iter 23  trainloss 2.83819  validloss 2.80247±0.00000  bestvalidloss 2.80247  last_update 0\n",
      "train: iter 24  trainloss 2.77720  validloss 2.73287±0.00000  bestvalidloss 2.73287  last_update 0\n",
      "train: iter 25  trainloss 2.74481  validloss 2.66811±0.00000  bestvalidloss 2.66811  last_update 0\n",
      "train: iter 26  trainloss 2.70582  validloss 2.62822±0.00000  bestvalidloss 2.62822  last_update 0\n",
      "train: iter 27  trainloss 2.67415  validloss 2.62281±0.00000  bestvalidloss 2.62281  last_update 0\n",
      "train: iter 28  trainloss 2.61435  validloss 2.52786±0.00000  bestvalidloss 2.52786  last_update 0\n",
      "train: iter 29  trainloss 2.59170  validloss 2.47972±0.00000  bestvalidloss 2.47972  last_update 0\n",
      "train: iter 30  trainloss 2.55886  validloss 2.46047±0.00000  bestvalidloss 2.46047  last_update 0\n",
      "train: iter 31  trainloss 2.52115  validloss 2.45726±0.00000  bestvalidloss 2.45726  last_update 0\n",
      "train: iter 32  trainloss 2.48696  validloss 2.38055±0.00000  bestvalidloss 2.38055  last_update 0\n",
      "train: iter 33  trainloss 2.46139  validloss 2.36469±0.00000  bestvalidloss 2.36469  last_update 0\n",
      "train: iter 34  trainloss 2.42434  validloss 2.31608±0.00000  bestvalidloss 2.31608  last_update 0\n",
      "train: iter 35  trainloss 2.40795  validloss 2.27909±0.00000  bestvalidloss 2.27909  last_update 0\n",
      "train: iter 36  trainloss 2.36537  validloss 2.31638±0.00000  bestvalidloss 2.27909  last_update 1\n",
      "train: iter 37  trainloss 2.35063  validloss 2.25253±0.00000  bestvalidloss 2.25253  last_update 0\n",
      "train: iter 38  trainloss 2.31935  validloss 2.21842±0.00000  bestvalidloss 2.21842  last_update 0\n",
      "train: iter 39  trainloss 2.28331  validloss 2.17985±0.00000  bestvalidloss 2.17985  last_update 0\n",
      "train: iter 40  trainloss 2.27242  validloss 2.16201±0.00000  bestvalidloss 2.16201  last_update 0\n",
      "train: iter 41  trainloss 2.26149  validloss 2.13913±0.00000  bestvalidloss 2.13913  last_update 0\n",
      "train: iter 42  trainloss 2.25051  validloss 2.10730±0.00000  bestvalidloss 2.10730  last_update 0\n",
      "train: iter 43  trainloss 2.21103  validloss 2.08942±0.00000  bestvalidloss 2.08942  last_update 0\n",
      "train: iter 44  trainloss 2.20143  validloss 2.05840±0.00000  bestvalidloss 2.05840  last_update 0\n",
      "train: iter 45  trainloss 2.16019  validloss 2.01298±0.00000  bestvalidloss 2.01298  last_update 0\n",
      "train: iter 46  trainloss 2.14577  validloss 1.99320±0.00000  bestvalidloss 1.99320  last_update 0\n",
      "train: iter 47  trainloss 2.09108  validloss 1.99787±0.00000  bestvalidloss 1.99320  last_update 1\n",
      "train: iter 48  trainloss 2.08378  validloss 1.93379±0.00000  bestvalidloss 1.93379  last_update 0\n",
      "train: iter 49  trainloss 2.03670  validloss 1.91313±0.00000  bestvalidloss 1.91313  last_update 0\n",
      "train: iter 50  trainloss 2.00223  validloss 1.87646±0.00000  bestvalidloss 1.87646  last_update 0\n",
      "train: iter 51  trainloss 1.98333  validloss 1.84037±0.00000  bestvalidloss 1.84037  last_update 0\n",
      "train: iter 52  trainloss 1.94323  validloss 1.78984±0.00000  bestvalidloss 1.78984  last_update 0\n",
      "train: iter 53  trainloss 1.92297  validloss 1.74572±0.00000  bestvalidloss 1.74572  last_update 0\n",
      "train: iter 54  trainloss 1.86200  validloss 1.70979±0.00000  bestvalidloss 1.70979  last_update 0\n",
      "train: iter 55  trainloss 1.83550  validloss 1.67205±0.00000  bestvalidloss 1.67205  last_update 0\n",
      "train: iter 56  trainloss 1.80635  validloss 1.63495±0.00000  bestvalidloss 1.63495  last_update 0\n",
      "train: iter 57  trainloss 1.74517  validloss 1.65412±0.00000  bestvalidloss 1.63495  last_update 1\n",
      "train: iter 58  trainloss 1.71136  validloss 1.56379±0.00000  bestvalidloss 1.56379  last_update 0\n",
      "train: iter 59  trainloss 1.65275  validloss 1.53075±0.00000  bestvalidloss 1.53075  last_update 0\n",
      "train: iter 60  trainloss 1.62344  validloss 1.46340±0.00000  bestvalidloss 1.46340  last_update 0\n",
      "train: iter 61  trainloss 1.55132  validloss 1.41325±0.00000  bestvalidloss 1.41325  last_update 0\n",
      "train: iter 62  trainloss 1.54099  validloss 1.33322±0.00000  bestvalidloss 1.33322  last_update 0\n",
      "train: iter 63  trainloss 1.48315  validloss 1.33888±0.00000  bestvalidloss 1.33322  last_update 1\n",
      "train: iter 64  trainloss 1.43927  validloss 1.22650±0.00000  bestvalidloss 1.22650  last_update 0\n",
      "train: iter 65  trainloss 1.40233  validloss 1.20923±0.00000  bestvalidloss 1.20923  last_update 0\n",
      "train: iter 66  trainloss 1.34963  validloss 1.18762±0.00000  bestvalidloss 1.18762  last_update 0\n",
      "train: iter 67  trainloss 1.30380  validloss 1.18275±0.00000  bestvalidloss 1.18275  last_update 0\n",
      "train: iter 68  trainloss 1.27386  validloss 1.09043±0.00000  bestvalidloss 1.09043  last_update 0\n",
      "train: iter 69  trainloss 1.18874  validloss 1.02343±0.00000  bestvalidloss 1.02343  last_update 0\n",
      "train: iter 70  trainloss 1.19514  validloss 1.01676±0.00000  bestvalidloss 1.01676  last_update 0\n",
      "train: iter 71  trainloss 1.12103  validloss 0.93043±0.00000  bestvalidloss 0.93043  last_update 0\n",
      "train: iter 72  trainloss 1.11148  validloss 0.91676±0.00000  bestvalidloss 0.91676  last_update 0\n",
      "train: iter 73  trainloss 1.03412  validloss 0.82977±0.00000  bestvalidloss 0.82977  last_update 0\n",
      "train: iter 74  trainloss 1.02428  validloss 0.83715±0.00000  bestvalidloss 0.82977  last_update 1\n",
      "train: iter 75  trainloss 0.97179  validloss 0.77516±0.00000  bestvalidloss 0.77516  last_update 0\n",
      "train: iter 76  trainloss 0.93354  validloss 0.73541±0.00000  bestvalidloss 0.73541  last_update 0\n",
      "train: iter 77  trainloss 0.87340  validloss 0.72225±0.00000  bestvalidloss 0.72225  last_update 0\n",
      "train: iter 78  trainloss 0.86514  validloss 0.63903±0.00000  bestvalidloss 0.63903  last_update 0\n",
      "train: iter 79  trainloss 0.84180  validloss 0.67925±0.00000  bestvalidloss 0.63903  last_update 1\n",
      "train: iter 80  trainloss 0.77917  validloss 0.59123±0.00000  bestvalidloss 0.59123  last_update 0\n",
      "train: iter 81  trainloss 0.75513  validloss 0.57576±0.00000  bestvalidloss 0.57576  last_update 0\n",
      "train: iter 82  trainloss 0.75478  validloss 0.52798±0.00000  bestvalidloss 0.52798  last_update 0\n",
      "train: iter 83  trainloss 0.66417  validloss 0.46494±0.00000  bestvalidloss 0.46494  last_update 0\n",
      "train: iter 84  trainloss 0.66766  validloss 0.42888±0.00000  bestvalidloss 0.42888  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 0.66669  validloss 0.38866±0.00000  bestvalidloss 0.38866  last_update 0\n",
      "train: iter 86  trainloss 0.60565  validloss 0.36644±0.00000  bestvalidloss 0.36644  last_update 0\n",
      "train: iter 87  trainloss 0.54993  validloss 0.34920±0.00000  bestvalidloss 0.34920  last_update 0\n",
      "train: iter 88  trainloss 0.54956  validloss 0.33241±0.00000  bestvalidloss 0.33241  last_update 0\n",
      "train: iter 89  trainloss 0.50141  validloss 0.28079±0.00000  bestvalidloss 0.28079  last_update 0\n",
      "train: iter 90  trainloss 0.44103  validloss 0.23386±0.00000  bestvalidloss 0.23386  last_update 0\n",
      "train: iter 91  trainloss 0.41881  validloss 0.21120±0.00000  bestvalidloss 0.21120  last_update 0\n",
      "train: iter 92  trainloss 0.43010  validloss 0.20776±0.00000  bestvalidloss 0.20776  last_update 0\n",
      "train: iter 93  trainloss 0.39884  validloss 0.17285±0.00000  bestvalidloss 0.17285  last_update 0\n",
      "train: iter 94  trainloss 0.40167  validloss 0.13696±0.00000  bestvalidloss 0.13696  last_update 0\n",
      "train: iter 95  trainloss 0.34982  validloss 0.11577±0.00000  bestvalidloss 0.11577  last_update 0\n",
      "train: iter 96  trainloss 0.32105  validloss 0.04149±0.00000  bestvalidloss 0.04149  last_update 0\n",
      "train: iter 97  trainloss 0.29150  validloss 0.10005±0.00000  bestvalidloss 0.04149  last_update 1\n",
      "train: iter 98  trainloss 0.28269  validloss 0.01568±0.00000  bestvalidloss 0.01568  last_update 0\n",
      "train: iter 99  trainloss 0.29620  validloss -0.05103±0.00000  bestvalidloss -0.05103  last_update 0\n",
      "train: iter 100  trainloss 0.26492  validloss -0.02933±0.00000  bestvalidloss -0.05103  last_update 1\n",
      "train: iter 101  trainloss 0.23278  validloss -0.04433±0.00000  bestvalidloss -0.05103  last_update 2\n",
      "train: iter 102  trainloss 0.23668  validloss -0.06017±0.00000  bestvalidloss -0.06017  last_update 0\n",
      "train: iter 103  trainloss 0.21929  validloss -0.10303±0.00000  bestvalidloss -0.10303  last_update 0\n",
      "train: iter 104  trainloss 0.21120  validloss -0.15642±0.00000  bestvalidloss -0.15642  last_update 0\n",
      "train: iter 105  trainloss 0.20160  validloss -0.13841±0.00000  bestvalidloss -0.15642  last_update 1\n",
      "train: iter 106  trainloss 0.18434  validloss -0.13909±0.00000  bestvalidloss -0.15642  last_update 2\n",
      "train: iter 107  trainloss 0.16235  validloss -0.15028±0.00000  bestvalidloss -0.15642  last_update 3\n",
      "train: iter 108  trainloss 0.17962  validloss -0.14075±0.00000  bestvalidloss -0.15642  last_update 4\n",
      "train: iter 109  trainloss 0.17840  validloss -0.16812±0.00000  bestvalidloss -0.16812  last_update 0\n",
      "train: iter 110  trainloss 0.12981  validloss -0.17013±0.00000  bestvalidloss -0.17013  last_update 0\n",
      "train: iter 111  trainloss 0.15376  validloss -0.22062±0.00000  bestvalidloss -0.22062  last_update 0\n",
      "train: iter 112  trainloss 0.12377  validloss -0.24597±0.00000  bestvalidloss -0.24597  last_update 0\n",
      "train: iter 113  trainloss 0.11665  validloss -0.21562±0.00000  bestvalidloss -0.24597  last_update 1\n",
      "train: iter 114  trainloss 0.13547  validloss -0.25613±0.00000  bestvalidloss -0.25613  last_update 0\n",
      "train: iter 115  trainloss 0.12790  validloss -0.23701±0.00000  bestvalidloss -0.25613  last_update 1\n",
      "train: iter 116  trainloss 0.12295  validloss -0.27926±0.00000  bestvalidloss -0.27926  last_update 0\n",
      "train: iter 117  trainloss 0.12754  validloss -0.22714±0.00000  bestvalidloss -0.27926  last_update 1\n",
      "train: iter 118  trainloss 0.08585  validloss -0.33182±0.00000  bestvalidloss -0.33182  last_update 0\n",
      "train: iter 119  trainloss 0.10631  validloss -0.29882±0.00000  bestvalidloss -0.33182  last_update 1\n",
      "train: iter 120  trainloss 0.11231  validloss -0.32018±0.00000  bestvalidloss -0.33182  last_update 2\n",
      "train: iter 121  trainloss 0.10323  validloss -0.32429±0.00000  bestvalidloss -0.33182  last_update 3\n",
      "train: iter 122  trainloss 0.09192  validloss -0.25278±0.00000  bestvalidloss -0.33182  last_update 4\n",
      "train: iter 123  trainloss 0.08430  validloss -0.28836±0.00000  bestvalidloss -0.33182  last_update 5\n",
      "train: iter 124  trainloss 0.08685  validloss -0.29120±0.00000  bestvalidloss -0.33182  last_update 6\n",
      "train: iter 125  trainloss 0.09994  validloss -0.33127±0.00000  bestvalidloss -0.33182  last_update 7\n",
      "train: iter 126  trainloss 0.10024  validloss -0.29305±0.00000  bestvalidloss -0.33182  last_update 8\n",
      "train: iter 127  trainloss 0.10614  validloss -0.36591±0.00000  bestvalidloss -0.36591  last_update 0\n",
      "train: iter 128  trainloss 0.07890  validloss -0.33304±0.00000  bestvalidloss -0.36591  last_update 1\n",
      "train: iter 129  trainloss 0.10772  validloss -0.32017±0.00000  bestvalidloss -0.36591  last_update 2\n",
      "train: iter 130  trainloss 0.09791  validloss -0.33101±0.00000  bestvalidloss -0.36591  last_update 3\n",
      "train: iter 131  trainloss 0.11884  validloss -0.36260±0.00000  bestvalidloss -0.36591  last_update 4\n",
      "train: iter 132  trainloss 0.09287  validloss -0.33341±0.00000  bestvalidloss -0.36591  last_update 5\n",
      "train: iter 133  trainloss 0.08187  validloss -0.36773±0.00000  bestvalidloss -0.36773  last_update 0\n",
      "train: iter 134  trainloss 0.09332  validloss -0.32598±0.00000  bestvalidloss -0.36773  last_update 1\n",
      "train: iter 135  trainloss 0.09995  validloss -0.30510±0.00000  bestvalidloss -0.36773  last_update 2\n",
      "train: iter 136  trainloss 0.08983  validloss -0.37767±0.00000  bestvalidloss -0.37767  last_update 0\n",
      "train: iter 137  trainloss 0.06215  validloss -0.40053±0.00000  bestvalidloss -0.40053  last_update 0\n",
      "train: iter 138  trainloss 0.05526  validloss -0.35847±0.00000  bestvalidloss -0.40053  last_update 1\n",
      "train: iter 139  trainloss 0.09590  validloss -0.29754±0.00000  bestvalidloss -0.40053  last_update 2\n",
      "train: iter 140  trainloss 0.08721  validloss -0.33530±0.00000  bestvalidloss -0.40053  last_update 3\n",
      "train: iter 141  trainloss 0.09652  validloss -0.34622±0.00000  bestvalidloss -0.40053  last_update 4\n",
      "train: iter 142  trainloss 0.12954  validloss -0.34740±0.00000  bestvalidloss -0.40053  last_update 5\n",
      "train: iter 143  trainloss 0.04494  validloss -0.32826±0.00000  bestvalidloss -0.40053  last_update 6\n",
      "train: iter 144  trainloss 0.10077  validloss -0.38349±0.00000  bestvalidloss -0.40053  last_update 7\n",
      "train: iter 145  trainloss 0.05603  validloss -0.38131±0.00000  bestvalidloss -0.40053  last_update 8\n",
      "train: iter 146  trainloss 0.06416  validloss -0.38668±0.00000  bestvalidloss -0.40053  last_update 9\n",
      "train: iter 147  trainloss 0.05163  validloss -0.30889±0.00000  bestvalidloss -0.40053  last_update 10\n",
      "train: iter 148  trainloss 0.10151  validloss -0.42061±0.00000  bestvalidloss -0.42061  last_update 0\n",
      "train: iter 149  trainloss 0.09276  validloss -0.35963±0.00000  bestvalidloss -0.42061  last_update 1\n",
      "train: iter 150  trainloss 0.06860  validloss -0.40032±0.00000  bestvalidloss -0.42061  last_update 2\n",
      "train: iter 151  trainloss 0.08484  validloss -0.36932±0.00000  bestvalidloss -0.42061  last_update 3\n",
      "train: iter 152  trainloss 0.07933  validloss -0.38453±0.00000  bestvalidloss -0.42061  last_update 4\n",
      "train: iter 153  trainloss 0.08948  validloss -0.40179±0.00000  bestvalidloss -0.42061  last_update 5\n",
      "train: iter 154  trainloss 0.06336  validloss -0.36680±0.00000  bestvalidloss -0.42061  last_update 6\n",
      "train: iter 155  trainloss 0.07825  validloss -0.38169±0.00000  bestvalidloss -0.42061  last_update 7\n",
      "train: iter 156  trainloss 0.08464  validloss -0.38133±0.00000  bestvalidloss -0.42061  last_update 8\n",
      "train: iter 157  trainloss 0.10097  validloss -0.40652±0.00000  bestvalidloss -0.42061  last_update 9\n",
      "train: iter 158  trainloss 0.06964  validloss -0.42167±0.00000  bestvalidloss -0.42167  last_update 0\n",
      "train: iter 159  trainloss 0.06733  validloss -0.39214±0.00000  bestvalidloss -0.42167  last_update 1\n",
      "train: iter 160  trainloss 0.08812  validloss -0.41197±0.00000  bestvalidloss -0.42167  last_update 2\n",
      "train: iter 161  trainloss 0.09965  validloss -0.35841±0.00000  bestvalidloss -0.42167  last_update 3\n",
      "train: iter 162  trainloss 0.08576  validloss -0.36400±0.00000  bestvalidloss -0.42167  last_update 4\n",
      "train: iter 163  trainloss 0.05965  validloss -0.35346±0.00000  bestvalidloss -0.42167  last_update 5\n",
      "train: iter 164  trainloss 0.09016  validloss -0.42719±0.00000  bestvalidloss -0.42719  last_update 0\n",
      "train: iter 165  trainloss 0.10771  validloss -0.36697±0.00000  bestvalidloss -0.42719  last_update 1\n",
      "train: iter 166  trainloss 0.12000  validloss -0.37393±0.00000  bestvalidloss -0.42719  last_update 2\n",
      "train: iter 167  trainloss 0.08550  validloss -0.41919±0.00000  bestvalidloss -0.42719  last_update 3\n",
      "train: iter 168  trainloss 0.08934  validloss -0.36072±0.00000  bestvalidloss -0.42719  last_update 4\n",
      "train: iter 169  trainloss 0.06217  validloss -0.41872±0.00000  bestvalidloss -0.42719  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 170  trainloss 0.06986  validloss -0.37554±0.00000  bestvalidloss -0.42719  last_update 6\n",
      "train: iter 171  trainloss 0.05795  validloss -0.39631±0.00000  bestvalidloss -0.42719  last_update 7\n",
      "train: iter 172  trainloss 0.08660  validloss -0.43212±0.00000  bestvalidloss -0.43212  last_update 0\n",
      "train: iter 173  trainloss 0.08880  validloss -0.44358±0.00000  bestvalidloss -0.44358  last_update 0\n",
      "train: iter 174  trainloss 0.09508  validloss -0.40510±0.00000  bestvalidloss -0.44358  last_update 1\n",
      "train: iter 175  trainloss 0.08998  validloss -0.37226±0.00000  bestvalidloss -0.44358  last_update 2\n",
      "train: iter 176  trainloss 0.11213  validloss -0.39133±0.00000  bestvalidloss -0.44358  last_update 3\n",
      "train: iter 177  trainloss 0.06724  validloss -0.36815±0.00000  bestvalidloss -0.44358  last_update 4\n",
      "train: iter 178  trainloss 0.07176  validloss -0.39292±0.00000  bestvalidloss -0.44358  last_update 5\n",
      "train: iter 179  trainloss 0.08490  validloss -0.34757±0.00000  bestvalidloss -0.44358  last_update 6\n",
      "train: iter 180  trainloss 0.05162  validloss -0.42269±0.00000  bestvalidloss -0.44358  last_update 7\n",
      "train: iter 181  trainloss 0.08938  validloss -0.39383±0.00000  bestvalidloss -0.44358  last_update 8\n",
      "train: iter 182  trainloss 0.04164  validloss -0.44199±0.00000  bestvalidloss -0.44358  last_update 9\n",
      "train: iter 183  trainloss 0.07032  validloss -0.40307±0.00000  bestvalidloss -0.44358  last_update 10\n",
      "train: iter 184  trainloss 0.07570  validloss -0.37086±0.00000  bestvalidloss -0.44358  last_update 11\n",
      "train: iter 185  trainloss 0.03301  validloss -0.39267±0.00000  bestvalidloss -0.44358  last_update 12\n",
      "train: iter 186  trainloss 0.07021  validloss -0.38393±0.00000  bestvalidloss -0.44358  last_update 13\n",
      "train: iter 187  trainloss 0.06545  validloss -0.41254±0.00000  bestvalidloss -0.44358  last_update 14\n",
      "train: iter 188  trainloss 0.07720  validloss -0.38890±0.00000  bestvalidloss -0.44358  last_update 15\n",
      "train: iter 189  trainloss 0.06106  validloss -0.43164±0.00000  bestvalidloss -0.44358  last_update 16\n",
      "train: iter 190  trainloss 0.08913  validloss -0.35201±0.00000  bestvalidloss -0.44358  last_update 17\n",
      "train: iter 191  trainloss 0.07119  validloss -0.39986±0.00000  bestvalidloss -0.44358  last_update 18\n",
      "train: iter 192  trainloss 0.11470  validloss -0.40859±0.00000  bestvalidloss -0.44358  last_update 19\n",
      "train: iter 193  trainloss 0.09545  validloss -0.38961±0.00000  bestvalidloss -0.44358  last_update 20\n",
      "train: iter 194  trainloss 0.05684  validloss -0.36675±0.00000  bestvalidloss -0.44358  last_update 21\n",
      "train: iter 195  trainloss 0.07799  validloss -0.40787±0.00000  bestvalidloss -0.44358  last_update 22\n",
      "train: iter 196  trainloss 0.08026  validloss -0.37734±0.00000  bestvalidloss -0.44358  last_update 23\n",
      "train: iter 197  trainloss 0.09386  validloss -0.40826±0.00000  bestvalidloss -0.44358  last_update 24\n",
      "train: iter 198  trainloss 0.06862  validloss -0.34320±0.00000  bestvalidloss -0.44358  last_update 25\n",
      "train: iter 199  trainloss 0.05560  validloss -0.37929±0.00000  bestvalidloss -0.44358  last_update 26\n",
      "train: iter 200  trainloss 0.05803  validloss -0.41534±0.00000  bestvalidloss -0.44358  last_update 27\n",
      "train: iter 201  trainloss 0.08173  validloss -0.39377±0.00000  bestvalidloss -0.44358  last_update 28\n",
      "train: iter 202  trainloss 0.08297  validloss -0.33252±0.00000  bestvalidloss -0.44358  last_update 29\n",
      "train: iter 203  trainloss 0.07728  validloss -0.37461±0.00000  bestvalidloss -0.44358  last_update 30\n",
      "train: iter 204  trainloss 0.04786  validloss -0.41321±0.00000  bestvalidloss -0.44358  last_update 31\n",
      "train: iter 205  trainloss 0.07512  validloss -0.40213±0.00000  bestvalidloss -0.44358  last_update 32\n",
      "train: iter 206  trainloss 0.08809  validloss -0.46412±0.00000  bestvalidloss -0.46412  last_update 0\n",
      "train: iter 207  trainloss 0.07999  validloss -0.40403±0.00000  bestvalidloss -0.46412  last_update 1\n",
      "train: iter 208  trainloss 0.07025  validloss -0.38679±0.00000  bestvalidloss -0.46412  last_update 2\n",
      "train: iter 209  trainloss 0.05305  validloss -0.40674±0.00000  bestvalidloss -0.46412  last_update 3\n",
      "train: iter 210  trainloss 0.08279  validloss -0.44199±0.00000  bestvalidloss -0.46412  last_update 4\n",
      "train: iter 211  trainloss 0.12413  validloss -0.36962±0.00000  bestvalidloss -0.46412  last_update 5\n",
      "train: iter 212  trainloss 0.09776  validloss -0.43847±0.00000  bestvalidloss -0.46412  last_update 6\n",
      "train: iter 213  trainloss 0.08928  validloss -0.41083±0.00000  bestvalidloss -0.46412  last_update 7\n",
      "train: iter 214  trainloss 0.04851  validloss -0.42958±0.00000  bestvalidloss -0.46412  last_update 8\n",
      "train: iter 215  trainloss 0.08866  validloss -0.40563±0.00000  bestvalidloss -0.46412  last_update 9\n",
      "train: iter 216  trainloss 0.05472  validloss -0.40842±0.00000  bestvalidloss -0.46412  last_update 10\n",
      "train: iter 217  trainloss 0.05206  validloss -0.38887±0.00000  bestvalidloss -0.46412  last_update 11\n",
      "train: iter 218  trainloss 0.05327  validloss -0.37989±0.00000  bestvalidloss -0.46412  last_update 12\n",
      "train: iter 219  trainloss 0.09382  validloss -0.41723±0.00000  bestvalidloss -0.46412  last_update 13\n",
      "train: iter 220  trainloss 0.09451  validloss -0.40917±0.00000  bestvalidloss -0.46412  last_update 14\n",
      "train: iter 221  trainloss 0.07133  validloss -0.37375±0.00000  bestvalidloss -0.46412  last_update 15\n",
      "train: iter 222  trainloss 0.05113  validloss -0.39086±0.00000  bestvalidloss -0.46412  last_update 16\n",
      "train: iter 223  trainloss 0.08718  validloss -0.41197±0.00000  bestvalidloss -0.46412  last_update 17\n",
      "train: iter 224  trainloss 0.06985  validloss -0.40378±0.00000  bestvalidloss -0.46412  last_update 18\n",
      "train: iter 225  trainloss 0.07104  validloss -0.45341±0.00000  bestvalidloss -0.46412  last_update 19\n",
      "train: iter 226  trainloss 0.07760  validloss -0.40758±0.00000  bestvalidloss -0.46412  last_update 20\n",
      "train: iter 227  trainloss 0.08165  validloss -0.41652±0.00000  bestvalidloss -0.46412  last_update 21\n",
      "train: iter 228  trainloss 0.10717  validloss -0.38646±0.00000  bestvalidloss -0.46412  last_update 22\n",
      "train: iter 229  trainloss 0.07322  validloss -0.39319±0.00000  bestvalidloss -0.46412  last_update 23\n",
      "train: iter 230  trainloss 0.08881  validloss -0.41968±0.00000  bestvalidloss -0.46412  last_update 24\n",
      "train: iter 231  trainloss 0.09300  validloss -0.34186±0.00000  bestvalidloss -0.46412  last_update 25\n",
      "train: iter 232  trainloss 0.09408  validloss -0.37705±0.00000  bestvalidloss -0.46412  last_update 26\n",
      "train: iter 233  trainloss 0.05467  validloss -0.44403±0.00000  bestvalidloss -0.46412  last_update 27\n",
      "train: iter 234  trainloss 0.08674  validloss -0.37188±0.00000  bestvalidloss -0.46412  last_update 28\n",
      "train: iter 235  trainloss 0.06467  validloss -0.40450±0.00000  bestvalidloss -0.46412  last_update 29\n",
      "train: iter 236  trainloss 0.06085  validloss -0.41153±0.00000  bestvalidloss -0.46412  last_update 30\n",
      "train: iter 237  trainloss 0.06692  validloss -0.44312±0.00000  bestvalidloss -0.46412  last_update 31\n",
      "train: iter 238  trainloss 0.08783  validloss -0.40645±0.00000  bestvalidloss -0.46412  last_update 32\n",
      "train: iter 239  trainloss 0.09076  validloss -0.34658±0.00000  bestvalidloss -0.46412  last_update 33\n",
      "train: iter 240  trainloss 0.07356  validloss -0.44070±0.00000  bestvalidloss -0.46412  last_update 34\n",
      "train: iter 241  trainloss 0.09363  validloss -0.36295±0.00000  bestvalidloss -0.46412  last_update 35\n",
      "train: iter 242  trainloss 0.04588  validloss -0.41255±0.00000  bestvalidloss -0.46412  last_update 36\n",
      "train: iter 243  trainloss 0.07567  validloss -0.39744±0.00000  bestvalidloss -0.46412  last_update 37\n",
      "train: iter 244  trainloss 0.10600  validloss -0.43005±0.00000  bestvalidloss -0.46412  last_update 38\n",
      "train: iter 245  trainloss 0.08338  validloss -0.42782±0.00000  bestvalidloss -0.46412  last_update 39\n",
      "train: iter 246  trainloss 0.06483  validloss -0.37984±0.00000  bestvalidloss -0.46412  last_update 40\n",
      "train: iter 247  trainloss 0.09505  validloss -0.38218±0.00000  bestvalidloss -0.46412  last_update 41\n",
      "train: iter 248  trainloss 0.10083  validloss -0.43053±0.00000  bestvalidloss -0.46412  last_update 42\n",
      "train: iter 249  trainloss 0.09712  validloss -0.38383±0.00000  bestvalidloss -0.46412  last_update 43\n",
      "train: iter 250  trainloss 0.07697  validloss -0.34039±0.00000  bestvalidloss -0.46412  last_update 44\n",
      "train: iter 251  trainloss 0.08589  validloss -0.41659±0.00000  bestvalidloss -0.46412  last_update 45\n",
      "train: iter 252  trainloss 0.06405  validloss -0.37546±0.00000  bestvalidloss -0.46412  last_update 46\n",
      "train: iter 253  trainloss 0.11297  validloss -0.43284±0.00000  bestvalidloss -0.46412  last_update 47\n",
      "train: iter 254  trainloss 0.11363  validloss -0.41040±0.00000  bestvalidloss -0.46412  last_update 48\n",
      "train: iter 255  trainloss 0.09578  validloss -0.39119±0.00000  bestvalidloss -0.46412  last_update 49\n",
      "train: iter 256  trainloss 0.10011  validloss -0.42385±0.00000  bestvalidloss -0.46412  last_update 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 257  trainloss 0.08508  validloss -0.36165±0.00000  bestvalidloss -0.46412  last_update 51\n",
      "train: iter 258  trainloss 0.06582  validloss -0.35333±0.00000  bestvalidloss -0.46412  last_update 52\n",
      "train: iter 259  trainloss 0.07875  validloss -0.41170±0.00000  bestvalidloss -0.46412  last_update 53\n",
      "train: iter 260  trainloss 0.08212  validloss -0.38333±0.00000  bestvalidloss -0.46412  last_update 54\n",
      "train: iter 261  trainloss 0.08678  validloss -0.41687±0.00000  bestvalidloss -0.46412  last_update 55\n",
      "train: iter 262  trainloss 0.08653  validloss -0.37737±0.00000  bestvalidloss -0.46412  last_update 56\n",
      "train: iter 263  trainloss 0.10805  validloss -0.39499±0.00000  bestvalidloss -0.46412  last_update 57\n",
      "train: iter 264  trainloss 0.10161  validloss -0.42868±0.00000  bestvalidloss -0.46412  last_update 58\n",
      "train: iter 265  trainloss 0.09637  validloss -0.39764±0.00000  bestvalidloss -0.46412  last_update 59\n",
      "train: iter 266  trainloss 0.08290  validloss -0.39349±0.00000  bestvalidloss -0.46412  last_update 60\n",
      "train: iter 267  trainloss 0.10813  validloss -0.40650±0.00000  bestvalidloss -0.46412  last_update 61\n",
      "train: iter 268  trainloss 0.09106  validloss -0.43207±0.00000  bestvalidloss -0.46412  last_update 62\n",
      "train: iter 269  trainloss 0.04604  validloss -0.40087±0.00000  bestvalidloss -0.46412  last_update 63\n",
      "train: iter 270  trainloss 0.09666  validloss -0.37426±0.00000  bestvalidloss -0.46412  last_update 64\n",
      "train: iter 271  trainloss 0.06833  validloss -0.39168±0.00000  bestvalidloss -0.46412  last_update 65\n",
      "train: iter 272  trainloss 0.09764  validloss -0.43158±0.00000  bestvalidloss -0.46412  last_update 66\n",
      "train: iter 273  trainloss 0.06141  validloss -0.35116±0.00000  bestvalidloss -0.46412  last_update 67\n",
      "train: iter 274  trainloss 0.06263  validloss -0.41312±0.00000  bestvalidloss -0.46412  last_update 68\n",
      "train: iter 275  trainloss 0.05901  validloss -0.39143±0.00000  bestvalidloss -0.46412  last_update 69\n",
      "train: iter 276  trainloss 0.05284  validloss -0.40654±0.00000  bestvalidloss -0.46412  last_update 70\n",
      "train: iter 277  trainloss 0.07100  validloss -0.40862±0.00000  bestvalidloss -0.46412  last_update 71\n",
      "train: iter 278  trainloss 0.07217  validloss -0.39593±0.00000  bestvalidloss -0.46412  last_update 72\n",
      "train: iter 279  trainloss 0.06349  validloss -0.43213±0.00000  bestvalidloss -0.46412  last_update 73\n",
      "train: iter 280  trainloss 0.08687  validloss -0.39728±0.00000  bestvalidloss -0.46412  last_update 74\n",
      "train: iter 281  trainloss 0.04529  validloss -0.38423±0.00000  bestvalidloss -0.46412  last_update 75\n",
      "train: iter 282  trainloss 0.08311  validloss -0.36928±0.00000  bestvalidloss -0.46412  last_update 76\n",
      "train: iter 283  trainloss 0.05343  validloss -0.42171±0.00000  bestvalidloss -0.46412  last_update 77\n",
      "train: iter 284  trainloss 0.09113  validloss -0.39196±0.00000  bestvalidloss -0.46412  last_update 78\n",
      "train: iter 285  trainloss 0.08679  validloss -0.44427±0.00000  bestvalidloss -0.46412  last_update 79\n",
      "train: iter 286  trainloss 0.06941  validloss -0.37810±0.00000  bestvalidloss -0.46412  last_update 80\n",
      "train: iter 287  trainloss 0.09594  validloss -0.42393±0.00000  bestvalidloss -0.46412  last_update 81\n",
      "train: iter 288  trainloss 0.03612  validloss -0.44993±0.00000  bestvalidloss -0.46412  last_update 82\n",
      "train: iter 289  trainloss 0.08258  validloss -0.45674±0.00000  bestvalidloss -0.46412  last_update 83\n",
      "train: iter 290  trainloss 0.05144  validloss -0.43881±0.00000  bestvalidloss -0.46412  last_update 84\n",
      "train: iter 291  trainloss 0.07087  validloss -0.35663±0.00000  bestvalidloss -0.46412  last_update 85\n",
      "train: iter 292  trainloss 0.06494  validloss -0.44712±0.00000  bestvalidloss -0.46412  last_update 86\n",
      "train: iter 293  trainloss 0.05045  validloss -0.41103±0.00000  bestvalidloss -0.46412  last_update 87\n",
      "train: iter 294  trainloss 0.06174  validloss -0.37395±0.00000  bestvalidloss -0.46412  last_update 88\n",
      "train: iter 295  trainloss 0.07930  validloss -0.42515±0.00000  bestvalidloss -0.46412  last_update 89\n",
      "train: iter 296  trainloss 0.09105  validloss -0.37641±0.00000  bestvalidloss -0.46412  last_update 90\n",
      "train: iter 297  trainloss 0.03847  validloss -0.41939±0.00000  bestvalidloss -0.46412  last_update 91\n",
      "train: iter 298  trainloss 0.06850  validloss -0.40314±0.00000  bestvalidloss -0.46412  last_update 92\n",
      "train: iter 299  trainloss 0.07808  validloss -0.40592±0.00000  bestvalidloss -0.46412  last_update 93\n",
      "train: iter 300  trainloss 0.03536  validloss -0.39878±0.00000  bestvalidloss -0.46412  last_update 94\n",
      "train: iter 301  trainloss 0.05903  validloss -0.35400±0.00000  bestvalidloss -0.46412  last_update 95\n",
      "train: iter 302  trainloss 0.08727  validloss -0.38677±0.00000  bestvalidloss -0.46412  last_update 96\n",
      "train: iter 303  trainloss 0.08820  validloss -0.41599±0.00000  bestvalidloss -0.46412  last_update 97\n",
      "train: iter 304  trainloss 0.07886  validloss -0.38570±0.00000  bestvalidloss -0.46412  last_update 98\n",
      "train: iter 305  trainloss 0.06797  validloss -0.37940±0.00000  bestvalidloss -0.46412  last_update 99\n",
      "train: iter 306  trainloss 0.05533  validloss -0.43088±0.00000  bestvalidloss -0.46412  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.5770, -0.1358, -3.5518, -1.9655], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 61.48760  validloss 69.89290±0.00000  bestvalidloss 69.89290  last_update 0\n",
      "train: iter 1  trainloss 43.04416  validloss 52.76609±0.00000  bestvalidloss 52.76609  last_update 0\n",
      "train: iter 2  trainloss 30.15887  validloss 36.14084±0.00000  bestvalidloss 36.14084  last_update 0\n",
      "train: iter 3  trainloss 22.19600  validloss 26.69783±0.00000  bestvalidloss 26.69783  last_update 0\n",
      "train: iter 4  trainloss 17.17559  validloss 20.54629±0.00000  bestvalidloss 20.54629  last_update 0\n",
      "train: iter 5  trainloss 13.93720  validloss 16.51345±0.00000  bestvalidloss 16.51345  last_update 0\n",
      "train: iter 6  trainloss 11.74764  validloss 13.84711±0.00000  bestvalidloss 13.84711  last_update 0\n",
      "train: iter 7  trainloss 10.23662  validloss 11.99830±0.00000  bestvalidloss 11.99830  last_update 0\n",
      "train: iter 8  trainloss 9.17722  validloss 10.67876±0.00000  bestvalidloss 10.67876  last_update 0\n",
      "train: iter 9  trainloss 8.38633  validloss 9.77024±0.00000  bestvalidloss 9.77024  last_update 0\n",
      "train: iter 10  trainloss 7.87086  validloss 9.02454±0.00000  bestvalidloss 9.02454  last_update 0\n",
      "train: iter 11  trainloss 7.37566  validloss 8.29881±0.00000  bestvalidloss 8.29881  last_update 0\n",
      "train: iter 12  trainloss 7.03359  validloss 7.88254±0.00000  bestvalidloss 7.88254  last_update 0\n",
      "train: iter 13  trainloss 6.66776  validloss 7.35120±0.00000  bestvalidloss 7.35120  last_update 0\n",
      "train: iter 14  trainloss 6.30040  validloss 6.92842±0.00000  bestvalidloss 6.92842  last_update 0\n",
      "train: iter 15  trainloss 5.97045  validloss 6.66580±0.00000  bestvalidloss 6.66580  last_update 0\n",
      "train: iter 16  trainloss 5.70544  validloss 6.21184±0.00000  bestvalidloss 6.21184  last_update 0\n",
      "train: iter 17  trainloss 5.52434  validloss 5.99784±0.00000  bestvalidloss 5.99784  last_update 0\n",
      "train: iter 18  trainloss 5.31654  validloss 5.70611±0.00000  bestvalidloss 5.70611  last_update 0\n",
      "train: iter 19  trainloss 5.16049  validloss 5.54636±0.00000  bestvalidloss 5.54636  last_update 0\n",
      "train: iter 20  trainloss 5.00917  validloss 5.31263±0.00000  bestvalidloss 5.31263  last_update 0\n",
      "train: iter 21  trainloss 4.86877  validloss 5.31402±0.00000  bestvalidloss 5.31263  last_update 1\n",
      "train: iter 22  trainloss 4.65007  validloss 5.03751±0.00000  bestvalidloss 5.03751  last_update 0\n",
      "train: iter 23  trainloss 4.50483  validloss 5.04198±0.00000  bestvalidloss 5.03751  last_update 1\n",
      "train: iter 24  trainloss 4.34406  validloss 4.81066±0.00000  bestvalidloss 4.81066  last_update 0\n",
      "train: iter 25  trainloss 4.35604  validloss 4.98282±0.00000  bestvalidloss 4.81066  last_update 1\n",
      "train: iter 26  trainloss 4.20305  validloss 4.75404±0.00000  bestvalidloss 4.75404  last_update 0\n",
      "train: iter 27  trainloss 4.22385  validloss 4.77143±0.00000  bestvalidloss 4.75404  last_update 1\n",
      "train: iter 28  trainloss 4.15423  validloss 4.77724±0.00000  bestvalidloss 4.75404  last_update 2\n",
      "train: iter 29  trainloss 4.11978  validloss 4.68681±0.00000  bestvalidloss 4.68681  last_update 0\n",
      "train: iter 30  trainloss 4.15663  validloss 4.80414±0.00000  bestvalidloss 4.68681  last_update 1\n",
      "train: iter 31  trainloss 4.10188  validloss 4.80133±0.00000  bestvalidloss 4.68681  last_update 2\n",
      "train: iter 32  trainloss 4.03607  validloss 4.50137±0.00000  bestvalidloss 4.50137  last_update 0\n",
      "train: iter 33  trainloss 4.01014  validloss 4.62120±0.00000  bestvalidloss 4.50137  last_update 1\n",
      "train: iter 34  trainloss 4.03621  validloss 4.50024±0.00000  bestvalidloss 4.50024  last_update 0\n",
      "train: iter 35  trainloss 3.99121  validloss 4.58755±0.00000  bestvalidloss 4.50024  last_update 1\n",
      "train: iter 36  trainloss 4.00926  validloss 4.68627±0.00000  bestvalidloss 4.50024  last_update 2\n",
      "train: iter 37  trainloss 3.98658  validloss 4.56510±0.00000  bestvalidloss 4.50024  last_update 3\n",
      "train: iter 38  trainloss 3.95038  validloss 4.68359±0.00000  bestvalidloss 4.50024  last_update 4\n",
      "train: iter 39  trainloss 3.92991  validloss 4.64423±0.00000  bestvalidloss 4.50024  last_update 5\n",
      "train: iter 40  trainloss 3.91115  validloss 4.73175±0.00000  bestvalidloss 4.50024  last_update 6\n",
      "train: iter 41  trainloss 3.90987  validloss 4.59406±0.00000  bestvalidloss 4.50024  last_update 7\n",
      "train: iter 42  trainloss 3.97207  validloss 4.80507±0.00000  bestvalidloss 4.50024  last_update 8\n",
      "train: iter 43  trainloss 3.88873  validloss 4.49692±0.00000  bestvalidloss 4.49692  last_update 0\n",
      "train: iter 44  trainloss 3.88146  validloss 4.59297±0.00000  bestvalidloss 4.49692  last_update 1\n",
      "train: iter 45  trainloss 3.85286  validloss 4.53110±0.00000  bestvalidloss 4.49692  last_update 2\n",
      "train: iter 46  trainloss 3.85543  validloss 4.77178±0.00000  bestvalidloss 4.49692  last_update 3\n",
      "train: iter 47  trainloss 3.88565  validloss 4.87181±0.00000  bestvalidloss 4.49692  last_update 4\n",
      "train: iter 48  trainloss 3.83058  validloss 4.56716±0.00000  bestvalidloss 4.49692  last_update 5\n",
      "train: iter 49  trainloss 3.83130  validloss 4.65439±0.00000  bestvalidloss 4.49692  last_update 6\n",
      "train: iter 50  trainloss 3.82844  validloss 4.59502±0.00000  bestvalidloss 4.49692  last_update 7\n",
      "train: iter 51  trainloss 3.76883  validloss 4.59546±0.00000  bestvalidloss 4.49692  last_update 8\n",
      "train: iter 52  trainloss 3.75856  validloss 4.55484±0.00000  bestvalidloss 4.49692  last_update 9\n",
      "train: iter 53  trainloss 3.77416  validloss 4.59861±0.00000  bestvalidloss 4.49692  last_update 10\n",
      "train: iter 54  trainloss 3.75837  validloss 4.54020±0.00000  bestvalidloss 4.49692  last_update 11\n",
      "train: iter 55  trainloss 3.74820  validloss 4.54973±0.00000  bestvalidloss 4.49692  last_update 12\n",
      "train: iter 56  trainloss 3.76169  validloss 4.50570±0.00000  bestvalidloss 4.49692  last_update 13\n",
      "train: iter 57  trainloss 3.73653  validloss 4.56269±0.00000  bestvalidloss 4.49692  last_update 14\n",
      "train: iter 58  trainloss 3.79226  validloss 4.41975±0.00000  bestvalidloss 4.41975  last_update 0\n",
      "train: iter 59  trainloss 3.71292  validloss 4.39855±0.00000  bestvalidloss 4.39855  last_update 0\n",
      "train: iter 60  trainloss 3.75078  validloss 4.35895±0.00000  bestvalidloss 4.35895  last_update 0\n",
      "train: iter 61  trainloss 3.73082  validloss 4.47289±0.00000  bestvalidloss 4.35895  last_update 1\n",
      "train: iter 62  trainloss 3.68956  validloss 4.58020±0.00000  bestvalidloss 4.35895  last_update 2\n",
      "train: iter 63  trainloss 3.72142  validloss 4.53844±0.00000  bestvalidloss 4.35895  last_update 3\n",
      "train: iter 64  trainloss 3.70144  validloss 4.40646±0.00000  bestvalidloss 4.35895  last_update 4\n",
      "train: iter 65  trainloss 3.68701  validloss 4.43822±0.00000  bestvalidloss 4.35895  last_update 5\n",
      "train: iter 66  trainloss 3.69939  validloss 4.49274±0.00000  bestvalidloss 4.35895  last_update 6\n",
      "train: iter 67  trainloss 3.69177  validloss 4.59575±0.00000  bestvalidloss 4.35895  last_update 7\n",
      "train: iter 68  trainloss 3.73424  validloss 4.46072±0.00000  bestvalidloss 4.35895  last_update 8\n",
      "train: iter 69  trainloss 3.66767  validloss 4.44328±0.00000  bestvalidloss 4.35895  last_update 9\n",
      "train: iter 70  trainloss 3.66533  validloss 4.48949±0.00000  bestvalidloss 4.35895  last_update 10\n",
      "train: iter 71  trainloss 3.70663  validloss 4.51720±0.00000  bestvalidloss 4.35895  last_update 11\n",
      "train: iter 72  trainloss 3.64858  validloss 4.48823±0.00000  bestvalidloss 4.35895  last_update 12\n",
      "train: iter 73  trainloss 3.65194  validloss 4.52474±0.00000  bestvalidloss 4.35895  last_update 13\n",
      "train: iter 74  trainloss 3.65459  validloss 4.45204±0.00000  bestvalidloss 4.35895  last_update 14\n",
      "train: iter 75  trainloss 3.61818  validloss 4.36307±0.00000  bestvalidloss 4.35895  last_update 15\n",
      "train: iter 76  trainloss 3.59267  validloss 4.47381±0.00000  bestvalidloss 4.35895  last_update 16\n",
      "train: iter 77  trainloss 3.66616  validloss 4.42176±0.00000  bestvalidloss 4.35895  last_update 17\n",
      "train: iter 78  trainloss 3.63143  validloss 4.29466±0.00000  bestvalidloss 4.29466  last_update 0\n",
      "train: iter 79  trainloss 3.68238  validloss 4.31291±0.00000  bestvalidloss 4.29466  last_update 1\n",
      "train: iter 80  trainloss 3.61494  validloss 4.22862±0.00000  bestvalidloss 4.22862  last_update 0\n",
      "train: iter 81  trainloss 3.61008  validloss 4.63246±0.00000  bestvalidloss 4.22862  last_update 1\n",
      "train: iter 82  trainloss 3.62118  validloss 4.30788±0.00000  bestvalidloss 4.22862  last_update 2\n",
      "train: iter 83  trainloss 3.60793  validloss 4.37248±0.00000  bestvalidloss 4.22862  last_update 3\n",
      "train: iter 84  trainloss 3.62705  validloss 4.53718±0.00000  bestvalidloss 4.22862  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 3.61451  validloss 4.48456±0.00000  bestvalidloss 4.22862  last_update 5\n",
      "train: iter 86  trainloss 3.62322  validloss 4.69339±0.00000  bestvalidloss 4.22862  last_update 6\n",
      "train: iter 87  trainloss 3.62179  validloss 4.39379±0.00000  bestvalidloss 4.22862  last_update 7\n",
      "train: iter 88  trainloss 3.61008  validloss 4.52628±0.00000  bestvalidloss 4.22862  last_update 8\n",
      "train: iter 89  trainloss 3.63954  validloss 4.33414±0.00000  bestvalidloss 4.22862  last_update 9\n",
      "train: iter 90  trainloss 3.62288  validloss 4.41354±0.00000  bestvalidloss 4.22862  last_update 10\n",
      "train: iter 91  trainloss 3.61933  validloss 4.54509±0.00000  bestvalidloss 4.22862  last_update 11\n",
      "train: iter 92  trainloss 3.62662  validloss 4.31364±0.00000  bestvalidloss 4.22862  last_update 12\n",
      "train: iter 93  trainloss 3.60416  validloss 4.41370±0.00000  bestvalidloss 4.22862  last_update 13\n",
      "train: iter 94  trainloss 3.59895  validloss 4.31969±0.00000  bestvalidloss 4.22862  last_update 14\n",
      "train: iter 95  trainloss 3.60002  validloss 4.46741±0.00000  bestvalidloss 4.22862  last_update 15\n",
      "train: iter 96  trainloss 3.59093  validloss 4.69044±0.00000  bestvalidloss 4.22862  last_update 16\n",
      "train: iter 97  trainloss 3.57689  validloss 4.35049±0.00000  bestvalidloss 4.22862  last_update 17\n",
      "train: iter 98  trainloss 3.60771  validloss 4.37255±0.00000  bestvalidloss 4.22862  last_update 18\n",
      "train: iter 99  trainloss 3.62879  validloss 4.50880±0.00000  bestvalidloss 4.22862  last_update 19\n",
      "train: iter 100  trainloss 3.57924  validloss 4.41673±0.00000  bestvalidloss 4.22862  last_update 20\n",
      "train: iter 101  trainloss 3.58920  validloss 4.52821±0.00000  bestvalidloss 4.22862  last_update 21\n",
      "train: iter 102  trainloss 3.59379  validloss 4.28242±0.00000  bestvalidloss 4.22862  last_update 22\n",
      "train: iter 103  trainloss 3.60498  validloss 4.41019±0.00000  bestvalidloss 4.22862  last_update 23\n",
      "train: iter 104  trainloss 3.57783  validloss 4.36921±0.00000  bestvalidloss 4.22862  last_update 24\n",
      "train: iter 105  trainloss 3.58717  validloss 4.60959±0.00000  bestvalidloss 4.22862  last_update 25\n",
      "train: iter 106  trainloss 3.60094  validloss 4.63592±0.00000  bestvalidloss 4.22862  last_update 26\n",
      "train: iter 107  trainloss 3.58052  validloss 4.56622±0.00000  bestvalidloss 4.22862  last_update 27\n",
      "train: iter 108  trainloss 3.63575  validloss 4.51984±0.00000  bestvalidloss 4.22862  last_update 28\n",
      "train: iter 109  trainloss 3.62274  validloss 4.46975±0.00000  bestvalidloss 4.22862  last_update 29\n",
      "train: iter 110  trainloss 3.59919  validloss 4.32355±0.00000  bestvalidloss 4.22862  last_update 30\n",
      "train: iter 111  trainloss 3.59194  validloss 4.58247±0.00000  bestvalidloss 4.22862  last_update 31\n",
      "train: iter 112  trainloss 3.59635  validloss 4.50169±0.00000  bestvalidloss 4.22862  last_update 32\n",
      "train: iter 113  trainloss 3.59429  validloss 4.56551±0.00000  bestvalidloss 4.22862  last_update 33\n",
      "train: iter 114  trainloss 3.56876  validloss 4.61823±0.00000  bestvalidloss 4.22862  last_update 34\n",
      "train: iter 115  trainloss 3.55517  validloss 4.53892±0.00000  bestvalidloss 4.22862  last_update 35\n",
      "train: iter 116  trainloss 3.56474  validloss 4.40316±0.00000  bestvalidloss 4.22862  last_update 36\n",
      "train: iter 117  trainloss 3.56276  validloss 4.49368±0.00000  bestvalidloss 4.22862  last_update 37\n",
      "train: iter 118  trainloss 3.62386  validloss 4.62593±0.00000  bestvalidloss 4.22862  last_update 38\n",
      "train: iter 119  trainloss 3.53698  validloss 4.61156±0.00000  bestvalidloss 4.22862  last_update 39\n",
      "train: iter 120  trainloss 3.53684  validloss 4.44615±0.00000  bestvalidloss 4.22862  last_update 40\n",
      "train: iter 121  trainloss 3.51791  validloss 4.32510±0.00000  bestvalidloss 4.22862  last_update 41\n",
      "train: iter 122  trainloss 3.58200  validloss 4.52450±0.00000  bestvalidloss 4.22862  last_update 42\n",
      "train: iter 123  trainloss 3.55346  validloss 4.28851±0.00000  bestvalidloss 4.22862  last_update 43\n",
      "train: iter 124  trainloss 3.58693  validloss 4.36331±0.00000  bestvalidloss 4.22862  last_update 44\n",
      "train: iter 125  trainloss 3.53146  validloss 4.37712±0.00000  bestvalidloss 4.22862  last_update 45\n",
      "train: iter 126  trainloss 3.57875  validloss 4.55516±0.00000  bestvalidloss 4.22862  last_update 46\n",
      "train: iter 127  trainloss 3.56932  validloss 4.51134±0.00000  bestvalidloss 4.22862  last_update 47\n",
      "train: iter 128  trainloss 3.53905  validloss 4.36481±0.00000  bestvalidloss 4.22862  last_update 48\n",
      "train: iter 129  trainloss 3.57932  validloss 4.49568±0.00000  bestvalidloss 4.22862  last_update 49\n",
      "train: iter 130  trainloss 3.52455  validloss 4.51654±0.00000  bestvalidloss 4.22862  last_update 50\n",
      "train: iter 131  trainloss 3.56665  validloss 4.29327±0.00000  bestvalidloss 4.22862  last_update 51\n",
      "train: iter 132  trainloss 3.55582  validloss 4.36771±0.00000  bestvalidloss 4.22862  last_update 52\n",
      "train: iter 133  trainloss 3.54984  validloss 4.65194±0.00000  bestvalidloss 4.22862  last_update 53\n",
      "train: iter 134  trainloss 3.54326  validloss 4.65398±0.00000  bestvalidloss 4.22862  last_update 54\n",
      "train: iter 135  trainloss 3.58748  validloss 4.34827±0.00000  bestvalidloss 4.22862  last_update 55\n",
      "train: iter 136  trainloss 3.55048  validloss 4.45263±0.00000  bestvalidloss 4.22862  last_update 56\n",
      "train: iter 137  trainloss 3.54965  validloss 4.58783±0.00000  bestvalidloss 4.22862  last_update 57\n",
      "train: iter 138  trainloss 3.59600  validloss 4.35744±0.00000  bestvalidloss 4.22862  last_update 58\n",
      "train: iter 139  trainloss 3.58156  validloss 4.32543±0.00000  bestvalidloss 4.22862  last_update 59\n",
      "train: iter 140  trainloss 3.53727  validloss 4.42775±0.00000  bestvalidloss 4.22862  last_update 60\n",
      "train: iter 141  trainloss 3.56871  validloss 4.31025±0.00000  bestvalidloss 4.22862  last_update 61\n",
      "train: iter 142  trainloss 3.51778  validloss 4.69652±0.00000  bestvalidloss 4.22862  last_update 62\n",
      "train: iter 143  trainloss 3.52025  validloss 4.42844±0.00000  bestvalidloss 4.22862  last_update 63\n",
      "train: iter 144  trainloss 3.53399  validloss 4.42279±0.00000  bestvalidloss 4.22862  last_update 64\n",
      "train: iter 145  trainloss 3.52043  validloss 4.62585±0.00000  bestvalidloss 4.22862  last_update 65\n",
      "train: iter 146  trainloss 3.56912  validloss 4.58838±0.00000  bestvalidloss 4.22862  last_update 66\n",
      "train: iter 147  trainloss 3.55734  validloss 4.64870±0.00000  bestvalidloss 4.22862  last_update 67\n",
      "train: iter 148  trainloss 3.50073  validloss 4.37054±0.00000  bestvalidloss 4.22862  last_update 68\n",
      "train: iter 149  trainloss 3.54586  validloss 4.31728±0.00000  bestvalidloss 4.22862  last_update 69\n",
      "train: iter 150  trainloss 3.50576  validloss 4.54084±0.00000  bestvalidloss 4.22862  last_update 70\n",
      "train: iter 151  trainloss 3.49699  validloss 4.65726±0.00000  bestvalidloss 4.22862  last_update 71\n",
      "train: iter 152  trainloss 3.51729  validloss 4.34430±0.00000  bestvalidloss 4.22862  last_update 72\n",
      "train: iter 153  trainloss 3.54798  validloss 4.43464±0.00000  bestvalidloss 4.22862  last_update 73\n",
      "train: iter 154  trainloss 3.56104  validloss 4.49565±0.00000  bestvalidloss 4.22862  last_update 74\n",
      "train: iter 155  trainloss 3.54394  validloss 4.72043±0.00000  bestvalidloss 4.22862  last_update 75\n",
      "train: iter 156  trainloss 3.55459  validloss 4.48238±0.00000  bestvalidloss 4.22862  last_update 76\n",
      "train: iter 157  trainloss 3.48937  validloss 4.56905±0.00000  bestvalidloss 4.22862  last_update 77\n",
      "train: iter 158  trainloss 3.53591  validloss 4.48265±0.00000  bestvalidloss 4.22862  last_update 78\n",
      "train: iter 159  trainloss 3.54663  validloss 4.52142±0.00000  bestvalidloss 4.22862  last_update 79\n",
      "train: iter 160  trainloss 3.49925  validloss 4.63321±0.00000  bestvalidloss 4.22862  last_update 80\n",
      "train: iter 161  trainloss 3.57261  validloss 4.49792±0.00000  bestvalidloss 4.22862  last_update 81\n",
      "train: iter 162  trainloss 3.50166  validloss 4.47523±0.00000  bestvalidloss 4.22862  last_update 82\n",
      "train: iter 163  trainloss 3.51580  validloss 4.48172±0.00000  bestvalidloss 4.22862  last_update 83\n",
      "train: iter 164  trainloss 3.57973  validloss 4.35554±0.00000  bestvalidloss 4.22862  last_update 84\n",
      "train: iter 165  trainloss 3.51786  validloss 4.54187±0.00000  bestvalidloss 4.22862  last_update 85\n",
      "train: iter 166  trainloss 3.54868  validloss 4.39206±0.00000  bestvalidloss 4.22862  last_update 86\n",
      "train: iter 167  trainloss 3.52506  validloss 4.54766±0.00000  bestvalidloss 4.22862  last_update 87\n",
      "train: iter 168  trainloss 3.52645  validloss 4.47559±0.00000  bestvalidloss 4.22862  last_update 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 169  trainloss 3.49354  validloss 4.39683±0.00000  bestvalidloss 4.22862  last_update 89\n",
      "train: iter 170  trainloss 3.49371  validloss 4.58126±0.00000  bestvalidloss 4.22862  last_update 90\n",
      "train: iter 171  trainloss 3.53358  validloss 4.57284±0.00000  bestvalidloss 4.22862  last_update 91\n",
      "train: iter 172  trainloss 3.54497  validloss 4.51960±0.00000  bestvalidloss 4.22862  last_update 92\n",
      "train: iter 173  trainloss 3.50354  validloss 4.65890±0.00000  bestvalidloss 4.22862  last_update 93\n",
      "train: iter 174  trainloss 3.53997  validloss 4.54642±0.00000  bestvalidloss 4.22862  last_update 94\n",
      "train: iter 175  trainloss 3.50937  validloss 4.40131±0.00000  bestvalidloss 4.22862  last_update 95\n",
      "train: iter 176  trainloss 3.49928  validloss 4.23169±0.00000  bestvalidloss 4.22862  last_update 96\n",
      "train: iter 177  trainloss 3.50600  validloss 4.33511±0.00000  bestvalidloss 4.22862  last_update 97\n",
      "train: iter 178  trainloss 3.52323  validloss 4.40484±0.00000  bestvalidloss 4.22862  last_update 98\n",
      "train: iter 179  trainloss 3.48737  validloss 4.65478±0.00000  bestvalidloss 4.22862  last_update 99\n",
      "train: iter 180  trainloss 3.50340  validloss 4.45738±0.00000  bestvalidloss 4.22862  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-9.2302)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(7.9096)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0613557178628085\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
