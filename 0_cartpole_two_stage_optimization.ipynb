{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-629.9164)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 758.98932  validloss 1277.95602±0.00000  bestvalidloss 1277.95602  last_update 0\n",
      "train: iter 1  trainloss 401.18172  validloss 476.58524±0.00000  bestvalidloss 476.58524  last_update 0\n",
      "train: iter 2  trainloss 86.96178  validloss 216.05511±0.00000  bestvalidloss 216.05511  last_update 0\n",
      "train: iter 3  trainloss 36.71726  validloss 50.02952±0.00000  bestvalidloss 50.02952  last_update 0\n",
      "train: iter 4  trainloss -171.58798  validloss -30.08887±0.00000  bestvalidloss -30.08887  last_update 0\n",
      "train: iter 5  trainloss -310.21976  validloss -192.17689±0.00000  bestvalidloss -192.17689  last_update 0\n",
      "train: iter 6  trainloss -412.86820  validloss -318.80389±0.00000  bestvalidloss -318.80389  last_update 0\n",
      "train: iter 7  trainloss -505.07276  validloss -467.47201±0.00000  bestvalidloss -467.47201  last_update 0\n",
      "train: iter 8  trainloss -594.40942  validloss -478.50148±0.00000  bestvalidloss -478.50148  last_update 0\n",
      "train: iter 9  trainloss -698.64719  validloss -596.19093±0.00000  bestvalidloss -596.19093  last_update 0\n",
      "train: iter 10  trainloss -745.95899  validloss -568.15054±0.00000  bestvalidloss -596.19093  last_update 1\n",
      "train: iter 11  trainloss -690.28784  validloss -748.50849±0.00000  bestvalidloss -748.50849  last_update 0\n",
      "train: iter 12  trainloss -806.31755  validloss -655.81384±0.00000  bestvalidloss -748.50849  last_update 1\n",
      "train: iter 13  trainloss -883.81186  validloss -818.97015±0.00000  bestvalidloss -818.97015  last_update 0\n",
      "train: iter 14  trainloss -904.33966  validloss -772.21057±0.00000  bestvalidloss -818.97015  last_update 1\n",
      "train: iter 15  trainloss -978.34431  validloss -835.83702±0.00000  bestvalidloss -835.83702  last_update 0\n",
      "train: iter 16  trainloss -1013.74675  validloss -888.96212±0.00000  bestvalidloss -888.96212  last_update 0\n",
      "train: iter 17  trainloss -1026.07594  validloss -957.99984±0.00000  bestvalidloss -957.99984  last_update 0\n",
      "train: iter 18  trainloss -1054.94213  validloss -1017.96418±0.00000  bestvalidloss -1017.96418  last_update 0\n",
      "train: iter 19  trainloss -1075.48268  validloss -1006.39780±0.00000  bestvalidloss -1017.96418  last_update 1\n",
      "train: iter 20  trainloss -1065.78615  validloss -953.78549±0.00000  bestvalidloss -1017.96418  last_update 2\n",
      "train: iter 21  trainloss -1137.44589  validloss -1049.31705±0.00000  bestvalidloss -1049.31705  last_update 0\n",
      "train: iter 22  trainloss -1121.86138  validloss -1086.66842±0.00000  bestvalidloss -1086.66842  last_update 0\n",
      "train: iter 23  trainloss -1102.02231  validloss -976.88663±0.00000  bestvalidloss -1086.66842  last_update 1\n",
      "train: iter 24  trainloss -1173.94874  validloss -1125.79280±0.00000  bestvalidloss -1125.79280  last_update 0\n",
      "train: iter 25  trainloss -1200.77473  validloss -1112.00682±0.00000  bestvalidloss -1125.79280  last_update 1\n",
      "train: iter 26  trainloss -1167.68838  validloss -1077.08416±0.00000  bestvalidloss -1125.79280  last_update 2\n",
      "train: iter 27  trainloss -1256.62510  validloss -1162.50425±0.00000  bestvalidloss -1162.50425  last_update 0\n",
      "train: iter 28  trainloss -1276.32340  validloss -1251.69319±0.00000  bestvalidloss -1251.69319  last_update 0\n",
      "train: iter 29  trainloss -1257.72922  validloss -1217.68750±0.00000  bestvalidloss -1251.69319  last_update 1\n",
      "train: iter 30  trainloss -1261.63890  validloss -1155.00994±0.00000  bestvalidloss -1251.69319  last_update 2\n",
      "train: iter 31  trainloss -1219.93979  validloss -951.14059±0.00000  bestvalidloss -1251.69319  last_update 3\n",
      "train: iter 32  trainloss -968.48719  validloss -1173.90608±0.00000  bestvalidloss -1251.69319  last_update 4\n",
      "train: iter 33  trainloss -1138.63970  validloss -696.09890±0.00000  bestvalidloss -1251.69319  last_update 5\n",
      "train: iter 34  trainloss -1390.67081  validloss -1236.46400±0.00000  bestvalidloss -1251.69319  last_update 6\n",
      "train: iter 35  trainloss -1368.35533  validloss -1299.08958±0.00000  bestvalidloss -1299.08958  last_update 0\n",
      "train: iter 36  trainloss -1402.09432  validloss -1307.63837±0.00000  bestvalidloss -1307.63837  last_update 0\n",
      "train: iter 37  trainloss -1157.89226  validloss -1328.35089±0.00000  bestvalidloss -1328.35089  last_update 0\n",
      "train: iter 38  trainloss -1374.78939  validloss -1028.39061±0.00000  bestvalidloss -1328.35089  last_update 1\n",
      "train: iter 39  trainloss -1431.42549  validloss -1369.38504±0.00000  bestvalidloss -1369.38504  last_update 0\n",
      "train: iter 40  trainloss -1335.80057  validloss -1257.92816±0.00000  bestvalidloss -1369.38504  last_update 1\n",
      "train: iter 41  trainloss -1416.93265  validloss -1251.00401±0.00000  bestvalidloss -1369.38504  last_update 2\n",
      "train: iter 42  trainloss -1463.47592  validloss -1342.97278±0.00000  bestvalidloss -1369.38504  last_update 3\n",
      "train: iter 43  trainloss -1407.40518  validloss -1405.29478±0.00000  bestvalidloss -1405.29478  last_update 0\n",
      "train: iter 44  trainloss -1439.44873  validloss -1242.48489±0.00000  bestvalidloss -1405.29478  last_update 1\n",
      "train: iter 45  trainloss -1487.10783  validloss -1394.21149±0.00000  bestvalidloss -1405.29478  last_update 2\n",
      "train: iter 46  trainloss -1463.70856  validloss -1399.57124±0.00000  bestvalidloss -1405.29478  last_update 3\n",
      "train: iter 47  trainloss -1398.22617  validloss -1307.60249±0.00000  bestvalidloss -1405.29478  last_update 4\n",
      "train: iter 48  trainloss -1509.02106  validloss -1353.64691±0.00000  bestvalidloss -1405.29478  last_update 5\n",
      "train: iter 49  trainloss -1510.64685  validloss -1412.23217±0.00000  bestvalidloss -1412.23217  last_update 0\n",
      "train: iter 50  trainloss -639.01565  validloss -1446.09503±0.00000  bestvalidloss -1446.09503  last_update 0\n",
      "train: iter 51  trainloss -1373.53809  validloss -1033.72951±0.00000  bestvalidloss -1446.09503  last_update 1\n",
      "train: iter 52  trainloss -1468.93776  validloss -1386.56217±0.00000  bestvalidloss -1446.09503  last_update 2\n",
      "train: iter 53  trainloss -1530.86383  validloss -1425.53705±0.00000  bestvalidloss -1446.09503  last_update 3\n",
      "train: iter 54  trainloss -1354.34378  validloss -1431.74897±0.00000  bestvalidloss -1446.09503  last_update 4\n",
      "train: iter 55  trainloss -1477.90967  validloss -1311.79961±0.00000  bestvalidloss -1446.09503  last_update 5\n",
      "train: iter 56  trainloss -1181.65113  validloss -1437.88713±0.00000  bestvalidloss -1446.09503  last_update 6\n",
      "train: iter 57  trainloss -1073.17044  validloss -364.25738±0.00000  bestvalidloss -1446.09503  last_update 7\n",
      "train: iter 58  trainloss -1492.56932  validloss -1328.42787±0.00000  bestvalidloss -1446.09503  last_update 8\n",
      "train: iter 59  trainloss -1399.14862  validloss -1395.80223±0.00000  bestvalidloss -1446.09503  last_update 9\n",
      "train: iter 60  trainloss -1480.17403  validloss -1394.73753±0.00000  bestvalidloss -1446.09503  last_update 10\n",
      "train: iter 61  trainloss -1515.62865  validloss -1403.07530±0.00000  bestvalidloss -1446.09503  last_update 11\n",
      "train: iter 62  trainloss -1550.33582  validloss -1472.32991±0.00000  bestvalidloss -1472.32991  last_update 0\n",
      "train: iter 63  trainloss -1516.82767  validloss -1320.97521±0.00000  bestvalidloss -1472.32991  last_update 1\n",
      "train: iter 64  trainloss -1269.39872  validloss -1345.35360±0.00000  bestvalidloss -1472.32991  last_update 2\n",
      "train: iter 65  trainloss -1527.36008  validloss -1450.37758±0.00000  bestvalidloss -1472.32991  last_update 3\n",
      "train: iter 66  trainloss -1445.10990  validloss -1476.70634±0.00000  bestvalidloss -1476.70634  last_update 0\n",
      "train: iter 67  trainloss -1493.90147  validloss -1373.48773±0.00000  bestvalidloss -1476.70634  last_update 1\n",
      "train: iter 68  trainloss -1563.94314  validloss -1452.86568±0.00000  bestvalidloss -1476.70634  last_update 2\n",
      "train: iter 69  trainloss -1530.20994  validloss -1434.59344±0.00000  bestvalidloss -1476.70634  last_update 3\n",
      "train: iter 70  trainloss -1589.78151  validloss -1506.62501±0.00000  bestvalidloss -1506.62501  last_update 0\n",
      "train: iter 71  trainloss -1592.34712  validloss -1504.15905±0.00000  bestvalidloss -1506.62501  last_update 1\n",
      "train: iter 72  trainloss -1612.11731  validloss -1506.75623±0.00000  bestvalidloss -1506.75623  last_update 0\n",
      "train: iter 73  trainloss -1293.70437  validloss -1517.96631±0.00000  bestvalidloss -1517.96631  last_update 0\n",
      "train: iter 74  trainloss -1518.60437  validloss -1291.52958±0.00000  bestvalidloss -1517.96631  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1074.55102  validloss -1179.54587±0.00000  bestvalidloss -1517.96631  last_update 2\n",
      "train: iter 76  trainloss -1395.12751  validloss -662.31178±0.00000  bestvalidloss -1517.96631  last_update 3\n",
      "train: iter 77  trainloss -1588.13798  validloss -1473.62390±0.00000  bestvalidloss -1517.96631  last_update 4\n",
      "train: iter 78  trainloss -1555.06700  validloss -1510.43419±0.00000  bestvalidloss -1517.96631  last_update 5\n",
      "train: iter 79  trainloss -1568.66406  validloss -1340.57903±0.00000  bestvalidloss -1517.96631  last_update 6\n",
      "train: iter 80  trainloss -1396.70131  validloss -1206.38925±0.00000  bestvalidloss -1517.96631  last_update 7\n",
      "train: iter 81  trainloss -1619.31732  validloss -1449.26719±0.00000  bestvalidloss -1517.96631  last_update 8\n",
      "train: iter 82  trainloss -1641.35730  validloss -1546.02252±0.00000  bestvalidloss -1546.02252  last_update 0\n",
      "train: iter 83  trainloss -1424.84414  validloss -1518.98477±0.00000  bestvalidloss -1546.02252  last_update 1\n",
      "train: iter 84  trainloss -1602.48331  validloss -1452.90347±0.00000  bestvalidloss -1546.02252  last_update 2\n",
      "train: iter 85  trainloss -1643.84408  validloss -1555.13317±0.00000  bestvalidloss -1555.13317  last_update 0\n",
      "train: iter 86  trainloss -1622.82197  validloss -1555.06688±0.00000  bestvalidloss -1555.13317  last_update 1\n",
      "train: iter 87  trainloss -1557.00686  validloss -1504.17922±0.00000  bestvalidloss -1555.13317  last_update 2\n",
      "train: iter 88  trainloss -1671.09351  validloss -1608.39014±0.00000  bestvalidloss -1608.39014  last_update 0\n",
      "train: iter 89  trainloss -1419.95180  validloss -1611.80153±0.00000  bestvalidloss -1611.80153  last_update 0\n",
      "train: iter 90  trainloss -1630.51089  validloss -1442.76920±0.00000  bestvalidloss -1611.80153  last_update 1\n",
      "train: iter 91  trainloss -1694.14714  validloss -1603.22544±0.00000  bestvalidloss -1611.80153  last_update 2\n",
      "train: iter 92  trainloss -1211.00732  validloss -1538.87762±0.00000  bestvalidloss -1611.80153  last_update 3\n",
      "train: iter 93  trainloss -1712.29888  validloss -1628.08210±0.00000  bestvalidloss -1628.08210  last_update 0\n",
      "train: iter 94  trainloss -1717.70512  validloss -1668.16000±0.00000  bestvalidloss -1668.16000  last_update 0\n",
      "train: iter 95  trainloss -1683.91218  validloss -1670.55920±0.00000  bestvalidloss -1670.55920  last_update 0\n",
      "train: iter 96  trainloss -1721.08810  validloss -1693.13373±0.00000  bestvalidloss -1693.13373  last_update 0\n",
      "train: iter 97  trainloss -1722.94473  validloss -1678.26729±0.00000  bestvalidloss -1693.13373  last_update 1\n",
      "train: iter 98  trainloss -1756.15568  validloss -1670.07174±0.00000  bestvalidloss -1693.13373  last_update 2\n",
      "train: iter 99  trainloss -1690.45044  validloss -1701.29533±0.00000  bestvalidloss -1701.29533  last_update 0\n",
      "train: iter 100  trainloss -1728.17640  validloss -1603.89680±0.00000  bestvalidloss -1701.29533  last_update 1\n",
      "train: iter 101  trainloss -1793.74267  validloss -1683.58145±0.00000  bestvalidloss -1701.29533  last_update 2\n",
      "train: iter 102  trainloss -1554.16916  validloss -1668.49088±0.00000  bestvalidloss -1701.29533  last_update 3\n",
      "train: iter 103  trainloss -1732.11858  validloss -1692.15698±0.00000  bestvalidloss -1701.29533  last_update 4\n",
      "train: iter 104  trainloss -1789.44160  validloss -1707.99152±0.00000  bestvalidloss -1707.99152  last_update 0\n",
      "train: iter 105  trainloss -1790.80560  validloss -1706.41633±0.00000  bestvalidloss -1707.99152  last_update 1\n",
      "train: iter 106  trainloss -1575.80846  validloss -1730.51568±0.00000  bestvalidloss -1730.51568  last_update 0\n",
      "train: iter 107  trainloss -1758.92435  validloss -1649.42016±0.00000  bestvalidloss -1730.51568  last_update 1\n",
      "train: iter 108  trainloss -1721.49456  validloss -1736.00292±0.00000  bestvalidloss -1736.00292  last_update 0\n",
      "train: iter 109  trainloss -1804.91062  validloss -1609.86145±0.00000  bestvalidloss -1736.00292  last_update 1\n",
      "train: iter 110  trainloss -1832.08272  validloss -1758.04594±0.00000  bestvalidloss -1758.04594  last_update 0\n",
      "train: iter 111  trainloss -1664.49988  validloss -1650.25155±0.00000  bestvalidloss -1758.04594  last_update 1\n",
      "train: iter 112  trainloss -1833.63438  validloss -1753.92999±0.00000  bestvalidloss -1758.04594  last_update 2\n",
      "train: iter 113  trainloss -1682.79504  validloss -1681.24668±0.00000  bestvalidloss -1758.04594  last_update 3\n",
      "train: iter 114  trainloss -1693.58395  validloss -1711.63619±0.00000  bestvalidloss -1758.04594  last_update 4\n",
      "train: iter 115  trainloss -1720.61849  validloss -1518.40681±0.00000  bestvalidloss -1758.04594  last_update 5\n",
      "train: iter 116  trainloss -1813.14994  validloss -1761.32604±0.00000  bestvalidloss -1761.32604  last_update 0\n",
      "train: iter 117  trainloss -1808.15053  validloss -1736.52382±0.00000  bestvalidloss -1761.32604  last_update 1\n",
      "train: iter 118  trainloss -1830.75954  validloss -1777.31165±0.00000  bestvalidloss -1777.31165  last_update 0\n",
      "train: iter 119  trainloss -1827.97112  validloss -1710.04549±0.00000  bestvalidloss -1777.31165  last_update 1\n",
      "train: iter 120  trainloss -1621.32672  validloss -1755.50415±0.00000  bestvalidloss -1777.31165  last_update 2\n",
      "train: iter 121  trainloss -1654.11809  validloss -1522.29015±0.00000  bestvalidloss -1777.31165  last_update 3\n",
      "train: iter 122  trainloss -1838.95058  validloss -1765.50757±0.00000  bestvalidloss -1777.31165  last_update 4\n",
      "train: iter 123  trainloss -1794.07933  validloss -1775.90253±0.00000  bestvalidloss -1777.31165  last_update 5\n",
      "train: iter 124  trainloss -1791.18957  validloss -1602.40235±0.00000  bestvalidloss -1777.31165  last_update 6\n",
      "train: iter 125  trainloss -1851.25286  validloss -1765.58746±0.00000  bestvalidloss -1777.31165  last_update 7\n",
      "train: iter 126  trainloss -1819.25704  validloss -1720.95764±0.00000  bestvalidloss -1777.31165  last_update 8\n",
      "train: iter 127  trainloss -1861.49852  validloss -1808.29977±0.00000  bestvalidloss -1808.29977  last_update 0\n",
      "train: iter 128  trainloss -1797.98440  validloss -1799.88333±0.00000  bestvalidloss -1808.29977  last_update 1\n",
      "train: iter 129  trainloss -1769.24824  validloss -1720.44029±0.00000  bestvalidloss -1808.29977  last_update 2\n",
      "train: iter 130  trainloss -1838.04187  validloss -1732.88747±0.00000  bestvalidloss -1808.29977  last_update 3\n",
      "train: iter 131  trainloss -1697.66469  validloss -1800.09346±0.00000  bestvalidloss -1808.29977  last_update 4\n",
      "train: iter 132  trainloss -1819.49699  validloss -1684.76569±0.00000  bestvalidloss -1808.29977  last_update 5\n",
      "train: iter 133  trainloss -1868.52266  validloss -1820.87668±0.00000  bestvalidloss -1820.87668  last_update 0\n",
      "train: iter 134  trainloss -977.05553  validloss -1657.36365±0.00000  bestvalidloss -1820.87668  last_update 1\n",
      "train: iter 135  trainloss -1715.60684  validloss -1606.77782±0.00000  bestvalidloss -1820.87668  last_update 2\n",
      "train: iter 136  trainloss -1813.38925  validloss -1649.55637±0.00000  bestvalidloss -1820.87668  last_update 3\n",
      "train: iter 137  trainloss -1878.36216  validloss -1807.30704±0.00000  bestvalidloss -1820.87668  last_update 4\n",
      "train: iter 138  trainloss -1850.58826  validloss -1837.07027±0.00000  bestvalidloss -1837.07027  last_update 0\n",
      "train: iter 139  trainloss -1685.96773  validloss -1742.19105±0.00000  bestvalidloss -1837.07027  last_update 1\n",
      "train: iter 140  trainloss -1874.24561  validloss -1770.45999±0.00000  bestvalidloss -1837.07027  last_update 2\n",
      "train: iter 141  trainloss -1876.42652  validloss -1790.94440±0.00000  bestvalidloss -1837.07027  last_update 3\n",
      "train: iter 142  trainloss -1897.87370  validloss -1824.63134±0.00000  bestvalidloss -1837.07027  last_update 4\n",
      "train: iter 143  trainloss -1749.76420  validloss -1765.74844±0.00000  bestvalidloss -1837.07027  last_update 5\n",
      "train: iter 144  trainloss -1890.31467  validloss -1713.23470±0.00000  bestvalidloss -1837.07027  last_update 6\n",
      "train: iter 145  trainloss -1899.07894  validloss -1835.13687±0.00000  bestvalidloss -1837.07027  last_update 7\n",
      "train: iter 146  trainloss -1885.52798  validloss -1842.71380±0.00000  bestvalidloss -1842.71380  last_update 0\n",
      "train: iter 147  trainloss -1801.59248  validloss -1839.68768±0.00000  bestvalidloss -1842.71380  last_update 1\n",
      "train: iter 148  trainloss -1817.70818  validloss -1695.95580±0.00000  bestvalidloss -1842.71380  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -1767.05849  validloss -1237.74593±0.00000  bestvalidloss -1842.71380  last_update 3\n",
      "train: iter 150  trainloss -1843.70796  validloss -1842.07975±0.00000  bestvalidloss -1842.71380  last_update 4\n",
      "train: iter 151  trainloss -1879.36418  validloss -1757.97905±0.00000  bestvalidloss -1842.71380  last_update 5\n",
      "train: iter 152  trainloss -1870.20448  validloss -1807.68434±0.00000  bestvalidloss -1842.71380  last_update 6\n",
      "train: iter 153  trainloss -1877.83250  validloss -1687.52953±0.00000  bestvalidloss -1842.71380  last_update 7\n",
      "train: iter 154  trainloss -1695.84229  validloss -1841.44954±0.00000  bestvalidloss -1842.71380  last_update 8\n",
      "train: iter 155  trainloss -1860.58980  validloss -1719.01653±0.00000  bestvalidloss -1842.71380  last_update 9\n",
      "train: iter 156  trainloss -1901.33299  validloss -1805.39404±0.00000  bestvalidloss -1842.71380  last_update 10\n",
      "train: iter 157  trainloss -1836.23417  validloss -1845.49476±0.00000  bestvalidloss -1845.49476  last_update 0\n",
      "train: iter 158  trainloss -1822.96891  validloss -1587.21504±0.00000  bestvalidloss -1845.49476  last_update 1\n",
      "train: iter 159  trainloss -1821.42284  validloss -1751.63524±0.00000  bestvalidloss -1845.49476  last_update 2\n",
      "train: iter 160  trainloss -1923.76630  validloss -1867.53936±0.00000  bestvalidloss -1867.53936  last_update 0\n",
      "train: iter 161  trainloss -1909.91617  validloss -1864.80521±0.00000  bestvalidloss -1867.53936  last_update 1\n",
      "train: iter 162  trainloss -1921.59274  validloss -1817.19958±0.00000  bestvalidloss -1867.53936  last_update 2\n",
      "train: iter 163  trainloss -1000.73339  validloss -1864.64482±0.00000  bestvalidloss -1867.53936  last_update 3\n",
      "train: iter 164  trainloss -1583.05620  validloss -1116.06485±0.00000  bestvalidloss -1867.53936  last_update 4\n",
      "train: iter 165  trainloss -1882.11751  validloss -1793.61653±0.00000  bestvalidloss -1867.53936  last_update 5\n",
      "train: iter 166  trainloss -1912.98346  validloss -1863.44854±0.00000  bestvalidloss -1867.53936  last_update 6\n",
      "train: iter 167  trainloss -1906.10557  validloss -1753.70956±0.00000  bestvalidloss -1867.53936  last_update 7\n",
      "train: iter 168  trainloss -1927.57757  validloss -1776.31960±0.00000  bestvalidloss -1867.53936  last_update 8\n",
      "train: iter 169  trainloss -1898.89731  validloss -1869.18792±0.00000  bestvalidloss -1869.18792  last_update 0\n",
      "train: iter 170  trainloss -1795.03682  validloss -1797.92039±0.00000  bestvalidloss -1869.18792  last_update 1\n",
      "train: iter 171  trainloss -1822.85251  validloss -1574.04388±0.00000  bestvalidloss -1869.18792  last_update 2\n",
      "train: iter 172  trainloss -1924.39096  validloss -1884.58821±0.00000  bestvalidloss -1884.58821  last_update 0\n",
      "train: iter 173  trainloss -1913.97320  validloss -1859.74188±0.00000  bestvalidloss -1884.58821  last_update 1\n",
      "train: iter 174  trainloss -1861.80015  validloss -1833.01290±0.00000  bestvalidloss -1884.58821  last_update 2\n",
      "train: iter 175  trainloss -1925.34605  validloss -1876.70615±0.00000  bestvalidloss -1884.58821  last_update 3\n",
      "train: iter 176  trainloss -1926.55709  validloss -1853.78839±0.00000  bestvalidloss -1884.58821  last_update 4\n",
      "train: iter 177  trainloss -1840.29246  validloss -1810.46720±0.00000  bestvalidloss -1884.58821  last_update 5\n",
      "train: iter 178  trainloss -1926.64449  validloss -1830.81929±0.00000  bestvalidloss -1884.58821  last_update 6\n",
      "train: iter 179  trainloss -1779.18348  validloss -1841.93624±0.00000  bestvalidloss -1884.58821  last_update 7\n",
      "train: iter 180  trainloss -1856.13452  validloss -1845.40039±0.00000  bestvalidloss -1884.58821  last_update 8\n",
      "train: iter 181  trainloss -1918.01608  validloss -1639.50175±0.00000  bestvalidloss -1884.58821  last_update 9\n",
      "train: iter 182  trainloss -1894.28643  validloss -1885.29185±0.00000  bestvalidloss -1885.29185  last_update 0\n",
      "train: iter 183  trainloss -1909.85937  validloss -1687.37562±0.00000  bestvalidloss -1885.29185  last_update 1\n",
      "train: iter 184  trainloss -1958.55726  validloss -1888.73274±0.00000  bestvalidloss -1888.73274  last_update 0\n",
      "train: iter 185  trainloss -1956.90929  validloss -1889.02935±0.00000  bestvalidloss -1889.02935  last_update 0\n",
      "train: iter 186  trainloss -1770.65685  validloss -1866.44156±0.00000  bestvalidloss -1889.02935  last_update 1\n",
      "train: iter 187  trainloss -1835.31197  validloss -1729.54667±0.00000  bestvalidloss -1889.02935  last_update 2\n",
      "train: iter 188  trainloss -1948.88717  validloss -1872.53949±0.00000  bestvalidloss -1889.02935  last_update 3\n",
      "train: iter 189  trainloss -1914.70304  validloss -1883.03704±0.00000  bestvalidloss -1889.02935  last_update 4\n",
      "train: iter 190  trainloss -1886.03584  validloss -1899.74039±0.00000  bestvalidloss -1899.74039  last_update 0\n",
      "train: iter 191  trainloss -1860.80409  validloss -1562.44262±0.00000  bestvalidloss -1899.74039  last_update 1\n",
      "train: iter 192  trainloss -1941.06615  validloss -1864.95298±0.00000  bestvalidloss -1899.74039  last_update 2\n",
      "train: iter 193  trainloss -1809.13431  validloss -1909.55809±0.00000  bestvalidloss -1909.55809  last_update 0\n",
      "train: iter 194  trainloss -1867.64858  validloss -1636.66917±0.00000  bestvalidloss -1909.55809  last_update 1\n",
      "train: iter 195  trainloss -1810.50089  validloss -1835.66119±0.00000  bestvalidloss -1909.55809  last_update 2\n",
      "train: iter 196  trainloss -1937.37391  validloss -1896.87239±0.00000  bestvalidloss -1909.55809  last_update 3\n",
      "train: iter 197  trainloss -1963.45144  validloss -1917.15213±0.00000  bestvalidloss -1917.15213  last_update 0\n",
      "train: iter 198  trainloss -1942.65747  validloss -1897.99987±0.00000  bestvalidloss -1917.15213  last_update 1\n",
      "train: iter 199  trainloss -1943.01094  validloss -1908.78826±0.00000  bestvalidloss -1917.15213  last_update 2\n",
      "train: iter 200  trainloss -1869.23680  validloss -1785.06660±0.00000  bestvalidloss -1917.15213  last_update 3\n",
      "train: iter 201  trainloss -1932.36154  validloss -1895.45747±0.00000  bestvalidloss -1917.15213  last_update 4\n",
      "train: iter 202  trainloss -1855.23431  validloss -1878.12881±0.00000  bestvalidloss -1917.15213  last_update 5\n",
      "train: iter 203  trainloss -1937.66703  validloss -1880.08584±0.00000  bestvalidloss -1917.15213  last_update 6\n",
      "train: iter 204  trainloss -1822.12420  validloss -1926.26025±0.00000  bestvalidloss -1926.26025  last_update 0\n",
      "train: iter 205  trainloss -1934.43985  validloss -1861.74689±0.00000  bestvalidloss -1926.26025  last_update 1\n",
      "train: iter 206  trainloss -1847.83381  validloss -1811.20345±0.00000  bestvalidloss -1926.26025  last_update 2\n",
      "train: iter 207  trainloss -1971.23288  validloss -1913.76384±0.00000  bestvalidloss -1926.26025  last_update 3\n",
      "train: iter 208  trainloss -1968.10991  validloss -1892.60907±0.00000  bestvalidloss -1926.26025  last_update 4\n",
      "train: iter 209  trainloss -1921.45700  validloss -1817.63772±0.00000  bestvalidloss -1926.26025  last_update 5\n",
      "train: iter 210  trainloss -1902.66616  validloss -1892.96395±0.00000  bestvalidloss -1926.26025  last_update 6\n",
      "train: iter 211  trainloss -1825.37793  validloss -1854.34203±0.00000  bestvalidloss -1926.26025  last_update 7\n",
      "train: iter 212  trainloss -1918.53385  validloss -1801.31177±0.00000  bestvalidloss -1926.26025  last_update 8\n",
      "train: iter 213  trainloss -1930.92587  validloss -1885.72600±0.00000  bestvalidloss -1926.26025  last_update 9\n",
      "train: iter 214  trainloss -1990.66481  validloss -1875.30708±0.00000  bestvalidloss -1926.26025  last_update 10\n",
      "train: iter 215  trainloss -1908.43761  validloss -1850.54187±0.00000  bestvalidloss -1926.26025  last_update 11\n",
      "train: iter 216  trainloss -1714.24411  validloss -1840.10217±0.00000  bestvalidloss -1926.26025  last_update 12\n",
      "train: iter 217  trainloss -1626.36694  validloss -1680.54358±0.00000  bestvalidloss -1926.26025  last_update 13\n",
      "train: iter 218  trainloss -1940.62613  validloss -1869.25334±0.00000  bestvalidloss -1926.26025  last_update 14\n",
      "train: iter 219  trainloss -1956.94113  validloss -1942.07365±0.00000  bestvalidloss -1942.07365  last_update 0\n",
      "train: iter 220  trainloss -1889.94194  validloss -1936.95136±0.00000  bestvalidloss -1942.07365  last_update 1\n",
      "train: iter 221  trainloss -1917.70804  validloss -1851.77134±0.00000  bestvalidloss -1942.07365  last_update 2\n",
      "train: iter 222  trainloss -1970.06046  validloss -1931.70621±0.00000  bestvalidloss -1942.07365  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1974.29761  validloss -1934.45902±0.00000  bestvalidloss -1942.07365  last_update 4\n",
      "train: iter 224  trainloss -1933.50374  validloss -1890.94378±0.00000  bestvalidloss -1942.07365  last_update 5\n",
      "train: iter 225  trainloss -1563.00710  validloss -1627.93423±0.00000  bestvalidloss -1942.07365  last_update 6\n",
      "train: iter 226  trainloss -1894.47086  validloss -1845.33864±0.00000  bestvalidloss -1942.07365  last_update 7\n",
      "train: iter 227  trainloss -1969.64520  validloss -1902.62108±0.00000  bestvalidloss -1942.07365  last_update 8\n",
      "train: iter 228  trainloss -1961.16275  validloss -1855.43396±0.00000  bestvalidloss -1942.07365  last_update 9\n",
      "train: iter 229  trainloss -1878.64805  validloss -1896.52968±0.00000  bestvalidloss -1942.07365  last_update 10\n",
      "train: iter 230  trainloss -1961.30001  validloss -1823.60780±0.00000  bestvalidloss -1942.07365  last_update 11\n",
      "train: iter 231  trainloss -1942.50846  validloss -1916.87770±0.00000  bestvalidloss -1942.07365  last_update 12\n",
      "train: iter 232  trainloss -1868.60689  validloss -1882.99622±0.00000  bestvalidloss -1942.07365  last_update 13\n",
      "train: iter 233  trainloss -1971.60619  validloss -1896.20469±0.00000  bestvalidloss -1942.07365  last_update 14\n",
      "train: iter 234  trainloss -1903.37965  validloss -1905.90554±0.00000  bestvalidloss -1942.07365  last_update 15\n",
      "train: iter 235  trainloss -1902.21090  validloss -1798.96179±0.00000  bestvalidloss -1942.07365  last_update 16\n",
      "train: iter 236  trainloss -1991.93721  validloss -1893.26970±0.00000  bestvalidloss -1942.07365  last_update 17\n",
      "train: iter 237  trainloss -1955.19983  validloss -1947.12524±0.00000  bestvalidloss -1947.12524  last_update 0\n",
      "train: iter 238  trainloss -1941.07551  validloss -1885.14840±0.00000  bestvalidloss -1947.12524  last_update 1\n",
      "train: iter 239  trainloss -1948.72656  validloss -1798.01633±0.00000  bestvalidloss -1947.12524  last_update 2\n",
      "train: iter 240  trainloss -1986.39913  validloss -1936.86246±0.00000  bestvalidloss -1947.12524  last_update 3\n",
      "train: iter 241  trainloss -1640.57249  validloss -1900.80063±0.00000  bestvalidloss -1947.12524  last_update 4\n",
      "train: iter 242  trainloss -1919.56031  validloss -1793.96066±0.00000  bestvalidloss -1947.12524  last_update 5\n",
      "train: iter 243  trainloss -1893.95897  validloss -1951.99495±0.00000  bestvalidloss -1951.99495  last_update 0\n",
      "train: iter 244  trainloss -1989.26733  validloss -1929.47339±0.00000  bestvalidloss -1951.99495  last_update 1\n",
      "train: iter 245  trainloss -2000.91011  validloss -1937.95613±0.00000  bestvalidloss -1951.99495  last_update 2\n",
      "train: iter 246  trainloss -1977.96097  validloss -1918.67340±0.00000  bestvalidloss -1951.99495  last_update 3\n",
      "train: iter 247  trainloss -1970.79444  validloss -1918.86271±0.00000  bestvalidloss -1951.99495  last_update 4\n",
      "train: iter 248  trainloss -1957.88816  validloss -1887.43750±0.00000  bestvalidloss -1951.99495  last_update 5\n",
      "train: iter 249  trainloss -2000.24064  validloss -1932.44081±0.00000  bestvalidloss -1951.99495  last_update 6\n",
      "train: iter 250  trainloss -1774.25999  validloss -1976.25111±0.00000  bestvalidloss -1976.25111  last_update 0\n",
      "train: iter 251  trainloss -1813.30523  validloss -1361.55013±0.00000  bestvalidloss -1976.25111  last_update 1\n",
      "train: iter 252  trainloss -1935.28256  validloss -1951.61546±0.00000  bestvalidloss -1976.25111  last_update 2\n",
      "train: iter 253  trainloss -1972.32680  validloss -1971.77006±0.00000  bestvalidloss -1976.25111  last_update 3\n",
      "train: iter 254  trainloss -2014.53271  validloss -1992.77799±0.00000  bestvalidloss -1992.77799  last_update 0\n",
      "train: iter 255  trainloss -1951.53227  validloss -1906.90084±0.00000  bestvalidloss -1992.77799  last_update 1\n",
      "train: iter 256  trainloss -1954.08391  validloss -1862.08245±0.00000  bestvalidloss -1992.77799  last_update 2\n",
      "train: iter 257  trainloss -2021.18818  validloss -1939.80731±0.00000  bestvalidloss -1992.77799  last_update 3\n",
      "train: iter 258  trainloss -1978.00588  validloss -1866.58450±0.00000  bestvalidloss -1992.77799  last_update 4\n",
      "train: iter 259  trainloss -1990.83846  validloss -1928.32339±0.00000  bestvalidloss -1992.77799  last_update 5\n",
      "train: iter 260  trainloss -1307.13889  validloss -1837.94761±0.00000  bestvalidloss -1992.77799  last_update 6\n",
      "train: iter 261  trainloss -1504.67166  validloss -874.33099±0.00000  bestvalidloss -1992.77799  last_update 7\n",
      "train: iter 262  trainloss -1914.81062  validloss -1816.17157±0.00000  bestvalidloss -1992.77799  last_update 8\n",
      "train: iter 263  trainloss -1997.79660  validloss -1949.44341±0.00000  bestvalidloss -1992.77799  last_update 9\n",
      "train: iter 264  trainloss -2005.78127  validloss -1976.47903±0.00000  bestvalidloss -1992.77799  last_update 10\n",
      "train: iter 265  trainloss -2008.02043  validloss -1975.14846±0.00000  bestvalidloss -1992.77799  last_update 11\n",
      "train: iter 266  trainloss -1993.96184  validloss -1947.89364±0.00000  bestvalidloss -1992.77799  last_update 12\n",
      "train: iter 267  trainloss -1960.43614  validloss -1961.49476±0.00000  bestvalidloss -1992.77799  last_update 13\n",
      "train: iter 268  trainloss -1994.67590  validloss -1943.19587±0.00000  bestvalidloss -1992.77799  last_update 14\n",
      "train: iter 269  trainloss -1991.82007  validloss -1964.86218±0.00000  bestvalidloss -1992.77799  last_update 15\n",
      "train: iter 270  trainloss -1998.48112  validloss -1939.26776±0.00000  bestvalidloss -1992.77799  last_update 16\n",
      "train: iter 271  trainloss -1975.29168  validloss -1915.55892±0.00000  bestvalidloss -1992.77799  last_update 17\n",
      "train: iter 272  trainloss -1785.05923  validloss -1961.44487±0.00000  bestvalidloss -1992.77799  last_update 18\n",
      "train: iter 273  trainloss -1999.43614  validloss -1960.35127±0.00000  bestvalidloss -1992.77799  last_update 19\n",
      "train: iter 274  trainloss -1967.44303  validloss -1907.77762±0.00000  bestvalidloss -1992.77799  last_update 20\n",
      "train: iter 275  trainloss -1978.68058  validloss -1941.16678±0.00000  bestvalidloss -1992.77799  last_update 21\n",
      "train: iter 276  trainloss -1991.62451  validloss -1924.87996±0.00000  bestvalidloss -1992.77799  last_update 22\n",
      "train: iter 277  trainloss -1930.59359  validloss -1933.50511±0.00000  bestvalidloss -1992.77799  last_update 23\n",
      "train: iter 278  trainloss -1997.30271  validloss -1983.85834±0.00000  bestvalidloss -1992.77799  last_update 24\n",
      "train: iter 279  trainloss -1956.12135  validloss -1939.74578±0.00000  bestvalidloss -1992.77799  last_update 25\n",
      "train: iter 280  trainloss -1916.86171  validloss -1954.49493±0.00000  bestvalidloss -1992.77799  last_update 26\n",
      "train: iter 281  trainloss -1987.71266  validloss -1957.97195±0.00000  bestvalidloss -1992.77799  last_update 27\n",
      "train: iter 282  trainloss -1971.62620  validloss -1972.35964±0.00000  bestvalidloss -1992.77799  last_update 28\n",
      "train: iter 283  trainloss -1969.27468  validloss -1921.01466±0.00000  bestvalidloss -1992.77799  last_update 29\n",
      "train: iter 284  trainloss -1965.70543  validloss -1952.90698±0.00000  bestvalidloss -1992.77799  last_update 30\n",
      "train: iter 285  trainloss -2039.39554  validloss -1997.46500±0.00000  bestvalidloss -1997.46500  last_update 0\n",
      "train: iter 286  trainloss -2002.89454  validloss -2000.04026±0.00000  bestvalidloss -2000.04026  last_update 0\n",
      "train: iter 287  trainloss -1985.06301  validloss -1888.97277±0.00000  bestvalidloss -2000.04026  last_update 1\n",
      "train: iter 288  trainloss -1900.90643  validloss -1903.97433±0.00000  bestvalidloss -2000.04026  last_update 2\n",
      "train: iter 289  trainloss -2022.91339  validloss -1938.79570±0.00000  bestvalidloss -2000.04026  last_update 3\n",
      "train: iter 290  trainloss -2012.42147  validloss -1969.38921±0.00000  bestvalidloss -2000.04026  last_update 4\n",
      "train: iter 291  trainloss -1790.28042  validloss -1882.89581±0.00000  bestvalidloss -2000.04026  last_update 5\n",
      "train: iter 292  trainloss -1979.95378  validloss -1949.53428±0.00000  bestvalidloss -2000.04026  last_update 6\n",
      "train: iter 293  trainloss -2007.42365  validloss -1964.39611±0.00000  bestvalidloss -2000.04026  last_update 7\n",
      "train: iter 294  trainloss -2032.19863  validloss -1956.94350±0.00000  bestvalidloss -2000.04026  last_update 8\n",
      "train: iter 295  trainloss -1871.57186  validloss -1910.02110±0.00000  bestvalidloss -2000.04026  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -1988.13235  validloss -1687.00446±0.00000  bestvalidloss -2000.04026  last_update 10\n",
      "train: iter 297  trainloss -1898.47579  validloss -1933.71180±0.00000  bestvalidloss -2000.04026  last_update 11\n",
      "train: iter 298  trainloss -2006.84749  validloss -1971.42971±0.00000  bestvalidloss -2000.04026  last_update 12\n",
      "train: iter 299  trainloss -2018.91498  validloss -2001.90267±0.00000  bestvalidloss -2001.90267  last_update 0\n",
      "train: iter 300  trainloss -2013.23610  validloss -1980.99917±0.00000  bestvalidloss -2001.90267  last_update 1\n",
      "train: iter 301  trainloss -2032.86090  validloss -1997.58943±0.00000  bestvalidloss -2001.90267  last_update 2\n",
      "train: iter 302  trainloss -1791.14306  validloss -1916.47551±0.00000  bestvalidloss -2001.90267  last_update 3\n",
      "train: iter 303  trainloss -1969.96968  validloss -1944.68824±0.00000  bestvalidloss -2001.90267  last_update 4\n",
      "train: iter 304  trainloss -2026.53000  validloss -1982.56834±0.00000  bestvalidloss -2001.90267  last_update 5\n",
      "train: iter 305  trainloss -2006.42303  validloss -1990.60009±0.00000  bestvalidloss -2001.90267  last_update 6\n",
      "train: iter 306  trainloss -2002.63260  validloss -2006.24374±0.00000  bestvalidloss -2006.24374  last_update 0\n",
      "train: iter 307  trainloss -1854.81651  validloss -1928.57548±0.00000  bestvalidloss -2006.24374  last_update 1\n",
      "train: iter 308  trainloss -2019.80927  validloss -1952.01296±0.00000  bestvalidloss -2006.24374  last_update 2\n",
      "train: iter 309  trainloss -2002.22110  validloss -1991.87715±0.00000  bestvalidloss -2006.24374  last_update 3\n",
      "train: iter 310  trainloss -1863.61964  validloss -1903.09076±0.00000  bestvalidloss -2006.24374  last_update 4\n",
      "train: iter 311  trainloss -1998.58060  validloss -1961.58412±0.00000  bestvalidloss -2006.24374  last_update 5\n",
      "train: iter 312  trainloss -1882.83752  validloss -1930.19053±0.00000  bestvalidloss -2006.24374  last_update 6\n",
      "train: iter 313  trainloss -2006.80878  validloss -1911.40316±0.00000  bestvalidloss -2006.24374  last_update 7\n",
      "train: iter 314  trainloss -2024.45837  validloss -2011.71436±0.00000  bestvalidloss -2011.71436  last_update 0\n",
      "train: iter 315  trainloss -2012.81660  validloss -1989.78600±0.00000  bestvalidloss -2011.71436  last_update 1\n",
      "train: iter 316  trainloss -1993.82024  validloss -1964.11096±0.00000  bestvalidloss -2011.71436  last_update 2\n",
      "train: iter 317  trainloss -2029.80102  validloss -1969.50028±0.00000  bestvalidloss -2011.71436  last_update 3\n",
      "train: iter 318  trainloss -2006.83802  validloss -1999.30692±0.00000  bestvalidloss -2011.71436  last_update 4\n",
      "train: iter 319  trainloss -1873.27655  validloss -1958.21953±0.00000  bestvalidloss -2011.71436  last_update 5\n",
      "train: iter 320  trainloss -1948.53650  validloss -1800.72221±0.00000  bestvalidloss -2011.71436  last_update 6\n",
      "train: iter 321  trainloss -2027.97090  validloss -1940.96972±0.00000  bestvalidloss -2011.71436  last_update 7\n",
      "train: iter 322  trainloss -2033.94243  validloss -2004.55027±0.00000  bestvalidloss -2011.71436  last_update 8\n",
      "train: iter 323  trainloss -2033.39211  validloss -2000.32458±0.00000  bestvalidloss -2011.71436  last_update 9\n",
      "train: iter 324  trainloss -1852.84635  validloss -1940.98258±0.00000  bestvalidloss -2011.71436  last_update 10\n",
      "train: iter 325  trainloss -1773.45054  validloss -1931.15341±0.00000  bestvalidloss -2011.71436  last_update 11\n",
      "train: iter 326  trainloss -2022.36773  validloss -2006.54647±0.00000  bestvalidloss -2011.71436  last_update 12\n",
      "train: iter 327  trainloss -2034.82799  validloss -2015.85790±0.00000  bestvalidloss -2015.85790  last_update 0\n",
      "train: iter 328  trainloss -2007.09067  validloss -1963.93140±0.00000  bestvalidloss -2015.85790  last_update 1\n",
      "train: iter 329  trainloss -2006.03137  validloss -1965.02600±0.00000  bestvalidloss -2015.85790  last_update 2\n",
      "train: iter 330  trainloss -1969.95437  validloss -1949.32917±0.00000  bestvalidloss -2015.85790  last_update 3\n",
      "train: iter 331  trainloss -2005.33575  validloss -1710.58420±0.00000  bestvalidloss -2015.85790  last_update 4\n",
      "train: iter 332  trainloss -1960.78901  validloss -1947.26221±0.00000  bestvalidloss -2015.85790  last_update 5\n",
      "train: iter 333  trainloss -1907.25198  validloss -1942.98577±0.00000  bestvalidloss -2015.85790  last_update 6\n",
      "train: iter 334  trainloss -2010.50108  validloss -1881.45238±0.00000  bestvalidloss -2015.85790  last_update 7\n",
      "train: iter 335  trainloss -2028.00047  validloss -2009.74148±0.00000  bestvalidloss -2015.85790  last_update 8\n",
      "train: iter 336  trainloss -2012.41375  validloss -1922.45269±0.00000  bestvalidloss -2015.85790  last_update 9\n",
      "train: iter 337  trainloss -1918.60567  validloss -1979.91396±0.00000  bestvalidloss -2015.85790  last_update 10\n",
      "train: iter 338  trainloss -1847.97223  validloss -1259.97779±0.00000  bestvalidloss -2015.85790  last_update 11\n",
      "train: iter 339  trainloss -2018.82896  validloss -1997.26788±0.00000  bestvalidloss -2015.85790  last_update 12\n",
      "train: iter 340  trainloss -1970.89221  validloss -1965.29988±0.00000  bestvalidloss -2015.85790  last_update 13\n",
      "train: iter 341  trainloss -2035.89070  validloss -1937.60095±0.00000  bestvalidloss -2015.85790  last_update 14\n",
      "train: iter 342  trainloss -2037.56217  validloss -1972.29758±0.00000  bestvalidloss -2015.85790  last_update 15\n",
      "train: iter 343  trainloss -2007.91263  validloss -1956.15477±0.00000  bestvalidloss -2015.85790  last_update 16\n",
      "train: iter 344  trainloss -1985.83092  validloss -1875.61811±0.00000  bestvalidloss -2015.85790  last_update 17\n",
      "train: iter 345  trainloss -1950.85000  validloss -1922.13984±0.00000  bestvalidloss -2015.85790  last_update 18\n",
      "train: iter 346  trainloss -1872.25940  validloss -1583.94507±0.00000  bestvalidloss -2015.85790  last_update 19\n",
      "train: iter 347  trainloss -1982.31484  validloss -1953.37203±0.00000  bestvalidloss -2015.85790  last_update 20\n",
      "train: iter 348  trainloss -2011.23756  validloss -1954.95898±0.00000  bestvalidloss -2015.85790  last_update 21\n",
      "train: iter 349  trainloss -2017.14070  validloss -1912.11841±0.00000  bestvalidloss -2015.85790  last_update 22\n",
      "train: iter 350  trainloss -1927.92832  validloss -1986.98427±0.00000  bestvalidloss -2015.85790  last_update 23\n",
      "train: iter 351  trainloss -2038.27088  validloss -1972.09880±0.00000  bestvalidloss -2015.85790  last_update 24\n",
      "train: iter 352  trainloss -1952.28525  validloss -1996.07010±0.00000  bestvalidloss -2015.85790  last_update 25\n",
      "train: iter 353  trainloss -2036.78820  validloss -1970.86795±0.00000  bestvalidloss -2015.85790  last_update 26\n",
      "train: iter 354  trainloss -2040.14782  validloss -1938.46293±0.00000  bestvalidloss -2015.85790  last_update 27\n",
      "train: iter 355  trainloss -1992.50263  validloss -1997.94727±0.00000  bestvalidloss -2015.85790  last_update 28\n",
      "train: iter 356  trainloss -2023.21820  validloss -1941.58909±0.00000  bestvalidloss -2015.85790  last_update 29\n",
      "train: iter 357  trainloss -1986.24297  validloss -1986.80322±0.00000  bestvalidloss -2015.85790  last_update 30\n",
      "train: iter 358  trainloss -1794.84962  validloss -1961.41738±0.00000  bestvalidloss -2015.85790  last_update 31\n",
      "train: iter 359  trainloss -2009.94832  validloss -1913.53504±0.00000  bestvalidloss -2015.85790  last_update 32\n",
      "train: iter 360  trainloss -1970.90647  validloss -2013.27612±0.00000  bestvalidloss -2015.85790  last_update 33\n",
      "train: iter 361  trainloss -1769.28454  validloss -1858.21909±0.00000  bestvalidloss -2015.85790  last_update 34\n",
      "train: iter 362  trainloss -2025.19100  validloss -1965.29313±0.00000  bestvalidloss -2015.85790  last_update 35\n",
      "train: iter 363  trainloss -2059.91617  validloss -2009.77526±0.00000  bestvalidloss -2015.85790  last_update 36\n",
      "train: iter 364  trainloss -2022.20438  validloss -2022.08007±0.00000  bestvalidloss -2022.08007  last_update 0\n",
      "train: iter 365  trainloss -1855.15566  validloss -1984.31391±0.00000  bestvalidloss -2022.08007  last_update 1\n",
      "train: iter 366  trainloss -2020.19588  validloss -1768.46400±0.00000  bestvalidloss -2022.08007  last_update 2\n",
      "train: iter 367  trainloss -2039.87554  validloss -2011.48823±0.00000  bestvalidloss -2022.08007  last_update 3\n",
      "train: iter 368  trainloss -2027.60265  validloss -2013.75812±0.00000  bestvalidloss -2022.08007  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -2054.75737  validloss -1980.89487±0.00000  bestvalidloss -2022.08007  last_update 5\n",
      "train: iter 370  trainloss -2000.53573  validloss -2032.79468±0.00000  bestvalidloss -2032.79468  last_update 0\n",
      "train: iter 371  trainloss -1999.09512  validloss -1907.24575±0.00000  bestvalidloss -2032.79468  last_update 1\n",
      "train: iter 372  trainloss -2020.75068  validloss -1751.12201±0.00000  bestvalidloss -2032.79468  last_update 2\n",
      "train: iter 373  trainloss -1405.15252  validloss -1846.06786±0.00000  bestvalidloss -2032.79468  last_update 3\n",
      "train: iter 374  trainloss -1977.24800  validloss -1878.29783±0.00000  bestvalidloss -2032.79468  last_update 4\n",
      "train: iter 375  trainloss -2014.89970  validloss -2000.02975±0.00000  bestvalidloss -2032.79468  last_update 5\n",
      "train: iter 376  trainloss -1862.37105  validloss -1964.15532±0.00000  bestvalidloss -2032.79468  last_update 6\n",
      "train: iter 377  trainloss -2050.29637  validloss -1993.84249±0.00000  bestvalidloss -2032.79468  last_update 7\n",
      "train: iter 378  trainloss -2027.86403  validloss -1878.82120±0.00000  bestvalidloss -2032.79468  last_update 8\n",
      "train: iter 379  trainloss -2042.16700  validloss -2009.00058±0.00000  bestvalidloss -2032.79468  last_update 9\n",
      "train: iter 380  trainloss -2053.90230  validloss -2001.88347±0.00000  bestvalidloss -2032.79468  last_update 10\n",
      "train: iter 381  trainloss -1919.25778  validloss -1970.06840±0.00000  bestvalidloss -2032.79468  last_update 11\n",
      "train: iter 382  trainloss -1892.73508  validloss -1981.98448±0.00000  bestvalidloss -2032.79468  last_update 12\n",
      "train: iter 383  trainloss -2025.86134  validloss -1913.66898±0.00000  bestvalidloss -2032.79468  last_update 13\n",
      "train: iter 384  trainloss -2040.55604  validloss -1984.36746±0.00000  bestvalidloss -2032.79468  last_update 14\n",
      "train: iter 385  trainloss -2056.28456  validloss -2027.69860±0.00000  bestvalidloss -2032.79468  last_update 15\n",
      "train: iter 386  trainloss -1992.90748  validloss -1962.91357±0.00000  bestvalidloss -2032.79468  last_update 16\n",
      "train: iter 387  trainloss -1939.18937  validloss -1971.76046±0.00000  bestvalidloss -2032.79468  last_update 17\n",
      "train: iter 388  trainloss -1867.99493  validloss -715.06699±0.00000  bestvalidloss -2032.79468  last_update 18\n",
      "train: iter 389  trainloss -2013.09550  validloss -1999.98970±0.00000  bestvalidloss -2032.79468  last_update 19\n",
      "train: iter 390  trainloss -2052.11728  validloss -1979.44656±0.00000  bestvalidloss -2032.79468  last_update 20\n",
      "train: iter 391  trainloss -2056.64258  validloss -2008.87865±0.00000  bestvalidloss -2032.79468  last_update 21\n",
      "train: iter 392  trainloss -2006.57466  validloss -1949.84695±0.00000  bestvalidloss -2032.79468  last_update 22\n",
      "train: iter 393  trainloss -1950.11692  validloss -1995.10616±0.00000  bestvalidloss -2032.79468  last_update 23\n",
      "train: iter 394  trainloss -2009.21586  validloss -1835.83973±0.00000  bestvalidloss -2032.79468  last_update 24\n",
      "train: iter 395  trainloss -1998.74219  validloss -1993.55123±0.00000  bestvalidloss -2032.79468  last_update 25\n",
      "train: iter 396  trainloss -2042.47064  validloss -1979.53878±0.00000  bestvalidloss -2032.79468  last_update 26\n",
      "train: iter 397  trainloss -1725.37225  validloss -1989.88331±0.00000  bestvalidloss -2032.79468  last_update 27\n",
      "train: iter 398  trainloss -2035.07607  validloss -1957.23276±0.00000  bestvalidloss -2032.79468  last_update 28\n",
      "train: iter 399  trainloss -2027.02120  validloss -1991.81514±0.00000  bestvalidloss -2032.79468  last_update 29\n",
      "train: iter 400  trainloss -2008.33621  validloss -1918.78747±0.00000  bestvalidloss -2032.79468  last_update 30\n",
      "train: iter 401  trainloss -2042.58169  validloss -2013.04971±0.00000  bestvalidloss -2032.79468  last_update 31\n",
      "train: iter 402  trainloss -2033.35841  validloss -1996.59068±0.00000  bestvalidloss -2032.79468  last_update 32\n",
      "train: iter 403  trainloss -2061.56006  validloss -2020.12083±0.00000  bestvalidloss -2032.79468  last_update 33\n",
      "train: iter 404  trainloss -2048.85974  validloss -2005.63165±0.00000  bestvalidloss -2032.79468  last_update 34\n",
      "train: iter 405  trainloss -2023.14473  validloss -1995.04811±0.00000  bestvalidloss -2032.79468  last_update 35\n",
      "train: iter 406  trainloss -1921.32626  validloss -1973.57224±0.00000  bestvalidloss -2032.79468  last_update 36\n",
      "train: iter 407  trainloss -2036.70299  validloss -1943.89847±0.00000  bestvalidloss -2032.79468  last_update 37\n",
      "train: iter 408  trainloss -2026.28891  validloss -2001.62057±0.00000  bestvalidloss -2032.79468  last_update 38\n",
      "train: iter 409  trainloss -1934.25415  validloss -1892.13562±0.00000  bestvalidloss -2032.79468  last_update 39\n",
      "train: iter 410  trainloss -1858.98558  validloss -1300.24442±0.00000  bestvalidloss -2032.79468  last_update 40\n",
      "train: iter 411  trainloss -2048.90594  validloss -1994.65920±0.00000  bestvalidloss -2032.79468  last_update 41\n",
      "train: iter 412  trainloss -2050.87974  validloss -1941.13286±0.00000  bestvalidloss -2032.79468  last_update 42\n",
      "train: iter 413  trainloss -2044.74306  validloss -2006.92607±0.00000  bestvalidloss -2032.79468  last_update 43\n",
      "train: iter 414  trainloss -2032.84248  validloss -1988.55322±0.00000  bestvalidloss -2032.79468  last_update 44\n",
      "train: iter 415  trainloss -1839.92182  validloss -1867.97341±0.00000  bestvalidloss -2032.79468  last_update 45\n",
      "train: iter 416  trainloss -2006.71783  validloss -1572.63744±0.00000  bestvalidloss -2032.79468  last_update 46\n",
      "train: iter 417  trainloss -2063.00881  validloss -1977.40300±0.00000  bestvalidloss -2032.79468  last_update 47\n",
      "train: iter 418  trainloss -2019.67111  validloss -2018.95803±0.00000  bestvalidloss -2032.79468  last_update 48\n",
      "train: iter 419  trainloss -1993.24287  validloss -2004.47394±0.00000  bestvalidloss -2032.79468  last_update 49\n",
      "train: iter 420  trainloss -1932.31897  validloss -1543.03479±0.00000  bestvalidloss -2032.79468  last_update 50\n",
      "train: iter 421  trainloss -2011.74482  validloss -1947.49196±0.00000  bestvalidloss -2032.79468  last_update 51\n",
      "train: iter 422  trainloss -1985.11300  validloss -2001.87649±0.00000  bestvalidloss -2032.79468  last_update 52\n",
      "train: iter 423  trainloss -2009.21848  validloss -1953.33324±0.00000  bestvalidloss -2032.79468  last_update 53\n",
      "train: iter 424  trainloss -2058.81920  validloss -1987.11150±0.00000  bestvalidloss -2032.79468  last_update 54\n",
      "train: iter 425  trainloss -745.56479  validloss -1985.74476±0.00000  bestvalidloss -2032.79468  last_update 55\n",
      "train: iter 426  trainloss -1345.48791  validloss -641.89026±0.00000  bestvalidloss -2032.79468  last_update 56\n",
      "train: iter 427  trainloss -1833.76326  validloss -1785.38646±0.00000  bestvalidloss -2032.79468  last_update 57\n",
      "train: iter 428  trainloss -2002.74206  validloss -1956.93228±0.00000  bestvalidloss -2032.79468  last_update 58\n",
      "train: iter 429  trainloss -2005.81916  validloss -2006.84318±0.00000  bestvalidloss -2032.79468  last_update 59\n",
      "train: iter 430  trainloss -1973.12190  validloss -2007.07968±0.00000  bestvalidloss -2032.79468  last_update 60\n",
      "train: iter 431  trainloss -2001.81533  validloss -1913.05965±0.00000  bestvalidloss -2032.79468  last_update 61\n",
      "train: iter 432  trainloss -2026.31996  validloss -2015.77422±0.00000  bestvalidloss -2032.79468  last_update 62\n",
      "train: iter 433  trainloss -1944.74220  validloss -2009.68473±0.00000  bestvalidloss -2032.79468  last_update 63\n",
      "train: iter 434  trainloss -2013.65789  validloss -1995.16037±0.00000  bestvalidloss -2032.79468  last_update 64\n",
      "train: iter 435  trainloss -2029.97490  validloss -1971.58073±0.00000  bestvalidloss -2032.79468  last_update 65\n",
      "train: iter 436  trainloss -2015.89324  validloss -1983.71303±0.00000  bestvalidloss -2032.79468  last_update 66\n",
      "train: iter 437  trainloss -2035.87134  validloss -2013.06749±0.00000  bestvalidloss -2032.79468  last_update 67\n",
      "train: iter 438  trainloss -2053.58698  validloss -1981.64726±0.00000  bestvalidloss -2032.79468  last_update 68\n",
      "train: iter 439  trainloss -1927.19251  validloss -2014.04635±0.00000  bestvalidloss -2032.79468  last_update 69\n",
      "train: iter 440  trainloss -2004.36640  validloss -1730.57177±0.00000  bestvalidloss -2032.79468  last_update 70\n",
      "train: iter 441  trainloss -2051.61560  validloss -2003.15563±0.00000  bestvalidloss -2032.79468  last_update 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 442  trainloss -2059.05709  validloss -2006.25477±0.00000  bestvalidloss -2032.79468  last_update 72\n",
      "train: iter 443  trainloss -1987.04351  validloss -2015.16746±0.00000  bestvalidloss -2032.79468  last_update 73\n",
      "train: iter 444  trainloss -2000.44074  validloss -1943.29235±0.00000  bestvalidloss -2032.79468  last_update 74\n",
      "train: iter 445  trainloss -2009.99395  validloss -1996.28962±0.00000  bestvalidloss -2032.79468  last_update 75\n",
      "train: iter 446  trainloss -2036.15472  validloss -1994.06169±0.00000  bestvalidloss -2032.79468  last_update 76\n",
      "train: iter 447  trainloss -2023.48999  validloss -2008.25084±0.00000  bestvalidloss -2032.79468  last_update 77\n",
      "train: iter 448  trainloss -1983.07419  validloss -1969.69835±0.00000  bestvalidloss -2032.79468  last_update 78\n",
      "train: iter 449  trainloss -1984.86860  validloss -1978.63766±0.00000  bestvalidloss -2032.79468  last_update 79\n",
      "train: iter 450  trainloss -1770.42790  validloss -1876.67414±0.00000  bestvalidloss -2032.79468  last_update 80\n",
      "train: iter 451  trainloss -2015.71089  validloss -1931.81754±0.00000  bestvalidloss -2032.79468  last_update 81\n",
      "train: iter 452  trainloss -2005.73952  validloss -1980.22091±0.00000  bestvalidloss -2032.79468  last_update 82\n",
      "train: iter 453  trainloss -2045.73500  validloss -2015.20723±0.00000  bestvalidloss -2032.79468  last_update 83\n",
      "train: iter 454  trainloss -1970.16647  validloss -2013.48915±0.00000  bestvalidloss -2032.79468  last_update 84\n",
      "train: iter 455  trainloss -1953.81421  validloss -1936.31049±0.00000  bestvalidloss -2032.79468  last_update 85\n",
      "train: iter 456  trainloss -2045.58127  validloss -1999.64987±0.00000  bestvalidloss -2032.79468  last_update 86\n",
      "train: iter 457  trainloss -1981.74071  validloss -1931.35484±0.00000  bestvalidloss -2032.79468  last_update 87\n",
      "train: iter 458  trainloss -2038.38976  validloss -2007.70915±0.00000  bestvalidloss -2032.79468  last_update 88\n",
      "train: iter 459  trainloss -2061.21859  validloss -1996.86457±0.00000  bestvalidloss -2032.79468  last_update 89\n",
      "train: iter 460  trainloss -2002.17026  validloss -2033.15203±0.00000  bestvalidloss -2033.15203  last_update 0\n",
      "train: iter 461  trainloss -1603.90527  validloss -361.59982±0.00000  bestvalidloss -2033.15203  last_update 1\n",
      "train: iter 462  trainloss -1995.28501  validloss -1883.98543±0.00000  bestvalidloss -2033.15203  last_update 2\n",
      "train: iter 463  trainloss -2027.66086  validloss -1985.99402±0.00000  bestvalidloss -2033.15203  last_update 3\n",
      "train: iter 464  trainloss -1980.27168  validloss -1965.03444±0.00000  bestvalidloss -2033.15203  last_update 4\n",
      "train: iter 465  trainloss -1992.78383  validloss -1996.17813±0.00000  bestvalidloss -2033.15203  last_update 5\n",
      "train: iter 466  trainloss -2054.37575  validloss -2019.89429±0.00000  bestvalidloss -2033.15203  last_update 6\n",
      "train: iter 467  trainloss -2062.65181  validloss -2010.46099±0.00000  bestvalidloss -2033.15203  last_update 7\n",
      "train: iter 468  trainloss -1969.34758  validloss -2009.37060±0.00000  bestvalidloss -2033.15203  last_update 8\n",
      "train: iter 469  trainloss -1936.89285  validloss -1491.37762±0.00000  bestvalidloss -2033.15203  last_update 9\n",
      "train: iter 470  trainloss -2063.43162  validloss -1992.25634±0.00000  bestvalidloss -2033.15203  last_update 10\n",
      "train: iter 471  trainloss -2037.68808  validloss -1993.35635±0.00000  bestvalidloss -2033.15203  last_update 11\n",
      "train: iter 472  trainloss -1991.08784  validloss -1981.26564±0.00000  bestvalidloss -2033.15203  last_update 12\n",
      "train: iter 473  trainloss -2040.60824  validloss -2007.22510±0.00000  bestvalidloss -2033.15203  last_update 13\n",
      "train: iter 474  trainloss -1988.20338  validloss -1975.71450±0.00000  bestvalidloss -2033.15203  last_update 14\n",
      "train: iter 475  trainloss -2064.38561  validloss -1985.95665±0.00000  bestvalidloss -2033.15203  last_update 15\n",
      "train: iter 476  trainloss -2048.13621  validloss -2024.13825±0.00000  bestvalidloss -2033.15203  last_update 16\n",
      "train: iter 477  trainloss -1861.10032  validloss -1919.35176±0.00000  bestvalidloss -2033.15203  last_update 17\n",
      "train: iter 478  trainloss -2038.25649  validloss -1943.55107±0.00000  bestvalidloss -2033.15203  last_update 18\n",
      "train: iter 479  trainloss -2060.62428  validloss -2007.04179±0.00000  bestvalidloss -2033.15203  last_update 19\n",
      "train: iter 480  trainloss -2045.36067  validloss -1994.43726±0.00000  bestvalidloss -2033.15203  last_update 20\n",
      "train: iter 481  trainloss -2058.00927  validloss -2013.31626±0.00000  bestvalidloss -2033.15203  last_update 21\n",
      "train: iter 482  trainloss -1451.54522  validloss -2014.35892±0.00000  bestvalidloss -2033.15203  last_update 22\n",
      "train: iter 483  trainloss -1999.30238  validloss -1906.63185±0.00000  bestvalidloss -2033.15203  last_update 23\n",
      "train: iter 484  trainloss -2048.80057  validloss -2017.04084±0.00000  bestvalidloss -2033.15203  last_update 24\n",
      "train: iter 485  trainloss -2034.05886  validloss -1985.32537±0.00000  bestvalidloss -2033.15203  last_update 25\n",
      "train: iter 486  trainloss -1749.22598  validloss -1995.90681±0.00000  bestvalidloss -2033.15203  last_update 26\n",
      "train: iter 487  trainloss -2035.29829  validloss -1957.15390±0.00000  bestvalidloss -2033.15203  last_update 27\n",
      "train: iter 488  trainloss -2042.53254  validloss -2013.57062±0.00000  bestvalidloss -2033.15203  last_update 28\n",
      "train: iter 489  trainloss -2084.45187  validloss -2039.27515±0.00000  bestvalidloss -2039.27515  last_update 0\n",
      "train: iter 490  trainloss -2075.82615  validloss -2034.75594±0.00000  bestvalidloss -2039.27515  last_update 1\n",
      "train: iter 491  trainloss -2070.92646  validloss -1977.36968±0.00000  bestvalidloss -2039.27515  last_update 2\n",
      "train: iter 492  trainloss -2019.38136  validloss -2031.85760±0.00000  bestvalidloss -2039.27515  last_update 3\n",
      "train: iter 493  trainloss -1870.11153  validloss -1890.10399±0.00000  bestvalidloss -2039.27515  last_update 4\n",
      "train: iter 494  trainloss -2063.59881  validloss -2003.12883±0.00000  bestvalidloss -2039.27515  last_update 5\n",
      "train: iter 495  trainloss -2020.57337  validloss -2007.91310±0.00000  bestvalidloss -2039.27515  last_update 6\n",
      "train: iter 496  trainloss -2082.05388  validloss -2012.20061±0.00000  bestvalidloss -2039.27515  last_update 7\n",
      "train: iter 497  trainloss -1879.43161  validloss -2018.41795±0.00000  bestvalidloss -2039.27515  last_update 8\n",
      "train: iter 498  trainloss -1897.86533  validloss -1198.29711±0.00000  bestvalidloss -2039.27515  last_update 9\n",
      "train: iter 499  trainloss -2050.68595  validloss -1979.88576±0.00000  bestvalidloss -2039.27515  last_update 10\n",
      "train: iter 500  trainloss -2068.86820  validloss -2027.51361±0.00000  bestvalidloss -2039.27515  last_update 11\n",
      "train: iter 501  trainloss -2063.32784  validloss -2032.53513±0.00000  bestvalidloss -2039.27515  last_update 12\n",
      "train: iter 502  trainloss -2075.79151  validloss -2001.10662±0.00000  bestvalidloss -2039.27515  last_update 13\n",
      "train: iter 503  trainloss -2064.62091  validloss -2011.22018±0.00000  bestvalidloss -2039.27515  last_update 14\n",
      "train: iter 504  trainloss -2029.94228  validloss -1865.68695±0.00000  bestvalidloss -2039.27515  last_update 15\n",
      "train: iter 505  trainloss -2083.35888  validloss -2022.28083±0.00000  bestvalidloss -2039.27515  last_update 16\n",
      "train: iter 506  trainloss -1728.32627  validloss -1993.50560±0.00000  bestvalidloss -2039.27515  last_update 17\n",
      "train: iter 507  trainloss -1971.67512  validloss -1940.14185±0.00000  bestvalidloss -2039.27515  last_update 18\n",
      "train: iter 508  trainloss -2058.14117  validloss -2027.53113±0.00000  bestvalidloss -2039.27515  last_update 19\n",
      "train: iter 509  trainloss -2056.25334  validloss -2013.65576±0.00000  bestvalidloss -2039.27515  last_update 20\n",
      "train: iter 510  trainloss -2076.41520  validloss -2006.59171±0.00000  bestvalidloss -2039.27515  last_update 21\n",
      "train: iter 511  trainloss -2063.26495  validloss -1992.62220±0.00000  bestvalidloss -2039.27515  last_update 22\n",
      "train: iter 512  trainloss -1694.78133  validloss -2002.65985±0.00000  bestvalidloss -2039.27515  last_update 23\n",
      "train: iter 513  trainloss -2028.41547  validloss -1880.41218±0.00000  bestvalidloss -2039.27515  last_update 24\n",
      "train: iter 514  trainloss -2049.50975  validloss -1996.87089±0.00000  bestvalidloss -2039.27515  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 515  trainloss -2062.42733  validloss -1952.38995±0.00000  bestvalidloss -2039.27515  last_update 26\n",
      "train: iter 516  trainloss -2057.09912  validloss -1977.22106±0.00000  bestvalidloss -2039.27515  last_update 27\n",
      "train: iter 517  trainloss -2027.39117  validloss -1960.28373±0.00000  bestvalidloss -2039.27515  last_update 28\n",
      "train: iter 518  trainloss -2046.75536  validloss -2022.39174±0.00000  bestvalidloss -2039.27515  last_update 29\n",
      "train: iter 519  trainloss -2049.49171  validloss -2009.47748±0.00000  bestvalidloss -2039.27515  last_update 30\n",
      "train: iter 520  trainloss -2014.93250  validloss -2026.74409±0.00000  bestvalidloss -2039.27515  last_update 31\n",
      "train: iter 521  trainloss -1998.37284  validloss -1970.37014±0.00000  bestvalidloss -2039.27515  last_update 32\n",
      "train: iter 522  trainloss -2070.73193  validloss -1973.45209±0.00000  bestvalidloss -2039.27515  last_update 33\n",
      "train: iter 523  trainloss -2063.76300  validloss -2023.64667±0.00000  bestvalidloss -2039.27515  last_update 34\n",
      "train: iter 524  trainloss -2050.42089  validloss -1940.36128±0.00000  bestvalidloss -2039.27515  last_update 35\n",
      "train: iter 525  trainloss -1923.68501  validloss -1994.82005±0.00000  bestvalidloss -2039.27515  last_update 36\n",
      "train: iter 526  trainloss -1945.17517  validloss -1529.86025±0.00000  bestvalidloss -2039.27515  last_update 37\n",
      "train: iter 527  trainloss -2019.03155  validloss -1929.84515±0.00000  bestvalidloss -2039.27515  last_update 38\n",
      "train: iter 528  trainloss -2023.98122  validloss -1966.80970±0.00000  bestvalidloss -2039.27515  last_update 39\n",
      "train: iter 529  trainloss -1992.68911  validloss -1798.85834±0.00000  bestvalidloss -2039.27515  last_update 40\n",
      "train: iter 530  trainloss -2039.68766  validloss -2002.38948±0.00000  bestvalidloss -2039.27515  last_update 41\n",
      "train: iter 531  trainloss -2049.72293  validloss -1950.18624±0.00000  bestvalidloss -2039.27515  last_update 42\n",
      "train: iter 532  trainloss -1999.75299  validloss -1776.56667±0.00000  bestvalidloss -2039.27515  last_update 43\n",
      "train: iter 533  trainloss -2071.18599  validloss -2011.09017±0.00000  bestvalidloss -2039.27515  last_update 44\n",
      "train: iter 534  trainloss -1968.90544  validloss -1972.53500±0.00000  bestvalidloss -2039.27515  last_update 45\n",
      "train: iter 535  trainloss -2044.98633  validloss -1983.07601±0.00000  bestvalidloss -2039.27515  last_update 46\n",
      "train: iter 536  trainloss -2064.26986  validloss -2011.05045±0.00000  bestvalidloss -2039.27515  last_update 47\n",
      "train: iter 537  trainloss -2080.06266  validloss -2026.60161±0.00000  bestvalidloss -2039.27515  last_update 48\n",
      "train: iter 538  trainloss -1893.06313  validloss -2022.34193±0.00000  bestvalidloss -2039.27515  last_update 49\n",
      "train: iter 539  trainloss -2035.06327  validloss -1949.63148±0.00000  bestvalidloss -2039.27515  last_update 50\n",
      "train: iter 540  trainloss -2037.12160  validloss -2000.36656±0.00000  bestvalidloss -2039.27515  last_update 51\n",
      "train: iter 541  trainloss -2012.99575  validloss -1988.65461±0.00000  bestvalidloss -2039.27515  last_update 52\n",
      "train: iter 542  trainloss -1829.82529  validloss -1923.41625±0.00000  bestvalidloss -2039.27515  last_update 53\n",
      "train: iter 543  trainloss -2061.87994  validloss -1996.90258±0.00000  bestvalidloss -2039.27515  last_update 54\n",
      "train: iter 544  trainloss -2082.51840  validloss -2021.77662±0.00000  bestvalidloss -2039.27515  last_update 55\n",
      "train: iter 545  trainloss -2084.52414  validloss -2006.82962±0.00000  bestvalidloss -2039.27515  last_update 56\n",
      "train: iter 546  trainloss -2069.20263  validloss -2041.95253±0.00000  bestvalidloss -2041.95253  last_update 0\n",
      "train: iter 547  trainloss -1993.13733  validloss -1999.95788±0.00000  bestvalidloss -2041.95253  last_update 1\n",
      "train: iter 548  trainloss -2030.36275  validloss -1920.02043±0.00000  bestvalidloss -2041.95253  last_update 2\n",
      "train: iter 549  trainloss -1794.65046  validloss -1930.99149±0.00000  bestvalidloss -2041.95253  last_update 3\n",
      "train: iter 550  trainloss -2034.93560  validloss -1924.31139±0.00000  bestvalidloss -2041.95253  last_update 4\n",
      "train: iter 551  trainloss -2044.92424  validloss -1974.47948±0.00000  bestvalidloss -2041.95253  last_update 5\n",
      "train: iter 552  trainloss -2077.20427  validloss -2009.97125±0.00000  bestvalidloss -2041.95253  last_update 6\n",
      "train: iter 553  trainloss -2094.29345  validloss -2034.89727±0.00000  bestvalidloss -2041.95253  last_update 7\n",
      "train: iter 554  trainloss -1925.43188  validloss -1981.89655±0.00000  bestvalidloss -2041.95253  last_update 8\n",
      "train: iter 555  trainloss -2017.90316  validloss -1879.83951±0.00000  bestvalidloss -2041.95253  last_update 9\n",
      "train: iter 556  trainloss -2070.15776  validloss -1884.93994±0.00000  bestvalidloss -2041.95253  last_update 10\n",
      "train: iter 557  trainloss -2084.68887  validloss -1999.57968±0.00000  bestvalidloss -2041.95253  last_update 11\n",
      "train: iter 558  trainloss -2071.89482  validloss -2022.95257±0.00000  bestvalidloss -2041.95253  last_update 12\n",
      "train: iter 559  trainloss -2039.45939  validloss -1985.21976±0.00000  bestvalidloss -2041.95253  last_update 13\n",
      "train: iter 560  trainloss -2028.74741  validloss -1924.36664±0.00000  bestvalidloss -2041.95253  last_update 14\n",
      "train: iter 561  trainloss -1943.85713  validloss -1996.82662±0.00000  bestvalidloss -2041.95253  last_update 15\n",
      "train: iter 562  trainloss -2063.93161  validloss -1996.63320±0.00000  bestvalidloss -2041.95253  last_update 16\n",
      "train: iter 563  trainloss -2076.01731  validloss -2035.87320±0.00000  bestvalidloss -2041.95253  last_update 17\n",
      "train: iter 564  trainloss -1984.32697  validloss -2026.17569±0.00000  bestvalidloss -2041.95253  last_update 18\n",
      "train: iter 565  trainloss -926.41944  validloss -1248.43987±0.00000  bestvalidloss -2041.95253  last_update 19\n",
      "train: iter 566  trainloss -1920.67237  validloss -1497.20801±0.00000  bestvalidloss -2041.95253  last_update 20\n",
      "train: iter 567  trainloss -2019.19013  validloss -1967.23613±0.00000  bestvalidloss -2041.95253  last_update 21\n",
      "train: iter 568  trainloss -2061.78693  validloss -2017.86509±0.00000  bestvalidloss -2041.95253  last_update 22\n",
      "train: iter 569  trainloss -2072.10784  validloss -2014.48582±0.00000  bestvalidloss -2041.95253  last_update 23\n",
      "train: iter 570  trainloss -2058.11017  validloss -1964.75631±0.00000  bestvalidloss -2041.95253  last_update 24\n",
      "train: iter 571  trainloss -1840.55065  validloss -1971.92464±0.00000  bestvalidloss -2041.95253  last_update 25\n",
      "train: iter 572  trainloss -2032.46775  validloss -1881.92080±0.00000  bestvalidloss -2041.95253  last_update 26\n",
      "train: iter 573  trainloss -2073.10453  validloss -2022.33582±0.00000  bestvalidloss -2041.95253  last_update 27\n",
      "train: iter 574  trainloss -2084.13905  validloss -2045.40173±0.00000  bestvalidloss -2045.40173  last_update 0\n",
      "train: iter 575  trainloss -2076.68965  validloss -2039.35596±0.00000  bestvalidloss -2045.40173  last_update 1\n",
      "train: iter 576  trainloss -2062.58929  validloss -2041.19177±0.00000  bestvalidloss -2045.40173  last_update 2\n",
      "train: iter 577  trainloss -2049.26233  validloss -2024.77850±0.00000  bestvalidloss -2045.40173  last_update 3\n",
      "train: iter 578  trainloss -1949.26931  validloss -2001.49411±0.00000  bestvalidloss -2045.40173  last_update 4\n",
      "train: iter 579  trainloss -2073.82210  validloss -1899.77685±0.00000  bestvalidloss -2045.40173  last_update 5\n",
      "train: iter 580  trainloss -2077.81238  validloss -2017.88787±0.00000  bestvalidloss -2045.40173  last_update 6\n",
      "train: iter 581  trainloss -2053.20719  validloss -2030.76692±0.00000  bestvalidloss -2045.40173  last_update 7\n",
      "train: iter 582  trainloss -2059.30992  validloss -2002.62018±0.00000  bestvalidloss -2045.40173  last_update 8\n",
      "train: iter 583  trainloss -2082.84854  validloss -2038.33823±0.00000  bestvalidloss -2045.40173  last_update 9\n",
      "train: iter 584  trainloss -2024.90169  validloss -2015.10551±0.00000  bestvalidloss -2045.40173  last_update 10\n",
      "train: iter 585  trainloss -1927.95551  validloss -1706.17832±0.00000  bestvalidloss -2045.40173  last_update 11\n",
      "train: iter 586  trainloss -1986.89248  validloss -1780.94687±0.00000  bestvalidloss -2045.40173  last_update 12\n",
      "train: iter 587  trainloss -2061.46701  validloss -1997.73511±0.00000  bestvalidloss -2045.40173  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 588  trainloss -2071.35049  validloss -1984.30194±0.00000  bestvalidloss -2045.40173  last_update 14\n",
      "train: iter 589  trainloss -2080.81609  validloss -2047.88411±0.00000  bestvalidloss -2047.88411  last_update 0\n",
      "train: iter 590  trainloss -2046.82468  validloss -2019.27897±0.00000  bestvalidloss -2047.88411  last_update 1\n",
      "train: iter 591  trainloss -1798.37652  validloss -1528.66492±0.00000  bestvalidloss -2047.88411  last_update 2\n",
      "train: iter 592  trainloss -2078.21351  validloss -2014.35837±0.00000  bestvalidloss -2047.88411  last_update 3\n",
      "train: iter 593  trainloss -2064.45341  validloss -1998.30112±0.00000  bestvalidloss -2047.88411  last_update 4\n",
      "train: iter 594  trainloss -2043.14577  validloss -1871.28240±0.00000  bestvalidloss -2047.88411  last_update 5\n",
      "train: iter 595  trainloss -2054.08461  validloss -2028.69443±0.00000  bestvalidloss -2047.88411  last_update 6\n",
      "train: iter 596  trainloss -1772.00980  validloss -1951.64044±0.00000  bestvalidloss -2047.88411  last_update 7\n",
      "train: iter 597  trainloss -2065.01136  validloss -1957.13873±0.00000  bestvalidloss -2047.88411  last_update 8\n",
      "train: iter 598  trainloss -2067.47258  validloss -2008.43328±0.00000  bestvalidloss -2047.88411  last_update 9\n",
      "train: iter 599  trainloss -2078.84756  validloss -2028.38397±0.00000  bestvalidloss -2047.88411  last_update 10\n",
      "train: iter 600  trainloss -2054.16473  validloss -2033.67085±0.00000  bestvalidloss -2047.88411  last_update 11\n",
      "train: iter 601  trainloss -1916.17358  validloss -1921.14866±0.00000  bestvalidloss -2047.88411  last_update 12\n",
      "train: iter 602  trainloss -2072.90461  validloss -1972.03533±0.00000  bestvalidloss -2047.88411  last_update 13\n",
      "train: iter 603  trainloss -2072.59112  validloss -1996.93689±0.00000  bestvalidloss -2047.88411  last_update 14\n",
      "train: iter 604  trainloss -2071.49533  validloss -1939.38592±0.00000  bestvalidloss -2047.88411  last_update 15\n",
      "train: iter 605  trainloss -2051.29004  validloss -2030.62059±0.00000  bestvalidloss -2047.88411  last_update 16\n",
      "train: iter 606  trainloss -2043.63857  validloss -1952.97057±0.00000  bestvalidloss -2047.88411  last_update 17\n",
      "train: iter 607  trainloss -2082.82033  validloss -2031.77020±0.00000  bestvalidloss -2047.88411  last_update 18\n",
      "train: iter 608  trainloss -2055.62106  validloss -2005.73662±0.00000  bestvalidloss -2047.88411  last_update 19\n",
      "train: iter 609  trainloss -2071.41205  validloss -1990.92567±0.00000  bestvalidloss -2047.88411  last_update 20\n",
      "train: iter 610  trainloss -1826.72649  validloss -2008.66625±0.00000  bestvalidloss -2047.88411  last_update 21\n",
      "train: iter 611  trainloss -1816.15899  validloss -1078.78589±0.00000  bestvalidloss -2047.88411  last_update 22\n",
      "train: iter 612  trainloss -2060.42905  validloss -2015.26252±0.00000  bestvalidloss -2047.88411  last_update 23\n",
      "train: iter 613  trainloss -2034.46424  validloss -2018.90999±0.00000  bestvalidloss -2047.88411  last_update 24\n",
      "train: iter 614  trainloss -2012.98221  validloss -1919.78428±0.00000  bestvalidloss -2047.88411  last_update 25\n",
      "train: iter 615  trainloss -2039.87293  validloss -1937.51521±0.00000  bestvalidloss -2047.88411  last_update 26\n",
      "train: iter 616  trainloss -2076.37442  validloss -1992.54089±0.00000  bestvalidloss -2047.88411  last_update 27\n",
      "train: iter 617  trainloss -2075.61309  validloss -1992.27867±0.00000  bestvalidloss -2047.88411  last_update 28\n",
      "train: iter 618  trainloss -2081.03832  validloss -1986.07356±0.00000  bestvalidloss -2047.88411  last_update 29\n",
      "train: iter 619  trainloss -2053.54441  validloss -2017.95748±0.00000  bestvalidloss -2047.88411  last_update 30\n",
      "train: iter 620  trainloss -2032.34764  validloss -2008.43201±0.00000  bestvalidloss -2047.88411  last_update 31\n",
      "train: iter 621  trainloss -2091.64652  validloss -2053.44511±0.00000  bestvalidloss -2053.44511  last_update 0\n",
      "train: iter 622  trainloss -2098.85499  validloss -2029.65491±0.00000  bestvalidloss -2053.44511  last_update 1\n",
      "train: iter 623  trainloss -1859.21818  validloss -1996.87092±0.00000  bestvalidloss -2053.44511  last_update 2\n",
      "train: iter 624  trainloss -1896.44305  validloss -1868.82280±0.00000  bestvalidloss -2053.44511  last_update 3\n",
      "train: iter 625  trainloss -1942.47248  validloss -1616.74067±0.00000  bestvalidloss -2053.44511  last_update 4\n",
      "train: iter 626  trainloss -2069.62465  validloss -1977.45527±0.00000  bestvalidloss -2053.44511  last_update 5\n",
      "train: iter 627  trainloss -2079.47527  validloss -2040.15367±0.00000  bestvalidloss -2053.44511  last_update 6\n",
      "train: iter 628  trainloss -2069.03617  validloss -2026.29415±0.00000  bestvalidloss -2053.44511  last_update 7\n",
      "train: iter 629  trainloss -2092.78359  validloss -2037.34722±0.00000  bestvalidloss -2053.44511  last_update 8\n",
      "train: iter 630  trainloss -2033.51341  validloss -1964.05938±0.00000  bestvalidloss -2053.44511  last_update 9\n",
      "train: iter 631  trainloss -2064.90915  validloss -1982.25071±0.00000  bestvalidloss -2053.44511  last_update 10\n",
      "train: iter 632  trainloss -2071.29553  validloss -2031.28740±0.00000  bestvalidloss -2053.44511  last_update 11\n",
      "train: iter 633  trainloss -2096.96122  validloss -2021.11426±0.00000  bestvalidloss -2053.44511  last_update 12\n",
      "train: iter 634  trainloss -2091.52821  validloss -2003.75665±0.00000  bestvalidloss -2053.44511  last_update 13\n",
      "train: iter 635  trainloss -1769.18383  validloss -2025.42924±0.00000  bestvalidloss -2053.44511  last_update 14\n",
      "train: iter 636  trainloss -2059.50055  validloss -1943.30680±0.00000  bestvalidloss -2053.44511  last_update 15\n",
      "train: iter 637  trainloss -2056.29077  validloss -1998.04969±0.00000  bestvalidloss -2053.44511  last_update 16\n",
      "train: iter 638  trainloss -2087.00231  validloss -2031.47909±0.00000  bestvalidloss -2053.44511  last_update 17\n",
      "train: iter 639  trainloss -2067.56722  validloss -2014.37352±0.00000  bestvalidloss -2053.44511  last_update 18\n",
      "train: iter 640  trainloss -2091.74368  validloss -1992.66453±0.00000  bestvalidloss -2053.44511  last_update 19\n",
      "train: iter 641  trainloss -2068.31153  validloss -2015.07952±0.00000  bestvalidloss -2053.44511  last_update 20\n",
      "train: iter 642  trainloss -1851.21661  validloss -1942.74464±0.00000  bestvalidloss -2053.44511  last_update 21\n",
      "train: iter 643  trainloss -2041.33452  validloss -1905.74424±0.00000  bestvalidloss -2053.44511  last_update 22\n",
      "train: iter 644  trainloss -2047.69043  validloss -2016.62560±0.00000  bestvalidloss -2053.44511  last_update 23\n",
      "train: iter 645  trainloss -2082.46222  validloss -2018.12569±0.00000  bestvalidloss -2053.44511  last_update 24\n",
      "train: iter 646  trainloss -1990.88240  validloss -2028.74001±0.00000  bestvalidloss -2053.44511  last_update 25\n",
      "train: iter 647  trainloss -2083.66631  validloss -2026.00705±0.00000  bestvalidloss -2053.44511  last_update 26\n",
      "train: iter 648  trainloss -2078.96819  validloss -2001.04968±0.00000  bestvalidloss -2053.44511  last_update 27\n",
      "train: iter 649  trainloss -2080.07462  validloss -2037.28105±0.00000  bestvalidloss -2053.44511  last_update 28\n",
      "train: iter 650  trainloss -1948.96354  validloss -2017.23907±0.00000  bestvalidloss -2053.44511  last_update 29\n",
      "train: iter 651  trainloss -2028.63014  validloss -1991.94346±0.00000  bestvalidloss -2053.44511  last_update 30\n",
      "train: iter 652  trainloss -1998.55473  validloss -1996.14127±0.00000  bestvalidloss -2053.44511  last_update 31\n",
      "train: iter 653  trainloss -2015.86787  validloss -2025.61522±0.00000  bestvalidloss -2053.44511  last_update 32\n",
      "train: iter 654  trainloss -2096.91236  validloss -2023.15791±0.00000  bestvalidloss -2053.44511  last_update 33\n",
      "train: iter 655  trainloss -2094.92459  validloss -2049.52644±0.00000  bestvalidloss -2053.44511  last_update 34\n",
      "train: iter 656  trainloss -2021.62774  validloss -1983.66891±0.00000  bestvalidloss -2053.44511  last_update 35\n",
      "train: iter 657  trainloss -2062.15396  validloss -1796.14343±0.00000  bestvalidloss -2053.44511  last_update 36\n",
      "train: iter 658  trainloss -1722.43419  validloss -2026.28723±0.00000  bestvalidloss -2053.44511  last_update 37\n",
      "train: iter 659  trainloss -1958.81854  validloss -1417.12579±0.00000  bestvalidloss -2053.44511  last_update 38\n",
      "train: iter 660  trainloss -2066.85903  validloss -1995.30211±0.00000  bestvalidloss -2053.44511  last_update 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 661  trainloss -2077.48575  validloss -2008.13497±0.00000  bestvalidloss -2053.44511  last_update 40\n",
      "train: iter 662  trainloss -2079.63797  validloss -2024.07134±0.00000  bestvalidloss -2053.44511  last_update 41\n",
      "train: iter 663  trainloss -2065.72099  validloss -1990.42716±0.00000  bestvalidloss -2053.44511  last_update 42\n",
      "train: iter 664  trainloss -1941.11623  validloss -1924.33683±0.00000  bestvalidloss -2053.44511  last_update 43\n",
      "train: iter 665  trainloss -2014.97297  validloss -1735.40660±0.00000  bestvalidloss -2053.44511  last_update 44\n",
      "train: iter 666  trainloss -2041.25397  validloss -1983.96897±0.00000  bestvalidloss -2053.44511  last_update 45\n",
      "train: iter 667  trainloss -1975.95128  validloss -2037.65580±0.00000  bestvalidloss -2053.44511  last_update 46\n",
      "train: iter 668  trainloss -2070.17751  validloss -1971.64332±0.00000  bestvalidloss -2053.44511  last_update 47\n",
      "train: iter 669  trainloss -2025.84422  validloss -1848.08702±0.00000  bestvalidloss -2053.44511  last_update 48\n",
      "train: iter 670  trainloss -2051.29704  validloss -1976.79451±0.00000  bestvalidloss -2053.44511  last_update 49\n",
      "train: iter 671  trainloss -2093.63430  validloss -2019.33885±0.00000  bestvalidloss -2053.44511  last_update 50\n",
      "train: iter 672  trainloss -2053.25870  validloss -1998.17042±0.00000  bestvalidloss -2053.44511  last_update 51\n",
      "train: iter 673  trainloss -2097.80930  validloss -2005.48740±0.00000  bestvalidloss -2053.44511  last_update 52\n",
      "train: iter 674  trainloss -2099.29912  validloss -1963.81917±0.00000  bestvalidloss -2053.44511  last_update 53\n",
      "train: iter 675  trainloss -2033.58238  validloss -2037.17078±0.00000  bestvalidloss -2053.44511  last_update 54\n",
      "train: iter 676  trainloss -1966.71850  validloss -1938.65676±0.00000  bestvalidloss -2053.44511  last_update 55\n",
      "train: iter 677  trainloss -2074.11621  validloss -1955.45165±0.00000  bestvalidloss -2053.44511  last_update 56\n",
      "train: iter 678  trainloss -2097.30306  validloss -1988.61674±0.00000  bestvalidloss -2053.44511  last_update 57\n",
      "train: iter 679  trainloss -2086.31540  validloss -2016.23665±0.00000  bestvalidloss -2053.44511  last_update 58\n",
      "train: iter 680  trainloss -2085.55170  validloss -2023.21036±0.00000  bestvalidloss -2053.44511  last_update 59\n",
      "train: iter 681  trainloss -1892.17428  validloss -2030.58096±0.00000  bestvalidloss -2053.44511  last_update 60\n",
      "train: iter 682  trainloss -2011.40605  validloss -1568.58010±0.00000  bestvalidloss -2053.44511  last_update 61\n",
      "train: iter 683  trainloss -2076.27655  validloss -2006.30058±0.00000  bestvalidloss -2053.44511  last_update 62\n",
      "train: iter 684  trainloss -1975.00282  validloss -2025.62795±0.00000  bestvalidloss -2053.44511  last_update 63\n",
      "train: iter 685  trainloss -1552.59019  validloss -1735.85634±0.00000  bestvalidloss -2053.44511  last_update 64\n",
      "train: iter 686  trainloss -2036.04609  validloss -1986.96968±0.00000  bestvalidloss -2053.44511  last_update 65\n",
      "train: iter 687  trainloss -2061.37128  validloss -2014.13316±0.00000  bestvalidloss -2053.44511  last_update 66\n",
      "train: iter 688  trainloss -2054.25823  validloss -2009.72936±0.00000  bestvalidloss -2053.44511  last_update 67\n",
      "train: iter 689  trainloss -2043.87955  validloss -1997.51015±0.00000  bestvalidloss -2053.44511  last_update 68\n",
      "train: iter 690  trainloss -2047.39878  validloss -2032.04639±0.00000  bestvalidloss -2053.44511  last_update 69\n",
      "train: iter 691  trainloss -2070.96107  validloss -2018.55154±0.00000  bestvalidloss -2053.44511  last_update 70\n",
      "train: iter 692  trainloss -1990.91613  validloss -1941.27352±0.00000  bestvalidloss -2053.44511  last_update 71\n",
      "train: iter 693  trainloss -2093.74468  validloss -2020.71024±0.00000  bestvalidloss -2053.44511  last_update 72\n",
      "train: iter 694  trainloss -2062.13518  validloss -2023.93279±0.00000  bestvalidloss -2053.44511  last_update 73\n",
      "train: iter 695  trainloss -2067.46189  validloss -2000.78607±0.00000  bestvalidloss -2053.44511  last_update 74\n",
      "train: iter 696  trainloss -2072.33685  validloss -2008.61334±0.00000  bestvalidloss -2053.44511  last_update 75\n",
      "train: iter 697  trainloss -1938.55930  validloss -2038.03917±0.00000  bestvalidloss -2053.44511  last_update 76\n",
      "train: iter 698  trainloss -2037.65413  validloss -1964.87222±0.00000  bestvalidloss -2053.44511  last_update 77\n",
      "train: iter 699  trainloss -2071.41318  validloss -2035.58770±0.00000  bestvalidloss -2053.44511  last_update 78\n",
      "train: iter 700  trainloss -2098.93133  validloss -2029.71011±0.00000  bestvalidloss -2053.44511  last_update 79\n",
      "train: iter 701  trainloss -2096.61086  validloss -2035.50507±0.00000  bestvalidloss -2053.44511  last_update 80\n",
      "train: iter 702  trainloss -1858.22466  validloss -1988.66267±0.00000  bestvalidloss -2053.44511  last_update 81\n",
      "train: iter 703  trainloss -2078.35468  validloss -2031.17957±0.00000  bestvalidloss -2053.44511  last_update 82\n",
      "train: iter 704  trainloss -2034.26230  validloss -1977.81006±0.00000  bestvalidloss -2053.44511  last_update 83\n",
      "train: iter 705  trainloss -2068.95030  validloss -2025.10906±0.00000  bestvalidloss -2053.44511  last_update 84\n",
      "train: iter 706  trainloss -1883.46829  validloss -1996.15573±0.00000  bestvalidloss -2053.44511  last_update 85\n",
      "train: iter 707  trainloss -1633.00601  validloss -1060.26057±0.00000  bestvalidloss -2053.44511  last_update 86\n",
      "train: iter 708  trainloss -2053.65741  validloss -2017.83683±0.00000  bestvalidloss -2053.44511  last_update 87\n",
      "train: iter 709  trainloss -2080.25784  validloss -1966.55480±0.00000  bestvalidloss -2053.44511  last_update 88\n",
      "train: iter 710  trainloss -2009.31241  validloss -2025.12858±0.00000  bestvalidloss -2053.44511  last_update 89\n",
      "train: iter 711  trainloss -1945.51565  validloss -2020.74175±0.00000  bestvalidloss -2053.44511  last_update 90\n",
      "train: iter 712  trainloss -1998.71211  validloss -1718.28701±0.00000  bestvalidloss -2053.44511  last_update 91\n",
      "train: iter 713  trainloss -2084.28247  validloss -1996.59736±0.00000  bestvalidloss -2053.44511  last_update 92\n",
      "train: iter 714  trainloss -2051.19269  validloss -2025.18826±0.00000  bestvalidloss -2053.44511  last_update 93\n",
      "train: iter 715  trainloss -2099.10282  validloss -2045.95201±0.00000  bestvalidloss -2053.44511  last_update 94\n",
      "train: iter 716  trainloss -2088.68123  validloss -2015.36289±0.00000  bestvalidloss -2053.44511  last_update 95\n",
      "train: iter 717  trainloss -2092.78752  validloss -2042.00890±0.00000  bestvalidloss -2053.44511  last_update 96\n",
      "train: iter 718  trainloss -2092.29488  validloss -2012.54868±0.00000  bestvalidloss -2053.44511  last_update 97\n",
      "train: iter 719  trainloss -2052.37908  validloss -2036.76150±0.00000  bestvalidloss -2053.44511  last_update 98\n",
      "train: iter 720  trainloss -2077.62471  validloss -2014.78033±0.00000  bestvalidloss -2053.44511  last_update 99\n",
      "train: iter 721  trainloss -2027.40279  validloss -1986.05970±0.00000  bestvalidloss -2053.44511  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3081) penalty_target_max tensor(-3.0287)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 5.24595  validloss 5.47176±0.00000  bestvalidloss 5.47176  last_update 0\n",
      "train: iter 1  trainloss 4.83215  validloss 5.04838±0.00000  bestvalidloss 5.04838  last_update 0\n",
      "train: iter 2  trainloss 4.48918  validloss 4.68891±0.00000  bestvalidloss 4.68891  last_update 0\n",
      "train: iter 3  trainloss 4.19165  validloss 4.34984±0.00000  bestvalidloss 4.34984  last_update 0\n",
      "train: iter 4  trainloss 3.91415  validloss 4.05729±0.00000  bestvalidloss 4.05729  last_update 0\n",
      "train: iter 5  trainloss 3.67754  validloss 3.79873±0.00000  bestvalidloss 3.79873  last_update 0\n",
      "train: iter 6  trainloss 3.45115  validloss 3.56447±0.00000  bestvalidloss 3.56447  last_update 0\n",
      "train: iter 7  trainloss 3.24137  validloss 3.35904±0.00000  bestvalidloss 3.35904  last_update 0\n",
      "train: iter 8  trainloss 3.04717  validloss 3.15761±0.00000  bestvalidloss 3.15761  last_update 0\n",
      "train: iter 9  trainloss 2.87067  validloss 2.97101±0.00000  bestvalidloss 2.97101  last_update 0\n",
      "train: iter 10  trainloss 2.71450  validloss 2.79435±0.00000  bestvalidloss 2.79435  last_update 0\n",
      "train: iter 11  trainloss 2.56138  validloss 2.64861±0.00000  bestvalidloss 2.64861  last_update 0\n",
      "train: iter 12  trainloss 2.42252  validloss 2.50032±0.00000  bestvalidloss 2.50032  last_update 0\n",
      "train: iter 13  trainloss 2.30158  validloss 2.36866±0.00000  bestvalidloss 2.36866  last_update 0\n",
      "train: iter 14  trainloss 2.19290  validloss 2.24353±0.00000  bestvalidloss 2.24353  last_update 0\n",
      "train: iter 15  trainloss 2.09115  validloss 2.13558±0.00000  bestvalidloss 2.13558  last_update 0\n",
      "train: iter 16  trainloss 2.00085  validloss 2.03873±0.00000  bestvalidloss 2.03873  last_update 0\n",
      "train: iter 17  trainloss 1.91375  validloss 1.95094±0.00000  bestvalidloss 1.95094  last_update 0\n",
      "train: iter 18  trainloss 1.83541  validloss 1.86553±0.00000  bestvalidloss 1.86553  last_update 0\n",
      "train: iter 19  trainloss 1.75610  validloss 1.78729±0.00000  bestvalidloss 1.78729  last_update 0\n",
      "train: iter 20  trainloss 1.68025  validloss 1.70895±0.00000  bestvalidloss 1.70895  last_update 0\n",
      "train: iter 21  trainloss 1.60848  validloss 1.63108±0.00000  bestvalidloss 1.63108  last_update 0\n",
      "train: iter 22  trainloss 1.53232  validloss 1.55219±0.00000  bestvalidloss 1.55219  last_update 0\n",
      "train: iter 23  trainloss 1.45778  validloss 1.47955±0.00000  bestvalidloss 1.47955  last_update 0\n",
      "train: iter 24  trainloss 1.39033  validloss 1.40333±0.00000  bestvalidloss 1.40333  last_update 0\n",
      "train: iter 25  trainloss 1.31973  validloss 1.32424±0.00000  bestvalidloss 1.32424  last_update 0\n",
      "train: iter 26  trainloss 1.25333  validloss 1.26166±0.00000  bestvalidloss 1.26166  last_update 0\n",
      "train: iter 27  trainloss 1.17491  validloss 1.18209±0.00000  bestvalidloss 1.18209  last_update 0\n",
      "train: iter 28  trainloss 1.10306  validloss 1.11570±0.00000  bestvalidloss 1.11570  last_update 0\n",
      "train: iter 29  trainloss 1.02895  validloss 1.03824±0.00000  bestvalidloss 1.03824  last_update 0\n",
      "train: iter 30  trainloss 0.95721  validloss 0.94870±0.00000  bestvalidloss 0.94870  last_update 0\n",
      "train: iter 31  trainloss 0.88806  validloss 0.88440±0.00000  bestvalidloss 0.88440  last_update 0\n",
      "train: iter 32  trainloss 0.80167  validloss 0.80261±0.00000  bestvalidloss 0.80261  last_update 0\n",
      "train: iter 33  trainloss 0.73731  validloss 0.72664±0.00000  bestvalidloss 0.72664  last_update 0\n",
      "train: iter 34  trainloss 0.65848  validloss 0.64315±0.00000  bestvalidloss 0.64315  last_update 0\n",
      "train: iter 35  trainloss 0.58123  validloss 0.56534±0.00000  bestvalidloss 0.56534  last_update 0\n",
      "train: iter 36  trainloss 0.49716  validloss 0.48916±0.00000  bestvalidloss 0.48916  last_update 0\n",
      "train: iter 37  trainloss 0.41587  validloss 0.41420±0.00000  bestvalidloss 0.41420  last_update 0\n",
      "train: iter 38  trainloss 0.34599  validloss 0.32300±0.00000  bestvalidloss 0.32300  last_update 0\n",
      "train: iter 39  trainloss 0.26293  validloss 0.23521±0.00000  bestvalidloss 0.23521  last_update 0\n",
      "train: iter 40  trainloss 0.19458  validloss 0.15900±0.00000  bestvalidloss 0.15900  last_update 0\n",
      "train: iter 41  trainloss 0.11760  validloss 0.07792±0.00000  bestvalidloss 0.07792  last_update 0\n",
      "train: iter 42  trainloss 0.03769  validloss 0.00451±0.00000  bestvalidloss 0.00451  last_update 0\n",
      "train: iter 43  trainloss -0.01452  validloss -0.09691±0.00000  bestvalidloss -0.09691  last_update 0\n",
      "train: iter 44  trainloss -0.08489  validloss -0.15842±0.00000  bestvalidloss -0.15842  last_update 0\n",
      "train: iter 45  trainloss -0.15023  validloss -0.20981±0.00000  bestvalidloss -0.20981  last_update 0\n",
      "train: iter 46  trainloss -0.21144  validloss -0.30398±0.00000  bestvalidloss -0.30398  last_update 0\n",
      "train: iter 47  trainloss -0.28969  validloss -0.36047±0.00000  bestvalidloss -0.36047  last_update 0\n",
      "train: iter 48  trainloss -0.33107  validloss -0.43271±0.00000  bestvalidloss -0.43271  last_update 0\n",
      "train: iter 49  trainloss -0.38289  validloss -0.47850±0.00000  bestvalidloss -0.47850  last_update 0\n",
      "train: iter 50  trainloss -0.41801  validloss -0.53913±0.00000  bestvalidloss -0.53913  last_update 0\n",
      "train: iter 51  trainloss -0.47956  validloss -0.62179±0.00000  bestvalidloss -0.62179  last_update 0\n",
      "train: iter 52  trainloss -0.57166  validloss -0.63489±0.00000  bestvalidloss -0.63489  last_update 0\n",
      "train: iter 53  trainloss -0.57060  validloss -0.68540±0.00000  bestvalidloss -0.68540  last_update 0\n",
      "train: iter 54  trainloss -0.63640  validloss -0.75827±0.00000  bestvalidloss -0.75827  last_update 0\n",
      "train: iter 55  trainloss -0.71185  validloss -0.81567±0.00000  bestvalidloss -0.81567  last_update 0\n",
      "train: iter 56  trainloss -0.73376  validloss -0.84720±0.00000  bestvalidloss -0.84720  last_update 0\n",
      "train: iter 57  trainloss -0.74488  validloss -0.92379±0.00000  bestvalidloss -0.92379  last_update 0\n",
      "train: iter 58  trainloss -0.80799  validloss -0.97490±0.00000  bestvalidloss -0.97490  last_update 0\n",
      "train: iter 59  trainloss -0.85072  validloss -1.03666±0.00000  bestvalidloss -1.03666  last_update 0\n",
      "train: iter 60  trainloss -0.86011  validloss -1.07222±0.00000  bestvalidloss -1.07222  last_update 0\n",
      "train: iter 61  trainloss -0.93719  validloss -1.13679±0.00000  bestvalidloss -1.13679  last_update 0\n",
      "train: iter 62  trainloss -0.96567  validloss -1.14211±0.00000  bestvalidloss -1.14211  last_update 0\n",
      "train: iter 63  trainloss -1.00454  validloss -1.16901±0.00000  bestvalidloss -1.16901  last_update 0\n",
      "train: iter 64  trainloss -1.07332  validloss -1.22825±0.00000  bestvalidloss -1.22825  last_update 0\n",
      "train: iter 65  trainloss -1.11155  validloss -1.32825±0.00000  bestvalidloss -1.32825  last_update 0\n",
      "train: iter 66  trainloss -1.14044  validloss -1.39048±0.00000  bestvalidloss -1.39048  last_update 0\n",
      "train: iter 67  trainloss -1.16113  validloss -1.34212±0.00000  bestvalidloss -1.39048  last_update 1\n",
      "train: iter 68  trainloss -1.18223  validloss -1.41392±0.00000  bestvalidloss -1.41392  last_update 0\n",
      "train: iter 69  trainloss -1.21189  validloss -1.43858±0.00000  bestvalidloss -1.43858  last_update 0\n",
      "train: iter 70  trainloss -1.31910  validloss -1.51134±0.00000  bestvalidloss -1.51134  last_update 0\n",
      "train: iter 71  trainloss -1.30275  validloss -1.50489±0.00000  bestvalidloss -1.51134  last_update 1\n",
      "train: iter 72  trainloss -1.33971  validloss -1.57524±0.00000  bestvalidloss -1.57524  last_update 0\n",
      "train: iter 73  trainloss -1.39148  validloss -1.62205±0.00000  bestvalidloss -1.62205  last_update 0\n",
      "train: iter 74  trainloss -1.41394  validloss -1.69673±0.00000  bestvalidloss -1.69673  last_update 0\n",
      "train: iter 75  trainloss -1.42978  validloss -1.70123±0.00000  bestvalidloss -1.70123  last_update 0\n",
      "train: iter 76  trainloss -1.49207  validloss -1.69929±0.00000  bestvalidloss -1.70123  last_update 1\n",
      "train: iter 77  trainloss -1.49544  validloss -1.74734±0.00000  bestvalidloss -1.74734  last_update 0\n",
      "train: iter 78  trainloss -1.56676  validloss -1.79785±0.00000  bestvalidloss -1.79785  last_update 0\n",
      "train: iter 79  trainloss -1.59055  validloss -1.80366±0.00000  bestvalidloss -1.80366  last_update 0\n",
      "train: iter 80  trainloss -1.59881  validloss -1.88046±0.00000  bestvalidloss -1.88046  last_update 0\n",
      "train: iter 81  trainloss -1.63554  validloss -1.87233±0.00000  bestvalidloss -1.88046  last_update 1\n",
      "train: iter 82  trainloss -1.68931  validloss -1.93741±0.00000  bestvalidloss -1.93741  last_update 0\n",
      "train: iter 83  trainloss -1.67424  validloss -2.04211±0.00000  bestvalidloss -2.04211  last_update 0\n",
      "train: iter 84  trainloss -1.71024  validloss -1.98542±0.00000  bestvalidloss -2.04211  last_update 1\n",
      "train: iter 85  trainloss -1.72506  validloss -2.03790±0.00000  bestvalidloss -2.04211  last_update 2\n",
      "train: iter 86  trainloss -1.76163  validloss -2.05355±0.00000  bestvalidloss -2.05355  last_update 0\n",
      "train: iter 87  trainloss -1.76689  validloss -2.09348±0.00000  bestvalidloss -2.09348  last_update 0\n",
      "train: iter 88  trainloss -1.77750  validloss -2.07048±0.00000  bestvalidloss -2.09348  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 89  trainloss -1.86000  validloss -2.15404±0.00000  bestvalidloss -2.15404  last_update 0\n",
      "train: iter 90  trainloss -1.85706  validloss -2.13943±0.00000  bestvalidloss -2.15404  last_update 1\n",
      "train: iter 91  trainloss -1.85230  validloss -2.21852±0.00000  bestvalidloss -2.21852  last_update 0\n",
      "train: iter 92  trainloss -1.86518  validloss -2.24358±0.00000  bestvalidloss -2.24358  last_update 0\n",
      "train: iter 93  trainloss -1.92436  validloss -2.20512±0.00000  bestvalidloss -2.24358  last_update 1\n",
      "train: iter 94  trainloss -1.92885  validloss -2.29552±0.00000  bestvalidloss -2.29552  last_update 0\n",
      "train: iter 95  trainloss -1.92443  validloss -2.30112±0.00000  bestvalidloss -2.30112  last_update 0\n",
      "train: iter 96  trainloss -1.93072  validloss -2.34619±0.00000  bestvalidloss -2.34619  last_update 0\n",
      "train: iter 97  trainloss -1.95478  validloss -2.34153±0.00000  bestvalidloss -2.34619  last_update 1\n",
      "train: iter 98  trainloss -1.96627  validloss -2.34798±0.00000  bestvalidloss -2.34798  last_update 0\n",
      "train: iter 99  trainloss -1.99520  validloss -2.36586±0.00000  bestvalidloss -2.36586  last_update 0\n",
      "train: iter 100  trainloss -1.95654  validloss -2.34382±0.00000  bestvalidloss -2.36586  last_update 1\n",
      "train: iter 101  trainloss -1.96417  validloss -2.44393±0.00000  bestvalidloss -2.44393  last_update 0\n",
      "train: iter 102  trainloss -1.99161  validloss -2.41610±0.00000  bestvalidloss -2.44393  last_update 1\n",
      "train: iter 103  trainloss -2.04697  validloss -2.40912±0.00000  bestvalidloss -2.44393  last_update 2\n",
      "train: iter 104  trainloss -2.00266  validloss -2.40333±0.00000  bestvalidloss -2.44393  last_update 3\n",
      "train: iter 105  trainloss -1.97303  validloss -2.41154±0.00000  bestvalidloss -2.44393  last_update 4\n",
      "train: iter 106  trainloss -1.97716  validloss -2.47974±0.00000  bestvalidloss -2.47974  last_update 0\n",
      "train: iter 107  trainloss -2.03138  validloss -2.44263±0.00000  bestvalidloss -2.47974  last_update 1\n",
      "train: iter 108  trainloss -2.07970  validloss -2.53630±0.00000  bestvalidloss -2.53630  last_update 0\n",
      "train: iter 109  trainloss -2.08142  validloss -2.50729±0.00000  bestvalidloss -2.53630  last_update 1\n",
      "train: iter 110  trainloss -2.05706  validloss -2.51165±0.00000  bestvalidloss -2.53630  last_update 2\n",
      "train: iter 111  trainloss -2.03286  validloss -2.55190±0.00000  bestvalidloss -2.55190  last_update 0\n",
      "train: iter 112  trainloss -1.98658  validloss -2.56375±0.00000  bestvalidloss -2.56375  last_update 0\n",
      "train: iter 113  trainloss -2.06391  validloss -2.54141±0.00000  bestvalidloss -2.56375  last_update 1\n",
      "train: iter 114  trainloss -2.06903  validloss -2.47835±0.00000  bestvalidloss -2.56375  last_update 2\n",
      "train: iter 115  trainloss -1.98513  validloss -2.53984±0.00000  bestvalidloss -2.56375  last_update 3\n",
      "train: iter 116  trainloss -2.05025  validloss -2.55845±0.00000  bestvalidloss -2.56375  last_update 4\n",
      "train: iter 117  trainloss -2.01415  validloss -2.53437±0.00000  bestvalidloss -2.56375  last_update 5\n",
      "train: iter 118  trainloss -2.00430  validloss -2.55931±0.00000  bestvalidloss -2.56375  last_update 6\n",
      "train: iter 119  trainloss -2.05076  validloss -2.54458±0.00000  bestvalidloss -2.56375  last_update 7\n",
      "train: iter 120  trainloss -2.05271  validloss -2.53392±0.00000  bestvalidloss -2.56375  last_update 8\n",
      "train: iter 121  trainloss -2.07445  validloss -2.58226±0.00000  bestvalidloss -2.58226  last_update 0\n",
      "train: iter 122  trainloss -2.04278  validloss -2.61270±0.00000  bestvalidloss -2.61270  last_update 0\n",
      "train: iter 123  trainloss -2.03404  validloss -2.59462±0.00000  bestvalidloss -2.61270  last_update 1\n",
      "train: iter 124  trainloss -2.03306  validloss -2.53659±0.00000  bestvalidloss -2.61270  last_update 2\n",
      "train: iter 125  trainloss -2.01080  validloss -2.52576±0.00000  bestvalidloss -2.61270  last_update 3\n",
      "train: iter 126  trainloss -2.02424  validloss -2.54102±0.00000  bestvalidloss -2.61270  last_update 4\n",
      "train: iter 127  trainloss -2.02693  validloss -2.65110±0.00000  bestvalidloss -2.65110  last_update 0\n",
      "train: iter 128  trainloss -2.07636  validloss -2.60196±0.00000  bestvalidloss -2.65110  last_update 1\n",
      "train: iter 129  trainloss -2.01043  validloss -2.63630±0.00000  bestvalidloss -2.65110  last_update 2\n",
      "train: iter 130  trainloss -2.09284  validloss -2.61051±0.00000  bestvalidloss -2.65110  last_update 3\n",
      "train: iter 131  trainloss -2.04057  validloss -2.50301±0.00000  bestvalidloss -2.65110  last_update 4\n",
      "train: iter 132  trainloss -2.04693  validloss -2.59640±0.00000  bestvalidloss -2.65110  last_update 5\n",
      "train: iter 133  trainloss -2.10561  validloss -2.55327±0.00000  bestvalidloss -2.65110  last_update 6\n",
      "train: iter 134  trainloss -2.00676  validloss -2.62635±0.00000  bestvalidloss -2.65110  last_update 7\n",
      "train: iter 135  trainloss -2.07342  validloss -2.62964±0.00000  bestvalidloss -2.65110  last_update 8\n",
      "train: iter 136  trainloss -2.05349  validloss -2.59683±0.00000  bestvalidloss -2.65110  last_update 9\n",
      "train: iter 137  trainloss -2.05350  validloss -2.60668±0.00000  bestvalidloss -2.65110  last_update 10\n",
      "train: iter 138  trainloss -2.08965  validloss -2.57178±0.00000  bestvalidloss -2.65110  last_update 11\n",
      "train: iter 139  trainloss -2.11957  validloss -2.66042±0.00000  bestvalidloss -2.66042  last_update 0\n",
      "train: iter 140  trainloss -2.06478  validloss -2.57700±0.00000  bestvalidloss -2.66042  last_update 1\n",
      "train: iter 141  trainloss -2.07011  validloss -2.54401±0.00000  bestvalidloss -2.66042  last_update 2\n",
      "train: iter 142  trainloss -2.04722  validloss -2.64017±0.00000  bestvalidloss -2.66042  last_update 3\n",
      "train: iter 143  trainloss -2.04806  validloss -2.64229±0.00000  bestvalidloss -2.66042  last_update 4\n",
      "train: iter 144  trainloss -2.09082  validloss -2.63032±0.00000  bestvalidloss -2.66042  last_update 5\n",
      "train: iter 145  trainloss -2.00072  validloss -2.60496±0.00000  bestvalidloss -2.66042  last_update 6\n",
      "train: iter 146  trainloss -2.05785  validloss -2.61533±0.00000  bestvalidloss -2.66042  last_update 7\n",
      "train: iter 147  trainloss -2.08615  validloss -2.66513±0.00000  bestvalidloss -2.66513  last_update 0\n",
      "train: iter 148  trainloss -2.05307  validloss -2.54082±0.00000  bestvalidloss -2.66513  last_update 1\n",
      "train: iter 149  trainloss -2.03454  validloss -2.55543±0.00000  bestvalidloss -2.66513  last_update 2\n",
      "train: iter 150  trainloss -2.05631  validloss -2.67154±0.00000  bestvalidloss -2.67154  last_update 0\n",
      "train: iter 151  trainloss -2.08848  validloss -2.59129±0.00000  bestvalidloss -2.67154  last_update 1\n",
      "train: iter 152  trainloss -2.10632  validloss -2.66237±0.00000  bestvalidloss -2.67154  last_update 2\n",
      "train: iter 153  trainloss -2.03878  validloss -2.69516±0.00000  bestvalidloss -2.69516  last_update 0\n",
      "train: iter 154  trainloss -2.06709  validloss -2.66979±0.00000  bestvalidloss -2.69516  last_update 1\n",
      "train: iter 155  trainloss -2.10392  validloss -2.63172±0.00000  bestvalidloss -2.69516  last_update 2\n",
      "train: iter 156  trainloss -2.08803  validloss -2.68397±0.00000  bestvalidloss -2.69516  last_update 3\n",
      "train: iter 157  trainloss -2.05323  validloss -2.65762±0.00000  bestvalidloss -2.69516  last_update 4\n",
      "train: iter 158  trainloss -2.04651  validloss -2.56008±0.00000  bestvalidloss -2.69516  last_update 5\n",
      "train: iter 159  trainloss -1.99710  validloss -2.65653±0.00000  bestvalidloss -2.69516  last_update 6\n",
      "train: iter 160  trainloss -2.04309  validloss -2.62632±0.00000  bestvalidloss -2.69516  last_update 7\n",
      "train: iter 161  trainloss -1.96284  validloss -2.64727±0.00000  bestvalidloss -2.69516  last_update 8\n",
      "train: iter 162  trainloss -2.09761  validloss -2.69022±0.00000  bestvalidloss -2.69516  last_update 9\n",
      "train: iter 163  trainloss -1.99534  validloss -2.69016±0.00000  bestvalidloss -2.69516  last_update 10\n",
      "train: iter 164  trainloss -2.04305  validloss -2.62727±0.00000  bestvalidloss -2.69516  last_update 11\n",
      "train: iter 165  trainloss -2.07346  validloss -2.65326±0.00000  bestvalidloss -2.69516  last_update 12\n",
      "train: iter 166  trainloss -2.01013  validloss -2.63222±0.00000  bestvalidloss -2.69516  last_update 13\n",
      "train: iter 167  trainloss -2.09319  validloss -2.62382±0.00000  bestvalidloss -2.69516  last_update 14\n",
      "train: iter 168  trainloss -1.99265  validloss -2.63068±0.00000  bestvalidloss -2.69516  last_update 15\n",
      "train: iter 169  trainloss -2.08671  validloss -2.56486±0.00000  bestvalidloss -2.69516  last_update 16\n",
      "train: iter 170  trainloss -2.05273  validloss -2.55625±0.00000  bestvalidloss -2.69516  last_update 17\n",
      "train: iter 171  trainloss -2.03268  validloss -2.64251±0.00000  bestvalidloss -2.69516  last_update 18\n",
      "train: iter 172  trainloss -2.04890  validloss -2.68066±0.00000  bestvalidloss -2.69516  last_update 19\n",
      "train: iter 173  trainloss -2.08730  validloss -2.58702±0.00000  bestvalidloss -2.69516  last_update 20\n",
      "train: iter 174  trainloss -2.07688  validloss -2.59861±0.00000  bestvalidloss -2.69516  last_update 21\n",
      "train: iter 175  trainloss -2.06558  validloss -2.63982±0.00000  bestvalidloss -2.69516  last_update 22\n",
      "train: iter 176  trainloss -1.99717  validloss -2.63933±0.00000  bestvalidloss -2.69516  last_update 23\n",
      "train: iter 177  trainloss -1.99463  validloss -2.62405±0.00000  bestvalidloss -2.69516  last_update 24\n",
      "train: iter 178  trainloss -2.06973  validloss -2.65107±0.00000  bestvalidloss -2.69516  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 179  trainloss -2.05512  validloss -2.66797±0.00000  bestvalidloss -2.69516  last_update 26\n",
      "train: iter 180  trainloss -2.03714  validloss -2.54833±0.00000  bestvalidloss -2.69516  last_update 27\n",
      "train: iter 181  trainloss -2.08361  validloss -2.64579±0.00000  bestvalidloss -2.69516  last_update 28\n",
      "train: iter 182  trainloss -2.02975  validloss -2.59595±0.00000  bestvalidloss -2.69516  last_update 29\n",
      "train: iter 183  trainloss -2.05269  validloss -2.65329±0.00000  bestvalidloss -2.69516  last_update 30\n",
      "train: iter 184  trainloss -2.04845  validloss -2.61028±0.00000  bestvalidloss -2.69516  last_update 31\n",
      "train: iter 185  trainloss -2.03844  validloss -2.59700±0.00000  bestvalidloss -2.69516  last_update 32\n",
      "train: iter 186  trainloss -1.98922  validloss -2.63816±0.00000  bestvalidloss -2.69516  last_update 33\n",
      "train: iter 187  trainloss -2.05806  validloss -2.69744±0.00000  bestvalidloss -2.69744  last_update 0\n",
      "train: iter 188  trainloss -2.10579  validloss -2.63834±0.00000  bestvalidloss -2.69744  last_update 1\n",
      "train: iter 189  trainloss -2.02655  validloss -2.59995±0.00000  bestvalidloss -2.69744  last_update 2\n",
      "train: iter 190  trainloss -1.98986  validloss -2.61179±0.00000  bestvalidloss -2.69744  last_update 3\n",
      "train: iter 191  trainloss -2.11130  validloss -2.67605±0.00000  bestvalidloss -2.69744  last_update 4\n",
      "train: iter 192  trainloss -2.02738  validloss -2.66167±0.00000  bestvalidloss -2.69744  last_update 5\n",
      "train: iter 193  trainloss -2.03785  validloss -2.68287±0.00000  bestvalidloss -2.69744  last_update 6\n",
      "train: iter 194  trainloss -2.07327  validloss -2.65339±0.00000  bestvalidloss -2.69744  last_update 7\n",
      "train: iter 195  trainloss -2.03157  validloss -2.63545±0.00000  bestvalidloss -2.69744  last_update 8\n",
      "train: iter 196  trainloss -2.05490  validloss -2.63027±0.00000  bestvalidloss -2.69744  last_update 9\n",
      "train: iter 197  trainloss -2.02451  validloss -2.63531±0.00000  bestvalidloss -2.69744  last_update 10\n",
      "train: iter 198  trainloss -1.95380  validloss -2.66396±0.00000  bestvalidloss -2.69744  last_update 11\n",
      "train: iter 199  trainloss -2.03369  validloss -2.71713±0.00000  bestvalidloss -2.71713  last_update 0\n",
      "train: iter 200  trainloss -2.00340  validloss -2.54213±0.00000  bestvalidloss -2.71713  last_update 1\n",
      "train: iter 201  trainloss -2.04027  validloss -2.56745±0.00000  bestvalidloss -2.71713  last_update 2\n",
      "train: iter 202  trainloss -2.10471  validloss -2.55869±0.00000  bestvalidloss -2.71713  last_update 3\n",
      "train: iter 203  trainloss -2.08038  validloss -2.61652±0.00000  bestvalidloss -2.71713  last_update 4\n",
      "train: iter 204  trainloss -2.09810  validloss -2.65180±0.00000  bestvalidloss -2.71713  last_update 5\n",
      "train: iter 205  trainloss -2.03748  validloss -2.61479±0.00000  bestvalidloss -2.71713  last_update 6\n",
      "train: iter 206  trainloss -2.05029  validloss -2.70085±0.00000  bestvalidloss -2.71713  last_update 7\n",
      "train: iter 207  trainloss -2.08860  validloss -2.62894±0.00000  bestvalidloss -2.71713  last_update 8\n",
      "train: iter 208  trainloss -2.05153  validloss -2.63559±0.00000  bestvalidloss -2.71713  last_update 9\n",
      "train: iter 209  trainloss -2.03075  validloss -2.62333±0.00000  bestvalidloss -2.71713  last_update 10\n",
      "train: iter 210  trainloss -2.05720  validloss -2.56168±0.00000  bestvalidloss -2.71713  last_update 11\n",
      "train: iter 211  trainloss -2.06139  validloss -2.60297±0.00000  bestvalidloss -2.71713  last_update 12\n",
      "train: iter 212  trainloss -2.10802  validloss -2.64381±0.00000  bestvalidloss -2.71713  last_update 13\n",
      "train: iter 213  trainloss -2.08170  validloss -2.62299±0.00000  bestvalidloss -2.71713  last_update 14\n",
      "train: iter 214  trainloss -2.05055  validloss -2.69359±0.00000  bestvalidloss -2.71713  last_update 15\n",
      "train: iter 215  trainloss -2.05123  validloss -2.72661±0.00000  bestvalidloss -2.72661  last_update 0\n",
      "train: iter 216  trainloss -2.07783  validloss -2.61161±0.00000  bestvalidloss -2.72661  last_update 1\n",
      "train: iter 217  trainloss -2.04841  validloss -2.67076±0.00000  bestvalidloss -2.72661  last_update 2\n",
      "train: iter 218  trainloss -2.03505  validloss -2.59998±0.00000  bestvalidloss -2.72661  last_update 3\n",
      "train: iter 219  trainloss -2.04081  validloss -2.59704±0.00000  bestvalidloss -2.72661  last_update 4\n",
      "train: iter 220  trainloss -2.09409  validloss -2.56290±0.00000  bestvalidloss -2.72661  last_update 5\n",
      "train: iter 221  trainloss -2.04849  validloss -2.59859±0.00000  bestvalidloss -2.72661  last_update 6\n",
      "train: iter 222  trainloss -2.03747  validloss -2.56166±0.00000  bestvalidloss -2.72661  last_update 7\n",
      "train: iter 223  trainloss -2.09384  validloss -2.66534±0.00000  bestvalidloss -2.72661  last_update 8\n",
      "train: iter 224  trainloss -2.11762  validloss -2.67186±0.00000  bestvalidloss -2.72661  last_update 9\n",
      "train: iter 225  trainloss -2.06888  validloss -2.60931±0.00000  bestvalidloss -2.72661  last_update 10\n",
      "train: iter 226  trainloss -2.02687  validloss -2.63123±0.00000  bestvalidloss -2.72661  last_update 11\n",
      "train: iter 227  trainloss -2.05933  validloss -2.62259±0.00000  bestvalidloss -2.72661  last_update 12\n",
      "train: iter 228  trainloss -2.10422  validloss -2.64439±0.00000  bestvalidloss -2.72661  last_update 13\n",
      "train: iter 229  trainloss -2.01995  validloss -2.60879±0.00000  bestvalidloss -2.72661  last_update 14\n",
      "train: iter 230  trainloss -2.00457  validloss -2.65897±0.00000  bestvalidloss -2.72661  last_update 15\n",
      "train: iter 231  trainloss -2.04279  validloss -2.62087±0.00000  bestvalidloss -2.72661  last_update 16\n",
      "train: iter 232  trainloss -2.02950  validloss -2.70648±0.00000  bestvalidloss -2.72661  last_update 17\n",
      "train: iter 233  trainloss -2.00529  validloss -2.58313±0.00000  bestvalidloss -2.72661  last_update 18\n",
      "train: iter 234  trainloss -2.08781  validloss -2.65667±0.00000  bestvalidloss -2.72661  last_update 19\n",
      "train: iter 235  trainloss -2.04846  validloss -2.58656±0.00000  bestvalidloss -2.72661  last_update 20\n",
      "train: iter 236  trainloss -2.05675  validloss -2.52454±0.00000  bestvalidloss -2.72661  last_update 21\n",
      "train: iter 237  trainloss -2.08042  validloss -2.66380±0.00000  bestvalidloss -2.72661  last_update 22\n",
      "train: iter 238  trainloss -2.06717  validloss -2.63320±0.00000  bestvalidloss -2.72661  last_update 23\n",
      "train: iter 239  trainloss -2.05509  validloss -2.57725±0.00000  bestvalidloss -2.72661  last_update 24\n",
      "train: iter 240  trainloss -2.10474  validloss -2.59908±0.00000  bestvalidloss -2.72661  last_update 25\n",
      "train: iter 241  trainloss -2.05786  validloss -2.69471±0.00000  bestvalidloss -2.72661  last_update 26\n",
      "train: iter 242  trainloss -2.04381  validloss -2.62570±0.00000  bestvalidloss -2.72661  last_update 27\n",
      "train: iter 243  trainloss -2.08403  validloss -2.62818±0.00000  bestvalidloss -2.72661  last_update 28\n",
      "train: iter 244  trainloss -2.05781  validloss -2.65448±0.00000  bestvalidloss -2.72661  last_update 29\n",
      "train: iter 245  trainloss -2.08595  validloss -2.61500±0.00000  bestvalidloss -2.72661  last_update 30\n",
      "train: iter 246  trainloss -2.01282  validloss -2.70069±0.00000  bestvalidloss -2.72661  last_update 31\n",
      "train: iter 247  trainloss -1.99400  validloss -2.58784±0.00000  bestvalidloss -2.72661  last_update 32\n",
      "train: iter 248  trainloss -2.08887  validloss -2.65250±0.00000  bestvalidloss -2.72661  last_update 33\n",
      "train: iter 249  trainloss -2.11506  validloss -2.65929±0.00000  bestvalidloss -2.72661  last_update 34\n",
      "train: iter 250  trainloss -2.02699  validloss -2.64313±0.00000  bestvalidloss -2.72661  last_update 35\n",
      "train: iter 251  trainloss -2.02427  validloss -2.71965±0.00000  bestvalidloss -2.72661  last_update 36\n",
      "train: iter 252  trainloss -2.03400  validloss -2.63135±0.00000  bestvalidloss -2.72661  last_update 37\n",
      "train: iter 253  trainloss -2.05228  validloss -2.61403±0.00000  bestvalidloss -2.72661  last_update 38\n",
      "train: iter 254  trainloss -2.00163  validloss -2.69917±0.00000  bestvalidloss -2.72661  last_update 39\n",
      "train: iter 255  trainloss -2.07418  validloss -2.57318±0.00000  bestvalidloss -2.72661  last_update 40\n",
      "train: iter 256  trainloss -2.03050  validloss -2.63740±0.00000  bestvalidloss -2.72661  last_update 41\n",
      "train: iter 257  trainloss -2.07387  validloss -2.59868±0.00000  bestvalidloss -2.72661  last_update 42\n",
      "train: iter 258  trainloss -2.00561  validloss -2.66482±0.00000  bestvalidloss -2.72661  last_update 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 259  trainloss -2.01617  validloss -2.61172±0.00000  bestvalidloss -2.72661  last_update 44\n",
      "train: iter 260  trainloss -2.09473  validloss -2.67624±0.00000  bestvalidloss -2.72661  last_update 45\n",
      "train: iter 261  trainloss -2.07282  validloss -2.64829±0.00000  bestvalidloss -2.72661  last_update 46\n",
      "train: iter 262  trainloss -2.08059  validloss -2.61640±0.00000  bestvalidloss -2.72661  last_update 47\n",
      "train: iter 263  trainloss -2.00533  validloss -2.47814±0.00000  bestvalidloss -2.72661  last_update 48\n",
      "train: iter 264  trainloss -2.00935  validloss -2.68089±0.00000  bestvalidloss -2.72661  last_update 49\n",
      "train: iter 265  trainloss -2.03481  validloss -2.67377±0.00000  bestvalidloss -2.72661  last_update 50\n",
      "train: iter 266  trainloss -2.05163  validloss -2.67983±0.00000  bestvalidloss -2.72661  last_update 51\n",
      "train: iter 267  trainloss -2.06340  validloss -2.69320±0.00000  bestvalidloss -2.72661  last_update 52\n",
      "train: iter 268  trainloss -2.03387  validloss -2.62058±0.00000  bestvalidloss -2.72661  last_update 53\n",
      "train: iter 269  trainloss -1.99388  validloss -2.62803±0.00000  bestvalidloss -2.72661  last_update 54\n",
      "train: iter 270  trainloss -2.06706  validloss -2.64247±0.00000  bestvalidloss -2.72661  last_update 55\n",
      "train: iter 271  trainloss -2.01928  validloss -2.68871±0.00000  bestvalidloss -2.72661  last_update 56\n",
      "train: iter 272  trainloss -2.09921  validloss -2.59450±0.00000  bestvalidloss -2.72661  last_update 57\n",
      "train: iter 273  trainloss -2.02066  validloss -2.63165±0.00000  bestvalidloss -2.72661  last_update 58\n",
      "train: iter 274  trainloss -2.05976  validloss -2.61293±0.00000  bestvalidloss -2.72661  last_update 59\n",
      "train: iter 275  trainloss -2.13062  validloss -2.54695±0.00000  bestvalidloss -2.72661  last_update 60\n",
      "train: iter 276  trainloss -2.02373  validloss -2.66171±0.00000  bestvalidloss -2.72661  last_update 61\n",
      "train: iter 277  trainloss -2.02130  validloss -2.60105±0.00000  bestvalidloss -2.72661  last_update 62\n",
      "train: iter 278  trainloss -2.04443  validloss -2.59491±0.00000  bestvalidloss -2.72661  last_update 63\n",
      "train: iter 279  trainloss -2.04636  validloss -2.67494±0.00000  bestvalidloss -2.72661  last_update 64\n",
      "train: iter 280  trainloss -2.08682  validloss -2.62486±0.00000  bestvalidloss -2.72661  last_update 65\n",
      "train: iter 281  trainloss -2.02587  validloss -2.63034±0.00000  bestvalidloss -2.72661  last_update 66\n",
      "train: iter 282  trainloss -2.01616  validloss -2.66006±0.00000  bestvalidloss -2.72661  last_update 67\n",
      "train: iter 283  trainloss -2.04702  validloss -2.63853±0.00000  bestvalidloss -2.72661  last_update 68\n",
      "train: iter 284  trainloss -2.03880  validloss -2.64795±0.00000  bestvalidloss -2.72661  last_update 69\n",
      "train: iter 285  trainloss -2.02716  validloss -2.64490±0.00000  bestvalidloss -2.72661  last_update 70\n",
      "train: iter 286  trainloss -2.04718  validloss -2.60334±0.00000  bestvalidloss -2.72661  last_update 71\n",
      "train: iter 287  trainloss -2.04452  validloss -2.58126±0.00000  bestvalidloss -2.72661  last_update 72\n",
      "train: iter 288  trainloss -2.12033  validloss -2.59743±0.00000  bestvalidloss -2.72661  last_update 73\n",
      "train: iter 289  trainloss -2.05505  validloss -2.55429±0.00000  bestvalidloss -2.72661  last_update 74\n",
      "train: iter 290  trainloss -2.07528  validloss -2.62361±0.00000  bestvalidloss -2.72661  last_update 75\n",
      "train: iter 291  trainloss -2.04001  validloss -2.67642±0.00000  bestvalidloss -2.72661  last_update 76\n",
      "train: iter 292  trainloss -2.05984  validloss -2.63590±0.00000  bestvalidloss -2.72661  last_update 77\n",
      "train: iter 293  trainloss -2.05266  validloss -2.64622±0.00000  bestvalidloss -2.72661  last_update 78\n",
      "train: iter 294  trainloss -2.05244  validloss -2.66565±0.00000  bestvalidloss -2.72661  last_update 79\n",
      "train: iter 295  trainloss -2.13330  validloss -2.57830±0.00000  bestvalidloss -2.72661  last_update 80\n",
      "train: iter 296  trainloss -2.03925  validloss -2.67500±0.00000  bestvalidloss -2.72661  last_update 81\n",
      "train: iter 297  trainloss -2.05818  validloss -2.73710±0.00000  bestvalidloss -2.73710  last_update 0\n",
      "train: iter 298  trainloss -2.07131  validloss -2.68332±0.00000  bestvalidloss -2.73710  last_update 1\n",
      "train: iter 299  trainloss -2.09474  validloss -2.64750±0.00000  bestvalidloss -2.73710  last_update 2\n",
      "train: iter 300  trainloss -2.03340  validloss -2.63791±0.00000  bestvalidloss -2.73710  last_update 3\n",
      "train: iter 301  trainloss -2.04591  validloss -2.64747±0.00000  bestvalidloss -2.73710  last_update 4\n",
      "train: iter 302  trainloss -2.07130  validloss -2.73634±0.00000  bestvalidloss -2.73710  last_update 5\n",
      "train: iter 303  trainloss -1.99507  validloss -2.63965±0.00000  bestvalidloss -2.73710  last_update 6\n",
      "train: iter 304  trainloss -2.01816  validloss -2.60530±0.00000  bestvalidloss -2.73710  last_update 7\n",
      "train: iter 305  trainloss -2.09439  validloss -2.57864±0.00000  bestvalidloss -2.73710  last_update 8\n",
      "train: iter 306  trainloss -2.07740  validloss -2.72988±0.00000  bestvalidloss -2.73710  last_update 9\n",
      "train: iter 307  trainloss -2.10420  validloss -2.64746±0.00000  bestvalidloss -2.73710  last_update 10\n",
      "train: iter 308  trainloss -2.06614  validloss -2.63054±0.00000  bestvalidloss -2.73710  last_update 11\n",
      "train: iter 309  trainloss -2.05706  validloss -2.54055±0.00000  bestvalidloss -2.73710  last_update 12\n",
      "train: iter 310  trainloss -2.06339  validloss -2.63183±0.00000  bestvalidloss -2.73710  last_update 13\n",
      "train: iter 311  trainloss -2.04815  validloss -2.59777±0.00000  bestvalidloss -2.73710  last_update 14\n",
      "train: iter 312  trainloss -2.00115  validloss -2.68719±0.00000  bestvalidloss -2.73710  last_update 15\n",
      "train: iter 313  trainloss -2.07605  validloss -2.60229±0.00000  bestvalidloss -2.73710  last_update 16\n",
      "train: iter 314  trainloss -2.06379  validloss -2.64318±0.00000  bestvalidloss -2.73710  last_update 17\n",
      "train: iter 315  trainloss -2.01885  validloss -2.63091±0.00000  bestvalidloss -2.73710  last_update 18\n",
      "train: iter 316  trainloss -1.95352  validloss -2.62437±0.00000  bestvalidloss -2.73710  last_update 19\n",
      "train: iter 317  trainloss -2.08968  validloss -2.66143±0.00000  bestvalidloss -2.73710  last_update 20\n",
      "train: iter 318  trainloss -2.04235  validloss -2.62465±0.00000  bestvalidloss -2.73710  last_update 21\n",
      "train: iter 319  trainloss -2.02026  validloss -2.66961±0.00000  bestvalidloss -2.73710  last_update 22\n",
      "train: iter 320  trainloss -2.03717  validloss -2.66183±0.00000  bestvalidloss -2.73710  last_update 23\n",
      "train: iter 321  trainloss -1.99626  validloss -2.52951±0.00000  bestvalidloss -2.73710  last_update 24\n",
      "train: iter 322  trainloss -2.04942  validloss -2.62546±0.00000  bestvalidloss -2.73710  last_update 25\n",
      "train: iter 323  trainloss -2.04442  validloss -2.60791±0.00000  bestvalidloss -2.73710  last_update 26\n",
      "train: iter 324  trainloss -2.07325  validloss -2.60734±0.00000  bestvalidloss -2.73710  last_update 27\n",
      "train: iter 325  trainloss -2.03606  validloss -2.63079±0.00000  bestvalidloss -2.73710  last_update 28\n",
      "train: iter 326  trainloss -2.05762  validloss -2.59229±0.00000  bestvalidloss -2.73710  last_update 29\n",
      "train: iter 327  trainloss -2.01021  validloss -2.56994±0.00000  bestvalidloss -2.73710  last_update 30\n",
      "train: iter 328  trainloss -2.09663  validloss -2.59581±0.00000  bestvalidloss -2.73710  last_update 31\n",
      "train: iter 329  trainloss -2.06566  validloss -2.60772±0.00000  bestvalidloss -2.73710  last_update 32\n",
      "train: iter 330  trainloss -2.09920  validloss -2.61318±0.00000  bestvalidloss -2.73710  last_update 33\n",
      "train: iter 331  trainloss -2.13044  validloss -2.62923±0.00000  bestvalidloss -2.73710  last_update 34\n",
      "train: iter 332  trainloss -2.03520  validloss -2.62356±0.00000  bestvalidloss -2.73710  last_update 35\n",
      "train: iter 333  trainloss -2.02125  validloss -2.62983±0.00000  bestvalidloss -2.73710  last_update 36\n",
      "train: iter 334  trainloss -2.03798  validloss -2.67811±0.00000  bestvalidloss -2.73710  last_update 37\n",
      "train: iter 335  trainloss -2.13310  validloss -2.59003±0.00000  bestvalidloss -2.73710  last_update 38\n",
      "train: iter 336  trainloss -2.07222  validloss -2.67051±0.00000  bestvalidloss -2.73710  last_update 39\n",
      "train: iter 337  trainloss -2.04673  validloss -2.57682±0.00000  bestvalidloss -2.73710  last_update 40\n",
      "train: iter 338  trainloss -2.03162  validloss -2.68116±0.00000  bestvalidloss -2.73710  last_update 41\n",
      "train: iter 339  trainloss -2.02831  validloss -2.70050±0.00000  bestvalidloss -2.73710  last_update 42\n",
      "train: iter 340  trainloss -2.05194  validloss -2.62311±0.00000  bestvalidloss -2.73710  last_update 43\n",
      "train: iter 341  trainloss -2.01948  validloss -2.69976±0.00000  bestvalidloss -2.73710  last_update 44\n",
      "train: iter 342  trainloss -2.08311  validloss -2.63801±0.00000  bestvalidloss -2.73710  last_update 45\n",
      "train: iter 343  trainloss -2.04343  validloss -2.51860±0.00000  bestvalidloss -2.73710  last_update 46\n",
      "train: iter 344  trainloss -2.06956  validloss -2.64699±0.00000  bestvalidloss -2.73710  last_update 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 345  trainloss -2.03245  validloss -2.63279±0.00000  bestvalidloss -2.73710  last_update 48\n",
      "train: iter 346  trainloss -2.01933  validloss -2.57852±0.00000  bestvalidloss -2.73710  last_update 49\n",
      "train: iter 347  trainloss -2.05301  validloss -2.60818±0.00000  bestvalidloss -2.73710  last_update 50\n",
      "train: iter 348  trainloss -2.05137  validloss -2.58108±0.00000  bestvalidloss -2.73710  last_update 51\n",
      "train: iter 349  trainloss -1.99839  validloss -2.66281±0.00000  bestvalidloss -2.73710  last_update 52\n",
      "train: iter 350  trainloss -2.06360  validloss -2.58194±0.00000  bestvalidloss -2.73710  last_update 53\n",
      "train: iter 351  trainloss -2.05221  validloss -2.66249±0.00000  bestvalidloss -2.73710  last_update 54\n",
      "train: iter 352  trainloss -2.04333  validloss -2.63688±0.00000  bestvalidloss -2.73710  last_update 55\n",
      "train: iter 353  trainloss -2.06228  validloss -2.64542±0.00000  bestvalidloss -2.73710  last_update 56\n",
      "train: iter 354  trainloss -2.06093  validloss -2.58947±0.00000  bestvalidloss -2.73710  last_update 57\n",
      "train: iter 355  trainloss -2.03599  validloss -2.67653±0.00000  bestvalidloss -2.73710  last_update 58\n",
      "train: iter 356  trainloss -2.06304  validloss -2.61528±0.00000  bestvalidloss -2.73710  last_update 59\n",
      "train: iter 357  trainloss -2.08998  validloss -2.64908±0.00000  bestvalidloss -2.73710  last_update 60\n",
      "train: iter 358  trainloss -2.11564  validloss -2.60022±0.00000  bestvalidloss -2.73710  last_update 61\n",
      "train: iter 359  trainloss -2.10926  validloss -2.68228±0.00000  bestvalidloss -2.73710  last_update 62\n",
      "train: iter 360  trainloss -1.96204  validloss -2.56385±0.00000  bestvalidloss -2.73710  last_update 63\n",
      "train: iter 361  trainloss -2.03821  validloss -2.58703±0.00000  bestvalidloss -2.73710  last_update 64\n",
      "train: iter 362  trainloss -2.07189  validloss -2.57877±0.00000  bestvalidloss -2.73710  last_update 65\n",
      "train: iter 363  trainloss -2.06053  validloss -2.61879±0.00000  bestvalidloss -2.73710  last_update 66\n",
      "train: iter 364  trainloss -2.04734  validloss -2.60248±0.00000  bestvalidloss -2.73710  last_update 67\n",
      "train: iter 365  trainloss -2.03983  validloss -2.54268±0.00000  bestvalidloss -2.73710  last_update 68\n",
      "train: iter 366  trainloss -2.08250  validloss -2.65791±0.00000  bestvalidloss -2.73710  last_update 69\n",
      "train: iter 367  trainloss -2.02613  validloss -2.62520±0.00000  bestvalidloss -2.73710  last_update 70\n",
      "train: iter 368  trainloss -2.11379  validloss -2.59362±0.00000  bestvalidloss -2.73710  last_update 71\n",
      "train: iter 369  trainloss -2.00645  validloss -2.66636±0.00000  bestvalidloss -2.73710  last_update 72\n",
      "train: iter 370  trainloss -2.09582  validloss -2.69304±0.00000  bestvalidloss -2.73710  last_update 73\n",
      "train: iter 371  trainloss -2.01853  validloss -2.57025±0.00000  bestvalidloss -2.73710  last_update 74\n",
      "train: iter 372  trainloss -2.09224  validloss -2.55430±0.00000  bestvalidloss -2.73710  last_update 75\n",
      "train: iter 373  trainloss -2.07842  validloss -2.58780±0.00000  bestvalidloss -2.73710  last_update 76\n",
      "train: iter 374  trainloss -2.01064  validloss -2.72812±0.00000  bestvalidloss -2.73710  last_update 77\n",
      "train: iter 375  trainloss -2.05776  validloss -2.64298±0.00000  bestvalidloss -2.73710  last_update 78\n",
      "train: iter 376  trainloss -2.03301  validloss -2.64059±0.00000  bestvalidloss -2.73710  last_update 79\n",
      "train: iter 377  trainloss -2.03648  validloss -2.65410±0.00000  bestvalidloss -2.73710  last_update 80\n",
      "train: iter 378  trainloss -2.07059  validloss -2.66821±0.00000  bestvalidloss -2.73710  last_update 81\n",
      "train: iter 379  trainloss -2.02280  validloss -2.67965±0.00000  bestvalidloss -2.73710  last_update 82\n",
      "train: iter 380  trainloss -1.94745  validloss -2.62308±0.00000  bestvalidloss -2.73710  last_update 83\n",
      "train: iter 381  trainloss -2.08496  validloss -2.66185±0.00000  bestvalidloss -2.73710  last_update 84\n",
      "train: iter 382  trainloss -2.00555  validloss -2.68893±0.00000  bestvalidloss -2.73710  last_update 85\n",
      "train: iter 383  trainloss -2.06124  validloss -2.62061±0.00000  bestvalidloss -2.73710  last_update 86\n",
      "train: iter 384  trainloss -2.07973  validloss -2.55848±0.00000  bestvalidloss -2.73710  last_update 87\n",
      "train: iter 385  trainloss -2.06238  validloss -2.61483±0.00000  bestvalidloss -2.73710  last_update 88\n",
      "train: iter 386  trainloss -2.10318  validloss -2.61449±0.00000  bestvalidloss -2.73710  last_update 89\n",
      "train: iter 387  trainloss -2.05015  validloss -2.56509±0.00000  bestvalidloss -2.73710  last_update 90\n",
      "train: iter 388  trainloss -2.02859  validloss -2.63637±0.00000  bestvalidloss -2.73710  last_update 91\n",
      "train: iter 389  trainloss -2.07347  validloss -2.66817±0.00000  bestvalidloss -2.73710  last_update 92\n",
      "train: iter 390  trainloss -2.07308  validloss -2.62278±0.00000  bestvalidloss -2.73710  last_update 93\n",
      "train: iter 391  trainloss -2.05024  validloss -2.60396±0.00000  bestvalidloss -2.73710  last_update 94\n",
      "train: iter 392  trainloss -2.05916  validloss -2.65882±0.00000  bestvalidloss -2.73710  last_update 95\n",
      "train: iter 393  trainloss -2.06579  validloss -2.63633±0.00000  bestvalidloss -2.73710  last_update 96\n",
      "train: iter 394  trainloss -2.04053  validloss -2.62364±0.00000  bestvalidloss -2.73710  last_update 97\n",
      "train: iter 395  trainloss -2.04950  validloss -2.70089±0.00000  bestvalidloss -2.73710  last_update 98\n",
      "train: iter 396  trainloss -2.03171  validloss -2.62727±0.00000  bestvalidloss -2.73710  last_update 99\n",
      "train: iter 397  trainloss -2.05062  validloss -2.66772±0.00000  bestvalidloss -2.73710  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.0532,  2.4792, -4.5338, -5.2497], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 101.66546  validloss 107.75871±0.00000  bestvalidloss 107.75871  last_update 0\n",
      "train: iter 1  trainloss 77.20132  validloss 84.51707±0.00000  bestvalidloss 84.51707  last_update 0\n",
      "train: iter 2  trainloss 57.79447  validloss 61.86759±0.00000  bestvalidloss 61.86759  last_update 0\n",
      "train: iter 3  trainloss 45.20485  validloss 47.52092±0.00000  bestvalidloss 47.52092  last_update 0\n",
      "train: iter 4  trainloss 36.12989  validloss 37.09838±0.00000  bestvalidloss 37.09838  last_update 0\n",
      "train: iter 5  trainloss 29.06865  validloss 29.77612±0.00000  bestvalidloss 29.77612  last_update 0\n",
      "train: iter 6  trainloss 23.41855  validloss 23.89229±0.00000  bestvalidloss 23.89229  last_update 0\n",
      "train: iter 7  trainloss 18.89349  validloss 18.93600±0.00000  bestvalidloss 18.93600  last_update 0\n",
      "train: iter 8  trainloss 15.29892  validloss 15.28047±0.00000  bestvalidloss 15.28047  last_update 0\n",
      "train: iter 9  trainloss 12.31101  validloss 12.24931±0.00000  bestvalidloss 12.24931  last_update 0\n",
      "train: iter 10  trainloss 9.99980  validloss 9.68757±0.00000  bestvalidloss 9.68757  last_update 0\n",
      "train: iter 11  trainloss 8.10729  validloss 7.90664±0.00000  bestvalidloss 7.90664  last_update 0\n",
      "train: iter 12  trainloss 6.74071  validloss 6.59752±0.00000  bestvalidloss 6.59752  last_update 0\n",
      "train: iter 13  trainloss 5.61809  validloss 5.50551±0.00000  bestvalidloss 5.50551  last_update 0\n",
      "train: iter 14  trainloss 4.80646  validloss 4.69665±0.00000  bestvalidloss 4.69665  last_update 0\n",
      "train: iter 15  trainloss 4.16554  validloss 3.99246±0.00000  bestvalidloss 3.99246  last_update 0\n",
      "train: iter 16  trainloss 3.72096  validloss 3.63553±0.00000  bestvalidloss 3.63553  last_update 0\n",
      "train: iter 17  trainloss 3.41678  validloss 3.31442±0.00000  bestvalidloss 3.31442  last_update 0\n",
      "train: iter 18  trainloss 3.17714  validloss 3.15690±0.00000  bestvalidloss 3.15690  last_update 0\n",
      "train: iter 19  trainloss 3.01165  validloss 2.99549±0.00000  bestvalidloss 2.99549  last_update 0\n",
      "train: iter 20  trainloss 2.90475  validloss 2.93295±0.00000  bestvalidloss 2.93295  last_update 0\n",
      "train: iter 21  trainloss 2.81786  validloss 2.96857±0.00000  bestvalidloss 2.93295  last_update 1\n",
      "train: iter 22  trainloss 2.77674  validloss 2.87625±0.00000  bestvalidloss 2.87625  last_update 0\n",
      "train: iter 23  trainloss 2.75517  validloss 3.03698±0.00000  bestvalidloss 2.87625  last_update 1\n",
      "train: iter 24  trainloss 2.74390  validloss 2.87662±0.00000  bestvalidloss 2.87625  last_update 2\n",
      "train: iter 25  trainloss 2.74234  validloss 2.98734±0.00000  bestvalidloss 2.87625  last_update 3\n",
      "train: iter 26  trainloss 2.71384  validloss 2.84910±0.00000  bestvalidloss 2.84910  last_update 0\n",
      "train: iter 27  trainloss 2.69878  validloss 2.91802±0.00000  bestvalidloss 2.84910  last_update 1\n",
      "train: iter 28  trainloss 2.71422  validloss 2.88473±0.00000  bestvalidloss 2.84910  last_update 2\n",
      "train: iter 29  trainloss 2.69520  validloss 2.93700±0.00000  bestvalidloss 2.84910  last_update 3\n",
      "train: iter 30  trainloss 2.73207  validloss 2.89006±0.00000  bestvalidloss 2.84910  last_update 4\n",
      "train: iter 31  trainloss 2.70932  validloss 2.85974±0.00000  bestvalidloss 2.84910  last_update 5\n",
      "train: iter 32  trainloss 2.70469  validloss 2.94675±0.00000  bestvalidloss 2.84910  last_update 6\n",
      "train: iter 33  trainloss 2.69298  validloss 3.04323±0.00000  bestvalidloss 2.84910  last_update 7\n",
      "train: iter 34  trainloss 2.71377  validloss 2.98743±0.00000  bestvalidloss 2.84910  last_update 8\n",
      "train: iter 35  trainloss 2.68750  validloss 2.85225±0.00000  bestvalidloss 2.84910  last_update 9\n",
      "train: iter 36  trainloss 2.69319  validloss 2.86634±0.00000  bestvalidloss 2.84910  last_update 10\n",
      "train: iter 37  trainloss 2.69089  validloss 2.91579±0.00000  bestvalidloss 2.84910  last_update 11\n",
      "train: iter 38  trainloss 2.68886  validloss 3.04554±0.00000  bestvalidloss 2.84910  last_update 12\n",
      "train: iter 39  trainloss 2.69399  validloss 2.96351±0.00000  bestvalidloss 2.84910  last_update 13\n",
      "train: iter 40  trainloss 2.72464  validloss 2.87720±0.00000  bestvalidloss 2.84910  last_update 14\n",
      "train: iter 41  trainloss 2.71505  validloss 2.91717±0.00000  bestvalidloss 2.84910  last_update 15\n",
      "train: iter 42  trainloss 2.70462  validloss 2.96622±0.00000  bestvalidloss 2.84910  last_update 16\n",
      "train: iter 43  trainloss 2.69488  validloss 3.01583±0.00000  bestvalidloss 2.84910  last_update 17\n",
      "train: iter 44  trainloss 2.52733  validloss 2.88346±0.00000  bestvalidloss 2.84910  last_update 18\n",
      "train: iter 45  trainloss 2.18110  validloss 2.84056±0.00000  bestvalidloss 2.84056  last_update 0\n",
      "train: iter 46  trainloss 2.07660  validloss 2.84954±0.00000  bestvalidloss 2.84056  last_update 1\n",
      "train: iter 47  trainloss 2.01265  validloss 2.81421±0.00000  bestvalidloss 2.81421  last_update 0\n",
      "train: iter 48  trainloss 1.95212  validloss 2.82938±0.00000  bestvalidloss 2.81421  last_update 1\n",
      "train: iter 49  trainloss 1.92863  validloss 3.22359±0.00000  bestvalidloss 2.81421  last_update 2\n",
      "train: iter 50  trainloss 1.91940  validloss 2.96738±0.00000  bestvalidloss 2.81421  last_update 3\n",
      "train: iter 51  trainloss 1.90060  validloss 2.90738±0.00000  bestvalidloss 2.81421  last_update 4\n",
      "train: iter 52  trainloss 1.90312  validloss 2.99369±0.00000  bestvalidloss 2.81421  last_update 5\n",
      "train: iter 53  trainloss 1.86783  validloss 2.94833±0.00000  bestvalidloss 2.81421  last_update 6\n",
      "train: iter 54  trainloss 1.84504  validloss 2.86842±0.00000  bestvalidloss 2.81421  last_update 7\n",
      "train: iter 55  trainloss 1.80140  validloss 2.78255±0.00000  bestvalidloss 2.78255  last_update 0\n",
      "train: iter 56  trainloss 1.79231  validloss 2.55677±0.00000  bestvalidloss 2.55677  last_update 0\n",
      "train: iter 57  trainloss 1.75666  validloss 2.44205±0.00000  bestvalidloss 2.44205  last_update 0\n",
      "train: iter 58  trainloss 1.71129  validloss 2.44113±0.00000  bestvalidloss 2.44113  last_update 0\n",
      "train: iter 59  trainloss 1.70395  validloss 2.41572±0.00000  bestvalidloss 2.41572  last_update 0\n",
      "train: iter 60  trainloss 1.68834  validloss 2.35170±0.00000  bestvalidloss 2.35170  last_update 0\n",
      "train: iter 61  trainloss 1.68127  validloss 2.30445±0.00000  bestvalidloss 2.30445  last_update 0\n",
      "train: iter 62  trainloss 1.71566  validloss 2.34698±0.00000  bestvalidloss 2.30445  last_update 1\n",
      "train: iter 63  trainloss 1.65100  validloss 2.36036±0.00000  bestvalidloss 2.30445  last_update 2\n",
      "train: iter 64  trainloss 1.65438  validloss 2.36931±0.00000  bestvalidloss 2.30445  last_update 3\n",
      "train: iter 65  trainloss 1.65867  validloss 2.31839±0.00000  bestvalidloss 2.30445  last_update 4\n",
      "train: iter 66  trainloss 1.64366  validloss 2.25376±0.00000  bestvalidloss 2.25376  last_update 0\n",
      "train: iter 67  trainloss 1.64009  validloss 2.49616±0.00000  bestvalidloss 2.25376  last_update 1\n",
      "train: iter 68  trainloss 1.63582  validloss 2.41535±0.00000  bestvalidloss 2.25376  last_update 2\n",
      "train: iter 69  trainloss 1.62775  validloss 2.18371±0.00000  bestvalidloss 2.18371  last_update 0\n",
      "train: iter 70  trainloss 1.62642  validloss 2.21735±0.00000  bestvalidloss 2.18371  last_update 1\n",
      "train: iter 71  trainloss 1.61712  validloss 2.29585±0.00000  bestvalidloss 2.18371  last_update 2\n",
      "train: iter 72  trainloss 1.57299  validloss 2.30473±0.00000  bestvalidloss 2.18371  last_update 3\n",
      "train: iter 73  trainloss 1.57350  validloss 2.30760±0.00000  bestvalidloss 2.18371  last_update 4\n",
      "train: iter 74  trainloss 1.60344  validloss 2.23396±0.00000  bestvalidloss 2.18371  last_update 5\n",
      "train: iter 75  trainloss 1.56003  validloss 2.21361±0.00000  bestvalidloss 2.18371  last_update 6\n",
      "train: iter 76  trainloss 1.56883  validloss 2.32013±0.00000  bestvalidloss 2.18371  last_update 7\n",
      "train: iter 77  trainloss 1.55633  validloss 2.17491±0.00000  bestvalidloss 2.17491  last_update 0\n",
      "train: iter 78  trainloss 1.56994  validloss 2.09314±0.00000  bestvalidloss 2.09314  last_update 0\n",
      "train: iter 79  trainloss 1.56175  validloss 2.11701±0.00000  bestvalidloss 2.09314  last_update 1\n",
      "train: iter 80  trainloss 1.55559  validloss 2.30882±0.00000  bestvalidloss 2.09314  last_update 2\n",
      "train: iter 81  trainloss 1.55100  validloss 2.23785±0.00000  bestvalidloss 2.09314  last_update 3\n",
      "train: iter 82  trainloss 1.54655  validloss 2.25558±0.00000  bestvalidloss 2.09314  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.56818  validloss 2.15300±0.00000  bestvalidloss 2.09314  last_update 5\n",
      "train: iter 84  trainloss 1.51869  validloss 2.21775±0.00000  bestvalidloss 2.09314  last_update 6\n",
      "train: iter 85  trainloss 1.53699  validloss 2.17665±0.00000  bestvalidloss 2.09314  last_update 7\n",
      "train: iter 86  trainloss 1.53879  validloss 2.11162±0.00000  bestvalidloss 2.09314  last_update 8\n",
      "train: iter 87  trainloss 1.53056  validloss 2.19475±0.00000  bestvalidloss 2.09314  last_update 9\n",
      "train: iter 88  trainloss 1.55613  validloss 2.29940±0.00000  bestvalidloss 2.09314  last_update 10\n",
      "train: iter 89  trainloss 1.53295  validloss 2.21833±0.00000  bestvalidloss 2.09314  last_update 11\n",
      "train: iter 90  trainloss 1.52819  validloss 2.26504±0.00000  bestvalidloss 2.09314  last_update 12\n",
      "train: iter 91  trainloss 1.53446  validloss 2.13696±0.00000  bestvalidloss 2.09314  last_update 13\n",
      "train: iter 92  trainloss 1.52645  validloss 2.11834±0.00000  bestvalidloss 2.09314  last_update 14\n",
      "train: iter 93  trainloss 1.51003  validloss 2.22005±0.00000  bestvalidloss 2.09314  last_update 15\n",
      "train: iter 94  trainloss 1.55166  validloss 2.26530±0.00000  bestvalidloss 2.09314  last_update 16\n",
      "train: iter 95  trainloss 1.52917  validloss 2.22222±0.00000  bestvalidloss 2.09314  last_update 17\n",
      "train: iter 96  trainloss 1.52276  validloss 2.23866±0.00000  bestvalidloss 2.09314  last_update 18\n",
      "train: iter 97  trainloss 1.51148  validloss 2.17652±0.00000  bestvalidloss 2.09314  last_update 19\n",
      "train: iter 98  trainloss 1.49830  validloss 2.12215±0.00000  bestvalidloss 2.09314  last_update 20\n",
      "train: iter 99  trainloss 1.51912  validloss 2.23888±0.00000  bestvalidloss 2.09314  last_update 21\n",
      "train: iter 100  trainloss 1.50639  validloss 2.12463±0.00000  bestvalidloss 2.09314  last_update 22\n",
      "train: iter 101  trainloss 1.51933  validloss 2.26366±0.00000  bestvalidloss 2.09314  last_update 23\n",
      "train: iter 102  trainloss 1.51282  validloss 2.21254±0.00000  bestvalidloss 2.09314  last_update 24\n",
      "train: iter 103  trainloss 1.50882  validloss 2.17091±0.00000  bestvalidloss 2.09314  last_update 25\n",
      "train: iter 104  trainloss 1.51315  validloss 2.13866±0.00000  bestvalidloss 2.09314  last_update 26\n",
      "train: iter 105  trainloss 1.50087  validloss 2.21476±0.00000  bestvalidloss 2.09314  last_update 27\n",
      "train: iter 106  trainloss 1.51134  validloss 2.14573±0.00000  bestvalidloss 2.09314  last_update 28\n",
      "train: iter 107  trainloss 1.51460  validloss 2.31562±0.00000  bestvalidloss 2.09314  last_update 29\n",
      "train: iter 108  trainloss 1.52277  validloss 2.10792±0.00000  bestvalidloss 2.09314  last_update 30\n",
      "train: iter 109  trainloss 1.49829  validloss 2.18119±0.00000  bestvalidloss 2.09314  last_update 31\n",
      "train: iter 110  trainloss 1.50997  validloss 2.17153±0.00000  bestvalidloss 2.09314  last_update 32\n",
      "train: iter 111  trainloss 1.50660  validloss 2.20175±0.00000  bestvalidloss 2.09314  last_update 33\n",
      "train: iter 112  trainloss 1.52699  validloss 2.14180±0.00000  bestvalidloss 2.09314  last_update 34\n",
      "train: iter 113  trainloss 1.52778  validloss 2.14467±0.00000  bestvalidloss 2.09314  last_update 35\n",
      "train: iter 114  trainloss 1.51662  validloss 2.30473±0.00000  bestvalidloss 2.09314  last_update 36\n",
      "train: iter 115  trainloss 1.50798  validloss 2.21992±0.00000  bestvalidloss 2.09314  last_update 37\n",
      "train: iter 116  trainloss 1.49510  validloss 2.24629±0.00000  bestvalidloss 2.09314  last_update 38\n",
      "train: iter 117  trainloss 1.50773  validloss 2.27878±0.00000  bestvalidloss 2.09314  last_update 39\n",
      "train: iter 118  trainloss 1.50251  validloss 2.27172±0.00000  bestvalidloss 2.09314  last_update 40\n",
      "train: iter 119  trainloss 1.48904  validloss 2.15878±0.00000  bestvalidloss 2.09314  last_update 41\n",
      "train: iter 120  trainloss 1.49353  validloss 2.17845±0.00000  bestvalidloss 2.09314  last_update 42\n",
      "train: iter 121  trainloss 1.51825  validloss 2.32022±0.00000  bestvalidloss 2.09314  last_update 43\n",
      "train: iter 122  trainloss 1.50466  validloss 2.21315±0.00000  bestvalidloss 2.09314  last_update 44\n",
      "train: iter 123  trainloss 1.51402  validloss 2.15662±0.00000  bestvalidloss 2.09314  last_update 45\n",
      "train: iter 124  trainloss 1.48424  validloss 2.31972±0.00000  bestvalidloss 2.09314  last_update 46\n",
      "train: iter 125  trainloss 1.49393  validloss 2.19574±0.00000  bestvalidloss 2.09314  last_update 47\n",
      "train: iter 126  trainloss 1.50506  validloss 2.20766±0.00000  bestvalidloss 2.09314  last_update 48\n",
      "train: iter 127  trainloss 1.49697  validloss 2.18547±0.00000  bestvalidloss 2.09314  last_update 49\n",
      "train: iter 128  trainloss 1.49188  validloss 2.28033±0.00000  bestvalidloss 2.09314  last_update 50\n",
      "train: iter 129  trainloss 1.52232  validloss 2.31118±0.00000  bestvalidloss 2.09314  last_update 51\n",
      "train: iter 130  trainloss 1.49456  validloss 2.21038±0.00000  bestvalidloss 2.09314  last_update 52\n",
      "train: iter 131  trainloss 1.51750  validloss 2.23043±0.00000  bestvalidloss 2.09314  last_update 53\n",
      "train: iter 132  trainloss 1.49305  validloss 2.28900±0.00000  bestvalidloss 2.09314  last_update 54\n",
      "train: iter 133  trainloss 1.49718  validloss 2.12528±0.00000  bestvalidloss 2.09314  last_update 55\n",
      "train: iter 134  trainloss 1.48646  validloss 2.32552±0.00000  bestvalidloss 2.09314  last_update 56\n",
      "train: iter 135  trainloss 1.49011  validloss 2.12574±0.00000  bestvalidloss 2.09314  last_update 57\n",
      "train: iter 136  trainloss 1.49132  validloss 2.17552±0.00000  bestvalidloss 2.09314  last_update 58\n",
      "train: iter 137  trainloss 1.47147  validloss 2.23837±0.00000  bestvalidloss 2.09314  last_update 59\n",
      "train: iter 138  trainloss 1.47339  validloss 2.18234±0.00000  bestvalidloss 2.09314  last_update 60\n",
      "train: iter 139  trainloss 1.49112  validloss 2.28691±0.00000  bestvalidloss 2.09314  last_update 61\n",
      "train: iter 140  trainloss 1.49484  validloss 2.30672±0.00000  bestvalidloss 2.09314  last_update 62\n",
      "train: iter 141  trainloss 1.48411  validloss 2.25463±0.00000  bestvalidloss 2.09314  last_update 63\n",
      "train: iter 142  trainloss 1.49304  validloss 2.17830±0.00000  bestvalidloss 2.09314  last_update 64\n",
      "train: iter 143  trainloss 1.49705  validloss 2.25817±0.00000  bestvalidloss 2.09314  last_update 65\n",
      "train: iter 144  trainloss 1.51086  validloss 2.43766±0.00000  bestvalidloss 2.09314  last_update 66\n",
      "train: iter 145  trainloss 1.50476  validloss 2.21620±0.00000  bestvalidloss 2.09314  last_update 67\n",
      "train: iter 146  trainloss 1.51269  validloss 2.33540±0.00000  bestvalidloss 2.09314  last_update 68\n",
      "train: iter 147  trainloss 1.48717  validloss 2.29179±0.00000  bestvalidloss 2.09314  last_update 69\n",
      "train: iter 148  trainloss 1.49149  validloss 2.11853±0.00000  bestvalidloss 2.09314  last_update 70\n",
      "train: iter 149  trainloss 1.50606  validloss 2.31703±0.00000  bestvalidloss 2.09314  last_update 71\n",
      "train: iter 150  trainloss 1.49029  validloss 2.34043±0.00000  bestvalidloss 2.09314  last_update 72\n",
      "train: iter 151  trainloss 1.48969  validloss 2.15938±0.00000  bestvalidloss 2.09314  last_update 73\n",
      "train: iter 152  trainloss 1.49445  validloss 2.20411±0.00000  bestvalidloss 2.09314  last_update 74\n",
      "train: iter 153  trainloss 1.46778  validloss 2.29459±0.00000  bestvalidloss 2.09314  last_update 75\n",
      "train: iter 154  trainloss 1.48313  validloss 2.10953±0.00000  bestvalidloss 2.09314  last_update 76\n",
      "train: iter 155  trainloss 1.48641  validloss 2.16557±0.00000  bestvalidloss 2.09314  last_update 77\n",
      "train: iter 156  trainloss 1.50387  validloss 2.22082±0.00000  bestvalidloss 2.09314  last_update 78\n",
      "train: iter 157  trainloss 1.46825  validloss 2.29356±0.00000  bestvalidloss 2.09314  last_update 79\n",
      "train: iter 158  trainloss 1.49291  validloss 2.17260±0.00000  bestvalidloss 2.09314  last_update 80\n",
      "train: iter 159  trainloss 1.48953  validloss 2.20201±0.00000  bestvalidloss 2.09314  last_update 81\n",
      "train: iter 160  trainloss 1.47860  validloss 2.17806±0.00000  bestvalidloss 2.09314  last_update 82\n",
      "train: iter 161  trainloss 1.48277  validloss 2.30409±0.00000  bestvalidloss 2.09314  last_update 83\n",
      "train: iter 162  trainloss 1.47979  validloss 2.34515±0.00000  bestvalidloss 2.09314  last_update 84\n",
      "train: iter 163  trainloss 1.51023  validloss 2.28137±0.00000  bestvalidloss 2.09314  last_update 85\n",
      "train: iter 164  trainloss 1.47168  validloss 2.30903±0.00000  bestvalidloss 2.09314  last_update 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 165  trainloss 1.48280  validloss 2.28264±0.00000  bestvalidloss 2.09314  last_update 87\n",
      "train: iter 166  trainloss 1.48650  validloss 2.23140±0.00000  bestvalidloss 2.09314  last_update 88\n",
      "train: iter 167  trainloss 1.47439  validloss 2.26607±0.00000  bestvalidloss 2.09314  last_update 89\n",
      "train: iter 168  trainloss 1.48840  validloss 2.31714±0.00000  bestvalidloss 2.09314  last_update 90\n",
      "train: iter 169  trainloss 1.50358  validloss 2.13677±0.00000  bestvalidloss 2.09314  last_update 91\n",
      "train: iter 170  trainloss 1.46923  validloss 2.14206±0.00000  bestvalidloss 2.09314  last_update 92\n",
      "train: iter 171  trainloss 1.48668  validloss 2.27891±0.00000  bestvalidloss 2.09314  last_update 93\n",
      "train: iter 172  trainloss 1.47669  validloss 2.29072±0.00000  bestvalidloss 2.09314  last_update 94\n",
      "train: iter 173  trainloss 1.47446  validloss 2.23153±0.00000  bestvalidloss 2.09314  last_update 95\n",
      "train: iter 174  trainloss 1.47478  validloss 2.22015±0.00000  bestvalidloss 2.09314  last_update 96\n",
      "train: iter 175  trainloss 1.48938  validloss 2.17376±0.00000  bestvalidloss 2.09314  last_update 97\n",
      "train: iter 176  trainloss 1.51469  validloss 2.17778±0.00000  bestvalidloss 2.09314  last_update 98\n",
      "train: iter 177  trainloss 1.50209  validloss 2.23712±0.00000  bestvalidloss 2.09314  last_update 99\n",
      "train: iter 178  trainloss 1.50140  validloss 2.27457±0.00000  bestvalidloss 2.09314  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-6.2511)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-5.0844)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07186930396773475\n",
      "tensor([-0.2419])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
