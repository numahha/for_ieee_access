{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n",
      "cfg_env cartpole\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)\n",
    "print(\"cfg_env\",cfg_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(2136.9849)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 122814.39326  validloss 143661.28102±0.00000  bestvalidloss 143661.28102  last_update 0\n",
      "train: iter 1  trainloss 30723.09066  validloss 14395.84054±0.00000  bestvalidloss 14395.84054  last_update 0\n",
      "train: iter 2  trainloss 2574.40453  validloss 6966.12006±0.00000  bestvalidloss 6966.12006  last_update 0\n",
      "train: iter 3  trainloss 131245.01732  validloss 107349.97111±0.00000  bestvalidloss 6966.12006  last_update 1\n",
      "train: iter 4  trainloss 1457.28365  validloss 1225.04236±0.00000  bestvalidloss 1225.04236  last_update 0\n",
      "train: iter 5  trainloss 1044.71325  validloss 1048.70734±0.00000  bestvalidloss 1048.70734  last_update 0\n",
      "train: iter 6  trainloss 924.02871  validloss 982.84557±0.00000  bestvalidloss 982.84557  last_update 0\n",
      "train: iter 7  trainloss 834.45302  validloss 918.61727±0.00000  bestvalidloss 918.61727  last_update 0\n",
      "train: iter 8  trainloss 770.71648  validloss 873.21448±0.00000  bestvalidloss 873.21448  last_update 0\n",
      "train: iter 9  trainloss 704.33024  validloss 842.00833±0.00000  bestvalidloss 842.00833  last_update 0\n",
      "train: iter 10  trainloss 650.08180  validloss 759.83421±0.00000  bestvalidloss 759.83421  last_update 0\n",
      "train: iter 11  trainloss 580.68701  validloss 695.47442±0.00000  bestvalidloss 695.47442  last_update 0\n",
      "train: iter 12  trainloss 521.71039  validloss 709.35655±0.00000  bestvalidloss 695.47442  last_update 1\n",
      "train: iter 13  trainloss 474.64058  validloss 551.95943±0.00000  bestvalidloss 551.95943  last_update 0\n",
      "train: iter 14  trainloss 392.41309  validloss 488.79187±0.00000  bestvalidloss 488.79187  last_update 0\n",
      "train: iter 15  trainloss 344.82270  validloss 443.03263±0.00000  bestvalidloss 443.03263  last_update 0\n",
      "train: iter 16  trainloss 312.84972  validloss 361.74195±0.00000  bestvalidloss 361.74195  last_update 0\n",
      "train: iter 17  trainloss 268.77452  validloss 305.06769±0.00000  bestvalidloss 305.06769  last_update 0\n",
      "train: iter 18  trainloss 238.21074  validloss 261.52335±0.00000  bestvalidloss 261.52335  last_update 0\n",
      "train: iter 19  trainloss 196.34845  validloss 216.29300±0.00000  bestvalidloss 216.29300  last_update 0\n",
      "train: iter 20  trainloss 178.68106  validloss 238.54699±0.00000  bestvalidloss 216.29300  last_update 1\n",
      "train: iter 21  trainloss 142.20549  validloss 135.13438±0.00000  bestvalidloss 135.13438  last_update 0\n",
      "train: iter 22  trainloss 106.06102  validloss 137.06415±0.00000  bestvalidloss 135.13438  last_update 1\n",
      "train: iter 23  trainloss 66.89992  validloss 73.42264±0.00000  bestvalidloss 73.42264  last_update 0\n",
      "train: iter 24  trainloss 59.75221  validloss 86.39555±0.00000  bestvalidloss 73.42264  last_update 1\n",
      "train: iter 25  trainloss 39.38278  validloss 41.48013±0.00000  bestvalidloss 41.48013  last_update 0\n",
      "train: iter 26  trainloss 76.59659  validloss 66.10112±0.00000  bestvalidloss 41.48013  last_update 1\n",
      "train: iter 27  trainloss 54.78168  validloss 1.83948±0.00000  bestvalidloss 1.83948  last_update 0\n",
      "train: iter 28  trainloss 2.72441  validloss 108.03208±0.00000  bestvalidloss 1.83948  last_update 1\n",
      "train: iter 29  trainloss -22.10942  validloss -42.17854±0.00000  bestvalidloss -42.17854  last_update 0\n",
      "train: iter 30  trainloss -33.77362  validloss 1.20609±0.00000  bestvalidloss -42.17854  last_update 1\n",
      "train: iter 31  trainloss -66.73867  validloss -70.23011±0.00000  bestvalidloss -70.23011  last_update 0\n",
      "train: iter 32  trainloss -52.19160  validloss -91.30020±0.00000  bestvalidloss -91.30020  last_update 0\n",
      "train: iter 33  trainloss -81.11994  validloss -53.43858±0.00000  bestvalidloss -91.30020  last_update 1\n",
      "train: iter 34  trainloss -91.87680  validloss -98.87440±0.00000  bestvalidloss -98.87440  last_update 0\n",
      "train: iter 35  trainloss -112.58800  validloss -130.53190±0.00000  bestvalidloss -130.53190  last_update 0\n",
      "train: iter 36  trainloss -128.29247  validloss -150.82924±0.00000  bestvalidloss -150.82924  last_update 0\n",
      "train: iter 37  trainloss -120.22588  validloss -119.44974±0.00000  bestvalidloss -150.82924  last_update 1\n",
      "train: iter 38  trainloss -149.36835  validloss -168.65209±0.00000  bestvalidloss -168.65209  last_update 0\n",
      "train: iter 39  trainloss -144.27915  validloss -168.18924±0.00000  bestvalidloss -168.65209  last_update 1\n",
      "train: iter 40  trainloss -162.93773  validloss -177.63038±0.00000  bestvalidloss -177.63038  last_update 0\n",
      "train: iter 41  trainloss -165.50662  validloss -201.15313±0.00000  bestvalidloss -201.15313  last_update 0\n",
      "train: iter 42  trainloss -150.04273  validloss -170.78268±0.00000  bestvalidloss -201.15313  last_update 1\n",
      "train: iter 43  trainloss -173.12856  validloss -204.56920±0.00000  bestvalidloss -204.56920  last_update 0\n",
      "train: iter 44  trainloss -166.87079  validloss -118.76439±0.00000  bestvalidloss -204.56920  last_update 1\n",
      "train: iter 45  trainloss -204.42671  validloss -233.69194±0.00000  bestvalidloss -233.69194  last_update 0\n",
      "train: iter 46  trainloss -228.41933  validloss -238.98818±0.00000  bestvalidloss -238.98818  last_update 0\n",
      "train: iter 47  trainloss -223.69283  validloss -223.78983±0.00000  bestvalidloss -238.98818  last_update 1\n",
      "train: iter 48  trainloss -246.16875  validloss -288.56315±0.00000  bestvalidloss -288.56315  last_update 0\n",
      "train: iter 49  trainloss -240.56276  validloss -280.96783±0.00000  bestvalidloss -288.56315  last_update 1\n",
      "train: iter 50  trainloss -253.28984  validloss -280.82769±0.00000  bestvalidloss -288.56315  last_update 2\n",
      "train: iter 51  trainloss -262.69565  validloss -308.86591±0.00000  bestvalidloss -308.86591  last_update 0\n",
      "train: iter 52  trainloss -234.53951  validloss -217.39226±0.00000  bestvalidloss -308.86591  last_update 1\n",
      "train: iter 53  trainloss -264.97723  validloss -296.95354±0.00000  bestvalidloss -308.86591  last_update 2\n",
      "train: iter 54  trainloss -291.93579  validloss -336.35638±0.00000  bestvalidloss -336.35638  last_update 0\n",
      "train: iter 55  trainloss -266.74593  validloss -327.88015±0.00000  bestvalidloss -336.35638  last_update 1\n",
      "train: iter 56  trainloss -272.86171  validloss -319.87511±0.00000  bestvalidloss -336.35638  last_update 2\n",
      "train: iter 57  trainloss -253.73313  validloss -249.10643±0.00000  bestvalidloss -336.35638  last_update 3\n",
      "train: iter 58  trainloss -124.05981  validloss -210.02173±0.00000  bestvalidloss -336.35638  last_update 4\n",
      "train: iter 59  trainloss -242.90626  validloss -224.68471±0.00000  bestvalidloss -336.35638  last_update 5\n",
      "train: iter 60  trainloss -323.63340  validloss -295.00150±0.00000  bestvalidloss -336.35638  last_update 6\n",
      "train: iter 61  trainloss -332.93522  validloss -338.69272±0.00000  bestvalidloss -338.69272  last_update 0\n",
      "train: iter 62  trainloss -352.22960  validloss -293.10228±0.00000  bestvalidloss -338.69272  last_update 1\n",
      "train: iter 63  trainloss -359.65638  validloss -342.26499±0.00000  bestvalidloss -342.26499  last_update 0\n",
      "train: iter 64  trainloss -370.43209  validloss -360.32513±0.00000  bestvalidloss -360.32513  last_update 0\n",
      "train: iter 65  trainloss -364.93056  validloss -331.67553±0.00000  bestvalidloss -360.32513  last_update 1\n",
      "train: iter 66  trainloss -375.88015  validloss -352.79671±0.00000  bestvalidloss -360.32513  last_update 2\n",
      "train: iter 67  trainloss -382.31922  validloss -345.40755±0.00000  bestvalidloss -360.32513  last_update 3\n",
      "train: iter 68  trainloss -363.49589  validloss -346.57158±0.00000  bestvalidloss -360.32513  last_update 4\n",
      "train: iter 69  trainloss -366.93972  validloss -334.07149±0.00000  bestvalidloss -360.32513  last_update 5\n",
      "train: iter 70  trainloss -323.32054  validloss -378.80754±0.00000  bestvalidloss -378.80754  last_update 0\n",
      "train: iter 71  trainloss -362.46602  validloss -262.68166±0.00000  bestvalidloss -378.80754  last_update 1\n",
      "train: iter 72  trainloss -421.19357  validloss -375.58462±0.00000  bestvalidloss -378.80754  last_update 2\n",
      "train: iter 73  trainloss -415.70452  validloss -340.86681±0.00000  bestvalidloss -378.80754  last_update 3\n",
      "train: iter 74  trainloss -417.44742  validloss -356.31702±0.00000  bestvalidloss -378.80754  last_update 4\n",
      "train: iter 75  trainloss -405.28515  validloss -344.33892±0.00000  bestvalidloss -378.80754  last_update 5\n",
      "train: iter 76  trainloss -414.85099  validloss -273.46759±0.00000  bestvalidloss -378.80754  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -446.82083  validloss -322.59343±0.00000  bestvalidloss -378.80754  last_update 7\n",
      "train: iter 78  trainloss -453.82183  validloss -364.54456±0.00000  bestvalidloss -378.80754  last_update 8\n",
      "train: iter 79  trainloss -462.29629  validloss -388.90003±0.00000  bestvalidloss -388.90003  last_update 0\n",
      "train: iter 80  trainloss -470.93852  validloss -394.62374±0.00000  bestvalidloss -394.62374  last_update 0\n",
      "train: iter 81  trainloss -461.67605  validloss -430.33666±0.00000  bestvalidloss -430.33666  last_update 0\n",
      "train: iter 82  trainloss -465.99303  validloss -352.84520±0.00000  bestvalidloss -430.33666  last_update 1\n",
      "train: iter 83  trainloss -445.11856  validloss -308.89149±0.00000  bestvalidloss -430.33666  last_update 2\n",
      "train: iter 84  trainloss -468.14633  validloss -369.57024±0.00000  bestvalidloss -430.33666  last_update 3\n",
      "train: iter 85  trainloss -482.32322  validloss -322.91574±0.00000  bestvalidloss -430.33666  last_update 4\n",
      "train: iter 86  trainloss -464.96947  validloss -363.83030±0.00000  bestvalidloss -430.33666  last_update 5\n",
      "train: iter 87  trainloss -494.83897  validloss -385.34309±0.00000  bestvalidloss -430.33666  last_update 6\n",
      "train: iter 88  trainloss -486.58404  validloss -318.70406±0.00000  bestvalidloss -430.33666  last_update 7\n",
      "train: iter 89  trainloss -491.16028  validloss -247.42346±0.00000  bestvalidloss -430.33666  last_update 8\n",
      "train: iter 90  trainloss -484.31407  validloss -310.44076±0.00000  bestvalidloss -430.33666  last_update 9\n",
      "train: iter 91  trainloss -503.63580  validloss -351.88360±0.00000  bestvalidloss -430.33666  last_update 10\n",
      "train: iter 92  trainloss -500.91484  validloss -361.73338±0.00000  bestvalidloss -430.33666  last_update 11\n",
      "train: iter 93  trainloss -534.02407  validloss -373.97747±0.00000  bestvalidloss -430.33666  last_update 12\n",
      "train: iter 94  trainloss -437.91590  validloss -360.72078±0.00000  bestvalidloss -430.33666  last_update 13\n",
      "train: iter 95  trainloss -530.88638  validloss -375.61253±0.00000  bestvalidloss -430.33666  last_update 14\n",
      "train: iter 96  trainloss -531.28242  validloss -280.25993±0.00000  bestvalidloss -430.33666  last_update 15\n",
      "train: iter 97  trainloss -519.25659  validloss -352.11569±0.00000  bestvalidloss -430.33666  last_update 16\n",
      "train: iter 98  trainloss -535.54711  validloss -357.19644±0.00000  bestvalidloss -430.33666  last_update 17\n",
      "train: iter 99  trainloss -567.13092  validloss -377.16684±0.00000  bestvalidloss -430.33666  last_update 18\n",
      "train: iter 100  trainloss -565.47034  validloss -385.18949±0.00000  bestvalidloss -430.33666  last_update 19\n",
      "train: iter 101  trainloss -563.79491  validloss -353.36774±0.00000  bestvalidloss -430.33666  last_update 20\n",
      "train: iter 102  trainloss -529.52049  validloss -446.80318±0.00000  bestvalidloss -446.80318  last_update 0\n",
      "train: iter 103  trainloss -520.94222  validloss -24.21586±0.00000  bestvalidloss -446.80318  last_update 1\n",
      "train: iter 104  trainloss -590.33212  validloss -481.56526±0.00000  bestvalidloss -481.56526  last_update 0\n",
      "train: iter 105  trainloss -603.31658  validloss -270.75002±0.00000  bestvalidloss -481.56526  last_update 1\n",
      "train: iter 106  trainloss -589.70829  validloss -307.40025±0.00000  bestvalidloss -481.56526  last_update 2\n",
      "train: iter 107  trainloss -592.04345  validloss -155.47399±0.00000  bestvalidloss -481.56526  last_update 3\n",
      "train: iter 108  trainloss -543.35747  validloss -477.33898±0.00000  bestvalidloss -481.56526  last_update 4\n",
      "train: iter 109  trainloss -635.09452  validloss -148.37259±0.00000  bestvalidloss -481.56526  last_update 5\n",
      "train: iter 110  trainloss -627.88994  validloss 167.13146±0.00000  bestvalidloss -481.56526  last_update 6\n",
      "train: iter 111  trainloss -574.42342  validloss -636.48446±0.00000  bestvalidloss -636.48446  last_update 0\n",
      "train: iter 112  trainloss -627.66596  validloss -471.22589±0.00000  bestvalidloss -636.48446  last_update 1\n",
      "train: iter 113  trainloss -619.47017  validloss -529.97601±0.00000  bestvalidloss -636.48446  last_update 2\n",
      "train: iter 114  trainloss -571.75511  validloss -430.50387±0.00000  bestvalidloss -636.48446  last_update 3\n",
      "train: iter 115  trainloss -629.01527  validloss -547.11108±0.00000  bestvalidloss -636.48446  last_update 4\n",
      "train: iter 116  trainloss -576.04122  validloss -399.00307±0.00000  bestvalidloss -636.48446  last_update 5\n",
      "train: iter 117  trainloss -667.86519  validloss -581.44715±0.00000  bestvalidloss -636.48446  last_update 6\n",
      "train: iter 118  trainloss -627.26733  validloss -355.30308±0.00000  bestvalidloss -636.48446  last_update 7\n",
      "train: iter 119  trainloss -615.61682  validloss -533.70447±0.00000  bestvalidloss -636.48446  last_update 8\n",
      "train: iter 120  trainloss -654.32650  validloss -652.48863±0.00000  bestvalidloss -652.48863  last_update 0\n",
      "train: iter 121  trainloss -641.05164  validloss -597.35854±0.00000  bestvalidloss -652.48863  last_update 1\n",
      "train: iter 122  trainloss -689.26313  validloss -563.16495±0.00000  bestvalidloss -652.48863  last_update 2\n",
      "train: iter 123  trainloss -697.64228  validloss -495.90340±0.00000  bestvalidloss -652.48863  last_update 3\n",
      "train: iter 124  trainloss -718.05216  validloss -464.74301±0.00000  bestvalidloss -652.48863  last_update 4\n",
      "train: iter 125  trainloss -677.95310  validloss -453.64712±0.00000  bestvalidloss -652.48863  last_update 5\n",
      "train: iter 126  trainloss -622.77526  validloss -656.85978±0.00000  bestvalidloss -656.85978  last_update 0\n",
      "train: iter 127  trainloss -685.12986  validloss -618.31769±0.00000  bestvalidloss -656.85978  last_update 1\n",
      "train: iter 128  trainloss -680.45687  validloss -414.96414±0.00000  bestvalidloss -656.85978  last_update 2\n",
      "train: iter 129  trainloss -689.24920  validloss -468.39033±0.00000  bestvalidloss -656.85978  last_update 3\n",
      "train: iter 130  trainloss -740.01167  validloss -707.78510±0.00000  bestvalidloss -707.78510  last_update 0\n",
      "train: iter 131  trainloss -723.21159  validloss -776.57143±0.00000  bestvalidloss -776.57143  last_update 0\n",
      "train: iter 132  trainloss -731.84007  validloss -723.11836±0.00000  bestvalidloss -776.57143  last_update 1\n",
      "train: iter 133  trainloss -703.50190  validloss -615.75971±0.00000  bestvalidloss -776.57143  last_update 2\n",
      "train: iter 134  trainloss -653.77791  validloss -637.84454±0.00000  bestvalidloss -776.57143  last_update 3\n",
      "train: iter 135  trainloss -581.40612  validloss -489.38179±0.00000  bestvalidloss -776.57143  last_update 4\n",
      "train: iter 136  trainloss -755.57034  validloss -745.37053±0.00000  bestvalidloss -776.57143  last_update 5\n",
      "train: iter 137  trainloss -785.60863  validloss -644.85822±0.00000  bestvalidloss -776.57143  last_update 6\n",
      "train: iter 138  trainloss -757.47608  validloss -657.66654±0.00000  bestvalidloss -776.57143  last_update 7\n",
      "train: iter 139  trainloss -729.77846  validloss -486.27141±0.00000  bestvalidloss -776.57143  last_update 8\n",
      "train: iter 140  trainloss -717.33787  validloss -839.71666±0.00000  bestvalidloss -839.71666  last_update 0\n",
      "train: iter 141  trainloss -768.84300  validloss -791.46232±0.00000  bestvalidloss -839.71666  last_update 1\n",
      "train: iter 142  trainloss -725.20740  validloss -613.02517±0.00000  bestvalidloss -839.71666  last_update 2\n",
      "train: iter 143  trainloss -751.55339  validloss -759.94473±0.00000  bestvalidloss -839.71666  last_update 3\n",
      "train: iter 144  trainloss -725.26610  validloss -815.59843±0.00000  bestvalidloss -839.71666  last_update 4\n",
      "train: iter 145  trainloss -749.54665  validloss -679.55827±0.00000  bestvalidloss -839.71666  last_update 5\n",
      "train: iter 146  trainloss -851.91434  validloss -792.59479±0.00000  bestvalidloss -839.71666  last_update 6\n",
      "train: iter 147  trainloss -777.92525  validloss -854.66317±0.00000  bestvalidloss -854.66317  last_update 0\n",
      "train: iter 148  trainloss -766.69210  validloss -802.51563±0.00000  bestvalidloss -854.66317  last_update 1\n",
      "train: iter 149  trainloss -722.32458  validloss -846.37524±0.00000  bestvalidloss -854.66317  last_update 2\n",
      "train: iter 150  trainloss -820.60020  validloss -720.92581±0.00000  bestvalidloss -854.66317  last_update 3\n",
      "train: iter 151  trainloss -807.15831  validloss -762.20759±0.00000  bestvalidloss -854.66317  last_update 4\n",
      "train: iter 152  trainloss -800.93748  validloss -665.05684±0.00000  bestvalidloss -854.66317  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -762.24658  validloss -733.50786±0.00000  bestvalidloss -854.66317  last_update 6\n",
      "train: iter 154  trainloss -833.94115  validloss -893.70594±0.00000  bestvalidloss -893.70594  last_update 0\n",
      "train: iter 155  trainloss -760.57753  validloss -727.44778±0.00000  bestvalidloss -893.70594  last_update 1\n",
      "train: iter 156  trainloss -818.31673  validloss -931.62704±0.00000  bestvalidloss -931.62704  last_update 0\n",
      "train: iter 157  trainloss -888.72786  validloss -924.22709±0.00000  bestvalidloss -931.62704  last_update 1\n",
      "train: iter 158  trainloss -755.83885  validloss -682.99439±0.00000  bestvalidloss -931.62704  last_update 2\n",
      "train: iter 159  trainloss -865.96686  validloss -828.93019±0.00000  bestvalidloss -931.62704  last_update 3\n",
      "train: iter 160  trainloss -779.63024  validloss -556.91714±0.00000  bestvalidloss -931.62704  last_update 4\n",
      "train: iter 161  trainloss -791.78968  validloss -680.85897±0.00000  bestvalidloss -931.62704  last_update 5\n",
      "train: iter 162  trainloss -842.14491  validloss -898.81387±0.00000  bestvalidloss -931.62704  last_update 6\n",
      "train: iter 163  trainloss -848.94673  validloss -855.82159±0.00000  bestvalidloss -931.62704  last_update 7\n",
      "train: iter 164  trainloss -817.07458  validloss -738.08965±0.00000  bestvalidloss -931.62704  last_update 8\n",
      "train: iter 165  trainloss -847.37481  validloss -760.32697±0.00000  bestvalidloss -931.62704  last_update 9\n",
      "train: iter 166  trainloss -346.71488  validloss -963.29080±0.00000  bestvalidloss -963.29080  last_update 0\n",
      "train: iter 167  trainloss -264.35680  validloss -521.95865±0.00000  bestvalidloss -963.29080  last_update 1\n",
      "train: iter 168  trainloss -513.93347  validloss -532.48438±0.00000  bestvalidloss -963.29080  last_update 2\n",
      "train: iter 169  trainloss -515.48838  validloss -535.48835±0.00000  bestvalidloss -963.29080  last_update 3\n",
      "train: iter 170  trainloss -725.09417  validloss -786.44140±0.00000  bestvalidloss -963.29080  last_update 4\n",
      "train: iter 171  trainloss -627.17097  validloss -848.34128±0.00000  bestvalidloss -963.29080  last_update 5\n",
      "train: iter 172  trainloss -661.82176  validloss -754.78786±0.00000  bestvalidloss -963.29080  last_update 6\n",
      "train: iter 173  trainloss -803.82489  validloss -856.85653±0.00000  bestvalidloss -963.29080  last_update 7\n",
      "train: iter 174  trainloss -763.75501  validloss -808.26758±0.00000  bestvalidloss -963.29080  last_update 8\n",
      "train: iter 175  trainloss -790.95875  validloss -913.49585±0.00000  bestvalidloss -963.29080  last_update 9\n",
      "train: iter 176  trainloss -845.71382  validloss -698.26598±0.00000  bestvalidloss -963.29080  last_update 10\n",
      "train: iter 177  trainloss -858.03778  validloss -933.40477±0.00000  bestvalidloss -963.29080  last_update 11\n",
      "train: iter 178  trainloss -857.58801  validloss -899.15608±0.00000  bestvalidloss -963.29080  last_update 12\n",
      "train: iter 179  trainloss -833.81694  validloss -858.16833±0.00000  bestvalidloss -963.29080  last_update 13\n",
      "train: iter 180  trainloss -877.29045  validloss -906.75764±0.00000  bestvalidloss -963.29080  last_update 14\n",
      "train: iter 181  trainloss -801.74849  validloss -982.77053±0.00000  bestvalidloss -982.77053  last_update 0\n",
      "train: iter 182  trainloss -908.08102  validloss -668.41740±0.00000  bestvalidloss -982.77053  last_update 1\n",
      "train: iter 183  trainloss -888.27759  validloss -961.71499±0.00000  bestvalidloss -982.77053  last_update 2\n",
      "train: iter 184  trainloss -904.60252  validloss -1006.63849±0.00000  bestvalidloss -1006.63849  last_update 0\n",
      "train: iter 185  trainloss -893.10572  validloss -874.93491±0.00000  bestvalidloss -1006.63849  last_update 1\n",
      "train: iter 186  trainloss -987.92900  validloss -980.77183±0.00000  bestvalidloss -1006.63849  last_update 2\n",
      "train: iter 187  trainloss -906.77839  validloss -992.18173±0.00000  bestvalidloss -1006.63849  last_update 3\n",
      "train: iter 188  trainloss -950.49653  validloss -922.12144±0.00000  bestvalidloss -1006.63849  last_update 4\n",
      "train: iter 189  trainloss -970.78001  validloss -1029.20376±0.00000  bestvalidloss -1029.20376  last_update 0\n",
      "train: iter 190  trainloss -928.17579  validloss -1024.58904±0.00000  bestvalidloss -1029.20376  last_update 1\n",
      "train: iter 191  trainloss -960.15626  validloss -993.27535±0.00000  bestvalidloss -1029.20376  last_update 2\n",
      "train: iter 192  trainloss -934.94000  validloss -965.31975±0.00000  bestvalidloss -1029.20376  last_update 3\n",
      "train: iter 193  trainloss -854.01774  validloss -875.94894±0.00000  bestvalidloss -1029.20376  last_update 4\n",
      "train: iter 194  trainloss -934.12479  validloss -1051.57330±0.00000  bestvalidloss -1051.57330  last_update 0\n",
      "train: iter 195  trainloss -1014.17967  validloss -1027.13437±0.00000  bestvalidloss -1051.57330  last_update 1\n",
      "train: iter 196  trainloss -1004.09949  validloss -1008.95799±0.00000  bestvalidloss -1051.57330  last_update 2\n",
      "train: iter 197  trainloss -900.55555  validloss -1072.47988±0.00000  bestvalidloss -1072.47988  last_update 0\n",
      "train: iter 198  trainloss -981.31156  validloss -975.31025±0.00000  bestvalidloss -1072.47988  last_update 1\n",
      "train: iter 199  trainloss -1000.08486  validloss -976.81229±0.00000  bestvalidloss -1072.47988  last_update 2\n",
      "train: iter 200  trainloss -896.12277  validloss -1105.14552±0.00000  bestvalidloss -1105.14552  last_update 0\n",
      "train: iter 201  trainloss -780.45718  validloss -507.65024±0.00000  bestvalidloss -1105.14552  last_update 1\n",
      "train: iter 202  trainloss -946.68203  validloss -945.21981±0.00000  bestvalidloss -1105.14552  last_update 2\n",
      "train: iter 203  trainloss -1027.03649  validloss -975.73436±0.00000  bestvalidloss -1105.14552  last_update 3\n",
      "train: iter 204  trainloss -988.96664  validloss -1076.69278±0.00000  bestvalidloss -1105.14552  last_update 4\n",
      "train: iter 205  trainloss -997.23117  validloss -962.88841±0.00000  bestvalidloss -1105.14552  last_update 5\n",
      "train: iter 206  trainloss -1067.99402  validloss -1104.02468±0.00000  bestvalidloss -1105.14552  last_update 6\n",
      "train: iter 207  trainloss -1058.75959  validloss -1131.10527±0.00000  bestvalidloss -1131.10527  last_update 0\n",
      "train: iter 208  trainloss -914.05605  validloss -1007.67730±0.00000  bestvalidloss -1131.10527  last_update 1\n",
      "train: iter 209  trainloss -924.09899  validloss -961.64337±0.00000  bestvalidloss -1131.10527  last_update 2\n",
      "train: iter 210  trainloss -829.67084  validloss -1065.99774±0.00000  bestvalidloss -1131.10527  last_update 3\n",
      "train: iter 211  trainloss -873.59108  validloss -977.73302±0.00000  bestvalidloss -1131.10527  last_update 4\n",
      "train: iter 212  trainloss -838.49839  validloss -1002.10554±0.00000  bestvalidloss -1131.10527  last_update 5\n",
      "train: iter 213  trainloss -1021.05734  validloss -1046.21030±0.00000  bestvalidloss -1131.10527  last_update 6\n",
      "train: iter 214  trainloss -1032.00445  validloss -1142.31337±0.00000  bestvalidloss -1142.31337  last_update 0\n",
      "train: iter 215  trainloss -1000.53335  validloss -1005.58756±0.00000  bestvalidloss -1142.31337  last_update 1\n",
      "train: iter 216  trainloss -1026.62387  validloss -1049.10387±0.00000  bestvalidloss -1142.31337  last_update 2\n",
      "train: iter 217  trainloss -1007.91083  validloss -1172.90352±0.00000  bestvalidloss -1172.90352  last_update 0\n",
      "train: iter 218  trainloss -982.52344  validloss -1008.45605±0.00000  bestvalidloss -1172.90352  last_update 1\n",
      "train: iter 219  trainloss -1035.52651  validloss -1105.46527±0.00000  bestvalidloss -1172.90352  last_update 2\n",
      "train: iter 220  trainloss -1065.17709  validloss -1131.21890±0.00000  bestvalidloss -1172.90352  last_update 3\n",
      "train: iter 221  trainloss -1038.56177  validloss -1050.79149±0.00000  bestvalidloss -1172.90352  last_update 4\n",
      "train: iter 222  trainloss -800.50145  validloss -1106.81448±0.00000  bestvalidloss -1172.90352  last_update 5\n",
      "train: iter 223  trainloss -880.72776  validloss -1015.48613±0.00000  bestvalidloss -1172.90352  last_update 6\n",
      "train: iter 224  trainloss -915.20403  validloss -1009.03887±0.00000  bestvalidloss -1172.90352  last_update 7\n",
      "train: iter 225  trainloss -1038.35600  validloss -1031.92477±0.00000  bestvalidloss -1172.90352  last_update 8\n",
      "train: iter 226  trainloss -934.77580  validloss -904.44576±0.00000  bestvalidloss -1172.90352  last_update 9\n",
      "train: iter 227  trainloss -773.01836  validloss -571.36713±0.00000  bestvalidloss -1172.90352  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1081.83054  validloss -1058.17499±0.00000  bestvalidloss -1172.90352  last_update 11\n",
      "train: iter 229  trainloss -1044.34623  validloss -1063.48487±0.00000  bestvalidloss -1172.90352  last_update 12\n",
      "train: iter 230  trainloss -1054.49597  validloss -965.04837±0.00000  bestvalidloss -1172.90352  last_update 13\n",
      "train: iter 231  trainloss -1134.54591  validloss -1181.25183±0.00000  bestvalidloss -1181.25183  last_update 0\n",
      "train: iter 232  trainloss -1110.50973  validloss -1198.08695±0.00000  bestvalidloss -1198.08695  last_update 0\n",
      "train: iter 233  trainloss -1117.57915  validloss -1168.63073±0.00000  bestvalidloss -1198.08695  last_update 1\n",
      "train: iter 234  trainloss -1140.00698  validloss -1232.62103±0.00000  bestvalidloss -1232.62103  last_update 0\n",
      "train: iter 235  trainloss -1095.70413  validloss -1092.51654±0.00000  bestvalidloss -1232.62103  last_update 1\n",
      "train: iter 236  trainloss -1080.70044  validloss -1139.37848±0.00000  bestvalidloss -1232.62103  last_update 2\n",
      "train: iter 237  trainloss -982.90407  validloss -583.86463±0.00000  bestvalidloss -1232.62103  last_update 3\n",
      "train: iter 238  trainloss -992.14821  validloss -1015.83743±0.00000  bestvalidloss -1232.62103  last_update 4\n",
      "train: iter 239  trainloss -1064.02434  validloss -717.35364±0.00000  bestvalidloss -1232.62103  last_update 5\n",
      "train: iter 240  trainloss -1100.09540  validloss -1199.04663±0.00000  bestvalidloss -1232.62103  last_update 6\n",
      "train: iter 241  trainloss -1160.00192  validloss -1228.28299±0.00000  bestvalidloss -1232.62103  last_update 7\n",
      "train: iter 242  trainloss -695.21957  validloss -1167.96749±0.00000  bestvalidloss -1232.62103  last_update 8\n",
      "train: iter 243  trainloss -989.38670  validloss -774.52434±0.00000  bestvalidloss -1232.62103  last_update 9\n",
      "train: iter 244  trainloss -1089.56508  validloss -1173.28008±0.00000  bestvalidloss -1232.62103  last_update 10\n",
      "train: iter 245  trainloss -1075.09271  validloss -1147.23501±0.00000  bestvalidloss -1232.62103  last_update 11\n",
      "train: iter 246  trainloss -1047.32304  validloss -1093.47831±0.00000  bestvalidloss -1232.62103  last_update 12\n",
      "train: iter 247  trainloss -1045.33973  validloss -1172.78702±0.00000  bestvalidloss -1232.62103  last_update 13\n",
      "train: iter 248  trainloss -1169.87235  validloss -1212.15058±0.00000  bestvalidloss -1232.62103  last_update 14\n",
      "train: iter 249  trainloss -1023.56027  validloss -1208.12053±0.00000  bestvalidloss -1232.62103  last_update 15\n",
      "train: iter 250  trainloss -1088.27748  validloss -418.94374±0.00000  bestvalidloss -1232.62103  last_update 16\n",
      "train: iter 251  trainloss -1103.17557  validloss -869.23508±0.00000  bestvalidloss -1232.62103  last_update 17\n",
      "train: iter 252  trainloss -1085.93890  validloss -1174.74454±0.00000  bestvalidloss -1232.62103  last_update 18\n",
      "train: iter 253  trainloss -1077.14785  validloss -1232.16701±0.00000  bestvalidloss -1232.62103  last_update 19\n",
      "train: iter 254  trainloss -1177.18510  validloss -1231.14055±0.00000  bestvalidloss -1232.62103  last_update 20\n",
      "train: iter 255  trainloss -1158.48489  validloss -1265.67446±0.00000  bestvalidloss -1265.67446  last_update 0\n",
      "train: iter 256  trainloss -1107.73423  validloss -1201.76193±0.00000  bestvalidloss -1265.67446  last_update 1\n",
      "train: iter 257  trainloss -1125.98475  validloss -1159.80057±0.00000  bestvalidloss -1265.67446  last_update 2\n",
      "train: iter 258  trainloss -1165.28240  validloss -1147.87825±0.00000  bestvalidloss -1265.67446  last_update 3\n",
      "train: iter 259  trainloss -1147.68072  validloss -1208.81878±0.00000  bestvalidloss -1265.67446  last_update 4\n",
      "train: iter 260  trainloss -1065.80668  validloss -691.05362±0.00000  bestvalidloss -1265.67446  last_update 5\n",
      "train: iter 261  trainloss -1071.56770  validloss -1030.81966±0.00000  bestvalidloss -1265.67446  last_update 6\n",
      "train: iter 262  trainloss -1095.68531  validloss -1141.24630±0.00000  bestvalidloss -1265.67446  last_update 7\n",
      "train: iter 263  trainloss -1128.18126  validloss -1133.83914±0.00000  bestvalidloss -1265.67446  last_update 8\n",
      "train: iter 264  trainloss -1125.41608  validloss -1227.56032±0.00000  bestvalidloss -1265.67446  last_update 9\n",
      "train: iter 265  trainloss -364.19908  validloss -1072.38041±0.00000  bestvalidloss -1265.67446  last_update 10\n",
      "train: iter 266  trainloss -552.92297  validloss -66.61034±0.00000  bestvalidloss -1265.67446  last_update 11\n",
      "train: iter 267  trainloss -82.87795  validloss -959.73157±0.00000  bestvalidloss -1265.67446  last_update 12\n",
      "train: iter 268  trainloss -518.34482  validloss -435.60182±0.00000  bestvalidloss -1265.67446  last_update 13\n",
      "train: iter 269  trainloss -756.56397  validloss -762.37412±0.00000  bestvalidloss -1265.67446  last_update 14\n",
      "train: iter 270  trainloss -863.55414  validloss -933.48752±0.00000  bestvalidloss -1265.67446  last_update 15\n",
      "train: iter 271  trainloss -929.51456  validloss -993.49692±0.00000  bestvalidloss -1265.67446  last_update 16\n",
      "train: iter 272  trainloss -1014.94743  validloss -1078.77398±0.00000  bestvalidloss -1265.67446  last_update 17\n",
      "train: iter 273  trainloss -1037.20330  validloss -1142.63115±0.00000  bestvalidloss -1265.67446  last_update 18\n",
      "train: iter 274  trainloss -794.84491  validloss -1057.51437±0.00000  bestvalidloss -1265.67446  last_update 19\n",
      "train: iter 275  trainloss -926.89803  validloss -1072.01611±0.00000  bestvalidloss -1265.67446  last_update 20\n",
      "train: iter 276  trainloss -1090.33186  validloss -1119.74214±0.00000  bestvalidloss -1265.67446  last_update 21\n",
      "train: iter 277  trainloss -875.07908  validloss -1107.88831±0.00000  bestvalidloss -1265.67446  last_update 22\n",
      "train: iter 278  trainloss -1069.47151  validloss -1103.06684±0.00000  bestvalidloss -1265.67446  last_update 23\n",
      "train: iter 279  trainloss -1153.05974  validloss -1178.03731±0.00000  bestvalidloss -1265.67446  last_update 24\n",
      "train: iter 280  trainloss -952.24615  validloss -1210.91557±0.00000  bestvalidloss -1265.67446  last_update 25\n",
      "train: iter 281  trainloss -1079.85388  validloss -1052.34529±0.00000  bestvalidloss -1265.67446  last_update 26\n",
      "train: iter 282  trainloss -1129.68761  validloss -1171.94133±0.00000  bestvalidloss -1265.67446  last_update 27\n",
      "train: iter 283  trainloss -1185.02898  validloss -1204.20584±0.00000  bestvalidloss -1265.67446  last_update 28\n",
      "train: iter 284  trainloss -1128.20283  validloss -1243.48255±0.00000  bestvalidloss -1265.67446  last_update 29\n",
      "train: iter 285  trainloss -1039.42688  validloss -1253.06471±0.00000  bestvalidloss -1265.67446  last_update 30\n",
      "train: iter 286  trainloss -1179.12206  validloss -1126.76217±0.00000  bestvalidloss -1265.67446  last_update 31\n",
      "train: iter 287  trainloss -1166.16856  validloss -1233.36791±0.00000  bestvalidloss -1265.67446  last_update 32\n",
      "train: iter 288  trainloss -1102.22629  validloss -1222.38554±0.00000  bestvalidloss -1265.67446  last_update 33\n",
      "train: iter 289  trainloss -1162.02389  validloss -1248.62023±0.00000  bestvalidloss -1265.67446  last_update 34\n",
      "train: iter 290  trainloss -1156.62712  validloss -1129.45017±0.00000  bestvalidloss -1265.67446  last_update 35\n",
      "train: iter 291  trainloss -1179.11423  validloss -1262.90413±0.00000  bestvalidloss -1265.67446  last_update 36\n",
      "train: iter 292  trainloss -1166.54209  validloss -1141.22934±0.00000  bestvalidloss -1265.67446  last_update 37\n",
      "train: iter 293  trainloss -1156.14606  validloss -1183.33487±0.00000  bestvalidloss -1265.67446  last_update 38\n",
      "train: iter 294  trainloss -1165.82279  validloss -1253.74117±0.00000  bestvalidloss -1265.67446  last_update 39\n",
      "train: iter 295  trainloss -1173.77110  validloss -1239.89944±0.00000  bestvalidloss -1265.67446  last_update 40\n",
      "train: iter 296  trainloss -1156.38747  validloss -1109.45997±0.00000  bestvalidloss -1265.67446  last_update 41\n",
      "train: iter 297  trainloss -809.64740  validloss -886.87535±0.00000  bestvalidloss -1265.67446  last_update 42\n",
      "train: iter 298  trainloss -1168.18852  validloss -1142.86410±0.00000  bestvalidloss -1265.67446  last_update 43\n",
      "train: iter 299  trainloss -1112.84396  validloss -1185.68376±0.00000  bestvalidloss -1265.67446  last_update 44\n",
      "train: iter 300  trainloss -1216.71571  validloss -1119.62934±0.00000  bestvalidloss -1265.67446  last_update 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 301  trainloss -1178.30771  validloss -1275.65180±0.00000  bestvalidloss -1275.65180  last_update 0\n",
      "train: iter 302  trainloss -1193.33995  validloss -958.89896±0.00000  bestvalidloss -1275.65180  last_update 1\n",
      "train: iter 303  trainloss -1204.10903  validloss -1268.59115±0.00000  bestvalidloss -1275.65180  last_update 2\n",
      "train: iter 304  trainloss -1117.66305  validloss -1303.96318±0.00000  bestvalidloss -1303.96318  last_update 0\n",
      "train: iter 305  trainloss -1162.03712  validloss -1189.10096±0.00000  bestvalidloss -1303.96318  last_update 1\n",
      "train: iter 306  trainloss -1204.84647  validloss -1259.87442±0.00000  bestvalidloss -1303.96318  last_update 2\n",
      "train: iter 307  trainloss -1251.77083  validloss -1302.92373±0.00000  bestvalidloss -1303.96318  last_update 3\n",
      "train: iter 308  trainloss -1229.95948  validloss -1296.12180±0.00000  bestvalidloss -1303.96318  last_update 4\n",
      "train: iter 309  trainloss -1161.13178  validloss -1209.78057±0.00000  bestvalidloss -1303.96318  last_update 5\n",
      "train: iter 310  trainloss -1156.10103  validloss -1248.66190±0.00000  bestvalidloss -1303.96318  last_update 6\n",
      "train: iter 311  trainloss -1195.00611  validloss -1207.65725±0.00000  bestvalidloss -1303.96318  last_update 7\n",
      "train: iter 312  trainloss -1267.21939  validloss -1309.89738±0.00000  bestvalidloss -1309.89738  last_update 0\n",
      "train: iter 313  trainloss -1076.66283  validloss -1312.41142±0.00000  bestvalidloss -1312.41142  last_update 0\n",
      "train: iter 314  trainloss -1043.47057  validloss -992.38837±0.00000  bestvalidloss -1312.41142  last_update 1\n",
      "train: iter 315  trainloss -1214.14063  validloss -1220.28419±0.00000  bestvalidloss -1312.41142  last_update 2\n",
      "train: iter 316  trainloss -1242.75654  validloss -1305.04679±0.00000  bestvalidloss -1312.41142  last_update 3\n",
      "train: iter 317  trainloss -1144.85028  validloss -1236.56085±0.00000  bestvalidloss -1312.41142  last_update 4\n",
      "train: iter 318  trainloss -1171.97627  validloss -1191.19479±0.00000  bestvalidloss -1312.41142  last_update 5\n",
      "train: iter 319  trainloss -1239.61531  validloss -1251.89837±0.00000  bestvalidloss -1312.41142  last_update 6\n",
      "train: iter 320  trainloss -1246.56501  validloss -1304.37203±0.00000  bestvalidloss -1312.41142  last_update 7\n",
      "train: iter 321  trainloss -1037.78860  validloss -1188.94548±0.00000  bestvalidloss -1312.41142  last_update 8\n",
      "train: iter 322  trainloss -1146.91475  validloss -956.68436±0.00000  bestvalidloss -1312.41142  last_update 9\n",
      "train: iter 323  trainloss -1225.73312  validloss -1151.99499±0.00000  bestvalidloss -1312.41142  last_update 10\n",
      "train: iter 324  trainloss -1279.82886  validloss -1313.70888±0.00000  bestvalidloss -1313.70888  last_update 0\n",
      "train: iter 325  trainloss -1109.79276  validloss -1332.48475±0.00000  bestvalidloss -1332.48475  last_update 0\n",
      "train: iter 326  trainloss -1239.55013  validloss -1256.99368±0.00000  bestvalidloss -1332.48475  last_update 1\n",
      "train: iter 327  trainloss -1218.40225  validloss -1233.61215±0.00000  bestvalidloss -1332.48475  last_update 2\n",
      "train: iter 328  trainloss -910.43381  validloss -1201.87327±0.00000  bestvalidloss -1332.48475  last_update 3\n",
      "train: iter 329  trainloss -1039.78676  validloss -840.32381±0.00000  bestvalidloss -1332.48475  last_update 4\n",
      "train: iter 330  trainloss -1218.69885  validloss -1280.31851±0.00000  bestvalidloss -1332.48475  last_update 5\n",
      "train: iter 331  trainloss -1253.58598  validloss -1319.75766±0.00000  bestvalidloss -1332.48475  last_update 6\n",
      "train: iter 332  trainloss -1033.01823  validloss -1180.49743±0.00000  bestvalidloss -1332.48475  last_update 7\n",
      "train: iter 333  trainloss -1210.15910  validloss -1267.55336±0.00000  bestvalidloss -1332.48475  last_update 8\n",
      "train: iter 334  trainloss -1091.97238  validloss -1154.86500±0.00000  bestvalidloss -1332.48475  last_update 9\n",
      "train: iter 335  trainloss -1241.81147  validloss -1281.30972±0.00000  bestvalidloss -1332.48475  last_update 10\n",
      "train: iter 336  trainloss -1261.91336  validloss -1314.92166±0.00000  bestvalidloss -1332.48475  last_update 11\n",
      "train: iter 337  trainloss -1216.52577  validloss -1179.64474±0.00000  bestvalidloss -1332.48475  last_update 12\n",
      "train: iter 338  trainloss -1063.52199  validloss -1139.64778±0.00000  bestvalidloss -1332.48475  last_update 13\n",
      "train: iter 339  trainloss -1243.88123  validloss -1127.95226±0.00000  bestvalidloss -1332.48475  last_update 14\n",
      "train: iter 340  trainloss -1034.03564  validloss -1349.43798±0.00000  bestvalidloss -1349.43798  last_update 0\n",
      "train: iter 341  trainloss -973.72387  validloss -883.50287±0.00000  bestvalidloss -1349.43798  last_update 1\n",
      "train: iter 342  trainloss -1169.56431  validloss -1161.70724±0.00000  bestvalidloss -1349.43798  last_update 2\n",
      "train: iter 343  trainloss -1257.04201  validloss -1285.86777±0.00000  bestvalidloss -1349.43798  last_update 3\n",
      "train: iter 344  trainloss -1180.65636  validloss -1319.43376±0.00000  bestvalidloss -1349.43798  last_update 4\n",
      "train: iter 345  trainloss -1204.73374  validloss -1124.68827±0.00000  bestvalidloss -1349.43798  last_update 5\n",
      "train: iter 346  trainloss -1207.51308  validloss -1253.49233±0.00000  bestvalidloss -1349.43798  last_update 6\n",
      "train: iter 347  trainloss -1298.97039  validloss -1345.86716±0.00000  bestvalidloss -1349.43798  last_update 7\n",
      "train: iter 348  trainloss -1177.62449  validloss -1362.07458±0.00000  bestvalidloss -1362.07458  last_update 0\n",
      "train: iter 349  trainloss -1208.06216  validloss -1174.14792±0.00000  bestvalidloss -1362.07458  last_update 1\n",
      "train: iter 350  trainloss -1243.42393  validloss -1293.67121±0.00000  bestvalidloss -1362.07458  last_update 2\n",
      "train: iter 351  trainloss -1229.44879  validloss -1350.17102±0.00000  bestvalidloss -1362.07458  last_update 3\n",
      "train: iter 352  trainloss -1096.14184  validloss -1158.82184±0.00000  bestvalidloss -1362.07458  last_update 4\n",
      "train: iter 353  trainloss -1254.07285  validloss -1204.53290±0.00000  bestvalidloss -1362.07458  last_update 5\n",
      "train: iter 354  trainloss -1293.17739  validloss -1311.22175±0.00000  bestvalidloss -1362.07458  last_update 6\n",
      "train: iter 355  trainloss -1179.01788  validloss -1330.77084±0.00000  bestvalidloss -1362.07458  last_update 7\n",
      "train: iter 356  trainloss -1134.77097  validloss -1157.90576±0.00000  bestvalidloss -1362.07458  last_update 8\n",
      "train: iter 357  trainloss -1299.21994  validloss -1335.68383±0.00000  bestvalidloss -1362.07458  last_update 9\n",
      "train: iter 358  trainloss -1301.56992  validloss -1400.60027±0.00000  bestvalidloss -1400.60027  last_update 0\n",
      "train: iter 359  trainloss -1084.64412  validloss -1328.94475±0.00000  bestvalidloss -1400.60027  last_update 1\n",
      "train: iter 360  trainloss -1108.58218  validloss -896.78483±0.00000  bestvalidloss -1400.60027  last_update 2\n",
      "train: iter 361  trainloss -1199.86427  validloss -1108.36150±0.00000  bestvalidloss -1400.60027  last_update 3\n",
      "train: iter 362  trainloss -1207.69038  validloss -1289.03545±0.00000  bestvalidloss -1400.60027  last_update 4\n",
      "train: iter 363  trainloss -1223.31660  validloss -1102.89319±0.00000  bestvalidloss -1400.60027  last_update 5\n",
      "train: iter 364  trainloss -1250.70302  validloss -1102.95723±0.00000  bestvalidloss -1400.60027  last_update 6\n",
      "train: iter 365  trainloss -1275.27177  validloss -1354.17595±0.00000  bestvalidloss -1400.60027  last_update 7\n",
      "train: iter 366  trainloss -1238.68793  validloss -1299.12360±0.00000  bestvalidloss -1400.60027  last_update 8\n",
      "train: iter 367  trainloss -1305.67645  validloss -1359.81758±0.00000  bestvalidloss -1400.60027  last_update 9\n",
      "train: iter 368  trainloss -1310.00076  validloss -1283.01364±0.00000  bestvalidloss -1400.60027  last_update 10\n",
      "train: iter 369  trainloss -1273.75713  validloss -1268.78251±0.00000  bestvalidloss -1400.60027  last_update 11\n",
      "train: iter 370  trainloss -1249.50192  validloss -1354.73943±0.00000  bestvalidloss -1400.60027  last_update 12\n",
      "train: iter 371  trainloss -1245.95158  validloss -1345.76884±0.00000  bestvalidloss -1400.60027  last_update 13\n",
      "train: iter 372  trainloss -1244.20227  validloss -1292.11911±0.00000  bestvalidloss -1400.60027  last_update 14\n",
      "train: iter 373  trainloss -1286.73406  validloss -1387.18744±0.00000  bestvalidloss -1400.60027  last_update 15\n",
      "train: iter 374  trainloss -1091.98711  validloss -1328.01988±0.00000  bestvalidloss -1400.60027  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 375  trainloss -1072.40381  validloss -1151.11379±0.00000  bestvalidloss -1400.60027  last_update 17\n",
      "train: iter 376  trainloss -1237.17414  validloss -1205.93766±0.00000  bestvalidloss -1400.60027  last_update 18\n",
      "train: iter 377  trainloss -1261.96485  validloss -1301.16883±0.00000  bestvalidloss -1400.60027  last_update 19\n",
      "train: iter 378  trainloss -1145.28899  validloss -1359.29832±0.00000  bestvalidloss -1400.60027  last_update 20\n",
      "train: iter 379  trainloss -1052.32545  validloss -999.48448±0.00000  bestvalidloss -1400.60027  last_update 21\n",
      "train: iter 380  trainloss -1234.37563  validloss -1034.90601±0.00000  bestvalidloss -1400.60027  last_update 22\n",
      "train: iter 381  trainloss -1295.71815  validloss -1277.17575±0.00000  bestvalidloss -1400.60027  last_update 23\n",
      "train: iter 382  trainloss -1270.29718  validloss -1362.49852±0.00000  bestvalidloss -1400.60027  last_update 24\n",
      "train: iter 383  trainloss -1256.27791  validloss -1336.20559±0.00000  bestvalidloss -1400.60027  last_update 25\n",
      "train: iter 384  trainloss -1301.03359  validloss -1324.79899±0.00000  bestvalidloss -1400.60027  last_update 26\n",
      "train: iter 385  trainloss -1276.76056  validloss -1382.73533±0.00000  bestvalidloss -1400.60027  last_update 27\n",
      "train: iter 386  trainloss -1285.91622  validloss -1311.65813±0.00000  bestvalidloss -1400.60027  last_update 28\n",
      "train: iter 387  trainloss -1309.22989  validloss -1359.04640±0.00000  bestvalidloss -1400.60027  last_update 29\n",
      "train: iter 388  trainloss -1246.09163  validloss -1381.08214±0.00000  bestvalidloss -1400.60027  last_update 30\n",
      "train: iter 389  trainloss -1280.84469  validloss -1303.91399±0.00000  bestvalidloss -1400.60027  last_update 31\n",
      "train: iter 390  trainloss -1244.94176  validloss -1343.57579±0.00000  bestvalidloss -1400.60027  last_update 32\n",
      "train: iter 391  trainloss -1300.83256  validloss -1215.74237±0.00000  bestvalidloss -1400.60027  last_update 33\n",
      "train: iter 392  trainloss -1332.91379  validloss -1401.77579±0.00000  bestvalidloss -1401.77579  last_update 0\n",
      "train: iter 393  trainloss -1244.87723  validloss -1320.80659±0.00000  bestvalidloss -1401.77579  last_update 1\n",
      "train: iter 394  trainloss -1339.69405  validloss -1356.00508±0.00000  bestvalidloss -1401.77579  last_update 2\n",
      "train: iter 395  trainloss -1130.40599  validloss -1185.98414±0.00000  bestvalidloss -1401.77579  last_update 3\n",
      "train: iter 396  trainloss -1271.50652  validloss -1268.18017±0.00000  bestvalidloss -1401.77579  last_update 4\n",
      "train: iter 397  trainloss -1339.91640  validloss -1411.61947±0.00000  bestvalidloss -1411.61947  last_update 0\n",
      "train: iter 398  trainloss -1149.91068  validloss -1372.53540±0.00000  bestvalidloss -1411.61947  last_update 1\n",
      "train: iter 399  trainloss -1144.73760  validloss -1164.04146±0.00000  bestvalidloss -1411.61947  last_update 2\n",
      "train: iter 400  trainloss -1298.90246  validloss -1222.79657±0.00000  bestvalidloss -1411.61947  last_update 3\n",
      "train: iter 401  trainloss -1314.67151  validloss -1348.21763±0.00000  bestvalidloss -1411.61947  last_update 4\n",
      "train: iter 402  trainloss -1307.73605  validloss -1374.29498±0.00000  bestvalidloss -1411.61947  last_update 5\n",
      "train: iter 403  trainloss -1316.26367  validloss -1307.54666±0.00000  bestvalidloss -1411.61947  last_update 6\n",
      "train: iter 404  trainloss -1186.38848  validloss -1350.14615±0.00000  bestvalidloss -1411.61947  last_update 7\n",
      "train: iter 405  trainloss -1293.74844  validloss -1317.06642±0.00000  bestvalidloss -1411.61947  last_update 8\n",
      "train: iter 406  trainloss -1316.39931  validloss -1353.46363±0.00000  bestvalidloss -1411.61947  last_update 9\n",
      "train: iter 407  trainloss -1311.31454  validloss -1361.03791±0.00000  bestvalidloss -1411.61947  last_update 10\n",
      "train: iter 408  trainloss -1333.57611  validloss -1388.90796±0.00000  bestvalidloss -1411.61947  last_update 11\n",
      "train: iter 409  trainloss -1204.78907  validloss -1308.41346±0.00000  bestvalidloss -1411.61947  last_update 12\n",
      "train: iter 410  trainloss -1344.82017  validloss -1397.51826±0.00000  bestvalidloss -1411.61947  last_update 13\n",
      "train: iter 411  trainloss -1202.46432  validloss -1316.35086±0.00000  bestvalidloss -1411.61947  last_update 14\n",
      "train: iter 412  trainloss -1303.40555  validloss -1327.79450±0.00000  bestvalidloss -1411.61947  last_update 15\n",
      "train: iter 413  trainloss -1298.50655  validloss -1256.26796±0.00000  bestvalidloss -1411.61947  last_update 16\n",
      "train: iter 414  trainloss -1361.28748  validloss -1412.06896±0.00000  bestvalidloss -1412.06896  last_update 0\n",
      "train: iter 415  trainloss -1211.46713  validloss -1398.31459±0.00000  bestvalidloss -1412.06896  last_update 1\n",
      "train: iter 416  trainloss -1238.74220  validloss -890.64211±0.00000  bestvalidloss -1412.06896  last_update 2\n",
      "train: iter 417  trainloss -1328.61723  validloss -1380.88617±0.00000  bestvalidloss -1412.06896  last_update 3\n",
      "train: iter 418  trainloss -1271.35563  validloss -1409.50732±0.00000  bestvalidloss -1412.06896  last_update 4\n",
      "train: iter 419  trainloss -1246.95878  validloss -1414.11050±0.00000  bestvalidloss -1414.11050  last_update 0\n",
      "train: iter 420  trainloss -1333.91614  validloss -1312.21445±0.00000  bestvalidloss -1414.11050  last_update 1\n",
      "train: iter 421  trainloss -1376.55720  validloss -1424.67131±0.00000  bestvalidloss -1424.67131  last_update 0\n",
      "train: iter 422  trainloss -1270.05325  validloss -1318.63137±0.00000  bestvalidloss -1424.67131  last_update 1\n",
      "train: iter 423  trainloss -1252.79476  validloss -1350.95848±0.00000  bestvalidloss -1424.67131  last_update 2\n",
      "train: iter 424  trainloss -1341.02827  validloss -1291.55631±0.00000  bestvalidloss -1424.67131  last_update 3\n",
      "train: iter 425  trainloss -1393.12357  validloss -1442.76763±0.00000  bestvalidloss -1442.76763  last_update 0\n",
      "train: iter 426  trainloss -1379.35094  validloss -1417.61995±0.00000  bestvalidloss -1442.76763  last_update 1\n",
      "train: iter 427  trainloss -1209.02513  validloss -1227.12755±0.00000  bestvalidloss -1442.76763  last_update 2\n",
      "train: iter 428  trainloss -1357.16824  validloss -1395.68925±0.00000  bestvalidloss -1442.76763  last_update 3\n",
      "train: iter 429  trainloss -1216.13868  validloss -1425.07398±0.00000  bestvalidloss -1442.76763  last_update 4\n",
      "train: iter 430  trainloss -1311.47585  validloss -1213.18074±0.00000  bestvalidloss -1442.76763  last_update 5\n",
      "train: iter 431  trainloss -1251.53886  validloss -1395.51361±0.00000  bestvalidloss -1442.76763  last_update 6\n",
      "train: iter 432  trainloss -1116.14930  validloss -1197.61562±0.00000  bestvalidloss -1442.76763  last_update 7\n",
      "train: iter 433  trainloss -1263.41778  validloss -1312.07780±0.00000  bestvalidloss -1442.76763  last_update 8\n",
      "train: iter 434  trainloss -1255.24638  validloss -1291.11121±0.00000  bestvalidloss -1442.76763  last_update 9\n",
      "train: iter 435  trainloss -1316.35308  validloss -1372.11628±0.00000  bestvalidloss -1442.76763  last_update 10\n",
      "train: iter 436  trainloss -1346.50985  validloss -1403.23391±0.00000  bestvalidloss -1442.76763  last_update 11\n",
      "train: iter 437  trainloss -1290.49009  validloss -1349.43141±0.00000  bestvalidloss -1442.76763  last_update 12\n",
      "train: iter 438  trainloss -1269.89118  validloss -1399.97923±0.00000  bestvalidloss -1442.76763  last_update 13\n",
      "train: iter 439  trainloss -1334.22095  validloss -1281.24740±0.00000  bestvalidloss -1442.76763  last_update 14\n",
      "train: iter 440  trainloss -1377.41428  validloss -1443.79335±0.00000  bestvalidloss -1443.79335  last_update 0\n",
      "train: iter 441  trainloss -1352.27188  validloss -1288.32007±0.00000  bestvalidloss -1443.79335  last_update 1\n",
      "train: iter 442  trainloss -1386.95990  validloss -1392.92896±0.00000  bestvalidloss -1443.79335  last_update 2\n",
      "train: iter 443  trainloss -1373.57402  validloss -1408.59928±0.00000  bestvalidloss -1443.79335  last_update 3\n",
      "train: iter 444  trainloss -1211.72371  validloss -1144.15111±0.00000  bestvalidloss -1443.79335  last_update 4\n",
      "train: iter 445  trainloss -1315.78455  validloss -1330.14489±0.00000  bestvalidloss -1443.79335  last_update 5\n",
      "train: iter 446  trainloss -1377.41346  validloss -1385.74490±0.00000  bestvalidloss -1443.79335  last_update 6\n",
      "train: iter 447  trainloss -1360.86819  validloss -1390.47399±0.00000  bestvalidloss -1443.79335  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 448  trainloss -1367.01749  validloss -1410.60689±0.00000  bestvalidloss -1443.79335  last_update 8\n",
      "train: iter 449  trainloss -1353.34462  validloss -1382.74521±0.00000  bestvalidloss -1443.79335  last_update 9\n",
      "train: iter 450  trainloss -1250.42104  validloss -1393.70314±0.00000  bestvalidloss -1443.79335  last_update 10\n",
      "train: iter 451  trainloss -1318.97110  validloss -1310.46753±0.00000  bestvalidloss -1443.79335  last_update 11\n",
      "train: iter 452  trainloss -1315.16079  validloss -1395.43244±0.00000  bestvalidloss -1443.79335  last_update 12\n",
      "train: iter 453  trainloss -1198.76868  validloss -1312.50867±0.00000  bestvalidloss -1443.79335  last_update 13\n",
      "train: iter 454  trainloss -1361.19566  validloss -1353.19518±0.00000  bestvalidloss -1443.79335  last_update 14\n",
      "train: iter 455  trainloss -1406.08091  validloss -1402.89812±0.00000  bestvalidloss -1443.79335  last_update 15\n",
      "train: iter 456  trainloss -1346.11336  validloss -1460.72684±0.00000  bestvalidloss -1460.72684  last_update 0\n",
      "train: iter 457  trainloss -1363.90830  validloss -1337.03878±0.00000  bestvalidloss -1460.72684  last_update 1\n",
      "train: iter 458  trainloss -1300.46162  validloss -1437.96316±0.00000  bestvalidloss -1460.72684  last_update 2\n",
      "train: iter 459  trainloss -1317.33121  validloss -1412.36238±0.00000  bestvalidloss -1460.72684  last_update 3\n",
      "train: iter 460  trainloss -1069.21708  validloss -454.47957±0.00000  bestvalidloss -1460.72684  last_update 4\n",
      "train: iter 461  trainloss -1321.14957  validloss -1373.83579±0.00000  bestvalidloss -1460.72684  last_update 5\n",
      "train: iter 462  trainloss -1251.14330  validloss -1289.05962±0.00000  bestvalidloss -1460.72684  last_update 6\n",
      "train: iter 463  trainloss -1315.99270  validloss -1349.05101±0.00000  bestvalidloss -1460.72684  last_update 7\n",
      "train: iter 464  trainloss -1425.56297  validloss -1404.85147±0.00000  bestvalidloss -1460.72684  last_update 8\n",
      "train: iter 465  trainloss -1407.16589  validloss -1467.00885±0.00000  bestvalidloss -1467.00885  last_update 0\n",
      "train: iter 466  trainloss -1373.68315  validloss -1367.06755±0.00000  bestvalidloss -1467.00885  last_update 1\n",
      "train: iter 467  trainloss -1330.71119  validloss -1364.23766±0.00000  bestvalidloss -1467.00885  last_update 2\n",
      "train: iter 468  trainloss -1357.77342  validloss -1371.40431±0.00000  bestvalidloss -1467.00885  last_update 3\n",
      "train: iter 469  trainloss -1442.92123  validloss -1446.44566±0.00000  bestvalidloss -1467.00885  last_update 4\n",
      "train: iter 470  trainloss -1395.43603  validloss -1494.97266±0.00000  bestvalidloss -1494.97266  last_update 0\n",
      "train: iter 471  trainloss -1404.06880  validloss -1184.53780±0.00000  bestvalidloss -1494.97266  last_update 1\n",
      "train: iter 472  trainloss -1235.07043  validloss -1477.70915±0.00000  bestvalidloss -1494.97266  last_update 2\n",
      "train: iter 473  trainloss -1363.51544  validloss -1376.08108±0.00000  bestvalidloss -1494.97266  last_update 3\n",
      "train: iter 474  trainloss -1350.26606  validloss -1390.14051±0.00000  bestvalidloss -1494.97266  last_update 4\n",
      "train: iter 475  trainloss -1388.04908  validloss -1462.39896±0.00000  bestvalidloss -1494.97266  last_update 5\n",
      "train: iter 476  trainloss -1364.06195  validloss -1432.32042±0.00000  bestvalidloss -1494.97266  last_update 6\n",
      "train: iter 477  trainloss -1374.60398  validloss -1302.75279±0.00000  bestvalidloss -1494.97266  last_update 7\n",
      "train: iter 478  trainloss -1297.38481  validloss -1361.77517±0.00000  bestvalidloss -1494.97266  last_update 8\n",
      "train: iter 479  trainloss -1388.33581  validloss -1385.48506±0.00000  bestvalidloss -1494.97266  last_update 9\n",
      "train: iter 480  trainloss -1377.53290  validloss -1418.73334±0.00000  bestvalidloss -1494.97266  last_update 10\n",
      "train: iter 481  trainloss -1438.42990  validloss -1475.48924±0.00000  bestvalidloss -1494.97266  last_update 11\n",
      "train: iter 482  trainloss -1240.85224  validloss -1364.72054±0.00000  bestvalidloss -1494.97266  last_update 12\n",
      "train: iter 483  trainloss -1371.49171  validloss -1296.29638±0.00000  bestvalidloss -1494.97266  last_update 13\n",
      "train: iter 484  trainloss -1393.58242  validloss -1464.75643±0.00000  bestvalidloss -1494.97266  last_update 14\n",
      "train: iter 485  trainloss -1398.85849  validloss -1443.93600±0.00000  bestvalidloss -1494.97266  last_update 15\n",
      "train: iter 486  trainloss -1380.31956  validloss -1476.50651±0.00000  bestvalidloss -1494.97266  last_update 16\n",
      "train: iter 487  trainloss -1442.72492  validloss -1396.98598±0.00000  bestvalidloss -1494.97266  last_update 17\n",
      "train: iter 488  trainloss -1429.27613  validloss -1470.29887±0.00000  bestvalidloss -1494.97266  last_update 18\n",
      "train: iter 489  trainloss -1337.91510  validloss -1401.97308±0.00000  bestvalidloss -1494.97266  last_update 19\n",
      "train: iter 490  trainloss -1423.93904  validloss -1384.67385±0.00000  bestvalidloss -1494.97266  last_update 20\n",
      "train: iter 491  trainloss -1479.67765  validloss -1493.68655±0.00000  bestvalidloss -1494.97266  last_update 21\n",
      "train: iter 492  trainloss -1371.43601  validloss -1506.25338±0.00000  bestvalidloss -1506.25338  last_update 0\n",
      "train: iter 493  trainloss -1418.98253  validloss -1393.51828±0.00000  bestvalidloss -1506.25338  last_update 1\n",
      "train: iter 494  trainloss -1415.71605  validloss -1507.21771±0.00000  bestvalidloss -1507.21771  last_update 0\n",
      "train: iter 495  trainloss -1391.27988  validloss -1499.10114±0.00000  bestvalidloss -1507.21771  last_update 1\n",
      "train: iter 496  trainloss -1347.48222  validloss -1422.21555±0.00000  bestvalidloss -1507.21771  last_update 2\n",
      "train: iter 497  trainloss -1278.28407  validloss -1251.58243±0.00000  bestvalidloss -1507.21771  last_update 3\n",
      "train: iter 498  trainloss -1442.13440  validloss -1426.33205±0.00000  bestvalidloss -1507.21771  last_update 4\n",
      "train: iter 499  trainloss -1280.19285  validloss -1382.76787±0.00000  bestvalidloss -1507.21771  last_update 5\n",
      "train: iter 500  trainloss -1358.07247  validloss -1464.16781±0.00000  bestvalidloss -1507.21771  last_update 6\n",
      "train: iter 501  trainloss -1483.43530  validloss -1512.82009±0.00000  bestvalidloss -1512.82009  last_update 0\n",
      "train: iter 502  trainloss -1411.46818  validloss -1497.80575±0.00000  bestvalidloss -1512.82009  last_update 1\n",
      "train: iter 503  trainloss -1478.47095  validloss -1472.07993±0.00000  bestvalidloss -1512.82009  last_update 2\n",
      "train: iter 504  trainloss -1416.09197  validloss -1523.45121±0.00000  bestvalidloss -1523.45121  last_update 0\n",
      "train: iter 505  trainloss -1174.01555  validloss -1519.45657±0.00000  bestvalidloss -1523.45121  last_update 1\n",
      "train: iter 506  trainloss -1398.45119  validloss -1345.47029±0.00000  bestvalidloss -1523.45121  last_update 2\n",
      "train: iter 507  trainloss -1420.79922  validloss -1462.86435±0.00000  bestvalidloss -1523.45121  last_update 3\n",
      "train: iter 508  trainloss -1460.31061  validloss -1352.31486±0.00000  bestvalidloss -1523.45121  last_update 4\n",
      "train: iter 509  trainloss -1467.31360  validloss -1523.35478±0.00000  bestvalidloss -1523.45121  last_update 5\n",
      "train: iter 510  trainloss -1207.46744  validloss -1518.85239±0.00000  bestvalidloss -1523.45121  last_update 6\n",
      "train: iter 511  trainloss -1294.52731  validloss -1352.08849±0.00000  bestvalidloss -1523.45121  last_update 7\n",
      "train: iter 512  trainloss -1378.39709  validloss -1314.00405±0.00000  bestvalidloss -1523.45121  last_update 8\n",
      "train: iter 513  trainloss -1394.06804  validloss -1435.96376±0.00000  bestvalidloss -1523.45121  last_update 9\n",
      "train: iter 514  trainloss -1377.27343  validloss -1426.19795±0.00000  bestvalidloss -1523.45121  last_update 10\n",
      "train: iter 515  trainloss -1425.30491  validloss -1475.62289±0.00000  bestvalidloss -1523.45121  last_update 11\n",
      "train: iter 516  trainloss -1423.14541  validloss -1312.21908±0.00000  bestvalidloss -1523.45121  last_update 12\n",
      "train: iter 517  trainloss -1360.25041  validloss -1293.69872±0.00000  bestvalidloss -1523.45121  last_update 13\n",
      "train: iter 518  trainloss -1442.05043  validloss -1417.44824±0.00000  bestvalidloss -1523.45121  last_update 14\n",
      "train: iter 519  trainloss -1459.28276  validloss -1440.42823±0.00000  bestvalidloss -1523.45121  last_update 15\n",
      "train: iter 520  trainloss -1394.61560  validloss -1530.77495±0.00000  bestvalidloss -1530.77495  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 521  trainloss -1196.16402  validloss -563.40086±0.00000  bestvalidloss -1530.77495  last_update 1\n",
      "train: iter 522  trainloss -1146.59821  validloss -1128.85526±0.00000  bestvalidloss -1530.77495  last_update 2\n",
      "train: iter 523  trainloss -1392.23595  validloss -1272.33552±0.00000  bestvalidloss -1530.77495  last_update 3\n",
      "train: iter 524  trainloss -1111.85876  validloss -1477.64077±0.00000  bestvalidloss -1530.77495  last_update 4\n",
      "train: iter 525  trainloss -1252.18071  validloss -1262.32534±0.00000  bestvalidloss -1530.77495  last_update 5\n",
      "train: iter 526  trainloss -1421.50155  validloss -1355.24346±0.00000  bestvalidloss -1530.77495  last_update 6\n",
      "train: iter 527  trainloss -1438.85168  validloss -1493.20281±0.00000  bestvalidloss -1530.77495  last_update 7\n",
      "train: iter 528  trainloss -1317.68390  validloss -1493.26059±0.00000  bestvalidloss -1530.77495  last_update 8\n",
      "train: iter 529  trainloss -1379.84066  validloss -1377.05173±0.00000  bestvalidloss -1530.77495  last_update 9\n",
      "train: iter 530  trainloss -1463.12830  validloss -1439.54555±0.00000  bestvalidloss -1530.77495  last_update 10\n",
      "train: iter 531  trainloss -1477.01080  validloss -1472.86437±0.00000  bestvalidloss -1530.77495  last_update 11\n",
      "train: iter 532  trainloss -1436.63887  validloss -1492.53241±0.00000  bestvalidloss -1530.77495  last_update 12\n",
      "train: iter 533  trainloss -1496.11063  validloss -1476.83506±0.00000  bestvalidloss -1530.77495  last_update 13\n",
      "train: iter 534  trainloss -1353.22474  validloss -1527.17709±0.00000  bestvalidloss -1530.77495  last_update 14\n",
      "train: iter 535  trainloss -1404.49962  validloss -1211.45880±0.00000  bestvalidloss -1530.77495  last_update 15\n",
      "train: iter 536  trainloss -1449.90765  validloss -1473.74907±0.00000  bestvalidloss -1530.77495  last_update 16\n",
      "train: iter 537  trainloss -1468.61637  validloss -1489.54852±0.00000  bestvalidloss -1530.77495  last_update 17\n",
      "train: iter 538  trainloss -1507.65270  validloss -1523.29307±0.00000  bestvalidloss -1530.77495  last_update 18\n",
      "train: iter 539  trainloss -1378.31410  validloss -1555.95502±0.00000  bestvalidloss -1555.95502  last_update 0\n",
      "train: iter 540  trainloss -1240.59108  validloss -1213.43599±0.00000  bestvalidloss -1555.95502  last_update 1\n",
      "train: iter 541  trainloss -1455.38090  validloss -1428.02186±0.00000  bestvalidloss -1555.95502  last_update 2\n",
      "train: iter 542  trainloss -1488.17406  validloss -1479.80582±0.00000  bestvalidloss -1555.95502  last_update 3\n",
      "train: iter 543  trainloss -1458.02795  validloss -1546.25677±0.00000  bestvalidloss -1555.95502  last_update 4\n",
      "train: iter 544  trainloss -1392.53941  validloss -1494.20307±0.00000  bestvalidloss -1555.95502  last_update 5\n",
      "train: iter 545  trainloss -1457.55005  validloss -1523.81248±0.00000  bestvalidloss -1555.95502  last_update 6\n",
      "train: iter 546  trainloss -1518.55701  validloss -1511.64474±0.00000  bestvalidloss -1555.95502  last_update 7\n",
      "train: iter 547  trainloss -1409.59923  validloss -1585.57137±0.00000  bestvalidloss -1585.57137  last_update 0\n",
      "train: iter 548  trainloss -1450.09391  validloss -1458.30395±0.00000  bestvalidloss -1585.57137  last_update 1\n",
      "train: iter 549  trainloss -1501.88131  validloss -1542.03548±0.00000  bestvalidloss -1585.57137  last_update 2\n",
      "train: iter 550  trainloss -1509.46766  validloss -1520.75340±0.00000  bestvalidloss -1585.57137  last_update 3\n",
      "train: iter 551  trainloss -1417.61384  validloss -1517.76883±0.00000  bestvalidloss -1585.57137  last_update 4\n",
      "train: iter 552  trainloss -1416.45548  validloss -1496.15880±0.00000  bestvalidloss -1585.57137  last_update 5\n",
      "train: iter 553  trainloss -1515.35778  validloss -1460.68104±0.00000  bestvalidloss -1585.57137  last_update 6\n",
      "train: iter 554  trainloss -1478.49095  validloss -1550.04323±0.00000  bestvalidloss -1585.57137  last_update 7\n",
      "train: iter 555  trainloss -1359.71675  validloss -1434.43953±0.00000  bestvalidloss -1585.57137  last_update 8\n",
      "train: iter 556  trainloss -1453.50933  validloss -1486.53503±0.00000  bestvalidloss -1585.57137  last_update 9\n",
      "train: iter 557  trainloss -1414.53293  validloss -1480.33802±0.00000  bestvalidloss -1585.57137  last_update 10\n",
      "train: iter 558  trainloss -1488.16445  validloss -1538.29731±0.00000  bestvalidloss -1585.57137  last_update 11\n",
      "train: iter 559  trainloss -1454.32637  validloss -1546.19898±0.00000  bestvalidloss -1585.57137  last_update 12\n",
      "train: iter 560  trainloss -1492.57403  validloss -1484.12291±0.00000  bestvalidloss -1585.57137  last_update 13\n",
      "train: iter 561  trainloss -1442.99095  validloss -1124.57828±0.00000  bestvalidloss -1585.57137  last_update 14\n",
      "train: iter 562  trainloss -961.25828  validloss -1478.25196±0.00000  bestvalidloss -1585.57137  last_update 15\n",
      "train: iter 563  trainloss -1249.02087  validloss -1021.06259±0.00000  bestvalidloss -1585.57137  last_update 16\n",
      "train: iter 564  trainloss -1330.83600  validloss -1393.42351±0.00000  bestvalidloss -1585.57137  last_update 17\n",
      "train: iter 565  trainloss -1378.86647  validloss -1123.00397±0.00000  bestvalidloss -1585.57137  last_update 18\n",
      "train: iter 566  trainloss -1474.48369  validloss -1466.59079±0.00000  bestvalidloss -1585.57137  last_update 19\n",
      "train: iter 567  trainloss -1510.77157  validloss -1538.34656±0.00000  bestvalidloss -1585.57137  last_update 20\n",
      "train: iter 568  trainloss -1422.19423  validloss -1493.16357±0.00000  bestvalidloss -1585.57137  last_update 21\n",
      "train: iter 569  trainloss -1514.45647  validloss -1520.72497±0.00000  bestvalidloss -1585.57137  last_update 22\n",
      "train: iter 570  trainloss -1504.40641  validloss -1575.88050±0.00000  bestvalidloss -1585.57137  last_update 23\n",
      "train: iter 571  trainloss -1468.00965  validloss -1446.95433±0.00000  bestvalidloss -1585.57137  last_update 24\n",
      "train: iter 572  trainloss -1457.73427  validloss -1495.39294±0.00000  bestvalidloss -1585.57137  last_update 25\n",
      "train: iter 573  trainloss -1329.27207  validloss -1411.67941±0.00000  bestvalidloss -1585.57137  last_update 26\n",
      "train: iter 574  trainloss -1442.91348  validloss -1357.33752±0.00000  bestvalidloss -1585.57137  last_update 27\n",
      "train: iter 575  trainloss -1513.29243  validloss -1540.57825±0.00000  bestvalidloss -1585.57137  last_update 28\n",
      "train: iter 576  trainloss -1506.07182  validloss -1435.65436±0.00000  bestvalidloss -1585.57137  last_update 29\n",
      "train: iter 577  trainloss -1510.57201  validloss -1553.34590±0.00000  bestvalidloss -1585.57137  last_update 30\n",
      "train: iter 578  trainloss -1499.31956  validloss -1537.26860±0.00000  bestvalidloss -1585.57137  last_update 31\n",
      "train: iter 579  trainloss -1415.53516  validloss -1466.28816±0.00000  bestvalidloss -1585.57137  last_update 32\n",
      "train: iter 580  trainloss -1499.81237  validloss -1514.70754±0.00000  bestvalidloss -1585.57137  last_update 33\n",
      "train: iter 581  trainloss -1480.12661  validloss -1539.49503±0.00000  bestvalidloss -1585.57137  last_update 34\n",
      "train: iter 582  trainloss -1525.40189  validloss -1537.70164±0.00000  bestvalidloss -1585.57137  last_update 35\n",
      "train: iter 583  trainloss -1548.81471  validloss -1577.24467±0.00000  bestvalidloss -1585.57137  last_update 36\n",
      "train: iter 584  trainloss -1469.88465  validloss -1563.16711±0.00000  bestvalidloss -1585.57137  last_update 37\n",
      "train: iter 585  trainloss -1457.58967  validloss -1307.45006±0.00000  bestvalidloss -1585.57137  last_update 38\n",
      "train: iter 586  trainloss -1480.28590  validloss -1560.41551±0.00000  bestvalidloss -1585.57137  last_update 39\n",
      "train: iter 587  trainloss -1527.10461  validloss -1570.49985±0.00000  bestvalidloss -1585.57137  last_update 40\n",
      "train: iter 588  trainloss -1518.88156  validloss -1497.48224±0.00000  bestvalidloss -1585.57137  last_update 41\n",
      "train: iter 589  trainloss -1282.84334  validloss -1484.79878±0.00000  bestvalidloss -1585.57137  last_update 42\n",
      "train: iter 590  trainloss -1264.78052  validloss -659.19448±0.00000  bestvalidloss -1585.57137  last_update 43\n",
      "train: iter 591  trainloss -1447.58474  validloss -1510.11744±0.00000  bestvalidloss -1585.57137  last_update 44\n",
      "train: iter 592  trainloss -1521.63552  validloss -1510.81919±0.00000  bestvalidloss -1585.57137  last_update 45\n",
      "train: iter 593  trainloss -1543.42122  validloss -1576.30895±0.00000  bestvalidloss -1585.57137  last_update 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 594  trainloss -1542.56814  validloss -1515.54160±0.00000  bestvalidloss -1585.57137  last_update 47\n",
      "train: iter 595  trainloss -1523.66306  validloss -1538.39368±0.00000  bestvalidloss -1585.57137  last_update 48\n",
      "train: iter 596  trainloss -1474.73571  validloss -1553.30098±0.00000  bestvalidloss -1585.57137  last_update 49\n",
      "train: iter 597  trainloss -1426.08193  validloss -1429.70620±0.00000  bestvalidloss -1585.57137  last_update 50\n",
      "train: iter 598  trainloss -1535.24904  validloss -1522.55944±0.00000  bestvalidloss -1585.57137  last_update 51\n",
      "train: iter 599  trainloss -1487.31202  validloss -1571.40982±0.00000  bestvalidloss -1585.57137  last_update 52\n",
      "train: iter 600  trainloss -1541.22352  validloss -1505.70410±0.00000  bestvalidloss -1585.57137  last_update 53\n",
      "train: iter 601  trainloss -1523.34209  validloss -1562.40414±0.00000  bestvalidloss -1585.57137  last_update 54\n",
      "train: iter 602  trainloss -1522.47782  validloss -1504.22989±0.00000  bestvalidloss -1585.57137  last_update 55\n",
      "train: iter 603  trainloss -1257.29625  validloss -1592.48262±0.00000  bestvalidloss -1592.48262  last_update 0\n",
      "train: iter 604  trainloss -1423.82426  validloss -1453.88047±0.00000  bestvalidloss -1592.48262  last_update 1\n",
      "train: iter 605  trainloss -1509.58279  validloss -1536.80223±0.00000  bestvalidloss -1592.48262  last_update 2\n",
      "train: iter 606  trainloss -1508.17168  validloss -1569.77907±0.00000  bestvalidloss -1592.48262  last_update 3\n",
      "train: iter 607  trainloss -1544.92202  validloss -1540.41456±0.00000  bestvalidloss -1592.48262  last_update 4\n",
      "train: iter 608  trainloss -1490.48150  validloss -1548.06278±0.00000  bestvalidloss -1592.48262  last_update 5\n",
      "train: iter 609  trainloss -1506.88088  validloss -1549.13661±0.00000  bestvalidloss -1592.48262  last_update 6\n",
      "train: iter 610  trainloss -1425.29951  validloss -1517.82582±0.00000  bestvalidloss -1592.48262  last_update 7\n",
      "train: iter 611  trainloss -1529.35016  validloss -1512.08605±0.00000  bestvalidloss -1592.48262  last_update 8\n",
      "train: iter 612  trainloss -1487.02468  validloss -1516.25679±0.00000  bestvalidloss -1592.48262  last_update 9\n",
      "train: iter 613  trainloss -1435.69048  validloss -1486.98864±0.00000  bestvalidloss -1592.48262  last_update 10\n",
      "train: iter 614  trainloss -1335.38442  validloss -1553.90545±0.00000  bestvalidloss -1592.48262  last_update 11\n",
      "train: iter 615  trainloss -1460.79626  validloss -1453.85324±0.00000  bestvalidloss -1592.48262  last_update 12\n",
      "train: iter 616  trainloss -1519.21779  validloss -1525.74180±0.00000  bestvalidloss -1592.48262  last_update 13\n",
      "train: iter 617  trainloss -1506.71241  validloss -1385.38801±0.00000  bestvalidloss -1592.48262  last_update 14\n",
      "train: iter 618  trainloss -1548.13315  validloss -1558.53189±0.00000  bestvalidloss -1592.48262  last_update 15\n",
      "train: iter 619  trainloss -1280.14378  validloss -1542.28950±0.00000  bestvalidloss -1592.48262  last_update 16\n",
      "train: iter 620  trainloss -1492.54870  validloss -1457.77145±0.00000  bestvalidloss -1592.48262  last_update 17\n",
      "train: iter 621  trainloss -1501.61436  validloss -1534.29314±0.00000  bestvalidloss -1592.48262  last_update 18\n",
      "train: iter 622  trainloss -1507.74644  validloss -1454.90207±0.00000  bestvalidloss -1592.48262  last_update 19\n",
      "train: iter 623  trainloss -1513.63723  validloss -1564.59317±0.00000  bestvalidloss -1592.48262  last_update 20\n",
      "train: iter 624  trainloss -1509.53093  validloss -1533.08949±0.00000  bestvalidloss -1592.48262  last_update 21\n",
      "train: iter 625  trainloss -1497.08782  validloss -1596.39526±0.00000  bestvalidloss -1596.39526  last_update 0\n",
      "train: iter 626  trainloss -1507.62662  validloss -1579.59433±0.00000  bestvalidloss -1596.39526  last_update 1\n",
      "train: iter 627  trainloss -1519.95586  validloss -1553.20475±0.00000  bestvalidloss -1596.39526  last_update 2\n",
      "train: iter 628  trainloss -1415.13974  validloss -1336.74714±0.00000  bestvalidloss -1596.39526  last_update 3\n",
      "train: iter 629  trainloss -1407.59751  validloss -1466.61121±0.00000  bestvalidloss -1596.39526  last_update 4\n",
      "train: iter 630  trainloss -1518.73259  validloss -1446.00613±0.00000  bestvalidloss -1596.39526  last_update 5\n",
      "train: iter 631  trainloss -1533.53567  validloss -1512.31664±0.00000  bestvalidloss -1596.39526  last_update 6\n",
      "train: iter 632  trainloss -1484.81015  validloss -1564.96154±0.00000  bestvalidloss -1596.39526  last_update 7\n",
      "train: iter 633  trainloss -1534.81663  validloss -1570.08851±0.00000  bestvalidloss -1596.39526  last_update 8\n",
      "train: iter 634  trainloss -1502.52283  validloss -1540.30694±0.00000  bestvalidloss -1596.39526  last_update 9\n",
      "train: iter 635  trainloss -1451.82186  validloss -1459.44322±0.00000  bestvalidloss -1596.39526  last_update 10\n",
      "train: iter 636  trainloss -1547.36121  validloss -1528.60563±0.00000  bestvalidloss -1596.39526  last_update 11\n",
      "train: iter 637  trainloss -1555.07248  validloss -1601.46101±0.00000  bestvalidloss -1601.46101  last_update 0\n",
      "train: iter 638  trainloss -1519.36058  validloss -1600.71797±0.00000  bestvalidloss -1601.46101  last_update 1\n",
      "train: iter 639  trainloss -1437.28816  validloss -1505.03048±0.00000  bestvalidloss -1601.46101  last_update 2\n",
      "train: iter 640  trainloss -1531.13760  validloss -1551.73196±0.00000  bestvalidloss -1601.46101  last_update 3\n",
      "train: iter 641  trainloss -1378.99479  validloss -1533.21877±0.00000  bestvalidloss -1601.46101  last_update 4\n",
      "train: iter 642  trainloss -1542.56352  validloss -1541.63730±0.00000  bestvalidloss -1601.46101  last_update 5\n",
      "train: iter 643  trainloss -1550.49362  validloss -1597.95699±0.00000  bestvalidloss -1601.46101  last_update 6\n",
      "train: iter 644  trainloss -1507.70204  validloss -1489.31724±0.00000  bestvalidloss -1601.46101  last_update 7\n",
      "train: iter 645  trainloss -1572.43397  validloss -1433.23810±0.00000  bestvalidloss -1601.46101  last_update 8\n",
      "train: iter 646  trainloss -1280.06693  validloss -1371.03535±0.00000  bestvalidloss -1601.46101  last_update 9\n",
      "train: iter 647  trainloss -1414.86769  validloss -1283.85938±0.00000  bestvalidloss -1601.46101  last_update 10\n",
      "train: iter 648  trainloss -1509.25792  validloss -1542.04510±0.00000  bestvalidloss -1601.46101  last_update 11\n",
      "train: iter 649  trainloss -1555.52269  validloss -1565.86043±0.00000  bestvalidloss -1601.46101  last_update 12\n",
      "train: iter 650  trainloss -1418.44190  validloss -1579.72130±0.00000  bestvalidloss -1601.46101  last_update 13\n",
      "train: iter 651  trainloss -1520.40513  validloss -1552.53719±0.00000  bestvalidloss -1601.46101  last_update 14\n",
      "train: iter 652  trainloss -1535.08433  validloss -1564.67723±0.00000  bestvalidloss -1601.46101  last_update 15\n",
      "train: iter 653  trainloss -1522.89767  validloss -1549.35938±0.00000  bestvalidloss -1601.46101  last_update 16\n",
      "train: iter 654  trainloss -1540.55510  validloss -1546.90992±0.00000  bestvalidloss -1601.46101  last_update 17\n",
      "train: iter 655  trainloss -1312.01024  validloss -1430.07412±0.00000  bestvalidloss -1601.46101  last_update 18\n",
      "train: iter 656  trainloss -1511.92767  validloss -1501.65237±0.00000  bestvalidloss -1601.46101  last_update 19\n",
      "train: iter 657  trainloss -1546.47919  validloss -1543.02773±0.00000  bestvalidloss -1601.46101  last_update 20\n",
      "train: iter 658  trainloss -1343.23067  validloss -1435.41591±0.00000  bestvalidloss -1601.46101  last_update 21\n",
      "train: iter 659  trainloss -1534.59596  validloss -1501.18535±0.00000  bestvalidloss -1601.46101  last_update 22\n",
      "train: iter 660  trainloss -1582.19968  validloss -1589.07192±0.00000  bestvalidloss -1601.46101  last_update 23\n",
      "train: iter 661  trainloss -1523.00510  validloss -1348.61153±0.00000  bestvalidloss -1601.46101  last_update 24\n",
      "train: iter 662  trainloss -1380.67018  validloss -1490.59446±0.00000  bestvalidloss -1601.46101  last_update 25\n",
      "train: iter 663  trainloss -1527.77244  validloss -1527.01586±0.00000  bestvalidloss -1601.46101  last_update 26\n",
      "train: iter 664  trainloss -1558.72344  validloss -1592.69833±0.00000  bestvalidloss -1601.46101  last_update 27\n",
      "train: iter 665  trainloss -1539.89680  validloss -1592.92283±0.00000  bestvalidloss -1601.46101  last_update 28\n",
      "train: iter 666  trainloss -1462.44667  validloss -1582.74220±0.00000  bestvalidloss -1601.46101  last_update 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 667  trainloss -1541.49541  validloss -1556.66892±0.00000  bestvalidloss -1601.46101  last_update 30\n",
      "train: iter 668  trainloss -1527.66329  validloss -1588.79426±0.00000  bestvalidloss -1601.46101  last_update 31\n",
      "train: iter 669  trainloss -1529.86946  validloss -1527.79509±0.00000  bestvalidloss -1601.46101  last_update 32\n",
      "train: iter 670  trainloss -1554.74388  validloss -1579.61988±0.00000  bestvalidloss -1601.46101  last_update 33\n",
      "train: iter 671  trainloss -1536.90933  validloss -1609.88261±0.00000  bestvalidloss -1609.88261  last_update 0\n",
      "train: iter 672  trainloss -1493.78086  validloss -1551.62336±0.00000  bestvalidloss -1609.88261  last_update 1\n",
      "train: iter 673  trainloss -1537.05291  validloss -1592.11221±0.00000  bestvalidloss -1609.88261  last_update 2\n",
      "train: iter 674  trainloss -1574.32523  validloss -1611.20310±0.00000  bestvalidloss -1611.20310  last_update 0\n",
      "train: iter 675  trainloss -1318.78055  validloss -1438.96723±0.00000  bestvalidloss -1611.20310  last_update 1\n",
      "train: iter 676  trainloss -1526.22545  validloss -1519.89721±0.00000  bestvalidloss -1611.20310  last_update 2\n",
      "train: iter 677  trainloss -1563.90484  validloss -1570.85663±0.00000  bestvalidloss -1611.20310  last_update 3\n",
      "train: iter 678  trainloss -1499.63461  validloss -1541.13815±0.00000  bestvalidloss -1611.20310  last_update 4\n",
      "train: iter 679  trainloss -1520.55153  validloss -1533.86456±0.00000  bestvalidloss -1611.20310  last_update 5\n",
      "train: iter 680  trainloss -1541.99114  validloss -1587.94114±0.00000  bestvalidloss -1611.20310  last_update 6\n",
      "train: iter 681  trainloss -1539.67995  validloss -1541.80540±0.00000  bestvalidloss -1611.20310  last_update 7\n",
      "train: iter 682  trainloss -1506.91371  validloss -1455.02653±0.00000  bestvalidloss -1611.20310  last_update 8\n",
      "train: iter 683  trainloss -1569.53354  validloss -1561.30520±0.00000  bestvalidloss -1611.20310  last_update 9\n",
      "train: iter 684  trainloss -1475.27049  validloss -1619.01687±0.00000  bestvalidloss -1619.01687  last_update 0\n",
      "train: iter 685  trainloss -1368.51062  validloss -1244.82365±0.00000  bestvalidloss -1619.01687  last_update 1\n",
      "train: iter 686  trainloss -1453.49085  validloss -1492.79248±0.00000  bestvalidloss -1619.01687  last_update 2\n",
      "train: iter 687  trainloss -1544.38935  validloss -1364.51061±0.00000  bestvalidloss -1619.01687  last_update 3\n",
      "train: iter 688  trainloss -1541.12537  validloss -1587.44377±0.00000  bestvalidloss -1619.01687  last_update 4\n",
      "train: iter 689  trainloss -1578.55331  validloss -1591.94722±0.00000  bestvalidloss -1619.01687  last_update 5\n",
      "train: iter 690  trainloss -1574.67597  validloss -1605.62207±0.00000  bestvalidloss -1619.01687  last_update 6\n",
      "train: iter 691  trainloss -1499.89946  validloss -1604.88273±0.00000  bestvalidloss -1619.01687  last_update 7\n",
      "train: iter 692  trainloss -1540.80854  validloss -1515.75419±0.00000  bestvalidloss -1619.01687  last_update 8\n",
      "train: iter 693  trainloss -1534.79198  validloss -1549.65139±0.00000  bestvalidloss -1619.01687  last_update 9\n",
      "train: iter 694  trainloss -1380.08261  validloss -1584.49397±0.00000  bestvalidloss -1619.01687  last_update 10\n",
      "train: iter 695  trainloss -1510.47005  validloss -1437.75232±0.00000  bestvalidloss -1619.01687  last_update 11\n",
      "train: iter 696  trainloss -1538.17600  validloss -1575.12828±0.00000  bestvalidloss -1619.01687  last_update 12\n",
      "train: iter 697  trainloss -1514.65126  validloss -1557.27642±0.00000  bestvalidloss -1619.01687  last_update 13\n",
      "train: iter 698  trainloss -1453.82545  validloss -1595.19251±0.00000  bestvalidloss -1619.01687  last_update 14\n",
      "train: iter 699  trainloss -1337.71387  validloss -1138.30841±0.00000  bestvalidloss -1619.01687  last_update 15\n",
      "train: iter 700  trainloss -1530.10866  validloss -1489.57030±0.00000  bestvalidloss -1619.01687  last_update 16\n",
      "train: iter 701  trainloss -1505.86268  validloss -1569.34689±0.00000  bestvalidloss -1619.01687  last_update 17\n",
      "train: iter 702  trainloss -1571.35005  validloss -1549.84955±0.00000  bestvalidloss -1619.01687  last_update 18\n",
      "train: iter 703  trainloss -1568.58146  validloss -1602.89471±0.00000  bestvalidloss -1619.01687  last_update 19\n",
      "train: iter 704  trainloss -1606.07175  validloss -1621.39847±0.00000  bestvalidloss -1621.39847  last_update 0\n",
      "train: iter 705  trainloss -1494.72807  validloss -1640.58664±0.00000  bestvalidloss -1640.58664  last_update 0\n",
      "train: iter 706  trainloss -1242.99491  validloss -1548.49183±0.00000  bestvalidloss -1640.58664  last_update 1\n",
      "train: iter 707  trainloss -1459.17429  validloss -1474.53920±0.00000  bestvalidloss -1640.58664  last_update 2\n",
      "train: iter 708  trainloss -1539.61896  validloss -1558.72512±0.00000  bestvalidloss -1640.58664  last_update 3\n",
      "train: iter 709  trainloss -1504.91745  validloss -1539.87988±0.00000  bestvalidloss -1640.58664  last_update 4\n",
      "train: iter 710  trainloss -1443.48117  validloss -1229.12339±0.00000  bestvalidloss -1640.58664  last_update 5\n",
      "train: iter 711  trainloss -1579.97509  validloss -1540.37655±0.00000  bestvalidloss -1640.58664  last_update 6\n",
      "train: iter 712  trainloss -1595.77515  validloss -1634.97017±0.00000  bestvalidloss -1640.58664  last_update 7\n",
      "train: iter 713  trainloss -1442.36445  validloss -1629.49666±0.00000  bestvalidloss -1640.58664  last_update 8\n",
      "train: iter 714  trainloss -1415.78608  validloss -1368.38934±0.00000  bestvalidloss -1640.58664  last_update 9\n",
      "train: iter 715  trainloss -1564.55061  validloss -1526.18479±0.00000  bestvalidloss -1640.58664  last_update 10\n",
      "train: iter 716  trainloss -1532.80500  validloss -1564.23989±0.00000  bestvalidloss -1640.58664  last_update 11\n",
      "train: iter 717  trainloss -1475.58427  validloss -1467.66388±0.00000  bestvalidloss -1640.58664  last_update 12\n",
      "train: iter 718  trainloss -1558.79638  validloss -1555.06076±0.00000  bestvalidloss -1640.58664  last_update 13\n",
      "train: iter 719  trainloss -1417.83250  validloss -954.20432±0.00000  bestvalidloss -1640.58664  last_update 14\n",
      "train: iter 720  trainloss -1575.16660  validloss -1569.91866±0.00000  bestvalidloss -1640.58664  last_update 15\n",
      "train: iter 721  trainloss -1534.89648  validloss -1622.30084±0.00000  bestvalidloss -1640.58664  last_update 16\n",
      "train: iter 722  trainloss -1524.35101  validloss -1579.46445±0.00000  bestvalidloss -1640.58664  last_update 17\n",
      "train: iter 723  trainloss -1581.99472  validloss -1571.21692±0.00000  bestvalidloss -1640.58664  last_update 18\n",
      "train: iter 724  trainloss -1597.89575  validloss -1630.99173±0.00000  bestvalidloss -1640.58664  last_update 19\n",
      "train: iter 725  trainloss -1376.96220  validloss -1589.48179±0.00000  bestvalidloss -1640.58664  last_update 20\n",
      "train: iter 726  trainloss -1370.89415  validloss -1384.72866±0.00000  bestvalidloss -1640.58664  last_update 21\n",
      "train: iter 727  trainloss -1547.07012  validloss -1471.65400±0.00000  bestvalidloss -1640.58664  last_update 22\n",
      "train: iter 728  trainloss -1580.41922  validloss -1567.70683±0.00000  bestvalidloss -1640.58664  last_update 23\n",
      "train: iter 729  trainloss -1561.98512  validloss -1610.82592±0.00000  bestvalidloss -1640.58664  last_update 24\n",
      "train: iter 730  trainloss -1482.48437  validloss -1384.89362±0.00000  bestvalidloss -1640.58664  last_update 25\n",
      "train: iter 731  trainloss -1579.20336  validloss -1552.97271±0.00000  bestvalidloss -1640.58664  last_update 26\n",
      "train: iter 732  trainloss -1295.81683  validloss -1633.14628±0.00000  bestvalidloss -1640.58664  last_update 27\n",
      "train: iter 733  trainloss -1260.31419  validloss -746.90302±0.00000  bestvalidloss -1640.58664  last_update 28\n",
      "train: iter 734  trainloss -1526.94516  validloss -1492.42524±0.00000  bestvalidloss -1640.58664  last_update 29\n",
      "train: iter 735  trainloss -1494.62434  validloss -1566.65462±0.00000  bestvalidloss -1640.58664  last_update 30\n",
      "train: iter 736  trainloss -1502.35102  validloss -1411.19116±0.00000  bestvalidloss -1640.58664  last_update 31\n",
      "train: iter 737  trainloss -1573.95768  validloss -1571.54072±0.00000  bestvalidloss -1640.58664  last_update 32\n",
      "train: iter 738  trainloss -1500.73286  validloss -1594.62287±0.00000  bestvalidloss -1640.58664  last_update 33\n",
      "train: iter 739  trainloss -1545.38357  validloss -1544.87115±0.00000  bestvalidloss -1640.58664  last_update 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 740  trainloss -1554.46037  validloss -1585.34232±0.00000  bestvalidloss -1640.58664  last_update 35\n",
      "train: iter 741  trainloss -1562.80760  validloss -1554.91017±0.00000  bestvalidloss -1640.58664  last_update 36\n",
      "train: iter 742  trainloss -1604.38845  validloss -1614.71960±0.00000  bestvalidloss -1640.58664  last_update 37\n",
      "train: iter 743  trainloss -1546.68413  validloss -1648.06707±0.00000  bestvalidloss -1648.06707  last_update 0\n",
      "train: iter 744  trainloss -1519.77275  validloss -1545.24978±0.00000  bestvalidloss -1648.06707  last_update 1\n",
      "train: iter 745  trainloss -1512.01017  validloss -1432.80767±0.00000  bestvalidloss -1648.06707  last_update 2\n",
      "train: iter 746  trainloss -1523.63340  validloss -1539.37051±0.00000  bestvalidloss -1648.06707  last_update 3\n",
      "train: iter 747  trainloss -1588.53859  validloss -1637.23518±0.00000  bestvalidloss -1648.06707  last_update 4\n",
      "train: iter 748  trainloss -1341.10963  validloss -1543.01663±0.00000  bestvalidloss -1648.06707  last_update 5\n",
      "train: iter 749  trainloss -1523.80798  validloss -1499.94948±0.00000  bestvalidloss -1648.06707  last_update 6\n",
      "train: iter 750  trainloss -1528.11380  validloss -1595.76493±0.00000  bestvalidloss -1648.06707  last_update 7\n",
      "train: iter 751  trainloss -1532.18949  validloss -1513.34557±0.00000  bestvalidloss -1648.06707  last_update 8\n",
      "train: iter 752  trainloss -1509.88176  validloss -1556.13466±0.00000  bestvalidloss -1648.06707  last_update 9\n",
      "train: iter 753  trainloss -1550.59734  validloss -1591.59464±0.00000  bestvalidloss -1648.06707  last_update 10\n",
      "train: iter 754  trainloss -1567.98861  validloss -1517.09845±0.00000  bestvalidloss -1648.06707  last_update 11\n",
      "train: iter 755  trainloss -1421.18902  validloss -1614.46845±0.00000  bestvalidloss -1648.06707  last_update 12\n",
      "train: iter 756  trainloss -1570.89973  validloss -1558.60133±0.00000  bestvalidloss -1648.06707  last_update 13\n",
      "train: iter 757  trainloss -1597.25870  validloss -1579.44202±0.00000  bestvalidloss -1648.06707  last_update 14\n",
      "train: iter 758  trainloss -1548.53963  validloss -1521.60260±0.00000  bestvalidloss -1648.06707  last_update 15\n",
      "train: iter 759  trainloss -1597.77052  validloss -1573.42762±0.00000  bestvalidloss -1648.06707  last_update 16\n",
      "train: iter 760  trainloss -1581.24637  validloss -1629.69731±0.00000  bestvalidloss -1648.06707  last_update 17\n",
      "train: iter 761  trainloss -1521.84818  validloss -1624.89779±0.00000  bestvalidloss -1648.06707  last_update 18\n",
      "train: iter 762  trainloss -1470.48942  validloss -1564.06733±0.00000  bestvalidloss -1648.06707  last_update 19\n",
      "train: iter 763  trainloss -1545.72336  validloss -1525.14595±0.00000  bestvalidloss -1648.06707  last_update 20\n",
      "train: iter 764  trainloss -1516.63478  validloss -1343.22994±0.00000  bestvalidloss -1648.06707  last_update 21\n",
      "train: iter 765  trainloss -1564.68807  validloss -1623.25841±0.00000  bestvalidloss -1648.06707  last_update 22\n",
      "train: iter 766  trainloss -1513.50922  validloss -1567.89615±0.00000  bestvalidloss -1648.06707  last_update 23\n",
      "train: iter 767  trainloss -1392.20902  validloss -1274.05693±0.00000  bestvalidloss -1648.06707  last_update 24\n",
      "train: iter 768  trainloss -1601.20940  validloss -1591.12360±0.00000  bestvalidloss -1648.06707  last_update 25\n",
      "train: iter 769  trainloss -1610.97258  validloss -1649.73868±0.00000  bestvalidloss -1649.73868  last_update 0\n",
      "train: iter 770  trainloss -1497.09394  validloss -1547.19185±0.00000  bestvalidloss -1649.73868  last_update 1\n",
      "train: iter 771  trainloss -1581.48388  validloss -1591.66870±0.00000  bestvalidloss -1649.73868  last_update 2\n",
      "train: iter 772  trainloss -1597.64629  validloss -1633.98267±0.00000  bestvalidloss -1649.73868  last_update 3\n",
      "train: iter 773  trainloss -1517.92604  validloss -1628.30756±0.00000  bestvalidloss -1649.73868  last_update 4\n",
      "train: iter 774  trainloss -1457.66986  validloss -1464.46962±0.00000  bestvalidloss -1649.73868  last_update 5\n",
      "train: iter 775  trainloss -1585.66518  validloss -1590.23700±0.00000  bestvalidloss -1649.73868  last_update 6\n",
      "train: iter 776  trainloss -1609.07630  validloss -1619.19834±0.00000  bestvalidloss -1649.73868  last_update 7\n",
      "train: iter 777  trainloss -1575.14316  validloss -1640.57095±0.00000  bestvalidloss -1649.73868  last_update 8\n",
      "train: iter 778  trainloss -1537.06947  validloss -1336.75719±0.00000  bestvalidloss -1649.73868  last_update 9\n",
      "train: iter 779  trainloss -1556.96943  validloss -1570.72672±0.00000  bestvalidloss -1649.73868  last_update 10\n",
      "train: iter 780  trainloss -1399.89864  validloss -1580.96589±0.00000  bestvalidloss -1649.73868  last_update 11\n",
      "train: iter 781  trainloss -1545.25757  validloss -1557.89519±0.00000  bestvalidloss -1649.73868  last_update 12\n",
      "train: iter 782  trainloss -1572.84821  validloss -1624.66075±0.00000  bestvalidloss -1649.73868  last_update 13\n",
      "train: iter 783  trainloss -1587.53547  validloss -1507.42435±0.00000  bestvalidloss -1649.73868  last_update 14\n",
      "train: iter 784  trainloss -1318.95447  validloss -1609.63850±0.00000  bestvalidloss -1649.73868  last_update 15\n",
      "train: iter 785  trainloss -1493.85838  validloss -1514.94142±0.00000  bestvalidloss -1649.73868  last_update 16\n",
      "train: iter 786  trainloss -1547.66629  validloss -1540.86668±0.00000  bestvalidloss -1649.73868  last_update 17\n",
      "train: iter 787  trainloss -1438.20794  validloss -1438.64303±0.00000  bestvalidloss -1649.73868  last_update 18\n",
      "train: iter 788  trainloss -1564.11976  validloss -1542.81950±0.00000  bestvalidloss -1649.73868  last_update 19\n",
      "train: iter 789  trainloss -1474.56696  validloss -1604.52667±0.00000  bestvalidloss -1649.73868  last_update 20\n",
      "train: iter 790  trainloss -1558.03261  validloss -1485.07927±0.00000  bestvalidloss -1649.73868  last_update 21\n",
      "train: iter 791  trainloss -1622.82078  validloss -1625.56018±0.00000  bestvalidloss -1649.73868  last_update 22\n",
      "train: iter 792  trainloss -1415.45534  validloss -1634.11743±0.00000  bestvalidloss -1649.73868  last_update 23\n",
      "train: iter 793  trainloss -1525.97516  validloss -1372.03532±0.00000  bestvalidloss -1649.73868  last_update 24\n",
      "train: iter 794  trainloss -1594.71528  validloss -1573.05411±0.00000  bestvalidloss -1649.73868  last_update 25\n",
      "train: iter 795  trainloss -1578.58674  validloss -1613.94584±0.00000  bestvalidloss -1649.73868  last_update 26\n",
      "train: iter 796  trainloss -1548.91173  validloss -1480.73234±0.00000  bestvalidloss -1649.73868  last_update 27\n",
      "train: iter 797  trainloss -1514.87188  validloss -1559.87024±0.00000  bestvalidloss -1649.73868  last_update 28\n",
      "train: iter 798  trainloss -1524.85216  validloss -1539.53545±0.00000  bestvalidloss -1649.73868  last_update 29\n",
      "train: iter 799  trainloss -1525.35170  validloss -1516.35711±0.00000  bestvalidloss -1649.73868  last_update 30\n",
      "train: iter 800  trainloss -1606.31100  validloss -1572.39309±0.00000  bestvalidloss -1649.73868  last_update 31\n",
      "train: iter 801  trainloss -1567.59431  validloss -1642.52098±0.00000  bestvalidloss -1649.73868  last_update 32\n",
      "train: iter 802  trainloss -1557.61920  validloss -1598.39467±0.00000  bestvalidloss -1649.73868  last_update 33\n",
      "train: iter 803  trainloss -1466.81819  validloss -1399.71086±0.00000  bestvalidloss -1649.73868  last_update 34\n",
      "train: iter 804  trainloss -1567.12514  validloss -1479.06934±0.00000  bestvalidloss -1649.73868  last_update 35\n",
      "train: iter 805  trainloss -1619.98802  validloss -1571.11217±0.00000  bestvalidloss -1649.73868  last_update 36\n",
      "train: iter 806  trainloss -1306.66278  validloss -1601.79426±0.00000  bestvalidloss -1649.73868  last_update 37\n",
      "train: iter 807  trainloss -1290.29716  validloss -1154.20265±0.00000  bestvalidloss -1649.73868  last_update 38\n",
      "train: iter 808  trainloss -1476.08573  validloss -1340.93364±0.00000  bestvalidloss -1649.73868  last_update 39\n",
      "train: iter 809  trainloss -1565.38614  validloss -1577.19236±0.00000  bestvalidloss -1649.73868  last_update 40\n",
      "train: iter 810  trainloss -1539.54208  validloss -1525.88756±0.00000  bestvalidloss -1649.73868  last_update 41\n",
      "train: iter 811  trainloss -1577.89086  validloss -1576.98622±0.00000  bestvalidloss -1649.73868  last_update 42\n",
      "train: iter 812  trainloss -1581.71037  validloss -1578.32550±0.00000  bestvalidloss -1649.73868  last_update 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 813  trainloss -1579.76804  validloss -1635.40555±0.00000  bestvalidloss -1649.73868  last_update 44\n",
      "train: iter 814  trainloss -1521.81131  validloss -1537.71845±0.00000  bestvalidloss -1649.73868  last_update 45\n",
      "train: iter 815  trainloss -1579.71302  validloss -1553.24368±0.00000  bestvalidloss -1649.73868  last_update 46\n",
      "train: iter 816  trainloss -1602.26705  validloss -1624.02044±0.00000  bestvalidloss -1649.73868  last_update 47\n",
      "train: iter 817  trainloss -1563.88165  validloss -1587.17351±0.00000  bestvalidloss -1649.73868  last_update 48\n",
      "train: iter 818  trainloss -1361.72940  validloss -1576.40519±0.00000  bestvalidloss -1649.73868  last_update 49\n",
      "train: iter 819  trainloss -1543.83904  validloss -1248.39805±0.00000  bestvalidloss -1649.73868  last_update 50\n",
      "train: iter 820  trainloss -1594.10003  validloss -1581.50719±0.00000  bestvalidloss -1649.73868  last_update 51\n",
      "train: iter 821  trainloss -1573.89971  validloss -1567.67183±0.00000  bestvalidloss -1649.73868  last_update 52\n",
      "train: iter 822  trainloss -1598.93553  validloss -1593.84196±0.00000  bestvalidloss -1649.73868  last_update 53\n",
      "train: iter 823  trainloss -1578.02983  validloss -1598.71010±0.00000  bestvalidloss -1649.73868  last_update 54\n",
      "train: iter 824  trainloss -1605.75710  validloss -1567.06349±0.00000  bestvalidloss -1649.73868  last_update 55\n",
      "train: iter 825  trainloss -1603.23797  validloss -1627.99209±0.00000  bestvalidloss -1649.73868  last_update 56\n",
      "train: iter 826  trainloss -1453.87168  validloss -1508.51688±0.00000  bestvalidloss -1649.73868  last_update 57\n",
      "train: iter 827  trainloss -1441.13123  validloss -1436.99307±0.00000  bestvalidloss -1649.73868  last_update 58\n",
      "train: iter 828  trainloss -1574.27789  validloss -1536.85820±0.00000  bestvalidloss -1649.73868  last_update 59\n",
      "train: iter 829  trainloss -1593.95381  validloss -1597.78362±0.00000  bestvalidloss -1649.73868  last_update 60\n",
      "train: iter 830  trainloss -1621.97365  validloss -1622.12939±0.00000  bestvalidloss -1649.73868  last_update 61\n",
      "train: iter 831  trainloss -1585.67411  validloss -1622.66455±0.00000  bestvalidloss -1649.73868  last_update 62\n",
      "train: iter 832  trainloss -1502.16306  validloss -1511.15312±0.00000  bestvalidloss -1649.73868  last_update 63\n",
      "train: iter 833  trainloss -1465.13888  validloss -1298.53155±0.00000  bestvalidloss -1649.73868  last_update 64\n",
      "train: iter 834  trainloss -1599.35916  validloss -1589.97770±0.00000  bestvalidloss -1649.73868  last_update 65\n",
      "train: iter 835  trainloss -1557.21859  validloss -1575.86101±0.00000  bestvalidloss -1649.73868  last_update 66\n",
      "train: iter 836  trainloss -1472.38965  validloss -1158.33237±0.00000  bestvalidloss -1649.73868  last_update 67\n",
      "train: iter 837  trainloss -1565.12975  validloss -1545.61942±0.00000  bestvalidloss -1649.73868  last_update 68\n",
      "train: iter 838  trainloss -1533.25054  validloss -1583.98050±0.00000  bestvalidloss -1649.73868  last_update 69\n",
      "train: iter 839  trainloss -1025.17726  validloss -314.87999±0.00000  bestvalidloss -1649.73868  last_update 70\n",
      "train: iter 840  trainloss -1531.52700  validloss -1457.23029±0.00000  bestvalidloss -1649.73868  last_update 71\n",
      "train: iter 841  trainloss -1575.85500  validloss -1554.77645±0.00000  bestvalidloss -1649.73868  last_update 72\n",
      "train: iter 842  trainloss -1468.64810  validloss -1606.30015±0.00000  bestvalidloss -1649.73868  last_update 73\n",
      "train: iter 843  trainloss -1477.87241  validloss -1437.49628±0.00000  bestvalidloss -1649.73868  last_update 74\n",
      "train: iter 844  trainloss -1526.58943  validloss -1524.37403±0.00000  bestvalidloss -1649.73868  last_update 75\n",
      "train: iter 845  trainloss -1585.65290  validloss -1595.08846±0.00000  bestvalidloss -1649.73868  last_update 76\n",
      "train: iter 846  trainloss -1599.21379  validloss -1601.42379±0.00000  bestvalidloss -1649.73868  last_update 77\n",
      "train: iter 847  trainloss -1424.97733  validloss -1556.34358±0.00000  bestvalidloss -1649.73868  last_update 78\n",
      "train: iter 848  trainloss -1562.96812  validloss -1538.60845±0.00000  bestvalidloss -1649.73868  last_update 79\n",
      "train: iter 849  trainloss -1565.55446  validloss -1598.35744±0.00000  bestvalidloss -1649.73868  last_update 80\n",
      "train: iter 850  trainloss -1523.22278  validloss -1491.35320±0.00000  bestvalidloss -1649.73868  last_update 81\n",
      "train: iter 851  trainloss -1502.60353  validloss -1584.23398±0.00000  bestvalidloss -1649.73868  last_update 82\n",
      "train: iter 852  trainloss -1579.94655  validloss -1542.15303±0.00000  bestvalidloss -1649.73868  last_update 83\n",
      "train: iter 853  trainloss -1595.20846  validloss -1630.23692±0.00000  bestvalidloss -1649.73868  last_update 84\n",
      "train: iter 854  trainloss -1570.05914  validloss -1640.81459±0.00000  bestvalidloss -1649.73868  last_update 85\n",
      "train: iter 855  trainloss -1609.27822  validloss -1548.41374±0.00000  bestvalidloss -1649.73868  last_update 86\n",
      "train: iter 856  trainloss -1627.56616  validloss -1641.44166±0.00000  bestvalidloss -1649.73868  last_update 87\n",
      "train: iter 857  trainloss -1445.80176  validloss -1627.37343±0.00000  bestvalidloss -1649.73868  last_update 88\n",
      "train: iter 858  trainloss -1549.39834  validloss -1523.65830±0.00000  bestvalidloss -1649.73868  last_update 89\n",
      "train: iter 859  trainloss -1512.41921  validloss -1562.34743±0.00000  bestvalidloss -1649.73868  last_update 90\n",
      "train: iter 860  trainloss -1602.31625  validloss -1611.66817±0.00000  bestvalidloss -1649.73868  last_update 91\n",
      "train: iter 861  trainloss -1580.43039  validloss -1641.77908±0.00000  bestvalidloss -1649.73868  last_update 92\n",
      "train: iter 862  trainloss -1526.59067  validloss -1619.89321±0.00000  bestvalidloss -1649.73868  last_update 93\n",
      "train: iter 863  trainloss -1506.96698  validloss -1585.62717±0.00000  bestvalidloss -1649.73868  last_update 94\n",
      "train: iter 864  trainloss -1614.87408  validloss -1521.05277±0.00000  bestvalidloss -1649.73868  last_update 95\n",
      "train: iter 865  trainloss -1537.76404  validloss -1636.78944±0.00000  bestvalidloss -1649.73868  last_update 96\n",
      "train: iter 866  trainloss -1559.75738  validloss -1594.51856±0.00000  bestvalidloss -1649.73868  last_update 97\n",
      "train: iter 867  trainloss -1581.30141  validloss -1615.93699±0.00000  bestvalidloss -1649.73868  last_update 98\n",
      "train: iter 868  trainloss -1615.91162  validloss -1558.57665±0.00000  bestvalidloss -1649.73868  last_update 99\n",
      "train: iter 869  trainloss -1557.59331  validloss -1588.58764±0.00000  bestvalidloss -1649.73868  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.5528) penalty_target_max tensor(7.4095)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 7.90469  validloss 8.31318±0.00000  bestvalidloss 8.31318  last_update 0\n",
      "train: iter 1  trainloss 7.23241  validloss 7.57375±0.00000  bestvalidloss 7.57375  last_update 0\n",
      "train: iter 2  trainloss 6.67434  validloss 6.93153±0.00000  bestvalidloss 6.93153  last_update 0\n",
      "train: iter 3  trainloss 6.20206  validloss 6.43238±0.00000  bestvalidloss 6.43238  last_update 0\n",
      "train: iter 4  trainloss 5.78550  validloss 5.97870±0.00000  bestvalidloss 5.97870  last_update 0\n",
      "train: iter 5  trainloss 5.43293  validloss 5.60436±0.00000  bestvalidloss 5.60436  last_update 0\n",
      "train: iter 6  trainloss 5.11675  validloss 5.26318±0.00000  bestvalidloss 5.26318  last_update 0\n",
      "train: iter 7  trainloss 4.86207  validloss 4.97277±0.00000  bestvalidloss 4.97277  last_update 0\n",
      "train: iter 8  trainloss 4.63583  validloss 4.73743±0.00000  bestvalidloss 4.73743  last_update 0\n",
      "train: iter 9  trainloss 4.41551  validloss 4.53422±0.00000  bestvalidloss 4.53422  last_update 0\n",
      "train: iter 10  trainloss 4.24635  validloss 4.34649±0.00000  bestvalidloss 4.34649  last_update 0\n",
      "train: iter 11  trainloss 4.06709  validloss 4.14849±0.00000  bestvalidloss 4.14849  last_update 0\n",
      "train: iter 12  trainloss 3.92927  validloss 4.01845±0.00000  bestvalidloss 4.01845  last_update 0\n",
      "train: iter 13  trainloss 3.79179  validloss 3.85869±0.00000  bestvalidloss 3.85869  last_update 0\n",
      "train: iter 14  trainloss 3.67605  validloss 3.73540±0.00000  bestvalidloss 3.73540  last_update 0\n",
      "train: iter 15  trainloss 3.56052  validloss 3.63544±0.00000  bestvalidloss 3.63544  last_update 0\n",
      "train: iter 16  trainloss 3.46865  validloss 3.52907±0.00000  bestvalidloss 3.52907  last_update 0\n",
      "train: iter 17  trainloss 3.41392  validloss 3.43009±0.00000  bestvalidloss 3.43009  last_update 0\n",
      "train: iter 18  trainloss 3.32520  validloss 3.34680±0.00000  bestvalidloss 3.34680  last_update 0\n",
      "train: iter 19  trainloss 3.26818  validloss 3.26598±0.00000  bestvalidloss 3.26598  last_update 0\n",
      "train: iter 20  trainloss 3.18245  validloss 3.20449±0.00000  bestvalidloss 3.20449  last_update 0\n",
      "train: iter 21  trainloss 3.13450  validloss 3.14374±0.00000  bestvalidloss 3.14374  last_update 0\n",
      "train: iter 22  trainloss 3.08280  validloss 3.09191±0.00000  bestvalidloss 3.09191  last_update 0\n",
      "train: iter 23  trainloss 3.04581  validloss 3.03103±0.00000  bestvalidloss 3.03103  last_update 0\n",
      "train: iter 24  trainloss 2.97804  validloss 2.98875±0.00000  bestvalidloss 2.98875  last_update 0\n",
      "train: iter 25  trainloss 2.95461  validloss 2.94870±0.00000  bestvalidloss 2.94870  last_update 0\n",
      "train: iter 26  trainloss 2.92655  validloss 2.91528±0.00000  bestvalidloss 2.91528  last_update 0\n",
      "train: iter 27  trainloss 2.87586  validloss 2.86607±0.00000  bestvalidloss 2.86607  last_update 0\n",
      "train: iter 28  trainloss 2.82930  validloss 2.84259±0.00000  bestvalidloss 2.84259  last_update 0\n",
      "train: iter 29  trainloss 2.79416  validloss 2.79959±0.00000  bestvalidloss 2.79959  last_update 0\n",
      "train: iter 30  trainloss 2.76857  validloss 2.76971±0.00000  bestvalidloss 2.76971  last_update 0\n",
      "train: iter 31  trainloss 2.74434  validloss 2.71107±0.00000  bestvalidloss 2.71107  last_update 0\n",
      "train: iter 32  trainloss 2.69724  validloss 2.72133±0.00000  bestvalidloss 2.71107  last_update 1\n",
      "train: iter 33  trainloss 2.70255  validloss 2.66983±0.00000  bestvalidloss 2.66983  last_update 0\n",
      "train: iter 34  trainloss 2.68054  validloss 2.65413±0.00000  bestvalidloss 2.65413  last_update 0\n",
      "train: iter 35  trainloss 2.63508  validloss 2.61664±0.00000  bestvalidloss 2.61664  last_update 0\n",
      "train: iter 36  trainloss 2.61202  validloss 2.57512±0.00000  bestvalidloss 2.57512  last_update 0\n",
      "train: iter 37  trainloss 2.61258  validloss 2.54839±0.00000  bestvalidloss 2.54839  last_update 0\n",
      "train: iter 38  trainloss 2.54505  validloss 2.54852±0.00000  bestvalidloss 2.54839  last_update 1\n",
      "train: iter 39  trainloss 2.52658  validloss 2.52838±0.00000  bestvalidloss 2.52838  last_update 0\n",
      "train: iter 40  trainloss 2.50502  validloss 2.51324±0.00000  bestvalidloss 2.51324  last_update 0\n",
      "train: iter 41  trainloss 2.48449  validloss 2.49706±0.00000  bestvalidloss 2.49706  last_update 0\n",
      "train: iter 42  trainloss 2.46858  validloss 2.46244±0.00000  bestvalidloss 2.46244  last_update 0\n",
      "train: iter 43  trainloss 2.44876  validloss 2.42953±0.00000  bestvalidloss 2.42953  last_update 0\n",
      "train: iter 44  trainloss 2.37759  validloss 2.43070±0.00000  bestvalidloss 2.42953  last_update 1\n",
      "train: iter 45  trainloss 2.39748  validloss 2.42247±0.00000  bestvalidloss 2.42247  last_update 0\n",
      "train: iter 46  trainloss 2.37750  validloss 2.33157±0.00000  bestvalidloss 2.33157  last_update 0\n",
      "train: iter 47  trainloss 2.33077  validloss 2.30406±0.00000  bestvalidloss 2.30406  last_update 0\n",
      "train: iter 48  trainloss 2.29568  validloss 2.26660±0.00000  bestvalidloss 2.26660  last_update 0\n",
      "train: iter 49  trainloss 2.29876  validloss 2.27594±0.00000  bestvalidloss 2.26660  last_update 1\n",
      "train: iter 50  trainloss 2.22779  validloss 2.23594±0.00000  bestvalidloss 2.23594  last_update 0\n",
      "train: iter 51  trainloss 2.20509  validloss 2.16828±0.00000  bestvalidloss 2.16828  last_update 0\n",
      "train: iter 52  trainloss 2.15847  validloss 2.14904±0.00000  bestvalidloss 2.14904  last_update 0\n",
      "train: iter 53  trainloss 2.10976  validloss 2.09106±0.00000  bestvalidloss 2.09106  last_update 0\n",
      "train: iter 54  trainloss 2.08704  validloss 2.06209±0.00000  bestvalidloss 2.06209  last_update 0\n",
      "train: iter 55  trainloss 2.05024  validloss 1.99554±0.00000  bestvalidloss 1.99554  last_update 0\n",
      "train: iter 56  trainloss 2.00562  validloss 2.02653±0.00000  bestvalidloss 1.99554  last_update 1\n",
      "train: iter 57  trainloss 1.95971  validloss 1.95978±0.00000  bestvalidloss 1.95978  last_update 0\n",
      "train: iter 58  trainloss 1.90290  validloss 1.89934±0.00000  bestvalidloss 1.89934  last_update 0\n",
      "train: iter 59  trainloss 1.86268  validloss 1.85402±0.00000  bestvalidloss 1.85402  last_update 0\n",
      "train: iter 60  trainloss 1.82887  validloss 1.80548±0.00000  bestvalidloss 1.80548  last_update 0\n",
      "train: iter 61  trainloss 1.76889  validloss 1.78425±0.00000  bestvalidloss 1.78425  last_update 0\n",
      "train: iter 62  trainloss 1.74970  validloss 1.73346±0.00000  bestvalidloss 1.73346  last_update 0\n",
      "train: iter 63  trainloss 1.66737  validloss 1.68574±0.00000  bestvalidloss 1.68574  last_update 0\n",
      "train: iter 64  trainloss 1.64198  validloss 1.63517±0.00000  bestvalidloss 1.63517  last_update 0\n",
      "train: iter 65  trainloss 1.59052  validloss 1.56309±0.00000  bestvalidloss 1.56309  last_update 0\n",
      "train: iter 66  trainloss 1.54116  validloss 1.53051±0.00000  bestvalidloss 1.53051  last_update 0\n",
      "train: iter 67  trainloss 1.49576  validloss 1.47561±0.00000  bestvalidloss 1.47561  last_update 0\n",
      "train: iter 68  trainloss 1.47194  validloss 1.41835±0.00000  bestvalidloss 1.41835  last_update 0\n",
      "train: iter 69  trainloss 1.43907  validloss 1.37153±0.00000  bestvalidloss 1.37153  last_update 0\n",
      "train: iter 70  trainloss 1.36959  validloss 1.33253±0.00000  bestvalidloss 1.33253  last_update 0\n",
      "train: iter 71  trainloss 1.34279  validloss 1.30347±0.00000  bestvalidloss 1.30347  last_update 0\n",
      "train: iter 72  trainloss 1.30637  validloss 1.26854±0.00000  bestvalidloss 1.26854  last_update 0\n",
      "train: iter 73  trainloss 1.25550  validloss 1.23313±0.00000  bestvalidloss 1.23313  last_update 0\n",
      "train: iter 74  trainloss 1.22096  validloss 1.20083±0.00000  bestvalidloss 1.20083  last_update 0\n",
      "train: iter 75  trainloss 1.18836  validloss 1.13655±0.00000  bestvalidloss 1.13655  last_update 0\n",
      "train: iter 76  trainloss 1.13620  validloss 1.16665±0.00000  bestvalidloss 1.13655  last_update 1\n",
      "train: iter 77  trainloss 1.11735  validloss 1.06475±0.00000  bestvalidloss 1.06475  last_update 0\n",
      "train: iter 78  trainloss 1.05978  validloss 1.02460±0.00000  bestvalidloss 1.02460  last_update 0\n",
      "train: iter 79  trainloss 1.03568  validloss 1.03139±0.00000  bestvalidloss 1.02460  last_update 1\n",
      "train: iter 80  trainloss 1.00339  validloss 0.97473±0.00000  bestvalidloss 0.97473  last_update 0\n",
      "train: iter 81  trainloss 0.98861  validloss 0.87926±0.00000  bestvalidloss 0.87926  last_update 0\n",
      "train: iter 82  trainloss 0.93640  validloss 0.89227±0.00000  bestvalidloss 0.87926  last_update 1\n",
      "train: iter 83  trainloss 0.90501  validloss 0.88331±0.00000  bestvalidloss 0.87926  last_update 2\n",
      "train: iter 84  trainloss 0.85382  validloss 0.89230±0.00000  bestvalidloss 0.87926  last_update 3\n",
      "train: iter 85  trainloss 0.83548  validloss 0.77143±0.00000  bestvalidloss 0.77143  last_update 0\n",
      "train: iter 86  trainloss 0.79529  validloss 0.76213±0.00000  bestvalidloss 0.76213  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 87  trainloss 0.77942  validloss 0.74748±0.00000  bestvalidloss 0.74748  last_update 0\n",
      "train: iter 88  trainloss 0.75541  validloss 0.71243±0.00000  bestvalidloss 0.71243  last_update 0\n",
      "train: iter 89  trainloss 0.71772  validloss 0.66616±0.00000  bestvalidloss 0.66616  last_update 0\n",
      "train: iter 90  trainloss 0.68688  validloss 0.65195±0.00000  bestvalidloss 0.65195  last_update 0\n",
      "train: iter 91  trainloss 0.66467  validloss 0.56696±0.00000  bestvalidloss 0.56696  last_update 0\n",
      "train: iter 92  trainloss 0.63847  validloss 0.60528±0.00000  bestvalidloss 0.56696  last_update 1\n",
      "train: iter 93  trainloss 0.60394  validloss 0.56852±0.00000  bestvalidloss 0.56696  last_update 2\n",
      "train: iter 94  trainloss 0.60927  validloss 0.53957±0.00000  bestvalidloss 0.53957  last_update 0\n",
      "train: iter 95  trainloss 0.55909  validloss 0.54636±0.00000  bestvalidloss 0.53957  last_update 1\n",
      "train: iter 96  trainloss 0.54131  validloss 0.48657±0.00000  bestvalidloss 0.48657  last_update 0\n",
      "train: iter 97  trainloss 0.52105  validloss 0.46806±0.00000  bestvalidloss 0.46806  last_update 0\n",
      "train: iter 98  trainloss 0.49471  validloss 0.41891±0.00000  bestvalidloss 0.41891  last_update 0\n",
      "train: iter 99  trainloss 0.50057  validloss 0.41601±0.00000  bestvalidloss 0.41601  last_update 0\n",
      "train: iter 100  trainloss 0.48921  validloss 0.41586±0.00000  bestvalidloss 0.41586  last_update 0\n",
      "train: iter 101  trainloss 0.44996  validloss 0.40024±0.00000  bestvalidloss 0.40024  last_update 0\n",
      "train: iter 102  trainloss 0.44470  validloss 0.33442±0.00000  bestvalidloss 0.33442  last_update 0\n",
      "train: iter 103  trainloss 0.40932  validloss 0.35016±0.00000  bestvalidloss 0.33442  last_update 1\n",
      "train: iter 104  trainloss 0.44303  validloss 0.34077±0.00000  bestvalidloss 0.33442  last_update 2\n",
      "train: iter 105  trainloss 0.42000  validloss 0.29062±0.00000  bestvalidloss 0.29062  last_update 0\n",
      "train: iter 106  trainloss 0.39907  validloss 0.28862±0.00000  bestvalidloss 0.28862  last_update 0\n",
      "train: iter 107  trainloss 0.38565  validloss 0.34123±0.00000  bestvalidloss 0.28862  last_update 1\n",
      "train: iter 108  trainloss 0.38523  validloss 0.29530±0.00000  bestvalidloss 0.28862  last_update 2\n",
      "train: iter 109  trainloss 0.35637  validloss 0.26775±0.00000  bestvalidloss 0.26775  last_update 0\n",
      "train: iter 110  trainloss 0.37846  validloss 0.27136±0.00000  bestvalidloss 0.26775  last_update 1\n",
      "train: iter 111  trainloss 0.35920  validloss 0.26576±0.00000  bestvalidloss 0.26576  last_update 0\n",
      "train: iter 112  trainloss 0.35922  validloss 0.27481±0.00000  bestvalidloss 0.26576  last_update 1\n",
      "train: iter 113  trainloss 0.34936  validloss 0.28249±0.00000  bestvalidloss 0.26576  last_update 2\n",
      "train: iter 114  trainloss 0.38327  validloss 0.20204±0.00000  bestvalidloss 0.20204  last_update 0\n",
      "train: iter 115  trainloss 0.35842  validloss 0.25416±0.00000  bestvalidloss 0.20204  last_update 1\n",
      "train: iter 116  trainloss 0.34618  validloss 0.19559±0.00000  bestvalidloss 0.19559  last_update 0\n",
      "train: iter 117  trainloss 0.35997  validloss 0.23146±0.00000  bestvalidloss 0.19559  last_update 1\n",
      "train: iter 118  trainloss 0.33210  validloss 0.22384±0.00000  bestvalidloss 0.19559  last_update 2\n",
      "train: iter 119  trainloss 0.32576  validloss 0.20357±0.00000  bestvalidloss 0.19559  last_update 3\n",
      "train: iter 120  trainloss 0.30976  validloss 0.23009±0.00000  bestvalidloss 0.19559  last_update 4\n",
      "train: iter 121  trainloss 0.32011  validloss 0.23104±0.00000  bestvalidloss 0.19559  last_update 5\n",
      "train: iter 122  trainloss 0.30700  validloss 0.17527±0.00000  bestvalidloss 0.17527  last_update 0\n",
      "train: iter 123  trainloss 0.36047  validloss 0.21180±0.00000  bestvalidloss 0.17527  last_update 1\n",
      "train: iter 124  trainloss 0.37090  validloss 0.20895±0.00000  bestvalidloss 0.17527  last_update 2\n",
      "train: iter 125  trainloss 0.32452  validloss 0.20968±0.00000  bestvalidloss 0.17527  last_update 3\n",
      "train: iter 126  trainloss 0.31131  validloss 0.16792±0.00000  bestvalidloss 0.16792  last_update 0\n",
      "train: iter 127  trainloss 0.33334  validloss 0.19640±0.00000  bestvalidloss 0.16792  last_update 1\n",
      "train: iter 128  trainloss 0.34482  validloss 0.20362±0.00000  bestvalidloss 0.16792  last_update 2\n",
      "train: iter 129  trainloss 0.33634  validloss 0.21072±0.00000  bestvalidloss 0.16792  last_update 3\n",
      "train: iter 130  trainloss 0.34658  validloss 0.19095±0.00000  bestvalidloss 0.16792  last_update 4\n",
      "train: iter 131  trainloss 0.32312  validloss 0.18033±0.00000  bestvalidloss 0.16792  last_update 5\n",
      "train: iter 132  trainloss 0.36271  validloss 0.19807±0.00000  bestvalidloss 0.16792  last_update 6\n",
      "train: iter 133  trainloss 0.31305  validloss 0.17312±0.00000  bestvalidloss 0.16792  last_update 7\n",
      "train: iter 134  trainloss 0.31869  validloss 0.13419±0.00000  bestvalidloss 0.13419  last_update 0\n",
      "train: iter 135  trainloss 0.34238  validloss 0.19416±0.00000  bestvalidloss 0.13419  last_update 1\n",
      "train: iter 136  trainloss 0.31989  validloss 0.19831±0.00000  bestvalidloss 0.13419  last_update 2\n",
      "train: iter 137  trainloss 0.30290  validloss 0.17683±0.00000  bestvalidloss 0.13419  last_update 3\n",
      "train: iter 138  trainloss 0.30807  validloss 0.18023±0.00000  bestvalidloss 0.13419  last_update 4\n",
      "train: iter 139  trainloss 0.33744  validloss 0.18865±0.00000  bestvalidloss 0.13419  last_update 5\n",
      "train: iter 140  trainloss 0.32074  validloss 0.12289±0.00000  bestvalidloss 0.12289  last_update 0\n",
      "train: iter 141  trainloss 0.33451  validloss 0.22266±0.00000  bestvalidloss 0.12289  last_update 1\n",
      "train: iter 142  trainloss 0.31712  validloss 0.19940±0.00000  bestvalidloss 0.12289  last_update 2\n",
      "train: iter 143  trainloss 0.31003  validloss 0.15935±0.00000  bestvalidloss 0.12289  last_update 3\n",
      "train: iter 144  trainloss 0.29234  validloss 0.16850±0.00000  bestvalidloss 0.12289  last_update 4\n",
      "train: iter 145  trainloss 0.33808  validloss 0.18100±0.00000  bestvalidloss 0.12289  last_update 5\n",
      "train: iter 146  trainloss 0.30282  validloss 0.20625±0.00000  bestvalidloss 0.12289  last_update 6\n",
      "train: iter 147  trainloss 0.29295  validloss 0.13442±0.00000  bestvalidloss 0.12289  last_update 7\n",
      "train: iter 148  trainloss 0.35082  validloss 0.20312±0.00000  bestvalidloss 0.12289  last_update 8\n",
      "train: iter 149  trainloss 0.30043  validloss 0.20695±0.00000  bestvalidloss 0.12289  last_update 9\n",
      "train: iter 150  trainloss 0.33309  validloss 0.14731±0.00000  bestvalidloss 0.12289  last_update 10\n",
      "train: iter 151  trainloss 0.33243  validloss 0.15711±0.00000  bestvalidloss 0.12289  last_update 11\n",
      "train: iter 152  trainloss 0.31807  validloss 0.15882±0.00000  bestvalidloss 0.12289  last_update 12\n",
      "train: iter 153  trainloss 0.32534  validloss 0.18414±0.00000  bestvalidloss 0.12289  last_update 13\n",
      "train: iter 154  trainloss 0.29931  validloss 0.22209±0.00000  bestvalidloss 0.12289  last_update 14\n",
      "train: iter 155  trainloss 0.31270  validloss 0.19344±0.00000  bestvalidloss 0.12289  last_update 15\n",
      "train: iter 156  trainloss 0.30702  validloss 0.16721±0.00000  bestvalidloss 0.12289  last_update 16\n",
      "train: iter 157  trainloss 0.31073  validloss 0.16318±0.00000  bestvalidloss 0.12289  last_update 17\n",
      "train: iter 158  trainloss 0.34027  validloss 0.13733±0.00000  bestvalidloss 0.12289  last_update 18\n",
      "train: iter 159  trainloss 0.28665  validloss 0.19100±0.00000  bestvalidloss 0.12289  last_update 19\n",
      "train: iter 160  trainloss 0.29595  validloss 0.18880±0.00000  bestvalidloss 0.12289  last_update 20\n",
      "train: iter 161  trainloss 0.31880  validloss 0.14995±0.00000  bestvalidloss 0.12289  last_update 21\n",
      "train: iter 162  trainloss 0.30563  validloss 0.24835±0.00000  bestvalidloss 0.12289  last_update 22\n",
      "train: iter 163  trainloss 0.31816  validloss 0.16493±0.00000  bestvalidloss 0.12289  last_update 23\n",
      "train: iter 164  trainloss 0.32082  validloss 0.15302±0.00000  bestvalidloss 0.12289  last_update 24\n",
      "train: iter 165  trainloss 0.32065  validloss 0.18198±0.00000  bestvalidloss 0.12289  last_update 25\n",
      "train: iter 166  trainloss 0.31609  validloss 0.16097±0.00000  bestvalidloss 0.12289  last_update 26\n",
      "train: iter 167  trainloss 0.31597  validloss 0.14698±0.00000  bestvalidloss 0.12289  last_update 27\n",
      "train: iter 168  trainloss 0.33104  validloss 0.19050±0.00000  bestvalidloss 0.12289  last_update 28\n",
      "train: iter 169  trainloss 0.32767  validloss 0.14981±0.00000  bestvalidloss 0.12289  last_update 29\n",
      "train: iter 170  trainloss 0.32920  validloss 0.10313±0.00000  bestvalidloss 0.10313  last_update 0\n",
      "train: iter 171  trainloss 0.34386  validloss 0.15951±0.00000  bestvalidloss 0.10313  last_update 1\n",
      "train: iter 172  trainloss 0.31363  validloss 0.21081±0.00000  bestvalidloss 0.10313  last_update 2\n",
      "train: iter 173  trainloss 0.35271  validloss 0.16866±0.00000  bestvalidloss 0.10313  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 174  trainloss 0.34717  validloss 0.16155±0.00000  bestvalidloss 0.10313  last_update 4\n",
      "train: iter 175  trainloss 0.30557  validloss 0.19422±0.00000  bestvalidloss 0.10313  last_update 5\n",
      "train: iter 176  trainloss 0.34021  validloss 0.17243±0.00000  bestvalidloss 0.10313  last_update 6\n",
      "train: iter 177  trainloss 0.31777  validloss 0.18798±0.00000  bestvalidloss 0.10313  last_update 7\n",
      "train: iter 178  trainloss 0.30740  validloss 0.12094±0.00000  bestvalidloss 0.10313  last_update 8\n",
      "train: iter 179  trainloss 0.30602  validloss 0.16041±0.00000  bestvalidloss 0.10313  last_update 9\n",
      "train: iter 180  trainloss 0.28842  validloss 0.11640±0.00000  bestvalidloss 0.10313  last_update 10\n",
      "train: iter 181  trainloss 0.32483  validloss 0.15993±0.00000  bestvalidloss 0.10313  last_update 11\n",
      "train: iter 182  trainloss 0.30514  validloss 0.20139±0.00000  bestvalidloss 0.10313  last_update 12\n",
      "train: iter 183  trainloss 0.29079  validloss 0.14830±0.00000  bestvalidloss 0.10313  last_update 13\n",
      "train: iter 184  trainloss 0.33894  validloss 0.24771±0.00000  bestvalidloss 0.10313  last_update 14\n",
      "train: iter 185  trainloss 0.30245  validloss 0.14791±0.00000  bestvalidloss 0.10313  last_update 15\n",
      "train: iter 186  trainloss 0.34224  validloss 0.17251±0.00000  bestvalidloss 0.10313  last_update 16\n",
      "train: iter 187  trainloss 0.28580  validloss 0.20111±0.00000  bestvalidloss 0.10313  last_update 17\n",
      "train: iter 188  trainloss 0.28554  validloss 0.12624±0.00000  bestvalidloss 0.10313  last_update 18\n",
      "train: iter 189  trainloss 0.28173  validloss 0.12227±0.00000  bestvalidloss 0.10313  last_update 19\n",
      "train: iter 190  trainloss 0.31530  validloss 0.14509±0.00000  bestvalidloss 0.10313  last_update 20\n",
      "train: iter 191  trainloss 0.35421  validloss 0.16041±0.00000  bestvalidloss 0.10313  last_update 21\n",
      "train: iter 192  trainloss 0.32982  validloss 0.22317±0.00000  bestvalidloss 0.10313  last_update 22\n",
      "train: iter 193  trainloss 0.30663  validloss 0.21082±0.00000  bestvalidloss 0.10313  last_update 23\n",
      "train: iter 194  trainloss 0.35713  validloss 0.17871±0.00000  bestvalidloss 0.10313  last_update 24\n",
      "train: iter 195  trainloss 0.32786  validloss 0.18515±0.00000  bestvalidloss 0.10313  last_update 25\n",
      "train: iter 196  trainloss 0.33082  validloss 0.19728±0.00000  bestvalidloss 0.10313  last_update 26\n",
      "train: iter 197  trainloss 0.33443  validloss 0.21375±0.00000  bestvalidloss 0.10313  last_update 27\n",
      "train: iter 198  trainloss 0.29182  validloss 0.19919±0.00000  bestvalidloss 0.10313  last_update 28\n",
      "train: iter 199  trainloss 0.31726  validloss 0.17674±0.00000  bestvalidloss 0.10313  last_update 29\n",
      "train: iter 200  trainloss 0.32983  validloss 0.20443±0.00000  bestvalidloss 0.10313  last_update 30\n",
      "train: iter 201  trainloss 0.32982  validloss 0.14676±0.00000  bestvalidloss 0.10313  last_update 31\n",
      "train: iter 202  trainloss 0.30824  validloss 0.19198±0.00000  bestvalidloss 0.10313  last_update 32\n",
      "train: iter 203  trainloss 0.29183  validloss 0.19760±0.00000  bestvalidloss 0.10313  last_update 33\n",
      "train: iter 204  trainloss 0.31729  validloss 0.13320±0.00000  bestvalidloss 0.10313  last_update 34\n",
      "train: iter 205  trainloss 0.29698  validloss 0.14099±0.00000  bestvalidloss 0.10313  last_update 35\n",
      "train: iter 206  trainloss 0.34111  validloss 0.17501±0.00000  bestvalidloss 0.10313  last_update 36\n",
      "train: iter 207  trainloss 0.29761  validloss 0.16893±0.00000  bestvalidloss 0.10313  last_update 37\n",
      "train: iter 208  trainloss 0.34209  validloss 0.15418±0.00000  bestvalidloss 0.10313  last_update 38\n",
      "train: iter 209  trainloss 0.31194  validloss 0.12639±0.00000  bestvalidloss 0.10313  last_update 39\n",
      "train: iter 210  trainloss 0.30801  validloss 0.15785±0.00000  bestvalidloss 0.10313  last_update 40\n",
      "train: iter 211  trainloss 0.32062  validloss 0.19416±0.00000  bestvalidloss 0.10313  last_update 41\n",
      "train: iter 212  trainloss 0.32207  validloss 0.16994±0.00000  bestvalidloss 0.10313  last_update 42\n",
      "train: iter 213  trainloss 0.29272  validloss 0.19097±0.00000  bestvalidloss 0.10313  last_update 43\n",
      "train: iter 214  trainloss 0.28703  validloss 0.20581±0.00000  bestvalidloss 0.10313  last_update 44\n",
      "train: iter 215  trainloss 0.30746  validloss 0.19221±0.00000  bestvalidloss 0.10313  last_update 45\n",
      "train: iter 216  trainloss 0.29309  validloss 0.16193±0.00000  bestvalidloss 0.10313  last_update 46\n",
      "train: iter 217  trainloss 0.30279  validloss 0.15224±0.00000  bestvalidloss 0.10313  last_update 47\n",
      "train: iter 218  trainloss 0.33727  validloss 0.18561±0.00000  bestvalidloss 0.10313  last_update 48\n",
      "train: iter 219  trainloss 0.33659  validloss 0.17415±0.00000  bestvalidloss 0.10313  last_update 49\n",
      "train: iter 220  trainloss 0.28748  validloss 0.20337±0.00000  bestvalidloss 0.10313  last_update 50\n",
      "train: iter 221  trainloss 0.32492  validloss 0.13780±0.00000  bestvalidloss 0.10313  last_update 51\n",
      "train: iter 222  trainloss 0.29881  validloss 0.21604±0.00000  bestvalidloss 0.10313  last_update 52\n",
      "train: iter 223  trainloss 0.34061  validloss 0.12604±0.00000  bestvalidloss 0.10313  last_update 53\n",
      "train: iter 224  trainloss 0.32796  validloss 0.15481±0.00000  bestvalidloss 0.10313  last_update 54\n",
      "train: iter 225  trainloss 0.29777  validloss 0.11636±0.00000  bestvalidloss 0.10313  last_update 55\n",
      "train: iter 226  trainloss 0.31906  validloss 0.14522±0.00000  bestvalidloss 0.10313  last_update 56\n",
      "train: iter 227  trainloss 0.32545  validloss 0.19104±0.00000  bestvalidloss 0.10313  last_update 57\n",
      "train: iter 228  trainloss 0.31989  validloss 0.18220±0.00000  bestvalidloss 0.10313  last_update 58\n",
      "train: iter 229  trainloss 0.29231  validloss 0.19920±0.00000  bestvalidloss 0.10313  last_update 59\n",
      "train: iter 230  trainloss 0.31085  validloss 0.17229±0.00000  bestvalidloss 0.10313  last_update 60\n",
      "train: iter 231  trainloss 0.32041  validloss 0.16497±0.00000  bestvalidloss 0.10313  last_update 61\n",
      "train: iter 232  trainloss 0.34833  validloss 0.10291±0.00000  bestvalidloss 0.10291  last_update 0\n",
      "train: iter 233  trainloss 0.34395  validloss 0.16711±0.00000  bestvalidloss 0.10291  last_update 1\n",
      "train: iter 234  trainloss 0.30697  validloss 0.15464±0.00000  bestvalidloss 0.10291  last_update 2\n",
      "train: iter 235  trainloss 0.33033  validloss 0.17000±0.00000  bestvalidloss 0.10291  last_update 3\n",
      "train: iter 236  trainloss 0.32499  validloss 0.15812±0.00000  bestvalidloss 0.10291  last_update 4\n",
      "train: iter 237  trainloss 0.33058  validloss 0.12890±0.00000  bestvalidloss 0.10291  last_update 5\n",
      "train: iter 238  trainloss 0.33466  validloss 0.14033±0.00000  bestvalidloss 0.10291  last_update 6\n",
      "train: iter 239  trainloss 0.32000  validloss 0.19002±0.00000  bestvalidloss 0.10291  last_update 7\n",
      "train: iter 240  trainloss 0.32249  validloss 0.21106±0.00000  bestvalidloss 0.10291  last_update 8\n",
      "train: iter 241  trainloss 0.32262  validloss 0.15127±0.00000  bestvalidloss 0.10291  last_update 9\n",
      "train: iter 242  trainloss 0.28401  validloss 0.17056±0.00000  bestvalidloss 0.10291  last_update 10\n",
      "train: iter 243  trainloss 0.32063  validloss 0.16042±0.00000  bestvalidloss 0.10291  last_update 11\n",
      "train: iter 244  trainloss 0.31262  validloss 0.23428±0.00000  bestvalidloss 0.10291  last_update 12\n",
      "train: iter 245  trainloss 0.34457  validloss 0.19081±0.00000  bestvalidloss 0.10291  last_update 13\n",
      "train: iter 246  trainloss 0.28331  validloss 0.20693±0.00000  bestvalidloss 0.10291  last_update 14\n",
      "train: iter 247  trainloss 0.32397  validloss 0.19878±0.00000  bestvalidloss 0.10291  last_update 15\n",
      "train: iter 248  trainloss 0.30689  validloss 0.19883±0.00000  bestvalidloss 0.10291  last_update 16\n",
      "train: iter 249  trainloss 0.36696  validloss 0.17217±0.00000  bestvalidloss 0.10291  last_update 17\n",
      "train: iter 250  trainloss 0.30174  validloss 0.14427±0.00000  bestvalidloss 0.10291  last_update 18\n",
      "train: iter 251  trainloss 0.29880  validloss 0.14161±0.00000  bestvalidloss 0.10291  last_update 19\n",
      "train: iter 252  trainloss 0.28603  validloss 0.22710±0.00000  bestvalidloss 0.10291  last_update 20\n",
      "train: iter 253  trainloss 0.34652  validloss 0.15501±0.00000  bestvalidloss 0.10291  last_update 21\n",
      "train: iter 254  trainloss 0.33226  validloss 0.21113±0.00000  bestvalidloss 0.10291  last_update 22\n",
      "train: iter 255  trainloss 0.31350  validloss 0.17021±0.00000  bestvalidloss 0.10291  last_update 23\n",
      "train: iter 256  trainloss 0.33213  validloss 0.16151±0.00000  bestvalidloss 0.10291  last_update 24\n",
      "train: iter 257  trainloss 0.32537  validloss 0.17226±0.00000  bestvalidloss 0.10291  last_update 25\n",
      "train: iter 258  trainloss 0.27706  validloss 0.17914±0.00000  bestvalidloss 0.10291  last_update 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 259  trainloss 0.30693  validloss 0.16196±0.00000  bestvalidloss 0.10291  last_update 27\n",
      "train: iter 260  trainloss 0.31067  validloss 0.14048±0.00000  bestvalidloss 0.10291  last_update 28\n",
      "train: iter 261  trainloss 0.30908  validloss 0.15213±0.00000  bestvalidloss 0.10291  last_update 29\n",
      "train: iter 262  trainloss 0.30127  validloss 0.14059±0.00000  bestvalidloss 0.10291  last_update 30\n",
      "train: iter 263  trainloss 0.30614  validloss 0.17883±0.00000  bestvalidloss 0.10291  last_update 31\n",
      "train: iter 264  trainloss 0.28687  validloss 0.13361±0.00000  bestvalidloss 0.10291  last_update 32\n",
      "train: iter 265  trainloss 0.32309  validloss 0.11967±0.00000  bestvalidloss 0.10291  last_update 33\n",
      "train: iter 266  trainloss 0.29795  validloss 0.19071±0.00000  bestvalidloss 0.10291  last_update 34\n",
      "train: iter 267  trainloss 0.34207  validloss 0.20732±0.00000  bestvalidloss 0.10291  last_update 35\n",
      "train: iter 268  trainloss 0.33136  validloss 0.20755±0.00000  bestvalidloss 0.10291  last_update 36\n",
      "train: iter 269  trainloss 0.29382  validloss 0.07869±0.00000  bestvalidloss 0.07869  last_update 0\n",
      "train: iter 270  trainloss 0.33432  validloss 0.19657±0.00000  bestvalidloss 0.07869  last_update 1\n",
      "train: iter 271  trainloss 0.34401  validloss 0.20570±0.00000  bestvalidloss 0.07869  last_update 2\n",
      "train: iter 272  trainloss 0.33493  validloss 0.15164±0.00000  bestvalidloss 0.07869  last_update 3\n",
      "train: iter 273  trainloss 0.30389  validloss 0.19759±0.00000  bestvalidloss 0.07869  last_update 4\n",
      "train: iter 274  trainloss 0.31336  validloss 0.19453±0.00000  bestvalidloss 0.07869  last_update 5\n",
      "train: iter 275  trainloss 0.32647  validloss 0.19415±0.00000  bestvalidloss 0.07869  last_update 6\n",
      "train: iter 276  trainloss 0.29368  validloss 0.13756±0.00000  bestvalidloss 0.07869  last_update 7\n",
      "train: iter 277  trainloss 0.33231  validloss 0.11765±0.00000  bestvalidloss 0.07869  last_update 8\n",
      "train: iter 278  trainloss 0.30795  validloss 0.13302±0.00000  bestvalidloss 0.07869  last_update 9\n",
      "train: iter 279  trainloss 0.31790  validloss 0.11815±0.00000  bestvalidloss 0.07869  last_update 10\n",
      "train: iter 280  trainloss 0.29688  validloss 0.19204±0.00000  bestvalidloss 0.07869  last_update 11\n",
      "train: iter 281  trainloss 0.32936  validloss 0.14674±0.00000  bestvalidloss 0.07869  last_update 12\n",
      "train: iter 282  trainloss 0.34202  validloss 0.17031±0.00000  bestvalidloss 0.07869  last_update 13\n",
      "train: iter 283  trainloss 0.29946  validloss 0.14761±0.00000  bestvalidloss 0.07869  last_update 14\n",
      "train: iter 284  trainloss 0.33998  validloss 0.19384±0.00000  bestvalidloss 0.07869  last_update 15\n",
      "train: iter 285  trainloss 0.28488  validloss 0.17378±0.00000  bestvalidloss 0.07869  last_update 16\n",
      "train: iter 286  trainloss 0.28478  validloss 0.18472±0.00000  bestvalidloss 0.07869  last_update 17\n",
      "train: iter 287  trainloss 0.34990  validloss 0.17468±0.00000  bestvalidloss 0.07869  last_update 18\n",
      "train: iter 288  trainloss 0.32147  validloss 0.15695±0.00000  bestvalidloss 0.07869  last_update 19\n",
      "train: iter 289  trainloss 0.31372  validloss 0.21053±0.00000  bestvalidloss 0.07869  last_update 20\n",
      "train: iter 290  trainloss 0.31543  validloss 0.17947±0.00000  bestvalidloss 0.07869  last_update 21\n",
      "train: iter 291  trainloss 0.30182  validloss 0.18054±0.00000  bestvalidloss 0.07869  last_update 22\n",
      "train: iter 292  trainloss 0.31599  validloss 0.15538±0.00000  bestvalidloss 0.07869  last_update 23\n",
      "train: iter 293  trainloss 0.31197  validloss 0.16814±0.00000  bestvalidloss 0.07869  last_update 24\n",
      "train: iter 294  trainloss 0.28927  validloss 0.12304±0.00000  bestvalidloss 0.07869  last_update 25\n",
      "train: iter 295  trainloss 0.31144  validloss 0.20048±0.00000  bestvalidloss 0.07869  last_update 26\n",
      "train: iter 296  trainloss 0.28407  validloss 0.16288±0.00000  bestvalidloss 0.07869  last_update 27\n",
      "train: iter 297  trainloss 0.33685  validloss 0.14741±0.00000  bestvalidloss 0.07869  last_update 28\n",
      "train: iter 298  trainloss 0.31507  validloss 0.13690±0.00000  bestvalidloss 0.07869  last_update 29\n",
      "train: iter 299  trainloss 0.27156  validloss 0.18583±0.00000  bestvalidloss 0.07869  last_update 30\n",
      "train: iter 300  trainloss 0.31158  validloss 0.15818±0.00000  bestvalidloss 0.07869  last_update 31\n",
      "train: iter 301  trainloss 0.29364  validloss 0.16673±0.00000  bestvalidloss 0.07869  last_update 32\n",
      "train: iter 302  trainloss 0.33890  validloss 0.16862±0.00000  bestvalidloss 0.07869  last_update 33\n",
      "train: iter 303  trainloss 0.32073  validloss 0.24245±0.00000  bestvalidloss 0.07869  last_update 34\n",
      "train: iter 304  trainloss 0.27538  validloss 0.18930±0.00000  bestvalidloss 0.07869  last_update 35\n",
      "train: iter 305  trainloss 0.27915  validloss 0.13665±0.00000  bestvalidloss 0.07869  last_update 36\n",
      "train: iter 306  trainloss 0.30174  validloss 0.18775±0.00000  bestvalidloss 0.07869  last_update 37\n",
      "train: iter 307  trainloss 0.30792  validloss 0.25165±0.00000  bestvalidloss 0.07869  last_update 38\n",
      "train: iter 308  trainloss 0.31586  validloss 0.21870±0.00000  bestvalidloss 0.07869  last_update 39\n",
      "train: iter 309  trainloss 0.32960  validloss 0.18591±0.00000  bestvalidloss 0.07869  last_update 40\n",
      "train: iter 310  trainloss 0.31241  validloss 0.15531±0.00000  bestvalidloss 0.07869  last_update 41\n",
      "train: iter 311  trainloss 0.30629  validloss 0.14085±0.00000  bestvalidloss 0.07869  last_update 42\n",
      "train: iter 312  trainloss 0.27660  validloss 0.14691±0.00000  bestvalidloss 0.07869  last_update 43\n",
      "train: iter 313  trainloss 0.26712  validloss 0.19930±0.00000  bestvalidloss 0.07869  last_update 44\n",
      "train: iter 314  trainloss 0.28731  validloss 0.16374±0.00000  bestvalidloss 0.07869  last_update 45\n",
      "train: iter 315  trainloss 0.30661  validloss 0.14734±0.00000  bestvalidloss 0.07869  last_update 46\n",
      "train: iter 316  trainloss 0.32151  validloss 0.22406±0.00000  bestvalidloss 0.07869  last_update 47\n",
      "train: iter 317  trainloss 0.30086  validloss 0.14151±0.00000  bestvalidloss 0.07869  last_update 48\n",
      "train: iter 318  trainloss 0.31390  validloss 0.18130±0.00000  bestvalidloss 0.07869  last_update 49\n",
      "train: iter 319  trainloss 0.33210  validloss 0.13235±0.00000  bestvalidloss 0.07869  last_update 50\n",
      "train: iter 320  trainloss 0.31471  validloss 0.17881±0.00000  bestvalidloss 0.07869  last_update 51\n",
      "train: iter 321  trainloss 0.34069  validloss 0.16159±0.00000  bestvalidloss 0.07869  last_update 52\n",
      "train: iter 322  trainloss 0.35483  validloss 0.18371±0.00000  bestvalidloss 0.07869  last_update 53\n",
      "train: iter 323  trainloss 0.32302  validloss 0.18182±0.00000  bestvalidloss 0.07869  last_update 54\n",
      "train: iter 324  trainloss 0.33996  validloss 0.14179±0.00000  bestvalidloss 0.07869  last_update 55\n",
      "train: iter 325  trainloss 0.31120  validloss 0.18200±0.00000  bestvalidloss 0.07869  last_update 56\n",
      "train: iter 326  trainloss 0.29460  validloss 0.23097±0.00000  bestvalidloss 0.07869  last_update 57\n",
      "train: iter 327  trainloss 0.32177  validloss 0.14481±0.00000  bestvalidloss 0.07869  last_update 58\n",
      "train: iter 328  trainloss 0.32489  validloss 0.20988±0.00000  bestvalidloss 0.07869  last_update 59\n",
      "train: iter 329  trainloss 0.30636  validloss 0.19309±0.00000  bestvalidloss 0.07869  last_update 60\n",
      "train: iter 330  trainloss 0.33174  validloss 0.11866±0.00000  bestvalidloss 0.07869  last_update 61\n",
      "train: iter 331  trainloss 0.31007  validloss 0.16552±0.00000  bestvalidloss 0.07869  last_update 62\n",
      "train: iter 332  trainloss 0.31068  validloss 0.15226±0.00000  bestvalidloss 0.07869  last_update 63\n",
      "train: iter 333  trainloss 0.31935  validloss 0.15719±0.00000  bestvalidloss 0.07869  last_update 64\n",
      "train: iter 334  trainloss 0.32041  validloss 0.16655±0.00000  bestvalidloss 0.07869  last_update 65\n",
      "train: iter 335  trainloss 0.32018  validloss 0.13495±0.00000  bestvalidloss 0.07869  last_update 66\n",
      "train: iter 336  trainloss 0.31795  validloss 0.21181±0.00000  bestvalidloss 0.07869  last_update 67\n",
      "train: iter 337  trainloss 0.28951  validloss 0.21442±0.00000  bestvalidloss 0.07869  last_update 68\n",
      "train: iter 338  trainloss 0.30970  validloss 0.12040±0.00000  bestvalidloss 0.07869  last_update 69\n",
      "train: iter 339  trainloss 0.30354  validloss 0.20888±0.00000  bestvalidloss 0.07869  last_update 70\n",
      "train: iter 340  trainloss 0.31185  validloss 0.18382±0.00000  bestvalidloss 0.07869  last_update 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 341  trainloss 0.28528  validloss 0.18499±0.00000  bestvalidloss 0.07869  last_update 72\n",
      "train: iter 342  trainloss 0.34505  validloss 0.13987±0.00000  bestvalidloss 0.07869  last_update 73\n",
      "train: iter 343  trainloss 0.31831  validloss 0.17314±0.00000  bestvalidloss 0.07869  last_update 74\n",
      "train: iter 344  trainloss 0.31725  validloss 0.19507±0.00000  bestvalidloss 0.07869  last_update 75\n",
      "train: iter 345  trainloss 0.31850  validloss 0.17615±0.00000  bestvalidloss 0.07869  last_update 76\n",
      "train: iter 346  trainloss 0.32797  validloss 0.15901±0.00000  bestvalidloss 0.07869  last_update 77\n",
      "train: iter 347  trainloss 0.30564  validloss 0.14424±0.00000  bestvalidloss 0.07869  last_update 78\n",
      "train: iter 348  trainloss 0.31395  validloss 0.18297±0.00000  bestvalidloss 0.07869  last_update 79\n",
      "train: iter 349  trainloss 0.30154  validloss 0.15427±0.00000  bestvalidloss 0.07869  last_update 80\n",
      "train: iter 350  trainloss 0.31073  validloss 0.16095±0.00000  bestvalidloss 0.07869  last_update 81\n",
      "train: iter 351  trainloss 0.29851  validloss 0.19841±0.00000  bestvalidloss 0.07869  last_update 82\n",
      "train: iter 352  trainloss 0.32227  validloss 0.15341±0.00000  bestvalidloss 0.07869  last_update 83\n",
      "train: iter 353  trainloss 0.33091  validloss 0.13462±0.00000  bestvalidloss 0.07869  last_update 84\n",
      "train: iter 354  trainloss 0.32713  validloss 0.16644±0.00000  bestvalidloss 0.07869  last_update 85\n",
      "train: iter 355  trainloss 0.28809  validloss 0.20849±0.00000  bestvalidloss 0.07869  last_update 86\n",
      "train: iter 356  trainloss 0.32437  validloss 0.12535±0.00000  bestvalidloss 0.07869  last_update 87\n",
      "train: iter 357  trainloss 0.27695  validloss 0.19197±0.00000  bestvalidloss 0.07869  last_update 88\n",
      "train: iter 358  trainloss 0.31865  validloss 0.11849±0.00000  bestvalidloss 0.07869  last_update 89\n",
      "train: iter 359  trainloss 0.30893  validloss 0.16494±0.00000  bestvalidloss 0.07869  last_update 90\n",
      "train: iter 360  trainloss 0.32158  validloss 0.12772±0.00000  bestvalidloss 0.07869  last_update 91\n",
      "train: iter 361  trainloss 0.30371  validloss 0.14585±0.00000  bestvalidloss 0.07869  last_update 92\n",
      "train: iter 362  trainloss 0.28887  validloss 0.21987±0.00000  bestvalidloss 0.07869  last_update 93\n",
      "train: iter 363  trainloss 0.29113  validloss 0.17551±0.00000  bestvalidloss 0.07869  last_update 94\n",
      "train: iter 364  trainloss 0.31922  validloss 0.22671±0.00000  bestvalidloss 0.07869  last_update 95\n",
      "train: iter 365  trainloss 0.32950  validloss 0.16336±0.00000  bestvalidloss 0.07869  last_update 96\n",
      "train: iter 366  trainloss 0.32469  validloss 0.14994±0.00000  bestvalidloss 0.07869  last_update 97\n",
      "train: iter 367  trainloss 0.30932  validloss 0.19329±0.00000  bestvalidloss 0.07869  last_update 98\n",
      "train: iter 368  trainloss 0.33980  validloss 0.19173±0.00000  bestvalidloss 0.07869  last_update 99\n",
      "train: iter 369  trainloss 0.32887  validloss 0.11970±0.00000  bestvalidloss 0.07869  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.5137, -0.4592, -3.6145, -1.4318], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 65.55991  validloss 77.14583±0.00000  bestvalidloss 77.14583  last_update 0\n",
      "train: iter 1  trainloss 46.63926  validloss 59.00230±0.00000  bestvalidloss 59.00230  last_update 0\n",
      "train: iter 2  trainloss 33.07988  validloss 41.25115±0.00000  bestvalidloss 41.25115  last_update 0\n",
      "train: iter 3  trainloss 24.70533  validloss 30.81574±0.00000  bestvalidloss 30.81574  last_update 0\n",
      "train: iter 4  trainloss 19.10741  validloss 23.62534±0.00000  bestvalidloss 23.62534  last_update 0\n",
      "train: iter 5  trainloss 15.39520  validloss 19.07860±0.00000  bestvalidloss 19.07860  last_update 0\n",
      "train: iter 6  trainloss 12.99627  validloss 16.15208±0.00000  bestvalidloss 16.15208  last_update 0\n",
      "train: iter 7  trainloss 11.25281  validloss 13.85369±0.00000  bestvalidloss 13.85369  last_update 0\n",
      "train: iter 8  trainloss 10.02591  validloss 12.15943±0.00000  bestvalidloss 12.15943  last_update 0\n",
      "train: iter 9  trainloss 9.24129  validloss 11.01096±0.00000  bestvalidloss 11.01096  last_update 0\n",
      "train: iter 10  trainloss 8.57870  validloss 10.21021±0.00000  bestvalidloss 10.21021  last_update 0\n",
      "train: iter 11  trainloss 8.08979  validloss 9.38549±0.00000  bestvalidloss 9.38549  last_update 0\n",
      "train: iter 12  trainloss 7.70005  validloss 9.01576±0.00000  bestvalidloss 9.01576  last_update 0\n",
      "train: iter 13  trainloss 7.37339  validloss 8.45886±0.00000  bestvalidloss 8.45886  last_update 0\n",
      "train: iter 14  trainloss 7.03934  validloss 7.83045±0.00000  bestvalidloss 7.83045  last_update 0\n",
      "train: iter 15  trainloss 6.77962  validloss 7.45576±0.00000  bestvalidloss 7.45576  last_update 0\n",
      "train: iter 16  trainloss 6.53621  validloss 7.06484±0.00000  bestvalidloss 7.06484  last_update 0\n",
      "train: iter 17  trainloss 6.34179  validloss 6.79802±0.00000  bestvalidloss 6.79802  last_update 0\n",
      "train: iter 18  trainloss 6.09644  validloss 6.49444±0.00000  bestvalidloss 6.49444  last_update 0\n",
      "train: iter 19  trainloss 5.88833  validloss 6.37983±0.00000  bestvalidloss 6.37983  last_update 0\n",
      "train: iter 20  trainloss 5.67852  validloss 6.09802±0.00000  bestvalidloss 6.09802  last_update 0\n",
      "train: iter 21  trainloss 5.52397  validloss 5.89129±0.00000  bestvalidloss 5.89129  last_update 0\n",
      "train: iter 22  trainloss 5.25973  validloss 5.86977±0.00000  bestvalidloss 5.86977  last_update 0\n",
      "train: iter 23  trainloss 4.97001  validloss 5.52081±0.00000  bestvalidloss 5.52081  last_update 0\n",
      "train: iter 24  trainloss 4.74892  validloss 5.30274±0.00000  bestvalidloss 5.30274  last_update 0\n",
      "train: iter 25  trainloss 4.62261  validloss 5.12994±0.00000  bestvalidloss 5.12994  last_update 0\n",
      "train: iter 26  trainloss 4.52271  validloss 4.99142±0.00000  bestvalidloss 4.99142  last_update 0\n",
      "train: iter 27  trainloss 4.46076  validloss 4.81432±0.00000  bestvalidloss 4.81432  last_update 0\n",
      "train: iter 28  trainloss 4.30833  validloss 4.77250±0.00000  bestvalidloss 4.77250  last_update 0\n",
      "train: iter 29  trainloss 4.35492  validloss 4.64267±0.00000  bestvalidloss 4.64267  last_update 0\n",
      "train: iter 30  trainloss 4.31775  validloss 4.81399±0.00000  bestvalidloss 4.64267  last_update 1\n",
      "train: iter 31  trainloss 4.20497  validloss 4.49415±0.00000  bestvalidloss 4.49415  last_update 0\n",
      "train: iter 32  trainloss 4.18513  validloss 4.49747±0.00000  bestvalidloss 4.49415  last_update 1\n",
      "train: iter 33  trainloss 4.18559  validloss 4.52665±0.00000  bestvalidloss 4.49415  last_update 2\n",
      "train: iter 34  trainloss 4.15224  validloss 4.32451±0.00000  bestvalidloss 4.32451  last_update 0\n",
      "train: iter 35  trainloss 4.12490  validloss 4.42642±0.00000  bestvalidloss 4.32451  last_update 1\n",
      "train: iter 36  trainloss 4.11803  validloss 4.48266±0.00000  bestvalidloss 4.32451  last_update 2\n",
      "train: iter 37  trainloss 4.11912  validloss 4.46994±0.00000  bestvalidloss 4.32451  last_update 3\n",
      "train: iter 38  trainloss 4.07516  validloss 4.41147±0.00000  bestvalidloss 4.32451  last_update 4\n",
      "train: iter 39  trainloss 4.07065  validloss 4.28997±0.00000  bestvalidloss 4.28997  last_update 0\n",
      "train: iter 40  trainloss 4.07576  validloss 4.28745±0.00000  bestvalidloss 4.28745  last_update 0\n",
      "train: iter 41  trainloss 4.05874  validloss 4.41834±0.00000  bestvalidloss 4.28745  last_update 1\n",
      "train: iter 42  trainloss 4.00307  validloss 4.35570±0.00000  bestvalidloss 4.28745  last_update 2\n",
      "train: iter 43  trainloss 4.00978  validloss 4.21062±0.00000  bestvalidloss 4.21062  last_update 0\n",
      "train: iter 44  trainloss 3.98925  validloss 4.27962±0.00000  bestvalidloss 4.21062  last_update 1\n",
      "train: iter 45  trainloss 3.99632  validloss 4.29236±0.00000  bestvalidloss 4.21062  last_update 2\n",
      "train: iter 46  trainloss 4.00193  validloss 4.27939±0.00000  bestvalidloss 4.21062  last_update 3\n",
      "train: iter 47  trainloss 3.94091  validloss 4.20196±0.00000  bestvalidloss 4.20196  last_update 0\n",
      "train: iter 48  trainloss 3.97843  validloss 4.26167±0.00000  bestvalidloss 4.20196  last_update 1\n",
      "train: iter 49  trainloss 3.92262  validloss 4.23683±0.00000  bestvalidloss 4.20196  last_update 2\n",
      "train: iter 50  trainloss 3.92643  validloss 4.23681±0.00000  bestvalidloss 4.20196  last_update 3\n",
      "train: iter 51  trainloss 3.92956  validloss 4.23688±0.00000  bestvalidloss 4.20196  last_update 4\n",
      "train: iter 52  trainloss 3.95391  validloss 4.29111±0.00000  bestvalidloss 4.20196  last_update 5\n",
      "train: iter 53  trainloss 3.93316  validloss 4.26117±0.00000  bestvalidloss 4.20196  last_update 6\n",
      "train: iter 54  trainloss 3.92168  validloss 4.26289±0.00000  bestvalidloss 4.20196  last_update 7\n",
      "train: iter 55  trainloss 3.99182  validloss 4.26977±0.00000  bestvalidloss 4.20196  last_update 8\n",
      "train: iter 56  trainloss 3.95704  validloss 4.26984±0.00000  bestvalidloss 4.20196  last_update 9\n",
      "train: iter 57  trainloss 3.93357  validloss 4.27019±0.00000  bestvalidloss 4.20196  last_update 10\n",
      "train: iter 58  trainloss 3.90373  validloss 4.20673±0.00000  bestvalidloss 4.20196  last_update 11\n",
      "train: iter 59  trainloss 3.91723  validloss 4.18241±0.00000  bestvalidloss 4.18241  last_update 0\n",
      "train: iter 60  trainloss 3.86534  validloss 4.24040±0.00000  bestvalidloss 4.18241  last_update 1\n",
      "train: iter 61  trainloss 3.91758  validloss 4.16752±0.00000  bestvalidloss 4.16752  last_update 0\n",
      "train: iter 62  trainloss 3.85311  validloss 4.12421±0.00000  bestvalidloss 4.12421  last_update 0\n",
      "train: iter 63  trainloss 3.90041  validloss 4.23129±0.00000  bestvalidloss 4.12421  last_update 1\n",
      "train: iter 64  trainloss 3.91000  validloss 4.13218±0.00000  bestvalidloss 4.12421  last_update 2\n",
      "train: iter 65  trainloss 3.89412  validloss 4.22975±0.00000  bestvalidloss 4.12421  last_update 3\n",
      "train: iter 66  trainloss 3.87861  validloss 4.14466±0.00000  bestvalidloss 4.12421  last_update 4\n",
      "train: iter 67  trainloss 3.91197  validloss 4.29175±0.00000  bestvalidloss 4.12421  last_update 5\n",
      "train: iter 68  trainloss 3.88934  validloss 4.29661±0.00000  bestvalidloss 4.12421  last_update 6\n",
      "train: iter 69  trainloss 3.88021  validloss 4.14891±0.00000  bestvalidloss 4.12421  last_update 7\n",
      "train: iter 70  trainloss 3.86816  validloss 4.16267±0.00000  bestvalidloss 4.12421  last_update 8\n",
      "train: iter 71  trainloss 3.87497  validloss 4.33413±0.00000  bestvalidloss 4.12421  last_update 9\n",
      "train: iter 72  trainloss 3.86510  validloss 4.19067±0.00000  bestvalidloss 4.12421  last_update 10\n",
      "train: iter 73  trainloss 3.85387  validloss 4.16851±0.00000  bestvalidloss 4.12421  last_update 11\n",
      "train: iter 74  trainloss 3.85269  validloss 4.21548±0.00000  bestvalidloss 4.12421  last_update 12\n",
      "train: iter 75  trainloss 3.90146  validloss 4.18058±0.00000  bestvalidloss 4.12421  last_update 13\n",
      "train: iter 76  trainloss 3.84464  validloss 4.21684±0.00000  bestvalidloss 4.12421  last_update 14\n",
      "train: iter 77  trainloss 3.84858  validloss 4.36284±0.00000  bestvalidloss 4.12421  last_update 15\n",
      "train: iter 78  trainloss 3.85432  validloss 4.14625±0.00000  bestvalidloss 4.12421  last_update 16\n",
      "train: iter 79  trainloss 3.84228  validloss 4.33152±0.00000  bestvalidloss 4.12421  last_update 17\n",
      "train: iter 80  trainloss 3.84011  validloss 4.33159±0.00000  bestvalidloss 4.12421  last_update 18\n",
      "train: iter 81  trainloss 3.82059  validloss 4.41702±0.00000  bestvalidloss 4.12421  last_update 19\n",
      "train: iter 82  trainloss 3.84547  validloss 4.29296±0.00000  bestvalidloss 4.12421  last_update 20\n",
      "train: iter 83  trainloss 3.81701  validloss 4.25237±0.00000  bestvalidloss 4.12421  last_update 21\n",
      "train: iter 84  trainloss 3.82246  validloss 4.32359±0.00000  bestvalidloss 4.12421  last_update 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 3.84240  validloss 4.12282±0.00000  bestvalidloss 4.12282  last_update 0\n",
      "train: iter 86  trainloss 3.84459  validloss 4.25184±0.00000  bestvalidloss 4.12282  last_update 1\n",
      "train: iter 87  trainloss 3.83298  validloss 4.19409±0.00000  bestvalidloss 4.12282  last_update 2\n",
      "train: iter 88  trainloss 3.83808  validloss 4.32926±0.00000  bestvalidloss 4.12282  last_update 3\n",
      "train: iter 89  trainloss 3.84305  validloss 4.35409±0.00000  bestvalidloss 4.12282  last_update 4\n",
      "train: iter 90  trainloss 3.83370  validloss 4.24336±0.00000  bestvalidloss 4.12282  last_update 5\n",
      "train: iter 91  trainloss 3.80221  validloss 4.25989±0.00000  bestvalidloss 4.12282  last_update 6\n",
      "train: iter 92  trainloss 3.82754  validloss 4.17524±0.00000  bestvalidloss 4.12282  last_update 7\n",
      "train: iter 93  trainloss 3.80434  validloss 4.26055±0.00000  bestvalidloss 4.12282  last_update 8\n",
      "train: iter 94  trainloss 3.83742  validloss 4.24571±0.00000  bestvalidloss 4.12282  last_update 9\n",
      "train: iter 95  trainloss 3.80851  validloss 4.28331±0.00000  bestvalidloss 4.12282  last_update 10\n",
      "train: iter 96  trainloss 3.79195  validloss 4.20611±0.00000  bestvalidloss 4.12282  last_update 11\n",
      "train: iter 97  trainloss 3.82186  validloss 4.32023±0.00000  bestvalidloss 4.12282  last_update 12\n",
      "train: iter 98  trainloss 3.82011  validloss 4.35623±0.00000  bestvalidloss 4.12282  last_update 13\n",
      "train: iter 99  trainloss 3.81410  validloss 4.35222±0.00000  bestvalidloss 4.12282  last_update 14\n",
      "train: iter 100  trainloss 3.78801  validloss 4.24320±0.00000  bestvalidloss 4.12282  last_update 15\n",
      "train: iter 101  trainloss 3.79546  validloss 4.30778±0.00000  bestvalidloss 4.12282  last_update 16\n",
      "train: iter 102  trainloss 3.78631  validloss 4.20489±0.00000  bestvalidloss 4.12282  last_update 17\n",
      "train: iter 103  trainloss 3.76948  validloss 4.26722±0.00000  bestvalidloss 4.12282  last_update 18\n",
      "train: iter 104  trainloss 3.77478  validloss 4.30885±0.00000  bestvalidloss 4.12282  last_update 19\n",
      "train: iter 105  trainloss 3.78369  validloss 4.24990±0.00000  bestvalidloss 4.12282  last_update 20\n",
      "train: iter 106  trainloss 3.80847  validloss 4.26464±0.00000  bestvalidloss 4.12282  last_update 21\n",
      "train: iter 107  trainloss 3.75848  validloss 4.20345±0.00000  bestvalidloss 4.12282  last_update 22\n",
      "train: iter 108  trainloss 3.80026  validloss 4.26795±0.00000  bestvalidloss 4.12282  last_update 23\n",
      "train: iter 109  trainloss 3.76987  validloss 4.23025±0.00000  bestvalidloss 4.12282  last_update 24\n",
      "train: iter 110  trainloss 3.79918  validloss 4.24352±0.00000  bestvalidloss 4.12282  last_update 25\n",
      "train: iter 111  trainloss 3.79251  validloss 4.30240±0.00000  bestvalidloss 4.12282  last_update 26\n",
      "train: iter 112  trainloss 3.80564  validloss 4.25431±0.00000  bestvalidloss 4.12282  last_update 27\n",
      "train: iter 113  trainloss 3.83407  validloss 4.29069±0.00000  bestvalidloss 4.12282  last_update 28\n",
      "train: iter 114  trainloss 3.75180  validloss 4.18551±0.00000  bestvalidloss 4.12282  last_update 29\n",
      "train: iter 115  trainloss 3.75088  validloss 4.10789±0.00000  bestvalidloss 4.10789  last_update 0\n",
      "train: iter 116  trainloss 3.77130  validloss 4.31573±0.00000  bestvalidloss 4.10789  last_update 1\n",
      "train: iter 117  trainloss 3.74447  validloss 4.26407±0.00000  bestvalidloss 4.10789  last_update 2\n",
      "train: iter 118  trainloss 3.73089  validloss 4.26665±0.00000  bestvalidloss 4.10789  last_update 3\n",
      "train: iter 119  trainloss 3.75887  validloss 4.26238±0.00000  bestvalidloss 4.10789  last_update 4\n",
      "train: iter 120  trainloss 3.76722  validloss 4.20158±0.00000  bestvalidloss 4.10789  last_update 5\n",
      "train: iter 121  trainloss 3.75186  validloss 4.36416±0.00000  bestvalidloss 4.10789  last_update 6\n",
      "train: iter 122  trainloss 3.72638  validloss 4.21545±0.00000  bestvalidloss 4.10789  last_update 7\n",
      "train: iter 123  trainloss 3.73379  validloss 4.44164±0.00000  bestvalidloss 4.10789  last_update 8\n",
      "train: iter 124  trainloss 3.78327  validloss 4.44495±0.00000  bestvalidloss 4.10789  last_update 9\n",
      "train: iter 125  trainloss 3.73374  validloss 4.21220±0.00000  bestvalidloss 4.10789  last_update 10\n",
      "train: iter 126  trainloss 3.75713  validloss 4.28631±0.00000  bestvalidloss 4.10789  last_update 11\n",
      "train: iter 127  trainloss 3.74960  validloss 4.20360±0.00000  bestvalidloss 4.10789  last_update 12\n",
      "train: iter 128  trainloss 3.75090  validloss 4.32273±0.00000  bestvalidloss 4.10789  last_update 13\n",
      "train: iter 129  trainloss 3.70187  validloss 4.31465±0.00000  bestvalidloss 4.10789  last_update 14\n",
      "train: iter 130  trainloss 3.73044  validloss 4.26563±0.00000  bestvalidloss 4.10789  last_update 15\n",
      "train: iter 131  trainloss 3.73442  validloss 4.38066±0.00000  bestvalidloss 4.10789  last_update 16\n",
      "train: iter 132  trainloss 3.71590  validloss 4.27784±0.00000  bestvalidloss 4.10789  last_update 17\n",
      "train: iter 133  trainloss 3.75699  validloss 4.29422±0.00000  bestvalidloss 4.10789  last_update 18\n",
      "train: iter 134  trainloss 3.75609  validloss 4.26290±0.00000  bestvalidloss 4.10789  last_update 19\n",
      "train: iter 135  trainloss 3.74632  validloss 4.28494±0.00000  bestvalidloss 4.10789  last_update 20\n",
      "train: iter 136  trainloss 3.72570  validloss 4.26402±0.00000  bestvalidloss 4.10789  last_update 21\n",
      "train: iter 137  trainloss 3.76041  validloss 4.28925±0.00000  bestvalidloss 4.10789  last_update 22\n",
      "train: iter 138  trainloss 3.71878  validloss 4.32617±0.00000  bestvalidloss 4.10789  last_update 23\n",
      "train: iter 139  trainloss 3.72561  validloss 4.21743±0.00000  bestvalidloss 4.10789  last_update 24\n",
      "train: iter 140  trainloss 3.67270  validloss 4.35620±0.00000  bestvalidloss 4.10789  last_update 25\n",
      "train: iter 141  trainloss 3.72555  validloss 4.35260±0.00000  bestvalidloss 4.10789  last_update 26\n",
      "train: iter 142  trainloss 3.69975  validloss 4.23994±0.00000  bestvalidloss 4.10789  last_update 27\n",
      "train: iter 143  trainloss 3.67480  validloss 4.31523±0.00000  bestvalidloss 4.10789  last_update 28\n",
      "train: iter 144  trainloss 3.69152  validloss 4.22715±0.00000  bestvalidloss 4.10789  last_update 29\n",
      "train: iter 145  trainloss 3.70088  validloss 4.33731±0.00000  bestvalidloss 4.10789  last_update 30\n",
      "train: iter 146  trainloss 3.69473  validloss 4.26395±0.00000  bestvalidloss 4.10789  last_update 31\n",
      "train: iter 147  trainloss 3.66394  validloss 4.31934±0.00000  bestvalidloss 4.10789  last_update 32\n",
      "train: iter 148  trainloss 3.71339  validloss 4.35841±0.00000  bestvalidloss 4.10789  last_update 33\n",
      "train: iter 149  trainloss 3.67814  validloss 4.38686±0.00000  bestvalidloss 4.10789  last_update 34\n",
      "train: iter 150  trainloss 3.71217  validloss 4.30655±0.00000  bestvalidloss 4.10789  last_update 35\n",
      "train: iter 151  trainloss 3.69521  validloss 4.30780±0.00000  bestvalidloss 4.10789  last_update 36\n",
      "train: iter 152  trainloss 3.68671  validloss 4.31881±0.00000  bestvalidloss 4.10789  last_update 37\n",
      "train: iter 153  trainloss 3.69355  validloss 4.29248±0.00000  bestvalidloss 4.10789  last_update 38\n",
      "train: iter 154  trainloss 3.69015  validloss 4.23199±0.00000  bestvalidloss 4.10789  last_update 39\n",
      "train: iter 155  trainloss 3.68648  validloss 4.25813±0.00000  bestvalidloss 4.10789  last_update 40\n",
      "train: iter 156  trainloss 3.69468  validloss 4.35057±0.00000  bestvalidloss 4.10789  last_update 41\n",
      "train: iter 157  trainloss 3.65450  validloss 4.29567±0.00000  bestvalidloss 4.10789  last_update 42\n",
      "train: iter 158  trainloss 3.71327  validloss 4.29338±0.00000  bestvalidloss 4.10789  last_update 43\n",
      "train: iter 159  trainloss 3.68821  validloss 4.39437±0.00000  bestvalidloss 4.10789  last_update 44\n",
      "train: iter 160  trainloss 3.69323  validloss 4.26520±0.00000  bestvalidloss 4.10789  last_update 45\n",
      "train: iter 161  trainloss 3.66015  validloss 4.37605±0.00000  bestvalidloss 4.10789  last_update 46\n",
      "train: iter 162  trainloss 3.61454  validloss 4.21628±0.00000  bestvalidloss 4.10789  last_update 47\n",
      "train: iter 163  trainloss 3.69422  validloss 4.21942±0.00000  bestvalidloss 4.10789  last_update 48\n",
      "train: iter 164  trainloss 3.68169  validloss 4.41868±0.00000  bestvalidloss 4.10789  last_update 49\n",
      "train: iter 165  trainloss 3.64548  validloss 4.27295±0.00000  bestvalidloss 4.10789  last_update 50\n",
      "train: iter 166  trainloss 3.67585  validloss 4.36953±0.00000  bestvalidloss 4.10789  last_update 51\n",
      "train: iter 167  trainloss 3.67345  validloss 4.31253±0.00000  bestvalidloss 4.10789  last_update 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 3.71498  validloss 4.35878±0.00000  bestvalidloss 4.10789  last_update 53\n",
      "train: iter 169  trainloss 3.69092  validloss 4.34727±0.00000  bestvalidloss 4.10789  last_update 54\n",
      "train: iter 170  trainloss 3.66461  validloss 4.29274±0.00000  bestvalidloss 4.10789  last_update 55\n",
      "train: iter 171  trainloss 3.69109  validloss 4.32520±0.00000  bestvalidloss 4.10789  last_update 56\n",
      "train: iter 172  trainloss 3.67333  validloss 4.31415±0.00000  bestvalidloss 4.10789  last_update 57\n",
      "train: iter 173  trainloss 3.69520  validloss 4.36454±0.00000  bestvalidloss 4.10789  last_update 58\n",
      "train: iter 174  trainloss 3.65707  validloss 4.28352±0.00000  bestvalidloss 4.10789  last_update 59\n",
      "train: iter 175  trainloss 3.62091  validloss 4.40976±0.00000  bestvalidloss 4.10789  last_update 60\n",
      "train: iter 176  trainloss 3.65769  validloss 4.29303±0.00000  bestvalidloss 4.10789  last_update 61\n",
      "train: iter 177  trainloss 3.67958  validloss 4.34913±0.00000  bestvalidloss 4.10789  last_update 62\n",
      "train: iter 178  trainloss 3.66511  validloss 4.29259±0.00000  bestvalidloss 4.10789  last_update 63\n",
      "train: iter 179  trainloss 3.64315  validloss 4.38606±0.00000  bestvalidloss 4.10789  last_update 64\n",
      "train: iter 180  trainloss 3.65230  validloss 4.31241±0.00000  bestvalidloss 4.10789  last_update 65\n",
      "train: iter 181  trainloss 3.64711  validloss 4.39623±0.00000  bestvalidloss 4.10789  last_update 66\n",
      "train: iter 182  trainloss 3.64767  validloss 4.27765±0.00000  bestvalidloss 4.10789  last_update 67\n",
      "train: iter 183  trainloss 3.66493  validloss 4.37117±0.00000  bestvalidloss 4.10789  last_update 68\n",
      "train: iter 184  trainloss 3.63819  validloss 4.40860±0.00000  bestvalidloss 4.10789  last_update 69\n",
      "train: iter 185  trainloss 3.67758  validloss 4.32571±0.00000  bestvalidloss 4.10789  last_update 70\n",
      "train: iter 186  trainloss 3.64673  validloss 4.36222±0.00000  bestvalidloss 4.10789  last_update 71\n",
      "train: iter 187  trainloss 3.62243  validloss 4.37357±0.00000  bestvalidloss 4.10789  last_update 72\n",
      "train: iter 188  trainloss 3.67488  validloss 4.31861±0.00000  bestvalidloss 4.10789  last_update 73\n",
      "train: iter 189  trainloss 3.64046  validloss 4.37024±0.00000  bestvalidloss 4.10789  last_update 74\n",
      "train: iter 190  trainloss 3.68411  validloss 4.38352±0.00000  bestvalidloss 4.10789  last_update 75\n",
      "train: iter 191  trainloss 3.67077  validloss 4.36134±0.00000  bestvalidloss 4.10789  last_update 76\n",
      "train: iter 192  trainloss 3.66308  validloss 4.48618±0.00000  bestvalidloss 4.10789  last_update 77\n",
      "train: iter 193  trainloss 3.61942  validloss 4.46559±0.00000  bestvalidloss 4.10789  last_update 78\n",
      "train: iter 194  trainloss 3.63919  validloss 4.38270±0.00000  bestvalidloss 4.10789  last_update 79\n",
      "train: iter 195  trainloss 3.62623  validloss 4.38802±0.00000  bestvalidloss 4.10789  last_update 80\n",
      "train: iter 196  trainloss 3.61538  validloss 4.35234±0.00000  bestvalidloss 4.10789  last_update 81\n",
      "train: iter 197  trainloss 3.62517  validloss 4.34386±0.00000  bestvalidloss 4.10789  last_update 82\n",
      "train: iter 198  trainloss 3.61818  validloss 4.36386±0.00000  bestvalidloss 4.10789  last_update 83\n",
      "train: iter 199  trainloss 3.64093  validloss 4.41181±0.00000  bestvalidloss 4.10789  last_update 84\n",
      "train: iter 200  trainloss 3.63512  validloss 4.42619±0.00000  bestvalidloss 4.10789  last_update 85\n",
      "train: iter 201  trainloss 3.63432  validloss 4.36409±0.00000  bestvalidloss 4.10789  last_update 86\n",
      "train: iter 202  trainloss 3.62204  validloss 4.47889±0.00000  bestvalidloss 4.10789  last_update 87\n",
      "train: iter 203  trainloss 3.63684  validloss 4.39918±0.00000  bestvalidloss 4.10789  last_update 88\n",
      "train: iter 204  trainloss 3.62985  validloss 4.37772±0.00000  bestvalidloss 4.10789  last_update 89\n",
      "train: iter 205  trainloss 3.65463  validloss 4.40291±0.00000  bestvalidloss 4.10789  last_update 90\n",
      "train: iter 206  trainloss 3.63248  validloss 4.32897±0.00000  bestvalidloss 4.10789  last_update 91\n",
      "train: iter 207  trainloss 3.60634  validloss 4.49400±0.00000  bestvalidloss 4.10789  last_update 92\n",
      "train: iter 208  trainloss 3.61985  validloss 4.35594±0.00000  bestvalidloss 4.10789  last_update 93\n",
      "train: iter 209  trainloss 3.63489  validloss 4.50558±0.00000  bestvalidloss 4.10789  last_update 94\n",
      "train: iter 210  trainloss 3.64306  validloss 4.36401±0.00000  bestvalidloss 4.10789  last_update 95\n",
      "train: iter 211  trainloss 3.64537  validloss 4.27014±0.00000  bestvalidloss 4.10789  last_update 96\n",
      "train: iter 212  trainloss 3.64882  validloss 4.40467±0.00000  bestvalidloss 4.10789  last_update 97\n",
      "train: iter 213  trainloss 3.62743  validloss 4.36211±0.00000  bestvalidloss 4.10789  last_update 98\n",
      "train: iter 214  trainloss 3.62773  validloss 4.41110±0.00000  bestvalidloss 4.10789  last_update 99\n",
      "train: iter 215  trainloss 3.61723  validloss 4.43783±0.00000  bestvalidloss 4.10789  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-9.0191)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(3.3334)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6626457511554824\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfff682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c9ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e0943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198825bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f45ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33660c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f08a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d77961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129676a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7f114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c970e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
