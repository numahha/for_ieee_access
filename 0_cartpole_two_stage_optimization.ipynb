{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(10846.4824)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 20920.99403  validloss 1140951.52238±0.00000  bestvalidloss 1140951.52238  last_update 0\n",
      "train: iter 1  trainloss 2552.76593  validloss 50381.58835±0.00000  bestvalidloss 50381.58835  last_update 0\n",
      "train: iter 2  trainloss 1134.61370  validloss 6784.05489±0.00000  bestvalidloss 6784.05489  last_update 0\n",
      "train: iter 3  trainloss 947.76243  validloss 2629.29753±0.00000  bestvalidloss 2629.29753  last_update 0\n",
      "train: iter 4  trainloss 896.56624  validloss 1633.27301±0.00000  bestvalidloss 1633.27301  last_update 0\n",
      "train: iter 5  trainloss 842.98642  validloss 1749.65312±0.00000  bestvalidloss 1633.27301  last_update 1\n",
      "train: iter 6  trainloss 749.24182  validloss 1290.32150±0.00000  bestvalidloss 1290.32150  last_update 0\n",
      "train: iter 7  trainloss 710.29848  validloss 1398.07934±0.00000  bestvalidloss 1290.32150  last_update 1\n",
      "train: iter 8  trainloss 792.40910  validloss 1478.71331±0.00000  bestvalidloss 1290.32150  last_update 2\n",
      "train: iter 9  trainloss 696.82575  validloss 2797.82186±0.00000  bestvalidloss 1290.32150  last_update 3\n",
      "train: iter 10  trainloss 755.26345  validloss 1436.12073±0.00000  bestvalidloss 1290.32150  last_update 4\n",
      "train: iter 11  trainloss 740.10355  validloss 1896.72051±0.00000  bestvalidloss 1290.32150  last_update 5\n",
      "train: iter 12  trainloss 682.09141  validloss 1493.03099±0.00000  bestvalidloss 1290.32150  last_update 6\n",
      "train: iter 13  trainloss 600.12529  validloss 1028.36788±0.00000  bestvalidloss 1028.36788  last_update 0\n",
      "train: iter 14  trainloss 518.45709  validloss 1338.16369±0.00000  bestvalidloss 1028.36788  last_update 1\n",
      "train: iter 15  trainloss 515.39357  validloss 2150.94414±0.00000  bestvalidloss 1028.36788  last_update 2\n",
      "train: iter 16  trainloss 604.48447  validloss 1330.24314±0.00000  bestvalidloss 1028.36788  last_update 3\n",
      "train: iter 17  trainloss 543.50486  validloss 1237.59198±0.00000  bestvalidloss 1028.36788  last_update 4\n",
      "train: iter 18  trainloss 685.21411  validloss 3998.12589±0.00000  bestvalidloss 1028.36788  last_update 5\n",
      "train: iter 19  trainloss 598.75133  validloss 1527.91193±0.00000  bestvalidloss 1028.36788  last_update 6\n",
      "train: iter 20  trainloss 488.87637  validloss 1105.63070±0.00000  bestvalidloss 1028.36788  last_update 7\n",
      "train: iter 21  trainloss 360.36641  validloss 927.69501±0.00000  bestvalidloss 927.69501  last_update 0\n",
      "train: iter 22  trainloss 364.13158  validloss 1311.33066±0.00000  bestvalidloss 927.69501  last_update 1\n",
      "train: iter 23  trainloss 284.76205  validloss 1811.25600±0.00000  bestvalidloss 927.69501  last_update 2\n",
      "train: iter 24  trainloss 321.82550  validloss 1038.99120±0.00000  bestvalidloss 927.69501  last_update 3\n",
      "train: iter 25  trainloss 269.70688  validloss 1559.19775±0.00000  bestvalidloss 927.69501  last_update 4\n",
      "train: iter 26  trainloss 306.47330  validloss 1578.14412±0.00000  bestvalidloss 927.69501  last_update 5\n",
      "train: iter 27  trainloss 313.32795  validloss 1445.99113±0.00000  bestvalidloss 927.69501  last_update 6\n",
      "train: iter 28  trainloss 291.77084  validloss 1162.89583±0.00000  bestvalidloss 927.69501  last_update 7\n",
      "train: iter 29  trainloss 322.11308  validloss 1051.74321±0.00000  bestvalidloss 927.69501  last_update 8\n",
      "train: iter 30  trainloss 164.67958  validloss 915.99396±0.00000  bestvalidloss 915.99396  last_update 0\n",
      "train: iter 31  trainloss 223.11114  validloss 913.96802±0.00000  bestvalidloss 913.96802  last_update 0\n",
      "train: iter 32  trainloss 147.97437  validloss 1266.76947±0.00000  bestvalidloss 913.96802  last_update 1\n",
      "train: iter 33  trainloss 202.95449  validloss 999.21515±0.00000  bestvalidloss 913.96802  last_update 2\n",
      "train: iter 34  trainloss 117.33931  validloss 1636.78286±0.00000  bestvalidloss 913.96802  last_update 3\n",
      "train: iter 35  trainloss 76.39500  validloss 1068.95411±0.00000  bestvalidloss 913.96802  last_update 4\n",
      "train: iter 36  trainloss 41.60433  validloss 706.16645±0.00000  bestvalidloss 706.16645  last_update 0\n",
      "train: iter 37  trainloss 45.03722  validloss 647.62898±0.00000  bestvalidloss 647.62898  last_update 0\n",
      "train: iter 38  trainloss -5.07803  validloss 630.97555±0.00000  bestvalidloss 630.97555  last_update 0\n",
      "train: iter 39  trainloss 108.38122  validloss 694.55233±0.00000  bestvalidloss 630.97555  last_update 1\n",
      "train: iter 40  trainloss -59.40393  validloss 471.64514±0.00000  bestvalidloss 471.64514  last_update 0\n",
      "train: iter 41  trainloss -33.92165  validloss 605.03637±0.00000  bestvalidloss 471.64514  last_update 1\n",
      "train: iter 42  trainloss -78.75897  validloss 651.91493±0.00000  bestvalidloss 471.64514  last_update 2\n",
      "train: iter 43  trainloss -52.29708  validloss 396.32478±0.00000  bestvalidloss 396.32478  last_update 0\n",
      "train: iter 44  trainloss -114.40949  validloss 393.54289±0.00000  bestvalidloss 393.54289  last_update 0\n",
      "train: iter 45  trainloss -35.15903  validloss 236.95239±0.00000  bestvalidloss 236.95239  last_update 0\n",
      "train: iter 46  trainloss -98.71871  validloss 667.33883±0.00000  bestvalidloss 236.95239  last_update 1\n",
      "train: iter 47  trainloss -159.34511  validloss 241.71601±0.00000  bestvalidloss 236.95239  last_update 2\n",
      "train: iter 48  trainloss -199.63006  validloss 276.65069±0.00000  bestvalidloss 236.95239  last_update 3\n",
      "train: iter 49  trainloss -215.91704  validloss 360.98527±0.00000  bestvalidloss 236.95239  last_update 4\n",
      "train: iter 50  trainloss -214.47328  validloss 234.40612±0.00000  bestvalidloss 234.40612  last_update 0\n",
      "train: iter 51  trainloss -177.97828  validloss 181.62059±0.00000  bestvalidloss 181.62059  last_update 0\n",
      "train: iter 52  trainloss -172.41060  validloss 114.59336±0.00000  bestvalidloss 114.59336  last_update 0\n",
      "train: iter 53  trainloss -99.17200  validloss 675.06397±0.00000  bestvalidloss 114.59336  last_update 1\n",
      "train: iter 54  trainloss -182.11761  validloss 214.63872±0.00000  bestvalidloss 114.59336  last_update 2\n",
      "train: iter 55  trainloss -236.53934  validloss 58.88283±0.00000  bestvalidloss 58.88283  last_update 0\n",
      "train: iter 56  trainloss -231.33456  validloss 204.76416±0.00000  bestvalidloss 58.88283  last_update 1\n",
      "train: iter 57  trainloss -286.38633  validloss 145.16738±0.00000  bestvalidloss 58.88283  last_update 2\n",
      "train: iter 58  trainloss -341.95350  validloss 162.12047±0.00000  bestvalidloss 58.88283  last_update 3\n",
      "train: iter 59  trainloss -360.01721  validloss 136.59894±0.00000  bestvalidloss 58.88283  last_update 4\n",
      "train: iter 60  trainloss -302.93041  validloss 62.83230±0.00000  bestvalidloss 58.88283  last_update 5\n",
      "train: iter 61  trainloss -387.28354  validloss 18.88434±0.00000  bestvalidloss 18.88434  last_update 0\n",
      "train: iter 62  trainloss -415.63309  validloss 133.87466±0.00000  bestvalidloss 18.88434  last_update 1\n",
      "train: iter 63  trainloss -404.57922  validloss 117.26064±0.00000  bestvalidloss 18.88434  last_update 2\n",
      "train: iter 64  trainloss -452.15990  validloss -81.76768±0.00000  bestvalidloss -81.76768  last_update 0\n",
      "train: iter 65  trainloss -329.28542  validloss 206.33570±0.00000  bestvalidloss -81.76768  last_update 1\n",
      "train: iter 66  trainloss -340.43141  validloss 124.63353±0.00000  bestvalidloss -81.76768  last_update 2\n",
      "train: iter 67  trainloss -466.62707  validloss -95.68462±0.00000  bestvalidloss -95.68462  last_update 0\n",
      "train: iter 68  trainloss -545.38705  validloss -109.77121±0.00000  bestvalidloss -109.77121  last_update 0\n",
      "train: iter 69  trainloss -419.37510  validloss -137.05850±0.00000  bestvalidloss -137.05850  last_update 0\n",
      "train: iter 70  trainloss -451.85669  validloss 177.21549±0.00000  bestvalidloss -137.05850  last_update 1\n",
      "train: iter 71  trainloss -529.36212  validloss -126.99312±0.00000  bestvalidloss -137.05850  last_update 2\n",
      "train: iter 72  trainloss -379.20655  validloss -203.83507±0.00000  bestvalidloss -203.83507  last_update 0\n",
      "train: iter 73  trainloss -578.17877  validloss -256.57645±0.00000  bestvalidloss -256.57645  last_update 0\n",
      "train: iter 74  trainloss -563.96616  validloss -249.25048±0.00000  bestvalidloss -256.57645  last_update 1\n",
      "train: iter 75  trainloss -449.23565  validloss -29.33152±0.00000  bestvalidloss -256.57645  last_update 2\n",
      "train: iter 76  trainloss -536.13091  validloss -62.29179±0.00000  bestvalidloss -256.57645  last_update 3\n",
      "train: iter 77  trainloss -594.85227  validloss -290.46818±0.00000  bestvalidloss -290.46818  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 78  trainloss -541.17441  validloss 770.81138±0.00000  bestvalidloss -290.46818  last_update 1\n",
      "train: iter 79  trainloss -568.62484  validloss -216.49109±0.00000  bestvalidloss -290.46818  last_update 2\n",
      "train: iter 80  trainloss -608.42260  validloss -176.38120±0.00000  bestvalidloss -290.46818  last_update 3\n",
      "train: iter 81  trainloss -549.44566  validloss -101.78729±0.00000  bestvalidloss -290.46818  last_update 4\n",
      "train: iter 82  trainloss -626.69697  validloss -272.91722±0.00000  bestvalidloss -290.46818  last_update 5\n",
      "train: iter 83  trainloss -646.17617  validloss -314.20075±0.00000  bestvalidloss -314.20075  last_update 0\n",
      "train: iter 84  trainloss -592.34353  validloss -215.71769±0.00000  bestvalidloss -314.20075  last_update 1\n",
      "train: iter 85  trainloss -499.74436  validloss -240.10994±0.00000  bestvalidloss -314.20075  last_update 2\n",
      "train: iter 86  trainloss -574.83226  validloss -342.32661±0.00000  bestvalidloss -342.32661  last_update 0\n",
      "train: iter 87  trainloss -677.03531  validloss -457.93873±0.00000  bestvalidloss -457.93873  last_update 0\n",
      "train: iter 88  trainloss -661.12763  validloss -526.65033±0.00000  bestvalidloss -526.65033  last_update 0\n",
      "train: iter 89  trainloss -657.28790  validloss -373.60239±0.00000  bestvalidloss -526.65033  last_update 1\n",
      "train: iter 90  trainloss -508.25749  validloss -273.35662±0.00000  bestvalidloss -526.65033  last_update 2\n",
      "train: iter 91  trainloss -714.70113  validloss -371.50371±0.00000  bestvalidloss -526.65033  last_update 3\n",
      "train: iter 92  trainloss -602.63851  validloss -435.98729±0.00000  bestvalidloss -526.65033  last_update 4\n",
      "train: iter 93  trainloss -690.51686  validloss -319.26508±0.00000  bestvalidloss -526.65033  last_update 5\n",
      "train: iter 94  trainloss -701.27267  validloss -531.57009±0.00000  bestvalidloss -531.57009  last_update 0\n",
      "train: iter 95  trainloss -722.83051  validloss -511.38027±0.00000  bestvalidloss -531.57009  last_update 1\n",
      "train: iter 96  trainloss -579.97647  validloss -268.75400±0.00000  bestvalidloss -531.57009  last_update 2\n",
      "train: iter 97  trainloss -634.76247  validloss 184.10027±0.00000  bestvalidloss -531.57009  last_update 3\n",
      "train: iter 98  trainloss -757.17575  validloss -306.24414±0.00000  bestvalidloss -531.57009  last_update 4\n",
      "train: iter 99  trainloss -756.76200  validloss -636.47410±0.00000  bestvalidloss -636.47410  last_update 0\n",
      "train: iter 100  trainloss -565.87947  validloss -230.37256±0.00000  bestvalidloss -636.47410  last_update 1\n",
      "train: iter 101  trainloss -692.50673  validloss -365.85359±0.00000  bestvalidloss -636.47410  last_update 2\n",
      "train: iter 102  trainloss -746.79388  validloss -538.94504±0.00000  bestvalidloss -636.47410  last_update 3\n",
      "train: iter 103  trainloss -771.96672  validloss -498.40013±0.00000  bestvalidloss -636.47410  last_update 4\n",
      "train: iter 104  trainloss -761.67150  validloss -488.23725±0.00000  bestvalidloss -636.47410  last_update 5\n",
      "train: iter 105  trainloss -734.58201  validloss -559.32514±0.00000  bestvalidloss -636.47410  last_update 6\n",
      "train: iter 106  trainloss -588.12503  validloss -592.25318±0.00000  bestvalidloss -636.47410  last_update 7\n",
      "train: iter 107  trainloss -387.34520  validloss -239.97798±0.00000  bestvalidloss -636.47410  last_update 8\n",
      "train: iter 108  trainloss -653.84560  validloss -262.57600±0.00000  bestvalidloss -636.47410  last_update 9\n",
      "train: iter 109  trainloss -735.13843  validloss -434.34744±0.00000  bestvalidloss -636.47410  last_update 10\n",
      "train: iter 110  trainloss -777.34217  validloss -587.53558±0.00000  bestvalidloss -636.47410  last_update 11\n",
      "train: iter 111  trainloss -757.71105  validloss -544.38853±0.00000  bestvalidloss -636.47410  last_update 12\n",
      "train: iter 112  trainloss -771.56998  validloss -352.48427±0.00000  bestvalidloss -636.47410  last_update 13\n",
      "train: iter 113  trainloss -825.51093  validloss -586.57881±0.00000  bestvalidloss -636.47410  last_update 14\n",
      "train: iter 114  trainloss -822.90100  validloss -570.10262±0.00000  bestvalidloss -636.47410  last_update 15\n",
      "train: iter 115  trainloss -820.41364  validloss -741.41089±0.00000  bestvalidloss -741.41089  last_update 0\n",
      "train: iter 116  trainloss -829.08775  validloss -474.06856±0.00000  bestvalidloss -741.41089  last_update 1\n",
      "train: iter 117  trainloss -645.12095  validloss -563.26058±0.00000  bestvalidloss -741.41089  last_update 2\n",
      "train: iter 118  trainloss -756.41576  validloss -760.18783±0.00000  bestvalidloss -760.18783  last_update 0\n",
      "train: iter 119  trainloss -831.27196  validloss -595.87771±0.00000  bestvalidloss -760.18783  last_update 1\n",
      "train: iter 120  trainloss -879.31834  validloss -515.66711±0.00000  bestvalidloss -760.18783  last_update 2\n",
      "train: iter 121  trainloss -804.52672  validloss -695.86477±0.00000  bestvalidloss -760.18783  last_update 3\n",
      "train: iter 122  trainloss -753.33193  validloss -533.56543±0.00000  bestvalidloss -760.18783  last_update 4\n",
      "train: iter 123  trainloss -767.85516  validloss -760.25555±0.00000  bestvalidloss -760.25555  last_update 0\n",
      "train: iter 124  trainloss -832.17265  validloss -549.30078±0.00000  bestvalidloss -760.25555  last_update 1\n",
      "train: iter 125  trainloss -787.88140  validloss -637.35784±0.00000  bestvalidloss -760.25555  last_update 2\n",
      "train: iter 126  trainloss -771.42322  validloss -672.39806±0.00000  bestvalidloss -760.25555  last_update 3\n",
      "train: iter 127  trainloss -889.05210  validloss -622.98826±0.00000  bestvalidloss -760.25555  last_update 4\n",
      "train: iter 128  trainloss -856.80437  validloss -648.74489±0.00000  bestvalidloss -760.25555  last_update 5\n",
      "train: iter 129  trainloss -887.26866  validloss -776.71711±0.00000  bestvalidloss -776.71711  last_update 0\n",
      "train: iter 130  trainloss -884.63572  validloss -763.54068±0.00000  bestvalidloss -776.71711  last_update 1\n",
      "train: iter 131  trainloss -763.88480  validloss -728.07441±0.00000  bestvalidloss -776.71711  last_update 2\n",
      "train: iter 132  trainloss -790.95707  validloss -551.65987±0.00000  bestvalidloss -776.71711  last_update 3\n",
      "train: iter 133  trainloss -717.16356  validloss -751.61249±0.00000  bestvalidloss -776.71711  last_update 4\n",
      "train: iter 134  trainloss -875.16076  validloss -636.36970±0.00000  bestvalidloss -776.71711  last_update 5\n",
      "train: iter 135  trainloss -842.16738  validloss -719.18037±0.00000  bestvalidloss -776.71711  last_update 6\n",
      "train: iter 136  trainloss -863.61987  validloss -741.54199±0.00000  bestvalidloss -776.71711  last_update 7\n",
      "train: iter 137  trainloss -863.60995  validloss -756.82280±0.00000  bestvalidloss -776.71711  last_update 8\n",
      "train: iter 138  trainloss -925.11627  validloss -863.62124±0.00000  bestvalidloss -863.62124  last_update 0\n",
      "train: iter 139  trainloss -766.80966  validloss -644.37183±0.00000  bestvalidloss -863.62124  last_update 1\n",
      "train: iter 140  trainloss -937.38341  validloss -635.94290±0.00000  bestvalidloss -863.62124  last_update 2\n",
      "train: iter 141  trainloss -842.81708  validloss -633.61304±0.00000  bestvalidloss -863.62124  last_update 3\n",
      "train: iter 142  trainloss -859.51506  validloss -513.39762±0.00000  bestvalidloss -863.62124  last_update 4\n",
      "train: iter 143  trainloss -816.82594  validloss -555.45066±0.00000  bestvalidloss -863.62124  last_update 5\n",
      "train: iter 144  trainloss -616.34603  validloss -271.67650±0.00000  bestvalidloss -863.62124  last_update 6\n",
      "train: iter 145  trainloss -836.73195  validloss -389.68419±0.00000  bestvalidloss -863.62124  last_update 7\n",
      "train: iter 146  trainloss -927.32650  validloss -747.08534±0.00000  bestvalidloss -863.62124  last_update 8\n",
      "train: iter 147  trainloss -777.62245  validloss -902.27105±0.00000  bestvalidloss -902.27105  last_update 0\n",
      "train: iter 148  trainloss -884.00031  validloss -509.28180±0.00000  bestvalidloss -902.27105  last_update 1\n",
      "train: iter 149  trainloss -976.01862  validloss -745.99238±0.00000  bestvalidloss -902.27105  last_update 2\n",
      "train: iter 150  trainloss -799.22613  validloss -828.39849±0.00000  bestvalidloss -902.27105  last_update 3\n",
      "train: iter 151  trainloss -923.52994  validloss -684.23668±0.00000  bestvalidloss -902.27105  last_update 4\n",
      "train: iter 152  trainloss -887.17861  validloss -503.03488±0.00000  bestvalidloss -902.27105  last_update 5\n",
      "train: iter 153  trainloss -955.16814  validloss -852.79329±0.00000  bestvalidloss -902.27105  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 154  trainloss -908.97945  validloss -685.73828±0.00000  bestvalidloss -902.27105  last_update 7\n",
      "train: iter 155  trainloss -810.36590  validloss -652.18297±0.00000  bestvalidloss -902.27105  last_update 8\n",
      "train: iter 156  trainloss -746.99555  validloss -820.04938±0.00000  bestvalidloss -902.27105  last_update 9\n",
      "train: iter 157  trainloss -887.56834  validloss -275.36502±0.00000  bestvalidloss -902.27105  last_update 10\n",
      "train: iter 158  trainloss -901.67549  validloss -843.62966±0.00000  bestvalidloss -902.27105  last_update 11\n",
      "train: iter 159  trainloss -974.84525  validloss -760.37063±0.00000  bestvalidloss -902.27105  last_update 12\n",
      "train: iter 160  trainloss -901.85720  validloss -677.60833±0.00000  bestvalidloss -902.27105  last_update 13\n",
      "train: iter 161  trainloss -749.93221  validloss -736.27115±0.00000  bestvalidloss -902.27105  last_update 14\n",
      "train: iter 162  trainloss -806.78932  validloss -556.60537±0.00000  bestvalidloss -902.27105  last_update 15\n",
      "train: iter 163  trainloss -850.50318  validloss -968.94332±0.00000  bestvalidloss -968.94332  last_update 0\n",
      "train: iter 164  trainloss -1021.27665  validloss -837.37195±0.00000  bestvalidloss -968.94332  last_update 1\n",
      "train: iter 165  trainloss -775.13401  validloss -915.83139±0.00000  bestvalidloss -968.94332  last_update 2\n",
      "train: iter 166  trainloss -712.90278  validloss -769.91418±0.00000  bestvalidloss -968.94332  last_update 3\n",
      "train: iter 167  trainloss -910.60454  validloss -365.36509±0.00000  bestvalidloss -968.94332  last_update 4\n",
      "train: iter 168  trainloss -930.83830  validloss -730.68249±0.00000  bestvalidloss -968.94332  last_update 5\n",
      "train: iter 169  trainloss -873.52539  validloss -868.77086±0.00000  bestvalidloss -968.94332  last_update 6\n",
      "train: iter 170  trainloss -902.22115  validloss -815.00218±0.00000  bestvalidloss -968.94332  last_update 7\n",
      "train: iter 171  trainloss -1034.46270  validloss -856.16972±0.00000  bestvalidloss -968.94332  last_update 8\n",
      "train: iter 172  trainloss -969.70178  validloss -685.84483±0.00000  bestvalidloss -968.94332  last_update 9\n",
      "train: iter 173  trainloss -926.48800  validloss -888.47850±0.00000  bestvalidloss -968.94332  last_update 10\n",
      "train: iter 174  trainloss -1000.18160  validloss -934.88671±0.00000  bestvalidloss -968.94332  last_update 11\n",
      "train: iter 175  trainloss -1065.65318  validloss -875.47600±0.00000  bestvalidloss -968.94332  last_update 12\n",
      "train: iter 176  trainloss -994.43701  validloss -1044.24541±0.00000  bestvalidloss -1044.24541  last_update 0\n",
      "train: iter 177  trainloss -1126.38999  validloss -977.48666±0.00000  bestvalidloss -1044.24541  last_update 1\n",
      "train: iter 178  trainloss -790.71876  validloss -947.35418±0.00000  bestvalidloss -1044.24541  last_update 2\n",
      "train: iter 179  trainloss -851.44824  validloss -623.63409±0.00000  bestvalidloss -1044.24541  last_update 3\n",
      "train: iter 180  trainloss -1025.82338  validloss -793.49841±0.00000  bestvalidloss -1044.24541  last_update 4\n",
      "train: iter 181  trainloss -973.93376  validloss -932.72936±0.00000  bestvalidloss -1044.24541  last_update 5\n",
      "train: iter 182  trainloss -1021.64724  validloss -953.89820±0.00000  bestvalidloss -1044.24541  last_update 6\n",
      "train: iter 183  trainloss -1045.66023  validloss -777.29358±0.00000  bestvalidloss -1044.24541  last_update 7\n",
      "train: iter 184  trainloss -815.23659  validloss -693.00013±0.00000  bestvalidloss -1044.24541  last_update 8\n",
      "train: iter 185  trainloss -1028.87761  validloss -809.51173±0.00000  bestvalidloss -1044.24541  last_update 9\n",
      "train: iter 186  trainloss -835.45337  validloss -896.46571±0.00000  bestvalidloss -1044.24541  last_update 10\n",
      "train: iter 187  trainloss -716.38380  validloss -589.14086±0.00000  bestvalidloss -1044.24541  last_update 11\n",
      "train: iter 188  trainloss -974.10076  validloss -576.82770±0.00000  bestvalidloss -1044.24541  last_update 12\n",
      "train: iter 189  trainloss -1135.73946  validloss -1022.70363±0.00000  bestvalidloss -1044.24541  last_update 13\n",
      "train: iter 190  trainloss -986.97562  validloss -1022.31955±0.00000  bestvalidloss -1044.24541  last_update 14\n",
      "train: iter 191  trainloss -1067.69322  validloss -1013.06624±0.00000  bestvalidloss -1044.24541  last_update 15\n",
      "train: iter 192  trainloss -1139.60690  validloss -961.97462±0.00000  bestvalidloss -1044.24541  last_update 16\n",
      "train: iter 193  trainloss -1005.88412  validloss -1047.58997±0.00000  bestvalidloss -1047.58997  last_update 0\n",
      "train: iter 194  trainloss -1020.09434  validloss -877.24081±0.00000  bestvalidloss -1047.58997  last_update 1\n",
      "train: iter 195  trainloss -1091.49568  validloss -989.55083±0.00000  bestvalidloss -1047.58997  last_update 2\n",
      "train: iter 196  trainloss -1120.81016  validloss -1059.63239±0.00000  bestvalidloss -1059.63239  last_update 0\n",
      "train: iter 197  trainloss -1026.04777  validloss -1043.21555±0.00000  bestvalidloss -1059.63239  last_update 1\n",
      "train: iter 198  trainloss -846.22420  validloss -793.44407±0.00000  bestvalidloss -1059.63239  last_update 2\n",
      "train: iter 199  trainloss -1025.09835  validloss -557.28206±0.00000  bestvalidloss -1059.63239  last_update 3\n",
      "train: iter 200  trainloss -1089.90425  validloss -1017.42684±0.00000  bestvalidloss -1059.63239  last_update 4\n",
      "train: iter 201  trainloss -874.22638  validloss -139.11869±0.00000  bestvalidloss -1059.63239  last_update 5\n",
      "train: iter 202  trainloss -1085.36960  validloss -854.66418±0.00000  bestvalidloss -1059.63239  last_update 6\n",
      "train: iter 203  trainloss -939.84381  validloss -1050.93470±0.00000  bestvalidloss -1059.63239  last_update 7\n",
      "train: iter 204  trainloss -1106.46491  validloss -785.31575±0.00000  bestvalidloss -1059.63239  last_update 8\n",
      "train: iter 205  trainloss -1123.27382  validloss -1087.87004±0.00000  bestvalidloss -1087.87004  last_update 0\n",
      "train: iter 206  trainloss -908.73961  validloss -1061.91794±0.00000  bestvalidloss -1087.87004  last_update 1\n",
      "train: iter 207  trainloss -870.74278  validloss -983.09245±0.00000  bestvalidloss -1087.87004  last_update 2\n",
      "train: iter 208  trainloss -1039.71474  validloss -873.86481±0.00000  bestvalidloss -1087.87004  last_update 3\n",
      "train: iter 209  trainloss -1080.65690  validloss -758.44593±0.00000  bestvalidloss -1087.87004  last_update 4\n",
      "train: iter 210  trainloss -1113.01794  validloss -1034.23359±0.00000  bestvalidloss -1087.87004  last_update 5\n",
      "train: iter 211  trainloss -1075.29002  validloss -1127.50311±0.00000  bestvalidloss -1127.50311  last_update 0\n",
      "train: iter 212  trainloss -1096.15814  validloss -1073.17224±0.00000  bestvalidloss -1127.50311  last_update 1\n",
      "train: iter 213  trainloss -1180.70808  validloss -1006.53813±0.00000  bestvalidloss -1127.50311  last_update 2\n",
      "train: iter 214  trainloss -1040.69786  validloss -1085.51198±0.00000  bestvalidloss -1127.50311  last_update 3\n",
      "train: iter 215  trainloss -1149.21244  validloss -862.65166±0.00000  bestvalidloss -1127.50311  last_update 4\n",
      "train: iter 216  trainloss -893.79918  validloss -948.88621±0.00000  bestvalidloss -1127.50311  last_update 5\n",
      "train: iter 217  trainloss -1069.53222  validloss -924.30701±0.00000  bestvalidloss -1127.50311  last_update 6\n",
      "train: iter 218  trainloss -1169.58998  validloss -1107.09980±0.00000  bestvalidloss -1127.50311  last_update 7\n",
      "train: iter 219  trainloss -1137.90696  validloss -1047.73968±0.00000  bestvalidloss -1127.50311  last_update 8\n",
      "train: iter 220  trainloss -1103.08722  validloss -663.84663±0.00000  bestvalidloss -1127.50311  last_update 9\n",
      "train: iter 221  trainloss -1159.83543  validloss -1120.37435±0.00000  bestvalidloss -1127.50311  last_update 10\n",
      "train: iter 222  trainloss -1098.89881  validloss -1004.95969±0.00000  bestvalidloss -1127.50311  last_update 11\n",
      "train: iter 223  trainloss -1109.52736  validloss -867.79499±0.00000  bestvalidloss -1127.50311  last_update 12\n",
      "train: iter 224  trainloss -1160.82901  validloss -825.02871±0.00000  bestvalidloss -1127.50311  last_update 13\n",
      "train: iter 225  trainloss -1153.06133  validloss -1121.91866±0.00000  bestvalidloss -1127.50311  last_update 14\n",
      "train: iter 226  trainloss -1044.30195  validloss -697.80099±0.00000  bestvalidloss -1127.50311  last_update 15\n",
      "train: iter 227  trainloss -1063.30618  validloss -1021.74782±0.00000  bestvalidloss -1127.50311  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1091.36606  validloss -991.59268±0.00000  bestvalidloss -1127.50311  last_update 17\n",
      "train: iter 229  trainloss -740.17296  validloss -1081.02162±0.00000  bestvalidloss -1127.50311  last_update 18\n",
      "train: iter 230  trainloss -1004.99409  validloss -634.93265±0.00000  bestvalidloss -1127.50311  last_update 19\n",
      "train: iter 231  trainloss -1151.30928  validloss -1084.11474±0.00000  bestvalidloss -1127.50311  last_update 20\n",
      "train: iter 232  trainloss -1051.12450  validloss -917.79513±0.00000  bestvalidloss -1127.50311  last_update 21\n",
      "train: iter 233  trainloss -1191.26550  validloss -869.42864±0.00000  bestvalidloss -1127.50311  last_update 22\n",
      "train: iter 234  trainloss -1174.15236  validloss -966.05131±0.00000  bestvalidloss -1127.50311  last_update 23\n",
      "train: iter 235  trainloss -991.88390  validloss -1126.89884±0.00000  bestvalidloss -1127.50311  last_update 24\n",
      "train: iter 236  trainloss -1073.66301  validloss -937.12241±0.00000  bestvalidloss -1127.50311  last_update 25\n",
      "train: iter 237  trainloss -1128.39771  validloss -768.63889±0.00000  bestvalidloss -1127.50311  last_update 26\n",
      "train: iter 238  trainloss -1235.30782  validloss -1153.00827±0.00000  bestvalidloss -1153.00827  last_update 0\n",
      "train: iter 239  trainloss -999.08885  validloss -939.96891±0.00000  bestvalidloss -1153.00827  last_update 1\n",
      "train: iter 240  trainloss -1138.82473  validloss -1033.13191±0.00000  bestvalidloss -1153.00827  last_update 2\n",
      "train: iter 241  trainloss -1118.58542  validloss -1120.47328±0.00000  bestvalidloss -1153.00827  last_update 3\n",
      "train: iter 242  trainloss -1142.90013  validloss -990.29656±0.00000  bestvalidloss -1153.00827  last_update 4\n",
      "train: iter 243  trainloss -1061.48200  validloss -1089.69300±0.00000  bestvalidloss -1153.00827  last_update 5\n",
      "train: iter 244  trainloss -1105.17434  validloss -1210.23701±0.00000  bestvalidloss -1210.23701  last_update 0\n",
      "train: iter 245  trainloss -1215.67814  validloss -1056.23649±0.00000  bestvalidloss -1210.23701  last_update 1\n",
      "train: iter 246  trainloss -1128.70136  validloss -1085.38362±0.00000  bestvalidloss -1210.23701  last_update 2\n",
      "train: iter 247  trainloss -939.87992  validloss -889.14392±0.00000  bestvalidloss -1210.23701  last_update 3\n",
      "train: iter 248  trainloss -1214.62331  validloss -999.79125±0.00000  bestvalidloss -1210.23701  last_update 4\n",
      "train: iter 249  trainloss -1241.74749  validloss -1127.47474±0.00000  bestvalidloss -1210.23701  last_update 5\n",
      "train: iter 250  trainloss -1086.99033  validloss -1122.08930±0.00000  bestvalidloss -1210.23701  last_update 6\n",
      "train: iter 251  trainloss -1189.63500  validloss -1080.27729±0.00000  bestvalidloss -1210.23701  last_update 7\n",
      "train: iter 252  trainloss -1144.66602  validloss -1084.45807±0.00000  bestvalidloss -1210.23701  last_update 8\n",
      "train: iter 253  trainloss -1090.04069  validloss -1062.75555±0.00000  bestvalidloss -1210.23701  last_update 9\n",
      "train: iter 254  trainloss -1091.53516  validloss -790.26625±0.00000  bestvalidloss -1210.23701  last_update 10\n",
      "train: iter 255  trainloss -1255.95841  validloss -1136.49344±0.00000  bestvalidloss -1210.23701  last_update 11\n",
      "train: iter 256  trainloss -1119.97533  validloss -1196.75089±0.00000  bestvalidloss -1210.23701  last_update 12\n",
      "train: iter 257  trainloss -1153.68039  validloss -1088.27933±0.00000  bestvalidloss -1210.23701  last_update 13\n",
      "train: iter 258  trainloss -1227.83958  validloss -1109.22799±0.00000  bestvalidloss -1210.23701  last_update 14\n",
      "train: iter 259  trainloss -1240.82762  validloss -1166.14203±0.00000  bestvalidloss -1210.23701  last_update 15\n",
      "train: iter 260  trainloss -1178.00464  validloss -1118.95678±0.00000  bestvalidloss -1210.23701  last_update 16\n",
      "train: iter 261  trainloss -1116.96077  validloss -1189.45546±0.00000  bestvalidloss -1210.23701  last_update 17\n",
      "train: iter 262  trainloss -1076.88232  validloss -1013.30226±0.00000  bestvalidloss -1210.23701  last_update 18\n",
      "train: iter 263  trainloss -1042.80555  validloss -809.47807±0.00000  bestvalidloss -1210.23701  last_update 19\n",
      "train: iter 264  trainloss -1257.68370  validloss -1059.19307±0.00000  bestvalidloss -1210.23701  last_update 20\n",
      "train: iter 265  trainloss -1221.58919  validloss -1245.05650±0.00000  bestvalidloss -1245.05650  last_update 0\n",
      "train: iter 266  trainloss -1176.34686  validloss -610.96477±0.00000  bestvalidloss -1245.05650  last_update 1\n",
      "train: iter 267  trainloss -1314.38689  validloss -1193.73546±0.00000  bestvalidloss -1245.05650  last_update 2\n",
      "train: iter 268  trainloss -900.52726  validloss -893.36714±0.00000  bestvalidloss -1245.05650  last_update 3\n",
      "train: iter 269  trainloss -1203.41644  validloss -1188.51925±0.00000  bestvalidloss -1245.05650  last_update 4\n",
      "train: iter 270  trainloss -1033.70990  validloss -1168.64186±0.00000  bestvalidloss -1245.05650  last_update 5\n",
      "train: iter 271  trainloss -1231.33306  validloss -729.10073±0.00000  bestvalidloss -1245.05650  last_update 6\n",
      "train: iter 272  trainloss -1242.85708  validloss -1196.14958±0.00000  bestvalidloss -1245.05650  last_update 7\n",
      "train: iter 273  trainloss -1215.99300  validloss -983.24878±0.00000  bestvalidloss -1245.05650  last_update 8\n",
      "train: iter 274  trainloss -1280.48042  validloss -1094.66790±0.00000  bestvalidloss -1245.05650  last_update 9\n",
      "train: iter 275  trainloss -952.59271  validloss -587.27476±0.00000  bestvalidloss -1245.05650  last_update 10\n",
      "train: iter 276  trainloss -1283.94997  validloss -1212.52127±0.00000  bestvalidloss -1245.05650  last_update 11\n",
      "train: iter 277  trainloss -1220.19089  validloss -1255.47217±0.00000  bestvalidloss -1255.47217  last_update 0\n",
      "train: iter 278  trainloss -1271.13539  validloss -1246.39065±0.00000  bestvalidloss -1255.47217  last_update 1\n",
      "train: iter 279  trainloss -1170.22945  validloss -932.33344±0.00000  bestvalidloss -1255.47217  last_update 2\n",
      "train: iter 280  trainloss -1118.30512  validloss -966.80436±0.00000  bestvalidloss -1255.47217  last_update 3\n",
      "train: iter 281  trainloss -1221.27552  validloss -1102.23991±0.00000  bestvalidloss -1255.47217  last_update 4\n",
      "train: iter 282  trainloss -1313.25344  validloss -1216.57970±0.00000  bestvalidloss -1255.47217  last_update 5\n",
      "train: iter 283  trainloss -1051.51052  validloss -1155.90199±0.00000  bestvalidloss -1255.47217  last_update 6\n",
      "train: iter 284  trainloss -1294.69855  validloss -1075.94410±0.00000  bestvalidloss -1255.47217  last_update 7\n",
      "train: iter 285  trainloss -1259.31956  validloss -1143.17049±0.00000  bestvalidloss -1255.47217  last_update 8\n",
      "train: iter 286  trainloss -1096.51101  validloss -996.34254±0.00000  bestvalidloss -1255.47217  last_update 9\n",
      "train: iter 287  trainloss -1237.51760  validloss -797.90383±0.00000  bestvalidloss -1255.47217  last_update 10\n",
      "train: iter 288  trainloss -1303.92873  validloss -1230.56473±0.00000  bestvalidloss -1255.47217  last_update 11\n",
      "train: iter 289  trainloss -1196.36986  validloss -967.76738±0.00000  bestvalidloss -1255.47217  last_update 12\n",
      "train: iter 290  trainloss -1166.42383  validloss -1175.43671±0.00000  bestvalidloss -1255.47217  last_update 13\n",
      "train: iter 291  trainloss -1196.15071  validloss -1206.34204±0.00000  bestvalidloss -1255.47217  last_update 14\n",
      "train: iter 292  trainloss -1102.60106  validloss -1120.48513±0.00000  bestvalidloss -1255.47217  last_update 15\n",
      "train: iter 293  trainloss -1235.63342  validloss -1021.42466±0.00000  bestvalidloss -1255.47217  last_update 16\n",
      "train: iter 294  trainloss -1279.71616  validloss -1257.75968±0.00000  bestvalidloss -1257.75968  last_update 0\n",
      "train: iter 295  trainloss -1329.70414  validloss -1132.04542±0.00000  bestvalidloss -1257.75968  last_update 1\n",
      "train: iter 296  trainloss -1251.54536  validloss -1231.32898±0.00000  bestvalidloss -1257.75968  last_update 2\n",
      "train: iter 297  trainloss -1152.54044  validloss -876.43085±0.00000  bestvalidloss -1257.75968  last_update 3\n",
      "train: iter 298  trainloss -1213.42259  validloss -1126.55930±0.00000  bestvalidloss -1257.75968  last_update 4\n",
      "train: iter 299  trainloss -1259.98814  validloss -1092.70356±0.00000  bestvalidloss -1257.75968  last_update 5\n",
      "train: iter 300  trainloss -1337.57399  validloss -1091.86918±0.00000  bestvalidloss -1257.75968  last_update 6\n",
      "train: iter 301  trainloss -941.13358  validloss -1289.10168±0.00000  bestvalidloss -1289.10168  last_update 0\n",
      "train: iter 302  trainloss -1167.83391  validloss -1061.29291±0.00000  bestvalidloss -1289.10168  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 303  trainloss -1281.45825  validloss -457.82002±0.00000  bestvalidloss -1289.10168  last_update 2\n",
      "train: iter 304  trainloss -1173.88302  validloss -1056.33468±0.00000  bestvalidloss -1289.10168  last_update 3\n",
      "train: iter 305  trainloss -1226.46376  validloss -1071.72164±0.00000  bestvalidloss -1289.10168  last_update 4\n",
      "train: iter 306  trainloss -1306.62477  validloss -1188.57374±0.00000  bestvalidloss -1289.10168  last_update 5\n",
      "train: iter 307  trainloss -1206.41203  validloss -1184.83426±0.00000  bestvalidloss -1289.10168  last_update 6\n",
      "train: iter 308  trainloss -1295.53308  validloss -1179.28001±0.00000  bestvalidloss -1289.10168  last_update 7\n",
      "train: iter 309  trainloss -1345.50529  validloss -1269.81459±0.00000  bestvalidloss -1289.10168  last_update 8\n",
      "train: iter 310  trainloss -1276.04585  validloss -1175.76660±0.00000  bestvalidloss -1289.10168  last_update 9\n",
      "train: iter 311  trainloss -1294.71192  validloss -1111.43957±0.00000  bestvalidloss -1289.10168  last_update 10\n",
      "train: iter 312  trainloss -1311.82176  validloss -787.99432±0.00000  bestvalidloss -1289.10168  last_update 11\n",
      "train: iter 313  trainloss -1224.46508  validloss -1178.06510±0.00000  bestvalidloss -1289.10168  last_update 12\n",
      "train: iter 314  trainloss -1297.41239  validloss -1185.88105±0.00000  bestvalidloss -1289.10168  last_update 13\n",
      "train: iter 315  trainloss -929.20857  validloss -552.31773±0.00000  bestvalidloss -1289.10168  last_update 14\n",
      "train: iter 316  trainloss -1249.70465  validloss -1002.45565±0.00000  bestvalidloss -1289.10168  last_update 15\n",
      "train: iter 317  trainloss -1356.80987  validloss -1265.99892±0.00000  bestvalidloss -1289.10168  last_update 16\n",
      "train: iter 318  trainloss -1278.82649  validloss -1044.85087±0.00000  bestvalidloss -1289.10168  last_update 17\n",
      "train: iter 319  trainloss -1315.14279  validloss -1291.24984±0.00000  bestvalidloss -1291.24984  last_update 0\n",
      "train: iter 320  trainloss -1280.04627  validloss -1187.17669±0.00000  bestvalidloss -1291.24984  last_update 1\n",
      "train: iter 321  trainloss -1275.85488  validloss -1107.30452±0.00000  bestvalidloss -1291.24984  last_update 2\n",
      "train: iter 322  trainloss -1308.49543  validloss -1305.64477±0.00000  bestvalidloss -1305.64477  last_update 0\n",
      "train: iter 323  trainloss -1310.33634  validloss -1306.86644±0.00000  bestvalidloss -1306.86644  last_update 0\n",
      "train: iter 324  trainloss -1337.54826  validloss -1232.07970±0.00000  bestvalidloss -1306.86644  last_update 1\n",
      "train: iter 325  trainloss -1301.73414  validloss -1193.08692±0.00000  bestvalidloss -1306.86644  last_update 2\n",
      "train: iter 326  trainloss -1273.37095  validloss -1190.66881±0.00000  bestvalidloss -1306.86644  last_update 3\n",
      "train: iter 327  trainloss -1315.18143  validloss -1265.46122±0.00000  bestvalidloss -1306.86644  last_update 4\n",
      "train: iter 328  trainloss -1133.66565  validloss -1135.69164±0.00000  bestvalidloss -1306.86644  last_update 5\n",
      "train: iter 329  trainloss -1330.70859  validloss -1054.25270±0.00000  bestvalidloss -1306.86644  last_update 6\n",
      "train: iter 330  trainloss -1367.53871  validloss -1266.13417±0.00000  bestvalidloss -1306.86644  last_update 7\n",
      "train: iter 331  trainloss -1311.14887  validloss -1103.80249±0.00000  bestvalidloss -1306.86644  last_update 8\n",
      "train: iter 332  trainloss -1343.19263  validloss -1335.22850±0.00000  bestvalidloss -1335.22850  last_update 0\n",
      "train: iter 333  trainloss -1300.73566  validloss -1258.91258±0.00000  bestvalidloss -1335.22850  last_update 1\n",
      "train: iter 334  trainloss -1156.61526  validloss -1164.83755±0.00000  bestvalidloss -1335.22850  last_update 2\n",
      "train: iter 335  trainloss -1310.66583  validloss -1182.62037±0.00000  bestvalidloss -1335.22850  last_update 3\n",
      "train: iter 336  trainloss -1111.15533  validloss -804.62150±0.00000  bestvalidloss -1335.22850  last_update 4\n",
      "train: iter 337  trainloss -1390.47213  validloss -1218.31497±0.00000  bestvalidloss -1335.22850  last_update 5\n",
      "train: iter 338  trainloss -1390.66248  validloss -1218.72972±0.00000  bestvalidloss -1335.22850  last_update 6\n",
      "train: iter 339  trainloss -1237.50952  validloss -1243.39490±0.00000  bestvalidloss -1335.22850  last_update 7\n",
      "train: iter 340  trainloss -1291.21062  validloss -1214.59123±0.00000  bestvalidloss -1335.22850  last_update 8\n",
      "train: iter 341  trainloss -1301.60358  validloss -1282.89088±0.00000  bestvalidloss -1335.22850  last_update 9\n",
      "train: iter 342  trainloss -1294.08931  validloss -993.74400±0.00000  bestvalidloss -1335.22850  last_update 10\n",
      "train: iter 343  trainloss -1323.01564  validloss -1160.53834±0.00000  bestvalidloss -1335.22850  last_update 11\n",
      "train: iter 344  trainloss -1267.92946  validloss -1134.20018±0.00000  bestvalidloss -1335.22850  last_update 12\n",
      "train: iter 345  trainloss -1365.43113  validloss -1192.15215±0.00000  bestvalidloss -1335.22850  last_update 13\n",
      "train: iter 346  trainloss -1088.55673  validloss -985.42062±0.00000  bestvalidloss -1335.22850  last_update 14\n",
      "train: iter 347  trainloss -1297.92320  validloss -1133.60974±0.00000  bestvalidloss -1335.22850  last_update 15\n",
      "train: iter 348  trainloss -1345.65805  validloss -1011.94273±0.00000  bestvalidloss -1335.22850  last_update 16\n",
      "train: iter 349  trainloss -1359.48379  validloss -1294.26486±0.00000  bestvalidloss -1335.22850  last_update 17\n",
      "train: iter 350  trainloss -1079.70765  validloss -1188.15129±0.00000  bestvalidloss -1335.22850  last_update 18\n",
      "train: iter 351  trainloss -1300.46080  validloss -1109.33751±0.00000  bestvalidloss -1335.22850  last_update 19\n",
      "train: iter 352  trainloss -1181.08141  validloss -1269.43137±0.00000  bestvalidloss -1335.22850  last_update 20\n",
      "train: iter 353  trainloss -1362.84316  validloss -1223.35289±0.00000  bestvalidloss -1335.22850  last_update 21\n",
      "train: iter 354  trainloss -1326.28969  validloss -669.58429±0.00000  bestvalidloss -1335.22850  last_update 22\n",
      "train: iter 355  trainloss -1240.68278  validloss -1295.61956±0.00000  bestvalidloss -1335.22850  last_update 23\n",
      "train: iter 356  trainloss -1294.29554  validloss -961.29044±0.00000  bestvalidloss -1335.22850  last_update 24\n",
      "train: iter 357  trainloss -1198.95002  validloss -1197.30991±0.00000  bestvalidloss -1335.22850  last_update 25\n",
      "train: iter 358  trainloss -1393.96883  validloss -1238.27720±0.00000  bestvalidloss -1335.22850  last_update 26\n",
      "train: iter 359  trainloss -1439.53388  validloss -1360.64757±0.00000  bestvalidloss -1360.64757  last_update 0\n",
      "train: iter 360  trainloss -1326.05745  validloss -1187.49799±0.00000  bestvalidloss -1360.64757  last_update 1\n",
      "train: iter 361  trainloss -1273.33596  validloss -1244.45840±0.00000  bestvalidloss -1360.64757  last_update 2\n",
      "train: iter 362  trainloss -1305.94577  validloss -1218.17129±0.00000  bestvalidloss -1360.64757  last_update 3\n",
      "train: iter 363  trainloss -1309.90698  validloss -1175.12112±0.00000  bestvalidloss -1360.64757  last_update 4\n",
      "train: iter 364  trainloss -1442.36953  validloss -1259.02361±0.00000  bestvalidloss -1360.64757  last_update 5\n",
      "train: iter 365  trainloss -1367.87076  validloss -1274.25726±0.00000  bestvalidloss -1360.64757  last_update 6\n",
      "train: iter 366  trainloss -1362.49025  validloss -1303.02060±0.00000  bestvalidloss -1360.64757  last_update 7\n",
      "train: iter 367  trainloss -1288.54384  validloss -956.59146±0.00000  bestvalidloss -1360.64757  last_update 8\n",
      "train: iter 368  trainloss -1389.66730  validloss -1026.81784±0.00000  bestvalidloss -1360.64757  last_update 9\n",
      "train: iter 369  trainloss -1406.72733  validloss -1277.71625±0.00000  bestvalidloss -1360.64757  last_update 10\n",
      "train: iter 370  trainloss -1172.32925  validloss -904.03865±0.00000  bestvalidloss -1360.64757  last_update 11\n",
      "train: iter 371  trainloss -1396.04962  validloss -1250.79580±0.00000  bestvalidloss -1360.64757  last_update 12\n",
      "train: iter 372  trainloss -1368.65687  validloss -1161.41397±0.00000  bestvalidloss -1360.64757  last_update 13\n",
      "train: iter 373  trainloss -1373.35588  validloss -990.11578±0.00000  bestvalidloss -1360.64757  last_update 14\n",
      "train: iter 374  trainloss -1313.80718  validloss -1245.28138±0.00000  bestvalidloss -1360.64757  last_update 15\n",
      "train: iter 375  trainloss -1476.74403  validloss -1331.28219±0.00000  bestvalidloss -1360.64757  last_update 16\n",
      "train: iter 376  trainloss -1331.72789  validloss -1331.49122±0.00000  bestvalidloss -1360.64757  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 377  trainloss -1311.02685  validloss -1141.37528±0.00000  bestvalidloss -1360.64757  last_update 18\n",
      "train: iter 378  trainloss -1279.14846  validloss -1214.10603±0.00000  bestvalidloss -1360.64757  last_update 19\n",
      "train: iter 379  trainloss -1311.35439  validloss -1198.90065±0.00000  bestvalidloss -1360.64757  last_update 20\n",
      "train: iter 380  trainloss -1421.58094  validloss -1317.40782±0.00000  bestvalidloss -1360.64757  last_update 21\n",
      "train: iter 381  trainloss -1353.33704  validloss -1291.47634±0.00000  bestvalidloss -1360.64757  last_update 22\n",
      "train: iter 382  trainloss -1284.81516  validloss -1265.55796±0.00000  bestvalidloss -1360.64757  last_update 23\n",
      "train: iter 383  trainloss -1433.16067  validloss -1220.44355±0.00000  bestvalidloss -1360.64757  last_update 24\n",
      "train: iter 384  trainloss -1405.04580  validloss -1381.57364±0.00000  bestvalidloss -1381.57364  last_update 0\n",
      "train: iter 385  trainloss -1284.36641  validloss -1106.31919±0.00000  bestvalidloss -1381.57364  last_update 1\n",
      "train: iter 386  trainloss -1152.35639  validloss -1156.66320±0.00000  bestvalidloss -1381.57364  last_update 2\n",
      "train: iter 387  trainloss -1308.91778  validloss -1123.75995±0.00000  bestvalidloss -1381.57364  last_update 3\n",
      "train: iter 388  trainloss -1388.88928  validloss -1048.69107±0.00000  bestvalidloss -1381.57364  last_update 4\n",
      "train: iter 389  trainloss -1363.33941  validloss -1303.48253±0.00000  bestvalidloss -1381.57364  last_update 5\n",
      "train: iter 390  trainloss -1411.62401  validloss -1180.59917±0.00000  bestvalidloss -1381.57364  last_update 6\n",
      "train: iter 391  trainloss -1481.00341  validloss -1361.32817±0.00000  bestvalidloss -1381.57364  last_update 7\n",
      "train: iter 392  trainloss -1240.91275  validloss -1291.78974±0.00000  bestvalidloss -1381.57364  last_update 8\n",
      "train: iter 393  trainloss -1203.03289  validloss -1040.76948±0.00000  bestvalidloss -1381.57364  last_update 9\n",
      "train: iter 394  trainloss -1378.83851  validloss -1186.30326±0.00000  bestvalidloss -1381.57364  last_update 10\n",
      "train: iter 395  trainloss -1442.07486  validloss -1254.87800±0.00000  bestvalidloss -1381.57364  last_update 11\n",
      "train: iter 396  trainloss -1421.00718  validloss -1358.43522±0.00000  bestvalidloss -1381.57364  last_update 12\n",
      "train: iter 397  trainloss -1418.56249  validloss -1303.09186±0.00000  bestvalidloss -1381.57364  last_update 13\n",
      "train: iter 398  trainloss -1334.63177  validloss -1256.71465±0.00000  bestvalidloss -1381.57364  last_update 14\n",
      "train: iter 399  trainloss -1274.18308  validloss -1206.07259±0.00000  bestvalidloss -1381.57364  last_update 15\n",
      "train: iter 400  trainloss -1426.59283  validloss -1146.15424±0.00000  bestvalidloss -1381.57364  last_update 16\n",
      "train: iter 401  trainloss -1355.17263  validloss -1218.10311±0.00000  bestvalidloss -1381.57364  last_update 17\n",
      "train: iter 402  trainloss -1381.39742  validloss -1182.19887±0.00000  bestvalidloss -1381.57364  last_update 18\n",
      "train: iter 403  trainloss -1445.25363  validloss -1277.74248±0.00000  bestvalidloss -1381.57364  last_update 19\n",
      "train: iter 404  trainloss -1263.13185  validloss -1123.67530±0.00000  bestvalidloss -1381.57364  last_update 20\n",
      "train: iter 405  trainloss -1436.33672  validloss -1325.38588±0.00000  bestvalidloss -1381.57364  last_update 21\n",
      "train: iter 406  trainloss -1430.94508  validloss -1226.33106±0.00000  bestvalidloss -1381.57364  last_update 22\n",
      "train: iter 407  trainloss -1339.65638  validloss -1181.77883±0.00000  bestvalidloss -1381.57364  last_update 23\n",
      "train: iter 408  trainloss -1381.67386  validloss -1258.93428±0.00000  bestvalidloss -1381.57364  last_update 24\n",
      "train: iter 409  trainloss -1362.67744  validloss -1057.66796±0.00000  bestvalidloss -1381.57364  last_update 25\n",
      "train: iter 410  trainloss -1438.42532  validloss -1303.65867±0.00000  bestvalidloss -1381.57364  last_update 26\n",
      "train: iter 411  trainloss -1489.11682  validloss -1358.69840±0.00000  bestvalidloss -1381.57364  last_update 27\n",
      "train: iter 412  trainloss -1209.65608  validloss -1373.44633±0.00000  bestvalidloss -1381.57364  last_update 28\n",
      "train: iter 413  trainloss -1421.21024  validloss -1193.25620±0.00000  bestvalidloss -1381.57364  last_update 29\n",
      "train: iter 414  trainloss -1317.52667  validloss -1282.15484±0.00000  bestvalidloss -1381.57364  last_update 30\n",
      "train: iter 415  trainloss -1385.51142  validloss -1364.59534±0.00000  bestvalidloss -1381.57364  last_update 31\n",
      "train: iter 416  trainloss -1394.51858  validloss -1119.28560±0.00000  bestvalidloss -1381.57364  last_update 32\n",
      "train: iter 417  trainloss -1366.23615  validloss -1385.27986±0.00000  bestvalidloss -1385.27986  last_update 0\n",
      "train: iter 418  trainloss -1487.63925  validloss -1331.61896±0.00000  bestvalidloss -1385.27986  last_update 1\n",
      "train: iter 419  trainloss -1098.36574  validloss -1166.71743±0.00000  bestvalidloss -1385.27986  last_update 2\n",
      "train: iter 420  trainloss -1314.69926  validloss -1264.92685±0.00000  bestvalidloss -1385.27986  last_update 3\n",
      "train: iter 421  trainloss -1290.77278  validloss -694.95025±0.00000  bestvalidloss -1385.27986  last_update 4\n",
      "train: iter 422  trainloss -1400.03561  validloss -1273.45031±0.00000  bestvalidloss -1385.27986  last_update 5\n",
      "train: iter 423  trainloss -1415.83296  validloss -1266.11179±0.00000  bestvalidloss -1385.27986  last_update 6\n",
      "train: iter 424  trainloss -1467.35516  validloss -1358.72415±0.00000  bestvalidloss -1385.27986  last_update 7\n",
      "train: iter 425  trainloss -1437.07447  validloss -1401.24667±0.00000  bestvalidloss -1401.24667  last_update 0\n",
      "train: iter 426  trainloss -1433.90464  validloss -1298.57775±0.00000  bestvalidloss -1401.24667  last_update 1\n",
      "train: iter 427  trainloss -1181.55769  validloss -1181.49623±0.00000  bestvalidloss -1401.24667  last_update 2\n",
      "train: iter 428  trainloss -1390.34037  validloss -1231.36216±0.00000  bestvalidloss -1401.24667  last_update 3\n",
      "train: iter 429  trainloss -1420.59707  validloss -1230.82093±0.00000  bestvalidloss -1401.24667  last_update 4\n",
      "train: iter 430  trainloss -1282.39138  validloss -1247.96499±0.00000  bestvalidloss -1401.24667  last_update 5\n",
      "train: iter 431  trainloss -1448.13039  validloss -1312.04430±0.00000  bestvalidloss -1401.24667  last_update 6\n",
      "train: iter 432  trainloss -1399.25869  validloss -1232.15400±0.00000  bestvalidloss -1401.24667  last_update 7\n",
      "train: iter 433  trainloss -1496.51430  validloss -1351.16718±0.00000  bestvalidloss -1401.24667  last_update 8\n",
      "train: iter 434  trainloss -1345.54727  validloss -1329.93516±0.00000  bestvalidloss -1401.24667  last_update 9\n",
      "train: iter 435  trainloss -1477.08638  validloss -1358.69632±0.00000  bestvalidloss -1401.24667  last_update 10\n",
      "train: iter 436  trainloss -1378.81165  validloss -996.08627±0.00000  bestvalidloss -1401.24667  last_update 11\n",
      "train: iter 437  trainloss -1294.32357  validloss -1220.92513±0.00000  bestvalidloss -1401.24667  last_update 12\n",
      "train: iter 438  trainloss -1416.26882  validloss -1010.56768±0.00000  bestvalidloss -1401.24667  last_update 13\n",
      "train: iter 439  trainloss -1433.46948  validloss -1196.63068±0.00000  bestvalidloss -1401.24667  last_update 14\n",
      "train: iter 440  trainloss -1444.40705  validloss -1370.14712±0.00000  bestvalidloss -1401.24667  last_update 15\n",
      "train: iter 441  trainloss -1459.82546  validloss -1337.51687±0.00000  bestvalidloss -1401.24667  last_update 16\n",
      "train: iter 442  trainloss -1383.27271  validloss -1225.60663±0.00000  bestvalidloss -1401.24667  last_update 17\n",
      "train: iter 443  trainloss -1465.32385  validloss -1350.59010±0.00000  bestvalidloss -1401.24667  last_update 18\n",
      "train: iter 444  trainloss -1518.68569  validloss -1412.49954±0.00000  bestvalidloss -1412.49954  last_update 0\n",
      "train: iter 445  trainloss -1330.07806  validloss -1394.15966±0.00000  bestvalidloss -1412.49954  last_update 1\n",
      "train: iter 446  trainloss -1367.26809  validloss -1156.09406±0.00000  bestvalidloss -1412.49954  last_update 2\n",
      "train: iter 447  trainloss -1461.14857  validloss -1352.22371±0.00000  bestvalidloss -1412.49954  last_update 3\n",
      "train: iter 448  trainloss -1366.51213  validloss -1313.99550±0.00000  bestvalidloss -1412.49954  last_update 4\n",
      "train: iter 449  trainloss -1200.80308  validloss -1031.51739±0.00000  bestvalidloss -1412.49954  last_update 5\n",
      "train: iter 450  trainloss -1299.91036  validloss -1221.49391±0.00000  bestvalidloss -1412.49954  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 451  trainloss -1450.37761  validloss -1274.33103±0.00000  bestvalidloss -1412.49954  last_update 7\n",
      "train: iter 452  trainloss -1459.17857  validloss -1383.90751±0.00000  bestvalidloss -1412.49954  last_update 8\n",
      "train: iter 453  trainloss -1452.19780  validloss -1308.22242±0.00000  bestvalidloss -1412.49954  last_update 9\n",
      "train: iter 454  trainloss -1372.77608  validloss -1238.35479±0.00000  bestvalidloss -1412.49954  last_update 10\n",
      "train: iter 455  trainloss -1471.86784  validloss -1148.27476±0.00000  bestvalidloss -1412.49954  last_update 11\n",
      "train: iter 456  trainloss -1345.97966  validloss -1321.28352±0.00000  bestvalidloss -1412.49954  last_update 12\n",
      "train: iter 457  trainloss -1316.35915  validloss -1022.62296±0.00000  bestvalidloss -1412.49954  last_update 13\n",
      "train: iter 458  trainloss -1438.21434  validloss -1183.30370±0.00000  bestvalidloss -1412.49954  last_update 14\n",
      "train: iter 459  trainloss -1451.46906  validloss -1290.15982±0.00000  bestvalidloss -1412.49954  last_update 15\n",
      "train: iter 460  trainloss -1411.66237  validloss -1323.95502±0.00000  bestvalidloss -1412.49954  last_update 16\n",
      "train: iter 461  trainloss -1391.17532  validloss -1200.15467±0.00000  bestvalidloss -1412.49954  last_update 17\n",
      "train: iter 462  trainloss -1475.78664  validloss -1276.32328±0.00000  bestvalidloss -1412.49954  last_update 18\n",
      "train: iter 463  trainloss -1418.33227  validloss -1430.14460±0.00000  bestvalidloss -1430.14460  last_update 0\n",
      "train: iter 464  trainloss -1324.68343  validloss -1254.17079±0.00000  bestvalidloss -1430.14460  last_update 1\n",
      "train: iter 465  trainloss -1371.02197  validloss -1123.63225±0.00000  bestvalidloss -1430.14460  last_update 2\n",
      "train: iter 466  trainloss -1404.51233  validloss -1253.04732±0.00000  bestvalidloss -1430.14460  last_update 3\n",
      "train: iter 467  trainloss -1374.80667  validloss -1323.05670±0.00000  bestvalidloss -1430.14460  last_update 4\n",
      "train: iter 468  trainloss -1497.62606  validloss -1335.68525±0.00000  bestvalidloss -1430.14460  last_update 5\n",
      "train: iter 469  trainloss -1443.59712  validloss -1314.01337±0.00000  bestvalidloss -1430.14460  last_update 6\n",
      "train: iter 470  trainloss -1339.64008  validloss -1220.53636±0.00000  bestvalidloss -1430.14460  last_update 7\n",
      "train: iter 471  trainloss -1486.28189  validloss -1219.24280±0.00000  bestvalidloss -1430.14460  last_update 8\n",
      "train: iter 472  trainloss -1188.52422  validloss -1339.19019±0.00000  bestvalidloss -1430.14460  last_update 9\n",
      "train: iter 473  trainloss -1373.95932  validloss -925.99113±0.00000  bestvalidloss -1430.14460  last_update 10\n",
      "train: iter 474  trainloss -1379.79337  validloss -1239.30575±0.00000  bestvalidloss -1430.14460  last_update 11\n",
      "train: iter 475  trainloss -1532.78304  validloss -1392.77893±0.00000  bestvalidloss -1430.14460  last_update 12\n",
      "train: iter 476  trainloss -1247.32641  validloss -1389.71565±0.00000  bestvalidloss -1430.14460  last_update 13\n",
      "train: iter 477  trainloss -1474.13950  validloss -1284.26707±0.00000  bestvalidloss -1430.14460  last_update 14\n",
      "train: iter 478  trainloss -1455.90979  validloss -1012.76162±0.00000  bestvalidloss -1430.14460  last_update 15\n",
      "train: iter 479  trainloss -1569.13202  validloss -1457.96305±0.00000  bestvalidloss -1457.96305  last_update 0\n",
      "train: iter 480  trainloss -1381.16544  validloss -1466.18345±0.00000  bestvalidloss -1466.18345  last_update 0\n",
      "train: iter 481  trainloss -1433.24609  validloss -1274.76737±0.00000  bestvalidloss -1466.18345  last_update 1\n",
      "train: iter 482  trainloss -1411.06490  validloss -1371.05706±0.00000  bestvalidloss -1466.18345  last_update 2\n",
      "train: iter 483  trainloss -1348.99002  validloss -857.79774±0.00000  bestvalidloss -1466.18345  last_update 3\n",
      "train: iter 484  trainloss -1466.70742  validloss -1187.21891±0.00000  bestvalidloss -1466.18345  last_update 4\n",
      "train: iter 485  trainloss -1422.15981  validloss -1078.50499±0.00000  bestvalidloss -1466.18345  last_update 5\n",
      "train: iter 486  trainloss -1472.20612  validloss -1208.56126±0.00000  bestvalidloss -1466.18345  last_update 6\n",
      "train: iter 487  trainloss -1542.98377  validloss -1395.64112±0.00000  bestvalidloss -1466.18345  last_update 7\n",
      "train: iter 488  trainloss -1375.13822  validloss -1434.33437±0.00000  bestvalidloss -1466.18345  last_update 8\n",
      "train: iter 489  trainloss -1395.72813  validloss -762.87937±0.00000  bestvalidloss -1466.18345  last_update 9\n",
      "train: iter 490  trainloss -1527.57977  validloss -1364.42112±0.00000  bestvalidloss -1466.18345  last_update 10\n",
      "train: iter 491  trainloss -1471.89856  validloss -1286.12846±0.00000  bestvalidloss -1466.18345  last_update 11\n",
      "train: iter 492  trainloss -1503.21409  validloss -1339.48732±0.00000  bestvalidloss -1466.18345  last_update 12\n",
      "train: iter 493  trainloss -1443.91793  validloss -1285.37109±0.00000  bestvalidloss -1466.18345  last_update 13\n",
      "train: iter 494  trainloss -1295.67803  validloss -1316.47685±0.00000  bestvalidloss -1466.18345  last_update 14\n",
      "train: iter 495  trainloss -1475.94554  validloss -1340.43683±0.00000  bestvalidloss -1466.18345  last_update 15\n",
      "train: iter 496  trainloss -1508.95173  validloss -1259.21505±0.00000  bestvalidloss -1466.18345  last_update 16\n",
      "train: iter 497  trainloss -1487.24622  validloss -1420.11882±0.00000  bestvalidloss -1466.18345  last_update 17\n",
      "train: iter 498  trainloss -1386.74351  validloss -1324.09586±0.00000  bestvalidloss -1466.18345  last_update 18\n",
      "train: iter 499  trainloss -1449.03402  validloss -1335.20399±0.00000  bestvalidloss -1466.18345  last_update 19\n",
      "train: iter 500  trainloss -1499.62562  validloss -1401.72398±0.00000  bestvalidloss -1466.18345  last_update 20\n",
      "train: iter 501  trainloss -1404.11580  validloss -1265.06294±0.00000  bestvalidloss -1466.18345  last_update 21\n",
      "train: iter 502  trainloss -1316.92054  validloss -1352.91906±0.00000  bestvalidloss -1466.18345  last_update 22\n",
      "train: iter 503  trainloss -1492.40220  validloss -1288.25888±0.00000  bestvalidloss -1466.18345  last_update 23\n",
      "train: iter 504  trainloss -1477.48327  validloss -1316.53295±0.00000  bestvalidloss -1466.18345  last_update 24\n",
      "train: iter 505  trainloss -1544.58843  validloss -1390.04907±0.00000  bestvalidloss -1466.18345  last_update 25\n",
      "train: iter 506  trainloss -1235.47492  validloss -1428.59446±0.00000  bestvalidloss -1466.18345  last_update 26\n",
      "train: iter 507  trainloss -1447.14554  validloss -1235.50058±0.00000  bestvalidloss -1466.18345  last_update 27\n",
      "train: iter 508  trainloss -1068.00547  validloss -1307.77697±0.00000  bestvalidloss -1466.18345  last_update 28\n",
      "train: iter 509  trainloss -1410.33877  validloss -1162.30082±0.00000  bestvalidloss -1466.18345  last_update 29\n",
      "train: iter 510  trainloss -1494.30343  validloss -1107.40695±0.00000  bestvalidloss -1466.18345  last_update 30\n",
      "train: iter 511  trainloss -1394.91792  validloss -1390.03216±0.00000  bestvalidloss -1466.18345  last_update 31\n",
      "train: iter 512  trainloss -1350.13803  validloss -1025.24848±0.00000  bestvalidloss -1466.18345  last_update 32\n",
      "train: iter 513  trainloss -1494.46783  validloss -1416.62453±0.00000  bestvalidloss -1466.18345  last_update 33\n",
      "train: iter 514  trainloss -1559.65769  validloss -1383.34135±0.00000  bestvalidloss -1466.18345  last_update 34\n",
      "train: iter 515  trainloss -1487.78078  validloss -1475.18678±0.00000  bestvalidloss -1475.18678  last_update 0\n",
      "train: iter 516  trainloss -1344.37101  validloss -1254.00880±0.00000  bestvalidloss -1475.18678  last_update 1\n",
      "train: iter 517  trainloss -1489.81423  validloss -1359.35092±0.00000  bestvalidloss -1475.18678  last_update 2\n",
      "train: iter 518  trainloss -1438.15694  validloss -1241.18697±0.00000  bestvalidloss -1475.18678  last_update 3\n",
      "train: iter 519  trainloss -1535.60294  validloss -1379.00937±0.00000  bestvalidloss -1475.18678  last_update 4\n",
      "train: iter 520  trainloss -1540.20112  validloss -1425.09095±0.00000  bestvalidloss -1475.18678  last_update 5\n",
      "train: iter 521  trainloss -1133.17323  validloss -1259.24194±0.00000  bestvalidloss -1475.18678  last_update 6\n",
      "train: iter 522  trainloss -1313.51872  validloss -566.22489±0.00000  bestvalidloss -1475.18678  last_update 7\n",
      "train: iter 523  trainloss -1342.91533  validloss -1340.69877±0.00000  bestvalidloss -1475.18678  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 524  trainloss -1448.91053  validloss -1415.19507±0.00000  bestvalidloss -1475.18678  last_update 9\n",
      "train: iter 525  trainloss -1444.16728  validloss -970.79517±0.00000  bestvalidloss -1475.18678  last_update 10\n",
      "train: iter 526  trainloss -1552.84461  validloss -1458.38947±0.00000  bestvalidloss -1475.18678  last_update 11\n",
      "train: iter 527  trainloss -1447.71923  validloss -1477.43760±0.00000  bestvalidloss -1477.43760  last_update 0\n",
      "train: iter 528  trainloss -1365.40670  validloss -1412.02271±0.00000  bestvalidloss -1477.43760  last_update 1\n",
      "train: iter 529  trainloss -1528.72078  validloss -1344.66738±0.00000  bestvalidloss -1477.43760  last_update 2\n",
      "train: iter 530  trainloss -1467.53090  validloss -1288.41394±0.00000  bestvalidloss -1477.43760  last_update 3\n",
      "train: iter 531  trainloss -1542.82001  validloss -1441.52522±0.00000  bestvalidloss -1477.43760  last_update 4\n",
      "train: iter 532  trainloss -1490.73926  validloss -1455.68230±0.00000  bestvalidloss -1477.43760  last_update 5\n",
      "train: iter 533  trainloss -1463.84220  validloss -1442.45956±0.00000  bestvalidloss -1477.43760  last_update 6\n",
      "train: iter 534  trainloss -1251.35726  validloss -1258.80703±0.00000  bestvalidloss -1477.43760  last_update 7\n",
      "train: iter 535  trainloss -1178.66667  validloss -1364.00516±0.00000  bestvalidloss -1477.43760  last_update 8\n",
      "train: iter 536  trainloss -1381.26048  validloss -961.01198±0.00000  bestvalidloss -1477.43760  last_update 9\n",
      "train: iter 537  trainloss -1460.48331  validloss -1365.25168±0.00000  bestvalidloss -1477.43760  last_update 10\n",
      "train: iter 538  trainloss -1451.30892  validloss -1114.81090±0.00000  bestvalidloss -1477.43760  last_update 11\n",
      "train: iter 539  trainloss -1521.49441  validloss -1341.88089±0.00000  bestvalidloss -1477.43760  last_update 12\n",
      "train: iter 540  trainloss -1563.30687  validloss -1397.22162±0.00000  bestvalidloss -1477.43760  last_update 13\n",
      "train: iter 541  trainloss -1508.52446  validloss -1457.47066±0.00000  bestvalidloss -1477.43760  last_update 14\n",
      "train: iter 542  trainloss -1409.27157  validloss -1390.01129±0.00000  bestvalidloss -1477.43760  last_update 15\n",
      "train: iter 543  trainloss -1490.17778  validloss -1444.95103±0.00000  bestvalidloss -1477.43760  last_update 16\n",
      "train: iter 544  trainloss -1542.10307  validloss -1256.98945±0.00000  bestvalidloss -1477.43760  last_update 17\n",
      "train: iter 545  trainloss -1497.83604  validloss -1436.24389±0.00000  bestvalidloss -1477.43760  last_update 18\n",
      "train: iter 546  trainloss -1425.14086  validloss -1134.71312±0.00000  bestvalidloss -1477.43760  last_update 19\n",
      "train: iter 547  trainloss -1545.53597  validloss -1425.86612±0.00000  bestvalidloss -1477.43760  last_update 20\n",
      "train: iter 548  trainloss -1430.94674  validloss -1393.31384±0.00000  bestvalidloss -1477.43760  last_update 21\n",
      "train: iter 549  trainloss -1429.64787  validloss -748.23139±0.00000  bestvalidloss -1477.43760  last_update 22\n",
      "train: iter 550  trainloss -1540.40069  validloss -1413.64704±0.00000  bestvalidloss -1477.43760  last_update 23\n",
      "train: iter 551  trainloss -1402.39622  validloss -1448.15424±0.00000  bestvalidloss -1477.43760  last_update 24\n",
      "train: iter 552  trainloss -1561.29044  validloss -1467.56205±0.00000  bestvalidloss -1477.43760  last_update 25\n",
      "train: iter 553  trainloss -1469.27622  validloss -1386.27568±0.00000  bestvalidloss -1477.43760  last_update 26\n",
      "train: iter 554  trainloss -1494.43591  validloss -1417.36601±0.00000  bestvalidloss -1477.43760  last_update 27\n",
      "train: iter 555  trainloss -1563.52998  validloss -1448.98816±0.00000  bestvalidloss -1477.43760  last_update 28\n",
      "train: iter 556  trainloss -1536.69823  validloss -1461.65577±0.00000  bestvalidloss -1477.43760  last_update 29\n",
      "train: iter 557  trainloss -1442.74365  validloss -1040.26130±0.00000  bestvalidloss -1477.43760  last_update 30\n",
      "train: iter 558  trainloss -1495.36368  validloss -1354.89521±0.00000  bestvalidloss -1477.43760  last_update 31\n",
      "train: iter 559  trainloss -1493.65769  validloss -1366.79031±0.00000  bestvalidloss -1477.43760  last_update 32\n",
      "train: iter 560  trainloss -1487.35013  validloss -1326.96836±0.00000  bestvalidloss -1477.43760  last_update 33\n",
      "train: iter 561  trainloss -1523.54814  validloss -1368.67296±0.00000  bestvalidloss -1477.43760  last_update 34\n",
      "train: iter 562  trainloss -1420.03629  validloss -1093.97970±0.00000  bestvalidloss -1477.43760  last_update 35\n",
      "train: iter 563  trainloss -1451.55575  validloss -1417.54669±0.00000  bestvalidloss -1477.43760  last_update 36\n",
      "train: iter 564  trainloss -1449.04817  validloss -1115.75800±0.00000  bestvalidloss -1477.43760  last_update 37\n",
      "train: iter 565  trainloss -1549.42963  validloss -1463.26038±0.00000  bestvalidloss -1477.43760  last_update 38\n",
      "train: iter 566  trainloss -1382.75963  validloss -880.79761±0.00000  bestvalidloss -1477.43760  last_update 39\n",
      "train: iter 567  trainloss -1468.60425  validloss -1184.23831±0.00000  bestvalidloss -1477.43760  last_update 40\n",
      "train: iter 568  trainloss -1572.99385  validloss -1472.69980±0.00000  bestvalidloss -1477.43760  last_update 41\n",
      "train: iter 569  trainloss -1471.74000  validloss -1492.23619±0.00000  bestvalidloss -1492.23619  last_update 0\n",
      "train: iter 570  trainloss -1494.06032  validloss -1394.23358±0.00000  bestvalidloss -1492.23619  last_update 1\n",
      "train: iter 571  trainloss -1560.09147  validloss -1479.40949±0.00000  bestvalidloss -1492.23619  last_update 2\n",
      "train: iter 572  trainloss -1405.75366  validloss -1384.79594±0.00000  bestvalidloss -1492.23619  last_update 3\n",
      "train: iter 573  trainloss -1304.10532  validloss -1203.13585±0.00000  bestvalidloss -1492.23619  last_update 4\n",
      "train: iter 574  trainloss -1499.77738  validloss -1366.44499±0.00000  bestvalidloss -1492.23619  last_update 5\n",
      "train: iter 575  trainloss -1538.89528  validloss -1347.34319±0.00000  bestvalidloss -1492.23619  last_update 6\n",
      "train: iter 576  trainloss -1495.93190  validloss -1478.57361±0.00000  bestvalidloss -1492.23619  last_update 7\n",
      "train: iter 577  trainloss -1391.19613  validloss -1198.59728±0.00000  bestvalidloss -1492.23619  last_update 8\n",
      "train: iter 578  trainloss -1460.18846  validloss -1134.26209±0.00000  bestvalidloss -1492.23619  last_update 9\n",
      "train: iter 579  trainloss -1489.77003  validloss -1407.68817±0.00000  bestvalidloss -1492.23619  last_update 10\n",
      "train: iter 580  trainloss -1528.32705  validloss -1227.92487±0.00000  bestvalidloss -1492.23619  last_update 11\n",
      "train: iter 581  trainloss -1524.06726  validloss -1442.85483±0.00000  bestvalidloss -1492.23619  last_update 12\n",
      "train: iter 582  trainloss -1471.61623  validloss -1520.51005±0.00000  bestvalidloss -1520.51005  last_update 0\n",
      "train: iter 583  trainloss -1495.96502  validloss -1192.22837±0.00000  bestvalidloss -1520.51005  last_update 1\n",
      "train: iter 584  trainloss -1553.65165  validloss -1368.13253±0.00000  bestvalidloss -1520.51005  last_update 2\n",
      "train: iter 585  trainloss -1492.28932  validloss -1336.17386±0.00000  bestvalidloss -1520.51005  last_update 3\n",
      "train: iter 586  trainloss -1531.81198  validloss -1447.51413±0.00000  bestvalidloss -1520.51005  last_update 4\n",
      "train: iter 587  trainloss -1436.24076  validloss -1350.18402±0.00000  bestvalidloss -1520.51005  last_update 5\n",
      "train: iter 588  trainloss -1253.66889  validloss -1461.92077±0.00000  bestvalidloss -1520.51005  last_update 6\n",
      "train: iter 589  trainloss -1554.73750  validloss -1285.25110±0.00000  bestvalidloss -1520.51005  last_update 7\n",
      "train: iter 590  trainloss -1405.72695  validloss -1304.40770±0.00000  bestvalidloss -1520.51005  last_update 8\n",
      "train: iter 591  trainloss -1505.77765  validloss -1340.99596±0.00000  bestvalidloss -1520.51005  last_update 9\n",
      "train: iter 592  trainloss -1528.91877  validloss -1461.90113±0.00000  bestvalidloss -1520.51005  last_update 10\n",
      "train: iter 593  trainloss -1485.67983  validloss -1484.20927±0.00000  bestvalidloss -1520.51005  last_update 11\n",
      "train: iter 594  trainloss -1471.29531  validloss -1179.33884±0.00000  bestvalidloss -1520.51005  last_update 12\n",
      "train: iter 595  trainloss -1565.68445  validloss -1468.68242±0.00000  bestvalidloss -1520.51005  last_update 13\n",
      "train: iter 596  trainloss -1521.49338  validloss -1406.37862±0.00000  bestvalidloss -1520.51005  last_update 14\n",
      "train: iter 597  trainloss -1475.20960  validloss -1439.61123±0.00000  bestvalidloss -1520.51005  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 598  trainloss -1580.70636  validloss -1498.58655±0.00000  bestvalidloss -1520.51005  last_update 16\n",
      "train: iter 599  trainloss -1400.08892  validloss -1400.58143±0.00000  bestvalidloss -1520.51005  last_update 17\n",
      "train: iter 600  trainloss -1448.74846  validloss -1306.10825±0.00000  bestvalidloss -1520.51005  last_update 18\n",
      "train: iter 601  trainloss -1481.08029  validloss -1302.38144±0.00000  bestvalidloss -1520.51005  last_update 19\n",
      "train: iter 602  trainloss -1515.94660  validloss -1320.04750±0.00000  bestvalidloss -1520.51005  last_update 20\n",
      "train: iter 603  trainloss -1580.37499  validloss -1441.71689±0.00000  bestvalidloss -1520.51005  last_update 21\n",
      "train: iter 604  trainloss -1437.00631  validloss -1419.19897±0.00000  bestvalidloss -1520.51005  last_update 22\n",
      "train: iter 605  trainloss -1518.56233  validloss -1403.22529±0.00000  bestvalidloss -1520.51005  last_update 23\n",
      "train: iter 606  trainloss -1500.45370  validloss -1247.91126±0.00000  bestvalidloss -1520.51005  last_update 24\n",
      "train: iter 607  trainloss -1562.55068  validloss -1434.22162±0.00000  bestvalidloss -1520.51005  last_update 25\n",
      "train: iter 608  trainloss -1535.73580  validloss -1501.92567±0.00000  bestvalidloss -1520.51005  last_update 26\n",
      "train: iter 609  trainloss -1508.23599  validloss -1461.46095±0.00000  bestvalidloss -1520.51005  last_update 27\n",
      "train: iter 610  trainloss -1451.60527  validloss -1450.51121±0.00000  bestvalidloss -1520.51005  last_update 28\n",
      "train: iter 611  trainloss -1590.25295  validloss -1466.96875±0.00000  bestvalidloss -1520.51005  last_update 29\n",
      "train: iter 612  trainloss -1559.25255  validloss -1455.84417±0.00000  bestvalidloss -1520.51005  last_update 30\n",
      "train: iter 613  trainloss -921.06215  validloss -1518.94067±0.00000  bestvalidloss -1520.51005  last_update 31\n",
      "train: iter 614  trainloss -1215.78574  validloss -1090.85684±0.00000  bestvalidloss -1520.51005  last_update 32\n",
      "train: iter 615  trainloss -1399.88678  validloss -1043.03836±0.00000  bestvalidloss -1520.51005  last_update 33\n",
      "train: iter 616  trainloss -1503.24706  validloss -1246.62246±0.00000  bestvalidloss -1520.51005  last_update 34\n",
      "train: iter 617  trainloss -1561.88850  validloss -1402.75402±0.00000  bestvalidloss -1520.51005  last_update 35\n",
      "train: iter 618  trainloss -1532.30650  validloss -1433.91060±0.00000  bestvalidloss -1520.51005  last_update 36\n",
      "train: iter 619  trainloss -1520.84519  validloss -1425.11830±0.00000  bestvalidloss -1520.51005  last_update 37\n",
      "train: iter 620  trainloss -1580.72860  validloss -1467.14133±0.00000  bestvalidloss -1520.51005  last_update 38\n",
      "train: iter 621  trainloss -1361.59844  validloss -1402.92520±0.00000  bestvalidloss -1520.51005  last_update 39\n",
      "train: iter 622  trainloss -1577.69650  validloss -1396.74829±0.00000  bestvalidloss -1520.51005  last_update 40\n",
      "train: iter 623  trainloss -1583.42544  validloss -1492.14462±0.00000  bestvalidloss -1520.51005  last_update 41\n",
      "train: iter 624  trainloss -1515.96870  validloss -1474.96618±0.00000  bestvalidloss -1520.51005  last_update 42\n",
      "train: iter 625  trainloss -1532.33292  validloss -1459.85553±0.00000  bestvalidloss -1520.51005  last_update 43\n",
      "train: iter 626  trainloss -1567.14332  validloss -1500.09878±0.00000  bestvalidloss -1520.51005  last_update 44\n",
      "train: iter 627  trainloss -1564.05204  validloss -1487.38666±0.00000  bestvalidloss -1520.51005  last_update 45\n",
      "train: iter 628  trainloss -1438.47468  validloss -1476.55779±0.00000  bestvalidloss -1520.51005  last_update 46\n",
      "train: iter 629  trainloss -1522.25215  validloss -1166.19851±0.00000  bestvalidloss -1520.51005  last_update 47\n",
      "train: iter 630  trainloss -1526.84140  validloss -1466.13971±0.00000  bestvalidloss -1520.51005  last_update 48\n",
      "train: iter 631  trainloss -1585.88243  validloss -1336.56456±0.00000  bestvalidloss -1520.51005  last_update 49\n",
      "train: iter 632  trainloss -1559.62054  validloss -1469.16567±0.00000  bestvalidloss -1520.51005  last_update 50\n",
      "train: iter 633  trainloss -1558.80295  validloss -1465.57889±0.00000  bestvalidloss -1520.51005  last_update 51\n",
      "train: iter 634  trainloss -1507.85106  validloss -1483.21809±0.00000  bestvalidloss -1520.51005  last_update 52\n",
      "train: iter 635  trainloss -1475.35741  validloss -1455.41260±0.00000  bestvalidloss -1520.51005  last_update 53\n",
      "train: iter 636  trainloss -1548.12071  validloss -1327.82554±0.00000  bestvalidloss -1520.51005  last_update 54\n",
      "train: iter 637  trainloss -1473.64912  validloss -1123.63668±0.00000  bestvalidloss -1520.51005  last_update 55\n",
      "train: iter 638  trainloss -1575.17503  validloss -1453.66214±0.00000  bestvalidloss -1520.51005  last_update 56\n",
      "train: iter 639  trainloss -1502.29460  validloss -1492.15782±0.00000  bestvalidloss -1520.51005  last_update 57\n",
      "train: iter 640  trainloss -1591.86101  validloss -1466.04348±0.00000  bestvalidloss -1520.51005  last_update 58\n",
      "train: iter 641  trainloss -769.34599  validloss -1134.23711±0.00000  bestvalidloss -1520.51005  last_update 59\n",
      "train: iter 642  trainloss -753.59323  validloss -679.06504±0.00000  bestvalidloss -1520.51005  last_update 60\n",
      "train: iter 643  trainloss -1339.88552  validloss -1042.74492±0.00000  bestvalidloss -1520.51005  last_update 61\n",
      "train: iter 644  trainloss -1396.98567  validloss -988.06995±0.00000  bestvalidloss -1520.51005  last_update 62\n",
      "train: iter 645  trainloss -1411.00027  validloss -1386.69567±0.00000  bestvalidloss -1520.51005  last_update 63\n",
      "train: iter 646  trainloss -1546.01570  validloss -1180.90777±0.00000  bestvalidloss -1520.51005  last_update 64\n",
      "train: iter 647  trainloss -1548.65100  validloss -1521.12076±0.00000  bestvalidloss -1521.12076  last_update 0\n",
      "train: iter 648  trainloss -1537.34972  validloss -1278.76718±0.00000  bestvalidloss -1521.12076  last_update 1\n",
      "train: iter 649  trainloss -1465.80900  validloss -1349.03886±0.00000  bestvalidloss -1521.12076  last_update 2\n",
      "train: iter 650  trainloss -1564.17595  validloss -1323.81441±0.00000  bestvalidloss -1521.12076  last_update 3\n",
      "train: iter 651  trainloss -1552.97205  validloss -1517.96478±0.00000  bestvalidloss -1521.12076  last_update 4\n",
      "train: iter 652  trainloss -1497.94034  validloss -1534.76257±0.00000  bestvalidloss -1534.76257  last_update 0\n",
      "train: iter 653  trainloss -1473.26921  validloss -1518.79630±0.00000  bestvalidloss -1534.76257  last_update 1\n",
      "train: iter 654  trainloss -1548.91314  validloss -1256.69023±0.00000  bestvalidloss -1534.76257  last_update 2\n",
      "train: iter 655  trainloss -1586.21930  validloss -1483.09362±0.00000  bestvalidloss -1534.76257  last_update 3\n",
      "train: iter 656  trainloss -1602.24891  validloss -1517.60767±0.00000  bestvalidloss -1534.76257  last_update 4\n",
      "train: iter 657  trainloss -1579.49786  validloss -1537.47057±0.00000  bestvalidloss -1537.47057  last_update 0\n",
      "train: iter 658  trainloss -1499.95554  validloss -1394.29393±0.00000  bestvalidloss -1537.47057  last_update 1\n",
      "train: iter 659  trainloss -1583.05404  validloss -1414.21323±0.00000  bestvalidloss -1537.47057  last_update 2\n",
      "train: iter 660  trainloss -1568.41983  validloss -1521.03781±0.00000  bestvalidloss -1537.47057  last_update 3\n",
      "train: iter 661  trainloss -1555.04163  validloss -1510.61648±0.00000  bestvalidloss -1537.47057  last_update 4\n",
      "train: iter 662  trainloss -1524.48400  validloss -1498.43628±0.00000  bestvalidloss -1537.47057  last_update 5\n",
      "train: iter 663  trainloss -1520.22403  validloss -1342.99993±0.00000  bestvalidloss -1537.47057  last_update 6\n",
      "train: iter 664  trainloss -1549.27143  validloss -1513.05056±0.00000  bestvalidloss -1537.47057  last_update 7\n",
      "train: iter 665  trainloss -1567.27595  validloss -1456.73932±0.00000  bestvalidloss -1537.47057  last_update 8\n",
      "train: iter 666  trainloss -1597.59457  validloss -1491.40186±0.00000  bestvalidloss -1537.47057  last_update 9\n",
      "train: iter 667  trainloss -1604.47533  validloss -1540.04841±0.00000  bestvalidloss -1540.04841  last_update 0\n",
      "train: iter 668  trainloss -1404.65531  validloss -1468.44029±0.00000  bestvalidloss -1540.04841  last_update 1\n",
      "train: iter 669  trainloss -1463.78058  validloss -908.38473±0.00000  bestvalidloss -1540.04841  last_update 2\n",
      "train: iter 670  trainloss -1468.54698  validloss -1354.62723±0.00000  bestvalidloss -1540.04841  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 671  trainloss -1605.34858  validloss -1489.50717±0.00000  bestvalidloss -1540.04841  last_update 4\n",
      "train: iter 672  trainloss -1604.26212  validloss -1528.87924±0.00000  bestvalidloss -1540.04841  last_update 5\n",
      "train: iter 673  trainloss -1567.43935  validloss -1512.33241±0.00000  bestvalidloss -1540.04841  last_update 6\n",
      "train: iter 674  trainloss -1484.18387  validloss -1508.63079±0.00000  bestvalidloss -1540.04841  last_update 7\n",
      "train: iter 675  trainloss -1552.56854  validloss -1059.84952±0.00000  bestvalidloss -1540.04841  last_update 8\n",
      "train: iter 676  trainloss -1578.08506  validloss -1521.28814±0.00000  bestvalidloss -1540.04841  last_update 9\n",
      "train: iter 677  trainloss -1482.00988  validloss -1475.17916±0.00000  bestvalidloss -1540.04841  last_update 10\n",
      "train: iter 678  trainloss -1514.01886  validloss -1371.84099±0.00000  bestvalidloss -1540.04841  last_update 11\n",
      "train: iter 679  trainloss -1595.25734  validloss -1469.50853±0.00000  bestvalidloss -1540.04841  last_update 12\n",
      "train: iter 680  trainloss -1282.56816  validloss -1423.94218±0.00000  bestvalidloss -1540.04841  last_update 13\n",
      "train: iter 681  trainloss -1523.51951  validloss -1190.01536±0.00000  bestvalidloss -1540.04841  last_update 14\n",
      "train: iter 682  trainloss -1556.51681  validloss -1348.59233±0.00000  bestvalidloss -1540.04841  last_update 15\n",
      "train: iter 683  trainloss -1597.06890  validloss -1511.44521±0.00000  bestvalidloss -1540.04841  last_update 16\n",
      "train: iter 684  trainloss -1521.57675  validloss -1504.24875±0.00000  bestvalidloss -1540.04841  last_update 17\n",
      "train: iter 685  trainloss -1472.04044  validloss -1017.42177±0.00000  bestvalidloss -1540.04841  last_update 18\n",
      "train: iter 686  trainloss -1541.26207  validloss -1497.37562±0.00000  bestvalidloss -1540.04841  last_update 19\n",
      "train: iter 687  trainloss -1607.65623  validloss -1461.82556±0.00000  bestvalidloss -1540.04841  last_update 20\n",
      "train: iter 688  trainloss -1590.38787  validloss -1535.53680±0.00000  bestvalidloss -1540.04841  last_update 21\n",
      "train: iter 689  trainloss -1590.99579  validloss -1503.43119±0.00000  bestvalidloss -1540.04841  last_update 22\n",
      "train: iter 690  trainloss -1492.65648  validloss -1508.02233±0.00000  bestvalidloss -1540.04841  last_update 23\n",
      "train: iter 691  trainloss -1320.58821  validloss -812.86575±0.00000  bestvalidloss -1540.04841  last_update 24\n",
      "train: iter 692  trainloss -1566.64752  validloss -1416.71264±0.00000  bestvalidloss -1540.04841  last_update 25\n",
      "train: iter 693  trainloss -1596.58811  validloss -1364.45194±0.00000  bestvalidloss -1540.04841  last_update 26\n",
      "train: iter 694  trainloss -1567.86851  validloss -1503.55278±0.00000  bestvalidloss -1540.04841  last_update 27\n",
      "train: iter 695  trainloss -1535.51875  validloss -1427.00395±0.00000  bestvalidloss -1540.04841  last_update 28\n",
      "train: iter 696  trainloss -1552.53941  validloss -1502.33308±0.00000  bestvalidloss -1540.04841  last_update 29\n",
      "train: iter 697  trainloss -1602.23988  validloss -1506.56689±0.00000  bestvalidloss -1540.04841  last_update 30\n",
      "train: iter 698  trainloss -1621.16950  validloss -1561.18785±0.00000  bestvalidloss -1561.18785  last_update 0\n",
      "train: iter 699  trainloss -1575.54198  validloss -1546.47554±0.00000  bestvalidloss -1561.18785  last_update 1\n",
      "train: iter 700  trainloss -1504.72136  validloss -1364.12300±0.00000  bestvalidloss -1561.18785  last_update 2\n",
      "train: iter 701  trainloss -1575.39294  validloss -1485.37776±0.00000  bestvalidloss -1561.18785  last_update 3\n",
      "train: iter 702  trainloss -1422.79617  validloss -1072.14287±0.00000  bestvalidloss -1561.18785  last_update 4\n",
      "train: iter 703  trainloss -1629.71266  validloss -1496.40407±0.00000  bestvalidloss -1561.18785  last_update 5\n",
      "train: iter 704  trainloss -1585.81214  validloss -1546.75872±0.00000  bestvalidloss -1561.18785  last_update 6\n",
      "train: iter 705  trainloss -1535.32602  validloss -1530.42818±0.00000  bestvalidloss -1561.18785  last_update 7\n",
      "train: iter 706  trainloss -1543.26959  validloss -1237.79826±0.00000  bestvalidloss -1561.18785  last_update 8\n",
      "train: iter 707  trainloss -1555.22747  validloss -1525.85938±0.00000  bestvalidloss -1561.18785  last_update 9\n",
      "train: iter 708  trainloss -1555.83491  validloss -1461.50988±0.00000  bestvalidloss -1561.18785  last_update 10\n",
      "train: iter 709  trainloss -1468.64629  validloss -1089.63592±0.00000  bestvalidloss -1561.18785  last_update 11\n",
      "train: iter 710  trainloss -1601.70276  validloss -1479.93254±0.00000  bestvalidloss -1561.18785  last_update 12\n",
      "train: iter 711  trainloss -1609.42623  validloss -1523.59981±0.00000  bestvalidloss -1561.18785  last_update 13\n",
      "train: iter 712  trainloss -1608.41322  validloss -1515.31061±0.00000  bestvalidloss -1561.18785  last_update 14\n",
      "train: iter 713  trainloss -1615.24208  validloss -1537.99733±0.00000  bestvalidloss -1561.18785  last_update 15\n",
      "train: iter 714  trainloss -1596.89836  validloss -1563.03688±0.00000  bestvalidloss -1563.03688  last_update 0\n",
      "train: iter 715  trainloss -1470.80357  validloss -1421.21837±0.00000  bestvalidloss -1563.03688  last_update 1\n",
      "train: iter 716  trainloss -1555.59671  validloss -1317.43553±0.00000  bestvalidloss -1563.03688  last_update 2\n",
      "train: iter 717  trainloss -1616.95749  validloss -1542.91506±0.00000  bestvalidloss -1563.03688  last_update 3\n",
      "train: iter 718  trainloss -1503.27768  validloss -1482.47031±0.00000  bestvalidloss -1563.03688  last_update 4\n",
      "train: iter 719  trainloss -1612.11928  validloss -1511.75971±0.00000  bestvalidloss -1563.03688  last_update 5\n",
      "train: iter 720  trainloss -1468.62938  validloss -1363.51665±0.00000  bestvalidloss -1563.03688  last_update 6\n",
      "train: iter 721  trainloss -1581.63175  validloss -1322.81725±0.00000  bestvalidloss -1563.03688  last_update 7\n",
      "train: iter 722  trainloss -1543.48474  validloss -1532.16241±0.00000  bestvalidloss -1563.03688  last_update 8\n",
      "train: iter 723  trainloss -1528.97293  validloss -1361.59547±0.00000  bestvalidloss -1563.03688  last_update 9\n",
      "train: iter 724  trainloss -1525.36691  validloss -1406.79901±0.00000  bestvalidloss -1563.03688  last_update 10\n",
      "train: iter 725  trainloss -1623.45785  validloss -1480.89183±0.00000  bestvalidloss -1563.03688  last_update 11\n",
      "train: iter 726  trainloss -1606.79814  validloss -1509.45769±0.00000  bestvalidloss -1563.03688  last_update 12\n",
      "train: iter 727  trainloss -1340.39875  validloss -1407.44352±0.00000  bestvalidloss -1563.03688  last_update 13\n",
      "train: iter 728  trainloss -1256.42008  validloss -952.56547±0.00000  bestvalidloss -1563.03688  last_update 14\n",
      "train: iter 729  trainloss -1526.61282  validloss -1389.96674±0.00000  bestvalidloss -1563.03688  last_update 15\n",
      "train: iter 730  trainloss -1596.86613  validloss -1367.81249±0.00000  bestvalidloss -1563.03688  last_update 16\n",
      "train: iter 731  trainloss -1561.33448  validloss -1508.88213±0.00000  bestvalidloss -1563.03688  last_update 17\n",
      "train: iter 732  trainloss -1601.24954  validloss -1502.53172±0.00000  bestvalidloss -1563.03688  last_update 18\n",
      "train: iter 733  trainloss -1640.32975  validloss -1550.90923±0.00000  bestvalidloss -1563.03688  last_update 19\n",
      "train: iter 734  trainloss -1597.61629  validloss -1571.74067±0.00000  bestvalidloss -1571.74067  last_update 0\n",
      "train: iter 735  trainloss -1598.63191  validloss -1405.87273±0.00000  bestvalidloss -1571.74067  last_update 1\n",
      "train: iter 736  trainloss -1528.60189  validloss -1415.71076±0.00000  bestvalidloss -1571.74067  last_update 2\n",
      "train: iter 737  trainloss -1573.20504  validloss -1440.99811±0.00000  bestvalidloss -1571.74067  last_update 3\n",
      "train: iter 738  trainloss -1608.13435  validloss -1459.92380±0.00000  bestvalidloss -1571.74067  last_update 4\n",
      "train: iter 739  trainloss -1543.55548  validloss -1514.37517±0.00000  bestvalidloss -1571.74067  last_update 5\n",
      "train: iter 740  trainloss -1586.02055  validloss -1497.85565±0.00000  bestvalidloss -1571.74067  last_update 6\n",
      "train: iter 741  trainloss -1554.91613  validloss -1543.27937±0.00000  bestvalidloss -1571.74067  last_update 7\n",
      "train: iter 742  trainloss -1465.30500  validloss -1467.65440±0.00000  bestvalidloss -1571.74067  last_update 8\n",
      "train: iter 743  trainloss -1596.72085  validloss -1313.37358±0.00000  bestvalidloss -1571.74067  last_update 9\n",
      "train: iter 744  trainloss -1633.67046  validloss -1568.38096±0.00000  bestvalidloss -1571.74067  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 745  trainloss -1573.53338  validloss -1436.25709±0.00000  bestvalidloss -1571.74067  last_update 11\n",
      "train: iter 746  trainloss -1531.14834  validloss -1443.63170±0.00000  bestvalidloss -1571.74067  last_update 12\n",
      "train: iter 747  trainloss -1157.17204  validloss -734.06173±0.00000  bestvalidloss -1571.74067  last_update 13\n",
      "train: iter 748  trainloss -1467.18626  validloss -1187.95956±0.00000  bestvalidloss -1571.74067  last_update 14\n",
      "train: iter 749  trainloss -1523.37618  validloss -1382.25173±0.00000  bestvalidloss -1571.74067  last_update 15\n",
      "train: iter 750  trainloss -1597.24852  validloss -1419.27157±0.00000  bestvalidloss -1571.74067  last_update 16\n",
      "train: iter 751  trainloss -1573.37901  validloss -1520.31818±0.00000  bestvalidloss -1571.74067  last_update 17\n",
      "train: iter 752  trainloss -1578.12945  validloss -1469.26826±0.00000  bestvalidloss -1571.74067  last_update 18\n",
      "train: iter 753  trainloss -1565.65855  validloss -1482.33481±0.00000  bestvalidloss -1571.74067  last_update 19\n",
      "train: iter 754  trainloss -1517.04476  validloss -781.04028±0.00000  bestvalidloss -1571.74067  last_update 20\n",
      "train: iter 755  trainloss -1460.64990  validloss -1416.73655±0.00000  bestvalidloss -1571.74067  last_update 21\n",
      "train: iter 756  trainloss -1611.88994  validloss -1444.48360±0.00000  bestvalidloss -1571.74067  last_update 22\n",
      "train: iter 757  trainloss -1612.33363  validloss -1493.42373±0.00000  bestvalidloss -1571.74067  last_update 23\n",
      "train: iter 758  trainloss -1628.87814  validloss -1496.58637±0.00000  bestvalidloss -1571.74067  last_update 24\n",
      "train: iter 759  trainloss -1590.34944  validloss -1533.29951±0.00000  bestvalidloss -1571.74067  last_update 25\n",
      "train: iter 760  trainloss -1570.18952  validloss -1370.53851±0.00000  bestvalidloss -1571.74067  last_update 26\n",
      "train: iter 761  trainloss -1475.72882  validloss -1451.32660±0.00000  bestvalidloss -1571.74067  last_update 27\n",
      "train: iter 762  trainloss -1556.00462  validloss -1478.60084±0.00000  bestvalidloss -1571.74067  last_update 28\n",
      "train: iter 763  trainloss -1603.10590  validloss -1262.62671±0.00000  bestvalidloss -1571.74067  last_update 29\n",
      "train: iter 764  trainloss -1573.00381  validloss -1508.30385±0.00000  bestvalidloss -1571.74067  last_update 30\n",
      "train: iter 765  trainloss -1612.64926  validloss -1506.97265±0.00000  bestvalidloss -1571.74067  last_update 31\n",
      "train: iter 766  trainloss -1573.90567  validloss -1496.19738±0.00000  bestvalidloss -1571.74067  last_update 32\n",
      "train: iter 767  trainloss -1591.61246  validloss -1501.40736±0.00000  bestvalidloss -1571.74067  last_update 33\n",
      "train: iter 768  trainloss -1640.08469  validloss -1449.21474±0.00000  bestvalidloss -1571.74067  last_update 34\n",
      "train: iter 769  trainloss -1384.16516  validloss -1402.41317±0.00000  bestvalidloss -1571.74067  last_update 35\n",
      "train: iter 770  trainloss -1515.75930  validloss -1139.23232±0.00000  bestvalidloss -1571.74067  last_update 36\n",
      "train: iter 771  trainloss -1591.20843  validloss -1465.74759±0.00000  bestvalidloss -1571.74067  last_update 37\n",
      "train: iter 772  trainloss -1606.27302  validloss -1519.72461±0.00000  bestvalidloss -1571.74067  last_update 38\n",
      "train: iter 773  trainloss -1625.01777  validloss -1487.41116±0.00000  bestvalidloss -1571.74067  last_update 39\n",
      "train: iter 774  trainloss -1617.77693  validloss -1555.54794±0.00000  bestvalidloss -1571.74067  last_update 40\n",
      "train: iter 775  trainloss -1612.35225  validloss -1495.00408±0.00000  bestvalidloss -1571.74067  last_update 41\n",
      "train: iter 776  trainloss -1576.91557  validloss -1512.70385±0.00000  bestvalidloss -1571.74067  last_update 42\n",
      "train: iter 777  trainloss -1571.31969  validloss -1468.68947±0.00000  bestvalidloss -1571.74067  last_update 43\n",
      "train: iter 778  trainloss -1654.52826  validloss -1508.18390±0.00000  bestvalidloss -1571.74067  last_update 44\n",
      "train: iter 779  trainloss -1419.04521  validloss -1451.22362±0.00000  bestvalidloss -1571.74067  last_update 45\n",
      "train: iter 780  trainloss -1520.38454  validloss -1056.76701±0.00000  bestvalidloss -1571.74067  last_update 46\n",
      "train: iter 781  trainloss -1624.72729  validloss -1502.17125±0.00000  bestvalidloss -1571.74067  last_update 47\n",
      "train: iter 782  trainloss -1637.28624  validloss -1542.24477±0.00000  bestvalidloss -1571.74067  last_update 48\n",
      "train: iter 783  trainloss -1448.35406  validloss -1552.68550±0.00000  bestvalidloss -1571.74067  last_update 49\n",
      "train: iter 784  trainloss -1595.35525  validloss -1465.94243±0.00000  bestvalidloss -1571.74067  last_update 50\n",
      "train: iter 785  trainloss -1639.58997  validloss -1520.22752±0.00000  bestvalidloss -1571.74067  last_update 51\n",
      "train: iter 786  trainloss -1617.16124  validloss -1418.25481±0.00000  bestvalidloss -1571.74067  last_update 52\n",
      "train: iter 787  trainloss -1614.97869  validloss -1500.21606±0.00000  bestvalidloss -1571.74067  last_update 53\n",
      "train: iter 788  trainloss -1602.86240  validloss -1512.55077±0.00000  bestvalidloss -1571.74067  last_update 54\n",
      "train: iter 789  trainloss -1628.83955  validloss -1497.43055±0.00000  bestvalidloss -1571.74067  last_update 55\n",
      "train: iter 790  trainloss -1622.93842  validloss -1573.18641±0.00000  bestvalidloss -1573.18641  last_update 0\n",
      "train: iter 791  trainloss -1644.97274  validloss -1482.79284±0.00000  bestvalidloss -1573.18641  last_update 1\n",
      "train: iter 792  trainloss -1642.56285  validloss -1569.48618±0.00000  bestvalidloss -1573.18641  last_update 2\n",
      "train: iter 793  trainloss -1393.14550  validloss -1215.69836±0.00000  bestvalidloss -1573.18641  last_update 3\n",
      "train: iter 794  trainloss -1621.77314  validloss -1464.96348±0.00000  bestvalidloss -1573.18641  last_update 4\n",
      "train: iter 795  trainloss -1638.86699  validloss -1490.07363±0.00000  bestvalidloss -1573.18641  last_update 5\n",
      "train: iter 796  trainloss -1640.59054  validloss -1526.73475±0.00000  bestvalidloss -1573.18641  last_update 6\n",
      "train: iter 797  trainloss -1659.09384  validloss -1538.58664±0.00000  bestvalidloss -1573.18641  last_update 7\n",
      "train: iter 798  trainloss -1411.66797  validloss -1597.83619±0.00000  bestvalidloss -1597.83619  last_update 0\n",
      "train: iter 799  trainloss -1472.49593  validloss -1366.99777±0.00000  bestvalidloss -1597.83619  last_update 1\n",
      "train: iter 800  trainloss -1610.89445  validloss -1426.66053±0.00000  bestvalidloss -1597.83619  last_update 2\n",
      "train: iter 801  trainloss -1565.82328  validloss -1521.33825±0.00000  bestvalidloss -1597.83619  last_update 3\n",
      "train: iter 802  trainloss -1642.57735  validloss -1422.33993±0.00000  bestvalidloss -1597.83619  last_update 4\n",
      "train: iter 803  trainloss -1623.86756  validloss -1552.46780±0.00000  bestvalidloss -1597.83619  last_update 5\n",
      "train: iter 804  trainloss -1642.92250  validloss -1482.44687±0.00000  bestvalidloss -1597.83619  last_update 6\n",
      "train: iter 805  trainloss -1606.01319  validloss -1550.09362±0.00000  bestvalidloss -1597.83619  last_update 7\n",
      "train: iter 806  trainloss -1609.85465  validloss -1492.83123±0.00000  bestvalidloss -1597.83619  last_update 8\n",
      "train: iter 807  trainloss -1512.29636  validloss -1522.75102±0.00000  bestvalidloss -1597.83619  last_update 9\n",
      "train: iter 808  trainloss -1628.07431  validloss -1373.29359±0.00000  bestvalidloss -1597.83619  last_update 10\n",
      "train: iter 809  trainloss -1643.96330  validloss -1466.52505±0.00000  bestvalidloss -1597.83619  last_update 11\n",
      "train: iter 810  trainloss -1493.48365  validloss -1556.16388±0.00000  bestvalidloss -1597.83619  last_update 12\n",
      "train: iter 811  trainloss -1407.48586  validloss 235.31057±0.00000  bestvalidloss -1597.83619  last_update 13\n",
      "train: iter 812  trainloss -1631.97789  validloss -1492.55907±0.00000  bestvalidloss -1597.83619  last_update 14\n",
      "train: iter 813  trainloss -1597.38898  validloss -1549.42545±0.00000  bestvalidloss -1597.83619  last_update 15\n",
      "train: iter 814  trainloss -1582.21968  validloss -1130.23829±0.00000  bestvalidloss -1597.83619  last_update 16\n",
      "train: iter 815  trainloss -1609.56259  validloss -1470.07310±0.00000  bestvalidloss -1597.83619  last_update 17\n",
      "train: iter 816  trainloss -1606.03743  validloss -1538.21648±0.00000  bestvalidloss -1597.83619  last_update 18\n",
      "train: iter 817  trainloss -1536.27304  validloss -1429.89264±0.00000  bestvalidloss -1597.83619  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 818  trainloss -1627.77669  validloss -1450.86417±0.00000  bestvalidloss -1597.83619  last_update 20\n",
      "train: iter 819  trainloss -1657.51322  validloss -1551.70655±0.00000  bestvalidloss -1597.83619  last_update 21\n",
      "train: iter 820  trainloss -1674.40149  validloss -1557.82600±0.00000  bestvalidloss -1597.83619  last_update 22\n",
      "train: iter 821  trainloss -1527.25594  validloss -1554.51194±0.00000  bestvalidloss -1597.83619  last_update 23\n",
      "train: iter 822  trainloss -1517.85128  validloss -1220.23063±0.00000  bestvalidloss -1597.83619  last_update 24\n",
      "train: iter 823  trainloss -1638.22470  validloss -1490.42378±0.00000  bestvalidloss -1597.83619  last_update 25\n",
      "train: iter 824  trainloss -1641.27314  validloss -1508.20582±0.00000  bestvalidloss -1597.83619  last_update 26\n",
      "train: iter 825  trainloss -1552.51803  validloss -1424.32051±0.00000  bestvalidloss -1597.83619  last_update 27\n",
      "train: iter 826  trainloss -1631.18138  validloss -1496.27684±0.00000  bestvalidloss -1597.83619  last_update 28\n",
      "train: iter 827  trainloss -1566.64324  validloss -1515.64093±0.00000  bestvalidloss -1597.83619  last_update 29\n",
      "train: iter 828  trainloss -1296.62059  validloss 146.92028±0.00000  bestvalidloss -1597.83619  last_update 30\n",
      "train: iter 829  trainloss -1567.93428  validloss -1386.85293±0.00000  bestvalidloss -1597.83619  last_update 31\n",
      "train: iter 830  trainloss -1619.14931  validloss -1544.04123±0.00000  bestvalidloss -1597.83619  last_update 32\n",
      "train: iter 831  trainloss -1643.77461  validloss -1526.77164±0.00000  bestvalidloss -1597.83619  last_update 33\n",
      "train: iter 832  trainloss -1649.53579  validloss -1549.57886±0.00000  bestvalidloss -1597.83619  last_update 34\n",
      "train: iter 833  trainloss -1600.67752  validloss -1474.98881±0.00000  bestvalidloss -1597.83619  last_update 35\n",
      "train: iter 834  trainloss -1499.87147  validloss -1218.10683±0.00000  bestvalidloss -1597.83619  last_update 36\n",
      "train: iter 835  trainloss -1631.21442  validloss -1559.17478±0.00000  bestvalidloss -1597.83619  last_update 37\n",
      "train: iter 836  trainloss -1617.61718  validloss -1424.06106±0.00000  bestvalidloss -1597.83619  last_update 38\n",
      "train: iter 837  trainloss -1657.68967  validloss -1510.34844±0.00000  bestvalidloss -1597.83619  last_update 39\n",
      "train: iter 838  trainloss -1519.79953  validloss -1468.77785±0.00000  bestvalidloss -1597.83619  last_update 40\n",
      "train: iter 839  trainloss -1628.27616  validloss -1455.73212±0.00000  bestvalidloss -1597.83619  last_update 41\n",
      "train: iter 840  trainloss -1627.74525  validloss -1549.02707±0.00000  bestvalidloss -1597.83619  last_update 42\n",
      "train: iter 841  trainloss -1592.54492  validloss -1486.39903±0.00000  bestvalidloss -1597.83619  last_update 43\n",
      "train: iter 842  trainloss -1574.46987  validloss -1131.34625±0.00000  bestvalidloss -1597.83619  last_update 44\n",
      "train: iter 843  trainloss -1665.44729  validloss -1530.31417±0.00000  bestvalidloss -1597.83619  last_update 45\n",
      "train: iter 844  trainloss -1632.07360  validloss -1581.02059±0.00000  bestvalidloss -1597.83619  last_update 46\n",
      "train: iter 845  trainloss -1604.18751  validloss -1517.62155±0.00000  bestvalidloss -1597.83619  last_update 47\n",
      "train: iter 846  trainloss -1647.24091  validloss -1485.56613±0.00000  bestvalidloss -1597.83619  last_update 48\n",
      "train: iter 847  trainloss -1646.88524  validloss -1600.64031±0.00000  bestvalidloss -1600.64031  last_update 0\n",
      "train: iter 848  trainloss -1609.03356  validloss -1575.99403±0.00000  bestvalidloss -1600.64031  last_update 1\n",
      "train: iter 849  trainloss -1655.89454  validloss -1533.44977±0.00000  bestvalidloss -1600.64031  last_update 2\n",
      "train: iter 850  trainloss -1612.39743  validloss -1565.21949±0.00000  bestvalidloss -1600.64031  last_update 3\n",
      "train: iter 851  trainloss -1535.03702  validloss -1345.39846±0.00000  bestvalidloss -1600.64031  last_update 4\n",
      "train: iter 852  trainloss -1574.82430  validloss -1501.13537±0.00000  bestvalidloss -1600.64031  last_update 5\n",
      "train: iter 853  trainloss -1334.07601  validloss -1292.71610±0.00000  bestvalidloss -1600.64031  last_update 6\n",
      "train: iter 854  trainloss -1589.72529  validloss -1302.97662±0.00000  bestvalidloss -1600.64031  last_update 7\n",
      "train: iter 855  trainloss -1603.73574  validloss -1545.85512±0.00000  bestvalidloss -1600.64031  last_update 8\n",
      "train: iter 856  trainloss -1632.65982  validloss -1479.82111±0.00000  bestvalidloss -1600.64031  last_update 9\n",
      "train: iter 857  trainloss -1592.75074  validloss -1421.24678±0.00000  bestvalidloss -1600.64031  last_update 10\n",
      "train: iter 858  trainloss -1656.37101  validloss -1582.90172±0.00000  bestvalidloss -1600.64031  last_update 11\n",
      "train: iter 859  trainloss -1651.90432  validloss -1591.70012±0.00000  bestvalidloss -1600.64031  last_update 12\n",
      "train: iter 860  trainloss -1637.10893  validloss -1544.31664±0.00000  bestvalidloss -1600.64031  last_update 13\n",
      "train: iter 861  trainloss -1653.39557  validloss -1559.00579±0.00000  bestvalidloss -1600.64031  last_update 14\n",
      "train: iter 862  trainloss -1595.82879  validloss -1459.49463±0.00000  bestvalidloss -1600.64031  last_update 15\n",
      "train: iter 863  trainloss -1659.61619  validloss -1515.98512±0.00000  bestvalidloss -1600.64031  last_update 16\n",
      "train: iter 864  trainloss -1567.40570  validloss -1595.40190±0.00000  bestvalidloss -1600.64031  last_update 17\n",
      "train: iter 865  trainloss -1604.22881  validloss -1522.67081±0.00000  bestvalidloss -1600.64031  last_update 18\n",
      "train: iter 866  trainloss -1583.27351  validloss -1337.14022±0.00000  bestvalidloss -1600.64031  last_update 19\n",
      "train: iter 867  trainloss -1645.28873  validloss -1511.04346±0.00000  bestvalidloss -1600.64031  last_update 20\n",
      "train: iter 868  trainloss -1506.24975  validloss -1540.98497±0.00000  bestvalidloss -1600.64031  last_update 21\n",
      "train: iter 869  trainloss -1604.80079  validloss -1350.87250±0.00000  bestvalidloss -1600.64031  last_update 22\n",
      "train: iter 870  trainloss -1654.26288  validloss -1519.58520±0.00000  bestvalidloss -1600.64031  last_update 23\n",
      "train: iter 871  trainloss -1593.27217  validloss -1501.89614±0.00000  bestvalidloss -1600.64031  last_update 24\n",
      "train: iter 872  trainloss -1657.82629  validloss -1496.71517±0.00000  bestvalidloss -1600.64031  last_update 25\n",
      "train: iter 873  trainloss -1669.16873  validloss -1583.89912±0.00000  bestvalidloss -1600.64031  last_update 26\n",
      "train: iter 874  trainloss -1594.83490  validloss -1573.76621±0.00000  bestvalidloss -1600.64031  last_update 27\n",
      "train: iter 875  trainloss -1631.94907  validloss -1417.13263±0.00000  bestvalidloss -1600.64031  last_update 28\n",
      "train: iter 876  trainloss -1616.49160  validloss -1486.22990±0.00000  bestvalidloss -1600.64031  last_update 29\n",
      "train: iter 877  trainloss -1610.91166  validloss -1526.89193±0.00000  bestvalidloss -1600.64031  last_update 30\n",
      "train: iter 878  trainloss -1529.10973  validloss -1498.50663±0.00000  bestvalidloss -1600.64031  last_update 31\n",
      "train: iter 879  trainloss -1654.12409  validloss -1517.13544±0.00000  bestvalidloss -1600.64031  last_update 32\n",
      "train: iter 880  trainloss -1677.94645  validloss -1583.23456±0.00000  bestvalidloss -1600.64031  last_update 33\n",
      "train: iter 881  trainloss -1614.27646  validloss -1583.68143±0.00000  bestvalidloss -1600.64031  last_update 34\n",
      "train: iter 882  trainloss -1430.10931  validloss -948.49391±0.00000  bestvalidloss -1600.64031  last_update 35\n",
      "train: iter 883  trainloss -1651.15640  validloss -1504.49345±0.00000  bestvalidloss -1600.64031  last_update 36\n",
      "train: iter 884  trainloss -1668.99920  validloss -1580.35006±0.00000  bestvalidloss -1600.64031  last_update 37\n",
      "train: iter 885  trainloss -1616.08592  validloss -1560.90381±0.00000  bestvalidloss -1600.64031  last_update 38\n",
      "train: iter 886  trainloss -1591.79400  validloss -1463.20663±0.00000  bestvalidloss -1600.64031  last_update 39\n",
      "train: iter 887  trainloss -1577.99320  validloss -1508.34580±0.00000  bestvalidloss -1600.64031  last_update 40\n",
      "train: iter 888  trainloss -1663.10501  validloss -1579.63362±0.00000  bestvalidloss -1600.64031  last_update 41\n",
      "train: iter 889  trainloss -1607.34952  validloss -1499.40661±0.00000  bestvalidloss -1600.64031  last_update 42\n",
      "train: iter 890  trainloss -1676.18766  validloss -1515.51402±0.00000  bestvalidloss -1600.64031  last_update 43\n",
      "train: iter 891  trainloss -1537.10923  validloss -1392.90794±0.00000  bestvalidloss -1600.64031  last_update 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 892  trainloss -1630.46935  validloss -1507.75667±0.00000  bestvalidloss -1600.64031  last_update 45\n",
      "train: iter 893  trainloss -1642.37918  validloss -1538.80390±0.00000  bestvalidloss -1600.64031  last_update 46\n",
      "train: iter 894  trainloss -1675.05644  validloss -1508.76505±0.00000  bestvalidloss -1600.64031  last_update 47\n",
      "train: iter 895  trainloss -1678.15867  validloss -1599.18747±0.00000  bestvalidloss -1600.64031  last_update 48\n",
      "train: iter 896  trainloss -1561.84812  validloss -1552.54015±0.00000  bestvalidloss -1600.64031  last_update 49\n",
      "train: iter 897  trainloss -1557.72708  validloss -1349.60877±0.00000  bestvalidloss -1600.64031  last_update 50\n",
      "train: iter 898  trainloss -1668.41488  validloss -1501.49983±0.00000  bestvalidloss -1600.64031  last_update 51\n",
      "train: iter 899  trainloss -1608.46246  validloss -1425.25883±0.00000  bestvalidloss -1600.64031  last_update 52\n",
      "train: iter 900  trainloss -1609.40287  validloss -1392.12366±0.00000  bestvalidloss -1600.64031  last_update 53\n",
      "train: iter 901  trainloss -1604.61287  validloss -1378.86106±0.00000  bestvalidloss -1600.64031  last_update 54\n",
      "train: iter 902  trainloss -1645.14971  validloss -1467.52379±0.00000  bestvalidloss -1600.64031  last_update 55\n",
      "train: iter 903  trainloss -1292.48616  validloss -1454.96739±0.00000  bestvalidloss -1600.64031  last_update 56\n",
      "train: iter 904  trainloss -1606.36366  validloss -1359.36851±0.00000  bestvalidloss -1600.64031  last_update 57\n",
      "train: iter 905  trainloss -1671.77452  validloss -1561.28780±0.00000  bestvalidloss -1600.64031  last_update 58\n",
      "train: iter 906  trainloss -1534.88873  validloss -1551.89835±0.00000  bestvalidloss -1600.64031  last_update 59\n",
      "train: iter 907  trainloss -1606.29284  validloss -1363.39303±0.00000  bestvalidloss -1600.64031  last_update 60\n",
      "train: iter 908  trainloss -1651.72396  validloss -1544.29278±0.00000  bestvalidloss -1600.64031  last_update 61\n",
      "train: iter 909  trainloss -1649.78309  validloss -1548.64064±0.00000  bestvalidloss -1600.64031  last_update 62\n",
      "train: iter 910  trainloss -1674.97349  validloss -1514.79388±0.00000  bestvalidloss -1600.64031  last_update 63\n",
      "train: iter 911  trainloss -1681.12975  validloss -1600.02037±0.00000  bestvalidloss -1600.64031  last_update 64\n",
      "train: iter 912  trainloss -1613.39914  validloss -1588.18430±0.00000  bestvalidloss -1600.64031  last_update 65\n",
      "train: iter 913  trainloss -1438.70586  validloss -853.62831±0.00000  bestvalidloss -1600.64031  last_update 66\n",
      "train: iter 914  trainloss -1609.64945  validloss -1404.02727±0.00000  bestvalidloss -1600.64031  last_update 67\n",
      "train: iter 915  trainloss -1655.82657  validloss -1552.01403±0.00000  bestvalidloss -1600.64031  last_update 68\n",
      "train: iter 916  trainloss -1524.01287  validloss -1503.99791±0.00000  bestvalidloss -1600.64031  last_update 69\n",
      "train: iter 917  trainloss -1635.79077  validloss -1424.14495±0.00000  bestvalidloss -1600.64031  last_update 70\n",
      "train: iter 918  trainloss -1686.40683  validloss -1568.16976±0.00000  bestvalidloss -1600.64031  last_update 71\n",
      "train: iter 919  trainloss -1685.86281  validloss -1558.58973±0.00000  bestvalidloss -1600.64031  last_update 72\n",
      "train: iter 920  trainloss -1663.58427  validloss -1516.25371±0.00000  bestvalidloss -1600.64031  last_update 73\n",
      "train: iter 921  trainloss -1675.39646  validloss -1526.80396±0.00000  bestvalidloss -1600.64031  last_update 74\n",
      "train: iter 922  trainloss -1400.34553  validloss -1483.44129±0.00000  bestvalidloss -1600.64031  last_update 75\n",
      "train: iter 923  trainloss -1457.92040  validloss -1468.21242±0.00000  bestvalidloss -1600.64031  last_update 76\n",
      "train: iter 924  trainloss -1627.00081  validloss -1509.92724±0.00000  bestvalidloss -1600.64031  last_update 77\n",
      "train: iter 925  trainloss -1663.35879  validloss -1558.92164±0.00000  bestvalidloss -1600.64031  last_update 78\n",
      "train: iter 926  trainloss -1571.52537  validloss -1577.46692±0.00000  bestvalidloss -1600.64031  last_update 79\n",
      "train: iter 927  trainloss -1616.12947  validloss -1542.57541±0.00000  bestvalidloss -1600.64031  last_update 80\n",
      "train: iter 928  trainloss -1635.31439  validloss -1437.14492±0.00000  bestvalidloss -1600.64031  last_update 81\n",
      "train: iter 929  trainloss -1644.80845  validloss -1542.74960±0.00000  bestvalidloss -1600.64031  last_update 82\n",
      "train: iter 930  trainloss -1681.40545  validloss -1555.93039±0.00000  bestvalidloss -1600.64031  last_update 83\n",
      "train: iter 931  trainloss -1612.20726  validloss -1595.49776±0.00000  bestvalidloss -1600.64031  last_update 84\n",
      "train: iter 932  trainloss -1674.15836  validloss -1507.58882±0.00000  bestvalidloss -1600.64031  last_update 85\n",
      "train: iter 933  trainloss -1617.32500  validloss -1539.85703±0.00000  bestvalidloss -1600.64031  last_update 86\n",
      "train: iter 934  trainloss -1427.95468  validloss -572.11778±0.00000  bestvalidloss -1600.64031  last_update 87\n",
      "train: iter 935  trainloss -1647.45893  validloss -1498.38634±0.00000  bestvalidloss -1600.64031  last_update 88\n",
      "train: iter 936  trainloss -1676.13311  validloss -1563.47093±0.00000  bestvalidloss -1600.64031  last_update 89\n",
      "train: iter 937  trainloss -1661.70322  validloss -1528.33814±0.00000  bestvalidloss -1600.64031  last_update 90\n",
      "train: iter 938  trainloss -1670.92464  validloss -1575.55074±0.00000  bestvalidloss -1600.64031  last_update 91\n",
      "train: iter 939  trainloss -1682.19548  validloss -1595.22133±0.00000  bestvalidloss -1600.64031  last_update 92\n",
      "train: iter 940  trainloss -1662.21063  validloss -1387.71649±0.00000  bestvalidloss -1600.64031  last_update 93\n",
      "train: iter 941  trainloss -1454.61407  validloss -1380.35103±0.00000  bestvalidloss -1600.64031  last_update 94\n",
      "train: iter 942  trainloss -1671.08911  validloss -1484.80518±0.00000  bestvalidloss -1600.64031  last_update 95\n",
      "train: iter 943  trainloss -1675.31266  validloss -1524.49391±0.00000  bestvalidloss -1600.64031  last_update 96\n",
      "train: iter 944  trainloss -1640.55370  validloss -1432.85076±0.00000  bestvalidloss -1600.64031  last_update 97\n",
      "train: iter 945  trainloss -1692.94981  validloss -1607.15117±0.00000  bestvalidloss -1607.15117  last_update 0\n",
      "train: iter 946  trainloss -1686.39400  validloss -1572.61426±0.00000  bestvalidloss -1607.15117  last_update 1\n",
      "train: iter 947  trainloss -1560.32109  validloss -1376.98886±0.00000  bestvalidloss -1607.15117  last_update 2\n",
      "train: iter 948  trainloss -1533.93099  validloss -967.63587±0.00000  bestvalidloss -1607.15117  last_update 3\n",
      "train: iter 949  trainloss -1654.71508  validloss -1540.98694±0.00000  bestvalidloss -1607.15117  last_update 4\n",
      "train: iter 950  trainloss -1664.91357  validloss -1565.28145±0.00000  bestvalidloss -1607.15117  last_update 5\n",
      "train: iter 951  trainloss -1669.50488  validloss -1542.43371±0.00000  bestvalidloss -1607.15117  last_update 6\n",
      "train: iter 952  trainloss -1684.75592  validloss -1589.13691±0.00000  bestvalidloss -1607.15117  last_update 7\n",
      "train: iter 953  trainloss -1673.24348  validloss -1504.47053±0.00000  bestvalidloss -1607.15117  last_update 8\n",
      "train: iter 954  trainloss -1689.68485  validloss -1587.91574±0.00000  bestvalidloss -1607.15117  last_update 9\n",
      "train: iter 955  trainloss -1661.45519  validloss -1563.44807±0.00000  bestvalidloss -1607.15117  last_update 10\n",
      "train: iter 956  trainloss -1396.38763  validloss -1435.03570±0.00000  bestvalidloss -1607.15117  last_update 11\n",
      "train: iter 957  trainloss -1612.04556  validloss -1478.13643±0.00000  bestvalidloss -1607.15117  last_update 12\n",
      "train: iter 958  trainloss -1622.56926  validloss -1485.18267±0.00000  bestvalidloss -1607.15117  last_update 13\n",
      "train: iter 959  trainloss -1687.08802  validloss -1528.73957±0.00000  bestvalidloss -1607.15117  last_update 14\n",
      "train: iter 960  trainloss -1680.80569  validloss -1596.43268±0.00000  bestvalidloss -1607.15117  last_update 15\n",
      "train: iter 961  trainloss -1694.64314  validloss -1572.58851±0.00000  bestvalidloss -1607.15117  last_update 16\n",
      "train: iter 962  trainloss -1589.26547  validloss -1524.03141±0.00000  bestvalidloss -1607.15117  last_update 17\n",
      "train: iter 963  trainloss -1401.60263  validloss -825.47581±0.00000  bestvalidloss -1607.15117  last_update 18\n",
      "train: iter 964  trainloss -1649.78081  validloss -1484.17258±0.00000  bestvalidloss -1607.15117  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 965  trainloss -1456.89028  validloss -1562.57992±0.00000  bestvalidloss -1607.15117  last_update 20\n",
      "train: iter 966  trainloss -1612.84868  validloss -1263.41895±0.00000  bestvalidloss -1607.15117  last_update 21\n",
      "train: iter 967  trainloss -1657.44645  validloss -1542.06103±0.00000  bestvalidloss -1607.15117  last_update 22\n",
      "train: iter 968  trainloss -1683.41562  validloss -1550.03715±0.00000  bestvalidloss -1607.15117  last_update 23\n",
      "train: iter 969  trainloss -1682.78482  validloss -1530.89238±0.00000  bestvalidloss -1607.15117  last_update 24\n",
      "train: iter 970  trainloss -1663.80092  validloss -1501.18121±0.00000  bestvalidloss -1607.15117  last_update 25\n",
      "train: iter 971  trainloss -1693.51807  validloss -1537.41541±0.00000  bestvalidloss -1607.15117  last_update 26\n",
      "train: iter 972  trainloss -1671.83024  validloss -1604.39450±0.00000  bestvalidloss -1607.15117  last_update 27\n",
      "train: iter 973  trainloss -1598.82613  validloss -1552.82389±0.00000  bestvalidloss -1607.15117  last_update 28\n",
      "train: iter 974  trainloss -1691.67664  validloss -1537.76142±0.00000  bestvalidloss -1607.15117  last_update 29\n",
      "train: iter 975  trainloss -1673.84403  validloss -1581.95613±0.00000  bestvalidloss -1607.15117  last_update 30\n",
      "train: iter 976  trainloss -1637.72958  validloss -1568.17164±0.00000  bestvalidloss -1607.15117  last_update 31\n",
      "train: iter 977  trainloss -1699.40245  validloss -1559.29805±0.00000  bestvalidloss -1607.15117  last_update 32\n",
      "train: iter 978  trainloss -1691.05636  validloss -1581.16794±0.00000  bestvalidloss -1607.15117  last_update 33\n",
      "train: iter 979  trainloss -1665.98663  validloss -1580.72486±0.00000  bestvalidloss -1607.15117  last_update 34\n",
      "train: iter 980  trainloss -1464.10939  validloss -1444.78773±0.00000  bestvalidloss -1607.15117  last_update 35\n",
      "train: iter 981  trainloss -1519.31431  validloss -1142.48142±0.00000  bestvalidloss -1607.15117  last_update 36\n",
      "train: iter 982  trainloss -1618.32101  validloss -1513.21477±0.00000  bestvalidloss -1607.15117  last_update 37\n",
      "train: iter 983  trainloss -1667.36981  validloss -1512.43181±0.00000  bestvalidloss -1607.15117  last_update 38\n",
      "train: iter 984  trainloss -1669.96897  validloss -1467.57840±0.00000  bestvalidloss -1607.15117  last_update 39\n",
      "train: iter 985  trainloss -1605.50171  validloss -1568.54323±0.00000  bestvalidloss -1607.15117  last_update 40\n",
      "train: iter 986  trainloss -1660.82954  validloss -1430.82083±0.00000  bestvalidloss -1607.15117  last_update 41\n",
      "train: iter 987  trainloss -1681.45572  validloss -1552.18041±0.00000  bestvalidloss -1607.15117  last_update 42\n",
      "train: iter 988  trainloss -1708.67741  validloss -1599.03833±0.00000  bestvalidloss -1607.15117  last_update 43\n",
      "train: iter 989  trainloss -1672.98099  validloss -1588.52214±0.00000  bestvalidloss -1607.15117  last_update 44\n",
      "train: iter 990  trainloss -1671.76360  validloss -1551.20378±0.00000  bestvalidloss -1607.15117  last_update 45\n",
      "train: iter 991  trainloss -1647.36544  validloss -1498.07766±0.00000  bestvalidloss -1607.15117  last_update 46\n",
      "train: iter 992  trainloss -1621.43946  validloss -1585.89289±0.00000  bestvalidloss -1607.15117  last_update 47\n",
      "train: iter 993  trainloss -1475.99418  validloss -1349.51653±0.00000  bestvalidloss -1607.15117  last_update 48\n",
      "train: iter 994  trainloss -1644.42808  validloss -1455.11705±0.00000  bestvalidloss -1607.15117  last_update 49\n",
      "train: iter 995  trainloss -1692.85190  validloss -1548.37429±0.00000  bestvalidloss -1607.15117  last_update 50\n",
      "train: iter 996  trainloss -1677.94014  validloss -1551.97020±0.00000  bestvalidloss -1607.15117  last_update 51\n",
      "train: iter 997  trainloss -1547.78979  validloss -1560.27937±0.00000  bestvalidloss -1607.15117  last_update 52\n",
      "train: iter 998  trainloss -1667.20424  validloss -1554.63866±0.00000  bestvalidloss -1607.15117  last_update 53\n",
      "train: iter 999  trainloss -1644.27916  validloss -1561.22523±0.00000  bestvalidloss -1607.15117  last_update 54\n",
      "train: iter 1000  trainloss -1700.14824  validloss -1596.34570±0.00000  bestvalidloss -1607.15117  last_update 55\n",
      "train: iter 1001  trainloss -1624.58791  validloss -1584.80551±0.00000  bestvalidloss -1607.15117  last_update 56\n",
      "train: iter 1002  trainloss -1623.43793  validloss -1389.24658±0.00000  bestvalidloss -1607.15117  last_update 57\n",
      "train: iter 1003  trainloss -1704.23162  validloss -1555.55332±0.00000  bestvalidloss -1607.15117  last_update 58\n",
      "train: iter 1004  trainloss -1673.32461  validloss -1584.92932±0.00000  bestvalidloss -1607.15117  last_update 59\n",
      "train: iter 1005  trainloss -1604.22169  validloss -1544.64485±0.00000  bestvalidloss -1607.15117  last_update 60\n",
      "train: iter 1006  trainloss -1298.94641  validloss -1194.24299±0.00000  bestvalidloss -1607.15117  last_update 61\n",
      "train: iter 1007  trainloss -1623.29492  validloss -1420.14688±0.00000  bestvalidloss -1607.15117  last_update 62\n",
      "train: iter 1008  trainloss -1666.60309  validloss -1494.57993±0.00000  bestvalidloss -1607.15117  last_update 63\n",
      "train: iter 1009  trainloss -1686.49899  validloss -1566.98790±0.00000  bestvalidloss -1607.15117  last_update 64\n",
      "train: iter 1010  trainloss -1624.61665  validloss -1532.36303±0.00000  bestvalidloss -1607.15117  last_update 65\n",
      "train: iter 1011  trainloss -1641.48576  validloss -1481.39055±0.00000  bestvalidloss -1607.15117  last_update 66\n",
      "train: iter 1012  trainloss -1683.51330  validloss -1527.38155±0.00000  bestvalidloss -1607.15117  last_update 67\n",
      "train: iter 1013  trainloss -1624.61081  validloss -1563.99885±0.00000  bestvalidloss -1607.15117  last_update 68\n",
      "train: iter 1014  trainloss -1673.30479  validloss -1349.16176±0.00000  bestvalidloss -1607.15117  last_update 69\n",
      "train: iter 1015  trainloss -1695.80788  validloss -1578.82171±0.00000  bestvalidloss -1607.15117  last_update 70\n",
      "train: iter 1016  trainloss -1672.53429  validloss -1449.88876±0.00000  bestvalidloss -1607.15117  last_update 71\n",
      "train: iter 1017  trainloss -1670.04650  validloss -1562.98857±0.00000  bestvalidloss -1607.15117  last_update 72\n",
      "train: iter 1018  trainloss -1666.75572  validloss -1571.76995±0.00000  bestvalidloss -1607.15117  last_update 73\n",
      "train: iter 1019  trainloss -1534.81536  validloss -1503.12154±0.00000  bestvalidloss -1607.15117  last_update 74\n",
      "train: iter 1020  trainloss -1655.92879  validloss -1355.78222±0.00000  bestvalidloss -1607.15117  last_update 75\n",
      "train: iter 1021  trainloss -1696.62907  validloss -1525.19467±0.00000  bestvalidloss -1607.15117  last_update 76\n",
      "train: iter 1022  trainloss -1654.12479  validloss -1553.71903±0.00000  bestvalidloss -1607.15117  last_update 77\n",
      "train: iter 1023  trainloss -1671.53695  validloss -1412.33633±0.00000  bestvalidloss -1607.15117  last_update 78\n",
      "train: iter 1024  trainloss -1632.98607  validloss -1451.29161±0.00000  bestvalidloss -1607.15117  last_update 79\n",
      "train: iter 1025  trainloss -1618.22298  validloss -1439.46223±0.00000  bestvalidloss -1607.15117  last_update 80\n",
      "train: iter 1026  trainloss -1618.56638  validloss -1529.53881±0.00000  bestvalidloss -1607.15117  last_update 81\n",
      "train: iter 1027  trainloss -1663.90881  validloss -1434.13969±0.00000  bestvalidloss -1607.15117  last_update 82\n",
      "train: iter 1028  trainloss -1712.33272  validloss -1592.26889±0.00000  bestvalidloss -1607.15117  last_update 83\n",
      "train: iter 1029  trainloss -1700.85911  validloss -1575.31122±0.00000  bestvalidloss -1607.15117  last_update 84\n",
      "train: iter 1030  trainloss -1627.25246  validloss -1500.52888±0.00000  bestvalidloss -1607.15117  last_update 85\n",
      "train: iter 1031  trainloss -1646.38549  validloss -1472.27122±0.00000  bestvalidloss -1607.15117  last_update 86\n",
      "train: iter 1032  trainloss -1624.23629  validloss -1566.61465±0.00000  bestvalidloss -1607.15117  last_update 87\n",
      "train: iter 1033  trainloss -1668.82909  validloss -1532.34332±0.00000  bestvalidloss -1607.15117  last_update 88\n",
      "train: iter 1034  trainloss -1678.66978  validloss -1552.20641±0.00000  bestvalidloss -1607.15117  last_update 89\n",
      "train: iter 1035  trainloss -1646.77834  validloss -1553.45377±0.00000  bestvalidloss -1607.15117  last_update 90\n",
      "train: iter 1036  trainloss -1576.01763  validloss -1155.44619±0.00000  bestvalidloss -1607.15117  last_update 91\n",
      "train: iter 1037  trainloss -1610.04392  validloss -1503.17660±0.00000  bestvalidloss -1607.15117  last_update 92\n",
      "train: iter 1038  trainloss -1589.21689  validloss -1580.22473±0.00000  bestvalidloss -1607.15117  last_update 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1039  trainloss -1683.80989  validloss -1523.87525±0.00000  bestvalidloss -1607.15117  last_update 94\n",
      "train: iter 1040  trainloss -1707.18829  validloss -1569.88811±0.00000  bestvalidloss -1607.15117  last_update 95\n",
      "train: iter 1041  trainloss -1641.14280  validloss -1558.65208±0.00000  bestvalidloss -1607.15117  last_update 96\n",
      "train: iter 1042  trainloss -1689.33472  validloss -1411.19779±0.00000  bestvalidloss -1607.15117  last_update 97\n",
      "train: iter 1043  trainloss -1697.44818  validloss -1587.93568±0.00000  bestvalidloss -1607.15117  last_update 98\n",
      "train: iter 1044  trainloss -1569.56989  validloss -1572.50760±0.00000  bestvalidloss -1607.15117  last_update 99\n",
      "train: iter 1045  trainloss -1553.11401  validloss -1483.34786±0.00000  bestvalidloss -1607.15117  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.8139) penalty_target_max tensor(13.0874)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.16020  validloss 4.30763±0.00000  bestvalidloss 4.30763  last_update 0\n",
      "train: iter 1  trainloss 3.87438  validloss 3.99484±0.00000  bestvalidloss 3.99484  last_update 0\n",
      "train: iter 2  trainloss 3.64103  validloss 3.72676±0.00000  bestvalidloss 3.72676  last_update 0\n",
      "train: iter 3  trainloss 3.45412  validloss 3.54625±0.00000  bestvalidloss 3.54625  last_update 0\n",
      "train: iter 4  trainloss 3.29190  validloss 3.35045±0.00000  bestvalidloss 3.35045  last_update 0\n",
      "train: iter 5  trainloss 3.13816  validloss 3.19628±0.00000  bestvalidloss 3.19628  last_update 0\n",
      "train: iter 6  trainloss 3.00884  validloss 3.06836±0.00000  bestvalidloss 3.06836  last_update 0\n",
      "train: iter 7  trainloss 2.88014  validloss 2.94116±0.00000  bestvalidloss 2.94116  last_update 0\n",
      "train: iter 8  trainloss 2.75669  validloss 2.81035±0.00000  bestvalidloss 2.81035  last_update 0\n",
      "train: iter 9  trainloss 2.63643  validloss 2.68751±0.00000  bestvalidloss 2.68751  last_update 0\n",
      "train: iter 10  trainloss 2.52862  validloss 2.57105±0.00000  bestvalidloss 2.57105  last_update 0\n",
      "train: iter 11  trainloss 2.40647  validloss 2.45380±0.00000  bestvalidloss 2.45380  last_update 0\n",
      "train: iter 12  trainloss 2.29498  validloss 2.33855±0.00000  bestvalidloss 2.33855  last_update 0\n",
      "train: iter 13  trainloss 2.18296  validloss 2.22018±0.00000  bestvalidloss 2.22018  last_update 0\n",
      "train: iter 14  trainloss 2.06970  validloss 2.10778±0.00000  bestvalidloss 2.10778  last_update 0\n",
      "train: iter 15  trainloss 1.96628  validloss 1.99874±0.00000  bestvalidloss 1.99874  last_update 0\n",
      "train: iter 16  trainloss 1.86611  validloss 1.89257±0.00000  bestvalidloss 1.89257  last_update 0\n",
      "train: iter 17  trainloss 1.76539  validloss 1.79648±0.00000  bestvalidloss 1.79648  last_update 0\n",
      "train: iter 18  trainloss 1.67171  validloss 1.69525±0.00000  bestvalidloss 1.69525  last_update 0\n",
      "train: iter 19  trainloss 1.57653  validloss 1.61001±0.00000  bestvalidloss 1.61001  last_update 0\n",
      "train: iter 20  trainloss 1.48098  validloss 1.50946±0.00000  bestvalidloss 1.50946  last_update 0\n",
      "train: iter 21  trainloss 1.38880  validloss 1.40566±0.00000  bestvalidloss 1.40566  last_update 0\n",
      "train: iter 22  trainloss 1.30207  validloss 1.30778±0.00000  bestvalidloss 1.30778  last_update 0\n",
      "train: iter 23  trainloss 1.21005  validloss 1.21407±0.00000  bestvalidloss 1.21407  last_update 0\n",
      "train: iter 24  trainloss 1.12241  validloss 1.12717±0.00000  bestvalidloss 1.12717  last_update 0\n",
      "train: iter 25  trainloss 1.03154  validloss 1.02712±0.00000  bestvalidloss 1.02712  last_update 0\n",
      "train: iter 26  trainloss 0.94755  validloss 0.92582±0.00000  bestvalidloss 0.92582  last_update 0\n",
      "train: iter 27  trainloss 0.86257  validloss 0.83535±0.00000  bestvalidloss 0.83535  last_update 0\n",
      "train: iter 28  trainloss 0.77028  validloss 0.74316±0.00000  bestvalidloss 0.74316  last_update 0\n",
      "train: iter 29  trainloss 0.70168  validloss 0.67145±0.00000  bestvalidloss 0.67145  last_update 0\n",
      "train: iter 30  trainloss 0.62920  validloss 0.57581±0.00000  bestvalidloss 0.57581  last_update 0\n",
      "train: iter 31  trainloss 0.55340  validloss 0.51799±0.00000  bestvalidloss 0.51799  last_update 0\n",
      "train: iter 32  trainloss 0.47848  validloss 0.44874±0.00000  bestvalidloss 0.44874  last_update 0\n",
      "train: iter 33  trainloss 0.43157  validloss 0.35579±0.00000  bestvalidloss 0.35579  last_update 0\n",
      "train: iter 34  trainloss 0.37836  validloss 0.30393±0.00000  bestvalidloss 0.30393  last_update 0\n",
      "train: iter 35  trainloss 0.32611  validloss 0.25113±0.00000  bestvalidloss 0.25113  last_update 0\n",
      "train: iter 36  trainloss 0.26446  validloss 0.18803±0.00000  bestvalidloss 0.18803  last_update 0\n",
      "train: iter 37  trainloss 0.22141  validloss 0.13403±0.00000  bestvalidloss 0.13403  last_update 0\n",
      "train: iter 38  trainloss 0.17370  validloss 0.06587±0.00000  bestvalidloss 0.06587  last_update 0\n",
      "train: iter 39  trainloss 0.10088  validloss 0.01442±0.00000  bestvalidloss 0.01442  last_update 0\n",
      "train: iter 40  trainloss 0.09031  validloss -0.02765±0.00000  bestvalidloss -0.02765  last_update 0\n",
      "train: iter 41  trainloss 0.04811  validloss -0.06026±0.00000  bestvalidloss -0.06026  last_update 0\n",
      "train: iter 42  trainloss 0.00957  validloss -0.12594±0.00000  bestvalidloss -0.12594  last_update 0\n",
      "train: iter 43  trainloss -0.00277  validloss -0.15616±0.00000  bestvalidloss -0.15616  last_update 0\n",
      "train: iter 44  trainloss -0.05200  validloss -0.20530±0.00000  bestvalidloss -0.20530  last_update 0\n",
      "train: iter 45  trainloss -0.07799  validloss -0.23819±0.00000  bestvalidloss -0.23819  last_update 0\n",
      "train: iter 46  trainloss -0.12147  validloss -0.29431±0.00000  bestvalidloss -0.29431  last_update 0\n",
      "train: iter 47  trainloss -0.13503  validloss -0.29591±0.00000  bestvalidloss -0.29591  last_update 0\n",
      "train: iter 48  trainloss -0.17941  validloss -0.29287±0.00000  bestvalidloss -0.29591  last_update 1\n",
      "train: iter 49  trainloss -0.19056  validloss -0.34138±0.00000  bestvalidloss -0.34138  last_update 0\n",
      "train: iter 50  trainloss -0.16488  validloss -0.40176±0.00000  bestvalidloss -0.40176  last_update 0\n",
      "train: iter 51  trainloss -0.22201  validloss -0.41705±0.00000  bestvalidloss -0.41705  last_update 0\n",
      "train: iter 52  trainloss -0.22201  validloss -0.46797±0.00000  bestvalidloss -0.46797  last_update 0\n",
      "train: iter 53  trainloss -0.25970  validloss -0.52672±0.00000  bestvalidloss -0.52672  last_update 0\n",
      "train: iter 54  trainloss -0.24116  validloss -0.52547±0.00000  bestvalidloss -0.52672  last_update 1\n",
      "train: iter 55  trainloss -0.27607  validloss -0.50898±0.00000  bestvalidloss -0.52672  last_update 2\n",
      "train: iter 56  trainloss -0.29783  validloss -0.51499±0.00000  bestvalidloss -0.52672  last_update 3\n",
      "train: iter 57  trainloss -0.31140  validloss -0.51358±0.00000  bestvalidloss -0.52672  last_update 4\n",
      "train: iter 58  trainloss -0.30498  validloss -0.54523±0.00000  bestvalidloss -0.54523  last_update 0\n",
      "train: iter 59  trainloss -0.35478  validloss -0.53920±0.00000  bestvalidloss -0.54523  last_update 1\n",
      "train: iter 60  trainloss -0.30658  validloss -0.60687±0.00000  bestvalidloss -0.60687  last_update 0\n",
      "train: iter 61  trainloss -0.33135  validloss -0.63404±0.00000  bestvalidloss -0.63404  last_update 0\n",
      "train: iter 62  trainloss -0.33756  validloss -0.60653±0.00000  bestvalidloss -0.63404  last_update 1\n",
      "train: iter 63  trainloss -0.35907  validloss -0.64233±0.00000  bestvalidloss -0.64233  last_update 0\n",
      "train: iter 64  trainloss -0.34310  validloss -0.63258±0.00000  bestvalidloss -0.64233  last_update 1\n",
      "train: iter 65  trainloss -0.35629  validloss -0.65029±0.00000  bestvalidloss -0.65029  last_update 0\n",
      "train: iter 66  trainloss -0.35101  validloss -0.63303±0.00000  bestvalidloss -0.65029  last_update 1\n",
      "train: iter 67  trainloss -0.35765  validloss -0.71050±0.00000  bestvalidloss -0.71050  last_update 0\n",
      "train: iter 68  trainloss -0.36578  validloss -0.67161±0.00000  bestvalidloss -0.71050  last_update 1\n",
      "train: iter 69  trainloss -0.31770  validloss -0.67025±0.00000  bestvalidloss -0.71050  last_update 2\n",
      "train: iter 70  trainloss -0.36946  validloss -0.71455±0.00000  bestvalidloss -0.71455  last_update 0\n",
      "train: iter 71  trainloss -0.37217  validloss -0.70372±0.00000  bestvalidloss -0.71455  last_update 1\n",
      "train: iter 72  trainloss -0.37212  validloss -0.64151±0.00000  bestvalidloss -0.71455  last_update 2\n",
      "train: iter 73  trainloss -0.39275  validloss -0.72106±0.00000  bestvalidloss -0.72106  last_update 0\n",
      "train: iter 74  trainloss -0.38448  validloss -0.65323±0.00000  bestvalidloss -0.72106  last_update 1\n",
      "train: iter 75  trainloss -0.38413  validloss -0.72446±0.00000  bestvalidloss -0.72446  last_update 0\n",
      "train: iter 76  trainloss -0.34442  validloss -0.67037±0.00000  bestvalidloss -0.72446  last_update 1\n",
      "train: iter 77  trainloss -0.36607  validloss -0.71563±0.00000  bestvalidloss -0.72446  last_update 2\n",
      "train: iter 78  trainloss -0.36499  validloss -0.67841±0.00000  bestvalidloss -0.72446  last_update 3\n",
      "train: iter 79  trainloss -0.38873  validloss -0.72862±0.00000  bestvalidloss -0.72862  last_update 0\n",
      "train: iter 80  trainloss -0.39029  validloss -0.66977±0.00000  bestvalidloss -0.72862  last_update 1\n",
      "train: iter 81  trainloss -0.36325  validloss -0.73182±0.00000  bestvalidloss -0.73182  last_update 0\n",
      "train: iter 82  trainloss -0.37532  validloss -0.73185±0.00000  bestvalidloss -0.73185  last_update 0\n",
      "train: iter 83  trainloss -0.36857  validloss -0.69390±0.00000  bestvalidloss -0.73185  last_update 1\n",
      "train: iter 84  trainloss -0.38178  validloss -0.71724±0.00000  bestvalidloss -0.73185  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss -0.38640  validloss -0.69764±0.00000  bestvalidloss -0.73185  last_update 3\n",
      "train: iter 86  trainloss -0.34109  validloss -0.73558±0.00000  bestvalidloss -0.73558  last_update 0\n",
      "train: iter 87  trainloss -0.37559  validloss -0.73713±0.00000  bestvalidloss -0.73713  last_update 0\n",
      "train: iter 88  trainloss -0.39651  validloss -0.74367±0.00000  bestvalidloss -0.74367  last_update 0\n",
      "train: iter 89  trainloss -0.38511  validloss -0.69808±0.00000  bestvalidloss -0.74367  last_update 1\n",
      "train: iter 90  trainloss -0.38789  validloss -0.72572±0.00000  bestvalidloss -0.74367  last_update 2\n",
      "train: iter 91  trainloss -0.39984  validloss -0.75747±0.00000  bestvalidloss -0.75747  last_update 0\n",
      "train: iter 92  trainloss -0.39313  validloss -0.75569±0.00000  bestvalidloss -0.75747  last_update 1\n",
      "train: iter 93  trainloss -0.40438  validloss -0.71815±0.00000  bestvalidloss -0.75747  last_update 2\n",
      "train: iter 94  trainloss -0.39522  validloss -0.74436±0.00000  bestvalidloss -0.75747  last_update 3\n",
      "train: iter 95  trainloss -0.36917  validloss -0.75865±0.00000  bestvalidloss -0.75865  last_update 0\n",
      "train: iter 96  trainloss -0.37375  validloss -0.77753±0.00000  bestvalidloss -0.77753  last_update 0\n",
      "train: iter 97  trainloss -0.34365  validloss -0.73202±0.00000  bestvalidloss -0.77753  last_update 1\n",
      "train: iter 98  trainloss -0.36912  validloss -0.74925±0.00000  bestvalidloss -0.77753  last_update 2\n",
      "train: iter 99  trainloss -0.35354  validloss -0.71905±0.00000  bestvalidloss -0.77753  last_update 3\n",
      "train: iter 100  trainloss -0.37328  validloss -0.70457±0.00000  bestvalidloss -0.77753  last_update 4\n",
      "train: iter 101  trainloss -0.36106  validloss -0.70149±0.00000  bestvalidloss -0.77753  last_update 5\n",
      "train: iter 102  trainloss -0.42305  validloss -0.71854±0.00000  bestvalidloss -0.77753  last_update 6\n",
      "train: iter 103  trainloss -0.36686  validloss -0.74183±0.00000  bestvalidloss -0.77753  last_update 7\n",
      "train: iter 104  trainloss -0.38240  validloss -0.74073±0.00000  bestvalidloss -0.77753  last_update 8\n",
      "train: iter 105  trainloss -0.38919  validloss -0.73806±0.00000  bestvalidloss -0.77753  last_update 9\n",
      "train: iter 106  trainloss -0.38115  validloss -0.73708±0.00000  bestvalidloss -0.77753  last_update 10\n",
      "train: iter 107  trainloss -0.37597  validloss -0.68859±0.00000  bestvalidloss -0.77753  last_update 11\n",
      "train: iter 108  trainloss -0.39720  validloss -0.72440±0.00000  bestvalidloss -0.77753  last_update 12\n",
      "train: iter 109  trainloss -0.39431  validloss -0.72613±0.00000  bestvalidloss -0.77753  last_update 13\n",
      "train: iter 110  trainloss -0.39254  validloss -0.70406±0.00000  bestvalidloss -0.77753  last_update 14\n",
      "train: iter 111  trainloss -0.39257  validloss -0.71349±0.00000  bestvalidloss -0.77753  last_update 15\n",
      "train: iter 112  trainloss -0.36886  validloss -0.73246±0.00000  bestvalidloss -0.77753  last_update 16\n",
      "train: iter 113  trainloss -0.35232  validloss -0.73802±0.00000  bestvalidloss -0.77753  last_update 17\n",
      "train: iter 114  trainloss -0.38989  validloss -0.71436±0.00000  bestvalidloss -0.77753  last_update 18\n",
      "train: iter 115  trainloss -0.38819  validloss -0.68141±0.00000  bestvalidloss -0.77753  last_update 19\n",
      "train: iter 116  trainloss -0.35732  validloss -0.74108±0.00000  bestvalidloss -0.77753  last_update 20\n",
      "train: iter 117  trainloss -0.39750  validloss -0.73652±0.00000  bestvalidloss -0.77753  last_update 21\n",
      "train: iter 118  trainloss -0.37793  validloss -0.73153±0.00000  bestvalidloss -0.77753  last_update 22\n",
      "train: iter 119  trainloss -0.37075  validloss -0.72734±0.00000  bestvalidloss -0.77753  last_update 23\n",
      "train: iter 120  trainloss -0.34901  validloss -0.72496±0.00000  bestvalidloss -0.77753  last_update 24\n",
      "train: iter 121  trainloss -0.38442  validloss -0.71501±0.00000  bestvalidloss -0.77753  last_update 25\n",
      "train: iter 122  trainloss -0.41682  validloss -0.74603±0.00000  bestvalidloss -0.77753  last_update 26\n",
      "train: iter 123  trainloss -0.37645  validloss -0.70536±0.00000  bestvalidloss -0.77753  last_update 27\n",
      "train: iter 124  trainloss -0.36662  validloss -0.73578±0.00000  bestvalidloss -0.77753  last_update 28\n",
      "train: iter 125  trainloss -0.38275  validloss -0.75276±0.00000  bestvalidloss -0.77753  last_update 29\n",
      "train: iter 126  trainloss -0.37155  validloss -0.75033±0.00000  bestvalidloss -0.77753  last_update 30\n",
      "train: iter 127  trainloss -0.39527  validloss -0.75523±0.00000  bestvalidloss -0.77753  last_update 31\n",
      "train: iter 128  trainloss -0.37278  validloss -0.77480±0.00000  bestvalidloss -0.77753  last_update 32\n",
      "train: iter 129  trainloss -0.35502  validloss -0.70472±0.00000  bestvalidloss -0.77753  last_update 33\n",
      "train: iter 130  trainloss -0.33427  validloss -0.73510±0.00000  bestvalidloss -0.77753  last_update 34\n",
      "train: iter 131  trainloss -0.38040  validloss -0.70265±0.00000  bestvalidloss -0.77753  last_update 35\n",
      "train: iter 132  trainloss -0.38351  validloss -0.78215±0.00000  bestvalidloss -0.78215  last_update 0\n",
      "train: iter 133  trainloss -0.38563  validloss -0.73030±0.00000  bestvalidloss -0.78215  last_update 1\n",
      "train: iter 134  trainloss -0.37126  validloss -0.74805±0.00000  bestvalidloss -0.78215  last_update 2\n",
      "train: iter 135  trainloss -0.41569  validloss -0.72192±0.00000  bestvalidloss -0.78215  last_update 3\n",
      "train: iter 136  trainloss -0.40702  validloss -0.72046±0.00000  bestvalidloss -0.78215  last_update 4\n",
      "train: iter 137  trainloss -0.37041  validloss -0.74593±0.00000  bestvalidloss -0.78215  last_update 5\n",
      "train: iter 138  trainloss -0.40188  validloss -0.77012±0.00000  bestvalidloss -0.78215  last_update 6\n",
      "train: iter 139  trainloss -0.37838  validloss -0.75464±0.00000  bestvalidloss -0.78215  last_update 7\n",
      "train: iter 140  trainloss -0.34616  validloss -0.78035±0.00000  bestvalidloss -0.78215  last_update 8\n",
      "train: iter 141  trainloss -0.38357  validloss -0.71513±0.00000  bestvalidloss -0.78215  last_update 9\n",
      "train: iter 142  trainloss -0.40081  validloss -0.72531±0.00000  bestvalidloss -0.78215  last_update 10\n",
      "train: iter 143  trainloss -0.39545  validloss -0.73680±0.00000  bestvalidloss -0.78215  last_update 11\n",
      "train: iter 144  trainloss -0.36296  validloss -0.75950±0.00000  bestvalidloss -0.78215  last_update 12\n",
      "train: iter 145  trainloss -0.38770  validloss -0.75123±0.00000  bestvalidloss -0.78215  last_update 13\n",
      "train: iter 146  trainloss -0.35399  validloss -0.72339±0.00000  bestvalidloss -0.78215  last_update 14\n",
      "train: iter 147  trainloss -0.38800  validloss -0.75598±0.00000  bestvalidloss -0.78215  last_update 15\n",
      "train: iter 148  trainloss -0.37280  validloss -0.70209±0.00000  bestvalidloss -0.78215  last_update 16\n",
      "train: iter 149  trainloss -0.37846  validloss -0.69299±0.00000  bestvalidloss -0.78215  last_update 17\n",
      "train: iter 150  trainloss -0.36005  validloss -0.70274±0.00000  bestvalidloss -0.78215  last_update 18\n",
      "train: iter 151  trainloss -0.38910  validloss -0.80740±0.00000  bestvalidloss -0.80740  last_update 0\n",
      "train: iter 152  trainloss -0.36226  validloss -0.71278±0.00000  bestvalidloss -0.80740  last_update 1\n",
      "train: iter 153  trainloss -0.39117  validloss -0.75759±0.00000  bestvalidloss -0.80740  last_update 2\n",
      "train: iter 154  trainloss -0.40685  validloss -0.73777±0.00000  bestvalidloss -0.80740  last_update 3\n",
      "train: iter 155  trainloss -0.40545  validloss -0.71259±0.00000  bestvalidloss -0.80740  last_update 4\n",
      "train: iter 156  trainloss -0.39172  validloss -0.76546±0.00000  bestvalidloss -0.80740  last_update 5\n",
      "train: iter 157  trainloss -0.35414  validloss -0.71758±0.00000  bestvalidloss -0.80740  last_update 6\n",
      "train: iter 158  trainloss -0.37925  validloss -0.71424±0.00000  bestvalidloss -0.80740  last_update 7\n",
      "train: iter 159  trainloss -0.35335  validloss -0.75006±0.00000  bestvalidloss -0.80740  last_update 8\n",
      "train: iter 160  trainloss -0.36855  validloss -0.68066±0.00000  bestvalidloss -0.80740  last_update 9\n",
      "train: iter 161  trainloss -0.37782  validloss -0.72407±0.00000  bestvalidloss -0.80740  last_update 10\n",
      "train: iter 162  trainloss -0.36730  validloss -0.77245±0.00000  bestvalidloss -0.80740  last_update 11\n",
      "train: iter 163  trainloss -0.38621  validloss -0.69116±0.00000  bestvalidloss -0.80740  last_update 12\n",
      "train: iter 164  trainloss -0.41600  validloss -0.71703±0.00000  bestvalidloss -0.80740  last_update 13\n",
      "train: iter 165  trainloss -0.39201  validloss -0.72361±0.00000  bestvalidloss -0.80740  last_update 14\n",
      "train: iter 166  trainloss -0.38149  validloss -0.71121±0.00000  bestvalidloss -0.80740  last_update 15\n",
      "train: iter 167  trainloss -0.35047  validloss -0.74458±0.00000  bestvalidloss -0.80740  last_update 16\n",
      "train: iter 168  trainloss -0.38919  validloss -0.71925±0.00000  bestvalidloss -0.80740  last_update 17\n",
      "train: iter 169  trainloss -0.37600  validloss -0.74844±0.00000  bestvalidloss -0.80740  last_update 18\n",
      "train: iter 170  trainloss -0.38112  validloss -0.73897±0.00000  bestvalidloss -0.80740  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 171  trainloss -0.39687  validloss -0.76452±0.00000  bestvalidloss -0.80740  last_update 20\n",
      "train: iter 172  trainloss -0.40360  validloss -0.71034±0.00000  bestvalidloss -0.80740  last_update 21\n",
      "train: iter 173  trainloss -0.35725  validloss -0.73384±0.00000  bestvalidloss -0.80740  last_update 22\n",
      "train: iter 174  trainloss -0.36428  validloss -0.72257±0.00000  bestvalidloss -0.80740  last_update 23\n",
      "train: iter 175  trainloss -0.40547  validloss -0.72056±0.00000  bestvalidloss -0.80740  last_update 24\n",
      "train: iter 176  trainloss -0.38797  validloss -0.71368±0.00000  bestvalidloss -0.80740  last_update 25\n",
      "train: iter 177  trainloss -0.34975  validloss -0.72041±0.00000  bestvalidloss -0.80740  last_update 26\n",
      "train: iter 178  trainloss -0.34823  validloss -0.74338±0.00000  bestvalidloss -0.80740  last_update 27\n",
      "train: iter 179  trainloss -0.37998  validloss -0.69665±0.00000  bestvalidloss -0.80740  last_update 28\n",
      "train: iter 180  trainloss -0.40631  validloss -0.76069±0.00000  bestvalidloss -0.80740  last_update 29\n",
      "train: iter 181  trainloss -0.36443  validloss -0.71644±0.00000  bestvalidloss -0.80740  last_update 30\n",
      "train: iter 182  trainloss -0.36623  validloss -0.76496±0.00000  bestvalidloss -0.80740  last_update 31\n",
      "train: iter 183  trainloss -0.39817  validloss -0.75409±0.00000  bestvalidloss -0.80740  last_update 32\n",
      "train: iter 184  trainloss -0.38896  validloss -0.72521±0.00000  bestvalidloss -0.80740  last_update 33\n",
      "train: iter 185  trainloss -0.37865  validloss -0.70773±0.00000  bestvalidloss -0.80740  last_update 34\n",
      "train: iter 186  trainloss -0.41340  validloss -0.75137±0.00000  bestvalidloss -0.80740  last_update 35\n",
      "train: iter 187  trainloss -0.41194  validloss -0.74471±0.00000  bestvalidloss -0.80740  last_update 36\n",
      "train: iter 188  trainloss -0.34887  validloss -0.69188±0.00000  bestvalidloss -0.80740  last_update 37\n",
      "train: iter 189  trainloss -0.36248  validloss -0.72366±0.00000  bestvalidloss -0.80740  last_update 38\n",
      "train: iter 190  trainloss -0.35237  validloss -0.73712±0.00000  bestvalidloss -0.80740  last_update 39\n",
      "train: iter 191  trainloss -0.39743  validloss -0.74827±0.00000  bestvalidloss -0.80740  last_update 40\n",
      "train: iter 192  trainloss -0.36919  validloss -0.71845±0.00000  bestvalidloss -0.80740  last_update 41\n",
      "train: iter 193  trainloss -0.39436  validloss -0.73303±0.00000  bestvalidloss -0.80740  last_update 42\n",
      "train: iter 194  trainloss -0.39455  validloss -0.71368±0.00000  bestvalidloss -0.80740  last_update 43\n",
      "train: iter 195  trainloss -0.37559  validloss -0.76287±0.00000  bestvalidloss -0.80740  last_update 44\n",
      "train: iter 196  trainloss -0.38146  validloss -0.73008±0.00000  bestvalidloss -0.80740  last_update 45\n",
      "train: iter 197  trainloss -0.38384  validloss -0.68138±0.00000  bestvalidloss -0.80740  last_update 46\n",
      "train: iter 198  trainloss -0.41628  validloss -0.73003±0.00000  bestvalidloss -0.80740  last_update 47\n",
      "train: iter 199  trainloss -0.35046  validloss -0.72961±0.00000  bestvalidloss -0.80740  last_update 48\n",
      "train: iter 200  trainloss -0.39470  validloss -0.76599±0.00000  bestvalidloss -0.80740  last_update 49\n",
      "train: iter 201  trainloss -0.36286  validloss -0.73356±0.00000  bestvalidloss -0.80740  last_update 50\n",
      "train: iter 202  trainloss -0.37937  validloss -0.69872±0.00000  bestvalidloss -0.80740  last_update 51\n",
      "train: iter 203  trainloss -0.39167  validloss -0.75419±0.00000  bestvalidloss -0.80740  last_update 52\n",
      "train: iter 204  trainloss -0.36894  validloss -0.77705±0.00000  bestvalidloss -0.80740  last_update 53\n",
      "train: iter 205  trainloss -0.34311  validloss -0.65423±0.00000  bestvalidloss -0.80740  last_update 54\n",
      "train: iter 206  trainloss -0.38139  validloss -0.75913±0.00000  bestvalidloss -0.80740  last_update 55\n",
      "train: iter 207  trainloss -0.40120  validloss -0.66779±0.00000  bestvalidloss -0.80740  last_update 56\n",
      "train: iter 208  trainloss -0.34527  validloss -0.67844±0.00000  bestvalidloss -0.80740  last_update 57\n",
      "train: iter 209  trainloss -0.41991  validloss -0.75736±0.00000  bestvalidloss -0.80740  last_update 58\n",
      "train: iter 210  trainloss -0.40690  validloss -0.70974±0.00000  bestvalidloss -0.80740  last_update 59\n",
      "train: iter 211  trainloss -0.39054  validloss -0.73573±0.00000  bestvalidloss -0.80740  last_update 60\n",
      "train: iter 212  trainloss -0.40359  validloss -0.71328±0.00000  bestvalidloss -0.80740  last_update 61\n",
      "train: iter 213  trainloss -0.35057  validloss -0.67965±0.00000  bestvalidloss -0.80740  last_update 62\n",
      "train: iter 214  trainloss -0.37365  validloss -0.76719±0.00000  bestvalidloss -0.80740  last_update 63\n",
      "train: iter 215  trainloss -0.33806  validloss -0.72858±0.00000  bestvalidloss -0.80740  last_update 64\n",
      "train: iter 216  trainloss -0.37744  validloss -0.72332±0.00000  bestvalidloss -0.80740  last_update 65\n",
      "train: iter 217  trainloss -0.38150  validloss -0.73258±0.00000  bestvalidloss -0.80740  last_update 66\n",
      "train: iter 218  trainloss -0.38731  validloss -0.74214±0.00000  bestvalidloss -0.80740  last_update 67\n",
      "train: iter 219  trainloss -0.34212  validloss -0.72549±0.00000  bestvalidloss -0.80740  last_update 68\n",
      "train: iter 220  trainloss -0.38710  validloss -0.67413±0.00000  bestvalidloss -0.80740  last_update 69\n",
      "train: iter 221  trainloss -0.35362  validloss -0.74520±0.00000  bestvalidloss -0.80740  last_update 70\n",
      "train: iter 222  trainloss -0.36446  validloss -0.73283±0.00000  bestvalidloss -0.80740  last_update 71\n",
      "train: iter 223  trainloss -0.39417  validloss -0.69074±0.00000  bestvalidloss -0.80740  last_update 72\n",
      "train: iter 224  trainloss -0.36864  validloss -0.68647±0.00000  bestvalidloss -0.80740  last_update 73\n",
      "train: iter 225  trainloss -0.35019  validloss -0.73726±0.00000  bestvalidloss -0.80740  last_update 74\n",
      "train: iter 226  trainloss -0.40387  validloss -0.71415±0.00000  bestvalidloss -0.80740  last_update 75\n",
      "train: iter 227  trainloss -0.35087  validloss -0.67427±0.00000  bestvalidloss -0.80740  last_update 76\n",
      "train: iter 228  trainloss -0.39526  validloss -0.69406±0.00000  bestvalidloss -0.80740  last_update 77\n",
      "train: iter 229  trainloss -0.38795  validloss -0.72920±0.00000  bestvalidloss -0.80740  last_update 78\n",
      "train: iter 230  trainloss -0.39046  validloss -0.77640±0.00000  bestvalidloss -0.80740  last_update 79\n",
      "train: iter 231  trainloss -0.38392  validloss -0.74379±0.00000  bestvalidloss -0.80740  last_update 80\n",
      "train: iter 232  trainloss -0.38131  validloss -0.69635±0.00000  bestvalidloss -0.80740  last_update 81\n",
      "train: iter 233  trainloss -0.36318  validloss -0.73930±0.00000  bestvalidloss -0.80740  last_update 82\n",
      "train: iter 234  trainloss -0.37007  validloss -0.74126±0.00000  bestvalidloss -0.80740  last_update 83\n",
      "train: iter 235  trainloss -0.39661  validloss -0.73719±0.00000  bestvalidloss -0.80740  last_update 84\n",
      "train: iter 236  trainloss -0.37161  validloss -0.69621±0.00000  bestvalidloss -0.80740  last_update 85\n",
      "train: iter 237  trainloss -0.37009  validloss -0.72576±0.00000  bestvalidloss -0.80740  last_update 86\n",
      "train: iter 238  trainloss -0.35802  validloss -0.73384±0.00000  bestvalidloss -0.80740  last_update 87\n",
      "train: iter 239  trainloss -0.41582  validloss -0.68099±0.00000  bestvalidloss -0.80740  last_update 88\n",
      "train: iter 240  trainloss -0.39727  validloss -0.75081±0.00000  bestvalidloss -0.80740  last_update 89\n",
      "train: iter 241  trainloss -0.38613  validloss -0.72445±0.00000  bestvalidloss -0.80740  last_update 90\n",
      "train: iter 242  trainloss -0.37325  validloss -0.71450±0.00000  bestvalidloss -0.80740  last_update 91\n",
      "train: iter 243  trainloss -0.39296  validloss -0.69487±0.00000  bestvalidloss -0.80740  last_update 92\n",
      "train: iter 244  trainloss -0.36461  validloss -0.72233±0.00000  bestvalidloss -0.80740  last_update 93\n",
      "train: iter 245  trainloss -0.37769  validloss -0.72574±0.00000  bestvalidloss -0.80740  last_update 94\n",
      "train: iter 246  trainloss -0.36269  validloss -0.71071±0.00000  bestvalidloss -0.80740  last_update 95\n",
      "train: iter 247  trainloss -0.37565  validloss -0.70291±0.00000  bestvalidloss -0.80740  last_update 96\n",
      "train: iter 248  trainloss -0.35775  validloss -0.72777±0.00000  bestvalidloss -0.80740  last_update 97\n",
      "train: iter 249  trainloss -0.40625  validloss -0.76255±0.00000  bestvalidloss -0.80740  last_update 98\n",
      "train: iter 250  trainloss -0.39501  validloss -0.70316±0.00000  bestvalidloss -0.80740  last_update 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 251  trainloss -0.40631  validloss -0.72542±0.00000  bestvalidloss -0.80740  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.1956, -1.8563, -3.1189, -3.3115], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 70.32105  validloss 70.16736±0.00000  bestvalidloss 70.16736  last_update 0\n",
      "train: iter 1  trainloss 54.56973  validloss 57.70331±0.00000  bestvalidloss 57.70331  last_update 0\n",
      "train: iter 2  trainloss 40.23480  validloss 42.66551±0.00000  bestvalidloss 42.66551  last_update 0\n",
      "train: iter 3  trainloss 30.95478  validloss 31.95234±0.00000  bestvalidloss 31.95234  last_update 0\n",
      "train: iter 4  trainloss 24.19101  validloss 25.07351±0.00000  bestvalidloss 25.07351  last_update 0\n",
      "train: iter 5  trainloss 19.20722  validloss 19.49711±0.00000  bestvalidloss 19.49711  last_update 0\n",
      "train: iter 6  trainloss 15.66250  validloss 16.07263±0.00000  bestvalidloss 16.07263  last_update 0\n",
      "train: iter 7  trainloss 13.05418  validloss 13.51363±0.00000  bestvalidloss 13.51363  last_update 0\n",
      "train: iter 8  trainloss 11.20066  validloss 11.72775±0.00000  bestvalidloss 11.72775  last_update 0\n",
      "train: iter 9  trainloss 9.86880  validloss 10.42014±0.00000  bestvalidloss 10.42014  last_update 0\n",
      "train: iter 10  trainloss 8.90120  validloss 9.58132±0.00000  bestvalidloss 9.58132  last_update 0\n",
      "train: iter 11  trainloss 8.20768  validloss 9.04424±0.00000  bestvalidloss 9.04424  last_update 0\n",
      "train: iter 12  trainloss 7.75138  validloss 8.63162±0.00000  bestvalidloss 8.63162  last_update 0\n",
      "train: iter 13  trainloss 7.35001  validloss 8.42450±0.00000  bestvalidloss 8.42450  last_update 0\n",
      "train: iter 14  trainloss 7.09551  validloss 8.30863±0.00000  bestvalidloss 8.30863  last_update 0\n",
      "train: iter 15  trainloss 6.95634  validloss 8.12411±0.00000  bestvalidloss 8.12411  last_update 0\n",
      "train: iter 16  trainloss 6.81492  validloss 8.03056±0.00000  bestvalidloss 8.03056  last_update 0\n",
      "train: iter 17  trainloss 6.67735  validloss 7.90150±0.00000  bestvalidloss 7.90150  last_update 0\n",
      "train: iter 18  trainloss 6.63372  validloss 7.80241±0.00000  bestvalidloss 7.80241  last_update 0\n",
      "train: iter 19  trainloss 6.47824  validloss 7.84252±0.00000  bestvalidloss 7.80241  last_update 1\n",
      "train: iter 20  trainloss 6.40513  validloss 7.63024±0.00000  bestvalidloss 7.63024  last_update 0\n",
      "train: iter 21  trainloss 6.26515  validloss 7.46633±0.00000  bestvalidloss 7.46633  last_update 0\n",
      "train: iter 22  trainloss 5.98353  validloss 7.20157±0.00000  bestvalidloss 7.20157  last_update 0\n",
      "train: iter 23  trainloss 5.52020  validloss 6.40718±0.00000  bestvalidloss 6.40718  last_update 0\n",
      "train: iter 24  trainloss 5.19599  validloss 5.86990±0.00000  bestvalidloss 5.86990  last_update 0\n",
      "train: iter 25  trainloss 4.94591  validloss 5.55105±0.00000  bestvalidloss 5.55105  last_update 0\n",
      "train: iter 26  trainloss 4.73023  validloss 5.35774±0.00000  bestvalidloss 5.35774  last_update 0\n",
      "train: iter 27  trainloss 4.54182  validloss 5.25430±0.00000  bestvalidloss 5.25430  last_update 0\n",
      "train: iter 28  trainloss 4.41366  validloss 5.07747±0.00000  bestvalidloss 5.07747  last_update 0\n",
      "train: iter 29  trainloss 4.21556  validloss 4.92103±0.00000  bestvalidloss 4.92103  last_update 0\n",
      "train: iter 30  trainloss 4.13584  validloss 4.85988±0.00000  bestvalidloss 4.85988  last_update 0\n",
      "train: iter 31  trainloss 4.02216  validloss 4.87246±0.00000  bestvalidloss 4.85988  last_update 1\n",
      "train: iter 32  trainloss 3.94047  validloss 4.73906±0.00000  bestvalidloss 4.73906  last_update 0\n",
      "train: iter 33  trainloss 3.89241  validloss 4.89744±0.00000  bestvalidloss 4.73906  last_update 1\n",
      "train: iter 34  trainloss 3.82107  validloss 4.74235±0.00000  bestvalidloss 4.73906  last_update 2\n",
      "train: iter 35  trainloss 3.70194  validloss 4.76218±0.00000  bestvalidloss 4.73906  last_update 3\n",
      "train: iter 36  trainloss 3.69384  validloss 4.67356±0.00000  bestvalidloss 4.67356  last_update 0\n",
      "train: iter 37  trainloss 3.62053  validloss 4.54874±0.00000  bestvalidloss 4.54874  last_update 0\n",
      "train: iter 38  trainloss 3.60682  validloss 4.42897±0.00000  bestvalidloss 4.42897  last_update 0\n",
      "train: iter 39  trainloss 3.54542  validloss 4.51486±0.00000  bestvalidloss 4.42897  last_update 1\n",
      "train: iter 40  trainloss 3.46313  validloss 4.59970±0.00000  bestvalidloss 4.42897  last_update 2\n",
      "train: iter 41  trainloss 3.41365  validloss 4.70993±0.00000  bestvalidloss 4.42897  last_update 3\n",
      "train: iter 42  trainloss 3.41982  validloss 4.30188±0.00000  bestvalidloss 4.30188  last_update 0\n",
      "train: iter 43  trainloss 3.38356  validloss 4.56956±0.00000  bestvalidloss 4.30188  last_update 1\n",
      "train: iter 44  trainloss 3.29181  validloss 4.40686±0.00000  bestvalidloss 4.30188  last_update 2\n",
      "train: iter 45  trainloss 3.28978  validloss 4.59152±0.00000  bestvalidloss 4.30188  last_update 3\n",
      "train: iter 46  trainloss 3.27881  validloss 4.76649±0.00000  bestvalidloss 4.30188  last_update 4\n",
      "train: iter 47  trainloss 3.24841  validloss 4.57040±0.00000  bestvalidloss 4.30188  last_update 5\n",
      "train: iter 48  trainloss 3.23941  validloss 4.49643±0.00000  bestvalidloss 4.30188  last_update 6\n",
      "train: iter 49  trainloss 3.25305  validloss 4.53644±0.00000  bestvalidloss 4.30188  last_update 7\n",
      "train: iter 50  trainloss 3.27041  validloss 4.57441±0.00000  bestvalidloss 4.30188  last_update 8\n",
      "train: iter 51  trainloss 3.28400  validloss 4.48281±0.00000  bestvalidloss 4.30188  last_update 9\n",
      "train: iter 52  trainloss 3.20455  validloss 4.69645±0.00000  bestvalidloss 4.30188  last_update 10\n",
      "train: iter 53  trainloss 3.17538  validloss 4.54503±0.00000  bestvalidloss 4.30188  last_update 11\n",
      "train: iter 54  trainloss 3.22946  validloss 4.50721±0.00000  bestvalidloss 4.30188  last_update 12\n",
      "train: iter 55  trainloss 3.19414  validloss 4.63492±0.00000  bestvalidloss 4.30188  last_update 13\n",
      "train: iter 56  trainloss 3.20036  validloss 4.53133±0.00000  bestvalidloss 4.30188  last_update 14\n",
      "train: iter 57  trainloss 3.24699  validloss 5.19798±0.00000  bestvalidloss 4.30188  last_update 15\n",
      "train: iter 58  trainloss 3.21464  validloss 4.90200±0.00000  bestvalidloss 4.30188  last_update 16\n",
      "train: iter 59  trainloss 3.20050  validloss 4.60472±0.00000  bestvalidloss 4.30188  last_update 17\n",
      "train: iter 60  trainloss 3.21314  validloss 4.53325±0.00000  bestvalidloss 4.30188  last_update 18\n",
      "train: iter 61  trainloss 3.20900  validloss 4.64775±0.00000  bestvalidloss 4.30188  last_update 19\n",
      "train: iter 62  trainloss 3.18141  validloss 4.50719±0.00000  bestvalidloss 4.30188  last_update 20\n",
      "train: iter 63  trainloss 3.20502  validloss 4.53183±0.00000  bestvalidloss 4.30188  last_update 21\n",
      "train: iter 64  trainloss 3.22782  validloss 4.45303±0.00000  bestvalidloss 4.30188  last_update 22\n",
      "train: iter 65  trainloss 3.16903  validloss 4.51788±0.00000  bestvalidloss 4.30188  last_update 23\n",
      "train: iter 66  trainloss 3.21859  validloss 4.52551±0.00000  bestvalidloss 4.30188  last_update 24\n",
      "train: iter 67  trainloss 3.18401  validloss 4.57894±0.00000  bestvalidloss 4.30188  last_update 25\n",
      "train: iter 68  trainloss 3.16911  validloss 4.60363±0.00000  bestvalidloss 4.30188  last_update 26\n",
      "train: iter 69  trainloss 3.18621  validloss 4.53743±0.00000  bestvalidloss 4.30188  last_update 27\n",
      "train: iter 70  trainloss 3.18027  validloss 4.60928±0.00000  bestvalidloss 4.30188  last_update 28\n",
      "train: iter 71  trainloss 3.20765  validloss 4.48522±0.00000  bestvalidloss 4.30188  last_update 29\n",
      "train: iter 72  trainloss 3.18122  validloss 4.78537±0.00000  bestvalidloss 4.30188  last_update 30\n",
      "train: iter 73  trainloss 3.16580  validloss 4.44492±0.00000  bestvalidloss 4.30188  last_update 31\n",
      "train: iter 74  trainloss 3.22698  validloss 4.63042±0.00000  bestvalidloss 4.30188  last_update 32\n",
      "train: iter 75  trainloss 3.15404  validloss 4.69896±0.00000  bestvalidloss 4.30188  last_update 33\n",
      "train: iter 76  trainloss 3.18911  validloss 4.57148±0.00000  bestvalidloss 4.30188  last_update 34\n",
      "train: iter 77  trainloss 3.17495  validloss 4.86558±0.00000  bestvalidloss 4.30188  last_update 35\n",
      "train: iter 78  trainloss 3.15682  validloss 4.69159±0.00000  bestvalidloss 4.30188  last_update 36\n",
      "train: iter 79  trainloss 3.13451  validloss 4.56440±0.00000  bestvalidloss 4.30188  last_update 37\n",
      "train: iter 80  trainloss 3.18883  validloss 4.49480±0.00000  bestvalidloss 4.30188  last_update 38\n",
      "train: iter 81  trainloss 3.19268  validloss 4.70429±0.00000  bestvalidloss 4.30188  last_update 39\n",
      "train: iter 82  trainloss 3.17510  validloss 4.73931±0.00000  bestvalidloss 4.30188  last_update 40\n",
      "train: iter 83  trainloss 3.14161  validloss 4.67049±0.00000  bestvalidloss 4.30188  last_update 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 3.15870  validloss 4.51288±0.00000  bestvalidloss 4.30188  last_update 42\n",
      "train: iter 85  trainloss 3.18558  validloss 4.53590±0.00000  bestvalidloss 4.30188  last_update 43\n",
      "train: iter 86  trainloss 3.14305  validloss 4.53365±0.00000  bestvalidloss 4.30188  last_update 44\n",
      "train: iter 87  trainloss 3.21894  validloss 4.48859±0.00000  bestvalidloss 4.30188  last_update 45\n",
      "train: iter 88  trainloss 3.18116  validloss 4.41216±0.00000  bestvalidloss 4.30188  last_update 46\n",
      "train: iter 89  trainloss 3.12908  validloss 4.69785±0.00000  bestvalidloss 4.30188  last_update 47\n",
      "train: iter 90  trainloss 3.16747  validloss 4.71356±0.00000  bestvalidloss 4.30188  last_update 48\n",
      "train: iter 91  trainloss 3.11603  validloss 4.65563±0.00000  bestvalidloss 4.30188  last_update 49\n",
      "train: iter 92  trainloss 3.18315  validloss 4.76369±0.00000  bestvalidloss 4.30188  last_update 50\n",
      "train: iter 93  trainloss 3.12166  validloss 4.73484±0.00000  bestvalidloss 4.30188  last_update 51\n",
      "train: iter 94  trainloss 3.17901  validloss 4.41170±0.00000  bestvalidloss 4.30188  last_update 52\n",
      "train: iter 95  trainloss 3.18565  validloss 4.53772±0.00000  bestvalidloss 4.30188  last_update 53\n",
      "train: iter 96  trainloss 3.17835  validloss 4.63400±0.00000  bestvalidloss 4.30188  last_update 54\n",
      "train: iter 97  trainloss 3.14665  validloss 4.60871±0.00000  bestvalidloss 4.30188  last_update 55\n",
      "train: iter 98  trainloss 3.13870  validloss 4.68078±0.00000  bestvalidloss 4.30188  last_update 56\n",
      "train: iter 99  trainloss 3.16241  validloss 4.66788±0.00000  bestvalidloss 4.30188  last_update 57\n",
      "train: iter 100  trainloss 3.19624  validloss 4.40603±0.00000  bestvalidloss 4.30188  last_update 58\n",
      "train: iter 101  trainloss 3.12752  validloss 4.70448±0.00000  bestvalidloss 4.30188  last_update 59\n",
      "train: iter 102  trainloss 3.18475  validloss 4.46524±0.00000  bestvalidloss 4.30188  last_update 60\n",
      "train: iter 103  trainloss 3.14599  validloss 4.57554±0.00000  bestvalidloss 4.30188  last_update 61\n",
      "train: iter 104  trainloss 3.14504  validloss 4.77799±0.00000  bestvalidloss 4.30188  last_update 62\n",
      "train: iter 105  trainloss 3.17450  validloss 4.45679±0.00000  bestvalidloss 4.30188  last_update 63\n",
      "train: iter 106  trainloss 3.14577  validloss 4.49584±0.00000  bestvalidloss 4.30188  last_update 64\n",
      "train: iter 107  trainloss 3.13924  validloss 4.50080±0.00000  bestvalidloss 4.30188  last_update 65\n",
      "train: iter 108  trainloss 3.13399  validloss 4.57236±0.00000  bestvalidloss 4.30188  last_update 66\n",
      "train: iter 109  trainloss 3.16392  validloss 4.82045±0.00000  bestvalidloss 4.30188  last_update 67\n",
      "train: iter 110  trainloss 3.13308  validloss 4.49194±0.00000  bestvalidloss 4.30188  last_update 68\n",
      "train: iter 111  trainloss 3.14738  validloss 4.61179±0.00000  bestvalidloss 4.30188  last_update 69\n",
      "train: iter 112  trainloss 3.13855  validloss 4.52765±0.00000  bestvalidloss 4.30188  last_update 70\n",
      "train: iter 113  trainloss 3.13518  validloss 4.95083±0.00000  bestvalidloss 4.30188  last_update 71\n",
      "train: iter 114  trainloss 3.16015  validloss 4.58384±0.00000  bestvalidloss 4.30188  last_update 72\n",
      "train: iter 115  trainloss 3.18355  validloss 4.62079±0.00000  bestvalidloss 4.30188  last_update 73\n",
      "train: iter 116  trainloss 3.17726  validloss 4.72805±0.00000  bestvalidloss 4.30188  last_update 74\n",
      "train: iter 117  trainloss 3.14078  validloss 4.65645±0.00000  bestvalidloss 4.30188  last_update 75\n",
      "train: iter 118  trainloss 3.12066  validloss 4.47851±0.00000  bestvalidloss 4.30188  last_update 76\n",
      "train: iter 119  trainloss 3.11068  validloss 4.69569±0.00000  bestvalidloss 4.30188  last_update 77\n",
      "train: iter 120  trainloss 3.16257  validloss 4.53845±0.00000  bestvalidloss 4.30188  last_update 78\n",
      "train: iter 121  trainloss 3.18091  validloss 4.60694±0.00000  bestvalidloss 4.30188  last_update 79\n",
      "train: iter 122  trainloss 3.19540  validloss 4.78961±0.00000  bestvalidloss 4.30188  last_update 80\n",
      "train: iter 123  trainloss 3.13653  validloss 4.99479±0.00000  bestvalidloss 4.30188  last_update 81\n",
      "train: iter 124  trainloss 3.10135  validloss 4.74258±0.00000  bestvalidloss 4.30188  last_update 82\n",
      "train: iter 125  trainloss 3.15821  validloss 4.47962±0.00000  bestvalidloss 4.30188  last_update 83\n",
      "train: iter 126  trainloss 3.16789  validloss 4.65162±0.00000  bestvalidloss 4.30188  last_update 84\n",
      "train: iter 127  trainloss 3.16008  validloss 4.54498±0.00000  bestvalidloss 4.30188  last_update 85\n",
      "train: iter 128  trainloss 3.12759  validloss 4.72053±0.00000  bestvalidloss 4.30188  last_update 86\n",
      "train: iter 129  trainloss 3.13598  validloss 4.60100±0.00000  bestvalidloss 4.30188  last_update 87\n",
      "train: iter 130  trainloss 3.09042  validloss 4.73864±0.00000  bestvalidloss 4.30188  last_update 88\n",
      "train: iter 131  trainloss 3.11472  validloss 4.66338±0.00000  bestvalidloss 4.30188  last_update 89\n",
      "train: iter 132  trainloss 3.13067  validloss 4.69530±0.00000  bestvalidloss 4.30188  last_update 90\n",
      "train: iter 133  trainloss 3.10909  validloss 4.53513±0.00000  bestvalidloss 4.30188  last_update 91\n",
      "train: iter 134  trainloss 3.11034  validloss 4.63886±0.00000  bestvalidloss 4.30188  last_update 92\n",
      "train: iter 135  trainloss 3.17397  validloss 4.71307±0.00000  bestvalidloss 4.30188  last_update 93\n",
      "train: iter 136  trainloss 3.15454  validloss 4.61072±0.00000  bestvalidloss 4.30188  last_update 94\n",
      "train: iter 137  trainloss 3.11273  validloss 4.84315±0.00000  bestvalidloss 4.30188  last_update 95\n",
      "train: iter 138  trainloss 3.13580  validloss 4.57320±0.00000  bestvalidloss 4.30188  last_update 96\n",
      "train: iter 139  trainloss 3.08388  validloss 4.57750±0.00000  bestvalidloss 4.30188  last_update 97\n",
      "train: iter 140  trainloss 3.12192  validloss 4.48576±0.00000  bestvalidloss 4.30188  last_update 98\n",
      "train: iter 141  trainloss 3.12286  validloss 4.63645±0.00000  bestvalidloss 4.30188  last_update 99\n",
      "train: iter 142  trainloss 3.10799  validloss 4.97309±0.00000  bestvalidloss 4.30188  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-7.0911)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(1.9157)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0704959981900204\n",
      "tensor([-0.2217])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2afdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b640b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75801e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da354af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b1333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
