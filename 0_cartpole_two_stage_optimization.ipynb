{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(1040.3992)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 48\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 930.93196  validloss 548.64564±0.00000  bestvalidloss 548.64564  last_update 0\n",
      "train: iter 1  trainloss 540.92762  validloss 504.33754±0.00000  bestvalidloss 504.33754  last_update 0\n",
      "train: iter 2  trainloss 518.77472  validloss 487.92977±0.00000  bestvalidloss 487.92977  last_update 0\n",
      "train: iter 3  trainloss 498.25149  validloss 478.66071±0.00000  bestvalidloss 478.66071  last_update 0\n",
      "train: iter 4  trainloss 478.69146  validloss 465.88599±0.00000  bestvalidloss 465.88599  last_update 0\n",
      "train: iter 5  trainloss 446.88643  validloss 449.44622±0.00000  bestvalidloss 449.44622  last_update 0\n",
      "train: iter 6  trainloss 348.03149  validloss 392.06709±0.00000  bestvalidloss 392.06709  last_update 0\n",
      "train: iter 7  trainloss 242.49964  validloss 228.96654±0.00000  bestvalidloss 228.96654  last_update 0\n",
      "train: iter 8  trainloss 191.23077  validloss 174.71710±0.00000  bestvalidloss 174.71710  last_update 0\n",
      "train: iter 9  trainloss 150.51340  validloss 99.33364±0.00000  bestvalidloss 99.33364  last_update 0\n",
      "train: iter 10  trainloss 116.38890  validloss 94.25917±0.00000  bestvalidloss 94.25917  last_update 0\n",
      "train: iter 11  trainloss 87.49098  validloss 40.15185±0.00000  bestvalidloss 40.15185  last_update 0\n",
      "train: iter 12  trainloss 67.13473  validloss 13.89946±0.00000  bestvalidloss 13.89946  last_update 0\n",
      "train: iter 13  trainloss 73.13074  validloss 1.18000±0.00000  bestvalidloss 1.18000  last_update 0\n",
      "train: iter 14  trainloss 62.82603  validloss -26.85001±0.00000  bestvalidloss -26.85001  last_update 0\n",
      "train: iter 15  trainloss 24.91527  validloss -41.95516±0.00000  bestvalidloss -41.95516  last_update 0\n",
      "train: iter 16  trainloss 4.64212  validloss -58.15680±0.00000  bestvalidloss -58.15680  last_update 0\n",
      "train: iter 17  trainloss -6.08480  validloss -83.62256±0.00000  bestvalidloss -83.62256  last_update 0\n",
      "train: iter 18  trainloss -33.10282  validloss -96.38159±0.00000  bestvalidloss -96.38159  last_update 0\n",
      "train: iter 19  trainloss -46.51275  validloss -113.04217±0.00000  bestvalidloss -113.04217  last_update 0\n",
      "train: iter 20  trainloss 58.90780  validloss -144.88354±0.00000  bestvalidloss -144.88354  last_update 0\n",
      "train: iter 21  trainloss 54.28346  validloss 178.96836±0.00000  bestvalidloss -144.88354  last_update 1\n",
      "train: iter 22  trainloss -30.85389  validloss -9.92788±0.00000  bestvalidloss -144.88354  last_update 2\n",
      "train: iter 23  trainloss -71.85874  validloss -153.60893±0.00000  bestvalidloss -153.60893  last_update 0\n",
      "train: iter 24  trainloss -73.53830  validloss -168.87353±0.00000  bestvalidloss -168.87353  last_update 0\n",
      "train: iter 25  trainloss -82.24202  validloss -144.59783±0.00000  bestvalidloss -168.87353  last_update 1\n",
      "train: iter 26  trainloss -94.08548  validloss -176.21809±0.00000  bestvalidloss -176.21809  last_update 0\n",
      "train: iter 27  trainloss -88.09177  validloss -23.11985±0.00000  bestvalidloss -176.21809  last_update 1\n",
      "train: iter 28  trainloss -129.88294  validloss -180.15908±0.00000  bestvalidloss -180.15908  last_update 0\n",
      "train: iter 29  trainloss -131.47680  validloss -199.12394±0.00000  bestvalidloss -199.12394  last_update 0\n",
      "train: iter 30  trainloss -63.80104  validloss -205.10174±0.00000  bestvalidloss -205.10174  last_update 0\n",
      "train: iter 31  trainloss -139.60265  validloss -197.80428±0.00000  bestvalidloss -205.10174  last_update 1\n",
      "train: iter 32  trainloss -144.83269  validloss -190.20164±0.00000  bestvalidloss -205.10174  last_update 2\n",
      "train: iter 33  trainloss -112.15203  validloss -194.88594±0.00000  bestvalidloss -205.10174  last_update 3\n",
      "train: iter 34  trainloss -148.76694  validloss -130.97041±0.00000  bestvalidloss -205.10174  last_update 4\n",
      "train: iter 35  trainloss -168.11307  validloss -231.84074±0.00000  bestvalidloss -231.84074  last_update 0\n",
      "train: iter 36  trainloss -175.83090  validloss -218.35193±0.00000  bestvalidloss -231.84074  last_update 1\n",
      "train: iter 37  trainloss -170.44287  validloss -217.01733±0.00000  bestvalidloss -231.84074  last_update 2\n",
      "train: iter 38  trainloss -180.67292  validloss -163.08452±0.00000  bestvalidloss -231.84074  last_update 3\n",
      "train: iter 39  trainloss -190.65092  validloss -248.18076±0.00000  bestvalidloss -248.18076  last_update 0\n",
      "train: iter 40  trainloss -188.43085  validloss -226.36845±0.00000  bestvalidloss -248.18076  last_update 1\n",
      "train: iter 41  trainloss -206.39761  validloss -258.55507±0.00000  bestvalidloss -258.55507  last_update 0\n",
      "train: iter 42  trainloss -212.10051  validloss -226.93707±0.00000  bestvalidloss -258.55507  last_update 1\n",
      "train: iter 43  trainloss -173.03692  validloss -258.71481±0.00000  bestvalidloss -258.71481  last_update 0\n",
      "train: iter 44  trainloss -218.68331  validloss -251.41193±0.00000  bestvalidloss -258.71481  last_update 1\n",
      "train: iter 45  trainloss -219.52000  validloss -282.23273±0.00000  bestvalidloss -282.23273  last_update 0\n",
      "train: iter 46  trainloss -224.09426  validloss -275.51607±0.00000  bestvalidloss -282.23273  last_update 1\n",
      "train: iter 47  trainloss -219.46022  validloss -292.89437±0.00000  bestvalidloss -292.89437  last_update 0\n",
      "train: iter 48  trainloss -253.37273  validloss -286.16418±0.00000  bestvalidloss -292.89437  last_update 1\n",
      "train: iter 49  trainloss -243.67981  validloss -287.69824±0.00000  bestvalidloss -292.89437  last_update 2\n",
      "train: iter 50  trainloss -231.68731  validloss -297.27771±0.00000  bestvalidloss -297.27771  last_update 0\n",
      "train: iter 51  trainloss -210.14654  validloss -297.32509±0.00000  bestvalidloss -297.32509  last_update 0\n",
      "train: iter 52  trainloss -149.61450  validloss -284.26720±0.00000  bestvalidloss -297.32509  last_update 1\n",
      "train: iter 53  trainloss -211.59884  validloss -273.29755±0.00000  bestvalidloss -297.32509  last_update 2\n",
      "train: iter 54  trainloss -235.50577  validloss -316.18310±0.00000  bestvalidloss -316.18310  last_update 0\n",
      "train: iter 55  trainloss -255.38783  validloss -326.60964±0.00000  bestvalidloss -326.60964  last_update 0\n",
      "train: iter 56  trainloss -256.31451  validloss -328.28850±0.00000  bestvalidloss -328.28850  last_update 0\n",
      "train: iter 57  trainloss -263.82246  validloss -328.26590±0.00000  bestvalidloss -328.28850  last_update 1\n",
      "train: iter 58  trainloss -265.38289  validloss -272.70367±0.00000  bestvalidloss -328.28850  last_update 2\n",
      "train: iter 59  trainloss -290.28283  validloss -354.86310±0.00000  bestvalidloss -354.86310  last_update 0\n",
      "train: iter 60  trainloss -294.18838  validloss -333.55958±0.00000  bestvalidloss -354.86310  last_update 1\n",
      "train: iter 61  trainloss -308.24443  validloss -374.96622±0.00000  bestvalidloss -374.96622  last_update 0\n",
      "train: iter 62  trainloss -304.81440  validloss -318.34346±0.00000  bestvalidloss -374.96622  last_update 1\n",
      "train: iter 63  trainloss -307.77728  validloss -351.11868±0.00000  bestvalidloss -374.96622  last_update 2\n",
      "train: iter 64  trainloss -329.53281  validloss -391.05660±0.00000  bestvalidloss -391.05660  last_update 0\n",
      "train: iter 65  trainloss -338.91752  validloss -408.76943±0.00000  bestvalidloss -408.76943  last_update 0\n",
      "train: iter 66  trainloss -344.99589  validloss -371.99910±0.00000  bestvalidloss -408.76943  last_update 1\n",
      "train: iter 67  trainloss -342.14886  validloss -407.37644±0.00000  bestvalidloss -408.76943  last_update 2\n",
      "train: iter 68  trainloss -362.91202  validloss -409.20687±0.00000  bestvalidloss -409.20687  last_update 0\n",
      "train: iter 69  trainloss -367.22281  validloss -408.47175±0.00000  bestvalidloss -409.20687  last_update 1\n",
      "train: iter 70  trainloss -374.45566  validloss -423.53742±0.00000  bestvalidloss -423.53742  last_update 0\n",
      "train: iter 71  trainloss -384.34243  validloss -460.96076±0.00000  bestvalidloss -460.96076  last_update 0\n",
      "train: iter 72  trainloss -399.79631  validloss -468.18909±0.00000  bestvalidloss -468.18909  last_update 0\n",
      "train: iter 73  trainloss -393.88031  validloss -417.96446±0.00000  bestvalidloss -468.18909  last_update 1\n",
      "train: iter 74  trainloss -382.29677  validloss -471.10129±0.00000  bestvalidloss -471.10129  last_update 0\n",
      "train: iter 75  trainloss -348.85012  validloss -396.68919±0.00000  bestvalidloss -471.10129  last_update 1\n",
      "train: iter 76  trainloss -368.90302  validloss -412.12194±0.00000  bestvalidloss -471.10129  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -410.19810  validloss -480.69770±0.00000  bestvalidloss -480.69770  last_update 0\n",
      "train: iter 78  trainloss -419.68517  validloss -461.24156±0.00000  bestvalidloss -480.69770  last_update 1\n",
      "train: iter 79  trainloss -431.22695  validloss -491.09596±0.00000  bestvalidloss -491.09596  last_update 0\n",
      "train: iter 80  trainloss -411.84945  validloss -463.79628±0.00000  bestvalidloss -491.09596  last_update 1\n",
      "train: iter 81  trainloss -403.30781  validloss -489.39639±0.00000  bestvalidloss -491.09596  last_update 2\n",
      "train: iter 82  trainloss -437.64956  validloss -496.12560±0.00000  bestvalidloss -496.12560  last_update 0\n",
      "train: iter 83  trainloss -451.89302  validloss -523.04469±0.00000  bestvalidloss -523.04469  last_update 0\n",
      "train: iter 84  trainloss -447.81227  validloss -523.44221±0.00000  bestvalidloss -523.44221  last_update 0\n",
      "train: iter 85  trainloss -463.42298  validloss -526.39394±0.00000  bestvalidloss -526.39394  last_update 0\n",
      "train: iter 86  trainloss -462.94295  validloss -527.46622±0.00000  bestvalidloss -527.46622  last_update 0\n",
      "train: iter 87  trainloss -448.49729  validloss -520.70813±0.00000  bestvalidloss -527.46622  last_update 1\n",
      "train: iter 88  trainloss -467.60343  validloss -527.47497±0.00000  bestvalidloss -527.47497  last_update 0\n",
      "train: iter 89  trainloss -435.69502  validloss -526.76466±0.00000  bestvalidloss -527.47497  last_update 1\n",
      "train: iter 90  trainloss -447.49442  validloss -525.63420±0.00000  bestvalidloss -527.47497  last_update 2\n",
      "train: iter 91  trainloss -451.99668  validloss -514.30536±0.00000  bestvalidloss -527.47497  last_update 3\n",
      "train: iter 92  trainloss -463.57395  validloss -535.83249±0.00000  bestvalidloss -535.83249  last_update 0\n",
      "train: iter 93  trainloss -450.96624  validloss -333.50673±0.00000  bestvalidloss -535.83249  last_update 1\n",
      "train: iter 94  trainloss -430.34828  validloss -545.35894±0.00000  bestvalidloss -545.35894  last_update 0\n",
      "train: iter 95  trainloss -465.82548  validloss -541.39642±0.00000  bestvalidloss -545.35894  last_update 1\n",
      "train: iter 96  trainloss -477.92908  validloss -532.34604±0.00000  bestvalidloss -545.35894  last_update 2\n",
      "train: iter 97  trainloss -465.04933  validloss -453.57004±0.00000  bestvalidloss -545.35894  last_update 3\n",
      "train: iter 98  trainloss -493.00614  validloss -552.17500±0.00000  bestvalidloss -552.17500  last_update 0\n",
      "train: iter 99  trainloss -494.81184  validloss -566.00831±0.00000  bestvalidloss -566.00831  last_update 0\n",
      "train: iter 100  trainloss -475.16370  validloss -559.57651±0.00000  bestvalidloss -566.00831  last_update 1\n",
      "train: iter 101  trainloss -480.27878  validloss -555.63903±0.00000  bestvalidloss -566.00831  last_update 2\n",
      "train: iter 102  trainloss -492.29416  validloss -572.97110±0.00000  bestvalidloss -572.97110  last_update 0\n",
      "train: iter 103  trainloss -493.52815  validloss -579.30408±0.00000  bestvalidloss -579.30408  last_update 0\n",
      "train: iter 104  trainloss -506.05876  validloss -569.50663±0.00000  bestvalidloss -579.30408  last_update 1\n",
      "train: iter 105  trainloss -503.16691  validloss -588.28767±0.00000  bestvalidloss -588.28767  last_update 0\n",
      "train: iter 106  trainloss -511.48995  validloss -586.26668±0.00000  bestvalidloss -588.28767  last_update 1\n",
      "train: iter 107  trainloss -505.20696  validloss -572.22535±0.00000  bestvalidloss -588.28767  last_update 2\n",
      "train: iter 108  trainloss -517.54166  validloss -592.49806±0.00000  bestvalidloss -592.49806  last_update 0\n",
      "train: iter 109  trainloss -482.41278  validloss -601.11498±0.00000  bestvalidloss -601.11498  last_update 0\n",
      "train: iter 110  trainloss -456.28841  validloss -560.56734±0.00000  bestvalidloss -601.11498  last_update 1\n",
      "train: iter 111  trainloss -514.88114  validloss -605.40154±0.00000  bestvalidloss -605.40154  last_update 0\n",
      "train: iter 112  trainloss -522.07027  validloss -611.89478±0.00000  bestvalidloss -611.89478  last_update 0\n",
      "train: iter 113  trainloss -528.66778  validloss -622.22752±0.00000  bestvalidloss -622.22752  last_update 0\n",
      "train: iter 114  trainloss -513.86076  validloss -626.91820±0.00000  bestvalidloss -626.91820  last_update 0\n",
      "train: iter 115  trainloss -534.23404  validloss -633.96580±0.00000  bestvalidloss -633.96580  last_update 0\n",
      "train: iter 116  trainloss -550.87589  validloss -638.28356±0.00000  bestvalidloss -638.28356  last_update 0\n",
      "train: iter 117  trainloss -550.88483  validloss -643.86313±0.00000  bestvalidloss -643.86313  last_update 0\n",
      "train: iter 118  trainloss -549.65333  validloss -622.19918±0.00000  bestvalidloss -643.86313  last_update 1\n",
      "train: iter 119  trainloss -538.03346  validloss -642.26733±0.00000  bestvalidloss -643.86313  last_update 2\n",
      "train: iter 120  trainloss -546.75316  validloss -638.02707±0.00000  bestvalidloss -643.86313  last_update 3\n",
      "train: iter 121  trainloss -532.11480  validloss -599.04222±0.00000  bestvalidloss -643.86313  last_update 4\n",
      "train: iter 122  trainloss -541.44559  validloss -649.17529±0.00000  bestvalidloss -649.17529  last_update 0\n",
      "train: iter 123  trainloss -541.74715  validloss -591.23493±0.00000  bestvalidloss -649.17529  last_update 1\n",
      "train: iter 124  trainloss -544.97469  validloss -634.05447±0.00000  bestvalidloss -649.17529  last_update 2\n",
      "train: iter 125  trainloss -555.40416  validloss -666.69159±0.00000  bestvalidloss -666.69159  last_update 0\n",
      "train: iter 126  trainloss -574.61873  validloss -669.20657±0.00000  bestvalidloss -669.20657  last_update 0\n",
      "train: iter 127  trainloss -577.39718  validloss -672.89109±0.00000  bestvalidloss -672.89109  last_update 0\n",
      "train: iter 128  trainloss -527.79130  validloss -670.34381±0.00000  bestvalidloss -672.89109  last_update 1\n",
      "train: iter 129  trainloss -584.76820  validloss -594.75021±0.00000  bestvalidloss -672.89109  last_update 2\n",
      "train: iter 130  trainloss -565.82389  validloss -683.18418±0.00000  bestvalidloss -683.18418  last_update 0\n",
      "train: iter 131  trainloss -585.72751  validloss -685.01142±0.00000  bestvalidloss -685.01142  last_update 0\n",
      "train: iter 132  trainloss -593.48628  validloss -688.81433±0.00000  bestvalidloss -688.81433  last_update 0\n",
      "train: iter 133  trainloss -553.78030  validloss -687.20776±0.00000  bestvalidloss -688.81433  last_update 1\n",
      "train: iter 134  trainloss -593.33041  validloss -661.69255±0.00000  bestvalidloss -688.81433  last_update 2\n",
      "train: iter 135  trainloss -561.91551  validloss -681.33647±0.00000  bestvalidloss -688.81433  last_update 3\n",
      "train: iter 136  trainloss -547.63612  validloss -694.79403±0.00000  bestvalidloss -694.79403  last_update 0\n",
      "train: iter 137  trainloss -590.25838  validloss -696.46120±0.00000  bestvalidloss -696.46120  last_update 0\n",
      "train: iter 138  trainloss -587.00113  validloss -643.81572±0.00000  bestvalidloss -696.46120  last_update 1\n",
      "train: iter 139  trainloss -611.90432  validloss -707.25558±0.00000  bestvalidloss -707.25558  last_update 0\n",
      "train: iter 140  trainloss -604.47588  validloss -713.77522±0.00000  bestvalidloss -713.77522  last_update 0\n",
      "train: iter 141  trainloss -567.75209  validloss -675.84059±0.00000  bestvalidloss -713.77522  last_update 1\n",
      "train: iter 142  trainloss -595.20307  validloss -706.99626±0.00000  bestvalidloss -713.77522  last_update 2\n",
      "train: iter 143  trainloss -581.55760  validloss -678.45675±0.00000  bestvalidloss -713.77522  last_update 3\n",
      "train: iter 144  trainloss -595.01473  validloss -685.02531±0.00000  bestvalidloss -713.77522  last_update 4\n",
      "train: iter 145  trainloss -594.03035  validloss -659.16728±0.00000  bestvalidloss -713.77522  last_update 5\n",
      "train: iter 146  trainloss -603.87708  validloss -718.91712±0.00000  bestvalidloss -718.91712  last_update 0\n",
      "train: iter 147  trainloss -604.82297  validloss -708.64359±0.00000  bestvalidloss -718.91712  last_update 1\n",
      "train: iter 148  trainloss -612.60823  validloss -709.08750±0.00000  bestvalidloss -718.91712  last_update 2\n",
      "train: iter 149  trainloss -605.25850  validloss -692.63465±0.00000  bestvalidloss -718.91712  last_update 3\n",
      "train: iter 150  trainloss -617.38311  validloss -702.42729±0.00000  bestvalidloss -718.91712  last_update 4\n",
      "train: iter 151  trainloss -632.65271  validloss -733.48980±0.00000  bestvalidloss -733.48980  last_update 0\n",
      "train: iter 152  trainloss -622.33183  validloss -737.43078±0.00000  bestvalidloss -737.43078  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -604.34714  validloss -644.95528±0.00000  bestvalidloss -737.43078  last_update 1\n",
      "train: iter 154  trainloss -607.43739  validloss -737.63595±0.00000  bestvalidloss -737.63595  last_update 0\n",
      "train: iter 155  trainloss -621.27185  validloss -718.77420±0.00000  bestvalidloss -737.63595  last_update 1\n",
      "train: iter 156  trainloss -629.04182  validloss -714.97394±0.00000  bestvalidloss -737.63595  last_update 2\n",
      "train: iter 157  trainloss -622.38945  validloss -727.83518±0.00000  bestvalidloss -737.63595  last_update 3\n",
      "train: iter 158  trainloss -632.62202  validloss -736.85038±0.00000  bestvalidloss -737.63595  last_update 4\n",
      "train: iter 159  trainloss -634.82490  validloss -744.45310±0.00000  bestvalidloss -744.45310  last_update 0\n",
      "train: iter 160  trainloss -633.79067  validloss -739.21219±0.00000  bestvalidloss -744.45310  last_update 1\n",
      "train: iter 161  trainloss -632.39030  validloss -747.67614±0.00000  bestvalidloss -747.67614  last_update 0\n",
      "train: iter 162  trainloss -545.60943  validloss -630.67883±0.00000  bestvalidloss -747.67614  last_update 1\n",
      "train: iter 163  trainloss -601.66110  validloss -707.81963±0.00000  bestvalidloss -747.67614  last_update 2\n",
      "train: iter 164  trainloss -611.48675  validloss -729.16882±0.00000  bestvalidloss -747.67614  last_update 3\n",
      "train: iter 165  trainloss -594.55443  validloss -679.60380±0.00000  bestvalidloss -747.67614  last_update 4\n",
      "train: iter 166  trainloss -601.98765  validloss -719.79967±0.00000  bestvalidloss -747.67614  last_update 5\n",
      "train: iter 167  trainloss -607.90704  validloss -672.45394±0.00000  bestvalidloss -747.67614  last_update 6\n",
      "train: iter 168  trainloss -599.11074  validloss -728.20231±0.00000  bestvalidloss -747.67614  last_update 7\n",
      "train: iter 169  trainloss -635.49466  validloss -745.30177±0.00000  bestvalidloss -747.67614  last_update 8\n",
      "train: iter 170  trainloss -633.19986  validloss -753.30934±0.00000  bestvalidloss -753.30934  last_update 0\n",
      "train: iter 171  trainloss -624.95751  validloss -744.29249±0.00000  bestvalidloss -753.30934  last_update 1\n",
      "train: iter 172  trainloss -637.17546  validloss -748.19761±0.00000  bestvalidloss -753.30934  last_update 2\n",
      "train: iter 173  trainloss -645.40891  validloss -707.71853±0.00000  bestvalidloss -753.30934  last_update 3\n",
      "train: iter 174  trainloss -638.65388  validloss -755.09930±0.00000  bestvalidloss -755.09930  last_update 0\n",
      "train: iter 175  trainloss -653.71692  validloss -756.24546±0.00000  bestvalidloss -756.24546  last_update 0\n",
      "train: iter 176  trainloss -657.73363  validloss -748.19040±0.00000  bestvalidloss -756.24546  last_update 1\n",
      "train: iter 177  trainloss -643.47400  validloss -684.60199±0.00000  bestvalidloss -756.24546  last_update 2\n",
      "train: iter 178  trainloss -636.94348  validloss -751.34669±0.00000  bestvalidloss -756.24546  last_update 3\n",
      "train: iter 179  trainloss -648.65951  validloss -745.04701±0.00000  bestvalidloss -756.24546  last_update 4\n",
      "train: iter 180  trainloss -661.84379  validloss -747.42342±0.00000  bestvalidloss -756.24546  last_update 5\n",
      "train: iter 181  trainloss -649.62598  validloss -760.04348±0.00000  bestvalidloss -760.04348  last_update 0\n",
      "train: iter 182  trainloss -598.74332  validloss -762.61761±0.00000  bestvalidloss -762.61761  last_update 0\n",
      "train: iter 183  trainloss -615.80320  validloss -731.21819±0.00000  bestvalidloss -762.61761  last_update 1\n",
      "train: iter 184  trainloss -620.38956  validloss -744.42605±0.00000  bestvalidloss -762.61761  last_update 2\n",
      "train: iter 185  trainloss -625.86478  validloss -757.26213±0.00000  bestvalidloss -762.61761  last_update 3\n",
      "train: iter 186  trainloss -625.92388  validloss -751.33162±0.00000  bestvalidloss -762.61761  last_update 4\n",
      "train: iter 187  trainloss -638.85722  validloss -725.79392±0.00000  bestvalidloss -762.61761  last_update 5\n",
      "train: iter 188  trainloss -637.41520  validloss -755.15249±0.00000  bestvalidloss -762.61761  last_update 6\n",
      "train: iter 189  trainloss -618.08555  validloss -767.29738±0.00000  bestvalidloss -767.29738  last_update 0\n",
      "train: iter 190  trainloss -633.03958  validloss -758.73054±0.00000  bestvalidloss -767.29738  last_update 1\n",
      "train: iter 191  trainloss -651.97487  validloss -754.99788±0.00000  bestvalidloss -767.29738  last_update 2\n",
      "train: iter 192  trainloss -657.20054  validloss -773.17296±0.00000  bestvalidloss -773.17296  last_update 0\n",
      "train: iter 193  trainloss -646.72303  validloss -741.56378±0.00000  bestvalidloss -773.17296  last_update 1\n",
      "train: iter 194  trainloss -602.16862  validloss -694.19184±0.00000  bestvalidloss -773.17296  last_update 2\n",
      "train: iter 195  trainloss -610.06686  validloss -745.14600±0.00000  bestvalidloss -773.17296  last_update 3\n",
      "train: iter 196  trainloss -644.20099  validloss -747.87224±0.00000  bestvalidloss -773.17296  last_update 4\n",
      "train: iter 197  trainloss -634.84143  validloss -759.82722±0.00000  bestvalidloss -773.17296  last_update 5\n",
      "train: iter 198  trainloss -648.35873  validloss -721.64223±0.00000  bestvalidloss -773.17296  last_update 6\n",
      "train: iter 199  trainloss -654.46105  validloss -762.13222±0.00000  bestvalidloss -773.17296  last_update 7\n",
      "train: iter 200  trainloss -665.32101  validloss -755.80258±0.00000  bestvalidloss -773.17296  last_update 8\n",
      "train: iter 201  trainloss -656.68027  validloss -762.33863±0.00000  bestvalidloss -773.17296  last_update 9\n",
      "train: iter 202  trainloss -570.51180  validloss -652.38975±0.00000  bestvalidloss -773.17296  last_update 10\n",
      "train: iter 203  trainloss -629.76081  validloss -711.72157±0.00000  bestvalidloss -773.17296  last_update 11\n",
      "train: iter 204  trainloss -622.84171  validloss -763.29398±0.00000  bestvalidloss -773.17296  last_update 12\n",
      "train: iter 205  trainloss -639.82456  validloss -753.95839±0.00000  bestvalidloss -773.17296  last_update 13\n",
      "train: iter 206  trainloss -655.39656  validloss -750.89672±0.00000  bestvalidloss -773.17296  last_update 14\n",
      "train: iter 207  trainloss -653.57419  validloss -765.89953±0.00000  bestvalidloss -773.17296  last_update 15\n",
      "train: iter 208  trainloss -653.47893  validloss -774.05761±0.00000  bestvalidloss -774.05761  last_update 0\n",
      "train: iter 209  trainloss -660.85773  validloss -748.90015±0.00000  bestvalidloss -774.05761  last_update 1\n",
      "train: iter 210  trainloss -647.82058  validloss -747.21110±0.00000  bestvalidloss -774.05761  last_update 2\n",
      "train: iter 211  trainloss -653.30249  validloss -748.86308±0.00000  bestvalidloss -774.05761  last_update 3\n",
      "train: iter 212  trainloss -630.06134  validloss -763.15231±0.00000  bestvalidloss -774.05761  last_update 4\n",
      "train: iter 213  trainloss -597.61907  validloss -721.04252±0.00000  bestvalidloss -774.05761  last_update 5\n",
      "train: iter 214  trainloss -615.02961  validloss -708.90990±0.00000  bestvalidloss -774.05761  last_update 6\n",
      "train: iter 215  trainloss -638.26822  validloss -774.32435±0.00000  bestvalidloss -774.32435  last_update 0\n",
      "train: iter 216  trainloss -596.54684  validloss -594.99663±0.00000  bestvalidloss -774.32435  last_update 1\n",
      "train: iter 217  trainloss -647.85369  validloss -639.94101±0.00000  bestvalidloss -774.32435  last_update 2\n",
      "train: iter 218  trainloss -557.58393  validloss -756.53398±0.00000  bestvalidloss -774.32435  last_update 3\n",
      "train: iter 219  trainloss -633.11860  validloss -613.54502±0.00000  bestvalidloss -774.32435  last_update 4\n",
      "train: iter 220  trainloss -667.23381  validloss -743.45334±0.00000  bestvalidloss -774.32435  last_update 5\n",
      "train: iter 221  trainloss -663.97781  validloss -776.13832±0.00000  bestvalidloss -776.13832  last_update 0\n",
      "train: iter 222  trainloss -660.44910  validloss -786.26206±0.00000  bestvalidloss -786.26206  last_update 0\n",
      "train: iter 223  trainloss -648.93410  validloss -776.09928±0.00000  bestvalidloss -786.26206  last_update 1\n",
      "train: iter 224  trainloss -664.36918  validloss -745.18277±0.00000  bestvalidloss -786.26206  last_update 2\n",
      "train: iter 225  trainloss -669.76302  validloss -786.22809±0.00000  bestvalidloss -786.26206  last_update 3\n",
      "train: iter 226  trainloss -673.08043  validloss -778.76918±0.00000  bestvalidloss -786.26206  last_update 4\n",
      "train: iter 227  trainloss -672.66725  validloss -784.08822±0.00000  bestvalidloss -786.26206  last_update 5\n",
      "train: iter 228  trainloss -612.73633  validloss -697.86306±0.00000  bestvalidloss -786.26206  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 229  trainloss -657.47354  validloss -773.65744±0.00000  bestvalidloss -786.26206  last_update 7\n",
      "train: iter 230  trainloss -674.10066  validloss -786.36715±0.00000  bestvalidloss -786.36715  last_update 0\n",
      "train: iter 231  trainloss -653.49951  validloss -779.52498±0.00000  bestvalidloss -786.36715  last_update 1\n",
      "train: iter 232  trainloss -668.57316  validloss -784.34928±0.00000  bestvalidloss -786.36715  last_update 2\n",
      "train: iter 233  trainloss -671.48957  validloss -739.58238±0.00000  bestvalidloss -786.36715  last_update 3\n",
      "train: iter 234  trainloss -664.90693  validloss -764.11982±0.00000  bestvalidloss -786.36715  last_update 4\n",
      "train: iter 235  trainloss -661.12155  validloss -591.09916±0.00000  bestvalidloss -786.36715  last_update 5\n",
      "train: iter 236  trainloss -622.07627  validloss -747.16578±0.00000  bestvalidloss -786.36715  last_update 6\n",
      "train: iter 237  trainloss -650.79392  validloss -714.69047±0.00000  bestvalidloss -786.36715  last_update 7\n",
      "train: iter 238  trainloss -644.25095  validloss -773.86891±0.00000  bestvalidloss -786.36715  last_update 8\n",
      "train: iter 239  trainloss -624.28636  validloss -763.18882±0.00000  bestvalidloss -786.36715  last_update 9\n",
      "train: iter 240  trainloss -675.86296  validloss -774.03365±0.00000  bestvalidloss -786.36715  last_update 10\n",
      "train: iter 241  trainloss -679.08752  validloss -783.15609±0.00000  bestvalidloss -786.36715  last_update 11\n",
      "train: iter 242  trainloss -667.76022  validloss -761.56514±0.00000  bestvalidloss -786.36715  last_update 12\n",
      "train: iter 243  trainloss -672.16319  validloss -784.02110±0.00000  bestvalidloss -786.36715  last_update 13\n",
      "train: iter 244  trainloss -684.26558  validloss -783.19357±0.00000  bestvalidloss -786.36715  last_update 14\n",
      "train: iter 245  trainloss -580.80740  validloss -788.60359±0.00000  bestvalidloss -788.60359  last_update 0\n",
      "train: iter 246  trainloss -644.41847  validloss -747.48918±0.00000  bestvalidloss -788.60359  last_update 1\n",
      "train: iter 247  trainloss -636.45880  validloss -788.96873±0.00000  bestvalidloss -788.96873  last_update 0\n",
      "train: iter 248  trainloss -635.53464  validloss -778.61862±0.00000  bestvalidloss -788.96873  last_update 1\n",
      "train: iter 249  trainloss -652.70690  validloss -759.81337±0.00000  bestvalidloss -788.96873  last_update 2\n",
      "train: iter 250  trainloss -579.51700  validloss -752.42318±0.00000  bestvalidloss -788.96873  last_update 3\n",
      "train: iter 251  trainloss -645.44645  validloss -759.26475±0.00000  bestvalidloss -788.96873  last_update 4\n",
      "train: iter 252  trainloss -654.75350  validloss -772.96210±0.00000  bestvalidloss -788.96873  last_update 5\n",
      "train: iter 253  trainloss -645.93192  validloss -789.90317±0.00000  bestvalidloss -789.90317  last_update 0\n",
      "train: iter 254  trainloss -648.24449  validloss -778.97669±0.00000  bestvalidloss -789.90317  last_update 1\n",
      "train: iter 255  trainloss -644.11975  validloss -713.85309±0.00000  bestvalidloss -789.90317  last_update 2\n",
      "train: iter 256  trainloss -647.66351  validloss -730.45274±0.00000  bestvalidloss -789.90317  last_update 3\n",
      "train: iter 257  trainloss -660.81127  validloss -791.72429±0.00000  bestvalidloss -791.72429  last_update 0\n",
      "train: iter 258  trainloss -652.70566  validloss -682.71061±0.00000  bestvalidloss -791.72429  last_update 1\n",
      "train: iter 259  trainloss -665.77683  validloss -780.81890±0.00000  bestvalidloss -791.72429  last_update 2\n",
      "train: iter 260  trainloss -666.20001  validloss -789.75699±0.00000  bestvalidloss -791.72429  last_update 3\n",
      "train: iter 261  trainloss -672.14670  validloss -778.23513±0.00000  bestvalidloss -791.72429  last_update 4\n",
      "train: iter 262  trainloss -663.69297  validloss -780.19887±0.00000  bestvalidloss -791.72429  last_update 5\n",
      "train: iter 263  trainloss -645.94412  validloss -760.77036±0.00000  bestvalidloss -791.72429  last_update 6\n",
      "train: iter 264  trainloss -645.59910  validloss -777.56617±0.00000  bestvalidloss -791.72429  last_update 7\n",
      "train: iter 265  trainloss -665.15492  validloss -774.69727±0.00000  bestvalidloss -791.72429  last_update 8\n",
      "train: iter 266  trainloss -656.33747  validloss -783.86814±0.00000  bestvalidloss -791.72429  last_update 9\n",
      "train: iter 267  trainloss -663.86986  validloss -768.66899±0.00000  bestvalidloss -791.72429  last_update 10\n",
      "train: iter 268  trainloss -674.13587  validloss -779.27000±0.00000  bestvalidloss -791.72429  last_update 11\n",
      "train: iter 269  trainloss -678.54309  validloss -755.60074±0.00000  bestvalidloss -791.72429  last_update 12\n",
      "train: iter 270  trainloss -681.79148  validloss -790.22675±0.00000  bestvalidloss -791.72429  last_update 13\n",
      "train: iter 271  trainloss -682.52733  validloss -769.09375±0.00000  bestvalidloss -791.72429  last_update 14\n",
      "train: iter 272  trainloss -637.51222  validloss -747.77449±0.00000  bestvalidloss -791.72429  last_update 15\n",
      "train: iter 273  trainloss -553.40213  validloss -600.40037±0.00000  bestvalidloss -791.72429  last_update 16\n",
      "train: iter 274  trainloss -656.45039  validloss -759.57098±0.00000  bestvalidloss -791.72429  last_update 17\n",
      "train: iter 275  trainloss -680.98381  validloss -787.10280±0.00000  bestvalidloss -791.72429  last_update 18\n",
      "train: iter 276  trainloss -684.35929  validloss -783.63423±0.00000  bestvalidloss -791.72429  last_update 19\n",
      "train: iter 277  trainloss -652.17288  validloss -763.54090±0.00000  bestvalidloss -791.72429  last_update 20\n",
      "train: iter 278  trainloss -650.04391  validloss -753.21621±0.00000  bestvalidloss -791.72429  last_update 21\n",
      "train: iter 279  trainloss -681.23103  validloss -659.34728±0.00000  bestvalidloss -791.72429  last_update 22\n",
      "train: iter 280  trainloss -655.15808  validloss -749.27030±0.00000  bestvalidloss -791.72429  last_update 23\n",
      "train: iter 281  trainloss -625.53439  validloss -716.05477±0.00000  bestvalidloss -791.72429  last_update 24\n",
      "train: iter 282  trainloss -681.19050  validloss -791.20701±0.00000  bestvalidloss -791.72429  last_update 25\n",
      "train: iter 283  trainloss -694.10761  validloss -743.09386±0.00000  bestvalidloss -791.72429  last_update 26\n",
      "train: iter 284  trainloss -635.72099  validloss -792.36140±0.00000  bestvalidloss -792.36140  last_update 0\n",
      "train: iter 285  trainloss -646.38202  validloss -693.77815±0.00000  bestvalidloss -792.36140  last_update 1\n",
      "train: iter 286  trainloss -660.46195  validloss -779.51326±0.00000  bestvalidloss -792.36140  last_update 2\n",
      "train: iter 287  trainloss -638.66040  validloss -782.15103±0.00000  bestvalidloss -792.36140  last_update 3\n",
      "train: iter 288  trainloss -655.79994  validloss -788.86747±0.00000  bestvalidloss -792.36140  last_update 4\n",
      "train: iter 289  trainloss -639.95732  validloss -790.64495±0.00000  bestvalidloss -792.36140  last_update 5\n",
      "train: iter 290  trainloss -654.88254  validloss -762.44540±0.00000  bestvalidloss -792.36140  last_update 6\n",
      "train: iter 291  trainloss -651.04524  validloss -793.01448±0.00000  bestvalidloss -793.01448  last_update 0\n",
      "train: iter 292  trainloss -662.04868  validloss -727.79701±0.00000  bestvalidloss -793.01448  last_update 1\n",
      "train: iter 293  trainloss -671.35255  validloss -792.22016±0.00000  bestvalidloss -793.01448  last_update 2\n",
      "train: iter 294  trainloss -673.66976  validloss -772.72170±0.00000  bestvalidloss -793.01448  last_update 3\n",
      "train: iter 295  trainloss -685.00768  validloss -771.97249±0.00000  bestvalidloss -793.01448  last_update 4\n",
      "train: iter 296  trainloss -678.71981  validloss -789.61556±0.00000  bestvalidloss -793.01448  last_update 5\n",
      "train: iter 297  trainloss -678.41222  validloss -796.41649±0.00000  bestvalidloss -796.41649  last_update 0\n",
      "train: iter 298  trainloss -653.43501  validloss -768.30847±0.00000  bestvalidloss -796.41649  last_update 1\n",
      "train: iter 299  trainloss -684.66554  validloss -751.55620±0.00000  bestvalidloss -796.41649  last_update 2\n",
      "train: iter 300  trainloss -683.83878  validloss -791.77878±0.00000  bestvalidloss -796.41649  last_update 3\n",
      "train: iter 301  trainloss -647.29028  validloss -792.48580±0.00000  bestvalidloss -796.41649  last_update 4\n",
      "train: iter 302  trainloss -667.95388  validloss -768.51883±0.00000  bestvalidloss -796.41649  last_update 5\n",
      "train: iter 303  trainloss -687.78237  validloss -785.62966±0.00000  bestvalidloss -796.41649  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 304  trainloss -673.09604  validloss -798.09933±0.00000  bestvalidloss -798.09933  last_update 0\n",
      "train: iter 305  trainloss -663.52851  validloss -689.71745±0.00000  bestvalidloss -798.09933  last_update 1\n",
      "train: iter 306  trainloss -678.71352  validloss -765.86602±0.00000  bestvalidloss -798.09933  last_update 2\n",
      "train: iter 307  trainloss -640.20572  validloss -664.66019±0.00000  bestvalidloss -798.09933  last_update 3\n",
      "train: iter 308  trainloss -641.97531  validloss -791.54694±0.00000  bestvalidloss -798.09933  last_update 4\n",
      "train: iter 309  trainloss -659.58302  validloss -783.54022±0.00000  bestvalidloss -798.09933  last_update 5\n",
      "train: iter 310  trainloss -639.14894  validloss -796.32788±0.00000  bestvalidloss -798.09933  last_update 6\n",
      "train: iter 311  trainloss -658.46000  validloss -766.69327±0.00000  bestvalidloss -798.09933  last_update 7\n",
      "train: iter 312  trainloss -668.44912  validloss -790.01773±0.00000  bestvalidloss -798.09933  last_update 8\n",
      "train: iter 313  trainloss -653.41750  validloss -699.52244±0.00000  bestvalidloss -798.09933  last_update 9\n",
      "train: iter 314  trainloss -682.29600  validloss -796.37428±0.00000  bestvalidloss -798.09933  last_update 10\n",
      "train: iter 315  trainloss -676.49349  validloss -789.80245±0.00000  bestvalidloss -798.09933  last_update 11\n",
      "train: iter 316  trainloss -685.59080  validloss -794.28316±0.00000  bestvalidloss -798.09933  last_update 12\n",
      "train: iter 317  trainloss -675.16814  validloss -789.61759±0.00000  bestvalidloss -798.09933  last_update 13\n",
      "train: iter 318  trainloss -685.98004  validloss -797.75511±0.00000  bestvalidloss -798.09933  last_update 14\n",
      "train: iter 319  trainloss -686.22443  validloss -788.05430±0.00000  bestvalidloss -798.09933  last_update 15\n",
      "train: iter 320  trainloss -684.54481  validloss -803.46837±0.00000  bestvalidloss -803.46837  last_update 0\n",
      "train: iter 321  trainloss -682.64898  validloss -791.79846±0.00000  bestvalidloss -803.46837  last_update 1\n",
      "train: iter 322  trainloss -683.13001  validloss -764.04494±0.00000  bestvalidloss -803.46837  last_update 2\n",
      "train: iter 323  trainloss -692.57560  validloss -784.79611±0.00000  bestvalidloss -803.46837  last_update 3\n",
      "train: iter 324  trainloss -691.76885  validloss -798.32037±0.00000  bestvalidloss -803.46837  last_update 4\n",
      "train: iter 325  trainloss -696.14673  validloss -786.65096±0.00000  bestvalidloss -803.46837  last_update 5\n",
      "train: iter 326  trainloss -668.43840  validloss -798.77712±0.00000  bestvalidloss -803.46837  last_update 6\n",
      "train: iter 327  trainloss -693.89964  validloss -780.81935±0.00000  bestvalidloss -803.46837  last_update 7\n",
      "train: iter 328  trainloss -616.49213  validloss -748.69957±0.00000  bestvalidloss -803.46837  last_update 8\n",
      "train: iter 329  trainloss -656.41592  validloss -748.44561±0.00000  bestvalidloss -803.46837  last_update 9\n",
      "train: iter 330  trainloss -660.18779  validloss -757.00830±0.00000  bestvalidloss -803.46837  last_update 10\n",
      "train: iter 331  trainloss -658.35767  validloss -808.50535±0.00000  bestvalidloss -808.50535  last_update 0\n",
      "train: iter 332  trainloss -641.17808  validloss -720.91642±0.00000  bestvalidloss -808.50535  last_update 1\n",
      "train: iter 333  trainloss -683.09084  validloss -769.65046±0.00000  bestvalidloss -808.50535  last_update 2\n",
      "train: iter 334  trainloss -673.59420  validloss -802.58750±0.00000  bestvalidloss -808.50535  last_update 3\n",
      "train: iter 335  trainloss -693.48342  validloss -801.87167±0.00000  bestvalidloss -808.50535  last_update 4\n",
      "train: iter 336  trainloss -685.02287  validloss -795.20909±0.00000  bestvalidloss -808.50535  last_update 5\n",
      "train: iter 337  trainloss -680.57330  validloss -802.00724±0.00000  bestvalidloss -808.50535  last_update 6\n",
      "train: iter 338  trainloss -689.97305  validloss -803.13869±0.00000  bestvalidloss -808.50535  last_update 7\n",
      "train: iter 339  trainloss -674.63060  validloss -775.96103±0.00000  bestvalidloss -808.50535  last_update 8\n",
      "train: iter 340  trainloss -671.12647  validloss -802.99804±0.00000  bestvalidloss -808.50535  last_update 9\n",
      "train: iter 341  trainloss -668.80158  validloss -774.77504±0.00000  bestvalidloss -808.50535  last_update 10\n",
      "train: iter 342  trainloss -637.29456  validloss -693.44081±0.00000  bestvalidloss -808.50535  last_update 11\n",
      "train: iter 343  trainloss -668.82554  validloss -762.98246±0.00000  bestvalidloss -808.50535  last_update 12\n",
      "train: iter 344  trainloss -662.54896  validloss -784.89142±0.00000  bestvalidloss -808.50535  last_update 13\n",
      "train: iter 345  trainloss -680.06797  validloss -745.51927±0.00000  bestvalidloss -808.50535  last_update 14\n",
      "train: iter 346  trainloss -669.15663  validloss -768.98792±0.00000  bestvalidloss -808.50535  last_update 15\n",
      "train: iter 347  trainloss -692.61420  validloss -802.09502±0.00000  bestvalidloss -808.50535  last_update 16\n",
      "train: iter 348  trainloss -695.62700  validloss -779.96000±0.00000  bestvalidloss -808.50535  last_update 17\n",
      "train: iter 349  trainloss -692.39011  validloss -728.35821±0.00000  bestvalidloss -808.50535  last_update 18\n",
      "train: iter 350  trainloss -664.85711  validloss -803.44124±0.00000  bestvalidloss -808.50535  last_update 19\n",
      "train: iter 351  trainloss -676.75541  validloss -782.22461±0.00000  bestvalidloss -808.50535  last_update 20\n",
      "train: iter 352  trainloss -685.77308  validloss -738.89621±0.00000  bestvalidloss -808.50535  last_update 21\n",
      "train: iter 353  trainloss -662.81291  validloss -749.72478±0.00000  bestvalidloss -808.50535  last_update 22\n",
      "train: iter 354  trainloss -668.03546  validloss -799.03591±0.00000  bestvalidloss -808.50535  last_update 23\n",
      "train: iter 355  trainloss -688.92211  validloss -694.46361±0.00000  bestvalidloss -808.50535  last_update 24\n",
      "train: iter 356  trainloss -701.05121  validloss -762.49046±0.00000  bestvalidloss -808.50535  last_update 25\n",
      "train: iter 357  trainloss -691.33760  validloss -714.67297±0.00000  bestvalidloss -808.50535  last_update 26\n",
      "train: iter 358  trainloss -642.25374  validloss -780.31965±0.00000  bestvalidloss -808.50535  last_update 27\n",
      "train: iter 359  trainloss -640.22231  validloss -757.87894±0.00000  bestvalidloss -808.50535  last_update 28\n",
      "train: iter 360  trainloss -654.29187  validloss -754.26924±0.00000  bestvalidloss -808.50535  last_update 29\n",
      "train: iter 361  trainloss -669.14372  validloss -705.25852±0.00000  bestvalidloss -808.50535  last_update 30\n",
      "train: iter 362  trainloss -681.43124  validloss -784.98223±0.00000  bestvalidloss -808.50535  last_update 31\n",
      "train: iter 363  trainloss -702.44628  validloss -779.57132±0.00000  bestvalidloss -808.50535  last_update 32\n",
      "train: iter 364  trainloss -673.04728  validloss -809.11651±0.00000  bestvalidloss -809.11651  last_update 0\n",
      "train: iter 365  trainloss -672.08003  validloss -756.09352±0.00000  bestvalidloss -809.11651  last_update 1\n",
      "train: iter 366  trainloss -694.52968  validloss -794.41907±0.00000  bestvalidloss -809.11651  last_update 2\n",
      "train: iter 367  trainloss -692.98916  validloss -789.74454±0.00000  bestvalidloss -809.11651  last_update 3\n",
      "train: iter 368  trainloss -650.13423  validloss -559.33953±0.00000  bestvalidloss -809.11651  last_update 4\n",
      "train: iter 369  trainloss -676.36860  validloss -773.13758±0.00000  bestvalidloss -809.11651  last_update 5\n",
      "train: iter 370  trainloss -692.61630  validloss -793.99848±0.00000  bestvalidloss -809.11651  last_update 6\n",
      "train: iter 371  trainloss -699.75723  validloss -811.76799±0.00000  bestvalidloss -811.76799  last_update 0\n",
      "train: iter 372  trainloss -693.28629  validloss -664.86980±0.00000  bestvalidloss -811.76799  last_update 1\n",
      "train: iter 373  trainloss -693.37103  validloss -789.49490±0.00000  bestvalidloss -811.76799  last_update 2\n",
      "train: iter 374  trainloss -679.70459  validloss -792.68841±0.00000  bestvalidloss -811.76799  last_update 3\n",
      "train: iter 375  trainloss -685.06664  validloss -798.23624±0.00000  bestvalidloss -811.76799  last_update 4\n",
      "train: iter 376  trainloss -677.87289  validloss -813.05741±0.00000  bestvalidloss -813.05741  last_update 0\n",
      "train: iter 377  trainloss -681.11692  validloss -744.23182±0.00000  bestvalidloss -813.05741  last_update 1\n",
      "train: iter 378  trainloss -697.72916  validloss -793.22656±0.00000  bestvalidloss -813.05741  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 379  trainloss -681.72109  validloss -801.74976±0.00000  bestvalidloss -813.05741  last_update 3\n",
      "train: iter 380  trainloss -676.75499  validloss -787.86225±0.00000  bestvalidloss -813.05741  last_update 4\n",
      "train: iter 381  trainloss -683.33798  validloss -802.43390±0.00000  bestvalidloss -813.05741  last_update 5\n",
      "train: iter 382  trainloss -694.84893  validloss -710.05807±0.00000  bestvalidloss -813.05741  last_update 6\n",
      "train: iter 383  trainloss -673.49672  validloss -776.40023±0.00000  bestvalidloss -813.05741  last_update 7\n",
      "train: iter 384  trainloss -664.50283  validloss -771.18597±0.00000  bestvalidloss -813.05741  last_update 8\n",
      "train: iter 385  trainloss -675.07120  validloss -786.84051±0.00000  bestvalidloss -813.05741  last_update 9\n",
      "train: iter 386  trainloss -587.72411  validloss -807.11963±0.00000  bestvalidloss -813.05741  last_update 10\n",
      "train: iter 387  trainloss -645.04428  validloss -609.41329±0.00000  bestvalidloss -813.05741  last_update 11\n",
      "train: iter 388  trainloss -678.49994  validloss -792.30664±0.00000  bestvalidloss -813.05741  last_update 12\n",
      "train: iter 389  trainloss -671.46454  validloss -768.67925±0.00000  bestvalidloss -813.05741  last_update 13\n",
      "train: iter 390  trainloss -692.78349  validloss -762.67452±0.00000  bestvalidloss -813.05741  last_update 14\n",
      "train: iter 391  trainloss -687.12508  validloss -790.78002±0.00000  bestvalidloss -813.05741  last_update 15\n",
      "train: iter 392  trainloss -691.99201  validloss -800.96373±0.00000  bestvalidloss -813.05741  last_update 16\n",
      "train: iter 393  trainloss -697.67455  validloss -793.51969±0.00000  bestvalidloss -813.05741  last_update 17\n",
      "train: iter 394  trainloss -693.28492  validloss -783.26455±0.00000  bestvalidloss -813.05741  last_update 18\n",
      "train: iter 395  trainloss -678.04280  validloss -782.58544±0.00000  bestvalidloss -813.05741  last_update 19\n",
      "train: iter 396  trainloss -687.71530  validloss -644.41208±0.00000  bestvalidloss -813.05741  last_update 20\n",
      "train: iter 397  trainloss -695.46797  validloss -790.58894±0.00000  bestvalidloss -813.05741  last_update 21\n",
      "train: iter 398  trainloss -704.45895  validloss -802.84079±0.00000  bestvalidloss -813.05741  last_update 22\n",
      "train: iter 399  trainloss -705.10394  validloss -808.70282±0.00000  bestvalidloss -813.05741  last_update 23\n",
      "train: iter 400  trainloss -649.74578  validloss -808.78127±0.00000  bestvalidloss -813.05741  last_update 24\n",
      "train: iter 401  trainloss -671.85563  validloss -771.68395±0.00000  bestvalidloss -813.05741  last_update 25\n",
      "train: iter 402  trainloss -671.52578  validloss -794.16570±0.00000  bestvalidloss -813.05741  last_update 26\n",
      "train: iter 403  trainloss -667.48992  validloss -785.23701±0.00000  bestvalidloss -813.05741  last_update 27\n",
      "train: iter 404  trainloss -678.52110  validloss -803.46985±0.00000  bestvalidloss -813.05741  last_update 28\n",
      "train: iter 405  trainloss -685.22055  validloss -797.91459±0.00000  bestvalidloss -813.05741  last_update 29\n",
      "train: iter 406  trainloss -683.14928  validloss -783.21392±0.00000  bestvalidloss -813.05741  last_update 30\n",
      "train: iter 407  trainloss -694.80667  validloss -722.31268±0.00000  bestvalidloss -813.05741  last_update 31\n",
      "train: iter 408  trainloss -703.72774  validloss -813.81916±0.00000  bestvalidloss -813.81916  last_update 0\n",
      "train: iter 409  trainloss -704.30794  validloss -807.98177±0.00000  bestvalidloss -813.81916  last_update 1\n",
      "train: iter 410  trainloss -708.74335  validloss -810.73058±0.00000  bestvalidloss -813.81916  last_update 2\n",
      "train: iter 411  trainloss -675.86835  validloss -802.42097±0.00000  bestvalidloss -813.81916  last_update 3\n",
      "train: iter 412  trainloss -614.35458  validloss -776.88806±0.00000  bestvalidloss -813.81916  last_update 4\n",
      "train: iter 413  trainloss -688.93566  validloss -768.02903±0.00000  bestvalidloss -813.81916  last_update 5\n",
      "train: iter 414  trainloss -671.08066  validloss -797.55736±0.00000  bestvalidloss -813.81916  last_update 6\n",
      "train: iter 415  trainloss -700.90434  validloss -778.99579±0.00000  bestvalidloss -813.81916  last_update 7\n",
      "train: iter 416  trainloss -687.76566  validloss -814.73103±0.00000  bestvalidloss -814.73103  last_update 0\n",
      "train: iter 417  trainloss -656.37685  validloss -795.67346±0.00000  bestvalidloss -814.73103  last_update 1\n",
      "train: iter 418  trainloss -678.25884  validloss -734.51892±0.00000  bestvalidloss -814.73103  last_update 2\n",
      "train: iter 419  trainloss -687.25458  validloss -796.56932±0.00000  bestvalidloss -814.73103  last_update 3\n",
      "train: iter 420  trainloss -693.18038  validloss -765.18654±0.00000  bestvalidloss -814.73103  last_update 4\n",
      "train: iter 421  trainloss -707.05061  validloss -806.47241±0.00000  bestvalidloss -814.73103  last_update 5\n",
      "train: iter 422  trainloss -689.23639  validloss -758.61336±0.00000  bestvalidloss -814.73103  last_update 6\n",
      "train: iter 423  trainloss -694.52789  validloss -786.71773±0.00000  bestvalidloss -814.73103  last_update 7\n",
      "train: iter 424  trainloss -679.20622  validloss -796.10264±0.00000  bestvalidloss -814.73103  last_update 8\n",
      "train: iter 425  trainloss -680.75892  validloss -779.63252±0.00000  bestvalidloss -814.73103  last_update 9\n",
      "train: iter 426  trainloss -660.54615  validloss -753.45103±0.00000  bestvalidloss -814.73103  last_update 10\n",
      "train: iter 427  trainloss -694.78247  validloss -785.08839±0.00000  bestvalidloss -814.73103  last_update 11\n",
      "train: iter 428  trainloss -703.34604  validloss -802.62789±0.00000  bestvalidloss -814.73103  last_update 12\n",
      "train: iter 429  trainloss -702.87115  validloss -810.30779±0.00000  bestvalidloss -814.73103  last_update 13\n",
      "train: iter 430  trainloss -711.10943  validloss -810.67426±0.00000  bestvalidloss -814.73103  last_update 14\n",
      "train: iter 431  trainloss -662.89727  validloss -809.12327±0.00000  bestvalidloss -814.73103  last_update 15\n",
      "train: iter 432  trainloss -696.69259  validloss -635.74130±0.00000  bestvalidloss -814.73103  last_update 16\n",
      "train: iter 433  trainloss -662.04524  validloss -792.01962±0.00000  bestvalidloss -814.73103  last_update 17\n",
      "train: iter 434  trainloss -694.38018  validloss -770.97992±0.00000  bestvalidloss -814.73103  last_update 18\n",
      "train: iter 435  trainloss -659.72657  validloss -791.47920±0.00000  bestvalidloss -814.73103  last_update 19\n",
      "train: iter 436  trainloss -677.02184  validloss -751.55338±0.00000  bestvalidloss -814.73103  last_update 20\n",
      "train: iter 437  trainloss -694.60983  validloss -801.71803±0.00000  bestvalidloss -814.73103  last_update 21\n",
      "train: iter 438  trainloss -704.02362  validloss -816.28357±0.00000  bestvalidloss -816.28357  last_update 0\n",
      "train: iter 439  trainloss -696.54299  validloss -812.20991±0.00000  bestvalidloss -816.28357  last_update 1\n",
      "train: iter 440  trainloss -667.49008  validloss -728.05552±0.00000  bestvalidloss -816.28357  last_update 2\n",
      "train: iter 441  trainloss -687.44181  validloss -798.60349±0.00000  bestvalidloss -816.28357  last_update 3\n",
      "train: iter 442  trainloss -672.54275  validloss -768.06693±0.00000  bestvalidloss -816.28357  last_update 4\n",
      "train: iter 443  trainloss -688.03834  validloss -772.35953±0.00000  bestvalidloss -816.28357  last_update 5\n",
      "train: iter 444  trainloss -707.64818  validloss -796.05234±0.00000  bestvalidloss -816.28357  last_update 6\n",
      "train: iter 445  trainloss -693.27259  validloss -787.18076±0.00000  bestvalidloss -816.28357  last_update 7\n",
      "train: iter 446  trainloss -697.56926  validloss -778.00938±0.00000  bestvalidloss -816.28357  last_update 8\n",
      "train: iter 447  trainloss -693.53785  validloss -805.15605±0.00000  bestvalidloss -816.28357  last_update 9\n",
      "train: iter 448  trainloss -692.63272  validloss -789.07005±0.00000  bestvalidloss -816.28357  last_update 10\n",
      "train: iter 449  trainloss -669.82032  validloss -809.05891±0.00000  bestvalidloss -816.28357  last_update 11\n",
      "train: iter 450  trainloss -673.05425  validloss -745.34730±0.00000  bestvalidloss -816.28357  last_update 12\n",
      "train: iter 451  trainloss -701.85554  validloss -797.77113±0.00000  bestvalidloss -816.28357  last_update 13\n",
      "train: iter 452  trainloss -688.48638  validloss -811.10361±0.00000  bestvalidloss -816.28357  last_update 14\n",
      "train: iter 453  trainloss -664.61547  validloss -782.11749±0.00000  bestvalidloss -816.28357  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 454  trainloss -673.10204  validloss -735.48077±0.00000  bestvalidloss -816.28357  last_update 16\n",
      "train: iter 455  trainloss -659.12752  validloss -103.29385±0.00000  bestvalidloss -816.28357  last_update 17\n",
      "train: iter 456  trainloss -692.35495  validloss -808.15323±0.00000  bestvalidloss -816.28357  last_update 18\n",
      "train: iter 457  trainloss -694.66959  validloss -808.87964±0.00000  bestvalidloss -816.28357  last_update 19\n",
      "train: iter 458  trainloss -708.04023  validloss -810.39228±0.00000  bestvalidloss -816.28357  last_update 20\n",
      "train: iter 459  trainloss -699.74609  validloss -816.59361±0.00000  bestvalidloss -816.59361  last_update 0\n",
      "train: iter 460  trainloss -696.91868  validloss -785.22500±0.00000  bestvalidloss -816.59361  last_update 1\n",
      "train: iter 461  trainloss -707.48466  validloss -818.83554±0.00000  bestvalidloss -818.83554  last_update 0\n",
      "train: iter 462  trainloss -697.88041  validloss -742.55506±0.00000  bestvalidloss -818.83554  last_update 1\n",
      "train: iter 463  trainloss -702.45417  validloss -807.54453±0.00000  bestvalidloss -818.83554  last_update 2\n",
      "train: iter 464  trainloss -662.42196  validloss -796.59549±0.00000  bestvalidloss -818.83554  last_update 3\n",
      "train: iter 465  trainloss -670.79383  validloss -790.06900±0.00000  bestvalidloss -818.83554  last_update 4\n",
      "train: iter 466  trainloss -670.86357  validloss -797.68035±0.00000  bestvalidloss -818.83554  last_update 5\n",
      "train: iter 467  trainloss -694.23014  validloss -776.52798±0.00000  bestvalidloss -818.83554  last_update 6\n",
      "train: iter 468  trainloss -661.95411  validloss -778.44201±0.00000  bestvalidloss -818.83554  last_update 7\n",
      "train: iter 469  trainloss -663.12233  validloss -716.63335±0.00000  bestvalidloss -818.83554  last_update 8\n",
      "train: iter 470  trainloss -692.44636  validloss -755.56791±0.00000  bestvalidloss -818.83554  last_update 9\n",
      "train: iter 471  trainloss -683.98964  validloss -800.62800±0.00000  bestvalidloss -818.83554  last_update 10\n",
      "train: iter 472  trainloss -702.62628  validloss -781.13891±0.00000  bestvalidloss -818.83554  last_update 11\n",
      "train: iter 473  trainloss -675.33288  validloss -809.10081±0.00000  bestvalidloss -818.83554  last_update 12\n",
      "train: iter 474  trainloss -646.11571  validloss -439.40201±0.00000  bestvalidloss -818.83554  last_update 13\n",
      "train: iter 475  trainloss -672.55997  validloss -801.41502±0.00000  bestvalidloss -818.83554  last_update 14\n",
      "train: iter 476  trainloss -680.53088  validloss -805.67422±0.00000  bestvalidloss -818.83554  last_update 15\n",
      "train: iter 477  trainloss -687.29736  validloss -758.54066±0.00000  bestvalidloss -818.83554  last_update 16\n",
      "train: iter 478  trainloss -692.14112  validloss -788.52028±0.00000  bestvalidloss -818.83554  last_update 17\n",
      "train: iter 479  trainloss -607.50138  validloss -811.37751±0.00000  bestvalidloss -818.83554  last_update 18\n",
      "train: iter 480  trainloss -705.98838  validloss -789.66585±0.00000  bestvalidloss -818.83554  last_update 19\n",
      "train: iter 481  trainloss -709.22908  validloss -805.45531±0.00000  bestvalidloss -818.83554  last_update 20\n",
      "train: iter 482  trainloss -689.95214  validloss -810.19332±0.00000  bestvalidloss -818.83554  last_update 21\n",
      "train: iter 483  trainloss -708.39075  validloss -800.19610±0.00000  bestvalidloss -818.83554  last_update 22\n",
      "train: iter 484  trainloss -656.54308  validloss -810.82948±0.00000  bestvalidloss -818.83554  last_update 23\n",
      "train: iter 485  trainloss -679.99437  validloss -683.97999±0.00000  bestvalidloss -818.83554  last_update 24\n",
      "train: iter 486  trainloss -710.76424  validloss -804.83969±0.00000  bestvalidloss -818.83554  last_update 25\n",
      "train: iter 487  trainloss -670.84240  validloss -817.17171±0.00000  bestvalidloss -818.83554  last_update 26\n",
      "train: iter 488  trainloss -663.57678  validloss -656.92453±0.00000  bestvalidloss -818.83554  last_update 27\n",
      "train: iter 489  trainloss -708.47301  validloss -791.56658±0.00000  bestvalidloss -818.83554  last_update 28\n",
      "train: iter 490  trainloss -692.29713  validloss -800.06826±0.00000  bestvalidloss -818.83554  last_update 29\n",
      "train: iter 491  trainloss -666.37190  validloss -805.51348±0.00000  bestvalidloss -818.83554  last_update 30\n",
      "train: iter 492  trainloss -662.53168  validloss -675.19844±0.00000  bestvalidloss -818.83554  last_update 31\n",
      "train: iter 493  trainloss -566.40103  validloss -801.89670±0.00000  bestvalidloss -818.83554  last_update 32\n",
      "train: iter 494  trainloss -55.10350  validloss 208.61612±0.00000  bestvalidloss -818.83554  last_update 33\n",
      "train: iter 495  trainloss -597.82837  validloss -481.29009±0.00000  bestvalidloss -818.83554  last_update 34\n",
      "train: iter 496  trainloss -669.30692  validloss -775.03666±0.00000  bestvalidloss -818.83554  last_update 35\n",
      "train: iter 497  trainloss -662.53944  validloss -803.12769±0.00000  bestvalidloss -818.83554  last_update 36\n",
      "train: iter 498  trainloss -672.72053  validloss -799.36796±0.00000  bestvalidloss -818.83554  last_update 37\n",
      "train: iter 499  trainloss -684.35964  validloss -766.61669±0.00000  bestvalidloss -818.83554  last_update 38\n",
      "train: iter 500  trainloss -688.69870  validloss -791.38569±0.00000  bestvalidloss -818.83554  last_update 39\n",
      "train: iter 501  trainloss -694.17490  validloss -787.75280±0.00000  bestvalidloss -818.83554  last_update 40\n",
      "train: iter 502  trainloss -660.82806  validloss -785.83214±0.00000  bestvalidloss -818.83554  last_update 41\n",
      "train: iter 503  trainloss -693.47437  validloss -791.82804±0.00000  bestvalidloss -818.83554  last_update 42\n",
      "train: iter 504  trainloss -700.80711  validloss -813.03137±0.00000  bestvalidloss -818.83554  last_update 43\n",
      "train: iter 505  trainloss -667.65103  validloss -804.77539±0.00000  bestvalidloss -818.83554  last_update 44\n",
      "train: iter 506  trainloss -701.77589  validloss -803.16308±0.00000  bestvalidloss -818.83554  last_update 45\n",
      "train: iter 507  trainloss -709.24109  validloss -810.98507±0.00000  bestvalidloss -818.83554  last_update 46\n",
      "train: iter 508  trainloss -716.04808  validloss -793.64531±0.00000  bestvalidloss -818.83554  last_update 47\n",
      "train: iter 509  trainloss -701.96635  validloss -812.94921±0.00000  bestvalidloss -818.83554  last_update 48\n",
      "train: iter 510  trainloss -696.84422  validloss -798.42971±0.00000  bestvalidloss -818.83554  last_update 49\n",
      "train: iter 511  trainloss -708.05698  validloss -798.25559±0.00000  bestvalidloss -818.83554  last_update 50\n",
      "train: iter 512  trainloss -707.62828  validloss -793.30597±0.00000  bestvalidloss -818.83554  last_update 51\n",
      "train: iter 513  trainloss -708.63745  validloss -808.79724±0.00000  bestvalidloss -818.83554  last_update 52\n",
      "train: iter 514  trainloss -712.53378  validloss -804.63633±0.00000  bestvalidloss -818.83554  last_update 53\n",
      "train: iter 515  trainloss -635.25416  validloss -820.70928±0.00000  bestvalidloss -820.70928  last_update 0\n",
      "train: iter 516  trainloss -666.71164  validloss -794.70848±0.00000  bestvalidloss -820.70928  last_update 1\n",
      "train: iter 517  trainloss -678.20080  validloss -775.91820±0.00000  bestvalidloss -820.70928  last_update 2\n",
      "train: iter 518  trainloss -691.79108  validloss -777.73142±0.00000  bestvalidloss -820.70928  last_update 3\n",
      "train: iter 519  trainloss -691.83088  validloss -796.19601±0.00000  bestvalidloss -820.70928  last_update 4\n",
      "train: iter 520  trainloss -703.27218  validloss -812.75086±0.00000  bestvalidloss -820.70928  last_update 5\n",
      "train: iter 521  trainloss -705.65124  validloss -762.40586±0.00000  bestvalidloss -820.70928  last_update 6\n",
      "train: iter 522  trainloss -679.20119  validloss -810.31625±0.00000  bestvalidloss -820.70928  last_update 7\n",
      "train: iter 523  trainloss -712.25728  validloss -812.10477±0.00000  bestvalidloss -820.70928  last_update 8\n",
      "train: iter 524  trainloss -715.23424  validloss -803.25336±0.00000  bestvalidloss -820.70928  last_update 9\n",
      "train: iter 525  trainloss -701.70821  validloss -805.22458±0.00000  bestvalidloss -820.70928  last_update 10\n",
      "train: iter 526  trainloss -716.09328  validloss -784.52056±0.00000  bestvalidloss -820.70928  last_update 11\n",
      "train: iter 527  trainloss -712.52331  validloss -807.69386±0.00000  bestvalidloss -820.70928  last_update 12\n",
      "train: iter 528  trainloss -707.67903  validloss -819.68544±0.00000  bestvalidloss -820.70928  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 529  trainloss -710.33167  validloss -815.38718±0.00000  bestvalidloss -820.70928  last_update 14\n",
      "train: iter 530  trainloss -718.63053  validloss -805.12500±0.00000  bestvalidloss -820.70928  last_update 15\n",
      "train: iter 531  trainloss -710.96695  validloss -818.72810±0.00000  bestvalidloss -820.70928  last_update 16\n",
      "train: iter 532  trainloss -706.34371  validloss -775.02652±0.00000  bestvalidloss -820.70928  last_update 17\n",
      "train: iter 533  trainloss -682.82497  validloss -808.94259±0.00000  bestvalidloss -820.70928  last_update 18\n",
      "train: iter 534  trainloss -708.87542  validloss -778.56359±0.00000  bestvalidloss -820.70928  last_update 19\n",
      "train: iter 535  trainloss -716.73754  validloss -813.83961±0.00000  bestvalidloss -820.70928  last_update 20\n",
      "train: iter 536  trainloss -690.62424  validloss -777.47184±0.00000  bestvalidloss -820.70928  last_update 21\n",
      "train: iter 537  trainloss -711.23835  validloss -799.28571±0.00000  bestvalidloss -820.70928  last_update 22\n",
      "train: iter 538  trainloss -697.50063  validloss -800.57740±0.00000  bestvalidloss -820.70928  last_update 23\n",
      "train: iter 539  trainloss -712.97376  validloss -818.89441±0.00000  bestvalidloss -820.70928  last_update 24\n",
      "train: iter 540  trainloss -704.79245  validloss -814.12943±0.00000  bestvalidloss -820.70928  last_update 25\n",
      "train: iter 541  trainloss -712.15371  validloss -804.79147±0.00000  bestvalidloss -820.70928  last_update 26\n",
      "train: iter 542  trainloss -669.57158  validloss -792.42203±0.00000  bestvalidloss -820.70928  last_update 27\n",
      "train: iter 543  trainloss -705.46120  validloss -697.28873±0.00000  bestvalidloss -820.70928  last_update 28\n",
      "train: iter 544  trainloss -699.36408  validloss -808.34081±0.00000  bestvalidloss -820.70928  last_update 29\n",
      "train: iter 545  trainloss -690.56747  validloss -804.68121±0.00000  bestvalidloss -820.70928  last_update 30\n",
      "train: iter 546  trainloss -689.22047  validloss -800.57966±0.00000  bestvalidloss -820.70928  last_update 31\n",
      "train: iter 547  trainloss -713.12640  validloss -812.12592±0.00000  bestvalidloss -820.70928  last_update 32\n",
      "train: iter 548  trainloss -709.11136  validloss -796.03977±0.00000  bestvalidloss -820.70928  last_update 33\n",
      "train: iter 549  trainloss -695.64258  validloss -790.79881±0.00000  bestvalidloss -820.70928  last_update 34\n",
      "train: iter 550  trainloss -713.55775  validloss -736.22592±0.00000  bestvalidloss -820.70928  last_update 35\n",
      "train: iter 551  trainloss -719.75702  validloss -816.58581±0.00000  bestvalidloss -820.70928  last_update 36\n",
      "train: iter 552  trainloss -693.74416  validloss -819.62813±0.00000  bestvalidloss -820.70928  last_update 37\n",
      "train: iter 553  trainloss -679.86034  validloss -798.29949±0.00000  bestvalidloss -820.70928  last_update 38\n",
      "train: iter 554  trainloss -713.88138  validloss -801.06594±0.00000  bestvalidloss -820.70928  last_update 39\n",
      "train: iter 555  trainloss -688.27456  validloss -791.32313±0.00000  bestvalidloss -820.70928  last_update 40\n",
      "train: iter 556  trainloss -720.72114  validloss -751.98604±0.00000  bestvalidloss -820.70928  last_update 41\n",
      "train: iter 557  trainloss -715.33022  validloss -780.22781±0.00000  bestvalidloss -820.70928  last_update 42\n",
      "train: iter 558  trainloss -702.34326  validloss -757.01018±0.00000  bestvalidloss -820.70928  last_update 43\n",
      "train: iter 559  trainloss -666.95590  validloss -793.70832±0.00000  bestvalidloss -820.70928  last_update 44\n",
      "train: iter 560  trainloss -676.20588  validloss -772.87727±0.00000  bestvalidloss -820.70928  last_update 45\n",
      "train: iter 561  trainloss -701.11246  validloss -757.99768±0.00000  bestvalidloss -820.70928  last_update 46\n",
      "train: iter 562  trainloss -659.42639  validloss -753.27283±0.00000  bestvalidloss -820.70928  last_update 47\n",
      "train: iter 563  trainloss -679.52715  validloss -809.19024±0.00000  bestvalidloss -820.70928  last_update 48\n",
      "train: iter 564  trainloss -589.13919  validloss -764.23038±0.00000  bestvalidloss -820.70928  last_update 49\n",
      "train: iter 565  trainloss -664.32407  validloss -759.67488±0.00000  bestvalidloss -820.70928  last_update 50\n",
      "train: iter 566  trainloss -692.57031  validloss -789.54026±0.00000  bestvalidloss -820.70928  last_update 51\n",
      "train: iter 567  trainloss -697.79643  validloss -768.73290±0.00000  bestvalidloss -820.70928  last_update 52\n",
      "train: iter 568  trainloss -711.03136  validloss -808.08102±0.00000  bestvalidloss -820.70928  last_update 53\n",
      "train: iter 569  trainloss -717.55206  validloss -819.77604±0.00000  bestvalidloss -820.70928  last_update 54\n",
      "train: iter 570  trainloss -720.03210  validloss -803.85792±0.00000  bestvalidloss -820.70928  last_update 55\n",
      "train: iter 571  trainloss -688.71865  validloss -739.36888±0.00000  bestvalidloss -820.70928  last_update 56\n",
      "train: iter 572  trainloss -669.63043  validloss -752.06018±0.00000  bestvalidloss -820.70928  last_update 57\n",
      "train: iter 573  trainloss -702.72869  validloss -797.30788±0.00000  bestvalidloss -820.70928  last_update 58\n",
      "train: iter 574  trainloss -712.60718  validloss -808.07410±0.00000  bestvalidloss -820.70928  last_update 59\n",
      "train: iter 575  trainloss -712.10089  validloss -778.94699±0.00000  bestvalidloss -820.70928  last_update 60\n",
      "train: iter 576  trainloss -712.84159  validloss -801.73984±0.00000  bestvalidloss -820.70928  last_update 61\n",
      "train: iter 577  trainloss -719.86632  validloss -765.79278±0.00000  bestvalidloss -820.70928  last_update 62\n",
      "train: iter 578  trainloss -716.68299  validloss -814.93634±0.00000  bestvalidloss -820.70928  last_update 63\n",
      "train: iter 579  trainloss -661.35619  validloss -740.14458±0.00000  bestvalidloss -820.70928  last_update 64\n",
      "train: iter 580  trainloss -711.86122  validloss -809.42360±0.00000  bestvalidloss -820.70928  last_update 65\n",
      "train: iter 581  trainloss -704.60182  validloss -789.37598±0.00000  bestvalidloss -820.70928  last_update 66\n",
      "train: iter 582  trainloss -711.09236  validloss -815.62420±0.00000  bestvalidloss -820.70928  last_update 67\n",
      "train: iter 583  trainloss -723.61540  validloss -775.32917±0.00000  bestvalidloss -820.70928  last_update 68\n",
      "train: iter 584  trainloss -719.81965  validloss -804.50928±0.00000  bestvalidloss -820.70928  last_update 69\n",
      "train: iter 585  trainloss -721.58439  validloss -818.18604±0.00000  bestvalidloss -820.70928  last_update 70\n",
      "train: iter 586  trainloss -714.15495  validloss -813.53451±0.00000  bestvalidloss -820.70928  last_update 71\n",
      "train: iter 587  trainloss -720.73656  validloss -809.22970±0.00000  bestvalidloss -820.70928  last_update 72\n",
      "train: iter 588  trainloss -724.94333  validloss -805.72907±0.00000  bestvalidloss -820.70928  last_update 73\n",
      "train: iter 589  trainloss -710.20690  validloss -801.41228±0.00000  bestvalidloss -820.70928  last_update 74\n",
      "train: iter 590  trainloss -689.02412  validloss -816.14105±0.00000  bestvalidloss -820.70928  last_update 75\n",
      "train: iter 591  trainloss -717.53152  validloss -808.89759±0.00000  bestvalidloss -820.70928  last_update 76\n",
      "train: iter 592  trainloss -704.68122  validloss -736.47549±0.00000  bestvalidloss -820.70928  last_update 77\n",
      "train: iter 593  trainloss -705.54222  validloss -728.48867±0.00000  bestvalidloss -820.70928  last_update 78\n",
      "train: iter 594  trainloss -717.81358  validloss -777.98580±0.00000  bestvalidloss -820.70928  last_update 79\n",
      "train: iter 595  trainloss -726.51118  validloss -816.62300±0.00000  bestvalidloss -820.70928  last_update 80\n",
      "train: iter 596  trainloss -707.48101  validloss -787.07958±0.00000  bestvalidloss -820.70928  last_update 81\n",
      "train: iter 597  trainloss -704.28981  validloss -805.43229±0.00000  bestvalidloss -820.70928  last_update 82\n",
      "train: iter 598  trainloss -698.34471  validloss -803.49749±0.00000  bestvalidloss -820.70928  last_update 83\n",
      "train: iter 599  trainloss -686.56842  validloss -802.28091±0.00000  bestvalidloss -820.70928  last_update 84\n",
      "train: iter 600  trainloss -702.04666  validloss -814.89826±0.00000  bestvalidloss -820.70928  last_update 85\n",
      "train: iter 601  trainloss -706.10488  validloss -720.05626±0.00000  bestvalidloss -820.70928  last_update 86\n",
      "train: iter 602  trainloss -709.15469  validloss -804.81483±0.00000  bestvalidloss -820.70928  last_update 87\n",
      "train: iter 603  trainloss -717.21332  validloss -772.10142±0.00000  bestvalidloss -820.70928  last_update 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 604  trainloss -688.43544  validloss -795.71280±0.00000  bestvalidloss -820.70928  last_update 89\n",
      "train: iter 605  trainloss -718.17982  validloss -798.25352±0.00000  bestvalidloss -820.70928  last_update 90\n",
      "train: iter 606  trainloss -714.72109  validloss -817.57453±0.00000  bestvalidloss -820.70928  last_update 91\n",
      "train: iter 607  trainloss -704.84742  validloss -784.07257±0.00000  bestvalidloss -820.70928  last_update 92\n",
      "train: iter 608  trainloss -683.22919  validloss -655.48746±0.00000  bestvalidloss -820.70928  last_update 93\n",
      "train: iter 609  trainloss -711.42093  validloss -775.82777±0.00000  bestvalidloss -820.70928  last_update 94\n",
      "train: iter 610  trainloss -707.58946  validloss -700.81643±0.00000  bestvalidloss -820.70928  last_update 95\n",
      "train: iter 611  trainloss -709.36279  validloss -821.96937±0.00000  bestvalidloss -821.96937  last_update 0\n",
      "train: iter 612  trainloss -715.26996  validloss -787.77723±0.00000  bestvalidloss -821.96937  last_update 1\n",
      "train: iter 613  trainloss -703.78891  validloss -798.73930±0.00000  bestvalidloss -821.96937  last_update 2\n",
      "train: iter 614  trainloss -710.38230  validloss -730.96870±0.00000  bestvalidloss -821.96937  last_update 3\n",
      "train: iter 615  trainloss -702.97253  validloss -783.24473±0.00000  bestvalidloss -821.96937  last_update 4\n",
      "train: iter 616  trainloss -727.34541  validloss -807.85461±0.00000  bestvalidloss -821.96937  last_update 5\n",
      "train: iter 617  trainloss -716.35999  validloss -789.67307±0.00000  bestvalidloss -821.96937  last_update 6\n",
      "train: iter 618  trainloss -695.18463  validloss -815.98112±0.00000  bestvalidloss -821.96937  last_update 7\n",
      "train: iter 619  trainloss -716.59965  validloss -804.91345±0.00000  bestvalidloss -821.96937  last_update 8\n",
      "train: iter 620  trainloss -722.28229  validloss -802.59695±0.00000  bestvalidloss -821.96937  last_update 9\n",
      "train: iter 621  trainloss -725.43167  validloss -814.47030±0.00000  bestvalidloss -821.96937  last_update 10\n",
      "train: iter 622  trainloss -706.79479  validloss -818.34033±0.00000  bestvalidloss -821.96937  last_update 11\n",
      "train: iter 623  trainloss -708.95176  validloss -811.66129±0.00000  bestvalidloss -821.96937  last_update 12\n",
      "train: iter 624  trainloss -731.30613  validloss -799.23013±0.00000  bestvalidloss -821.96937  last_update 13\n",
      "train: iter 625  trainloss -721.51432  validloss -798.47876±0.00000  bestvalidloss -821.96937  last_update 14\n",
      "train: iter 626  trainloss -728.09476  validloss -810.77178±0.00000  bestvalidloss -821.96937  last_update 15\n",
      "train: iter 627  trainloss -687.04732  validloss -813.52792±0.00000  bestvalidloss -821.96937  last_update 16\n",
      "train: iter 628  trainloss -725.75583  validloss -807.12325±0.00000  bestvalidloss -821.96937  last_update 17\n",
      "train: iter 629  trainloss -724.76516  validloss -809.02766±0.00000  bestvalidloss -821.96937  last_update 18\n",
      "train: iter 630  trainloss -726.17648  validloss -810.64006±0.00000  bestvalidloss -821.96937  last_update 19\n",
      "train: iter 631  trainloss -681.02206  validloss -807.29696±0.00000  bestvalidloss -821.96937  last_update 20\n",
      "train: iter 632  trainloss -669.06722  validloss -700.79035±0.00000  bestvalidloss -821.96937  last_update 21\n",
      "train: iter 633  trainloss -708.63129  validloss -763.66857±0.00000  bestvalidloss -821.96937  last_update 22\n",
      "train: iter 634  trainloss -703.21763  validloss -805.63836±0.00000  bestvalidloss -821.96937  last_update 23\n",
      "train: iter 635  trainloss -719.55925  validloss -799.57759±0.00000  bestvalidloss -821.96937  last_update 24\n",
      "train: iter 636  trainloss -710.24568  validloss -820.93617±0.00000  bestvalidloss -821.96937  last_update 25\n",
      "train: iter 637  trainloss -717.80385  validloss -810.95900±0.00000  bestvalidloss -821.96937  last_update 26\n",
      "train: iter 638  trainloss -727.33623  validloss -820.82857±0.00000  bestvalidloss -821.96937  last_update 27\n",
      "train: iter 639  trainloss -717.75912  validloss -804.79915±0.00000  bestvalidloss -821.96937  last_update 28\n",
      "train: iter 640  trainloss -725.30520  validloss -818.33713±0.00000  bestvalidloss -821.96937  last_update 29\n",
      "train: iter 641  trainloss -706.94260  validloss -793.78698±0.00000  bestvalidloss -821.96937  last_update 30\n",
      "train: iter 642  trainloss -721.89838  validloss -798.52170±0.00000  bestvalidloss -821.96937  last_update 31\n",
      "train: iter 643  trainloss -735.67458  validloss -804.40041±0.00000  bestvalidloss -821.96937  last_update 32\n",
      "train: iter 644  trainloss -713.79042  validloss -789.93833±0.00000  bestvalidloss -821.96937  last_update 33\n",
      "train: iter 645  trainloss -736.27519  validloss -766.29953±0.00000  bestvalidloss -821.96937  last_update 34\n",
      "train: iter 646  trainloss -709.06727  validloss -787.94481±0.00000  bestvalidloss -821.96937  last_update 35\n",
      "train: iter 647  trainloss -715.32461  validloss -798.69355±0.00000  bestvalidloss -821.96937  last_update 36\n",
      "train: iter 648  trainloss -727.11113  validloss -722.83867±0.00000  bestvalidloss -821.96937  last_update 37\n",
      "train: iter 649  trainloss -713.11756  validloss -747.07731±0.00000  bestvalidloss -821.96937  last_update 38\n",
      "train: iter 650  trainloss -736.42270  validloss -802.37840±0.00000  bestvalidloss -821.96937  last_update 39\n",
      "train: iter 651  trainloss -707.37560  validloss -803.03564±0.00000  bestvalidloss -821.96937  last_update 40\n",
      "train: iter 652  trainloss -713.94460  validloss -791.48008±0.00000  bestvalidloss -821.96937  last_update 41\n",
      "train: iter 653  trainloss -693.94625  validloss -813.19515±0.00000  bestvalidloss -821.96937  last_update 42\n",
      "train: iter 654  trainloss -724.29938  validloss -669.09181±0.00000  bestvalidloss -821.96937  last_update 43\n",
      "train: iter 655  trainloss -726.78470  validloss -790.68094±0.00000  bestvalidloss -821.96937  last_update 44\n",
      "train: iter 656  trainloss -725.17406  validloss -775.37948±0.00000  bestvalidloss -821.96937  last_update 45\n",
      "train: iter 657  trainloss -731.80902  validloss -817.32398±0.00000  bestvalidloss -821.96937  last_update 46\n",
      "train: iter 658  trainloss -742.29154  validloss -782.70332±0.00000  bestvalidloss -821.96937  last_update 47\n",
      "train: iter 659  trainloss -723.81746  validloss -735.17156±0.00000  bestvalidloss -821.96937  last_update 48\n",
      "train: iter 660  trainloss -732.18115  validloss -792.55478±0.00000  bestvalidloss -821.96937  last_update 49\n",
      "train: iter 661  trainloss -741.18668  validloss -783.80534±0.00000  bestvalidloss -821.96937  last_update 50\n",
      "train: iter 662  trainloss -703.57376  validloss -767.21488±0.00000  bestvalidloss -821.96937  last_update 51\n",
      "train: iter 663  trainloss -721.94829  validloss -784.51444±0.00000  bestvalidloss -821.96937  last_update 52\n",
      "train: iter 664  trainloss -716.77527  validloss -798.31774±0.00000  bestvalidloss -821.96937  last_update 53\n",
      "train: iter 665  trainloss -733.86787  validloss -816.29282±0.00000  bestvalidloss -821.96937  last_update 54\n",
      "train: iter 666  trainloss -737.96001  validloss -815.05444±0.00000  bestvalidloss -821.96937  last_update 55\n",
      "train: iter 667  trainloss -732.68949  validloss -758.31411±0.00000  bestvalidloss -821.96937  last_update 56\n",
      "train: iter 668  trainloss -731.61973  validloss -798.88158±0.00000  bestvalidloss -821.96937  last_update 57\n",
      "train: iter 669  trainloss -735.20089  validloss -814.65414±0.00000  bestvalidloss -821.96937  last_update 58\n",
      "train: iter 670  trainloss -730.20028  validloss -800.66511±0.00000  bestvalidloss -821.96937  last_update 59\n",
      "train: iter 671  trainloss -738.48296  validloss -803.70700±0.00000  bestvalidloss -821.96937  last_update 60\n",
      "train: iter 672  trainloss -742.53106  validloss -806.48593±0.00000  bestvalidloss -821.96937  last_update 61\n",
      "train: iter 673  trainloss -721.24836  validloss -797.11656±0.00000  bestvalidloss -821.96937  last_update 62\n",
      "train: iter 674  trainloss -725.24453  validloss -744.01198±0.00000  bestvalidloss -821.96937  last_update 63\n",
      "train: iter 675  trainloss -745.35663  validloss -806.81072±0.00000  bestvalidloss -821.96937  last_update 64\n",
      "train: iter 676  trainloss -742.12419  validloss -787.77850±0.00000  bestvalidloss -821.96937  last_update 65\n",
      "train: iter 677  trainloss -722.10656  validloss -767.26098±0.00000  bestvalidloss -821.96937  last_update 66\n",
      "train: iter 678  trainloss -726.55470  validloss -765.61295±0.00000  bestvalidloss -821.96937  last_update 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 679  trainloss -750.73391  validloss -799.53785±0.00000  bestvalidloss -821.96937  last_update 68\n",
      "train: iter 680  trainloss -742.93089  validloss -793.63997±0.00000  bestvalidloss -821.96937  last_update 69\n",
      "train: iter 681  trainloss -733.49851  validloss -784.64408±0.00000  bestvalidloss -821.96937  last_update 70\n",
      "train: iter 682  trainloss -709.98992  validloss -789.82335±0.00000  bestvalidloss -821.96937  last_update 71\n",
      "train: iter 683  trainloss -689.30288  validloss -806.48191±0.00000  bestvalidloss -821.96937  last_update 72\n",
      "train: iter 684  trainloss -740.54607  validloss -787.31323±0.00000  bestvalidloss -821.96937  last_update 73\n",
      "train: iter 685  trainloss -742.64252  validloss -819.40426±0.00000  bestvalidloss -821.96937  last_update 74\n",
      "train: iter 686  trainloss -732.69331  validloss -789.50309±0.00000  bestvalidloss -821.96937  last_update 75\n",
      "train: iter 687  trainloss -740.01598  validloss -803.92455±0.00000  bestvalidloss -821.96937  last_update 76\n",
      "train: iter 688  trainloss -748.01165  validloss -808.12802±0.00000  bestvalidloss -821.96937  last_update 77\n",
      "train: iter 689  trainloss -748.55045  validloss -793.20683±0.00000  bestvalidloss -821.96937  last_update 78\n",
      "train: iter 690  trainloss -726.23009  validloss -787.30836±0.00000  bestvalidloss -821.96937  last_update 79\n",
      "train: iter 691  trainloss -723.16538  validloss -798.63918±0.00000  bestvalidloss -821.96937  last_update 80\n",
      "train: iter 692  trainloss -729.65393  validloss -780.45301±0.00000  bestvalidloss -821.96937  last_update 81\n",
      "train: iter 693  trainloss -701.52498  validloss -801.09819±0.00000  bestvalidloss -821.96937  last_update 82\n",
      "train: iter 694  trainloss -732.32308  validloss -786.69624±0.00000  bestvalidloss -821.96937  last_update 83\n",
      "train: iter 695  trainloss -737.36606  validloss -811.35742±0.00000  bestvalidloss -821.96937  last_update 84\n",
      "train: iter 696  trainloss -749.90426  validloss -818.82254±0.00000  bestvalidloss -821.96937  last_update 85\n",
      "train: iter 697  trainloss -684.70456  validloss -788.00969±0.00000  bestvalidloss -821.96937  last_update 86\n",
      "train: iter 698  trainloss -735.24199  validloss -789.40874±0.00000  bestvalidloss -821.96937  last_update 87\n",
      "train: iter 699  trainloss -734.95732  validloss -811.30866±0.00000  bestvalidloss -821.96937  last_update 88\n",
      "train: iter 700  trainloss -739.86134  validloss -821.61661±0.00000  bestvalidloss -821.96937  last_update 89\n",
      "train: iter 701  trainloss -749.32659  validloss -817.03083±0.00000  bestvalidloss -821.96937  last_update 90\n",
      "train: iter 702  trainloss -750.83395  validloss -819.46701±0.00000  bestvalidloss -821.96937  last_update 91\n",
      "train: iter 703  trainloss -739.52065  validloss -795.42247±0.00000  bestvalidloss -821.96937  last_update 92\n",
      "train: iter 704  trainloss -707.86868  validloss -816.69603±0.00000  bestvalidloss -821.96937  last_update 93\n",
      "train: iter 705  trainloss -752.38010  validloss -803.45296±0.00000  bestvalidloss -821.96937  last_update 94\n",
      "train: iter 706  trainloss -725.95386  validloss -818.34134±0.00000  bestvalidloss -821.96937  last_update 95\n",
      "train: iter 707  trainloss -730.99679  validloss -674.92742±0.00000  bestvalidloss -821.96937  last_update 96\n",
      "train: iter 708  trainloss -733.57565  validloss -811.54203±0.00000  bestvalidloss -821.96937  last_update 97\n",
      "train: iter 709  trainloss -733.91499  validloss -795.65375±0.00000  bestvalidloss -821.96937  last_update 98\n",
      "train: iter 710  trainloss -752.79852  validloss -820.00053±0.00000  bestvalidloss -821.96937  last_update 99\n",
      "train: iter 711  trainloss -753.51008  validloss -798.08065±0.00000  bestvalidloss -821.96937  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-5.6026) penalty_target_max tensor(23.0230)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGfCAYAAACqZFPKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACX6ElEQVR4nO2dd3gU5drG79mSTW+kEQi99w4BUVAEFQuK2BEU9cAHVo4K6lGPDSseC4oV7Cg2FJAiTRAE6T2AtFBSIKQnW+f7Y3Z232lbkuxmN3l+1xV2d+bdmXd2l5l7nsrxPM+DIAiCIAgiTNHV9wQIgiAIgiBqA4kZgiAIgiDCGhIzBEEQBEGENSRmCIIgCIIIa0jMEARBEAQR1pCYIQiCIAgirCExQxAEQRBEWENihiAIgiCIsIbEDEEQBEEQYQ2JGYIgCIIgwhpDIDc+a9Ys/Pjjjzh48CCioqIwePBgvPLKK+jYsaNrTHV1NaZPn44FCxbAbDZj1KhReO+995Cenu4ac/LkSUyZMgVr1qxBbGwsJkyYgFmzZsFg8G36DocDZ86cQVxcHDiOq/PjJAiCIAii7uF5HmVlZcjMzIRO58H+wgeQUaNG8fPmzeP37t3L79y5k7/qqqv4Fi1a8OXl5a4xkydP5rOysvhVq1bxW7du5QcNGsQPHjzYtd5ms/HdunXjR4wYwe/YsYNfunQpn5KSws+cOdPneeTm5vIA6I/+6I/+6I/+6C8M/3Jzcz1e5zmeD16jycLCQqSlpWHdunW4+OKLUVJSgtTUVHz99de48cYbAQAHDx5E586dsWnTJgwaNAi//fYbrr76apw5c8ZlrZk7dy4ef/xxFBYWIiIiwut+S0pKkJiYiNzcXMTHxwfuAC2VwBsdAAA7b9qMXm2bBW5fBEEQgeaV1oDDKjyfeap+50I0SkpLS5GVlYXi4mIkJCRojguom0lOSUkJACA5ORkAsG3bNlitVowYMcI1plOnTmjRooVLzGzatAndu3eXuJ1GjRqFKVOmYN++fejdu7diP2azGWaz2fW6rKwMABAfHx9YMeOIBUyCGyvCoA/svgiCIAJNpA6wO13zdD4j6hFvISJBCwB2OBx46KGHMGTIEHTr1g0AkJeXh4iICCQmJkrGpqenIy8vzzWGFTLienGdGrNmzUJCQoLrLysrq46PRgOdDlanPrSaq4KzT4IgCIJo5ARNzEydOhV79+7FggULAr6vmTNnoqSkxPWXm5sb8H2KWDnB7WW1VAZtnwRBEIGBEiaI8CAobqZp06Zh8eLF+OOPP9C8eXPX8oyMDFgsFhQXF0usM/n5+cjIyHCN2bJli2R7+fn5rnVqmEwmmEymOj4K37ByEQBfCRtZZgiCIAgiKATUMsPzPKZNm4affvoJq1evRuvWrSXr+/btC6PRiFWrVrmW5eTk4OTJk8jOzgYAZGdnY8+ePSgoKHCNWblyJeLj49GlS5dATr9G2HSCiLJZSMwQBEEQRDAIqGVm6tSp+Prrr7Fo0SLExcW5YlwSEhIQFRWFhIQETJo0CY888giSk5MRHx+P+++/H9nZ2Rg0aBAAYOTIkejSpQvGjx+PV199FXl5eXjqqacwderUerO+eMIlZqor6nkmBEEQBNE4CKiYef/99wEAw4YNkyyfN28eJk6cCAB48803odPpMHbsWEnRPBG9Xo/FixdjypQpyM7ORkxMDCZMmIDnnnsukFOvMQ6dM2bGXF3PMyEIgiCIxkFAxYwvJWwiIyMxZ84czJkzR3NMy5YtsXTp0rqcWsBwGCIBeHAzlZwGVr8ADLwPyFSmlRMEQRAE4R/Um6mO4fWCm8muJWZ+vA/Y9TXw4bDgTYogCKImUPsXIkwgMVPH8E7LjEMrNbvwYBBnQxAEQRANHxIzdQxnEGJmHFazxgC60yEIgiCIuoTETB3DGZxuJptFa0TwJkMQBFEr6HxFhAckZuoYnWiZ0RIzZJkhCIIgiDqFxEwdo3eKGZ4sMwRBEAQRFEjM1DF6o+Bm0hQzZJkhCIIgiDqFxEwd4xIzdrLMEARBEEQwIDFTxxgiBDcTpyVmyDJDEARBEHUKiZk6xmAU6szoeRssNofKCBIzBEGECXTzRYQJJGbqmIgIwc1khA2VFptyAJ0cCIIgCKJOITFTx4ip2UbYUGGxq4wgMUMQBEEQdQmJmbpG7xQznA2VZjXLTJDnQxAEUWPohEWEByRm6hqnmIkgywxBEARBBAUSM3WN3ggAMMKOClXLDIkZgiAIgqhLSMzUNXomZkZNzJBlhiAIgiDqFBIzdQ0jZirV3ExkmSEIgiCIOoXETF3jdDNFcDZUqKVmk2WGIAiCIOoUEjN1DWuZMZNlhiCIMIbOV0SYQGKmrnGKGQPsZJkhCIIgiCBAYqauEd1MFDNDEARBEEGBxExdQ9lMBEEQBBFUSMzUNd7EDFlmCIIgCKJOITFT14hF8zgbyskyQxBEWEPnKyI8IDFT1zCWmdIqsswQBEEQRKAhMVPXML2ZSqutKgNIzBAEQRBEXUJipq5hejOVVZNlhiAIgiACDYmZukbiZiLLDEEQBEEEGhIzdY0oZjg7qs3VsDt46XrSMgRBEARRp5CYqWuiksDHZgAAhup2q2Q0kZohCCJMILc4ESaQmKlrdDpwXa8HAFyu26Z0NdHJgSAIgiDqFBIzgSClHQAgiStXyWgiMUMQBEEQdQmJmUBgiAIAmGBRZjSRZYYgiLCBzldEeEBiJhAYTAAAE6y4UGGRruPoIycIgiCIuoSurIHAKFhmIjkLzsvFDN3pEARBEESdQmImEDCWmfPlcjFDEARBEERdQmImEBgiAQCRsOBcuVm6jmJmCIIgCKJOITETCMQAYM6KL/46gSMFZcxKEjMEQRAEUZeQmAkEjJsJAO7/Zqd7HQUAEwQRLtC9FxEm0JU1EDjdTCYI8TIHzpa615GbiSAIgiDqFBIzgcAoihnBMhNp1IHneeU4tWUEQRAEQfgFiZlAIFpmOBs4OFBtdeB0cZVzJWOZ4R3BnxtBEITPkCWZCA9IzAQCZ8wMALROMAAACsuErKb8Mia7yWEP6rQIgiAIoiFCYiYQOLOZACA5QrC+VFnsuFBhwdFzVe5xZJkhCIIgiFpDYiYQ6A0ApwcAxBkF60uFxY4qqx2SKBkSMwRBEARRa0jMBApn3ExihNBostJig90hC/jlyc1EEARBELWFxEygcGY0xRsE60uF2Q6bgwdPAcAEQRAEUaeQmAkUTstMnIG1zDikbiYKACYIIpShulhEmEBiJlCIYkYviJkKsx1WOw8H+5FTnRmCIAiCqDUkZgKFU8zE6j3FzJCbiSAIgiBqC4mZQBERDQCI0wl1ZSosNtgcPHRgBAwFABMEQRBErSExEygiEwEACSgHAFSa7bDZHdJ6mmSZIQiCIIhaQ2ImUEQlAQBi+QoArGWGcTVRADBBECENBQAT4QGJmUARlQgAiOHLAACVFjvsDh4cx4gZsswQBEEQRK0hMRMonG6maLsgZirMgmWGA4kZgiAIgqhLSMwECqdlJsomiJlys80ZM0NihiAIgiDqEhIzgcJpmYlyWmaKKqxkmSEIIrygonlEmEBiJlA4A4BNtlIAQFGFGRabQxoATGKGIAiCIGoNiZlA4XQzGSyCmHHwwLlys9QyQ9lMBEEQBFFrSMwEiqhkAABXeQ6J0UYAQH6pmerMEARBEEQdQ2ImUCRmCY/VJWgdYwEA5JdWg6MKwARBEARRp4SNmJkzZw5atWqFyMhIDBw4EFu2bKnvKXkmIgaIzQAAdI44B0AUMwxkmSEIIqShAGAiPAgLMfPtt9/ikUcewTPPPIPt27ejZ8+eGDVqFAoKCup7ap5Jbg0AaGcUxExeSbWsNxOJGYIgCIKoLWEhZmbPno17770Xd911F7p06YK5c+ciOjoan376qep4s9mM0tJSyV+9kNwGANDOkA8AOHquQnKfY7eTm4kgCIIgakvIixmLxYJt27ZhxIgRrmU6nQ4jRozApk2bVN8za9YsJCQkuP6ysrKCNV0p8c0AAJkGt5his5lsdlvQp0QQBEEQDY2QFzPnzp2D3W5Henq6ZHl6ejry8vJU3zNz5kyUlJS4/nJzc4MxVSXO9Owm+irXIrbOjN1GYoYgCIIgaouhvicQCEwmE0wmU31PA4hMAADEoZJZyIgZcjMRBEEQRK0JectMSkoK9Ho98vPzJcvz8/ORkZFRT7PyEaeYMVhKEWsSdKNO4mYiMUMQRAhD7QyIMCHkxUxERAT69u2LVatWuZY5HA6sWrUK2dnZ9TgzH3CKGVQVIyFKKJzHkZuJIAiCIOqUsHAzPfLII5gwYQL69euHAQMG4H//+x8qKipw11131ffUPCOKmeoSxEUKH7U0m4nEDEEQBEHUlrAQMzfffDMKCwvx9NNPIy8vD7169cKyZcsUQcEhByNmElIFywxbZ4YsMwRBhDbkZiLCg7AQMwAwbdo0TJs2rb6n4R+RicKjrQpNInnFaofDBthtwIVjQJN25J8mCIIgiBoQ8jEzYY0pHuKdTVqE0J9JapmxAz/eC7zbD9j+WX3MkCAIgiDCHhIzgUSncwoaINVYDUAlZmbfj8KLDW8GeXIEQRAE0TAgMRNoopMBAOk6oQowm83koNRsgiAIgqg1JGYCjbOlQRp/HgBVACYIgiCIuobETKBJEMRME0chAIDj3GLGarPUy5QIgiB8gpISiDCBxEygcVpmUh3nFKusVmuwZ0MQBEEQDQ4SM4HGaZlJsAjtGNhsJiu5mQiCIAii1pCYCTTxzQEAEZVnAUizmaxWVsyQOZcgiFCDzktEeEBiJtA4LTNcyWkAUsuMzUZuJoIgCIKoLSRmAo0zZgaV53BFxySpZYbcTARBEARRa0jMBJqoJMAYDQB49+o0NIkxulbZSMwQBEEQRK0hMRNoOM5lnTGUn4FeUmeG3EwEQYQuNoeypxxBhCIkZoKBM24GJacBKppHEESYUFJFN1xEeEBiJhjEZQqPZWcBngkAtpOYIQgidCHLDBEukJgJBs7+TKi6APCMZYYRM9U2B15YvB9VFurXRBAEQRD+QGImGEQlCo/VxdByM50tqcbHG47hvbVHgjo1giAIggh3SMwEg8hE4VFmmVHrmn20sCJIkyIIgvAMOZmIcIHETDCIShIeq4olYqbSbK6f+RAEQRBEA4LETDBwiZkL0gBgtWwmqh5OEETIQCckIjwgMRMMWDHDGG71TGsDETp1EARBEIR/kJgJBmIAsMzNxIoZEjEEQRAEUTMM9T2BRoFombFWgJUtek7FMsORrCEIgiAIfyDLTDAwJQCc3vnCbZlJMCk/fpIyBEGECpTNRIQLJGaCgU4HJDRXLE6M1LueiycNMswQBEEQhH+QmAkWyW0Ui+JVLDMEQRAEQfgHXU2DRXJrxaIIHWUzEQRBEERtITETLFQsM1mJJsUyCgAmCIIgCP8gMRMsElsqFqkFABMEQYQKPNmKiTCBrqbBIj5TuYxX9mZy8JQ/QBCEj+xeCJzdXd+zIIh6h+rMBIu4psplDqWYsdlJzBAE4QNH1wI/3iM8f7akXqdCEPUNWWaCRWy6cpmKmLHYlUHBBEEQCvL21vcMCCJkIDETLPQGILqJdJnDqhhWUFqNvafpLosgCIIgfIXETDCJzZC+tltcT8VAu12nSnD1Oxuw5xQJGoIgPECZjwThgsRMMImRWWbsSsuMyB+HCwM8GYIgwpogJAtQNhMRLpCYCSYRcdLXjGVGjo7uugiCIAjCJ0jMBBNTrPS1B8sMaRmCIDxCJwmCcEFiJphE+C5mdHSeIgjCE0FxMxFEeEBiJpgoLDNmzaFWqjdDEARBED5BRfOCicIy446Z0bnugXhM0K9A0rlSAO2CNjWCIAiCCFfIMhNMPLiZdBCK5Q3T7cJ/jZ/htn2TgzkzgiAIgghbSMwEE4WbyW2ZiTIKQTJtuTPBnBFBEARBhD0kZoKJB8tMUqQeAMBRyB1BEARB+AWJmWBi0q4zwzk7aOtBvZkIgggNqGgeES6QmAkmcsuMrdr1VIyZ0ZFlhiAIgiD8gsRMMElqqbmK4+0Y3b2pS9QQBEF4hm58CEKExEwwic8Ebv8euPw55TqHA/+7pRd6Z8X7tckvNh3Hje9vREmVdgE+giAIgmjIkJgJNu0vB1oNVS7n7TDqdejTPE65zgP/WbQPW09cwEd/HK2jCRIEER5QPAtBiJCYqQ/0RuUyXnAvRRvdX0m1WbsRpZxys63W0yIIIpygrtkEIUJipj6ITVcucwjZTCa9e9G50oogTYggCIIgwhcSM/VBdIpymTM1m2MCgIvKKl0ihyAIQgpZTQhChMRMfaBT+dhF0cKIl5ht7wMvtwRObw/SxAiCCB8om4kgREjMhAw8wPOu2BkAaLvvHcBSBvz6YD3OiyAIgiBCGxIzoYTDLqkK7IKjr4kgCIIgtKCrZH1xw0fKZbwdsJmVy3V6lFVb8c2WkyiqcIsdm50K7BEEQRAEiZn6osdNQNcbpMs0LDM8p8fMH/dg5o97MPnLba7lFhIzBEEQBEFipl5J7yJ9zTsk/ZpELA4Oi3efBQBsOVbkWm62kpghCIIgCBIz9Un2/UCPW9yveTtgU1pmKq3qWQusZcbuoMwGgiDqFiqaR4QLJGbqE2MkMOZ9QGcQXpvLAbsyZqZCQ8ywlhmLjaw0BEEQROOExEx9o9MBManC84oC1QDgcouWZcZdk8Zso+J6BNGo4MkaSxAiJGZCgdg04bEsDzi+XrH6bJl6R+xq1jJDwcAEQRBEIyVgYub48eOYNGkSWrdujaioKLRt2xbPPPMMLBZpTMju3bsxdOhQREZGIisrC6+++qpiWwsXLkSnTp0QGRmJ7t27Y+nSpYGadv0g9mpa94rqarvG18QKGHIzEUQjgwt8PAvFzBDhQsDEzMGDB+FwOPDBBx9g3759ePPNNzF37lw88cQTrjGlpaUYOXIkWrZsiW3btuG1117Ds88+iw8//NA1ZuPGjbj11lsxadIk7NixA2PGjMGYMWOwd+/eQE09+IiWmTM7VFc7NL4mNmbGTGKGIBoX5GYiCBeGQG34iiuuwBVXXOF63aZNG+Tk5OD999/H66+/DgD46quvYLFY8OmnnyIiIgJdu3bFzp07MXv2bNx3330AgLfeegtXXHEFHn30UQDA888/j5UrV+Ldd9/F3LlzAzX94KLWRZvBF8sMiRmCIAiisRLUmJmSkhIkJye7Xm/atAkXX3wxIiIiXMtGjRqFnJwcXLhwwTVmxIgRku2MGjUKmzZt0tyP2WxGaWmp5C+kiUnzuFrL1Gu2uoN+yc1EEI2MILiZCCJcCJqYOXLkCN555x3861//ci3Ly8tDerrUKiG+zsvL8zhGXK/GrFmzkJCQ4PrLysqqq8MIDGzxvNYXA837S1ZHcOqZSmSZIYhGDLmZCMKF32JmxowZ4DjO49/Bgwcl7zl9+jSuuOIKjBs3Dvfee2+dTV6LmTNnoqSkxPWXm5sb8H3WihbZ7udxmYDOKFkdbZCetBzOAnnSOjOUmk0QRN1CcokIF/yOmZk+fTomTpzocUybNm1cz8+cOYPhw4dj8ODBksBeAMjIyEB+fr5kmfg6IyPD4xhxvRomkwkmk8nrsYQMeiMw5EFgy8fA0EeAJdMlqyN1UqtLtc2O6AiDNJuJUrMJgiCIRorfYiY1NRWpqak+jT19+jSGDx+Ovn37Yt68edDppIag7OxsPPnkk7BarTAaBWvEypUr0bFjRyQlJbnGrFq1Cg899JDrfStXrkR2djYaFCP+C1z+nPBcL7XMJEZI74+qLIKYYWNmqE8TQRAE0VgJWMzM6dOnMWzYMLRo0QKvv/46CgsLkZeXJ4l1ue222xAREYFJkyZh3759+Pbbb/HWW2/hkUcecY158MEHsWzZMrzxxhs4ePAgnn32WWzduhXTpk0L1NTrBzaYTyfVmCnR0q+pyiliSqpsimUEQRAE0dgImJhZuXIljhw5glWrVqF58+Zo2rSp608kISEBK1aswLFjx9C3b19Mnz4dTz/9tCstGwAGDx6Mr7/+Gh9++CF69uyJ77//Hj///DO6desWqKnXP7KYmfgI4PVxPV2vq53CpajC3fqgrNoGK7maCIIgiEZIwOrMTJw40WtsDQD06NED69crS/izjBs3DuPGjaujmYUBOr30td2KG/s2xxsrcnC2pBojZv+B2wa2QGmVtM3BhQoL0uIjgzhRgiAIgqh/qDdTKGK3yF4LomVYR3es0tebT2LXqWLJsKJK2fsIgiBqAbUzIMIFEjOhSMlp6etzOUDpWbx0bSfJ4tyiKsnronISMwRBEETjg8RMKFJ6SrlsdidwHwzFvLv6K1bFmgRv4fkKEjMEQRBE44PETChSdUF9eeFBDO+Qim7N4iWL26XFAgAukJuJIAiCaISQmAlFUjo4n6j4q23VLkuMiChmzpObiSAaEUGuz0vtE4gQhsRMKHLL10C/ScCdPyvXVZdKxEx6vAlNE4QMpiJyMxEEUYdI9AuJGSKECVhqNlELUtoDV88GLpxQrjOXIYYRM61TYpAULXQdp2wmgmhMUKYRQYiQZSaUkbU1AACYpZaZ1imxaBLrFDPkZiKIRkSwLSVkmSFCFxIzoYxOTcyUycRMNJJjnGKG3EwEQdQlbJsVcjMRIQyJmVBGr+IFNJdK3Ezt0+LIzUQQREAg+UKECyRmQhmDSmuCQ8tg1Lu/ts5N411upgsVFvB090QQRECgcwsRupCYCWWMUcAt30iX7fgStvwDrpfp8SaXZcbm4FHKdNImCIKoFZTNRIQJJGZCnU5XKRYNSRSK6qXERoDjOEQa9YiJEJpTrtifF9TpEQRBEER9Q2ImDOnVPB7zJvbH0geHupZ1yRSqAr+9+nB9TYsgiPoiKFYTsswQoQuJmXCg+QDJS52lDMM7pSEtzh1TM/eOvgCE5pNnS6QNKAmCaOAESMxIumaTm4kIYUjMhAMTfgWmbQUSsoTX5jLFkCaxJlfPpp93nAnm7AiCIAiiXiExEw4YI4WqwO0uE15Xl6oOG9UlAwDw1qpDKDdTIDBBNB7IzUQ0bkjMhBMmZ7dss7qY+b/h7cBxQLXVgfzS6iBOjCCIeiUYLiByMxEhDPVmCicinWKmukS6fNe3QEJz6FsNwfTYFUDVBRRXDg7+/AiCCB5BEBckX4hwgSwz4YRomdnxBVDmTMHO/Rv46T5g/lWAw4Fp1vmYZlgESwFlNRFE44HcTETjhsRMOCGKGQBY+m/hMXeze5nd7HpaXl4RpEkRBFEvBLtvErmZiBCGxEw4ERHtfn7huPBYdta9zOpOyS4124MzJ4Ig6gcSFwThgsRMOKFjQpxi0oTH0tPuZVUXXE/Lqq1BmhRBEPUPuZmIxg2JmXCi3eVArJB+jX9WASv+A5Sccq9nxExFFWUzEQRRO6hoHhEukJgJJwwRwB3fu19vfBs49bf7dWWR+2k1iRmCaDSQ0CAaOSRmwo24TO11jGUmv6gMPJ3gCKKRQG4monFDYibciE7WXlfltszknivF9pPFgZ8PQRCNA7o5IkIYEjPhBscB438GhjykXMe4mYycDbtPFQdrVgRB1CcBExqc9yEEEQKQmAlH2g4Hhj/hbjwpwlhmDLDh1AXqnk0QjQNyMxGNGxIz4YrBBEzdAjy4C2g5RFjGxMxEwIb1hwvhcNAJiCCImkFnDyJcIDETzkREA0mtAKOzmF4la5mx41B+Of6zaG/9zI0giOBBFYCJRg6JmYaAMUp4ZCwzRtgAAF9tPokjBeX1MSuCIIIGCQ2icUNipiEQESM8MjEzzROMrudHCsqCPSOCIAiCCBokZhoCLstMsWvRvy9rjUs7CS0PiiqotQFBNGjIzUQ0ckjMNATEmBlzqWsRZ63CYH4nYlCFogqzxhsJgmgYUDYT0bgxeB9ChDzxKlWB176Me8wl6Gzsit8rPgr+nAiCCDAkLghChCwzDYHUTspl5hIAwBD9PhRVWII8IYIgggq5mYhGDomZhkBaF4+rScwQBFF7SMwQoQuJmYZAXAYQlaS5msQMQTR0SGgQjRsSMw0BjgMufUpzdWEZBQATRIOG3ExEI4fETEOh/z3AtG1A60sUqwrKzLhQW+vMxneA94cAFedrtx2CIMIUEjNE6EJipiGR0g5o3l911YGzparLfWbFU0D+XmDD7NpthyCIsIEjAUOECSRmGhr6CMUiDg7sO1NLMSNip/gbggg5yM1ENHJIzDQ09MrSQdEw48WlB7Bwa249TIggiHBFapkhMUOELiRmGhqc8iuNRRUA4NHvdwd7NgRBBAUSGkTjhsRMQ8OsbCoZy1WpDl1zsAD/FFJHbYIIewLkAuKCsA+CqAtIzDQ0qksUi+bf1hGAkMFtdwgnpJ25xbhr/t+47I11QZ0eQRB1RNDFBYkZInQhMdPQqFYG+mZG2gAI574LlUIA7/4aBwRz3ocQBBFkSGgQjRsSMw2NqETFIr2tCknRRgDuasCRRvdXX2mxBWVqBEHUJYEXMJIAYHIzESEMiZmGxiWPK5dZK9Ek1gQAOFcuVANmz0vnyijdmiDCDj7YQoPEDBG6kJhpaMSkADd9Ll1mqUByjFB/5ny5IFwqGGvMuQpqd0AQ4Ufg06apaB4RLpCYaYgYo6WvLRVIdVpmjp2rAACUVTNihno3EQThDXIzESEMiZmGiFzMWCtxcYcUAMD3207B4eBRYXaLmfPUVZsgwg+JYYbcTETjhsRMQ8Rgkr42l+LaLkmIjtDjZFElDheUo9xMlhmCCG+oOi9BiJCYaYjIqwBvfAdRs9tgaJaQ0bT52HmUM26mcspmIghCBcpmIsIFEjMNEb1RucxuwZi4QwCALceKJJaZKovd921zVGeGIEICymYiCBckZhoiaV2A5v0Vi1umCLE0+8+WSsRMpT9ihiCIEIHcTAQhQmKmIaLTA5NWAtfNkSxulhgJADh+rsJVbwbw0zJDpmaCCA2C8H+R3ExEuEBipqHCcUBEjGRRfIQOTWIi4OCBQ/nuBpNUAZggwhwSGkQjh8RMQ8YoFTOctQId0uMUw8jNRBDhSDCK5hFEeEBipiETIas3Yy5Hs6QoxbAqKwUAE0TYEWxrDFl/iBAmKGLGbDajV69e4DgOO3fulKzbvXs3hg4disjISGRlZeHVV19VvH/hwoXo1KkTIiMj0b17dyxdujQY0w5/ZG4mWMqRmRCpGEaWGYIIcwIkNKidAREuBEXMPPbYY8jMzFQsLy0txciRI9GyZUts27YNr732Gp599ll8+OGHrjEbN27ErbfeikmTJmHHjh0YM2YMxowZg7179wZj6uFNdIr0tbkMTRPdlpnBicWIR7l/AcAEQYQIwRYaJGyI0CXgYua3337DihUr8PrrryvWffXVV7BYLPj000/RtWtX3HLLLXjggQcwe/Zs15i33noLV1xxBR599FF07twZzz//PPr06YN333030FMPf2LTpa8tFch0ipkWXD6+rv4/bDA9RAHABBGO8EFuNEluJiKECaiYyc/Px7333osvvvgC0dHRivWbNm3CxRdfjIiICNeyUaNGIScnBxcuXHCNGTFihOR9o0aNwqZNmzT3azabUVpaKvlrlBgipK8t5ciIF9xM/bgcAEA8V+ldzEhOYhQzQxChAQkNghAJmJjheR4TJ07E5MmT0a9fP9UxeXl5SE+XWg/E13l5eR7HiOvVmDVrFhISElx/WVlZtTmUhoO5HO3SYjG6e1P07tzetTjaVoIjBeW48q31+HXXGeX7gnAHSBBEaMPzjvqeAkFo4reYmTFjBjiO8/h38OBBvPPOOygrK8PMmTMDMW+PzJw5EyUlJa6/3NzcoM8hJDGXQa/jMOf2Phif3cq1OJM7j7vn/40DZ0tx/zc7lO/jKaaGIEKOoLiZ2N3RjQwRuhj8fcP06dMxceJEj2PatGmD1atXY9OmTTCZpB2c+/Xrh9tvvx2fffYZMjIykJ+fL1kvvs7IyHA9qo0R16thMpkU+yUAnNgAfHQpcPcKwG51Lc7kzmNlUaX2++iOjCBCkOC6mUjKEKGM32ImNTUVqampXse9/fbbeOGFF1yvz5w5g1GjRuHbb7/FwIEDAQDZ2dl48sknYbVaYTQKzRFXrlyJjh07IikpyTVm1apVeOihh1zbWrlyJbKzs/2deuPkmreBXx9wvz69DSg5CdgtrkWZ3HnP25CIGYqZIYjGAsdRXA4RHvgtZnylRYsWktexsbEAgLZt26J58+YAgNtuuw3//e9/MWnSJDz++OPYu3cv3nrrLbz55puu9z344IO45JJL8MYbb2D06NFYsGABtm7dKknfJjzQdwLQbazQSfuFNGFZySnA5hYzKVyJ67laHRqyzBBECBJkcUExM0QoU68VgBMSErBixQocO3YMffv2xfTp0/H000/jvvvuc40ZPHgwvv76a3z44Yfo2bMnvv/+e/z888/o1q1bPc48zDDFAgYT0GaY8Pr0NuC3R12rjXBnM1kdKidIB8XMEEToQW4mghAJmGVGTqtWrVQDyHr06IH169d7fO+4ceMwbty4QE2t8ZAgWMTw+7OSxSa442cqzCpp2nRHRhChB7UzIAgX1JupMZGgnqLOWmYqLXbY5dYZEjMEEeIEvmgeZTMRoQyJmcZEvLKlBABEQGqNqZAX0aOTGEGEIMGOmQnq7gjCL0jMNCZMcaqLjZxMzMhdTUydGRvFzxBEaMAHPmZG2miS1AwRupCYaUxExKovZmJmADUx43YzLdpxqs6nRRBEbQmC0CDTDBHCkJhpTETEqC5unyzt4VRuFqwvPM/jwNlSVJrdadwV1VLhQxBE44CkDBHKkJhpTGiJmRQT/n5yBDqmC26o8mrBMrPpn/O48q31uP+rba6xOjiUAcIEQQSfoLiZ2F1QIgARupCYaUxouJk4uwWpcSbERwmZ+iVVgvVl0U6h6WROnruong68MkCYIIh6wM94FptFaGey9LEa7o5uYojQhcRMY0LDMiO2NmiaEAUAOFNcBQBIixf6W3Fw35Fx4FFppiBgggg7Dv0mFMzc8oHPb5GkZgdiTgRRR5CYaUxoiRmbGQDQLEkQM6cuCE0njXrh56FjTmN6OFCuVliPIIjg4q+byVG7/7fkZiJCmaBVACZCAKNny0xzp5j5bNMJZCVHY/bKQwCkYkbH8epVggmCCDKBT5vmgtwygSBqCllmGhM6nbqgcYmZaNeiF5YccL9N4mZykJghiEYISRkilCEx09hQczU5O2i3ahKtXAepZSYOVei0/Fbgr7kBmR5BED4S5GwmsswQoQyJmcaGmphxWmZaNonBTf2aK1azlpmR+m1ILtwCLHtccxePLtyF//tqG/VyIYiAEuTqvPTfmQhhSMw0NtTSs6suuO667r+0vWK1zo+zWIXZhoXbTmHpnjycLamu8TQJgvBCkG8WeFIzRAhDYqaxYYxULrObgR/vBaqKkZGgXM9aZrwh1qghCCKIBKE3E0/FMokQhsRMYyMhS335noXAKy1hhB1xkdIkt8Qovc+bZ8WMxUapnAQROIItLkjMEKELiZnGRrM+ntdXnMOsG7rjiq4ZrkVTLm7j8+ZZMWMmMUMQgYMPRswMFc0jwgMSM42NDld4Xm8uxdU9MjF3fF9EGQWLTO+seJ83X1zJihmqFEwQQSEY8TNUNI8IYUjMNDZS2gMTftVeX3XB9XTLk5fh7ydHIMbIqQ412+xwyPzopeRmIoggEVgBw/O8tNFkQPdGELWDxExjpPXFwP/9BdzwsXIdI2biIo1IjTNp3pF1fGoZZv12QLKM3EwEESQC7GaSG3soAJgIZUjMNFbSOgM9ximXVxUrl3kwL3+0/hgqmS7aUjFDbiaCCByBLZrHQ9bOgGwzRAhDYoaQwlhmXHjxlf9x6JzreXGVxfWc3EwEQRBEMCAx09gZ8C/pazUx41C3sHDO+jOH88tcy0qr3FYacjMRRAAJuJtJtk0H/X8mQhcSM42dq16Vvq4uVo7RsMwYIYicY+cqXMvKmSaUZiud/AgicPCqT+ty65KieeRmIkIYEjOElMoi5TINf7xBFDPnNcSMncQMQYQO6lmJWigCgKnXGhHCkJghpJzdpVymYZkRxcyOk8U4daESgNCbScRspQBggggYfruZ/AsY5sHLumbT/2cidCExQwD/Wg/0ukN4fv4wUHpGul7jJCaKGQB46/fDAIBKi3sZxcwQRCCpRTaTL2KGUrOJMILEDAE07QGMmQNk9BBen94mXa9hmenTPA6vjhXec7igHIDMzURihiACR620hW9vptRsIlwgMUO4iXP2Y5JnNGmImY/v6InuzRMAAP8UlIPneYmbiVKzCSJY+CI0GKeRD60JFMYbamdAhDAkZgg3kYnCo7xwntZJzGFDyybRAIAysw1DX10jczORj50gAoe/lpKaxMww2UwkZogQhsQM4SYqUXiUp2dr1JmBw4boCIPr5akLVZLV5GYiiADC1yJmpiYuI6ozQ4QwJGYIN/5aZuxC64J/XdxGdTW5mQgiWAQ+AJggQhkSM4Qbl2WmRLrcblUMBQA4hPiYmVd1RkyEXrG62mrHofwy2CkLgiACgL//r/yMmZG+AzxZZogQhsQM4Ua0zLBuJrsV+Hmy+niHW+R8eGc/xerFu89i5Jt/4KWlBxTrCIKoJQF2M8mL5HGUzUSEMCRmCDeiZYZ1MxV4ECJMLM2Qdim4vncz1WGfbDhW+7kRBCEj0EXzpO/hqWgeEcKQmCHcRApp1qguBk5tA76+GTi6Rnu8zP10/6XtYNBxGNE5LXBzJAiiDqhBzAwF0RAhjMH7EKLRILqZzh8BPr5UeH5omfZ4h1TMtEmNxc5nRiImQo+r3t6AA2dLAzNPgiBq4GbyL2YGvCxmhsQMEcKQZYZwk9zaLWh8wWFTLIo1GcBxHAa3beLTJuwOHofzy+hESRB+U4vqvD7WmZEuoABgInQhMUO4iYgBpm0FTPG+jbcrxYxIz6xEyWutNO2nF+3F5W/+gY/WH/V1lgRB1Aj/xQ8VzSPCBRIzhJTYVGDKRiB7GtD5WmDAv7THqlhmRC7rlIbmSVGu10UVFgDA3HX/4P21/7iWf7X5JADg9RWHajlxgmhk1CabqSZ1Zig1mwhhKGaGUJKYBYx60f16x5eAtUI5zqFRfwZAjMmANf8ehsEvr0ZhmRnnys2IMurx8m8HAQDX926GjIRI13hOa0MEQWhQmzozvmUzUTo2ES6QZYbwTsvB6ss9uJkAwKjXIS3OBADIL63Gc4v3u9YdyJMGB+s4kjME4Rd8LWJmalBnBpSaTYQwJGYI74x5H2imLIrnyc0kkhEvWF/eXnUYP2w/5Vr+684zknE60jIEUXN8cjPVpM6Mv/sgiPqBxAzhndhU4Nq3lcs9uJlE0p2upF2npC0SftxxGmsOFrhec2SZIQg/qU2cjG8xM9LUbIqZIUIXEjOE/xicsS5+WGbUeGXZQddzuZQprfYulDwx88fdePz73bXaBkGENP66mSQBw770ZpK7mXybFkHUByRmCN9IagXENQVaXgR0GCUs8xIzA6iLmRv7NgcAHMwrcy9k1Mx3f+eix7Mr8N3fuTWaakmVFd9sycW3W3Nxrtxco20QRFgRADeTUDSPfQ/FzBChC4kZwjciYoCH9wN3LgJ0RmGZD5aZ9ASpmBnZJR1PX9MFTWXLWcvMYz/sljz6Cxu4aLWTaVwOfSYNhQC7mWq7P4IIIiRmCN/R6QC9we1mqi4BCnM8vqV7swQkRQviZ+LgVvjwzn6IjzSifXqcZBzHccjJK8Olb6xlltVsmjaH+6Rrs9MJmGX+n8fQ+T/L8NfR8/U9FaK2+J3N5H9dGmnRPPq/RIQuJGYI/4nPFB7XvQzMGQCc2KQ5NDkmAptmXoZdz4zEs9d2dS3vkBYrGcdxwL8X7sLRQnc9myYxETWaHitgLCFghThXbsa7qw8jr6S6vqeCZ3/dD5uDx/TvdtX3VIha46/byKH+XGs4NZokwggSM4T/JLWUvj68XPr66Frg0ArXy0ijHglRRsmQzMQoyWsOyqDf5BqKGdaNYrbWv5iZ+tV2vL7iECbO21LfU2l8nDsCvNsf2Pl1fc+k/vHbzcRLA/MpZoYIYUjMEP6T2EL6mo2dsduAz68Dvh4HVBZpbiLVWUxPRC01Oz7SqFjmCxIxY6v/E/DmY8LnIAl4rmcaTSb84oeAc4eAn6fU90zqngC7mRQ188gyQ4QwJGYI/0mUWWbK8tzP2bYHVRc0N5ESKxUzRRUWnDhfKVlWUxcRGzNj1mhw2dhpNGLGWul9TEPAJy1TuwBgjsQMEcKQmCH8J76Z9HXBQSBvr/Dcwlw8PPjl5ZYZNaosdpy6UIlRb/6Bb7ac9Hl6UssMiRk1uEbTDauxHKcv+Flnhuf9fg9B1BckZgj/0RuAu34DLnpYeJ2/B5g7BDi0HDjFxIVYqzQ3kRrrXcxUWux4bXkOcvLLMPPHPT5Pjw0ANlsD52ZatPM0LntjLY4UhI77yFcajWWmIeN30Tw2ANj7eLtD4WfybV4EUQ+QmCFqRsvBQO/x0mVf3wR8d6f7tQcxEx/lvWF7tdWOCrP/YiRYlpkHF+zEP4UVmL4w/CoNk5ZpCNSmzox3rHZelppNlhkidCExQ9SchCzP6z3EK/jSi6nSYoehBh0orfbgxsyU17L1Qn1AvbAaALx/Ab3+BgDbHLL/O2SZIUIYEjNEzTF4SZ32YJkBgDuzW3pcX2W1Q1eDXyh7Eg5GNlOwzvHHzlXAZnfA7uDx7C/7sHTP2Rpvi6RMQ6PuezPZ7LLUbJBlhghdSMwQtePad7XXeckkefrqLphxZSePY9j4l7vn/+3TlNj3VAehzow9CGrml11nMPz1tZjy1Xb8uusM5m88jv/7anvNN0hqpgHgr5uJ/b/gi2VGOoZSs4lQhsQMUTt63wEMmqq+zotlxqDX4V8Xt/E4hk3PXn2wACWV3l06wa4z4wjCSf7j9UcBACv35yO/tPaVhEnLNAD8djNpvFcDm90hiZnhKGaGCGFIzBC1g+OAtpeqr/MiZoS3c4g0av8M1+YUSl7nXvBeN0QSMxMEy4w8tCAQsDEudRHuQjEz6nyw7h88v3h/fU+jBvjpZqqJZSZMGk3ml1bjQoWlvqdBBBkSM0Ttkbc3EGEL6LGcOwxs+wxwCFaTzU+MwM39vAQTOzlZ5F3MSGNmgiBm6tIyU3AQ2PguYDNLFusZ7dF4asQEn1m/HcQnG44hJ4SqNWvj7+/O/5gZCcFQ7bWk3GzDwJdWoffzK+t7KkSQCaiYWbJkCQYOHIioqCgkJSVhzJgxkvUnT57E6NGjER0djbS0NDz66KOw2WySMWvXrkWfPn1gMpnQrl07zJ8/P5BTJmpCSntg7CfA4Puly7UsM+/2A359ANj+OQAgARW4qrVvF+jXl+d49d2zlpl9Z0pwtsS7hag2eBQzDgfioSHq1HhvILDiSWCTNBZJV8eWlEYjh/z43ByMJaLcbPMwMkTw183k53irQ+pm8l88BZ+TTBVxRZ0cokETMDHzww8/YPz48bjrrruwa9cu/Pnnn7jttttc6+12O0aPHg2LxYKNGzfis88+w/z58/H000+7xhw7dgyjR4/G8OHDsXPnTjz00EO45557sHz5crVdEvVJ9xuBbmOly7yVkj/p7Lb9Sktc8utFSEC5a9Ub43qqvuXouQpsOnre42ZtTMzM+sPnkD1rteRCVdeodV2wO3iculCJ4vk3Y3fkvejI+V7BGABwapvkpV4jRb2mQZnkZVJiZSwPwYiDqj21KJrni5tJbpkJg5gZ9ndtrWE7FCI8CYiYsdlsePDBB/Haa69h8uTJ6NChA7p06YKbbrrJNWbFihXYv38/vvzyS/Tq1QtXXnklnn/+ecyZMwcWi+DvnDt3Llq3bo033ngDnTt3xrRp03DjjTfizTffDMS0idqS1lX6Ws0ys/Ed93PZyXHRTcn4fnI2fp12Ea7rlam5m72nSzxOw6oiXCZ99jeW7c1TGS1wrtyMifO2YNle/9Od1S58M37YjYteWYPEk0L38An62glwVsxIT9j+XXQ5ONAMheSqUoG9eAdS/NYf/llm7A6HrGt26H8mJGYaLwERM9u3b8fp06eh0+nQu3dvNG3aFFdeeSX27t3rGrNp0yZ0794d6enprmWjRo1CaWkp9u3b5xozYsQIybZHjRqFTZs2edy/2WxGaWmp5I8IAvK6M3IxU10CrHjK/dphd8XNAECrJrHo1yoZ3ZsnwKDXIc7krhL824ND8e+RHQAAB896jmewqsTJrMkpxOQvt6mMFnhn1WGszSnE5C/V0533nSnB26sOw6KybTUxs3DbKclrE1e7wnpabiZ/T9izDB/jz8gHMdLye63m0xBhxUww0u1rTa3cTN5/N3Kh7AiDmBlWpPsr9InwJiBi5uhRIY302WefxVNPPYXFixcjKSkJw4YNQ1FREQAgLy9PImQAuF7n5eV5HFNaWoqqKu04iFmzZiEhIcH1l5XlW3ApUQeMeNb9XO5mkosb3g7YmYu87IKdEG10PY+JMKBTRjwA4Mcdp/HFXydw/FwFlu/Lw+QvtqGASVdWVC71gTIvMRI3vr8Js1cewuyVhxTrfLmLN8HfGAzpNnUSy4z7uZq40sLu4HGLYS0A4I7qr/2cT8OHdTOFR7yFv/Es/mYzOaDjWGtV6IsZ9v8+WWYaF36JmRkzZoDjOI9/Bw8edP3on3zySYwdOxZ9+/bFvHnzwHEcFi5cGJADYZk5cyZKSkpcf7m5uQHfJ+HkooeBq14XnlfKYlvk4sZhB+xsCqVUzLA3kokxRvRvlYy4SMFa85+f92LMe39i+ne7sGxfHm796C/3bmpwR5YY5bYqqcWhVDkbVv64/ZRinS/XPRNqZ5lhs5lY8WTx44QtObmTl0kBa5nxRySGDbJGkwu2nMRHfxzVHK60zAS+ZlNtafDfIaGJ925/DNOnT8fEiRM9jmnTpg3OnhXiDrp06eJabjKZ0KZNG5w8KQRCZmRkYMuWLZL35ufnu9aJj+Iydkx8fDyioqI052AymWAyee/KTASIFtnCY+7fQoqxwfldWGRZPbzDo2XmdLHbkhMfKVhpnhrdGY//IHTQLmYK6P1TWAGr3QGjXqcMXGSwO3jVYFq28eWFSiuSY9RbNRSUmRXLfAkWNaF2dS9YNxMrYPw5YVvtDkQ6n5OWUWK1O9CcK8CCiBdQeuAeoPPM+p6SZ2rhZuJ5HjOcneiv6tEUzRKV51O5dcoRBpYOssw0XvyyzKSmpqJTp04e/yIiItC3b1+YTCbk5OS43mu1WnH8+HG0bCnUJMnOzsaePXtQUFDgGrNy5UrEx8e7RFB2djZWrVolmcPKlSuRnZ1d4wMmgkB6VyAmDbBVAbmb3cvlYkZumdG482OL6g3rmKa527wSwdUkdzMNbtvE9bzSou7uYc/bahV2WQEkt9z4Imb66g7hWt2fkguE3cHjke92Yv6fx7y+n3UzsQLGnzo6nkQeIVz8njB8jebcOXTZ/XKNt3PqQmWQSv/XvM6Mze7+v1ah4WK1ycSAPQzcTKw1iWJmGhcBiZmJj4/H5MmT8cwzz2DFihXIycnBlClTAADjxo0DAIwcORJdunTB+PHjsWvXLixfvhxPPfUUpk6d6rKqTJ48GUePHsVjjz2GgwcP4r333sN3332Hhx9+OBDTJuoKjgNaOgXn2V3u5QrLjFzMSF0xb9/aG+nxJnx1z0DXsvT4SPTKSlTdba6zoJ5ouWgSE4GLO6Tivdv7uMRIpUVdMJmt7uV5KmImQu/+r1JllW5Dfo5Xi7eI4cx4O2IObMc3upatOViAH7efxrO/eq84q2csM9VMiwZ/LTMi8haC9cHp4ios3n0mZDKHbA4eRtTOlTL/z2O46JU1ePm3g3U0Kw/4WdGXHW9nbhy0fgnhGABsk4iZ0J8vUXcErM7Ma6+9hltuuQXjx49H//79ceLECaxevRpJSUkAAL1ej8WLF0Ov1yM7Oxt33HEH7rzzTjz33HOubbRu3RpLlizBypUr0bNnT7zxxhv4+OOPMWrUqEBNm6gr0pwuxoID7mWqlhlGwNilYubanpnY/MQI9G2ZLFn+5T0D0a1ZvGKXYqsD8YQ2rl8WPr97ABKjIxAdoQegXQytmhEoO05cAAC8sSIHE+dtgcXmkHjAys02iWCRW2YqNKw/AMAX5vg0Tu42YC1D7J20XzEzDtbN4PPbAsbw19Zi2tc7sHBbIGPafBdtdXHxe36J8Hv/wEMsSkDw6QtlLDM2pueSxkdkl30e4SBm2CBuf/5vEOGPXzEz/mA0GvH666/j9ddf1xzTsmVLLF261ON2hg0bhh07dtT19IhAk9ZZeBTFTOEh4IgsHVhumbH7FiQbazKgV1Yi9p6WptyvOlCA4Z3SXOZxIxM1G2syoKzahkqz+p032137+22n8NCIDnhn9REAwOqD+RJ3ToXZjvhI92ubg4fDwbtcQeXV2iKFFUFsVhLP85LXpdVWsHJNJxEzNbPMyN0G9Y14sVl3qBA3929Rz7OpGzdccDtL17xrts2HYF6rQy5mwisAWK1EA9Fwod5MRGBwWWb2CxaZOf2B7Z9Jx9jMHt1MnshUCVhcsT8fd3y82WWBMOjcP2/RMrN8Xx4KypRuJNZ1c6akGusOuRtcFpZbJCKkwmxTNOF7a9Vh13NPpfDZu102Dlke+7L5WBFmrzyElfuFAHj2Islu3x9rgtTNJA0GPVMc2JYPngiV2IaapPTLCarHzG83k/spGzMj/y27x8jETCiY87zAzjlUfldEcCAxQwSGJu2ApNaArRrY+4P6GGulRzeTJzIT3GKmc1O3DeNQfjlKq4TtGGSWGQB4d80RTPj0b8X2qmVxMHfNd4/Jk/V2Kqu2KU70rJgp82SZYS4IbIaSfP8ceLy96jDu/XwrAOmFhLX8+BczwwoY977/9/thDH55Neb5EIgcCEIltsFqD5e+0Cr46WZiRbWWRUohZsLAMsO6UkPld0UEBxIzRGDgOKDnrcLzbZ+pj7FUyiwzvheWYy0zY/s0k6w7cLYUbbnTSKt2X5yjIwyS9XJEN9Mt/ZUFFv8pkMb6VJhtHu/6PFpmHOxz9zbkQcVy2P2x2/cnm0nr5C4Ksf/6EIgcCAJ60fGjCVWDv/hJAoC9pzDLs5fCIWaGFWAUM9O4IDFDBI52lwmPp7eqr7dW1ihmBgAyEyNdz7s1S5D0csotLMYq06MYt/lGV9XhGJM0PEyeoi1aRoa0S8G4vs0l644UlkteV1hsqhcAMSunrFr7ONgLBGtVqbLILTPy90ndXK5t+OVmYiwzKusNGs0sA02ouAPCLnXdXzeTJDXbe7VjufuJDwsxQ5aZxgqJGSJwNO0JRMRqr7fI3Ex+xMykx7vFTIf0OLx5Uy/cNaQVACAKTGG7aqEpZUmVtGjd8XNC5pPdGbxb7RQWkUY9WjaJloz9RyZmHlywE6UqgqWoUtjHhUrt42BPsKxVxZNlhud5yYXl6Dm3paimAcBqly+bg8fcdf9o1uIJFKESmFxvF7+zu4DNHypz/L3ib9E8RsAwMTNaYtJql5cg8E3s8TyPFxbvx8Ktwa+8bqWieY0WEjNE4NAbgfaXa6+3lNfYMmPU6/DrtIvww5RsJMdEQKfjMG14O7RIjpZaGJwn8H6tpOndry4/iILSakz+chv6v/g78p0F9yKNOmQlS8WM2nVi4VahrUF8pAEpsUJdJLFo34UK7Wq/rPiwMEHHcssMu0ubg9e84Nc8ZkZ9zMu/HcTET//Ggi0nayQyDpwtlfTJ8ndecp5ZtBcjZq/TLOxWl9gcfP3U3/ngYuC3R4Fd3wR2PxpuJi3LjL2G7Qz+OlqEjzccw6Pf767BJGuHNJspzCxtRK0IWGo2QQAA+t4F7PtJfR1vB8xM/IofMTMA0L15guR1k1gTfntwKCylBcAccZvCCXjyJW3RNTMev+/Px887z2BtTiFu/egv/FMojYcxGfRom+rBmuTkgtMKY9Tr0DQhEufKzcgrqUa3ZgmudWpYGAuMJ8sMe0mttto1M05YQeQNi923sVuOF2HL8SLM+HEP3rqlF67r1czjeJ7ncdf8v5FbVOn6PI+/PNrneVntDnyw7h90b56AwW1TJOs+23QCALBk91ncpBLPJHKhwoIpX21Ds8RovHFTT5/3LZ+HvkbvrCPy9vg33u/sIrmbSbiXladgu8bI2xn4uD9WeMpLDgQaK8XMNFrIMkMEllZDPa+vLHI/l7ic7MCq54B/Vnt+v80CFLkDfWNMBiRFMpckp0BKiDLi6h6ZGNDa3dpALmQAwTLTNTMej1zeAa+O7aEZP3r6ghCLY9BzyEgQXF5nS6WWmUdHdVS8T6t6r9wyI3mP1aFtmbE7sGJfHlYdyFddz1Jl8exmUuPBBTu9jikoM2NtTqHk8/Snqu/BvDLM+u0gbvtos+YYrQuuyH9/3Ye/jhbhh+2nZFYc3y+kHmNmKouErDyrf1anwOJvnRl1y4yv2Uy8j5aZSKP7/x9bvykY2CibqdFCYoYILDod0GaY9nq2szbrctr5NbD+DeCL6z1v/4vrgbd7AUeYHl6shUfmutJqhSASadSD4zg8cFl73NQ/C8nR6g0nxbgVg06wzABCCrfdweNgXhkAIC1O2ezUrNFXSWmZcZ+Uq612TVfAS0sP4r4vtmHSZ1txOL/MtXzmj7vR7Znl+PCPf9T3wfPgeb7GrQROnK/AxiPnAKj39impql2XcMA/FxrblPTUhZrVzPF48fv8WuD7u4HVz9do2wHHB6sJm43kYKx0Wj2XahoAzBarLDPX/nfgD9I6MyRmGhMkZojAc+sCYNx84Mk8IL2bdB0rZlgRcsHHmicnNgiPWz9V345d6vLpmBGHrpnKVggikQapoyGVESQDWiVjYGsh9qbQ2T07wqBzWWbySsyY9+cxl5hJUhFCRRUWTPh0C37bc1ZiBpfXmWEx2xyuC0t6vHY3+HkbjzvH2/HNllyUm234cftp13q5YKq02PHD9lOa2/PEJa+txW0fb8aeUyWq/a4Ky5XdxVm0xBlLucRd4Xkse2xijy7AP9uF1VPMjOgC2vsDlu09iz+dQq5uqbmlxZf35ha5LWe+FJezyQOAed/EASuCPNVcCgTUaLLxQmKGCDzGKKDr9cJjnwnSdRLLDHMX5+OJ0wXrD/IgZvQ6DovvvwgRBvWffrRJW8z0apGI/93Sy/W6FXcW460LkRUtnPR3nLyAF5a4e1ElxSjFzIbDhVh3qBBTvtouaW55urha8wJfbbW7XAGvj9OOB/l680kczCtFQalbSLAXk2qZ6Bj7/kafgjQf+W6n67nN7pBUUN5yvEhVzOw/U+rxzlhrHa9RHNBbhhXrzhB7dAFQrfashS8Bz3YHj8lfbsftH28OcusCNfzbv1WSweRDAHANLTOsSPfU2iMQ2DRKHxANHxIzRHDpfw8wcSmQ2kl4zcbMsKnZtblQsL59lQwpjuPQTKUdQoRBhyYyAcKO65Aeh6YJUeiUEQcAWBYxA3ebv0T/w28CkKZMA0BitNHjNNmT/turDuNfX7jr8bBuJrPN7jpJG/XK/7JThrV1Pb/if+tRUOYWM6eLq1xWH9Z6wYNzWZC88eP20y531F3z/8aAF90uvWqrXbVh5kPf7sQ9n2nUF4J2cCbremPT371dFKsllhm3m6nIQ2aZHF/qzLA1gkurvF+oS6utfogePwNl2e36sA926+XV7s/FaneA53nFxV9ZAdi342B7IgXbMlMvdWYOLgXy9gZnX4QmJGaI4KLTAa2GAHFNhdcSywxz4lOzzDgcQLWyeq9yHLMdjdo1ahlLRh2nyLy4rHO663mHdOE9F7UTMm4iOWHbTc4p2yNc0iEVbWT1agCpSKmQNb38/UCB63m7tFh0TBdEU7XV4bpLNuo5fHXPQDw6qiMinMLm+t7SbCM2dgYARsxeB4eD16hlw8MA7xeck07XzfrDUvdKlcWu2byT7W8lR0s4sIHQrJup1KuYUbfM+JNJ4y3IGIDEDVXkIWsNAHLyytDj2RX490JfU5RrY+nx/l4rE3xeytRdsjl4PPHTHvR9fiXyz54C5gwC/nxL0auK99FaKq1WHdyYGVYMB0XMnN4OLLgVmDsk8PsiPEJihqgfTMKFWhozYxWaT144oS5mFtwGvJwFXDjuedse3Ewiky9pAwDITHAX31O78F3cIQVZyVFIjzehg1NcdHRaZkSMsOOVsd2REuu26nw8oR84Lyd/9qIrR68TMqsAwTIjXiD0Oh2GtEvB1OHtsObRYfj9kUtc8xLZeuKC5PWpC1U4VFCmmjH1muED7DLdi1RcUKybOtxt8cnJV7fiVFntNSqyp3WhqWQEF2uN8dQiAoDEZcfGzPhT1FgusLxZVIoqPMcFfeAMvpbHJR0pKMdzv+5XuMA2HyvCmDl/eoyfYvElLb/aand976yYKZOJmW+25KLMbMPxRS8AhQeAlU8rLDGim6nSYsOHf/yDE+eV2YCA9Lv1JkLrksP5ZZjvjBsT5qH9/VVb7dhw+FztXVEF9dMChFBCYoaoH0zOIFx5zMznY4C3egCnt7mXixeVQ78Jjzu+9Lxt3rObCRCK6P0wZTC+vGega1mLZKUlxWTQY/H9Q7HioUtcKaftZeIBDjtu7t8CL13f3bXIqNepCjI93MuOn5NfDNwnX4NOB5MzGJm1zLAFAZslRqFdmmAtimLSYbceZ1x3Tv4+fkH1IjnO8AdiODNuN6ySLO/bMgmPjuqEG5xWn5y8MtWLe0GZGa8sy0E0qmGCUjhqCQKtiwgruNhMmO+3ncLBvFLXNqutdnyy4Rge/nancMFmju3UhSrXfjnWucLzgljW4KysoahaWjF7OEUVnq0OESouQQC4/r0/8emfx/DEj3skwmv/mRLszC3G0j1nPW5XJK+UmS8zsY3/nMOgl1Zh+b483Dh3I/q9sBJ/HCqExeYWFmzLDUllaKv785F/R0Xl1dh9qhivLz+El5YexNXvbFCdV33FzLy2PEdzHnL+vXAX7vhkM2b9dkBzDBFekJgh6gfRMsOaxx1W4ORG4fnJTe7lcuuKURnvIkESM6PtCujbMgltUmPx6cR+6NYsXrPYWkKUEQlM/Evb1BjZ/oQT9siuGXjrll5YfP9FwnJeKR4McC+Ttz1gXVBJ0REwOS0zQtE84cTMdgJnWfzARS4rxPHzSovP9hMXvDazFHl+TDd8MqEfALcVKievDBUqlp1fd51BWXkZ9kfejb1R92HBvQMl67UaYYp373EmA36YMtgVaC1xM8kuhM8vFu6Cn/hpD/o8vxLPL96Pn3acxmcbj0syaMrNNhQ7P1vWMuNYcAfwUiZQXgA5x85V4JstuRJnjVpaMbs+t6hSKgRkwk3H7JxdJ8aR7MwtxqPf71Ls40KlEGdT7MGN9cuuMzhfzq53b/+pn/cir7Qa//piG/aeLkWFxY6Xlh6QWHLKmNR5NtCXtcDtPlUs2SfHAdO/24UNRwpdx6EmkFnLjDeLWl2x7UQRimXlADxZXRbvFgTjvD+PB3JaRBAhMUPUD1FJymV2jROfzSztW2NUWlAkt8w+uJlYLu2UjsX3D0Xnptop2yxxkUYMbusuvsfu77pezdCtmbMysYplRgcHRndvqrpd1mpj1HMuS9Aj3+3COeeFS6sZZNvUWDw5uotkWe8Wia7nOXnqbiY1ruyWgURnWrlLzOSXaV5cszhBHBh5C7o0lcYilWrUm3nW2aE7wqBD35ZJiIsUipGzLiu52PvzyHnk5JXhmy25kgyqX3adcT0Xt+Ny4TGuQ13OYuG72v2tYj5f/XVCsUzNqsCKkucW78ckJsjZkyVAzd1iMuhxpliZbVVhtuGpn/ei13Mrsf2k3GVYiZPnK/Hikv0S8ctW55WXFxDnxl7cpQHA6tYzuRDl4FBUt+789DJ8J+vBxLrrPFXD9sbuU8UKQaXGztxijH1/E7Yck1ok2fpHB86WYs+pkhrPJVCs2JeHrzYrf3te2fczsEv5O27MkJgh6oce4wCjzMKhJTzsFsDMnIi8WmZkRfOKc4ETG2s2Tw2+mMRYILTaMKhUTL2qayr+5YzXkaOTBXGylVRFDDrt/7ITB7dC6xT3Z/rJhP5YNf0SAELnb0ndFg+ZMyYmbV0UM0cLy1UvvIA0SyY+QpoppnYRL6u24g9ncLB4sYuOEI5VjJmpttrx/TZlDZyr31mvWMa660S32/4zpfhs43FFkDUA1cwftcahb6w4pHyvjHWHCl2WCPnF/+vNJ13P1fp1RRp1EnEqipNysw1fOd9709xNLoFnszswZs5GXPzaGqdgYDLeGAtJG7nlEIDZ6oDVFzeTh98F5/yXdd3xPPCYLL2ftcycULES+kKVxY5r3/0T177rPYZouyxGTET8Tq12B658az2ueXdDACxFNW/VYLM7cN8X2/DkT3sl7kav2G3AwgnAT/cB5dpB9o0NEjNE/ZDcBhh8v3RZlTLWAwBQlidN4VYLrPVUZ+Z/3YB5V0rjcGqJXuK/0DjZqsyzd/M4dG+WgJ6yvlKAYLVhiVSphaP3ENGqdzbbFEmOiUDrJjGIMuphsTlw4Kw7E8xTaKuJubPPiI9ERnwkHDzwwhL1YEdO4iq0Y+mDQ11fxz+F5VixL08STMoKHHFxtFGwqNw1729YbA58tfkkThZVIiM+EuP6NneNV7MiiO4vk0Hninua8eMePPPLPkn7CDfKbRw4qwxwXrLnrOJCqhYCJAbCenJrnHeKGdayExWhV/0+zzGp9TYH7xILFyqtOOcsRni+wiLr3+W5wGBptVUSAFzFWMDYz4gVM6mc1JKhgwPnys1eqzuzFqqjso7zvsK6+Lyld2uVQBDnyabne3LdBRu2arVarSZNWPe12YfszkBhrQa2fw6U1KzwZl1DYoaoPwZNAdqPBBJbCK8rNKqqzh0CfDrK/dpDECcA7XYGuVtqNk9vaFlmVNPL7eA4Ds9d1w1tUmIwsku668L/2cS+zHt5dcuMRsyMyA19muG567rip/8bDECI2+jWTHCfyd02WrDl6DmOw7+dPaZ2a5jppWLGhoQoIzpnCPv81xfbcN8X27Bol7sSsZrriU2LPphXikU7hfFTL22HSUNb+zTvSKMeWUkqLkgZPA8s23sWeSXVWLg1F5Pm/419Z4Rjk1sm5G4SNRF4pEC4YHsSM+IFlRVykQZ1MZMvy3IS4zs8NjBl9q1W96fcbJOMYfeqar0CsCpiuuR1tPP3mOelKzrbrfpkUSXMfjRDFTEzwdfe3KNaQkCsA1TIiEO/RIMvsDdRftbGYutS+RrPBkD75inYrHsF+OV+YK6X/ntBgrpmE/VHVCJw+0KhD9PPU1QDM11UMOZUr2KG+c++5BFmRYC69/opZgCgZ1YiVv97GADBBVFcZUXrWOl2+rRMxBeyWA5PbiZAEB93ZreSLLuhT3P8fVzdFK+1DZZsNj5IbTz7wnnXKL/g/bzjDK7vLVhY1MQM645Yc7DQJZz6tkhCelykYrwakUYdspK9uCABvLb8IN6zbkdcpEFx1988MRJgjDTnyy04eb4SolNRvFyN7t4UJqMOP24/jUP55biim+cqxeIF9eFvd7qWWe0OVXGaX6r++5a7quT9u0TULtg8D1Ra3J87awXUcr2YOOnyeJMO8MEbwrqZHDxw8nwlNh09j083HMMXkwYiSyVrUA57cVeb3zurDsNk1OG+i9uq9gYD3G4mVswENCCZdwCc733XjzGNWf0qb6B1vgk2R1YKj1oW9SBDlhmi/tE5zcQVHsQMiz9ihoVT+bnXRUl6P2Jm1MYmxUQIsS6S8Tyu7dlMGmgM7QBg8Dzw+38FYSjj2p6ZisrGcjzJvKbxnsWE3M0EKCvvVphtmPnjHjy9aC+OKVLSpePf/N0dq5KZGOm1krJIlI+WGbHholzIcBzQvZnU/Xe+woINTB8m8ediMujQs3kiAGD2ykPYf6YU5RoWDgA45MwSWn3Q/RsvM9ugVxGnp1UaZfI8r7DMaIkZLUuGVdMyI3wOTXEe0dD+vxUX6duFWl5D6GRRJZ5etA/Hz1fi5WUHFeP/Pl6EFxbvl8ybfS6/0OcWVeKNlUJ6uNlm1xYzVUJWGNsnLKCp4n6KDLZOj1bhSVVUsiQJEjNEKBCV6N94u/PkpFWxVeukIi+Kd/h34NXWwIHF/u1fjtbJRc0y4+lEJBuv13H4ctJArH9suGuZTkvMnPwL2DBbsHDJiDEZ8NTVnaF0kvgm5DT3Ka5nY32cn/2jTteUyNYTF/DNlpP4fNMJzF6pDKwd3jFVddsJUUZwHOdOd/dApFGP9ATfrDhqJDr3xZJfUi1xBVmcMTsmo1C8UOTR73d5vFDuPV0iCboFBBGhFgCs5nIorbZ5rGtjYd6j5mYCpN8TK4TKzTY05wqxKfJ+3GxYq7mPOJNvYkae1cUGt8r7gwHAuLmb8PGGY64ig4DUuiS3ppxhYk0qzHaFiPw/Z3sPBy/EU9WVZaagrFoSdwZAKsx9FDOVFhusdodETFf65WZiPt8g9Af7eP1RDHl5tUqQcoAs3TWExAxR/7S+BGiR7ft40TKj0arAZzHz1Vig6gLw7e2+79sf1ISLJ383rzxJ6XQcmidFYXSPphjVNR3xkRqeYS+m3ut7N8f6f1/iep0cE4H2TdwXfrVgY5b/G9YWHAd8MqEf0uNNksrJzQ3F7oHO4/vXxW0w/fIOqttie0eJvHpjT9X4EVFcdGuW4LFjOACYjHqkxHgeA2ifguWXBQ4OPPbDbmz8x13YUbQ6mAx6tE2NcdWx2XemVCFWWPafLZVYZQDhQqz3sd3C2ZIqFcuMm2omU0nLMsNJnkvTpwfrvPcWSo72LSpBaZlxiw9PAeyHC9zBwlVMQHNRhQVrcgpcx3W2xO3CfPjbnYqg3h7NE1xxX6VVVr/FTEmlFb/sOqMI/h7+2lpc+dZ6nDhfgZ25xXhp6QGcYC/wPoiZsmorejy7AqPfXi8RrVX+uJnY84q/DXllVFns2Hz0vMcmqy8sOYDTxVV4RWFVq+9Gq1JIzBD1jyECuOo138fbqoHqEu1U7lAJkPMQM6MKu445YXEchzm39cEH4/t56DXk/aKYlei+0CdEGbHywcGu1zEmzxeqRy7vgK1PjsBlndPx5+OX4s8Zl+KRyztgIHcAH+iZ7855QjfodZh2aTt8MWkA/nN1F9w1pBVeHdtDc/upcSZJJpYaSdFuV1nPrES8OrYHLu2U5loWadAhPsr7BZcDj7uHKIOKi2UB0mKqPFu/RCzOZzLowHEc/pp5mWudvNEoS6XFjgcX7HQeh+A2q7DYfA6OzSupVrjuJM1ImYBZLbcLO559vve0bxkxsRF6DGiV7HWcGAAsis9P/zzmWucpgH3J7rMY/8lmVFnsqLK4j+eR73bhrnl/Y+46wXLDWgjWHSrEjztOS7YTFWFAfKTwGZdWW12ZZIBvbqbJX27DA9/swMu/uS/eQkNV4bvaduICxsz5Ex/+cRTL9ua5xlis3re97cQF2Bw8DuWXS8SMVhC2Kux5opbxM/d/swM3f/gXPlx/1OtYrQKYoQKJGSI0yOgOjP0EuOFjoONVnscWHAReawd8P0l9vdZ/cI3WBj6Rtwf443Xv8TqSefgWM+OCFT8+ND30G4mliJNYtsRic5P1vwDrlMLSoNehSazJ9ZzjONx/aTt83nmz5j44jsPQ9qmYdFFrPHNNV1zbK9Pj9M4zvY4y4iMF8fPnW8DXNwM2iyR2pnliFG7qn4X+KRbcrF+DSJgRazL41FjSoOcwpJ3noGZAWsRQjliLJy0+0lXbZ1duMQAo4pPGyI5bzCrjeaCkwm1lkM+8TWoMhrYXXFkT5/2NTzYck6xnjWmnmT5f2pkx6mLGZ3ge1/RUL/jIWmPEzDR5zzAA0Mm+H3n/p/WHz+G7rbmqAbH/FJbDZnfglEpMEUuUUY/4KOG3UlRhkVjMfLHMbDoqWOIWMsUAj59Xzzxi45DKK+XtMOyKFhns75MNhPcnmyknr9j9opZi5vcD+QCALzZ5L9ynbE1CbiaCUKf7jUIxvWT1onIuTmwQrDKHl7uXaVUAZrF5Tin1yNyLgNXPAxvf8f09vsTMXDghWJnk62oT5KcZSyTbJlNxuX16HKJRjRnGBcCaF7TT5Bk4joPJKLOEeLA8RRr1GD+opWQZG3B7U78sAELH8b+euAw39c8CVj4NHFoG7PsJg9q4BYgYr3LHgf/DK8aP8ITha1fBPMkcVS7a6XEmZKjE1rRsEi1xRTZRcauIqdsmJm2+jVPM7HSKmcu7pEveM7htiuT1iM5prliZwjLtC3NSdARSY6VuswhGwbAum525F/De2iP48q8Trlo8YvHCOKfVjS3K+G8NF6BneFzeJUN1zYUKC95ceQi7TxW79n9Jh1TJfAFlppxaDZlv/85FSZUVEbBirO4PpDmboC7efRbdnl2O77blKt7DEh2hR+emgpD649A5yT60rFZqGJm5H2Uyj84yxSN1HCNmqqQ3OmPf34jsWasltXbYo2ctbf7Ma9K8v9wv6igYWCxa6QlHaHmVFJCYIUKPvhP9SnEE4Jvp1VoLMSNyZofvY1XdTMzcik8KTTVfdXanlhyDnycpraKBkvnItsmM65wegzfGMu0QfLVAyTPEHHbBArb8SeDIKsXw58d0c7l4Jl/SFl8ylZR7NE/E+seG44PxfRXvg6Uc9w5tg57NEzCoTTLG9RPSvOMqjgMARun/Vm1HkakSZ3Nz/yykMxlai6YOwfW9m+GjO/tJxm2aMRw9ZMUNRXHEVknu5LxwirFAsTKXXYsm0gyrF8Z0d1XptTGxLk3jTZiQ7RZ7TWIikBInnf/r49z9w+TxNq8uy8FTP7tjXxZOzsbzY7ph0xOXISZCL7mQZiVH4b/XdoVf8A5kJERi4eRsRdbXfxbtxVurDuPWD/9yWSsijXq8dqPUtVgpu2ir1c7Zf7YULyw5gAcNP+CNiLn4xfSUa1211eE15jXSqMfo7oI1bMW+PIlrqcxs89oNXcTINAr9h4nnOcNYW1jrXfUFd1sNQIijAiBpHMpasM5XWBCNaiSh1K/6NxKLYR251KMjvLtnHUEINq4NJGaI0COlPfDvw0CSb8XSAEiDgbXuVmpjmRHxMWATgIabiTkRiS0WxLlLAoBrY5nxMVWc+cw4hxVXdmUtCj6euOSfh8MGbJ0HbHoX+PIG1bf85+rO2PbUCMy4spOkgScAZCVHqxYLBHjEmAxYNO0iLLgvW3KhAQSrQ/t0pWWmWYJSzBh0HFJiTbj/0nZ4aER79MxKxJs391K6RRx2/O/mXrimp9I9xlpm5Bf2WCZIOzHaKKmrMnFwK2QkRKKHM62bzTAa0SUdF3dwZ3X1aZmElFi3y2pg62RJXy/2I1D7VWYmRmH8oJaINRlgMuqlVireIbHseGpj4B4kvL9/q2TcIytkuHyf4K6osNhd2UwReh3apEi/k1UHC3Dj+xtdrp8iD4UAR+i2AwAyON9rJIn0byX0fjt+vkKyjwqzTVFFWkvcGJnPhw0CZ7Op2MaxHRZdDVtJHk6cr8Di3VJhI8KKlrJqG3aa7sWOyMnYfuiYzyJLr5I9CAjHdq7cDzc4g9wyU1RhweWz12HOmiPuXSm8TORmIgjvxDQR4mh8hY2H0bpb8SfeRRMPdV4Uy7xYZuTb4mtzx8VaZrSyvKR1bCSfmd0mfe1rloTCMmMDLhz3/BaOc8Xf+IyXE71JD3TKiAeOrcfsjBXg4MANfZppHIewrekjO+KhER7cLbwDbVJj8c6tvZl3Ot1MjGWmm1zMmAz4ctJAdGkaj8/uGoAMxgokXrDEdhas64fjOHTJdFuX+rRIQjKTnTX75l7Q6ziM6CyITjY2R+5Ok2cNXd2jqUzM8JJKzz7BfJZXdRey69QQs42MBk61T5SYpg94bi/gb1xP+7RYDGqTjDYpMUiNMyHSqIODlxbNK6qwKIKuv9nidluxVZLPlFTjhcX7kVdSjb+Pu4PA/zrqfi5vQTLrg/m45LW1mPa124LL8+7O5PJMswhOeB15/iDW5hQy79E+dp2GZeayN9ah3wu/47yPgoa1EsnFzEfrj+JwQTleW57j3lWI+5lIzBChi8GPCx4rErzFzKx7Fdjwv5rNSetuRG2fRSoZAqzFRWHVqEXMDLstre7j8pROyWdm1W4D4XG/slNIPRX0ijfphAv4Z1fjhuL5WDjkDJ67rlsNUlfZ8vTa72VjWZolRmFga3eWj8mgw0XtU7D0waHomZUoERZ250Xqut7NAMjusnkeGfGRGNE5HQNaJaN3i0SJaT/d6XJ67/Y++OPR4YjxEOew5AFpXZ4ZV3aSdFEHeEU8i3fcczHqdfhgfD/cybjFRMRaLAadDjEmg8JyBQDvrj6CZxbt9RrM6w8/Tx2CBfdlQ6fjwHGcq08Xy+H8ckVWzhM/7XGJB7nb6+MNxzD67fWwOXh0zYxHpwyp9c4gEzO5Ks1Y950pRa/nVuDhb3fKApDdn6eO411ZWefKzRj88mq86OyFVlRhcVV/fnXZQU3LjFh1mxVenmCz9+TWULk7EHC7maqtdvz3132BraZcA0jMEKFLrOzO79Kn1McBMsuMlpgxA2X5wJoXgd+fqf38WKyyk7K5TL1+jWY8C1+7bCZfYoYcMjEjscxYpRYdX7Mk1GJm6qr+BHt36k2UyNb3iy91xq6oWcxkr09tAz64GDi2XrpSZZ/pcSZ8OL4vLmHcQRzH4at73LE/JhU32fhBLRFp1OGei4Tg9vhII/53cy/FnT3Hcfh4Qj98N1lwpYmp0NERehicfqUIg06Iw2E+H9aKMXFwK8FKxRAdYUC7FObizvOKwGSvqHweA1trZ4WJrsBv7hukcNWVVtvw2aYTeHrRPs33+2M3Sok1KcoLqImZvNJqSZd1EbHGzflypaVITO3+v2HtMO1SafkA+ffnULmkLtuXh7JqG37acdrVc0x4LyNm4MCvu85g45FzWLDlJM6WVOOj9cdQbbXj8tnrMOSV1bDaHXhv7T+qYoa1KHmqRM3CBiDLawOpGWFEMfPJhmOY9+dx1Ure9QmJGSJ0aX2x+/nULUAzlcBQEVs1YHP+5/RkmbH60FzGI85TrFxsyF1YBQfU3y5x9cg6b7NWjfNHfBc0B5cAOUuYbWlYVdjtO9QsM8x6rRo+CjxYl2oLOz9v8QTVJVKLlM4pKDy4mVx8cT1wdhfw2dWyrDjlsRj1OozsmqGoimzQ6/D1PQNxZ3ZLXKeSgv7cdV2x8+mRaJXidrv0bZkkuaCpCa9WKTFY9tBQrHt0uGIdO/72AVnYOONSrHt0GJ64qrPKWNn2eQfS4yPx6o090C4t1jdho/IdDGzjtkhlJkRKagWJF8hYkwEzruzkffu1oGUTpXBpkez+rA3O4pMAcOPcTYqxm48VYduJImz8RzuLr11arCRmCZDGzACA3cslVQwKlr9XfH7bx5tdtYwA4OlFe3G+woJKix3DXlsLQN3NxKay+5oZxYqZaqtczCi/a3FabDB0KEFihghdWg5xP49JBfSM26n7OOnYvN1Ca4LSM55jZny+SDM4VFxDcsEkDy4uPun7tgBhXuyF124Gls/0PjdzGbDgNmDHl8w+fLHM2KWiZ8eXQCFT4bOmbqa6bIIn+a58sPYsuM393CVmfHifmekGLgnCVhNC2vaCwe1S8Nx13WAyKC0zHMcpTPlZydF45QYmg0zD+tQpIx6pcZ5drp2bxiMzMQotm8RI3Uc2C7D5A6AwR/ZZCM9v6peF3x+5BNc73V4eUZlfCuNus/M8/j2qI+4Y1ALJMRESoZPuYf5xGlWt2cMYxGxLDTUrzIDWSa7nsZEGjO6hXiMHANblFGLs+5vwwhKNmxAIhR05jpPMV26Z8RZIzQoVVsyw2xG7fQPAd1tPuZ6fdgYeS1xbzhuUCiYW58M/jnqs6CsiFTPSc6ba/xrRFWcL0dgZEjNE6GKKBe78Bbj5SyA6WSoYsgYqx1vKBVeBJ8uMpQamUbkLCVARMzLLjFYQrFZMid2iFGGb5/owN5UMLc2YGdkdnXwcKwZq7GaqoZhREx3+Fjlk6w5xHiwzngROXWWU+cjlTAVjv61avgi1LR8Avz0GzBkAyAKA/UZDbN3SX6gP9LAzmPr567ph21MjkMZ0OzfodZh3V3/X60ij+3dj1OtcWVwDWiVjz7MjseWJy9CasbZ8ML4f1j82XPI+tvpzF5W0/GzG2lRcacXMKztLenxlJUfhhTHdALiLx2mh44TeXbCZcVfL8+CcgkIeMxNhNOLWAVketyUiFTPu74OtmKw6FxU3Exvjcrq4Cgv+9lyLBwCKmCKV1bKgaLNV+V2LGsbmtBj7lAEXREjMEKFNm0uAztcIz9liegnN1ceXnqp7NxMrohx2YPHDUkuIfAygHvwLeK5OXJM+K3aVzAVfspnklhm1+fiCWgCwvxfK6hLgnT7AMpklqibZVSI6g/b7fG326es+S04L6ehqotcbteqz48PnnMtUaJZsv+7urp+7rht+mDLYVfSQ4zjVSszDO6bh2Kyr8NuDQ/HHo8MxxdkQ8uUbuuPtW3rhkcs7YPbNPREXaURafKRkjglRQor7uL7CPvQ6ThK/ckU3ZTG/hCgjOjrT7ZOdmV+s6Lmqe1O0aqLMtnKvd2/TwTsbrv4wCY+cmILZzdYBADLjpaUFPryzPy5ur940VY6eETOeqk0DQDwq0IU7rhzrPJ9UyLKkxCrGIq8sO4ipX29HSZUV7609gtPFVZLGpXLxInZ5ZxEzsmz20LTM+NY5jCBCgeTWwL2rgZg0oFij/HbRMSBaIyjRVg1YfBQzxblCN29TnFQAHfhFY9syUVGucaenFagrdzP5ilq6uS9F88Tidlr46o5TDQD2k53fCOLvr/eAK2apz8Ff96CnmBmfW0qoHIvazehHlwLlecC5w8AVL/k1zVoVSmTREpA6g/oY+efiy29PY0yEQYe+LZNU18nhOM5V3PDhER1wc78sVxzRA5e19/r+p67ujMRoIy7rnI7OTePQs3kC2qXFSWr5sCy4bxBeWnoAlznT2XU6Dh+M74ttJy7g4REdJGnbLG/d0gvX9WqGVjOWSFcc+BUAcH3VTxgz6zXwv28F/mTW8w5J7aQmMRGS3lAsrGVmUnZzHD4YjePn1c9Py02PoylXhLHmZ6Bnqg6vP5SPP08edPWtEolmXJp2B4/31wrrtx4vQn6pGa8uy5EUaGQtM3PWHMGe04zr1YmYBWYnNxNB1AHN+gKJWYBJaVYGILh35BerVGdApM0suKK8UZwL/K8b8LazvogvlYNtsrtyLdGklf6s5mbyBbWLvJZIkWczebqoi+vK8oBN7wFVxerjPKWX1xbWcuQK7rYDJzZ5F6XivHxq9qmRji0+ZwOx1c7j5c5mg0dWep6TGlpurdIzwL6fPH+eKjEwClgx48nN5Mv3VscVYCMMOklAtC/7Mxn0mD6yI3plJcJk0GPRtIvwxk09Vd4skBQTgdfG9ZRYbkZ1zcATV3VGpFGPZolRGNAqGW1TYyTVqNumxgKWSgyIOg2NCBJwHKeImYHD7mpyCQCzbtCulcW6qAa1iMH/eWi02pQT0q2v1v8l2ecPf59QCBnAnaYNSGv55Je6xdsOZ/sNwB0AXFRhkdSWYRHr84RqzAxZZojwxKRsYgcAOHcISO8mXSbepVsrPbuZLBVCEGy+UN8BFYXu93lD7mbSeo/kzl+WGl2TGI2aWma8iRlREH1xA1CwDzi5UYhdkqNWAVh+0fRWKVSnUS9FLvYAYOPbwO/PAu1HArcv9DB/57H5YpnR6d3L5IIP8P17kVupfEHLrTVnkBCYfNXrwIB7td7sw5yYz9aTGPEl1qkmlsNaEfiLpk7H4bvJ2eB5QZwsvv8iHDtXIRRC/OwafMf/gfsMj2HgFbepb0D+udnNaHF+AxJRhmLEYUTndLx6Yw9sPlqEH7afkgw1cszvymaWdCRvkxoj6QclEoNqiZvJwKn/NgtKzaiy2LH6YAGW7j2rOmb3Kbf1RQwA/qdQ+2ZPdEWFqmWGxAwRnkQqC3EBENw7bCZRdApw+X+BL8cC5YXad/Q8D3w7HvhnFdBmmHu5w+5bLIRcVGiJGYllpg7cTGqWGV+ymby5mUShVeCsA5Lzm8ZAeRVjecsEO6D3cprRM3EHrPiRiBnn5/uXMyj68ArP2xQ/F18sM6wIUbXM+BoMrSHKLJVAhLobRNOtJWZYHV6pLWZ4D5YWEYlQ9DDep99ekC9iQewFJMb4dGuWIAgZngeO/QEAmNvzH+gu0mitIv/cNn+A+OPrsTmtFU6N/xM6HYeb+mVhVNcMl5i5pmcmXruxByJLjwNi31q7Ba1SYrDkgYuQEGVEfqkZY9/fqNhdDFflMdamVRPBVZWTX4bOTy/z+fjLqm144Jsdri7taoiCR575BAAnzlegpYf4o2BAbiYiPFFzM4kCRwx6HP4k8OgRIGuQ8NpSph3LYrcKQgYAjq51LzeXKl1IasgtM5puJo1aLjV1M6lZZrREitylURcBwPILnIf+T5qwrhA1awy73FcriVq/KxH5NrTEjHgsknR6D/tUs8z8/l/gpabA8Q0a8/RS9dlngeuDmFGzOrnWhYll5vifrriVgFLKFLdLU6nbIwot+ed2fD0AwFR6XHBVOUmIMuLeoa1x38Vt8M6tvYU0ffa37vx/3DUzAc2Tol01ceTEyiwzejhwr34xFkQ8jyhUe3bbeeGXXWfw6Pe7AQDZbZoo6iWdr7Dgl11nXJV/2Wym2z7ajPqGxAwRnqjd7XccLTxWOgtfcTrhLt8U6xY/RUr/MgD1rCBAyLQJlGVG7mYq8Z5OqUA1m8lXy4wPbiZvKMSLTVZ4zoeLJCtmWOHIvlf8fNn9bXhTe5su8aNWylQ+Jy8xM74KKJ3K6XTDbOFx+ZPq75EXMlQO0N6fL58tay2SCO76j5mpEfOvAr69Q7uOkxrVJcChFcrfu6dYuLO73M9VBawoZny/AXlydBdpQUOJlVb6/zhVo3dZDFeNtiluoaOHHU8av8Yg3QHcrF+LSovdY5sLX2mWJDQplfPu6sMoq1b+7k4XV6labIIJiRkifJn8JxDvLPbVaijQcrB0PXuRjHMGAJ4/AlVsGtky1aU+ihlfY2ZYywx7sa4Gfrnf+34U+/XDzcTLrACerCbydVoXMvm+5Cd3n0QRc7VgLzCqlhnmgv/7s9qb9Ohmks3Zq5vJ15iZGlxEvNW18SQg2N+cOM5mBi4wmX6sZYatsaQIAA5Fy4wMVuyVF/j+vu8nAV+PA9a/7l62dR7wYjqw72f197CflSfRU5sikRKxLv1/rNNxWDX9Esy+qSceHdXRtTwrxoHJQ1u5XrMZUZGw4GhhOd6+tTc4Drh3aGvMvaOPxym0UqmcDAhZWH1aKDPUDuWXu4r3yalpx+66gmJmiPAloxvwyH5BFOj0yhYC7Mk3rqkQHJy3R31bjFlZQnWJbwHAVlktGrm4YddZKoHzh6UXa3OpcqwvF0c1y4wv2UyA53Rnny0zcjEjCwD25WQvyVpiTpSSz6dEEJa+XlDVxI9rfw7hd7D7O+Dif3sQMypuJk9oBTIDHhqUekvNVhEzRceAhCyZyHaOm3clcHobcNcyoGW29HuUZPLVwDJT3zEz7G/dW1A5i5hltuF/wLAZwvPFDwmPCycAXZVpyBJLq9rNjDi32hRWZD9zlfNF29RYt6tKKGuDdJMViHL/zponmgCn7uLB4a4hrXFZ53RseWIEkmMiIHbdiEY1/mP4Akscg7DB4c6w6tYsASeLKhW9mJJiIhQtOwa3bYKN/0jr17AUlpnRPEkjNiwIkJghwh/R5ZTaUbr83CH38zjtUuYAgA+Gqi83lwJmH9K5xZNR0VFg++eex31xPZD7F5DEBBVWq5xQ9RHS10XHgNwtQisH0aXhj2XGW9ViFl/FjHwcLwss9iZmKou0Lxys5erAr/7FSngUMzZgrrMSbHWJd8uMV1eQE0/ZTFoWFn8tM/sXAd/dCXS6Wv0ie3qb8LjzK6eYYX4fEsuMvM6ML26meo6ZYY+3JlYwX2LfRNjPzdP7alOKwKERH6YYx3zulnLJ9zC2V4arzs2tA1ui2cVCYVG2/cX3k7OR9+MMXF26BrdiDVpVf+1a171ZAh68rD2e/Hkvthwrci1PjpadeyAUHNQWM7xmzZ5gQW4mouGg0wOTfne/ZovnpdWw0V11qbrVRM6F40J9mk9Geo7lMJcLQgYALjBly9XEjPxk/nYv4Kf7gJ1MinRNY2YAz2LGkwvKUzNGh8x95UkUrX5R6Ke15BH3MquGZcZffHUzndkuvct3qAgXb0G6IrVNzXaoVU+Wvd74rvB4cLH0c1ZkJzFuJ5Fau5nqOWZG8nsN8FzY362qm0kjANgf1GLCVMex1rVKye8xMcL9ObRKiXV1Kmfp1yoZVzdz/796ZWx3Zl0S2qfH4bt/ZeO+i90V1sWKyc0S3fE5XTI1antBCEQurGc3E4kZomGR1R+4by0w4D5g6HT38ub9Nd/ikeoSoZkjIFQe1mL7Z0KhPbE2jRbittT2I8dmVr+AHF0rxIscWOxfnZmqC9LXNXEzWauA97KBH+5R35fDJrWoeDrZ5yxVLpO0jvCzN5NkHj5mMzkcUjHjLTXb0524J2sBuw9rFXBio/A5sdsrzwfe7AqsfIaZg+z799m94kXMhEMAsHx37G/DbhU+v29uA9a+4l5+dB1QIet8Hcdk5fjaid6bZUacW60sM9oBwJpzkdeHYs8nHsW0+8PskO6u0dU1013i4pb+WeiaGY8O6bHo10qIlxFbVLRsEo3+TB0cOQbY8fv+fDjqsQYNuZmIhkdmb+FPvkyk243A3u9929bh5cA/q93bYJsZ1gQtk7WWZcZhk9ZhAYC9P8J1chr5gvJtakJk6zzgyO/SZWIMhc6oFA5aIuTQMqDwgPA39mP1AGCHj24mNSHGxif522hSsm0L8M8aoFLFLM7OiXd4j5mRB05r4avQ+HmKUN13+JNC4LqI2LX8z/8xg+UXB619aFhm2IskGzMTFgHAsjmyvxe7FTi6BshZIvxd/G9g07vAyqeBrtcD4+a7x8akAGVnhOdVF4AYjXYnLOznVg8BwNK5yHqUsb9BXyqaA5Lvu2fzRNw6oAU6psdKOrm3SY3Fkgek7vapw9uiWVIUhrRrgqYJUfhwfF98tfkkdp8qBs9MXwcH1uQUYtGu07i+t0bfvABDYoZoHETEANd/KNz9xmW4xcz1HwDJbYFPRqi/TxQyQN2IGS2qNVxZtmqlmGFP8qe3K98jFyYn/3IHPLIUOsuWtxmmLMWvZbVhrTs8r2GZ8dHNpOa+08pm8pcDvwK7F6ivc8isL6yYUavF4nCor5e/9hQADAAHlwJx6YKQAYCN7ygz8OT4apnRck9puS92fCFUUU7v4hwe4kXzHA5lcDh7bLO7uNtK7PsJuOFjdywde2zWSgC+iBmNoHTFHD18bg6Herq+ax+ybEbNccz/A4dVZpkpVx93Zodw7hr8gOL8odNxHtsssBj0OtzY1y1ORnbNwMiuGSg328B/GAs47xXGD2iOxTnlGNlF2fAzWJCYIRoPPW8WHh0OIbUzb7fQkVt+58XphH5OYvVbkaRWNd93y4uAExqF0wANywyEE/axP4CmGv1nxEJ/LA47sOUjwSoxbIY0EJolb6/w2LSnipixqrsV2Hlaq5QXd96uXUtHjprLTe5KqClWZSl495xYy4xdKmYkdW5ULDOe4o48mfnPHQEW3Cpdxun8t3b4GpejFjPDcv4I8H428Kzz+wy0ZcZTFWRfcNiUlhm29IIoZEReagpc+QrQ727vmUlqsMKgpjEzdjOgUy9+p3ivR5evbB07H9Yywx7nh8OER0MkkD21zq1qsSYDYHJ//k9c0R6Pj0mCXuerG7TuoZgZovGh0wGDpwE3fChYbKIZX7DeBPznHHDVq8r3meKA/lp9crxw1xIgJlV7vZaY+XgEsOA24N0Bvr/PVg0s/TewdhZQeEj7RFnq7BWjJpQcNuD7u5TL2YaTlgoV95Q8m4mNCSkANs0RMpjsNvWU97oKAPaEPAaGjXVhLxSfXwvsWqAUPyys+PIUM2NREW46vfeYC4VlRuuUrWGZ8RSLwRLImJnT2wRxsewJP98oS/GXx1N5rGBtAZY+5nzOihkfyiwAsgBglfe4KgB7+Ny8CSdfA4Dlop4V6uwNgZp1Ryz+F+h4J95Rr0IGIDFDEILp/u4VQGw6MPwJ4SLTRKWDrSkOGP06cNdvQKKzOmbLi5Tj2mm4rLSaYwIyUcKcFMSMJ0+WBjllzF1qRaFnC4c+Qv1Y7Va3O0Rr29YK5Z1p6WmplYfd98KJwPIngJ8mq1/cAekFoDbxCJ7wFAMjdyn89C/PtWAkgkusPcILosjbBYTTe0+J9jUIWjObyUdB6MtnbasG1r4MnNrq2zZFVj0vPP41x7/3yStJy12QFi//J8TfNfsZWKuA9W943zcrLjy5gDzGhHl4n/y9WmLm6Dp3sL2IRUPM5O0VOspL9iH+vpjP8pf7gbf7+Fd4UA1PFst6gMQMQQBAi4HA9BzgooeE17HpyjGRztTEloOBh3YLJvqJi4Epm4BL/+Me12k08NBeockli0cxU+x+PrWWfU7YAoDH1wPLZmiPjU0HDCql07WsImIgJSBYi8S6JiLb5ktfsyfsE86CGIeXa2d1aRXNq0vk6dfsHBUuR70X8aPiFvv+LuD1DkDpGXhEp/cueHI3Cy5D13x8PWWLYsbbBdWPZprFJwRr38eX+TiHOkRumbFbvYuZwgPA+tlKy8yq57zvz1c3kycx6o+Y0bpZ+fxaoXwAC3vcrJvpyEpg3hXSCtCuIHbmd7b9c6GtS24tzzOSWLIA3Xj4AYkZghBhgys5DrjxU6AnE+cQoSJGOE4Iomw5xL0sMhFIzAKMMn+52vtFRMtMtxuVxf/8hb2Irp2lXG9iOo7HpCiL8wFK0zpvF+7oCpn4G/YiEa0RVKllWdASM8F2M8nbOsgtM6mdlJaZoqPA1zcLgdXsXb/DJrze95NQsfjgEs/z4HxwMwGCy1Dcj2bGFC8LbBbdTF4+Q/FiGMhMJX+q9bLIa/DIY2a8iRkAWPVfpWXGF7wFAFvKgVPbvLiZ/BEzfhT0Y5vYqhX0FAP72X2ofb++FAP1hK9ZfkGCxAxBaNFtLDCaMUnLxQkLG3cinkDk2S2eLDNiZo+nfbCkd5MGQLJ4swg0aet+HpOmLmbktToA4Y5OHmgpkthCfblWM0stMSMut1ZJT8p1iTxjyVPDTWuF7ILFC26yQ8uAT0cprQWFTEsNb9lNnM73i8CpLe73qMHzMuHoFDPeYkTE310g7qyrLghVqz1hqQDWvapsRSKfk8IyY/Ej/sVLAPDRtcKf5D3eLDMAPr7Us5jxVnGYPT6Lj8cCSK04av8fWWuNmptJbVxN8NqKI7iQmCEIT0TEABc9DPS/B0ho5mFcNNDhCiAiFmh9ibBs2EzhscctwqMnMSNidGZ89J3oeVx8JhCrkQbprft2EtMNNzZVJfUb7s7jvqJX7/KreZH0Jmbmjwb2LPRvDr4iDwD2FJdSXaIUHEVH3c/labNndrpfexNjtirfLSL7fxF6SWnWmZHNheeBHV8pCyXKEUsC+Hsx8qX43Bc3CFWr2fIGctbOAta8CLw3SKhuvGS6W1zK6xUp3Ew+XozZ71vt/8bn1wl/rKWHFUCiKPGpAzuDp6BeQBZkrGJl0nJBehM+bFybKyNPzTKj8X/QV0IsZoZSswnCGyOe9W3cLd8Id4smZ3O4nrcALQYBCU6rRWKW922Ilplr3gI6XgV8fZP6uJg0IP6COyPJH6KY7K2YVHXLjDfrjhy1uBvAg5vJeRGVx6SIFyh5LE5dInczeQqQri5RXrBYi5jE9WET4kpEtnzgeR7mMt8vAls+EP4SNCxg4GXHwWvX2ZHMoYaWGXMpEJWovZ7nlbEearDBxCueFB4zewO971BWkpZnM/ljzRBZ9V/tddUlws0LoOwvpvUb8WRZ85rNxP7u1TL7NI7Pm0WKjWsT56c2f09iZv8vwLkcYOi/fWuSSm4mgmhA6HRuISOS1MpdOCuti/dtsHfXGR4KWzVp4715pppIAYBINmZGy83kpS2DHC0xo3URKMsXHuWB1jW9W2zSXnjsPd77WMlFkamoqhbTxDuA7V9Il+kYS5b8AuvNEiKfh7e7dzla3d15XmYlsvmWjitaZvy9GHk7Tk/r2eaiaunsYgCr3IImEY4+ZDP5C/vbk8caWVQy99g5NuunXOdPALDdrBS2lUVQxdtxFzPWJ3Gbar+z6hJtwfXdeGD1C0JcmBbkZiKIRoovYoY96XgSK2ld1DOuRDL7AJP/VF/HCq64dHU3k79oWmY07gzXvCg8si4voOZi5u7lwPifgB43ex/L3gWz7gStooh7vpO+1jOWGbZJpsMmrcPjC2wWmy9oig5eCEoWsVncrRz6TNDenrmGbqZvbvV8odNK+y09IzQX/dhZvkDtrl9068jdTJLgcKt/5Qp8gS2PIE9pP7NDXZiLwkLt9+/NciQXR3KRUlVDMcM2sBV/L2rCausnQuXk8/9Ij1280RDHaKX3UwAwQTRS1Oq5sJYEYzQwlLk4chwwbStw+fPK96V19uwa6HUbkNoBuOIV4Np3petYS0y7y2uebcKiZWE4uxPY9B7whqxruehOkgsIc5ky4LLLGGkGlhoxTYC2lwJNe3ifK2umZ0/ycmGlBWuZuXDc/dzup2UGqH2tD3Y7Z3e6X1eXuCs/awVnA0Igc1WxdzFjiJS+LjwALH/Sw3zy1ZeLtYvydguPakHSNrPTYsZmM1m1s5m0qmP7C9tSRG6Z+WKMu7QAi2gFiVT5fR781bOrSe6ClY+tqWXm3BH3c9FVp2UlqioC3ukDvNxC6PlWcgp4o4N7/Z6FQtzTu/2BI7Jq4xLLTP2nZlPMDEEEC0OEUJzPUi6cjCNigNZDgT53CoGJ3cYq35PSXvjjdO6YAkCIndBKhwaEAGEAGDRZeFz8kPuE0+t24PgG4Y5drJ3DEhHrf6aD2BpBzl/veX5fotwyU6qsajzgXqFx4H8Tvc8jMgEY877QzFELrTveeA8B3ikd3OJA6y7UYfNfzPgbm6SFPI4il7GaeGrDsWeh0NqAjaNSIzIBKJddEE9vBSrOqzdu1BJprLXCZlF3M1mrVCpL25Q1iMRt+Vx7xwuslUwtpX3bZ8pl4jwjE5Xr9i8SAuPHfqRcBygFpNzSpNYkFfAeJ8duR/xdeHN5AUJ9JLXjEF2bX94APFPsvvmRd5+vZwJmmTl06BCuu+46pKSkID4+HhdddBHWrFkjGXPy5EmMHj0a0dHRSEtLw6OPPgqbTarw1q5diz59+sBkMqFdu3aYP39+oKZMEIGnxUCg3WVAxysEIQMAWQPUhQzL4GnApN+FBnr3rBLicLKnCs0Cx37iHtduBDBwCtDhSun7x/8MpHQEJiwW2jfc9i3Q6Sr1fbUfqW4N8kSn0f6NF5FfaEvPAjlLpcsiE/yzHqmdkH0h3oNbL70rYHIKP7YoGYvd6r/bqCYB3CyiGNBqVAoACV4Cz8/s8H5nrfWZ5v4F5CwD5gwCTm4GProU+HyMtmXGzAjVqiJ1y4ylXGnpc9ilQeEOm3sfWpl0/sI2PvU3YFYrGFruomRRuJmcwsNaBXw1DvjdQ7CyFjqZy1gUM95q3oh4+/1aKgQBW3RMFsBcy8yoOiBgYubqq6+GzWbD6tWrsW3bNvTs2RNXX3018vKEtDG73Y7Ro0fDYrFg48aN+OyzzzB//nw8/fTTrm0cO3YMo0ePxvDhw7Fz50489NBDuOeee7B8eYA6FxNEKJPVH+gxDmjuDDaMTgZuXwh0vxF4YIcgam5bCFz5srJbb+uhwLQtbgEl57FjwI3zgL53AVe9Bgx5AHj8BNCsrxBcO/IF6fjsaUDWIPfrQVOAtjWoDCsXMw6rssO3mgnfE/LxPW/z7X1sDFK7Ee6UegDI6AEkt3bPUQ2/AoCd4oy1zFz7jmAV8wfxIqrWgVzEl8/PW4o4u42RLwhlCADBAvPNzYLb6dORguA4ugYoPKi+nRImgLnyvLpVpfK8MoX6/D/uPkOAYE0SY0NGOoW3WBIBAFoMBppr9DPTgrUIqvW08vgZJ3rfPs8L9ZtEESAXM6LwyPkNOLwCKDnpfZss176jdCmKAsnfQHMtKs8Jbqi3e0ktnJ9fJxSJ1HKNBYGAiJlz587h8OHDmDFjBnr06IH27dvj5ZdfRmVlJfbuFczRK1aswP79+/Hll1+iV69euPLKK/H8889jzpw5sFgEE9/cuXPRunVrvPHGG+jcuTOmTZuGG2+8EW+++abH/ZvNZpSWlkr+CKJBk9xGEDVyEeMr0clAtxuAa/4nVAUGhAvlvauB+7cCg+8Hbv9eWD5sJjDqReDORe736wzA2I8Fd0W7y92WnVYa4knEl3R1v8UM4zrrMwG4jukJ5MlKwTYCveo1wWIm0iIbSG6rfA+LzazdMJQlvpngWgTcYqbjaGEZe0F2jW+uvS3xs/FkmfGlEOPx9Z7Xs99B28vcvxGtekT5Gm7HYuYCXVmkbhHK/RvIl3WsXy2zFB5a5n6eNUAQ4+OZXmKczv8u3eJnaK1iKi4z/59qYpkR4XnB2vJaW2DdK8IyufVHPEZfu8WzrsEb5wm/H3ncV+kp4J81dWc5KS/UtuItuE1bxAaBgIiZJk2aoGPHjvj8889RUVEBm82GDz74AGlpaejbty8AYNOmTejevTvS0913Q6NGjUJpaSn27dvnGjNihLRp36hRo7Bpk6yZloxZs2YhISHB9ZeV5cMJkyAIz7S/XLhoXPK48NoYKdylZ08TTqLRycAjB4DbvhMsOzNyhd5V177j3kavO4RAXUBoARGX6X2/Wm0gWl8sBKbKs3XYC2+3sVKB56kqLytmOL3UatSsj7Ryshps3Ep3pj5Q52vcz/vdLfTtSussfY84R6Ms0LbXHcDDe4Gh09X3KR6rmtWgSXvBrWj086KuxvnD7ufxTd19x3KWqY8XY6jkloLTTF2ZyvPqAbK2KmDFf6TLtApBpjoDy6OTpd8tx/lv5aouESxAb3RyW0XYmB42S0iOp4zAn6cCuVvcDViP/C48ymNmjv0huHHk1r3hT2nEyDGp92JBTrW4ry/GSC1vnE5wzdXEHVv0j+f18n50QSQgYobjOPz+++/YsWMH4uLiEBkZidmzZ2PZsmVISkoCAOTl5UmEDADXa9EVpTWmtLQUVVXaUeIzZ85ESUmJ6y8310tFVIIgfCM6WRq/Mvh+wUojYox0X5hFC4lohQCEIoLjfxKadN611DdLkjiG3Q4gxAXNyAWufVu63MRYZuSxNpVF6kGnnE4mZjigzXBgwL+Aq98UUm9TOkjfI9YBktfpiUoGLv63+7VYAwcQ7tB1OiBBZm0RLQBRSe5lmX2AMXOEuWil+YoXJDXLzPUfCG7F2FQhq62mpHVxW4zSuwlzFD8rVpywiK44T+UI9v2oniEEaLfNkHOlxnFxOqmIkweaq1FdAix+WBo34mtwMVtI8Zq3pOt2fgksZcRo0VHB8qNm4TjwK7DscemyztcAD+8BhjwoXc5acEThFqdRFZwlsSXw4C7BNa1GXCYw85T0/5GIGASvRUz9iRm/splmzJiBV17x/J/iwIED6NixI6ZOnYq0tDSsX78eUVFR+Pjjj3HNNdfg77//RtOmXop91RKTyQSTqY6CwgiCqD23fiu4MtjGnXL6TRJcXUmtgV1fA+CAVhe511/9ltCdPG+PUCJ/wL3qd8Rs2wh5Voq5VDhZi1VS/3NeuLhEJUotOpZKQXRc9ap7WeuLpdsa+wnw9yeCyJrLNBrN7O2uJAtIY3HE2kHyImuiwGJFDiuSut0AbH5fcaiuOVeoZA+lMCJq0GTlRdIT7S4XLAltLxPisirOCdsTrWC+XrRSO0ldQiz7F6kv90R8c3fQdGZvoM0w9XGcTvodNGkrrc6sRsEBoEDm3tLpAdXkNQ4SywgrkNUyw/L2uJ9XXQBeSFWOAYCf/iV93XKIu6RD9jTht/vjPcJrNg5GrB3lqfaUSHJrz8HuZWeE/0P3rALm9JeuO3dY/T0iNQ2+rwP8ssxMnz4dBw4c8PjXpk0brF69GosXL8aCBQswZMgQ9OnTB++99x6ioqLw2WdCeltGRgby86UR7+LrjIwMj2Pi4+MRFeVjQz6CIOqfjlcIFhy9h/unLtcJ4iWhGXDxo4J1owUTZKzTAbFpQjbYqBe1Tfusu0Ht7jI2zf1cbxDq8cSmCdaXLmOA5v2lQkAkLgNI6+rch1Gw1Fz1qtLKktFd6uKISgRu+VpwPQ2eJiyLbyptTSDWcWFjetjjyxogXFzkiEHJctK7q6fdA0KfsRs00oVFhj8B3PQ5cMOHwucZly5Y4cRtaomZzD7S12qWGX/cXnI3FfvdeXJpJLeRitP4TCDV6drTiuOSCxlAmh3E/paekFViZoPCm/XVnpcaV7ysvnzUS4L1Uvw/o9MLCQBq+/RmmelyHTDiv8Jvm7UcTfpdOXbwA8IjayUU8SZmahqzVwf4ZZlJTU1FaqqGomSorBRMojrZgel0Ojic+ejZ2dl48cUXUVBQgLQ04Qe6cuVKxMfHo0uXLq4xS5dK0zRXrlyJ7Oxsf6ZNEEQoM2WjcFfcRiX4taaMeV8wiTd33lk27w+c+lu4OHq6e71JpZYIy9iPhPYGrS92u7DkokpsOCpijBZS1+Xp612uBTa9CxhjgP6ThGXsxVu+3eb9gKteFzJ5Ns8Vll3yuGBFkveBum+tcu63fy9kyYx8QXCL/HivsNyUIE2ZFvfd5TrVjwCAdhzTsJnA18wFN62TcsxlTwPLZmhvW8QQBUxcKvQI+tJZuoCNG1ETVHcuAnZ9K+zjwC/u5fHNgbtfFH4TuVu8BzyLxKa6P5tWQ4GcJcJz1uoDSGN/4jOF2LHZnb1vP7MPMOA+4PBK4B+ZWFUTE1qI1kitquE3fS48XvSQdHlWf6EUw+EVwuu7fnMXIVQLama7wocYASmal52djaSkJEyYMAFPP/00oqKi8NFHH7lSrQFg5MiR6NKlC8aPH49XX30VeXl5eOqppzB16lSXi2jy5Ml499138dhjj+Huu+/G6tWr8d1332HJkiWBmDZBEPVBelfhry7pJUvHvukL4M+3BKuE3Sy4UAbc5/9207sKqe8sbHXc8T8DLWU3W1oXmJEvCG63hGbuCxdrmVG7wx/gFCBdrhMsD8YoYTtyMaNmAWt/ufAncuciIeC0w5VCnMiZ7W7R4K3uTEY3QRQ2aScImF/uB8ALIm/kC8CKp4Rx8c2B9qOEyrJZ/QUrltpxdRwtCIW0LkDBfmFZelch2y0xS4hbOrFJcCuJgbRqRSPbDHO7nthYpfhM4eKcNUDa9dwbbJBuZm+3mAGE710sRscGf3Ocu2ilnGveApY+KgTqTlziDlyWiyNA6i5lGTQV+GuOYL384zVhWYQHN5O3IHu2h1fLwe7nddHmJIgERMykpKRg2bJlePLJJ3HppZfCarWia9euWLRoEXr2FFSfXq/H4sWLMWXKFGRnZyMmJgYTJkzAc88959pO69atsWTJEjz88MN466230Lx5c3z88ccYNWpUIKZNEERDJb6pVITMPO1byrIv6PTAv9YD4KWl9a9+U0hFbt5P/X0cJ4gClth0wTpTli/EEGnBXnQMEVIR4CtsvEl0srROkFaTUpGIGODB3cI4nQ64f7uQMaM3SC/MkQnA7d8JF0zRklWhUtn2ipeETtktBgm9mwCgFROH1O9u4e8w4xbxNke2fQgrfLqNFTKKWg4RgmjXvOBOqW81FOgwShBj138gZFGtfkGw7A2+X7BMtHdef5r1A05sEJ6rFaXrdLVQeyW+mTvOp/d4IZg6IkbqMlOrz6IlKEe9KLhgK8+7xYzYGyouQzjWyiJg9OvA2d1Ccc2aEpPqf9PZeiJg7Qz69evntbhdy5YtFW4kOcOGDcOOHRpR1z7CO5Un1ZshCMJFdR1WLY1pJTyy55gONwqPZX7u56ZFzniIGOn2PHHDN8DaWcCub4QLZk3Pddd9JlQ4jsrycRsqZf/5GMDsvNuvUMnC4g2AWQdXZG1cJoB4IPMiwAYguadgPel8u3IOKX3c245r73mOfIR7rKGJdOzls93PO94EbP0Y2P09cOmrgvDNGiFYzOxWIKaNIEirLMDI/wnvKS0FRrwufOb9JwEHFrv3Je5n1DvA8JcEYbHgNqDbjUB5hTAXB6TzscD9fkDIOEob6OH4DEBEOjDkKSAmTfobu3UpAF6Yf8ebpHNSo8VIYN8KwWomHzfiDaGDdr9JQtNJkayBQgXmmHQhg/HYOiFwPwDXWPG6zXvpAs/x3kY0AE6dOkW1ZgiCIAgiTMnNzUXz5toFJBuFmHE4HDhz5gzi4uLA1UWHYCelpaXIyspCbm4u4uM1MgcaMI35+BvzsQON+/jp2BvnsQON+/jr69h5nkdZWRkyMzMVSUUsjaJrtk6n86joakt8fHyj+2GzNObjb8zHDjTu46djb5zHDjTu46+PY09I8N7SpP6SwgmCIAiCIOoAEjMEQRAEQYQ1JGZqgclkwjPPPNNoWyc05uNvzMcONO7jp2NvnMcONO7jD/VjbxQBwARBEARBNFzIMkMQBEEQRFhDYoYgCIIgiLCGxAxBEARBEGENiRmCIAiCIMIaEjMEQRAEQYQ1JGZqwZw5c9CqVStERkZi4MCB2LJlS31Pqdb88ccfuOaaa5CZmQmO4/Dzzz9L1vM8j6effhpNmzZFVFQURowYgcOHD0vGFBUV4fbbb0d8fDwSExMxadIklJeXB/EoasasWbPQv39/xMXFIS0tDWPGjEFOTo5kTHV1NaZOnYomTZogNjYWY8eORX5+vmTMyZMnMXr0aERHRyMtLQ2PPvoobDaNDrghwvvvv48ePXq4qntmZ2fjt99+c61vqMetxcsvvwyO4/DQQw+5ljXUz+DZZ58Fx3GSv06dOrnWN9TjZjl9+jTuuOMONGnSBFFRUejevTu2bt3qWt9Qz3utWrVSfPccx2HqVKHTdlh99zxRIxYsWMBHRETwn376Kb9v3z7+3nvv5RMTE/n8/Pz6nlqtWLp0Kf/kk0/yP/74Iw+A/+mnnyTrX375ZT4hIYH/+eef+V27dvHXXnst37p1a76qqso15oorruB79uzJ//XXX/z69ev5du3a8bfeemuQj8R/Ro0axc+bN4/fu3cvv3PnTv6qq67iW7RowZeXl7vGTJ48mc/KyuJXrVrFb926lR80aBA/ePBg13qbzcZ369aNHzFiBL9jxw5+6dKlfEpKCj9z5sz6OCSf+eWXX/glS5bwhw4d4nNycvgnnniCNxqN/N69e3meb7jHrcaWLVv4Vq1a8T169OAffPBB1/KG+hk888wzfNeuXfmzZ8+6/goLC13rG+pxixQVFfEtW7bkJ06cyG/evJk/evQov3z5cv7IkSOuMQ31vFdQUCD53leuXMkD4NesWcPzfHh99yRmasiAAQP4qVOnul7b7XY+MzOTnzVrVj3Oqm6RixmHw8FnZGTwr732mmtZcXExbzKZ+G+++YbneZ7fv38/D4D/+++/XWN+++03nuM4/vTp00Gbe11QUFDAA+DXrVvH87xwrEajkV+4cKFrzIEDB3gA/KZNm3ieF8SgTqfj8/LyXGPef/99Pj4+njebzcE9gFqSlJTEf/zxx43quMvKyvj27dvzK1eu5C+55BKXmGnIn8EzzzzD9+zZU3VdQz5ukccff5y/6KKLNNc3pvPegw8+yLdt25Z3OBxh992Tm6kGWCwWbNu2DSNGjHAt0+l0GDFiBDZt2lSPMwssx44dQ15enuS4ExISMHDgQNdxb9q0CYmJiejXr59rzIgRI6DT6bB58+agz7k2lJSUAACSk5MBANu2bYPVapUcf6dOndCiRQvJ8Xfv3h3p6emuMaNGjUJpaSn27dsXxNnXHLvdjgULFqCiogLZ2dmN5rgBYOrUqRg9erTkWIGG/90fPnwYmZmZaNOmDW6//XacPHkSQMM/bgD45Zdf0K9fP4wbNw5paWno3bs3PvroI9f6xnLes1gs+PLLL3H33XeD47iw++5JzNSAc+fOwW63S75AAEhPT0deXl49zSrwiMfm6bjz8vKQlpYmWW8wGJCcnBxWn43D4cBDDz2EIUOGoFu3bgCEY4uIiEBiYqJkrPz41T4fcV0os2fPHsTGxsJkMmHy5Mn46aef0KVLlwZ/3CILFizA9u3bMWvWLMW6hvwZDBw4EPPnz8eyZcvw/vvv49ixYxg6dCjKysoa9HGLHD16FO+//z7at2+P5cuXY8qUKXjggQfw2WefAWg8572ff/4ZxcXFmDhxIoDw+80bgro3gggTpk6dir1792LDhg31PZWg0bFjR+zcuRMlJSX4/vvvMWHCBKxbt66+pxUUcnNz8eCDD2LlypWIjIys7+kElSuvvNL1vEePHhg4cCBatmyJ7777DlFRUfU4s+DgcDjQr18/vPTSSwCA3r17Y+/evZg7dy4mTJhQz7MLHp988gmuvPJKZGZm1vdUagRZZmpASkoK9Hq9Iqo7Pz8fGRkZ9TSrwCMem6fjzsjIQEFBgWS9zWZDUVFR2Hw206ZNw+LFi7FmzRo0b97ctTwjIwMWiwXFxcWS8fLjV/t8xHWhTEREBNq1a4e+ffti1qxZ6NmzJ956660Gf9yA4E4pKChAnz59YDAYYDAYsG7dOrz99tswGAxIT09v8J+BSGJiIjp06IAjR440iu++adOm6NKli2RZ586dXa62xnDeO3HiBH7//Xfcc889rmXh9t2TmKkBERER6Nu3L1atWuVa5nA4sGrVKmRnZ9fjzAJL69atkZGRITnu0tJSbN682XXc2dnZKC4uxrZt21xjVq9eDYfDgYEDBwZ9zv7A8zymTZuGn376CatXr0br1q0l6/v27Quj0Sg5/pycHJw8eVJy/Hv27JGc2FauXIn4+HjFCTPUcTgcMJvNjeK4L7vsMuzZswc7d+50/fXr1w+3336763lD/wxEysvL8c8//6Bp06aN4rsfMmSIogTDoUOH0LJlSwAN/7wHAPPmzUNaWhpGjx7tWhZ2331Qw40bEAsWLOBNJhM/f/58fv/+/fx9993HJyYmSqK6w5GysjJ+x44d/I4dO3gA/OzZs/kdO3bwJ06c4HleSFFMTEzkFy1axO/evZu/7rrrVFMUe/fuzW/evJnfsGED3759+5BPUeR5np8yZQqfkJDAr127VpKuWFlZ6RozefJkvkWLFvzq1av5rVu38tnZ2Xx2drZrvZiqOHLkSH7nzp38smXL+NTU1JBPU50xYwa/bt06/tixY/zu3bv5GTNm8BzH8StWrOB5vuEetyfYbCaeb7ifwfTp0/m1a9fyx44d4//8809+xIgRfEpKCl9QUMDzfMM9bpEtW7bwBoOBf/HFF/nDhw/zX331FR8dHc1/+eWXrjEN+bxnt9v5Fi1a8I8//rhiXTh99yRmasE777zDt2jRgo+IiOAHDBjA//XXX/U9pVqzZs0aHoDib8KECTzPC2mK//nPf/j09HTeZDLxl112GZ+TkyPZxvnz5/lbb72Vj42N5ePj4/m77rqLLysrq4ej8Q+14wbAz5s3zzWmqqqK/7//+z8+KSmJj46O5q+//nr+7Nmzku0cP36cv/LKK/moqCg+JSWFnz59Om+1WoN8NP5x99138y1btuQjIiL41NRU/rLLLnMJGZ5vuMftCbmYaaifwc0338w3bdqUj4iI4Js1a8bffPPNkhorDfW4WX799Ve+W7duvMlk4jt16sR/+OGHkvUN+by3fPlyHoDieHg+vL57jud5Pri2IIIgCIIgiLqDYmYIgiAIgghrSMwQBEEQBBHWkJghCIIgCCKsITFDEARBEERYQ2KGIAiCIIiwhsQMQRAEQRBhDYkZgiAIgiDCGhIzBEEQBEGENSRmCIIgCIIIa0jMEARBEAQR1pCYIQiCIAgirPl/R9JHodH/RhQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.70565  validloss 10.60127±0.00000  bestvalidloss 10.60127  last_update 0\n",
      "train: iter 1  trainloss 8.82994  validloss 9.58359±0.00000  bestvalidloss 9.58359  last_update 0\n",
      "train: iter 2  trainloss 8.08212  validloss 8.72706±0.00000  bestvalidloss 8.72706  last_update 0\n",
      "train: iter 3  trainloss 7.41583  validloss 8.02485±0.00000  bestvalidloss 8.02485  last_update 0\n",
      "train: iter 4  trainloss 6.87468  validloss 7.40213±0.00000  bestvalidloss 7.40213  last_update 0\n",
      "train: iter 5  trainloss 6.38674  validloss 6.90206±0.00000  bestvalidloss 6.90206  last_update 0\n",
      "train: iter 6  trainloss 5.96338  validloss 6.40324±0.00000  bestvalidloss 6.40324  last_update 0\n",
      "train: iter 7  trainloss 5.59235  validloss 5.98195±0.00000  bestvalidloss 5.98195  last_update 0\n",
      "train: iter 8  trainloss 5.26709  validloss 5.62230±0.00000  bestvalidloss 5.62230  last_update 0\n",
      "train: iter 9  trainloss 4.97106  validloss 5.29572±0.00000  bestvalidloss 5.29572  last_update 0\n",
      "train: iter 10  trainloss 4.72058  validloss 5.01946±0.00000  bestvalidloss 5.01946  last_update 0\n",
      "train: iter 11  trainloss 4.48367  validloss 4.77188±0.00000  bestvalidloss 4.77188  last_update 0\n",
      "train: iter 12  trainloss 4.28162  validloss 4.53718±0.00000  bestvalidloss 4.53718  last_update 0\n",
      "train: iter 13  trainloss 4.09235  validloss 4.33484±0.00000  bestvalidloss 4.33484  last_update 0\n",
      "train: iter 14  trainloss 3.93264  validloss 4.14494±0.00000  bestvalidloss 4.14494  last_update 0\n",
      "train: iter 15  trainloss 3.78332  validloss 3.98441±0.00000  bestvalidloss 3.98441  last_update 0\n",
      "train: iter 16  trainloss 3.63900  validloss 3.82160±0.00000  bestvalidloss 3.82160  last_update 0\n",
      "train: iter 17  trainloss 3.51422  validloss 3.68919±0.00000  bestvalidloss 3.68919  last_update 0\n",
      "train: iter 18  trainloss 3.40853  validloss 3.58237±0.00000  bestvalidloss 3.58237  last_update 0\n",
      "train: iter 19  trainloss 3.29795  validloss 3.46499±0.00000  bestvalidloss 3.46499  last_update 0\n",
      "train: iter 20  trainloss 3.20315  validloss 3.34943±0.00000  bestvalidloss 3.34943  last_update 0\n",
      "train: iter 21  trainloss 3.12002  validloss 3.24907±0.00000  bestvalidloss 3.24907  last_update 0\n",
      "train: iter 22  trainloss 3.03789  validloss 3.17343±0.00000  bestvalidloss 3.17343  last_update 0\n",
      "train: iter 23  trainloss 2.96039  validloss 3.08792±0.00000  bestvalidloss 3.08792  last_update 0\n",
      "train: iter 24  trainloss 2.89735  validloss 3.01702±0.00000  bestvalidloss 3.01702  last_update 0\n",
      "train: iter 25  trainloss 2.83205  validloss 2.94970±0.00000  bestvalidloss 2.94970  last_update 0\n",
      "train: iter 26  trainloss 2.77628  validloss 2.87865±0.00000  bestvalidloss 2.87865  last_update 0\n",
      "train: iter 27  trainloss 2.71641  validloss 2.83124±0.00000  bestvalidloss 2.83124  last_update 0\n",
      "train: iter 28  trainloss 2.67435  validloss 2.77178±0.00000  bestvalidloss 2.77178  last_update 0\n",
      "train: iter 29  trainloss 2.62652  validloss 2.71665±0.00000  bestvalidloss 2.71665  last_update 0\n",
      "train: iter 30  trainloss 2.57804  validloss 2.66931±0.00000  bestvalidloss 2.66931  last_update 0\n",
      "train: iter 31  trainloss 2.53961  validloss 2.62207±0.00000  bestvalidloss 2.62207  last_update 0\n",
      "train: iter 32  trainloss 2.50312  validloss 2.58543±0.00000  bestvalidloss 2.58543  last_update 0\n",
      "train: iter 33  trainloss 2.46783  validloss 2.53845±0.00000  bestvalidloss 2.53845  last_update 0\n",
      "train: iter 34  trainloss 2.43229  validloss 2.50820±0.00000  bestvalidloss 2.50820  last_update 0\n",
      "train: iter 35  trainloss 2.40045  validloss 2.47337±0.00000  bestvalidloss 2.47337  last_update 0\n",
      "train: iter 36  trainloss 2.37239  validloss 2.44167±0.00000  bestvalidloss 2.44167  last_update 0\n",
      "train: iter 37  trainloss 2.34133  validloss 2.40962±0.00000  bestvalidloss 2.40962  last_update 0\n",
      "train: iter 38  trainloss 2.31495  validloss 2.37488±0.00000  bestvalidloss 2.37488  last_update 0\n",
      "train: iter 39  trainloss 2.28857  validloss 2.34912±0.00000  bestvalidloss 2.34912  last_update 0\n",
      "train: iter 40  trainloss 2.26380  validloss 2.32146±0.00000  bestvalidloss 2.32146  last_update 0\n",
      "train: iter 41  trainloss 2.23984  validloss 2.29257±0.00000  bestvalidloss 2.29257  last_update 0\n",
      "train: iter 42  trainloss 2.21544  validloss 2.26939±0.00000  bestvalidloss 2.26939  last_update 0\n",
      "train: iter 43  trainloss 2.19371  validloss 2.24578±0.00000  bestvalidloss 2.24578  last_update 0\n",
      "train: iter 44  trainloss 2.17276  validloss 2.22631±0.00000  bestvalidloss 2.22631  last_update 0\n",
      "train: iter 45  trainloss 2.15048  validloss 2.19936±0.00000  bestvalidloss 2.19936  last_update 0\n",
      "train: iter 46  trainloss 2.12949  validloss 2.17950±0.00000  bestvalidloss 2.17950  last_update 0\n",
      "train: iter 47  trainloss 2.10969  validloss 2.15713±0.00000  bestvalidloss 2.15713  last_update 0\n",
      "train: iter 48  trainloss 2.08794  validloss 2.13602±0.00000  bestvalidloss 2.13602  last_update 0\n",
      "train: iter 49  trainloss 2.06972  validloss 2.11753±0.00000  bestvalidloss 2.11753  last_update 0\n",
      "train: iter 50  trainloss 2.05130  validloss 2.09215±0.00000  bestvalidloss 2.09215  last_update 0\n",
      "train: iter 51  trainloss 2.02924  validloss 2.07467±0.00000  bestvalidloss 2.07467  last_update 0\n",
      "train: iter 52  trainloss 2.00826  validloss 2.05106±0.00000  bestvalidloss 2.05106  last_update 0\n",
      "train: iter 53  trainloss 1.98806  validloss 2.03040±0.00000  bestvalidloss 2.03040  last_update 0\n",
      "train: iter 54  trainloss 1.96974  validloss 2.00953±0.00000  bestvalidloss 2.00953  last_update 0\n",
      "train: iter 55  trainloss 1.94787  validloss 1.99077±0.00000  bestvalidloss 1.99077  last_update 0\n",
      "train: iter 56  trainloss 1.92608  validloss 1.96293±0.00000  bestvalidloss 1.96293  last_update 0\n",
      "train: iter 57  trainloss 1.90432  validloss 1.94030±0.00000  bestvalidloss 1.94030  last_update 0\n",
      "train: iter 58  trainloss 1.88225  validloss 1.91903±0.00000  bestvalidloss 1.91903  last_update 0\n",
      "train: iter 59  trainloss 1.85847  validloss 1.89447±0.00000  bestvalidloss 1.89447  last_update 0\n",
      "train: iter 60  trainloss 1.83609  validloss 1.87310±0.00000  bestvalidloss 1.87310  last_update 0\n",
      "train: iter 61  trainloss 1.80921  validloss 1.84679±0.00000  bestvalidloss 1.84679  last_update 0\n",
      "train: iter 62  trainloss 1.78518  validloss 1.82333±0.00000  bestvalidloss 1.82333  last_update 0\n",
      "train: iter 63  trainloss 1.76173  validloss 1.79593±0.00000  bestvalidloss 1.79593  last_update 0\n",
      "train: iter 64  trainloss 1.73338  validloss 1.76740±0.00000  bestvalidloss 1.76740  last_update 0\n",
      "train: iter 65  trainloss 1.70450  validloss 1.73883±0.00000  bestvalidloss 1.73883  last_update 0\n",
      "train: iter 66  trainloss 1.67572  validloss 1.71030±0.00000  bestvalidloss 1.71030  last_update 0\n",
      "train: iter 67  trainloss 1.64617  validloss 1.67933±0.00000  bestvalidloss 1.67933  last_update 0\n",
      "train: iter 68  trainloss 1.61353  validloss 1.64768±0.00000  bestvalidloss 1.64768  last_update 0\n",
      "train: iter 69  trainloss 1.58300  validloss 1.61577±0.00000  bestvalidloss 1.61577  last_update 0\n",
      "train: iter 70  trainloss 1.54895  validloss 1.58152±0.00000  bestvalidloss 1.58152  last_update 0\n",
      "train: iter 71  trainloss 1.51589  validloss 1.54082±0.00000  bestvalidloss 1.54082  last_update 0\n",
      "train: iter 72  trainloss 1.48157  validloss 1.50634±0.00000  bestvalidloss 1.50634  last_update 0\n",
      "train: iter 73  trainloss 1.44445  validloss 1.47191±0.00000  bestvalidloss 1.47191  last_update 0\n",
      "train: iter 74  trainloss 1.40911  validloss 1.42984±0.00000  bestvalidloss 1.42984  last_update 0\n",
      "train: iter 75  trainloss 1.37133  validloss 1.39287±0.00000  bestvalidloss 1.39287  last_update 0\n",
      "train: iter 76  trainloss 1.33481  validloss 1.35166±0.00000  bestvalidloss 1.35166  last_update 0\n",
      "train: iter 77  trainloss 1.29522  validloss 1.31569±0.00000  bestvalidloss 1.31569  last_update 0\n",
      "train: iter 78  trainloss 1.25705  validloss 1.27444±0.00000  bestvalidloss 1.27444  last_update 0\n",
      "train: iter 79  trainloss 1.22010  validloss 1.22554±0.00000  bestvalidloss 1.22554  last_update 0\n",
      "train: iter 80  trainloss 1.18447  validloss 1.18731±0.00000  bestvalidloss 1.18731  last_update 0\n",
      "train: iter 81  trainloss 1.14708  validloss 1.14334±0.00000  bestvalidloss 1.14334  last_update 0\n",
      "train: iter 82  trainloss 1.11499  validloss 1.10818±0.00000  bestvalidloss 1.10818  last_update 0\n",
      "train: iter 83  trainloss 1.07936  validloss 1.07213±0.00000  bestvalidloss 1.07213  last_update 0\n",
      "train: iter 84  trainloss 1.04797  validloss 1.03746±0.00000  bestvalidloss 1.03746  last_update 0\n",
      "train: iter 85  trainloss 1.01973  validloss 0.99560±0.00000  bestvalidloss 0.99560  last_update 0\n",
      "train: iter 86  trainloss 0.99064  validloss 0.95302±0.00000  bestvalidloss 0.95302  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 87  trainloss 0.96357  validloss 0.92224±0.00000  bestvalidloss 0.92224  last_update 0\n",
      "train: iter 88  trainloss 0.94044  validloss 0.89449±0.00000  bestvalidloss 0.89449  last_update 0\n",
      "train: iter 89  trainloss 0.91855  validloss 0.86001±0.00000  bestvalidloss 0.86001  last_update 0\n",
      "train: iter 90  trainloss 0.89228  validloss 0.82906±0.00000  bestvalidloss 0.82906  last_update 0\n",
      "train: iter 91  trainloss 0.87701  validloss 0.80870±0.00000  bestvalidloss 0.80870  last_update 0\n",
      "train: iter 92  trainloss 0.86034  validloss 0.77818±0.00000  bestvalidloss 0.77818  last_update 0\n",
      "train: iter 93  trainloss 0.84343  validloss 0.77028±0.00000  bestvalidloss 0.77028  last_update 0\n",
      "train: iter 94  trainloss 0.82154  validloss 0.73850±0.00000  bestvalidloss 0.73850  last_update 0\n",
      "train: iter 95  trainloss 0.81508  validloss 0.71886±0.00000  bestvalidloss 0.71886  last_update 0\n",
      "train: iter 96  trainloss 0.78888  validloss 0.70021±0.00000  bestvalidloss 0.70021  last_update 0\n",
      "train: iter 97  trainloss 0.79196  validloss 0.68327±0.00000  bestvalidloss 0.68327  last_update 0\n",
      "train: iter 98  trainloss 0.78611  validloss 0.65902±0.00000  bestvalidloss 0.65902  last_update 0\n",
      "train: iter 99  trainloss 0.76586  validloss 0.65080±0.00000  bestvalidloss 0.65080  last_update 0\n",
      "train: iter 100  trainloss 0.77462  validloss 0.63346±0.00000  bestvalidloss 0.63346  last_update 0\n",
      "train: iter 101  trainloss 0.77105  validloss 0.62807±0.00000  bestvalidloss 0.62807  last_update 0\n",
      "train: iter 102  trainloss 0.74671  validloss 0.62333±0.00000  bestvalidloss 0.62333  last_update 0\n",
      "train: iter 103  trainloss 0.75214  validloss 0.60469±0.00000  bestvalidloss 0.60469  last_update 0\n",
      "train: iter 104  trainloss 0.74452  validloss 0.59374±0.00000  bestvalidloss 0.59374  last_update 0\n",
      "train: iter 105  trainloss 0.74385  validloss 0.59357±0.00000  bestvalidloss 0.59357  last_update 0\n",
      "train: iter 106  trainloss 0.73254  validloss 0.58583±0.00000  bestvalidloss 0.58583  last_update 0\n",
      "train: iter 107  trainloss 0.73504  validloss 0.58678±0.00000  bestvalidloss 0.58583  last_update 1\n",
      "train: iter 108  trainloss 0.72376  validloss 0.57305±0.00000  bestvalidloss 0.57305  last_update 0\n",
      "train: iter 109  trainloss 0.71998  validloss 0.57561±0.00000  bestvalidloss 0.57305  last_update 1\n",
      "train: iter 110  trainloss 0.72344  validloss 0.54005±0.00000  bestvalidloss 0.54005  last_update 0\n",
      "train: iter 111  trainloss 0.71669  validloss 0.54867±0.00000  bestvalidloss 0.54005  last_update 1\n",
      "train: iter 112  trainloss 0.72465  validloss 0.54705±0.00000  bestvalidloss 0.54005  last_update 2\n",
      "train: iter 113  trainloss 0.70603  validloss 0.53778±0.00000  bestvalidloss 0.53778  last_update 0\n",
      "train: iter 114  trainloss 0.71315  validloss 0.53863±0.00000  bestvalidloss 0.53778  last_update 1\n",
      "train: iter 115  trainloss 0.71545  validloss 0.55265±0.00000  bestvalidloss 0.53778  last_update 2\n",
      "train: iter 116  trainloss 0.69700  validloss 0.55745±0.00000  bestvalidloss 0.53778  last_update 3\n",
      "train: iter 117  trainloss 0.70863  validloss 0.54346±0.00000  bestvalidloss 0.53778  last_update 4\n",
      "train: iter 118  trainloss 0.69340  validloss 0.51017±0.00000  bestvalidloss 0.51017  last_update 0\n",
      "train: iter 119  trainloss 0.70831  validloss 0.52046±0.00000  bestvalidloss 0.51017  last_update 1\n",
      "train: iter 120  trainloss 0.68723  validloss 0.53118±0.00000  bestvalidloss 0.51017  last_update 2\n",
      "train: iter 121  trainloss 0.71193  validloss 0.51566±0.00000  bestvalidloss 0.51017  last_update 3\n",
      "train: iter 122  trainloss 0.69835  validloss 0.50873±0.00000  bestvalidloss 0.50873  last_update 0\n",
      "train: iter 123  trainloss 0.69924  validloss 0.49739±0.00000  bestvalidloss 0.49739  last_update 0\n",
      "train: iter 124  trainloss 0.69694  validloss 0.48748±0.00000  bestvalidloss 0.48748  last_update 0\n",
      "train: iter 125  trainloss 0.69652  validloss 0.49534±0.00000  bestvalidloss 0.48748  last_update 1\n",
      "train: iter 126  trainloss 0.68865  validloss 0.50224±0.00000  bestvalidloss 0.48748  last_update 2\n",
      "train: iter 127  trainloss 0.70673  validloss 0.50693±0.00000  bestvalidloss 0.48748  last_update 3\n",
      "train: iter 128  trainloss 0.70123  validloss 0.49712±0.00000  bestvalidloss 0.48748  last_update 4\n",
      "train: iter 129  trainloss 0.69587  validloss 0.48850±0.00000  bestvalidloss 0.48748  last_update 5\n",
      "train: iter 130  trainloss 0.69393  validloss 0.48853±0.00000  bestvalidloss 0.48748  last_update 6\n",
      "train: iter 131  trainloss 0.68921  validloss 0.49217±0.00000  bestvalidloss 0.48748  last_update 7\n",
      "train: iter 132  trainloss 0.69857  validloss 0.48909±0.00000  bestvalidloss 0.48748  last_update 8\n",
      "train: iter 133  trainloss 0.68632  validloss 0.49464±0.00000  bestvalidloss 0.48748  last_update 9\n",
      "train: iter 134  trainloss 0.68715  validloss 0.49716±0.00000  bestvalidloss 0.48748  last_update 10\n",
      "train: iter 135  trainloss 0.69346  validloss 0.48327±0.00000  bestvalidloss 0.48327  last_update 0\n",
      "train: iter 136  trainloss 0.70548  validloss 0.45750±0.00000  bestvalidloss 0.45750  last_update 0\n",
      "train: iter 137  trainloss 0.67537  validloss 0.47342±0.00000  bestvalidloss 0.45750  last_update 1\n",
      "train: iter 138  trainloss 0.69888  validloss 0.49965±0.00000  bestvalidloss 0.45750  last_update 2\n",
      "train: iter 139  trainloss 0.68901  validloss 0.45959±0.00000  bestvalidloss 0.45750  last_update 3\n",
      "train: iter 140  trainloss 0.69253  validloss 0.45790±0.00000  bestvalidloss 0.45750  last_update 4\n",
      "train: iter 141  trainloss 0.69393  validloss 0.47698±0.00000  bestvalidloss 0.45750  last_update 5\n",
      "train: iter 142  trainloss 0.68547  validloss 0.45833±0.00000  bestvalidloss 0.45750  last_update 6\n",
      "train: iter 143  trainloss 0.68156  validloss 0.46956±0.00000  bestvalidloss 0.45750  last_update 7\n",
      "train: iter 144  trainloss 0.68182  validloss 0.46531±0.00000  bestvalidloss 0.45750  last_update 8\n",
      "train: iter 145  trainloss 0.67048  validloss 0.45173±0.00000  bestvalidloss 0.45173  last_update 0\n",
      "train: iter 146  trainloss 0.69207  validloss 0.49487±0.00000  bestvalidloss 0.45173  last_update 1\n",
      "train: iter 147  trainloss 0.68769  validloss 0.48661±0.00000  bestvalidloss 0.45173  last_update 2\n",
      "train: iter 148  trainloss 0.70393  validloss 0.46431±0.00000  bestvalidloss 0.45173  last_update 3\n",
      "train: iter 149  trainloss 0.70276  validloss 0.46884±0.00000  bestvalidloss 0.45173  last_update 4\n",
      "train: iter 150  trainloss 0.68974  validloss 0.47351±0.00000  bestvalidloss 0.45173  last_update 5\n",
      "train: iter 151  trainloss 0.68750  validloss 0.47919±0.00000  bestvalidloss 0.45173  last_update 6\n",
      "train: iter 152  trainloss 0.69142  validloss 0.47201±0.00000  bestvalidloss 0.45173  last_update 7\n",
      "train: iter 153  trainloss 0.69185  validloss 0.48708±0.00000  bestvalidloss 0.45173  last_update 8\n",
      "train: iter 154  trainloss 0.67418  validloss 0.46624±0.00000  bestvalidloss 0.45173  last_update 9\n",
      "train: iter 155  trainloss 0.69360  validloss 0.48067±0.00000  bestvalidloss 0.45173  last_update 10\n",
      "train: iter 156  trainloss 0.69057  validloss 0.47049±0.00000  bestvalidloss 0.45173  last_update 11\n",
      "train: iter 157  trainloss 0.68283  validloss 0.48487±0.00000  bestvalidloss 0.45173  last_update 12\n",
      "train: iter 158  trainloss 0.68254  validloss 0.46285±0.00000  bestvalidloss 0.45173  last_update 13\n",
      "train: iter 159  trainloss 0.69751  validloss 0.49922±0.00000  bestvalidloss 0.45173  last_update 14\n",
      "train: iter 160  trainloss 0.68262  validloss 0.45316±0.00000  bestvalidloss 0.45173  last_update 15\n",
      "train: iter 161  trainloss 0.68806  validloss 0.45694±0.00000  bestvalidloss 0.45173  last_update 16\n",
      "train: iter 162  trainloss 0.68020  validloss 0.44748±0.00000  bestvalidloss 0.44748  last_update 0\n",
      "train: iter 163  trainloss 0.70247  validloss 0.45720±0.00000  bestvalidloss 0.44748  last_update 1\n",
      "train: iter 164  trainloss 0.68245  validloss 0.42528±0.00000  bestvalidloss 0.42528  last_update 0\n",
      "train: iter 165  trainloss 0.69618  validloss 0.44318±0.00000  bestvalidloss 0.42528  last_update 1\n",
      "train: iter 166  trainloss 0.70115  validloss 0.46269±0.00000  bestvalidloss 0.42528  last_update 2\n",
      "train: iter 167  trainloss 0.68564  validloss 0.43118±0.00000  bestvalidloss 0.42528  last_update 3\n",
      "train: iter 168  trainloss 0.69604  validloss 0.44955±0.00000  bestvalidloss 0.42528  last_update 4\n",
      "train: iter 169  trainloss 0.67845  validloss 0.47300±0.00000  bestvalidloss 0.42528  last_update 5\n",
      "train: iter 170  trainloss 0.68803  validloss 0.49183±0.00000  bestvalidloss 0.42528  last_update 6\n",
      "train: iter 171  trainloss 0.68623  validloss 0.45095±0.00000  bestvalidloss 0.42528  last_update 7\n",
      "train: iter 172  trainloss 0.69863  validloss 0.47789±0.00000  bestvalidloss 0.42528  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 173  trainloss 0.69984  validloss 0.45542±0.00000  bestvalidloss 0.42528  last_update 9\n",
      "train: iter 174  trainloss 0.69387  validloss 0.44987±0.00000  bestvalidloss 0.42528  last_update 10\n",
      "train: iter 175  trainloss 0.67558  validloss 0.44559±0.00000  bestvalidloss 0.42528  last_update 11\n",
      "train: iter 176  trainloss 0.69506  validloss 0.46018±0.00000  bestvalidloss 0.42528  last_update 12\n",
      "train: iter 177  trainloss 0.68120  validloss 0.45241±0.00000  bestvalidloss 0.42528  last_update 13\n",
      "train: iter 178  trainloss 0.69609  validloss 0.43652±0.00000  bestvalidloss 0.42528  last_update 14\n",
      "train: iter 179  trainloss 0.68812  validloss 0.44505±0.00000  bestvalidloss 0.42528  last_update 15\n",
      "train: iter 180  trainloss 0.68615  validloss 0.46547±0.00000  bestvalidloss 0.42528  last_update 16\n",
      "train: iter 181  trainloss 0.69030  validloss 0.46569±0.00000  bestvalidloss 0.42528  last_update 17\n",
      "train: iter 182  trainloss 0.66850  validloss 0.46996±0.00000  bestvalidloss 0.42528  last_update 18\n",
      "train: iter 183  trainloss 0.68930  validloss 0.47624±0.00000  bestvalidloss 0.42528  last_update 19\n",
      "train: iter 184  trainloss 0.67704  validloss 0.42486±0.00000  bestvalidloss 0.42486  last_update 0\n",
      "train: iter 185  trainloss 0.67572  validloss 0.45608±0.00000  bestvalidloss 0.42486  last_update 1\n",
      "train: iter 186  trainloss 0.68658  validloss 0.44480±0.00000  bestvalidloss 0.42486  last_update 2\n",
      "train: iter 187  trainloss 0.69014  validloss 0.44216±0.00000  bestvalidloss 0.42486  last_update 3\n",
      "train: iter 188  trainloss 0.68873  validloss 0.47646±0.00000  bestvalidloss 0.42486  last_update 4\n",
      "train: iter 189  trainloss 0.68152  validloss 0.47441±0.00000  bestvalidloss 0.42486  last_update 5\n",
      "train: iter 190  trainloss 0.70183  validloss 0.45829±0.00000  bestvalidloss 0.42486  last_update 6\n",
      "train: iter 191  trainloss 0.70596  validloss 0.44941±0.00000  bestvalidloss 0.42486  last_update 7\n",
      "train: iter 192  trainloss 0.68217  validloss 0.44347±0.00000  bestvalidloss 0.42486  last_update 8\n",
      "train: iter 193  trainloss 0.68789  validloss 0.47020±0.00000  bestvalidloss 0.42486  last_update 9\n",
      "train: iter 194  trainloss 0.69500  validloss 0.46785±0.00000  bestvalidloss 0.42486  last_update 10\n",
      "train: iter 195  trainloss 0.67997  validloss 0.45684±0.00000  bestvalidloss 0.42486  last_update 11\n",
      "train: iter 196  trainloss 0.69092  validloss 0.46156±0.00000  bestvalidloss 0.42486  last_update 12\n",
      "train: iter 197  trainloss 0.69267  validloss 0.45580±0.00000  bestvalidloss 0.42486  last_update 13\n",
      "train: iter 198  trainloss 0.69565  validloss 0.44654±0.00000  bestvalidloss 0.42486  last_update 14\n",
      "train: iter 199  trainloss 0.69786  validloss 0.46650±0.00000  bestvalidloss 0.42486  last_update 15\n",
      "train: iter 200  trainloss 0.67952  validloss 0.44505±0.00000  bestvalidloss 0.42486  last_update 16\n",
      "train: iter 201  trainloss 0.67237  validloss 0.47544±0.00000  bestvalidloss 0.42486  last_update 17\n",
      "train: iter 202  trainloss 0.67766  validloss 0.42297±0.00000  bestvalidloss 0.42297  last_update 0\n",
      "train: iter 203  trainloss 0.70705  validloss 0.45055±0.00000  bestvalidloss 0.42297  last_update 1\n",
      "train: iter 204  trainloss 0.66773  validloss 0.45513±0.00000  bestvalidloss 0.42297  last_update 2\n",
      "train: iter 205  trainloss 0.69544  validloss 0.47119±0.00000  bestvalidloss 0.42297  last_update 3\n",
      "train: iter 206  trainloss 0.68349  validloss 0.42998±0.00000  bestvalidloss 0.42297  last_update 4\n",
      "train: iter 207  trainloss 0.69424  validloss 0.44972±0.00000  bestvalidloss 0.42297  last_update 5\n",
      "train: iter 208  trainloss 0.69876  validloss 0.46407±0.00000  bestvalidloss 0.42297  last_update 6\n",
      "train: iter 209  trainloss 0.68611  validloss 0.45634±0.00000  bestvalidloss 0.42297  last_update 7\n",
      "train: iter 210  trainloss 0.67967  validloss 0.46052±0.00000  bestvalidloss 0.42297  last_update 8\n",
      "train: iter 211  trainloss 0.69654  validloss 0.45157±0.00000  bestvalidloss 0.42297  last_update 9\n",
      "train: iter 212  trainloss 0.68512  validloss 0.42592±0.00000  bestvalidloss 0.42297  last_update 10\n",
      "train: iter 213  trainloss 0.68543  validloss 0.44813±0.00000  bestvalidloss 0.42297  last_update 11\n",
      "train: iter 214  trainloss 0.67950  validloss 0.46567±0.00000  bestvalidloss 0.42297  last_update 12\n",
      "train: iter 215  trainloss 0.68873  validloss 0.46199±0.00000  bestvalidloss 0.42297  last_update 13\n",
      "train: iter 216  trainloss 0.68595  validloss 0.47933±0.00000  bestvalidloss 0.42297  last_update 14\n",
      "train: iter 217  trainloss 0.69734  validloss 0.45285±0.00000  bestvalidloss 0.42297  last_update 15\n",
      "train: iter 218  trainloss 0.71402  validloss 0.44631±0.00000  bestvalidloss 0.42297  last_update 16\n",
      "train: iter 219  trainloss 0.70267  validloss 0.47336±0.00000  bestvalidloss 0.42297  last_update 17\n",
      "train: iter 220  trainloss 0.68490  validloss 0.46822±0.00000  bestvalidloss 0.42297  last_update 18\n",
      "train: iter 221  trainloss 0.68979  validloss 0.46483±0.00000  bestvalidloss 0.42297  last_update 19\n",
      "train: iter 222  trainloss 0.68029  validloss 0.44447±0.00000  bestvalidloss 0.42297  last_update 20\n",
      "train: iter 223  trainloss 0.67886  validloss 0.44416±0.00000  bestvalidloss 0.42297  last_update 21\n",
      "train: iter 224  trainloss 0.70024  validloss 0.49492±0.00000  bestvalidloss 0.42297  last_update 22\n",
      "train: iter 225  trainloss 0.68035  validloss 0.45569±0.00000  bestvalidloss 0.42297  last_update 23\n",
      "train: iter 226  trainloss 0.68972  validloss 0.46293±0.00000  bestvalidloss 0.42297  last_update 24\n",
      "train: iter 227  trainloss 0.68986  validloss 0.45356±0.00000  bestvalidloss 0.42297  last_update 25\n",
      "train: iter 228  trainloss 0.69282  validloss 0.43028±0.00000  bestvalidloss 0.42297  last_update 26\n",
      "train: iter 229  trainloss 0.68074  validloss 0.44996±0.00000  bestvalidloss 0.42297  last_update 27\n",
      "train: iter 230  trainloss 0.67212  validloss 0.46521±0.00000  bestvalidloss 0.42297  last_update 28\n",
      "train: iter 231  trainloss 0.68262  validloss 0.45196±0.00000  bestvalidloss 0.42297  last_update 29\n",
      "train: iter 232  trainloss 0.69779  validloss 0.47046±0.00000  bestvalidloss 0.42297  last_update 30\n",
      "train: iter 233  trainloss 0.70098  validloss 0.45581±0.00000  bestvalidloss 0.42297  last_update 31\n",
      "train: iter 234  trainloss 0.68523  validloss 0.44733±0.00000  bestvalidloss 0.42297  last_update 32\n",
      "train: iter 235  trainloss 0.68125  validloss 0.43887±0.00000  bestvalidloss 0.42297  last_update 33\n",
      "train: iter 236  trainloss 0.67866  validloss 0.46822±0.00000  bestvalidloss 0.42297  last_update 34\n",
      "train: iter 237  trainloss 0.68599  validloss 0.46269±0.00000  bestvalidloss 0.42297  last_update 35\n",
      "train: iter 238  trainloss 0.70279  validloss 0.44978±0.00000  bestvalidloss 0.42297  last_update 36\n",
      "train: iter 239  trainloss 0.68703  validloss 0.45230±0.00000  bestvalidloss 0.42297  last_update 37\n",
      "train: iter 240  trainloss 0.68647  validloss 0.44066±0.00000  bestvalidloss 0.42297  last_update 38\n",
      "train: iter 241  trainloss 0.69363  validloss 0.43357±0.00000  bestvalidloss 0.42297  last_update 39\n",
      "train: iter 242  trainloss 0.70057  validloss 0.45376±0.00000  bestvalidloss 0.42297  last_update 40\n",
      "train: iter 243  trainloss 0.69324  validloss 0.46768±0.00000  bestvalidloss 0.42297  last_update 41\n",
      "train: iter 244  trainloss 0.69506  validloss 0.45187±0.00000  bestvalidloss 0.42297  last_update 42\n",
      "train: iter 245  trainloss 0.67635  validloss 0.46941±0.00000  bestvalidloss 0.42297  last_update 43\n",
      "train: iter 246  trainloss 0.67706  validloss 0.46562±0.00000  bestvalidloss 0.42297  last_update 44\n",
      "train: iter 247  trainloss 0.70403  validloss 0.46304±0.00000  bestvalidloss 0.42297  last_update 45\n",
      "train: iter 248  trainloss 0.69119  validloss 0.46436±0.00000  bestvalidloss 0.42297  last_update 46\n",
      "train: iter 249  trainloss 0.70721  validloss 0.46064±0.00000  bestvalidloss 0.42297  last_update 47\n",
      "train: iter 250  trainloss 0.70847  validloss 0.43521±0.00000  bestvalidloss 0.42297  last_update 48\n",
      "train: iter 251  trainloss 0.67373  validloss 0.44915±0.00000  bestvalidloss 0.42297  last_update 49\n",
      "train: iter 252  trainloss 0.68671  validloss 0.46972±0.00000  bestvalidloss 0.42297  last_update 50\n",
      "train: iter 253  trainloss 0.69188  validloss 0.45691±0.00000  bestvalidloss 0.42297  last_update 51\n",
      "train: iter 254  trainloss 0.68217  validloss 0.45506±0.00000  bestvalidloss 0.42297  last_update 52\n",
      "train: iter 255  trainloss 0.70340  validloss 0.46084±0.00000  bestvalidloss 0.42297  last_update 53\n",
      "train: iter 256  trainloss 0.67177  validloss 0.47983±0.00000  bestvalidloss 0.42297  last_update 54\n",
      "train: iter 257  trainloss 0.70976  validloss 0.46644±0.00000  bestvalidloss 0.42297  last_update 55\n",
      "train: iter 258  trainloss 0.67542  validloss 0.45818±0.00000  bestvalidloss 0.42297  last_update 56\n",
      "train: iter 259  trainloss 0.67057  validloss 0.43663±0.00000  bestvalidloss 0.42297  last_update 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 260  trainloss 0.68397  validloss 0.45505±0.00000  bestvalidloss 0.42297  last_update 58\n",
      "train: iter 261  trainloss 0.66749  validloss 0.42575±0.00000  bestvalidloss 0.42297  last_update 59\n",
      "train: iter 262  trainloss 0.67863  validloss 0.43934±0.00000  bestvalidloss 0.42297  last_update 60\n",
      "train: iter 263  trainloss 0.67312  validloss 0.43603±0.00000  bestvalidloss 0.42297  last_update 61\n",
      "train: iter 264  trainloss 0.68137  validloss 0.44669±0.00000  bestvalidloss 0.42297  last_update 62\n",
      "train: iter 265  trainloss 0.69412  validloss 0.43927±0.00000  bestvalidloss 0.42297  last_update 63\n",
      "train: iter 266  trainloss 0.68886  validloss 0.44011±0.00000  bestvalidloss 0.42297  last_update 64\n",
      "train: iter 267  trainloss 0.69560  validloss 0.43576±0.00000  bestvalidloss 0.42297  last_update 65\n",
      "train: iter 268  trainloss 0.67619  validloss 0.45520±0.00000  bestvalidloss 0.42297  last_update 66\n",
      "train: iter 269  trainloss 0.71361  validloss 0.43436±0.00000  bestvalidloss 0.42297  last_update 67\n",
      "train: iter 270  trainloss 0.68499  validloss 0.43660±0.00000  bestvalidloss 0.42297  last_update 68\n",
      "train: iter 271  trainloss 0.69445  validloss 0.46208±0.00000  bestvalidloss 0.42297  last_update 69\n",
      "train: iter 272  trainloss 0.69434  validloss 0.44643±0.00000  bestvalidloss 0.42297  last_update 70\n",
      "train: iter 273  trainloss 0.69194  validloss 0.43369±0.00000  bestvalidloss 0.42297  last_update 71\n",
      "train: iter 274  trainloss 0.68911  validloss 0.46328±0.00000  bestvalidloss 0.42297  last_update 72\n",
      "train: iter 275  trainloss 0.66666  validloss 0.43913±0.00000  bestvalidloss 0.42297  last_update 73\n",
      "train: iter 276  trainloss 0.70303  validloss 0.44629±0.00000  bestvalidloss 0.42297  last_update 74\n",
      "train: iter 277  trainloss 0.68466  validloss 0.43026±0.00000  bestvalidloss 0.42297  last_update 75\n",
      "train: iter 278  trainloss 0.68164  validloss 0.40544±0.00000  bestvalidloss 0.40544  last_update 0\n",
      "train: iter 279  trainloss 0.68204  validloss 0.46546±0.00000  bestvalidloss 0.40544  last_update 1\n",
      "train: iter 280  trainloss 0.69918  validloss 0.43844±0.00000  bestvalidloss 0.40544  last_update 2\n",
      "train: iter 281  trainloss 0.68260  validloss 0.45919±0.00000  bestvalidloss 0.40544  last_update 3\n",
      "train: iter 282  trainloss 0.69292  validloss 0.46897±0.00000  bestvalidloss 0.40544  last_update 4\n",
      "train: iter 283  trainloss 0.68572  validloss 0.45650±0.00000  bestvalidloss 0.40544  last_update 5\n",
      "train: iter 284  trainloss 0.67461  validloss 0.45354±0.00000  bestvalidloss 0.40544  last_update 6\n",
      "train: iter 285  trainloss 0.67894  validloss 0.45228±0.00000  bestvalidloss 0.40544  last_update 7\n",
      "train: iter 286  trainloss 0.68992  validloss 0.46564±0.00000  bestvalidloss 0.40544  last_update 8\n",
      "train: iter 287  trainloss 0.70623  validloss 0.43081±0.00000  bestvalidloss 0.40544  last_update 9\n",
      "train: iter 288  trainloss 0.68792  validloss 0.47945±0.00000  bestvalidloss 0.40544  last_update 10\n",
      "train: iter 289  trainloss 0.69144  validloss 0.47129±0.00000  bestvalidloss 0.40544  last_update 11\n",
      "train: iter 290  trainloss 0.68701  validloss 0.47037±0.00000  bestvalidloss 0.40544  last_update 12\n",
      "train: iter 291  trainloss 0.68548  validloss 0.43817±0.00000  bestvalidloss 0.40544  last_update 13\n",
      "train: iter 292  trainloss 0.68339  validloss 0.45049±0.00000  bestvalidloss 0.40544  last_update 14\n",
      "train: iter 293  trainloss 0.68043  validloss 0.47174±0.00000  bestvalidloss 0.40544  last_update 15\n",
      "train: iter 294  trainloss 0.68237  validloss 0.46776±0.00000  bestvalidloss 0.40544  last_update 16\n",
      "train: iter 295  trainloss 0.69711  validloss 0.45199±0.00000  bestvalidloss 0.40544  last_update 17\n",
      "train: iter 296  trainloss 0.67435  validloss 0.43522±0.00000  bestvalidloss 0.40544  last_update 18\n",
      "train: iter 297  trainloss 0.68642  validloss 0.46189±0.00000  bestvalidloss 0.40544  last_update 19\n",
      "train: iter 298  trainloss 0.69137  validloss 0.44750±0.00000  bestvalidloss 0.40544  last_update 20\n",
      "train: iter 299  trainloss 0.69103  validloss 0.46013±0.00000  bestvalidloss 0.40544  last_update 21\n",
      "train: iter 300  trainloss 0.67750  validloss 0.44916±0.00000  bestvalidloss 0.40544  last_update 22\n",
      "train: iter 301  trainloss 0.69494  validloss 0.44361±0.00000  bestvalidloss 0.40544  last_update 23\n",
      "train: iter 302  trainloss 0.69430  validloss 0.45044±0.00000  bestvalidloss 0.40544  last_update 24\n",
      "train: iter 303  trainloss 0.69729  validloss 0.42371±0.00000  bestvalidloss 0.40544  last_update 25\n",
      "train: iter 304  trainloss 0.68164  validloss 0.46821±0.00000  bestvalidloss 0.40544  last_update 26\n",
      "train: iter 305  trainloss 0.68532  validloss 0.44056±0.00000  bestvalidloss 0.40544  last_update 27\n",
      "train: iter 306  trainloss 0.68626  validloss 0.46021±0.00000  bestvalidloss 0.40544  last_update 28\n",
      "train: iter 307  trainloss 0.69603  validloss 0.45884±0.00000  bestvalidloss 0.40544  last_update 29\n",
      "train: iter 308  trainloss 0.68383  validloss 0.46970±0.00000  bestvalidloss 0.40544  last_update 30\n",
      "train: iter 309  trainloss 0.69553  validloss 0.46277±0.00000  bestvalidloss 0.40544  last_update 31\n",
      "train: iter 310  trainloss 0.67905  validloss 0.47069±0.00000  bestvalidloss 0.40544  last_update 32\n",
      "train: iter 311  trainloss 0.68907  validloss 0.43476±0.00000  bestvalidloss 0.40544  last_update 33\n",
      "train: iter 312  trainloss 0.70424  validloss 0.43284±0.00000  bestvalidloss 0.40544  last_update 34\n",
      "train: iter 313  trainloss 0.69736  validloss 0.44753±0.00000  bestvalidloss 0.40544  last_update 35\n",
      "train: iter 314  trainloss 0.67135  validloss 0.44811±0.00000  bestvalidloss 0.40544  last_update 36\n",
      "train: iter 315  trainloss 0.70129  validloss 0.46216±0.00000  bestvalidloss 0.40544  last_update 37\n",
      "train: iter 316  trainloss 0.69494  validloss 0.46191±0.00000  bestvalidloss 0.40544  last_update 38\n",
      "train: iter 317  trainloss 0.69491  validloss 0.46995±0.00000  bestvalidloss 0.40544  last_update 39\n",
      "train: iter 318  trainloss 0.68439  validloss 0.47365±0.00000  bestvalidloss 0.40544  last_update 40\n",
      "train: iter 319  trainloss 0.67344  validloss 0.44978±0.00000  bestvalidloss 0.40544  last_update 41\n",
      "train: iter 320  trainloss 0.68834  validloss 0.46211±0.00000  bestvalidloss 0.40544  last_update 42\n",
      "train: iter 321  trainloss 0.69146  validloss 0.45762±0.00000  bestvalidloss 0.40544  last_update 43\n",
      "train: iter 322  trainloss 0.68632  validloss 0.47469±0.00000  bestvalidloss 0.40544  last_update 44\n",
      "train: iter 323  trainloss 0.69345  validloss 0.44899±0.00000  bestvalidloss 0.40544  last_update 45\n",
      "train: iter 324  trainloss 0.67695  validloss 0.45578±0.00000  bestvalidloss 0.40544  last_update 46\n",
      "train: iter 325  trainloss 0.67772  validloss 0.45559±0.00000  bestvalidloss 0.40544  last_update 47\n",
      "train: iter 326  trainloss 0.68323  validloss 0.44426±0.00000  bestvalidloss 0.40544  last_update 48\n",
      "train: iter 327  trainloss 0.67643  validloss 0.43093±0.00000  bestvalidloss 0.40544  last_update 49\n",
      "train: iter 328  trainloss 0.69229  validloss 0.44260±0.00000  bestvalidloss 0.40544  last_update 50\n",
      "train: iter 329  trainloss 0.67299  validloss 0.46094±0.00000  bestvalidloss 0.40544  last_update 51\n",
      "train: iter 330  trainloss 0.68612  validloss 0.43175±0.00000  bestvalidloss 0.40544  last_update 52\n",
      "train: iter 331  trainloss 0.68998  validloss 0.45945±0.00000  bestvalidloss 0.40544  last_update 53\n",
      "train: iter 332  trainloss 0.68510  validloss 0.42714±0.00000  bestvalidloss 0.40544  last_update 54\n",
      "train: iter 333  trainloss 0.69661  validloss 0.46268±0.00000  bestvalidloss 0.40544  last_update 55\n",
      "train: iter 334  trainloss 0.67655  validloss 0.42570±0.00000  bestvalidloss 0.40544  last_update 56\n",
      "train: iter 335  trainloss 0.69067  validloss 0.44089±0.00000  bestvalidloss 0.40544  last_update 57\n",
      "train: iter 336  trainloss 0.69196  validloss 0.45417±0.00000  bestvalidloss 0.40544  last_update 58\n",
      "train: iter 337  trainloss 0.68035  validloss 0.45263±0.00000  bestvalidloss 0.40544  last_update 59\n",
      "train: iter 338  trainloss 0.69624  validloss 0.46298±0.00000  bestvalidloss 0.40544  last_update 60\n",
      "train: iter 339  trainloss 0.69146  validloss 0.44092±0.00000  bestvalidloss 0.40544  last_update 61\n",
      "train: iter 340  trainloss 0.68118  validloss 0.47656±0.00000  bestvalidloss 0.40544  last_update 62\n",
      "train: iter 341  trainloss 0.67648  validloss 0.45600±0.00000  bestvalidloss 0.40544  last_update 63\n",
      "train: iter 342  trainloss 0.69415  validloss 0.44845±0.00000  bestvalidloss 0.40544  last_update 64\n",
      "train: iter 343  trainloss 0.69231  validloss 0.42518±0.00000  bestvalidloss 0.40544  last_update 65\n",
      "train: iter 344  trainloss 0.69736  validloss 0.45465±0.00000  bestvalidloss 0.40544  last_update 66\n",
      "train: iter 345  trainloss 0.68968  validloss 0.48345±0.00000  bestvalidloss 0.40544  last_update 67\n",
      "train: iter 346  trainloss 0.67919  validloss 0.46715±0.00000  bestvalidloss 0.40544  last_update 68\n",
      "train: iter 347  trainloss 0.68794  validloss 0.43489±0.00000  bestvalidloss 0.40544  last_update 69\n",
      "train: iter 348  trainloss 0.67594  validloss 0.45629±0.00000  bestvalidloss 0.40544  last_update 70\n",
      "train: iter 349  trainloss 0.68735  validloss 0.45017±0.00000  bestvalidloss 0.40544  last_update 71\n",
      "train: iter 350  trainloss 0.69301  validloss 0.42667±0.00000  bestvalidloss 0.40544  last_update 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 351  trainloss 0.68422  validloss 0.47403±0.00000  bestvalidloss 0.40544  last_update 73\n",
      "train: iter 352  trainloss 0.68587  validloss 0.45272±0.00000  bestvalidloss 0.40544  last_update 74\n",
      "train: iter 353  trainloss 0.67659  validloss 0.45811±0.00000  bestvalidloss 0.40544  last_update 75\n",
      "train: iter 354  trainloss 0.69338  validloss 0.43233±0.00000  bestvalidloss 0.40544  last_update 76\n",
      "train: iter 355  trainloss 0.69954  validloss 0.46221±0.00000  bestvalidloss 0.40544  last_update 77\n",
      "train: iter 356  trainloss 0.70715  validloss 0.44715±0.00000  bestvalidloss 0.40544  last_update 78\n",
      "train: iter 357  trainloss 0.67403  validloss 0.47645±0.00000  bestvalidloss 0.40544  last_update 79\n",
      "train: iter 358  trainloss 0.69563  validloss 0.44356±0.00000  bestvalidloss 0.40544  last_update 80\n",
      "train: iter 359  trainloss 0.69692  validloss 0.43305±0.00000  bestvalidloss 0.40544  last_update 81\n",
      "train: iter 360  trainloss 0.68658  validloss 0.44036±0.00000  bestvalidloss 0.40544  last_update 82\n",
      "train: iter 361  trainloss 0.67700  validloss 0.48142±0.00000  bestvalidloss 0.40544  last_update 83\n",
      "train: iter 362  trainloss 0.69963  validloss 0.44830±0.00000  bestvalidloss 0.40544  last_update 84\n",
      "train: iter 363  trainloss 0.68654  validloss 0.45285±0.00000  bestvalidloss 0.40544  last_update 85\n",
      "train: iter 364  trainloss 0.70584  validloss 0.45241±0.00000  bestvalidloss 0.40544  last_update 86\n",
      "train: iter 365  trainloss 0.68012  validloss 0.45032±0.00000  bestvalidloss 0.40544  last_update 87\n",
      "train: iter 366  trainloss 0.70634  validloss 0.46405±0.00000  bestvalidloss 0.40544  last_update 88\n",
      "train: iter 367  trainloss 0.68577  validloss 0.45234±0.00000  bestvalidloss 0.40544  last_update 89\n",
      "train: iter 368  trainloss 0.68802  validloss 0.44752±0.00000  bestvalidloss 0.40544  last_update 90\n",
      "train: iter 369  trainloss 0.68802  validloss 0.45558±0.00000  bestvalidloss 0.40544  last_update 91\n",
      "train: iter 370  trainloss 0.69394  validloss 0.44343±0.00000  bestvalidloss 0.40544  last_update 92\n",
      "train: iter 371  trainloss 0.70701  validloss 0.47564±0.00000  bestvalidloss 0.40544  last_update 93\n",
      "train: iter 372  trainloss 0.68256  validloss 0.44991±0.00000  bestvalidloss 0.40544  last_update 94\n",
      "train: iter 373  trainloss 0.68027  validloss 0.42476±0.00000  bestvalidloss 0.40544  last_update 95\n",
      "train: iter 374  trainloss 0.68969  validloss 0.46285±0.00000  bestvalidloss 0.40544  last_update 96\n",
      "train: iter 375  trainloss 0.68686  validloss 0.43821±0.00000  bestvalidloss 0.40544  last_update 97\n",
      "train: iter 376  trainloss 0.67925  validloss 0.44346±0.00000  bestvalidloss 0.40544  last_update 98\n",
      "train: iter 377  trainloss 0.69138  validloss 0.44341±0.00000  bestvalidloss 0.40544  last_update 99\n",
      "train: iter 378  trainloss 0.68952  validloss 0.43880±0.00000  bestvalidloss 0.40544  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-4.2772, -1.4612], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 11.50150  validloss 17.42025±0.00000  bestvalidloss 17.42025  last_update 0\n",
      "train: iter 1  trainloss 6.35165  validloss 9.24475±0.00000  bestvalidloss 9.24475  last_update 0\n",
      "train: iter 2  trainloss 4.28880  validloss 5.21733±0.00000  bestvalidloss 5.21733  last_update 0\n",
      "train: iter 3  trainloss 3.63540  validloss 3.52461±0.00000  bestvalidloss 3.52461  last_update 0\n",
      "train: iter 4  trainloss 3.37947  validloss 2.71778±0.00000  bestvalidloss 2.71778  last_update 0\n",
      "train: iter 5  trainloss 3.22530  validloss 2.54519±0.00000  bestvalidloss 2.54519  last_update 0\n",
      "train: iter 6  trainloss 3.00022  validloss 2.34172±0.00000  bestvalidloss 2.34172  last_update 0\n",
      "train: iter 7  trainloss 2.81100  validloss 2.31221±0.00000  bestvalidloss 2.31221  last_update 0\n",
      "train: iter 8  trainloss 2.62881  validloss 2.07615±0.00000  bestvalidloss 2.07615  last_update 0\n",
      "train: iter 9  trainloss 2.36078  validloss 2.11262±0.00000  bestvalidloss 2.07615  last_update 1\n",
      "train: iter 10  trainloss 2.19465  validloss 1.93564±0.00000  bestvalidloss 1.93564  last_update 0\n",
      "train: iter 11  trainloss 2.13361  validloss 1.91257±0.00000  bestvalidloss 1.91257  last_update 0\n",
      "train: iter 12  trainloss 2.02314  validloss 1.77930±0.00000  bestvalidloss 1.77930  last_update 0\n",
      "train: iter 13  trainloss 1.96190  validloss 1.85313±0.00000  bestvalidloss 1.77930  last_update 1\n",
      "train: iter 14  trainloss 1.83583  validloss 1.64153±0.00000  bestvalidloss 1.64153  last_update 0\n",
      "train: iter 15  trainloss 1.83172  validloss 1.58778±0.00000  bestvalidloss 1.58778  last_update 0\n",
      "train: iter 16  trainloss 1.77652  validloss 1.58142±0.00000  bestvalidloss 1.58142  last_update 0\n",
      "train: iter 17  trainloss 1.74949  validloss 1.50348±0.00000  bestvalidloss 1.50348  last_update 0\n",
      "train: iter 18  trainloss 1.75269  validloss 1.46313±0.00000  bestvalidloss 1.46313  last_update 0\n",
      "train: iter 19  trainloss 1.66980  validloss 1.44005±0.00000  bestvalidloss 1.44005  last_update 0\n",
      "train: iter 20  trainloss 1.64004  validloss 1.47478±0.00000  bestvalidloss 1.44005  last_update 1\n",
      "train: iter 21  trainloss 1.59202  validloss 1.56235±0.00000  bestvalidloss 1.44005  last_update 2\n",
      "train: iter 22  trainloss 1.58387  validloss 1.39177±0.00000  bestvalidloss 1.39177  last_update 0\n",
      "train: iter 23  trainloss 1.58650  validloss 1.31593±0.00000  bestvalidloss 1.31593  last_update 0\n",
      "train: iter 24  trainloss 1.53744  validloss 1.42867±0.00000  bestvalidloss 1.31593  last_update 1\n",
      "train: iter 25  trainloss 1.54851  validloss 1.38542±0.00000  bestvalidloss 1.31593  last_update 2\n",
      "train: iter 26  trainloss 1.51680  validloss 1.38547±0.00000  bestvalidloss 1.31593  last_update 3\n",
      "train: iter 27  trainloss 1.46676  validloss 1.45430±0.00000  bestvalidloss 1.31593  last_update 4\n",
      "train: iter 28  trainloss 1.50458  validloss 1.32412±0.00000  bestvalidloss 1.31593  last_update 5\n",
      "train: iter 29  trainloss 1.48520  validloss 1.36059±0.00000  bestvalidloss 1.31593  last_update 6\n",
      "train: iter 30  trainloss 1.45118  validloss 1.48532±0.00000  bestvalidloss 1.31593  last_update 7\n",
      "train: iter 31  trainloss 1.41949  validloss 1.45564±0.00000  bestvalidloss 1.31593  last_update 8\n",
      "train: iter 32  trainloss 1.43855  validloss 1.38308±0.00000  bestvalidloss 1.31593  last_update 9\n",
      "train: iter 33  trainloss 1.46272  validloss 1.33483±0.00000  bestvalidloss 1.31593  last_update 10\n",
      "train: iter 34  trainloss 1.43195  validloss 1.32798±0.00000  bestvalidloss 1.31593  last_update 11\n",
      "train: iter 35  trainloss 1.40798  validloss 1.38857±0.00000  bestvalidloss 1.31593  last_update 12\n",
      "train: iter 36  trainloss 1.40814  validloss 1.29435±0.00000  bestvalidloss 1.29435  last_update 0\n",
      "train: iter 37  trainloss 1.42985  validloss 1.36276±0.00000  bestvalidloss 1.29435  last_update 1\n",
      "train: iter 38  trainloss 1.42729  validloss 1.43851±0.00000  bestvalidloss 1.29435  last_update 2\n",
      "train: iter 39  trainloss 1.43451  validloss 1.32717±0.00000  bestvalidloss 1.29435  last_update 3\n",
      "train: iter 40  trainloss 1.38304  validloss 1.32507±0.00000  bestvalidloss 1.29435  last_update 4\n",
      "train: iter 41  trainloss 1.40118  validloss 1.23714±0.00000  bestvalidloss 1.23714  last_update 0\n",
      "train: iter 42  trainloss 1.40352  validloss 1.26658±0.00000  bestvalidloss 1.23714  last_update 1\n",
      "train: iter 43  trainloss 1.39449  validloss 1.30087±0.00000  bestvalidloss 1.23714  last_update 2\n",
      "train: iter 44  trainloss 1.37551  validloss 1.35978±0.00000  bestvalidloss 1.23714  last_update 3\n",
      "train: iter 45  trainloss 1.43441  validloss 1.35711±0.00000  bestvalidloss 1.23714  last_update 4\n",
      "train: iter 46  trainloss 1.42900  validloss 1.37692±0.00000  bestvalidloss 1.23714  last_update 5\n",
      "train: iter 47  trainloss 1.39925  validloss 1.33383±0.00000  bestvalidloss 1.23714  last_update 6\n",
      "train: iter 48  trainloss 1.38432  validloss 1.37418±0.00000  bestvalidloss 1.23714  last_update 7\n",
      "train: iter 49  trainloss 1.37531  validloss 1.26445±0.00000  bestvalidloss 1.23714  last_update 8\n",
      "train: iter 50  trainloss 1.39996  validloss 1.20125±0.00000  bestvalidloss 1.20125  last_update 0\n",
      "train: iter 51  trainloss 1.37689  validloss 1.36635±0.00000  bestvalidloss 1.20125  last_update 1\n",
      "train: iter 52  trainloss 1.40054  validloss 1.29055±0.00000  bestvalidloss 1.20125  last_update 2\n",
      "train: iter 53  trainloss 1.39094  validloss 1.38463±0.00000  bestvalidloss 1.20125  last_update 3\n",
      "train: iter 54  trainloss 1.40122  validloss 1.38967±0.00000  bestvalidloss 1.20125  last_update 4\n",
      "train: iter 55  trainloss 1.39576  validloss 1.28258±0.00000  bestvalidloss 1.20125  last_update 5\n",
      "train: iter 56  trainloss 1.36165  validloss 1.31430±0.00000  bestvalidloss 1.20125  last_update 6\n",
      "train: iter 57  trainloss 1.39250  validloss 1.34005±0.00000  bestvalidloss 1.20125  last_update 7\n",
      "train: iter 58  trainloss 1.35298  validloss 1.30979±0.00000  bestvalidloss 1.20125  last_update 8\n",
      "train: iter 59  trainloss 1.41290  validloss 1.31164±0.00000  bestvalidloss 1.20125  last_update 9\n",
      "train: iter 60  trainloss 1.37734  validloss 1.29620±0.00000  bestvalidloss 1.20125  last_update 10\n",
      "train: iter 61  trainloss 1.37159  validloss 1.30853±0.00000  bestvalidloss 1.20125  last_update 11\n",
      "train: iter 62  trainloss 1.40059  validloss 1.38345±0.00000  bestvalidloss 1.20125  last_update 12\n",
      "train: iter 63  trainloss 1.39769  validloss 1.40351±0.00000  bestvalidloss 1.20125  last_update 13\n",
      "train: iter 64  trainloss 1.39399  validloss 1.30551±0.00000  bestvalidloss 1.20125  last_update 14\n",
      "train: iter 65  trainloss 1.40945  validloss 1.28812±0.00000  bestvalidloss 1.20125  last_update 15\n",
      "train: iter 66  trainloss 1.37597  validloss 1.24111±0.00000  bestvalidloss 1.20125  last_update 16\n",
      "train: iter 67  trainloss 1.39415  validloss 1.26888±0.00000  bestvalidloss 1.20125  last_update 17\n",
      "train: iter 68  trainloss 1.38830  validloss 1.26224±0.00000  bestvalidloss 1.20125  last_update 18\n",
      "train: iter 69  trainloss 1.40357  validloss 1.31194±0.00000  bestvalidloss 1.20125  last_update 19\n",
      "train: iter 70  trainloss 1.37718  validloss 1.35990±0.00000  bestvalidloss 1.20125  last_update 20\n",
      "train: iter 71  trainloss 1.35984  validloss 1.27861±0.00000  bestvalidloss 1.20125  last_update 21\n",
      "train: iter 72  trainloss 1.42339  validloss 1.23215±0.00000  bestvalidloss 1.20125  last_update 22\n",
      "train: iter 73  trainloss 1.35620  validloss 1.35387±0.00000  bestvalidloss 1.20125  last_update 23\n",
      "train: iter 74  trainloss 1.35343  validloss 1.35225±0.00000  bestvalidloss 1.20125  last_update 24\n",
      "train: iter 75  trainloss 1.34497  validloss 1.36954±0.00000  bestvalidloss 1.20125  last_update 25\n",
      "train: iter 76  trainloss 1.38410  validloss 1.34635±0.00000  bestvalidloss 1.20125  last_update 26\n",
      "train: iter 77  trainloss 1.39409  validloss 1.33192±0.00000  bestvalidloss 1.20125  last_update 27\n",
      "train: iter 78  trainloss 1.38065  validloss 1.39973±0.00000  bestvalidloss 1.20125  last_update 28\n",
      "train: iter 79  trainloss 1.36147  validloss 1.52872±0.00000  bestvalidloss 1.20125  last_update 29\n",
      "train: iter 80  trainloss 1.38358  validloss 1.34306±0.00000  bestvalidloss 1.20125  last_update 30\n",
      "train: iter 81  trainloss 1.36945  validloss 1.35055±0.00000  bestvalidloss 1.20125  last_update 31\n",
      "train: iter 82  trainloss 1.37803  validloss 1.30690±0.00000  bestvalidloss 1.20125  last_update 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.37538  validloss 1.24076±0.00000  bestvalidloss 1.20125  last_update 33\n",
      "train: iter 84  trainloss 1.40959  validloss 1.20593±0.00000  bestvalidloss 1.20125  last_update 34\n",
      "train: iter 85  trainloss 1.37812  validloss 1.28224±0.00000  bestvalidloss 1.20125  last_update 35\n",
      "train: iter 86  trainloss 1.36826  validloss 1.27868±0.00000  bestvalidloss 1.20125  last_update 36\n",
      "train: iter 87  trainloss 1.40378  validloss 1.33864±0.00000  bestvalidloss 1.20125  last_update 37\n",
      "train: iter 88  trainloss 1.36180  validloss 1.33552±0.00000  bestvalidloss 1.20125  last_update 38\n",
      "train: iter 89  trainloss 1.38374  validloss 1.25668±0.00000  bestvalidloss 1.20125  last_update 39\n",
      "train: iter 90  trainloss 1.38776  validloss 1.23247±0.00000  bestvalidloss 1.20125  last_update 40\n",
      "train: iter 91  trainloss 1.36914  validloss 1.39153±0.00000  bestvalidloss 1.20125  last_update 41\n",
      "train: iter 92  trainloss 1.36031  validloss 1.35378±0.00000  bestvalidloss 1.20125  last_update 42\n",
      "train: iter 93  trainloss 1.38439  validloss 1.35873±0.00000  bestvalidloss 1.20125  last_update 43\n",
      "train: iter 94  trainloss 1.41198  validloss 1.47926±0.00000  bestvalidloss 1.20125  last_update 44\n",
      "train: iter 95  trainloss 1.35802  validloss 1.28313±0.00000  bestvalidloss 1.20125  last_update 45\n",
      "train: iter 96  trainloss 1.40650  validloss 1.39512±0.00000  bestvalidloss 1.20125  last_update 46\n",
      "train: iter 97  trainloss 1.36729  validloss 1.40545±0.00000  bestvalidloss 1.20125  last_update 47\n",
      "train: iter 98  trainloss 1.37129  validloss 1.33329±0.00000  bestvalidloss 1.20125  last_update 48\n",
      "train: iter 99  trainloss 1.35753  validloss 1.33123±0.00000  bestvalidloss 1.20125  last_update 49\n",
      "train: iter 100  trainloss 1.36112  validloss 1.41645±0.00000  bestvalidloss 1.20125  last_update 50\n",
      "train: iter 101  trainloss 1.34750  validloss 1.35413±0.00000  bestvalidloss 1.20125  last_update 51\n",
      "train: iter 102  trainloss 1.38088  validloss 1.34687±0.00000  bestvalidloss 1.20125  last_update 52\n",
      "train: iter 103  trainloss 1.39159  validloss 1.37755±0.00000  bestvalidloss 1.20125  last_update 53\n",
      "train: iter 104  trainloss 1.39358  validloss 1.35855±0.00000  bestvalidloss 1.20125  last_update 54\n",
      "train: iter 105  trainloss 1.37933  validloss 1.28770±0.00000  bestvalidloss 1.20125  last_update 55\n",
      "train: iter 106  trainloss 1.35075  validloss 1.39011±0.00000  bestvalidloss 1.20125  last_update 56\n",
      "train: iter 107  trainloss 1.38110  validloss 1.35545±0.00000  bestvalidloss 1.20125  last_update 57\n",
      "train: iter 108  trainloss 1.39053  validloss 1.31440±0.00000  bestvalidloss 1.20125  last_update 58\n",
      "train: iter 109  trainloss 1.39096  validloss 1.38609±0.00000  bestvalidloss 1.20125  last_update 59\n",
      "train: iter 110  trainloss 1.41446  validloss 1.49920±0.00000  bestvalidloss 1.20125  last_update 60\n",
      "train: iter 111  trainloss 1.37716  validloss 1.24500±0.00000  bestvalidloss 1.20125  last_update 61\n",
      "train: iter 112  trainloss 1.36409  validloss 1.32152±0.00000  bestvalidloss 1.20125  last_update 62\n",
      "train: iter 113  trainloss 1.41270  validloss 1.26363±0.00000  bestvalidloss 1.20125  last_update 63\n",
      "train: iter 114  trainloss 1.36789  validloss 1.43327±0.00000  bestvalidloss 1.20125  last_update 64\n",
      "train: iter 115  trainloss 1.39894  validloss 1.30881±0.00000  bestvalidloss 1.20125  last_update 65\n",
      "train: iter 116  trainloss 1.38302  validloss 1.48424±0.00000  bestvalidloss 1.20125  last_update 66\n",
      "train: iter 117  trainloss 1.37591  validloss 1.31437±0.00000  bestvalidloss 1.20125  last_update 67\n",
      "train: iter 118  trainloss 1.37065  validloss 1.33337±0.00000  bestvalidloss 1.20125  last_update 68\n",
      "train: iter 119  trainloss 1.38165  validloss 1.37686±0.00000  bestvalidloss 1.20125  last_update 69\n",
      "train: iter 120  trainloss 1.35457  validloss 1.33777±0.00000  bestvalidloss 1.20125  last_update 70\n",
      "train: iter 121  trainloss 1.36521  validloss 1.37822±0.00000  bestvalidloss 1.20125  last_update 71\n",
      "train: iter 122  trainloss 1.37416  validloss 1.28888±0.00000  bestvalidloss 1.20125  last_update 72\n",
      "train: iter 123  trainloss 1.36899  validloss 1.28418±0.00000  bestvalidloss 1.20125  last_update 73\n",
      "train: iter 124  trainloss 1.38179  validloss 1.18412±0.00000  bestvalidloss 1.18412  last_update 0\n",
      "train: iter 125  trainloss 1.40226  validloss 1.33827±0.00000  bestvalidloss 1.18412  last_update 1\n",
      "train: iter 126  trainloss 1.37455  validloss 1.28190±0.00000  bestvalidloss 1.18412  last_update 2\n",
      "train: iter 127  trainloss 1.36343  validloss 1.23487±0.00000  bestvalidloss 1.18412  last_update 3\n",
      "train: iter 128  trainloss 1.37185  validloss 1.29252±0.00000  bestvalidloss 1.18412  last_update 4\n",
      "train: iter 129  trainloss 1.37796  validloss 1.35698±0.00000  bestvalidloss 1.18412  last_update 5\n",
      "train: iter 130  trainloss 1.37174  validloss 1.35148±0.00000  bestvalidloss 1.18412  last_update 6\n",
      "train: iter 131  trainloss 1.39692  validloss 1.33266±0.00000  bestvalidloss 1.18412  last_update 7\n",
      "train: iter 132  trainloss 1.38174  validloss 1.31174±0.00000  bestvalidloss 1.18412  last_update 8\n",
      "train: iter 133  trainloss 1.33758  validloss 1.25302±0.00000  bestvalidloss 1.18412  last_update 9\n",
      "train: iter 134  trainloss 1.36957  validloss 1.40181±0.00000  bestvalidloss 1.18412  last_update 10\n",
      "train: iter 135  trainloss 1.38029  validloss 1.27447±0.00000  bestvalidloss 1.18412  last_update 11\n",
      "train: iter 136  trainloss 1.39079  validloss 1.37386±0.00000  bestvalidloss 1.18412  last_update 12\n",
      "train: iter 137  trainloss 1.38198  validloss 1.31173±0.00000  bestvalidloss 1.18412  last_update 13\n",
      "train: iter 138  trainloss 1.36562  validloss 1.48910±0.00000  bestvalidloss 1.18412  last_update 14\n",
      "train: iter 139  trainloss 1.38103  validloss 1.47639±0.00000  bestvalidloss 1.18412  last_update 15\n",
      "train: iter 140  trainloss 1.37978  validloss 1.36601±0.00000  bestvalidloss 1.18412  last_update 16\n",
      "train: iter 141  trainloss 1.36174  validloss 1.44866±0.00000  bestvalidloss 1.18412  last_update 17\n",
      "train: iter 142  trainloss 1.36680  validloss 1.30409±0.00000  bestvalidloss 1.18412  last_update 18\n",
      "train: iter 143  trainloss 1.37540  validloss 1.35143±0.00000  bestvalidloss 1.18412  last_update 19\n",
      "train: iter 144  trainloss 1.33724  validloss 1.39902±0.00000  bestvalidloss 1.18412  last_update 20\n",
      "train: iter 145  trainloss 1.37109  validloss 1.25205±0.00000  bestvalidloss 1.18412  last_update 21\n",
      "train: iter 146  trainloss 1.39840  validloss 1.27861±0.00000  bestvalidloss 1.18412  last_update 22\n",
      "train: iter 147  trainloss 1.34386  validloss 1.33684±0.00000  bestvalidloss 1.18412  last_update 23\n",
      "train: iter 148  trainloss 1.33450  validloss 1.19282±0.00000  bestvalidloss 1.18412  last_update 24\n",
      "train: iter 149  trainloss 1.40282  validloss 1.24962±0.00000  bestvalidloss 1.18412  last_update 25\n",
      "train: iter 150  trainloss 1.34356  validloss 1.37181±0.00000  bestvalidloss 1.18412  last_update 26\n",
      "train: iter 151  trainloss 1.34708  validloss 1.26245±0.00000  bestvalidloss 1.18412  last_update 27\n",
      "train: iter 152  trainloss 1.33552  validloss 1.33533±0.00000  bestvalidloss 1.18412  last_update 28\n",
      "train: iter 153  trainloss 1.36430  validloss 1.31395±0.00000  bestvalidloss 1.18412  last_update 29\n",
      "train: iter 154  trainloss 1.40561  validloss 1.46963±0.00000  bestvalidloss 1.18412  last_update 30\n",
      "train: iter 155  trainloss 1.37493  validloss 1.23866±0.00000  bestvalidloss 1.18412  last_update 31\n",
      "train: iter 156  trainloss 1.34911  validloss 1.35854±0.00000  bestvalidloss 1.18412  last_update 32\n",
      "train: iter 157  trainloss 1.39355  validloss 1.40089±0.00000  bestvalidloss 1.18412  last_update 33\n",
      "train: iter 158  trainloss 1.35938  validloss 1.26391±0.00000  bestvalidloss 1.18412  last_update 34\n",
      "train: iter 159  trainloss 1.38657  validloss 1.37709±0.00000  bestvalidloss 1.18412  last_update 35\n",
      "train: iter 160  trainloss 1.35379  validloss 1.24869±0.00000  bestvalidloss 1.18412  last_update 36\n",
      "train: iter 161  trainloss 1.31971  validloss 1.31310±0.00000  bestvalidloss 1.18412  last_update 37\n",
      "train: iter 162  trainloss 1.39308  validloss 1.42545±0.00000  bestvalidloss 1.18412  last_update 38\n",
      "train: iter 163  trainloss 1.36692  validloss 1.32855±0.00000  bestvalidloss 1.18412  last_update 39\n",
      "train: iter 164  trainloss 1.35603  validloss 1.37121±0.00000  bestvalidloss 1.18412  last_update 40\n",
      "train: iter 165  trainloss 1.39166  validloss 1.28549±0.00000  bestvalidloss 1.18412  last_update 41\n",
      "train: iter 166  trainloss 1.37500  validloss 1.37744±0.00000  bestvalidloss 1.18412  last_update 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 1.42235  validloss 1.25347±0.00000  bestvalidloss 1.18412  last_update 43\n",
      "train: iter 168  trainloss 1.34952  validloss 1.30974±0.00000  bestvalidloss 1.18412  last_update 44\n",
      "train: iter 169  trainloss 1.36858  validloss 1.41383±0.00000  bestvalidloss 1.18412  last_update 45\n",
      "train: iter 170  trainloss 1.35031  validloss 1.32737±0.00000  bestvalidloss 1.18412  last_update 46\n",
      "train: iter 171  trainloss 1.36669  validloss 1.29922±0.00000  bestvalidloss 1.18412  last_update 47\n",
      "train: iter 172  trainloss 1.35342  validloss 1.26971±0.00000  bestvalidloss 1.18412  last_update 48\n",
      "train: iter 173  trainloss 1.35943  validloss 1.37822±0.00000  bestvalidloss 1.18412  last_update 49\n",
      "train: iter 174  trainloss 1.37176  validloss 1.26067±0.00000  bestvalidloss 1.18412  last_update 50\n",
      "train: iter 175  trainloss 1.35701  validloss 1.23931±0.00000  bestvalidloss 1.18412  last_update 51\n",
      "train: iter 176  trainloss 1.36902  validloss 1.36462±0.00000  bestvalidloss 1.18412  last_update 52\n",
      "train: iter 177  trainloss 1.38759  validloss 1.33978±0.00000  bestvalidloss 1.18412  last_update 53\n",
      "train: iter 178  trainloss 1.36647  validloss 1.42164±0.00000  bestvalidloss 1.18412  last_update 54\n",
      "train: iter 179  trainloss 1.37027  validloss 1.29510±0.00000  bestvalidloss 1.18412  last_update 55\n",
      "train: iter 180  trainloss 1.36657  validloss 1.30554±0.00000  bestvalidloss 1.18412  last_update 56\n",
      "train: iter 181  trainloss 1.38338  validloss 1.31959±0.00000  bestvalidloss 1.18412  last_update 57\n",
      "train: iter 182  trainloss 1.36123  validloss 1.30913±0.00000  bestvalidloss 1.18412  last_update 58\n",
      "train: iter 183  trainloss 1.36038  validloss 1.38442±0.00000  bestvalidloss 1.18412  last_update 59\n",
      "train: iter 184  trainloss 1.37377  validloss 1.32619±0.00000  bestvalidloss 1.18412  last_update 60\n",
      "train: iter 185  trainloss 1.33632  validloss 1.26123±0.00000  bestvalidloss 1.18412  last_update 61\n",
      "train: iter 186  trainloss 1.37827  validloss 1.45044±0.00000  bestvalidloss 1.18412  last_update 62\n",
      "train: iter 187  trainloss 1.36079  validloss 1.32725±0.00000  bestvalidloss 1.18412  last_update 63\n",
      "train: iter 188  trainloss 1.35487  validloss 1.42744±0.00000  bestvalidloss 1.18412  last_update 64\n",
      "train: iter 189  trainloss 1.36372  validloss 1.24772±0.00000  bestvalidloss 1.18412  last_update 65\n",
      "train: iter 190  trainloss 1.37230  validloss 1.42067±0.00000  bestvalidloss 1.18412  last_update 66\n",
      "train: iter 191  trainloss 1.37925  validloss 1.40996±0.00000  bestvalidloss 1.18412  last_update 67\n",
      "train: iter 192  trainloss 1.36614  validloss 1.26678±0.00000  bestvalidloss 1.18412  last_update 68\n",
      "train: iter 193  trainloss 1.36570  validloss 1.35614±0.00000  bestvalidloss 1.18412  last_update 69\n",
      "train: iter 194  trainloss 1.36723  validloss 1.28582±0.00000  bestvalidloss 1.18412  last_update 70\n",
      "train: iter 195  trainloss 1.34628  validloss 1.34042±0.00000  bestvalidloss 1.18412  last_update 71\n",
      "train: iter 196  trainloss 1.35329  validloss 1.43583±0.00000  bestvalidloss 1.18412  last_update 72\n",
      "train: iter 197  trainloss 1.36847  validloss 1.31947±0.00000  bestvalidloss 1.18412  last_update 73\n",
      "train: iter 198  trainloss 1.35210  validloss 1.22020±0.00000  bestvalidloss 1.18412  last_update 74\n",
      "train: iter 199  trainloss 1.33837  validloss 1.31693±0.00000  bestvalidloss 1.18412  last_update 75\n",
      "train: iter 200  trainloss 1.36019  validloss 1.22247±0.00000  bestvalidloss 1.18412  last_update 76\n",
      "train: iter 201  trainloss 1.39113  validloss 1.33729±0.00000  bestvalidloss 1.18412  last_update 77\n",
      "train: iter 202  trainloss 1.35507  validloss 1.38278±0.00000  bestvalidloss 1.18412  last_update 78\n",
      "train: iter 203  trainloss 1.35303  validloss 1.42719±0.00000  bestvalidloss 1.18412  last_update 79\n",
      "train: iter 204  trainloss 1.37494  validloss 1.41629±0.00000  bestvalidloss 1.18412  last_update 80\n",
      "train: iter 205  trainloss 1.37200  validloss 1.31039±0.00000  bestvalidloss 1.18412  last_update 81\n",
      "train: iter 206  trainloss 1.38221  validloss 1.29993±0.00000  bestvalidloss 1.18412  last_update 82\n",
      "train: iter 207  trainloss 1.35974  validloss 1.33606±0.00000  bestvalidloss 1.18412  last_update 83\n",
      "train: iter 208  trainloss 1.36045  validloss 1.33095±0.00000  bestvalidloss 1.18412  last_update 84\n",
      "train: iter 209  trainloss 1.37592  validloss 1.35650±0.00000  bestvalidloss 1.18412  last_update 85\n",
      "train: iter 210  trainloss 1.35219  validloss 1.35178±0.00000  bestvalidloss 1.18412  last_update 86\n",
      "train: iter 211  trainloss 1.35884  validloss 1.42073±0.00000  bestvalidloss 1.18412  last_update 87\n",
      "train: iter 212  trainloss 1.39573  validloss 1.31638±0.00000  bestvalidloss 1.18412  last_update 88\n",
      "train: iter 213  trainloss 1.35764  validloss 1.43530±0.00000  bestvalidloss 1.18412  last_update 89\n",
      "train: iter 214  trainloss 1.34810  validloss 1.31617±0.00000  bestvalidloss 1.18412  last_update 90\n",
      "train: iter 215  trainloss 1.32738  validloss 1.41175±0.00000  bestvalidloss 1.18412  last_update 91\n",
      "train: iter 216  trainloss 1.33078  validloss 1.29335±0.00000  bestvalidloss 1.18412  last_update 92\n",
      "train: iter 217  trainloss 1.39319  validloss 1.34054±0.00000  bestvalidloss 1.18412  last_update 93\n",
      "train: iter 218  trainloss 1.37488  validloss 1.37944±0.00000  bestvalidloss 1.18412  last_update 94\n",
      "train: iter 219  trainloss 1.33216  validloss 1.46602±0.00000  bestvalidloss 1.18412  last_update 95\n",
      "train: iter 220  trainloss 1.35175  validloss 1.29946±0.00000  bestvalidloss 1.18412  last_update 96\n",
      "train: iter 221  trainloss 1.37631  validloss 1.32138±0.00000  bestvalidloss 1.18412  last_update 97\n",
      "train: iter 222  trainloss 1.33598  validloss 1.27397±0.00000  bestvalidloss 1.18412  last_update 98\n",
      "train: iter 223  trainloss 1.35047  validloss 1.39121±0.00000  bestvalidloss 1.18412  last_update 99\n",
      "train: iter 224  trainloss 1.37574  validloss 1.45555±0.00000  bestvalidloss 1.18412  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_pendulum_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-5.7384)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(3.0266)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18578329082112913\n",
      "tensor([-0.3224])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
