{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(9098.5771)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 25951.22094  validloss 101989.84207±0.00000  bestvalidloss 101989.84207  last_update 0\n",
      "train: iter 1  trainloss 2014.84369  validloss 6183.24885±0.00000  bestvalidloss 6183.24885  last_update 0\n",
      "train: iter 2  trainloss 1577.27729  validloss 5300.91368±0.00000  bestvalidloss 5300.91368  last_update 0\n",
      "train: iter 3  trainloss 1128.69382  validloss 3369.61968±0.00000  bestvalidloss 3369.61968  last_update 0\n",
      "train: iter 4  trainloss 1018.66271  validloss 2975.35768±0.00000  bestvalidloss 2975.35768  last_update 0\n",
      "train: iter 5  trainloss 955.00086  validloss 2615.55996±0.00000  bestvalidloss 2615.55996  last_update 0\n",
      "train: iter 6  trainloss 909.97756  validloss 2680.40044±0.00000  bestvalidloss 2615.55996  last_update 1\n",
      "train: iter 7  trainloss 865.10320  validloss 2231.87209±0.00000  bestvalidloss 2231.87209  last_update 0\n",
      "train: iter 8  trainloss 826.68443  validloss 1951.45674±0.00000  bestvalidloss 1951.45674  last_update 0\n",
      "train: iter 9  trainloss 779.68552  validloss 1817.19079±0.00000  bestvalidloss 1817.19079  last_update 0\n",
      "train: iter 10  trainloss 787.32909  validloss 1722.68565±0.00000  bestvalidloss 1722.68565  last_update 0\n",
      "train: iter 11  trainloss 753.75717  validloss 1581.10296±0.00000  bestvalidloss 1581.10296  last_update 0\n",
      "train: iter 12  trainloss 709.14745  validloss 1824.80579±0.00000  bestvalidloss 1581.10296  last_update 1\n",
      "train: iter 13  trainloss 650.44698  validloss 1236.14518±0.00000  bestvalidloss 1236.14518  last_update 0\n",
      "train: iter 14  trainloss 614.98331  validloss 1329.88205±0.00000  bestvalidloss 1236.14518  last_update 1\n",
      "train: iter 15  trainloss 621.12009  validloss 1042.16532±0.00000  bestvalidloss 1042.16532  last_update 0\n",
      "train: iter 16  trainloss 584.76230  validloss 1345.99207±0.00000  bestvalidloss 1042.16532  last_update 1\n",
      "train: iter 17  trainloss 485.83807  validloss 934.79001±0.00000  bestvalidloss 934.79001  last_update 0\n",
      "train: iter 18  trainloss 406.70072  validloss 819.32826±0.00000  bestvalidloss 819.32826  last_update 0\n",
      "train: iter 19  trainloss 390.48654  validloss 718.32195±0.00000  bestvalidloss 718.32195  last_update 0\n",
      "train: iter 20  trainloss 322.42380  validloss 706.59618±0.00000  bestvalidloss 706.59618  last_update 0\n",
      "train: iter 21  trainloss 245.94658  validloss 551.92109±0.00000  bestvalidloss 551.92109  last_update 0\n",
      "train: iter 22  trainloss 206.12005  validloss 555.43632±0.00000  bestvalidloss 551.92109  last_update 1\n",
      "train: iter 23  trainloss 237.94209  validloss 540.59413±0.00000  bestvalidloss 540.59413  last_update 0\n",
      "train: iter 24  trainloss 313.27210  validloss 555.02183±0.00000  bestvalidloss 540.59413  last_update 1\n",
      "train: iter 25  trainloss 192.64274  validloss 724.30115±0.00000  bestvalidloss 540.59413  last_update 2\n",
      "train: iter 26  trainloss 85.15077  validloss 671.47886±0.00000  bestvalidloss 540.59413  last_update 3\n",
      "train: iter 27  trainloss 43.72891  validloss 412.44246±0.00000  bestvalidloss 412.44246  last_update 0\n",
      "train: iter 28  trainloss 78.92939  validloss 441.01976±0.00000  bestvalidloss 412.44246  last_update 1\n",
      "train: iter 29  trainloss 9.44412  validloss 393.23760±0.00000  bestvalidloss 393.23760  last_update 0\n",
      "train: iter 30  trainloss -21.13400  validloss 272.90453±0.00000  bestvalidloss 272.90453  last_update 0\n",
      "train: iter 31  trainloss -33.56805  validloss 276.65950±0.00000  bestvalidloss 272.90453  last_update 1\n",
      "train: iter 32  trainloss -20.80032  validloss 232.00927±0.00000  bestvalidloss 232.00927  last_update 0\n",
      "train: iter 33  trainloss -78.45147  validloss 262.50338±0.00000  bestvalidloss 232.00927  last_update 1\n",
      "train: iter 34  trainloss -67.85979  validloss 207.50669±0.00000  bestvalidloss 207.50669  last_update 0\n",
      "train: iter 35  trainloss -113.86464  validloss 112.48871±0.00000  bestvalidloss 112.48871  last_update 0\n",
      "train: iter 36  trainloss -139.54480  validloss 98.00300±0.00000  bestvalidloss 98.00300  last_update 0\n",
      "train: iter 37  trainloss -160.68516  validloss -10.07559±0.00000  bestvalidloss -10.07559  last_update 0\n",
      "train: iter 38  trainloss -151.62458  validloss -49.25082±0.00000  bestvalidloss -49.25082  last_update 0\n",
      "train: iter 39  trainloss -181.32289  validloss 70.33581±0.00000  bestvalidloss -49.25082  last_update 1\n",
      "train: iter 40  trainloss -170.35323  validloss 124.41420±0.00000  bestvalidloss -49.25082  last_update 2\n",
      "train: iter 41  trainloss -181.07683  validloss -3.70104±0.00000  bestvalidloss -49.25082  last_update 3\n",
      "train: iter 42  trainloss -205.45164  validloss 110.44231±0.00000  bestvalidloss -49.25082  last_update 4\n",
      "train: iter 43  trainloss -225.18896  validloss 98.26859±0.00000  bestvalidloss -49.25082  last_update 5\n",
      "train: iter 44  trainloss -225.09169  validloss 49.28553±0.00000  bestvalidloss -49.25082  last_update 6\n",
      "train: iter 45  trainloss -224.64605  validloss -148.38874±0.00000  bestvalidloss -148.38874  last_update 0\n",
      "train: iter 46  trainloss -291.35042  validloss -5.88237±0.00000  bestvalidloss -148.38874  last_update 1\n",
      "train: iter 47  trainloss -248.19163  validloss -78.46896±0.00000  bestvalidloss -148.38874  last_update 2\n",
      "train: iter 48  trainloss 100.00069  validloss 77.37810±0.00000  bestvalidloss -148.38874  last_update 3\n",
      "train: iter 49  trainloss -172.57960  validloss 176.50308±0.00000  bestvalidloss -148.38874  last_update 4\n",
      "train: iter 50  trainloss -322.45225  validloss 41.88835±0.00000  bestvalidloss -148.38874  last_update 5\n",
      "train: iter 51  trainloss -281.50403  validloss -195.38783±0.00000  bestvalidloss -195.38783  last_update 0\n",
      "train: iter 52  trainloss -283.49733  validloss -96.59923±0.00000  bestvalidloss -195.38783  last_update 1\n",
      "train: iter 53  trainloss -360.10553  validloss 229.98757±0.00000  bestvalidloss -195.38783  last_update 2\n",
      "train: iter 54  trainloss -256.05233  validloss -299.71473±0.00000  bestvalidloss -299.71473  last_update 0\n",
      "train: iter 55  trainloss -299.02767  validloss -285.48935±0.00000  bestvalidloss -299.71473  last_update 1\n",
      "train: iter 56  trainloss -410.09759  validloss -168.55000±0.00000  bestvalidloss -299.71473  last_update 2\n",
      "train: iter 57  trainloss -441.54300  validloss -89.65138±0.00000  bestvalidloss -299.71473  last_update 3\n",
      "train: iter 58  trainloss -354.90735  validloss -167.17839±0.00000  bestvalidloss -299.71473  last_update 4\n",
      "train: iter 59  trainloss -316.94226  validloss 102.22950±0.00000  bestvalidloss -299.71473  last_update 5\n",
      "train: iter 60  trainloss -450.09602  validloss -257.30140±0.00000  bestvalidloss -299.71473  last_update 6\n",
      "train: iter 61  trainloss -283.12063  validloss -290.62981±0.00000  bestvalidloss -299.71473  last_update 7\n",
      "train: iter 62  trainloss -455.69038  validloss -290.10163±0.00000  bestvalidloss -299.71473  last_update 8\n",
      "train: iter 63  trainloss -382.68880  validloss -381.18225±0.00000  bestvalidloss -381.18225  last_update 0\n",
      "train: iter 64  trainloss -334.59681  validloss -138.27607±0.00000  bestvalidloss -381.18225  last_update 1\n",
      "train: iter 65  trainloss -464.61670  validloss -55.14110±0.00000  bestvalidloss -381.18225  last_update 2\n",
      "train: iter 66  trainloss -508.16762  validloss -425.23234±0.00000  bestvalidloss -425.23234  last_update 0\n",
      "train: iter 67  trainloss -429.23231  validloss -196.31208±0.00000  bestvalidloss -425.23234  last_update 1\n",
      "train: iter 68  trainloss -362.31766  validloss -291.18536±0.00000  bestvalidloss -425.23234  last_update 2\n",
      "train: iter 69  trainloss -394.01447  validloss -316.40223±0.00000  bestvalidloss -425.23234  last_update 3\n",
      "train: iter 70  trainloss -368.60980  validloss -305.73778±0.00000  bestvalidloss -425.23234  last_update 4\n",
      "train: iter 71  trainloss 6.32519  validloss -352.61313±0.00000  bestvalidloss -425.23234  last_update 5\n",
      "train: iter 72  trainloss -255.69382  validloss 2.63073±0.00000  bestvalidloss -425.23234  last_update 6\n",
      "train: iter 73  trainloss -417.83442  validloss -277.21868±0.00000  bestvalidloss -425.23234  last_update 7\n",
      "train: iter 74  trainloss -457.70090  validloss -141.28931±0.00000  bestvalidloss -425.23234  last_update 8\n",
      "train: iter 75  trainloss -511.63629  validloss -252.08517±0.00000  bestvalidloss -425.23234  last_update 9\n",
      "train: iter 76  trainloss -501.87900  validloss -441.42763±0.00000  bestvalidloss -441.42763  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -518.18137  validloss -420.84388±0.00000  bestvalidloss -441.42763  last_update 1\n",
      "train: iter 78  trainloss -467.23788  validloss -380.42639±0.00000  bestvalidloss -441.42763  last_update 2\n",
      "train: iter 79  trainloss -520.03035  validloss -368.80736±0.00000  bestvalidloss -441.42763  last_update 3\n",
      "train: iter 80  trainloss -516.58121  validloss -192.48160±0.00000  bestvalidloss -441.42763  last_update 4\n",
      "train: iter 81  trainloss -622.84472  validloss -485.35826±0.00000  bestvalidloss -485.35826  last_update 0\n",
      "train: iter 82  trainloss -552.21193  validloss -520.43221±0.00000  bestvalidloss -520.43221  last_update 0\n",
      "train: iter 83  trainloss -553.01182  validloss -276.69079±0.00000  bestvalidloss -520.43221  last_update 1\n",
      "train: iter 84  trainloss -656.37233  validloss -508.52405±0.00000  bestvalidloss -520.43221  last_update 2\n",
      "train: iter 85  trainloss -369.28093  validloss -167.50653±0.00000  bestvalidloss -520.43221  last_update 3\n",
      "train: iter 86  trainloss -475.01666  validloss -283.46021±0.00000  bestvalidloss -520.43221  last_update 4\n",
      "train: iter 87  trainloss -487.89413  validloss -385.61524±0.00000  bestvalidloss -520.43221  last_update 5\n",
      "train: iter 88  trainloss -477.08556  validloss -138.06210±0.00000  bestvalidloss -520.43221  last_update 6\n",
      "train: iter 89  trainloss 278.75494  validloss -517.85270±0.00000  bestvalidloss -520.43221  last_update 7\n",
      "train: iter 90  trainloss 30.97620  validloss 169.59574±0.00000  bestvalidloss -520.43221  last_update 8\n",
      "train: iter 91  trainloss -215.86525  validloss -67.82211±0.00000  bestvalidloss -520.43221  last_update 9\n",
      "train: iter 92  trainloss -399.49964  validloss -256.35343±0.00000  bestvalidloss -520.43221  last_update 10\n",
      "train: iter 93  trainloss -416.90486  validloss -389.93491±0.00000  bestvalidloss -520.43221  last_update 11\n",
      "train: iter 94  trainloss -429.93278  validloss -126.64967±0.00000  bestvalidloss -520.43221  last_update 12\n",
      "train: iter 95  trainloss -542.60742  validloss -496.52333±0.00000  bestvalidloss -520.43221  last_update 13\n",
      "train: iter 96  trainloss -592.43846  validloss -479.55246±0.00000  bestvalidloss -520.43221  last_update 14\n",
      "train: iter 97  trainloss -545.15673  validloss -574.42489±0.00000  bestvalidloss -574.42489  last_update 0\n",
      "train: iter 98  trainloss -568.89804  validloss -547.53581±0.00000  bestvalidloss -574.42489  last_update 1\n",
      "train: iter 99  trainloss -617.46740  validloss -408.81273±0.00000  bestvalidloss -574.42489  last_update 2\n",
      "train: iter 100  trainloss -630.79834  validloss -566.96217±0.00000  bestvalidloss -574.42489  last_update 3\n",
      "train: iter 101  trainloss -590.51775  validloss -447.77329±0.00000  bestvalidloss -574.42489  last_update 4\n",
      "train: iter 102  trainloss -671.39574  validloss -580.82471±0.00000  bestvalidloss -580.82471  last_update 0\n",
      "train: iter 103  trainloss -425.11322  validloss -593.40872±0.00000  bestvalidloss -593.40872  last_update 0\n",
      "train: iter 104  trainloss -646.66791  validloss -599.64939±0.00000  bestvalidloss -599.64939  last_update 0\n",
      "train: iter 105  trainloss -652.42396  validloss -629.77401±0.00000  bestvalidloss -629.77401  last_update 0\n",
      "train: iter 106  trainloss -696.20915  validloss -565.84247±0.00000  bestvalidloss -629.77401  last_update 1\n",
      "train: iter 107  trainloss -653.30493  validloss -542.26122±0.00000  bestvalidloss -629.77401  last_update 2\n",
      "train: iter 108  trainloss -682.96110  validloss -411.05530±0.00000  bestvalidloss -629.77401  last_update 3\n",
      "train: iter 109  trainloss -651.18208  validloss -593.54315±0.00000  bestvalidloss -629.77401  last_update 4\n",
      "train: iter 110  trainloss -696.44509  validloss -619.37357±0.00000  bestvalidloss -629.77401  last_update 5\n",
      "train: iter 111  trainloss -739.45038  validloss -614.80497±0.00000  bestvalidloss -629.77401  last_update 6\n",
      "train: iter 112  trainloss -732.44065  validloss -600.84702±0.00000  bestvalidloss -629.77401  last_update 7\n",
      "train: iter 113  trainloss -749.16789  validloss -637.22104±0.00000  bestvalidloss -637.22104  last_update 0\n",
      "train: iter 114  trainloss -726.95554  validloss -610.80113±0.00000  bestvalidloss -637.22104  last_update 1\n",
      "train: iter 115  trainloss -731.64158  validloss -653.70762±0.00000  bestvalidloss -653.70762  last_update 0\n",
      "train: iter 116  trainloss -760.88857  validloss -556.35907±0.00000  bestvalidloss -653.70762  last_update 1\n",
      "train: iter 117  trainloss -772.60008  validloss -673.18834±0.00000  bestvalidloss -673.18834  last_update 0\n",
      "train: iter 118  trainloss -779.98243  validloss -411.66354±0.00000  bestvalidloss -673.18834  last_update 1\n",
      "train: iter 119  trainloss -812.12943  validloss -700.56777±0.00000  bestvalidloss -700.56777  last_update 0\n",
      "train: iter 120  trainloss -681.44679  validloss -697.37627±0.00000  bestvalidloss -700.56777  last_update 1\n",
      "train: iter 121  trainloss -768.43543  validloss -518.39859±0.00000  bestvalidloss -700.56777  last_update 2\n",
      "train: iter 122  trainloss -843.52258  validloss -734.79878±0.00000  bestvalidloss -734.79878  last_update 0\n",
      "train: iter 123  trainloss -697.59628  validloss -701.38528±0.00000  bestvalidloss -734.79878  last_update 1\n",
      "train: iter 124  trainloss -663.81508  validloss -590.01845±0.00000  bestvalidloss -734.79878  last_update 2\n",
      "train: iter 125  trainloss -794.33424  validloss -658.94814±0.00000  bestvalidloss -734.79878  last_update 3\n",
      "train: iter 126  trainloss -784.97786  validloss -645.61658±0.00000  bestvalidloss -734.79878  last_update 4\n",
      "train: iter 127  trainloss -803.21585  validloss -723.00616±0.00000  bestvalidloss -734.79878  last_update 5\n",
      "train: iter 128  trainloss -730.31617  validloss 35.12142±0.00000  bestvalidloss -734.79878  last_update 6\n",
      "train: iter 129  trainloss -726.76037  validloss -718.66138±0.00000  bestvalidloss -734.79878  last_update 7\n",
      "train: iter 130  trainloss -772.76343  validloss -605.06009±0.00000  bestvalidloss -734.79878  last_update 8\n",
      "train: iter 131  trainloss -832.60436  validloss -694.58036±0.00000  bestvalidloss -734.79878  last_update 9\n",
      "train: iter 132  trainloss -676.73469  validloss -757.87381±0.00000  bestvalidloss -757.87381  last_update 0\n",
      "train: iter 133  trainloss -782.43478  validloss -655.30282±0.00000  bestvalidloss -757.87381  last_update 1\n",
      "train: iter 134  trainloss -760.92007  validloss -674.37135±0.00000  bestvalidloss -757.87381  last_update 2\n",
      "train: iter 135  trainloss -730.40896  validloss -683.46231±0.00000  bestvalidloss -757.87381  last_update 3\n",
      "train: iter 136  trainloss -787.42965  validloss -695.08452±0.00000  bestvalidloss -757.87381  last_update 4\n",
      "train: iter 137  trainloss -779.61195  validloss -655.07247±0.00000  bestvalidloss -757.87381  last_update 5\n",
      "train: iter 138  trainloss -773.91185  validloss -681.79928±0.00000  bestvalidloss -757.87381  last_update 6\n",
      "train: iter 139  trainloss -846.87503  validloss -674.84567±0.00000  bestvalidloss -757.87381  last_update 7\n",
      "train: iter 140  trainloss -886.89163  validloss -775.07331±0.00000  bestvalidloss -775.07331  last_update 0\n",
      "train: iter 141  trainloss -853.35415  validloss -808.90108±0.00000  bestvalidloss -808.90108  last_update 0\n",
      "train: iter 142  trainloss -822.24743  validloss -726.62874±0.00000  bestvalidloss -808.90108  last_update 1\n",
      "train: iter 143  trainloss -872.36856  validloss -834.12364±0.00000  bestvalidloss -834.12364  last_update 0\n",
      "train: iter 144  trainloss -875.48748  validloss -755.69292±0.00000  bestvalidloss -834.12364  last_update 1\n",
      "train: iter 145  trainloss -749.28683  validloss -817.97994±0.00000  bestvalidloss -834.12364  last_update 2\n",
      "train: iter 146  trainloss -818.31253  validloss -533.54494±0.00000  bestvalidloss -834.12364  last_update 3\n",
      "train: iter 147  trainloss -789.69836  validloss -773.93200±0.00000  bestvalidloss -834.12364  last_update 4\n",
      "train: iter 148  trainloss -912.87802  validloss -811.40985±0.00000  bestvalidloss -834.12364  last_update 5\n",
      "train: iter 149  trainloss -871.78100  validloss -824.70703±0.00000  bestvalidloss -834.12364  last_update 6\n",
      "train: iter 150  trainloss -751.51888  validloss -812.27168±0.00000  bestvalidloss -834.12364  last_update 7\n",
      "train: iter 151  trainloss -823.49053  validloss -464.26407±0.00000  bestvalidloss -834.12364  last_update 8\n",
      "train: iter 152  trainloss -902.80479  validloss -829.94222±0.00000  bestvalidloss -834.12364  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -800.53114  validloss -749.13665±0.00000  bestvalidloss -834.12364  last_update 10\n",
      "train: iter 154  trainloss -892.05565  validloss -840.61635±0.00000  bestvalidloss -840.61635  last_update 0\n",
      "train: iter 155  trainloss -826.58173  validloss -436.41776±0.00000  bestvalidloss -840.61635  last_update 1\n",
      "train: iter 156  trainloss -905.04122  validloss -785.40236±0.00000  bestvalidloss -840.61635  last_update 2\n",
      "train: iter 157  trainloss -903.92272  validloss -726.22570±0.00000  bestvalidloss -840.61635  last_update 3\n",
      "train: iter 158  trainloss -750.96288  validloss -862.30918±0.00000  bestvalidloss -862.30918  last_update 0\n",
      "train: iter 159  trainloss -911.61938  validloss -825.70972±0.00000  bestvalidloss -862.30918  last_update 1\n",
      "train: iter 160  trainloss -846.66793  validloss -504.78517±0.00000  bestvalidloss -862.30918  last_update 2\n",
      "train: iter 161  trainloss -888.59374  validloss -805.23704±0.00000  bestvalidloss -862.30918  last_update 3\n",
      "train: iter 162  trainloss -983.54257  validloss -894.48927±0.00000  bestvalidloss -894.48927  last_update 0\n",
      "train: iter 163  trainloss -887.04786  validloss -859.83709±0.00000  bestvalidloss -894.48927  last_update 1\n",
      "train: iter 164  trainloss -901.36062  validloss -857.29825±0.00000  bestvalidloss -894.48927  last_update 2\n",
      "train: iter 165  trainloss -915.43014  validloss -838.43544±0.00000  bestvalidloss -894.48927  last_update 3\n",
      "train: iter 166  trainloss -928.83486  validloss -783.47874±0.00000  bestvalidloss -894.48927  last_update 4\n",
      "train: iter 167  trainloss -877.61013  validloss -841.23311±0.00000  bestvalidloss -894.48927  last_update 5\n",
      "train: iter 168  trainloss -835.60724  validloss -112.88047±0.00000  bestvalidloss -894.48927  last_update 6\n",
      "train: iter 169  trainloss -869.11425  validloss -751.66179±0.00000  bestvalidloss -894.48927  last_update 7\n",
      "train: iter 170  trainloss -934.51595  validloss -803.94174±0.00000  bestvalidloss -894.48927  last_update 8\n",
      "train: iter 171  trainloss -1011.99082  validloss -920.78227±0.00000  bestvalidloss -920.78227  last_update 0\n",
      "train: iter 172  trainloss -838.50100  validloss -873.05940±0.00000  bestvalidloss -920.78227  last_update 1\n",
      "train: iter 173  trainloss -962.49855  validloss -842.90349±0.00000  bestvalidloss -920.78227  last_update 2\n",
      "train: iter 174  trainloss -936.19785  validloss -881.33922±0.00000  bestvalidloss -920.78227  last_update 3\n",
      "train: iter 175  trainloss -942.22048  validloss -864.90065±0.00000  bestvalidloss -920.78227  last_update 4\n",
      "train: iter 176  trainloss -941.26037  validloss -702.28042±0.00000  bestvalidloss -920.78227  last_update 5\n",
      "train: iter 177  trainloss -757.09449  validloss -885.99224±0.00000  bestvalidloss -920.78227  last_update 6\n",
      "train: iter 178  trainloss -809.95347  validloss -820.64585±0.00000  bestvalidloss -920.78227  last_update 7\n",
      "train: iter 179  trainloss -982.94669  validloss -657.06460±0.00000  bestvalidloss -920.78227  last_update 8\n",
      "train: iter 180  trainloss -1047.68723  validloss -883.13869±0.00000  bestvalidloss -920.78227  last_update 9\n",
      "train: iter 181  trainloss -926.30882  validloss -909.46501±0.00000  bestvalidloss -920.78227  last_update 10\n",
      "train: iter 182  trainloss -1003.30688  validloss -742.35876±0.00000  bestvalidloss -920.78227  last_update 11\n",
      "train: iter 183  trainloss -910.02257  validloss -922.69225±0.00000  bestvalidloss -922.69225  last_update 0\n",
      "train: iter 184  trainloss -932.68579  validloss -818.47366±0.00000  bestvalidloss -922.69225  last_update 1\n",
      "train: iter 185  trainloss -955.44261  validloss -859.03277±0.00000  bestvalidloss -922.69225  last_update 2\n",
      "train: iter 186  trainloss -917.49761  validloss -849.76639±0.00000  bestvalidloss -922.69225  last_update 3\n",
      "train: iter 187  trainloss -1042.09257  validloss -856.10397±0.00000  bestvalidloss -922.69225  last_update 4\n",
      "train: iter 188  trainloss -893.09499  validloss -886.87771±0.00000  bestvalidloss -922.69225  last_update 5\n",
      "train: iter 189  trainloss -898.11364  validloss -860.96957±0.00000  bestvalidloss -922.69225  last_update 6\n",
      "train: iter 190  trainloss -1041.79132  validloss -924.94454±0.00000  bestvalidloss -924.94454  last_update 0\n",
      "train: iter 191  trainloss -1052.01622  validloss -940.02953±0.00000  bestvalidloss -940.02953  last_update 0\n",
      "train: iter 192  trainloss -1021.73276  validloss -941.80837±0.00000  bestvalidloss -941.80837  last_update 0\n",
      "train: iter 193  trainloss -1001.81749  validloss -954.88720±0.00000  bestvalidloss -954.88720  last_update 0\n",
      "train: iter 194  trainloss -902.79244  validloss -973.93665±0.00000  bestvalidloss -973.93665  last_update 0\n",
      "train: iter 195  trainloss -982.84913  validloss -888.26918±0.00000  bestvalidloss -973.93665  last_update 1\n",
      "train: iter 196  trainloss -986.56473  validloss -699.77849±0.00000  bestvalidloss -973.93665  last_update 2\n",
      "train: iter 197  trainloss -1010.27364  validloss -727.95136±0.00000  bestvalidloss -973.93665  last_update 3\n",
      "train: iter 198  trainloss -850.34107  validloss -864.09336±0.00000  bestvalidloss -973.93665  last_update 4\n",
      "train: iter 199  trainloss -1009.03342  validloss -877.80216±0.00000  bestvalidloss -973.93665  last_update 5\n",
      "train: iter 200  trainloss -1002.91038  validloss -984.65173±0.00000  bestvalidloss -984.65173  last_update 0\n",
      "train: iter 201  trainloss -884.18969  validloss -910.45034±0.00000  bestvalidloss -984.65173  last_update 1\n",
      "train: iter 202  trainloss -1039.04048  validloss -842.89077±0.00000  bestvalidloss -984.65173  last_update 2\n",
      "train: iter 203  trainloss -1038.94916  validloss -961.70684±0.00000  bestvalidloss -984.65173  last_update 3\n",
      "train: iter 204  trainloss -1104.00654  validloss -984.92634±0.00000  bestvalidloss -984.92634  last_update 0\n",
      "train: iter 205  trainloss -1103.09741  validloss -1017.81697±0.00000  bestvalidloss -1017.81697  last_update 0\n",
      "train: iter 206  trainloss -997.99515  validloss -966.50390±0.00000  bestvalidloss -1017.81697  last_update 1\n",
      "train: iter 207  trainloss -1069.79346  validloss -924.57024±0.00000  bestvalidloss -1017.81697  last_update 2\n",
      "train: iter 208  trainloss -976.19843  validloss -883.47677±0.00000  bestvalidloss -1017.81697  last_update 3\n",
      "train: iter 209  trainloss -1032.00321  validloss -940.78642±0.00000  bestvalidloss -1017.81697  last_update 4\n",
      "train: iter 210  trainloss -1006.38039  validloss -907.65246±0.00000  bestvalidloss -1017.81697  last_update 5\n",
      "train: iter 211  trainloss -842.36482  validloss -712.32419±0.00000  bestvalidloss -1017.81697  last_update 6\n",
      "train: iter 212  trainloss -1020.89193  validloss -866.96287±0.00000  bestvalidloss -1017.81697  last_update 7\n",
      "train: iter 213  trainloss -808.55257  validloss -1045.48270±0.00000  bestvalidloss -1045.48270  last_update 0\n",
      "train: iter 214  trainloss -1074.25124  validloss -861.05183±0.00000  bestvalidloss -1045.48270  last_update 1\n",
      "train: iter 215  trainloss -1118.43501  validloss -1012.70098±0.00000  bestvalidloss -1045.48270  last_update 2\n",
      "train: iter 216  trainloss -1052.09985  validloss -788.70021±0.00000  bestvalidloss -1045.48270  last_update 3\n",
      "train: iter 217  trainloss -1100.22738  validloss -979.58228±0.00000  bestvalidloss -1045.48270  last_update 4\n",
      "train: iter 218  trainloss -1022.81553  validloss -1005.73545±0.00000  bestvalidloss -1045.48270  last_update 5\n",
      "train: iter 219  trainloss -893.55469  validloss -981.91339±0.00000  bestvalidloss -1045.48270  last_update 6\n",
      "train: iter 220  trainloss -1030.34935  validloss -929.31143±0.00000  bestvalidloss -1045.48270  last_update 7\n",
      "train: iter 221  trainloss -1103.24543  validloss -983.83127±0.00000  bestvalidloss -1045.48270  last_update 8\n",
      "train: iter 222  trainloss -863.83040  validloss -1010.94897±0.00000  bestvalidloss -1045.48270  last_update 9\n",
      "train: iter 223  trainloss -1057.78688  validloss -842.12856±0.00000  bestvalidloss -1045.48270  last_update 10\n",
      "train: iter 224  trainloss -1047.08200  validloss -843.04287±0.00000  bestvalidloss -1045.48270  last_update 11\n",
      "train: iter 225  trainloss -1081.73631  validloss -964.83095±0.00000  bestvalidloss -1045.48270  last_update 12\n",
      "train: iter 226  trainloss -1040.39262  validloss -802.65557±0.00000  bestvalidloss -1045.48270  last_update 13\n",
      "train: iter 227  trainloss -1102.81053  validloss -989.12176±0.00000  bestvalidloss -1045.48270  last_update 14\n",
      "train: iter 228  trainloss -1044.54656  validloss -966.76867±0.00000  bestvalidloss -1045.48270  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 229  trainloss -1118.53646  validloss -925.21472±0.00000  bestvalidloss -1045.48270  last_update 16\n",
      "train: iter 230  trainloss -1051.22552  validloss -713.52744±0.00000  bestvalidloss -1045.48270  last_update 17\n",
      "train: iter 231  trainloss -1152.64750  validloss -887.37711±0.00000  bestvalidloss -1045.48270  last_update 18\n",
      "train: iter 232  trainloss -1096.93610  validloss -981.26285±0.00000  bestvalidloss -1045.48270  last_update 19\n",
      "train: iter 233  trainloss -991.74218  validloss -720.00173±0.00000  bestvalidloss -1045.48270  last_update 20\n",
      "train: iter 234  trainloss -1109.46131  validloss -997.53208±0.00000  bestvalidloss -1045.48270  last_update 21\n",
      "train: iter 235  trainloss -1117.06659  validloss -1000.04915±0.00000  bestvalidloss -1045.48270  last_update 22\n",
      "train: iter 236  trainloss -975.50618  validloss -532.35480±0.00000  bestvalidloss -1045.48270  last_update 23\n",
      "train: iter 237  trainloss -1153.01810  validloss -911.43139±0.00000  bestvalidloss -1045.48270  last_update 24\n",
      "train: iter 238  trainloss -1074.89831  validloss -890.02020±0.00000  bestvalidloss -1045.48270  last_update 25\n",
      "train: iter 239  trainloss -1148.56205  validloss -1002.61185±0.00000  bestvalidloss -1045.48270  last_update 26\n",
      "train: iter 240  trainloss -1147.27246  validloss -962.74047±0.00000  bestvalidloss -1045.48270  last_update 27\n",
      "train: iter 241  trainloss -1054.90540  validloss -887.01798±0.00000  bestvalidloss -1045.48270  last_update 28\n",
      "train: iter 242  trainloss -1064.65775  validloss -772.90748±0.00000  bestvalidloss -1045.48270  last_update 29\n",
      "train: iter 243  trainloss -1183.18020  validloss -840.91214±0.00000  bestvalidloss -1045.48270  last_update 30\n",
      "train: iter 244  trainloss -1214.30929  validloss -1061.86991±0.00000  bestvalidloss -1061.86991  last_update 0\n",
      "train: iter 245  trainloss -1190.97832  validloss -1068.36128±0.00000  bestvalidloss -1068.36128  last_update 0\n",
      "train: iter 246  trainloss -1148.17602  validloss -997.11636±0.00000  bestvalidloss -1068.36128  last_update 1\n",
      "train: iter 247  trainloss -1125.90535  validloss -905.07365±0.00000  bestvalidloss -1068.36128  last_update 2\n",
      "train: iter 248  trainloss -895.99112  validloss -993.19757±0.00000  bestvalidloss -1068.36128  last_update 3\n",
      "train: iter 249  trainloss -1149.66823  validloss -456.60397±0.00000  bestvalidloss -1068.36128  last_update 4\n",
      "train: iter 250  trainloss -1235.98713  validloss -999.88778±0.00000  bestvalidloss -1068.36128  last_update 5\n",
      "train: iter 251  trainloss -1072.55976  validloss -1061.47249±0.00000  bestvalidloss -1068.36128  last_update 6\n",
      "train: iter 252  trainloss -1133.24640  validloss -899.73530±0.00000  bestvalidloss -1068.36128  last_update 7\n",
      "train: iter 253  trainloss -893.34188  validloss -1089.01671±0.00000  bestvalidloss -1089.01671  last_update 0\n",
      "train: iter 254  trainloss -1069.39730  validloss -930.88956±0.00000  bestvalidloss -1089.01671  last_update 1\n",
      "train: iter 255  trainloss -1160.84864  validloss -1016.83290±0.00000  bestvalidloss -1089.01671  last_update 2\n",
      "train: iter 256  trainloss -1088.26917  validloss -819.94370±0.00000  bestvalidloss -1089.01671  last_update 3\n",
      "train: iter 257  trainloss -1212.86708  validloss -972.71621±0.00000  bestvalidloss -1089.01671  last_update 4\n",
      "train: iter 258  trainloss -1182.00601  validloss -999.53835±0.00000  bestvalidloss -1089.01671  last_update 5\n",
      "train: iter 259  trainloss -1064.45765  validloss -1051.01324±0.00000  bestvalidloss -1089.01671  last_update 6\n",
      "train: iter 260  trainloss -1237.36283  validloss -1029.13663±0.00000  bestvalidloss -1089.01671  last_update 7\n",
      "train: iter 261  trainloss -1220.90733  validloss -958.71520±0.00000  bestvalidloss -1089.01671  last_update 8\n",
      "train: iter 262  trainloss -1245.26699  validloss -1064.03153±0.00000  bestvalidloss -1089.01671  last_update 9\n",
      "train: iter 263  trainloss -1200.47927  validloss -1127.37090±0.00000  bestvalidloss -1127.37090  last_update 0\n",
      "train: iter 264  trainloss -1070.35965  validloss -1040.48579±0.00000  bestvalidloss -1127.37090  last_update 1\n",
      "train: iter 265  trainloss -1256.85159  validloss -1061.80003±0.00000  bestvalidloss -1127.37090  last_update 2\n",
      "train: iter 266  trainloss -1058.56325  validloss -998.64160±0.00000  bestvalidloss -1127.37090  last_update 3\n",
      "train: iter 267  trainloss -1070.81759  validloss -885.06090±0.00000  bestvalidloss -1127.37090  last_update 4\n",
      "train: iter 268  trainloss -1105.55735  validloss -981.65506±0.00000  bestvalidloss -1127.37090  last_update 5\n",
      "train: iter 269  trainloss -1203.71575  validloss -1096.31108±0.00000  bestvalidloss -1127.37090  last_update 6\n",
      "train: iter 270  trainloss -1177.03052  validloss -858.23040±0.00000  bestvalidloss -1127.37090  last_update 7\n",
      "train: iter 271  trainloss -1235.46370  validloss -1072.81646±0.00000  bestvalidloss -1127.37090  last_update 8\n",
      "train: iter 272  trainloss -1223.52960  validloss -1125.89781±0.00000  bestvalidloss -1127.37090  last_update 9\n",
      "train: iter 273  trainloss -1174.58941  validloss -1124.37549±0.00000  bestvalidloss -1127.37090  last_update 10\n",
      "train: iter 274  trainloss -1014.04363  validloss -944.36124±0.00000  bestvalidloss -1127.37090  last_update 11\n",
      "train: iter 275  trainloss -1283.33960  validloss -1096.52806±0.00000  bestvalidloss -1127.37090  last_update 12\n",
      "train: iter 276  trainloss -1265.31160  validloss -1018.48640±0.00000  bestvalidloss -1127.37090  last_update 13\n",
      "train: iter 277  trainloss -1168.63657  validloss -1053.21730±0.00000  bestvalidloss -1127.37090  last_update 14\n",
      "train: iter 278  trainloss -1105.12179  validloss -260.46696±0.00000  bestvalidloss -1127.37090  last_update 15\n",
      "train: iter 279  trainloss -1268.29990  validloss -986.53658±0.00000  bestvalidloss -1127.37090  last_update 16\n",
      "train: iter 280  trainloss -1088.10695  validloss -949.97242±0.00000  bestvalidloss -1127.37090  last_update 17\n",
      "train: iter 281  trainloss -1265.39272  validloss -979.28976±0.00000  bestvalidloss -1127.37090  last_update 18\n",
      "train: iter 282  trainloss -1270.78426  validloss -1006.29198±0.00000  bestvalidloss -1127.37090  last_update 19\n",
      "train: iter 283  trainloss -1270.67985  validloss -1053.85229±0.00000  bestvalidloss -1127.37090  last_update 20\n",
      "train: iter 284  trainloss -1050.12345  validloss -1055.35167±0.00000  bestvalidloss -1127.37090  last_update 21\n",
      "train: iter 285  trainloss -1199.89822  validloss -957.10709±0.00000  bestvalidloss -1127.37090  last_update 22\n",
      "train: iter 286  trainloss -1226.67792  validloss -848.87534±0.00000  bestvalidloss -1127.37090  last_update 23\n",
      "train: iter 287  trainloss -1325.31687  validloss -1190.65828±0.00000  bestvalidloss -1190.65828  last_update 0\n",
      "train: iter 288  trainloss -909.76287  validloss -1215.73795±0.00000  bestvalidloss -1215.73795  last_update 0\n",
      "train: iter 289  trainloss -1019.06817  validloss -449.27763±0.00000  bestvalidloss -1215.73795  last_update 1\n",
      "train: iter 290  trainloss -1254.57667  validloss -1097.20514±0.00000  bestvalidloss -1215.73795  last_update 2\n",
      "train: iter 291  trainloss -1260.36215  validloss -1017.13437±0.00000  bestvalidloss -1215.73795  last_update 3\n",
      "train: iter 292  trainloss -1234.51600  validloss -1107.41070±0.00000  bestvalidloss -1215.73795  last_update 4\n",
      "train: iter 293  trainloss -1287.22198  validloss -1145.30214±0.00000  bestvalidloss -1215.73795  last_update 5\n",
      "train: iter 294  trainloss -1193.14798  validloss -1181.80152±0.00000  bestvalidloss -1215.73795  last_update 6\n",
      "train: iter 295  trainloss -1140.78006  validloss -1116.68947±0.00000  bestvalidloss -1215.73795  last_update 7\n",
      "train: iter 296  trainloss -1317.99104  validloss -1223.96694±0.00000  bestvalidloss -1223.96694  last_update 0\n",
      "train: iter 297  trainloss -1183.55346  validloss -1239.97656±0.00000  bestvalidloss -1239.97656  last_update 0\n",
      "train: iter 298  trainloss -1305.71138  validloss -1096.02730±0.00000  bestvalidloss -1239.97656  last_update 1\n",
      "train: iter 299  trainloss -1300.53882  validloss -1201.56704±0.00000  bestvalidloss -1239.97656  last_update 2\n",
      "train: iter 300  trainloss -1278.08535  validloss -1135.02010±0.00000  bestvalidloss -1239.97656  last_update 3\n",
      "train: iter 301  trainloss -1104.60663  validloss -1195.32661±0.00000  bestvalidloss -1239.97656  last_update 4\n",
      "train: iter 302  trainloss -1267.40098  validloss -1067.13117±0.00000  bestvalidloss -1239.97656  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 303  trainloss -1124.29855  validloss -1137.49750±0.00000  bestvalidloss -1239.97656  last_update 6\n",
      "train: iter 304  trainloss -1332.41436  validloss -1140.31604±0.00000  bestvalidloss -1239.97656  last_update 7\n",
      "train: iter 305  trainloss -1140.48026  validloss -727.61542±0.00000  bestvalidloss -1239.97656  last_update 8\n",
      "train: iter 306  trainloss -1265.35341  validloss -1124.62976±0.00000  bestvalidloss -1239.97656  last_update 9\n",
      "train: iter 307  trainloss -1200.28919  validloss -1211.98147±0.00000  bestvalidloss -1239.97656  last_update 10\n",
      "train: iter 308  trainloss -1247.49383  validloss -1003.43612±0.00000  bestvalidloss -1239.97656  last_update 11\n",
      "train: iter 309  trainloss -1221.09436  validloss -1145.55408±0.00000  bestvalidloss -1239.97656  last_update 12\n",
      "train: iter 310  trainloss -1246.89182  validloss -883.06126±0.00000  bestvalidloss -1239.97656  last_update 13\n",
      "train: iter 311  trainloss -1302.59006  validloss -1218.22448±0.00000  bestvalidloss -1239.97656  last_update 14\n",
      "train: iter 312  trainloss -1275.46580  validloss -1187.26237±0.00000  bestvalidloss -1239.97656  last_update 15\n",
      "train: iter 313  trainloss -1237.18180  validloss -759.56560±0.00000  bestvalidloss -1239.97656  last_update 16\n",
      "train: iter 314  trainloss -1264.86985  validloss -1103.96835±0.00000  bestvalidloss -1239.97656  last_update 17\n",
      "train: iter 315  trainloss -1270.78974  validloss -1193.04518±0.00000  bestvalidloss -1239.97656  last_update 18\n",
      "train: iter 316  trainloss -1319.44020  validloss -1207.98574±0.00000  bestvalidloss -1239.97656  last_update 19\n",
      "train: iter 317  trainloss -1216.80578  validloss -1152.15862±0.00000  bestvalidloss -1239.97656  last_update 20\n",
      "train: iter 318  trainloss -1260.52328  validloss -1181.81849±0.00000  bestvalidloss -1239.97656  last_update 21\n",
      "train: iter 319  trainloss -1369.42112  validloss -1224.07552±0.00000  bestvalidloss -1239.97656  last_update 22\n",
      "train: iter 320  trainloss -1341.09296  validloss -1239.29420±0.00000  bestvalidloss -1239.97656  last_update 23\n",
      "train: iter 321  trainloss -1154.05204  validloss -839.05646±0.00000  bestvalidloss -1239.97656  last_update 24\n",
      "train: iter 322  trainloss -1086.29532  validloss -1198.62753±0.00000  bestvalidloss -1239.97656  last_update 25\n",
      "train: iter 323  trainloss -1289.60734  validloss -1098.91876±0.00000  bestvalidloss -1239.97656  last_update 26\n",
      "train: iter 324  trainloss -516.85309  validloss -363.61360±0.00000  bestvalidloss -1239.97656  last_update 27\n",
      "train: iter 325  trainloss -1125.57317  validloss -961.50019±0.00000  bestvalidloss -1239.97656  last_update 28\n",
      "train: iter 326  trainloss -1155.10410  validloss -952.36288±0.00000  bestvalidloss -1239.97656  last_update 29\n",
      "train: iter 327  trainloss -1222.37771  validloss -1057.17589±0.00000  bestvalidloss -1239.97656  last_update 30\n",
      "train: iter 328  trainloss -1316.90717  validloss -1158.40719±0.00000  bestvalidloss -1239.97656  last_update 31\n",
      "train: iter 329  trainloss -1316.65123  validloss -1118.22034±0.00000  bestvalidloss -1239.97656  last_update 32\n",
      "train: iter 330  trainloss -1329.12165  validloss -1165.03737±0.00000  bestvalidloss -1239.97656  last_update 33\n",
      "train: iter 331  trainloss -1332.08750  validloss -1192.22214±0.00000  bestvalidloss -1239.97656  last_update 34\n",
      "train: iter 332  trainloss -1341.17632  validloss -1253.13221±0.00000  bestvalidloss -1253.13221  last_update 0\n",
      "train: iter 333  trainloss -1242.27157  validloss -1182.44653±0.00000  bestvalidloss -1253.13221  last_update 1\n",
      "train: iter 334  trainloss -1327.61531  validloss -1166.28157±0.00000  bestvalidloss -1253.13221  last_update 2\n",
      "train: iter 335  trainloss -1351.16874  validloss -1158.72433±0.00000  bestvalidloss -1253.13221  last_update 3\n",
      "train: iter 336  trainloss -1248.01482  validloss -1264.44704±0.00000  bestvalidloss -1264.44704  last_update 0\n",
      "train: iter 337  trainloss -1306.05978  validloss -1188.09603±0.00000  bestvalidloss -1264.44704  last_update 1\n",
      "train: iter 338  trainloss -1203.94828  validloss -1180.88036±0.00000  bestvalidloss -1264.44704  last_update 2\n",
      "train: iter 339  trainloss -1202.95888  validloss -840.20263±0.00000  bestvalidloss -1264.44704  last_update 3\n",
      "train: iter 340  trainloss -1302.81694  validloss -1023.99034±0.00000  bestvalidloss -1264.44704  last_update 4\n",
      "train: iter 341  trainloss -1325.85633  validloss -1219.84104±0.00000  bestvalidloss -1264.44704  last_update 5\n",
      "train: iter 342  trainloss -1238.64777  validloss -1206.67513±0.00000  bestvalidloss -1264.44704  last_update 6\n",
      "train: iter 343  trainloss -1211.57764  validloss -1025.71211±0.00000  bestvalidloss -1264.44704  last_update 7\n",
      "train: iter 344  trainloss -1373.97249  validloss -1212.88506±0.00000  bestvalidloss -1264.44704  last_update 8\n",
      "train: iter 345  trainloss -1190.00419  validloss -1131.87600±0.00000  bestvalidloss -1264.44704  last_update 9\n",
      "train: iter 346  trainloss -1281.23825  validloss -899.60810±0.00000  bestvalidloss -1264.44704  last_update 10\n",
      "train: iter 347  trainloss -1123.21356  validloss -1215.94234±0.00000  bestvalidloss -1264.44704  last_update 11\n",
      "train: iter 348  trainloss -1348.82557  validloss -1218.11347±0.00000  bestvalidloss -1264.44704  last_update 12\n",
      "train: iter 349  trainloss -1364.39482  validloss -1212.56108±0.00000  bestvalidloss -1264.44704  last_update 13\n",
      "train: iter 350  trainloss -1391.33644  validloss -1237.61665±0.00000  bestvalidloss -1264.44704  last_update 14\n",
      "train: iter 351  trainloss -1322.83468  validloss -1208.49588±0.00000  bestvalidloss -1264.44704  last_update 15\n",
      "train: iter 352  trainloss -1389.39895  validloss -1246.66260±0.00000  bestvalidloss -1264.44704  last_update 16\n",
      "train: iter 353  trainloss -1170.58527  validloss -1235.00894±0.00000  bestvalidloss -1264.44704  last_update 17\n",
      "train: iter 354  trainloss -1096.46264  validloss -603.42203±0.00000  bestvalidloss -1264.44704  last_update 18\n",
      "train: iter 355  trainloss -1231.47374  validloss -1242.01276±0.00000  bestvalidloss -1264.44704  last_update 19\n",
      "train: iter 356  trainloss -1357.02124  validloss -1143.77012±0.00000  bestvalidloss -1264.44704  last_update 20\n",
      "train: iter 357  trainloss -1087.95256  validloss -1037.17692±0.00000  bestvalidloss -1264.44704  last_update 21\n",
      "train: iter 358  trainloss -1356.76355  validloss -1180.75369±0.00000  bestvalidloss -1264.44704  last_update 22\n",
      "train: iter 359  trainloss -1349.82013  validloss -1231.93495±0.00000  bestvalidloss -1264.44704  last_update 23\n",
      "train: iter 360  trainloss -1290.94021  validloss -982.57898±0.00000  bestvalidloss -1264.44704  last_update 24\n",
      "train: iter 361  trainloss -1356.30534  validloss -1212.79192±0.00000  bestvalidloss -1264.44704  last_update 25\n",
      "train: iter 362  trainloss -1385.47149  validloss -1105.90876±0.00000  bestvalidloss -1264.44704  last_update 26\n",
      "train: iter 363  trainloss -1336.39272  validloss -1166.90437±0.00000  bestvalidloss -1264.44704  last_update 27\n",
      "train: iter 364  trainloss -1326.94616  validloss -1168.41657±0.00000  bestvalidloss -1264.44704  last_update 28\n",
      "train: iter 365  trainloss -1359.30009  validloss -1236.77788±0.00000  bestvalidloss -1264.44704  last_update 29\n",
      "train: iter 366  trainloss -1330.88557  validloss -1180.54704±0.00000  bestvalidloss -1264.44704  last_update 30\n",
      "train: iter 367  trainloss -1382.82674  validloss -1237.73958±0.00000  bestvalidloss -1264.44704  last_update 31\n",
      "train: iter 368  trainloss -1340.83211  validloss -1289.23463±0.00000  bestvalidloss -1289.23463  last_update 0\n",
      "train: iter 369  trainloss -1367.96912  validloss -1155.22227±0.00000  bestvalidloss -1289.23463  last_update 1\n",
      "train: iter 370  trainloss -1378.66189  validloss -1216.09112±0.00000  bestvalidloss -1289.23463  last_update 2\n",
      "train: iter 371  trainloss -1322.68705  validloss -18.35597±0.00000  bestvalidloss -1289.23463  last_update 3\n",
      "train: iter 372  trainloss -1366.88560  validloss -1047.33200±0.00000  bestvalidloss -1289.23463  last_update 4\n",
      "train: iter 373  trainloss -1372.44379  validloss -1265.31658±0.00000  bestvalidloss -1289.23463  last_update 5\n",
      "train: iter 374  trainloss -1370.25796  validloss -1122.55900±0.00000  bestvalidloss -1289.23463  last_update 6\n",
      "train: iter 375  trainloss -1345.82810  validloss -1175.78815±0.00000  bestvalidloss -1289.23463  last_update 7\n",
      "train: iter 376  trainloss -1227.27405  validloss -1036.61617±0.00000  bestvalidloss -1289.23463  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 377  trainloss -1389.05420  validloss -1299.91937±0.00000  bestvalidloss -1299.91937  last_update 0\n",
      "train: iter 378  trainloss -1316.20064  validloss -1301.26958±0.00000  bestvalidloss -1301.26958  last_update 0\n",
      "train: iter 379  trainloss -1118.02610  validloss -1204.63194±0.00000  bestvalidloss -1301.26958  last_update 1\n",
      "train: iter 380  trainloss -826.78610  validloss -264.52213±0.00000  bestvalidloss -1301.26958  last_update 2\n",
      "train: iter 381  trainloss -974.40835  validloss -902.58277±0.00000  bestvalidloss -1301.26958  last_update 3\n",
      "train: iter 382  trainloss -1214.96792  validloss -1026.57666±0.00000  bestvalidloss -1301.26958  last_update 4\n",
      "train: iter 383  trainloss -1254.02030  validloss -1067.64235±0.00000  bestvalidloss -1301.26958  last_update 5\n",
      "train: iter 384  trainloss -1232.54703  validloss -1172.69135±0.00000  bestvalidloss -1301.26958  last_update 6\n",
      "train: iter 385  trainloss -1188.47447  validloss -1074.83028±0.00000  bestvalidloss -1301.26958  last_update 7\n",
      "train: iter 386  trainloss -1344.41641  validloss -1107.99603±0.00000  bestvalidloss -1301.26958  last_update 8\n",
      "train: iter 387  trainloss -1393.29178  validloss -1227.04721±0.00000  bestvalidloss -1301.26958  last_update 9\n",
      "train: iter 388  trainloss -1344.16531  validloss -1191.09601±0.00000  bestvalidloss -1301.26958  last_update 10\n",
      "train: iter 389  trainloss -1353.92173  validloss -1180.86285±0.00000  bestvalidloss -1301.26958  last_update 11\n",
      "train: iter 390  trainloss -1359.47503  validloss -1196.25289±0.00000  bestvalidloss -1301.26958  last_update 12\n",
      "train: iter 391  trainloss -1376.21078  validloss -1222.34857±0.00000  bestvalidloss -1301.26958  last_update 13\n",
      "train: iter 392  trainloss -1353.58092  validloss -1161.35292±0.00000  bestvalidloss -1301.26958  last_update 14\n",
      "train: iter 393  trainloss -1334.77822  validloss -1168.78883±0.00000  bestvalidloss -1301.26958  last_update 15\n",
      "train: iter 394  trainloss -1298.75319  validloss -1269.83596±0.00000  bestvalidloss -1301.26958  last_update 16\n",
      "train: iter 395  trainloss -1347.82214  validloss -1124.52949±0.00000  bestvalidloss -1301.26958  last_update 17\n",
      "train: iter 396  trainloss -1363.48650  validloss -1238.82912±0.00000  bestvalidloss -1301.26958  last_update 18\n",
      "train: iter 397  trainloss -1377.12087  validloss -1222.45570±0.00000  bestvalidloss -1301.26958  last_update 19\n",
      "train: iter 398  trainloss -1374.48291  validloss -1247.95644±0.00000  bestvalidloss -1301.26958  last_update 20\n",
      "train: iter 399  trainloss -1444.24952  validloss -1287.21268±0.00000  bestvalidloss -1301.26958  last_update 21\n",
      "train: iter 400  trainloss -1438.70645  validloss -1303.29131±0.00000  bestvalidloss -1303.29131  last_update 0\n",
      "train: iter 401  trainloss -1354.53380  validloss -1102.59539±0.00000  bestvalidloss -1303.29131  last_update 1\n",
      "train: iter 402  trainloss -1239.86054  validloss -1144.17411±0.00000  bestvalidloss -1303.29131  last_update 2\n",
      "train: iter 403  trainloss -1396.89796  validloss -1205.05202±0.00000  bestvalidloss -1303.29131  last_update 3\n",
      "train: iter 404  trainloss -1168.56692  validloss -1008.46864±0.00000  bestvalidloss -1303.29131  last_update 4\n",
      "train: iter 405  trainloss -1353.67507  validloss -1253.75648±0.00000  bestvalidloss -1303.29131  last_update 5\n",
      "train: iter 406  trainloss -1349.56950  validloss -1162.77800±0.00000  bestvalidloss -1303.29131  last_update 6\n",
      "train: iter 407  trainloss -1400.44909  validloss -1272.41687±0.00000  bestvalidloss -1303.29131  last_update 7\n",
      "train: iter 408  trainloss -1378.76668  validloss -1289.40815±0.00000  bestvalidloss -1303.29131  last_update 8\n",
      "train: iter 409  trainloss -1260.14694  validloss -1292.01845±0.00000  bestvalidloss -1303.29131  last_update 9\n",
      "train: iter 410  trainloss -1319.40518  validloss -1159.36946±0.00000  bestvalidloss -1303.29131  last_update 10\n",
      "train: iter 411  trainloss -1311.33677  validloss -1095.31705±0.00000  bestvalidloss -1303.29131  last_update 11\n",
      "train: iter 412  trainloss -1446.71562  validloss -1284.16236±0.00000  bestvalidloss -1303.29131  last_update 12\n",
      "train: iter 413  trainloss -1436.90538  validloss -1296.10465±0.00000  bestvalidloss -1303.29131  last_update 13\n",
      "train: iter 414  trainloss -1363.40154  validloss -1312.92280±0.00000  bestvalidloss -1312.92280  last_update 0\n",
      "train: iter 415  trainloss -1366.36784  validloss -1274.22162±0.00000  bestvalidloss -1312.92280  last_update 1\n",
      "train: iter 416  trainloss -1402.05054  validloss -1299.19774±0.00000  bestvalidloss -1312.92280  last_update 2\n",
      "train: iter 417  trainloss -1144.15746  validloss -946.23313±0.00000  bestvalidloss -1312.92280  last_update 3\n",
      "train: iter 418  trainloss -1407.07816  validloss -1317.93609±0.00000  bestvalidloss -1317.93609  last_update 0\n",
      "train: iter 419  trainloss -1437.93871  validloss -1247.61318±0.00000  bestvalidloss -1317.93609  last_update 1\n",
      "train: iter 420  trainloss -1413.27349  validloss -1236.20228±0.00000  bestvalidloss -1317.93609  last_update 2\n",
      "train: iter 421  trainloss -1375.12730  validloss -1300.91194±0.00000  bestvalidloss -1317.93609  last_update 3\n",
      "train: iter 422  trainloss -1266.71705  validloss -1235.33968±0.00000  bestvalidloss -1317.93609  last_update 4\n",
      "train: iter 423  trainloss -1193.08953  validloss -879.45633±0.00000  bestvalidloss -1317.93609  last_update 5\n",
      "train: iter 424  trainloss -1397.27430  validloss -1248.93278±0.00000  bestvalidloss -1317.93609  last_update 6\n",
      "train: iter 425  trainloss -1293.46909  validloss -1196.39481±0.00000  bestvalidloss -1317.93609  last_update 7\n",
      "train: iter 426  trainloss -1288.60584  validloss -892.85650±0.00000  bestvalidloss -1317.93609  last_update 8\n",
      "train: iter 427  trainloss -1228.50153  validloss -1136.00416±0.00000  bestvalidloss -1317.93609  last_update 9\n",
      "train: iter 428  trainloss -1321.45136  validloss -1076.25199±0.00000  bestvalidloss -1317.93609  last_update 10\n",
      "train: iter 429  trainloss -1443.57225  validloss -1244.83188±0.00000  bestvalidloss -1317.93609  last_update 11\n",
      "train: iter 430  trainloss -1382.15512  validloss -1286.15019±0.00000  bestvalidloss -1317.93609  last_update 12\n",
      "train: iter 431  trainloss -1355.92967  validloss -1215.54170±0.00000  bestvalidloss -1317.93609  last_update 13\n",
      "train: iter 432  trainloss -1396.17356  validloss -1250.80408±0.00000  bestvalidloss -1317.93609  last_update 14\n",
      "train: iter 433  trainloss -1426.20116  validloss -1316.90030±0.00000  bestvalidloss -1317.93609  last_update 15\n",
      "train: iter 434  trainloss -1256.37236  validloss -1249.61696±0.00000  bestvalidloss -1317.93609  last_update 16\n",
      "train: iter 435  trainloss -1371.44391  validloss -1162.60596±0.00000  bestvalidloss -1317.93609  last_update 17\n",
      "train: iter 436  trainloss -1370.55590  validloss -1295.44773±0.00000  bestvalidloss -1317.93609  last_update 18\n",
      "train: iter 437  trainloss -1422.11541  validloss -1272.35881±0.00000  bestvalidloss -1317.93609  last_update 19\n",
      "train: iter 438  trainloss -1457.97584  validloss -1289.29031±0.00000  bestvalidloss -1317.93609  last_update 20\n",
      "train: iter 439  trainloss -1186.02451  validloss -1157.37175±0.00000  bestvalidloss -1317.93609  last_update 21\n",
      "train: iter 440  trainloss -1239.37898  validloss -745.09411±0.00000  bestvalidloss -1317.93609  last_update 22\n",
      "train: iter 441  trainloss -1068.28353  validloss -200.17893±0.00000  bestvalidloss -1317.93609  last_update 23\n",
      "train: iter 442  trainloss -1401.88894  validloss -1278.75687±0.00000  bestvalidloss -1317.93609  last_update 24\n",
      "train: iter 443  trainloss -1289.99494  validloss -1059.66219±0.00000  bestvalidloss -1317.93609  last_update 25\n",
      "train: iter 444  trainloss -1420.81290  validloss -1300.82009±0.00000  bestvalidloss -1317.93609  last_update 26\n",
      "train: iter 445  trainloss -1414.09859  validloss -1287.72266±0.00000  bestvalidloss -1317.93609  last_update 27\n",
      "train: iter 446  trainloss -1450.43209  validloss -1282.22440±0.00000  bestvalidloss -1317.93609  last_update 28\n",
      "train: iter 447  trainloss -1369.49512  validloss -1121.11163±0.00000  bestvalidloss -1317.93609  last_update 29\n",
      "train: iter 448  trainloss -1439.01100  validloss -1332.25592±0.00000  bestvalidloss -1332.25592  last_update 0\n",
      "train: iter 449  trainloss -1422.02205  validloss -1248.63519±0.00000  bestvalidloss -1332.25592  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 450  trainloss -1419.84776  validloss -1164.58376±0.00000  bestvalidloss -1332.25592  last_update 2\n",
      "train: iter 451  trainloss -1479.36947  validloss -1333.68162±0.00000  bestvalidloss -1333.68162  last_update 0\n",
      "train: iter 452  trainloss -1356.28381  validloss -1355.20302±0.00000  bestvalidloss -1355.20302  last_update 0\n",
      "train: iter 453  trainloss -1334.77590  validloss -1011.43178±0.00000  bestvalidloss -1355.20302  last_update 1\n",
      "train: iter 454  trainloss -1414.66280  validloss -1325.36730±0.00000  bestvalidloss -1355.20302  last_update 2\n",
      "train: iter 455  trainloss -1395.77756  validloss -1322.10892±0.00000  bestvalidloss -1355.20302  last_update 3\n",
      "train: iter 456  trainloss -1418.00427  validloss -1309.94234±0.00000  bestvalidloss -1355.20302  last_update 4\n",
      "train: iter 457  trainloss -1434.35335  validloss -1316.55605±0.00000  bestvalidloss -1355.20302  last_update 5\n",
      "train: iter 458  trainloss -1346.91529  validloss -1328.14087±0.00000  bestvalidloss -1355.20302  last_update 6\n",
      "train: iter 459  trainloss -912.00489  validloss 1317.71134±0.00000  bestvalidloss -1355.20302  last_update 7\n",
      "train: iter 460  trainloss -1306.22832  validloss -1183.61190±0.00000  bestvalidloss -1355.20302  last_update 8\n",
      "train: iter 461  trainloss -1372.21121  validloss -1032.32008±0.00000  bestvalidloss -1355.20302  last_update 9\n",
      "train: iter 462  trainloss -1423.20353  validloss -1246.36114±0.00000  bestvalidloss -1355.20302  last_update 10\n",
      "train: iter 463  trainloss -1420.65209  validloss -1257.36011±0.00000  bestvalidloss -1355.20302  last_update 11\n",
      "train: iter 464  trainloss -1444.53996  validloss -1284.05034±0.00000  bestvalidloss -1355.20302  last_update 12\n",
      "train: iter 465  trainloss -1350.80433  validloss -1187.05798±0.00000  bestvalidloss -1355.20302  last_update 13\n",
      "train: iter 466  trainloss -1425.96375  validloss -1336.59386±0.00000  bestvalidloss -1355.20302  last_update 14\n",
      "train: iter 467  trainloss -1347.83516  validloss -1316.85195±0.00000  bestvalidloss -1355.20302  last_update 15\n",
      "train: iter 468  trainloss -1255.81915  validloss -662.85307±0.00000  bestvalidloss -1355.20302  last_update 16\n",
      "train: iter 469  trainloss -1446.15766  validloss -1359.31809±0.00000  bestvalidloss -1359.31809  last_update 0\n",
      "train: iter 470  trainloss -1408.50655  validloss -1248.53334±0.00000  bestvalidloss -1359.31809  last_update 1\n",
      "train: iter 471  trainloss -1296.04672  validloss -1134.19410±0.00000  bestvalidloss -1359.31809  last_update 2\n",
      "train: iter 472  trainloss -1462.30611  validloss -1327.67822±0.00000  bestvalidloss -1359.31809  last_update 3\n",
      "train: iter 473  trainloss -1430.03728  validloss -1379.80562±0.00000  bestvalidloss -1379.80562  last_update 0\n",
      "train: iter 474  trainloss -1408.10484  validloss -1339.67804±0.00000  bestvalidloss -1379.80562  last_update 1\n",
      "train: iter 475  trainloss -1372.34640  validloss -1166.10386±0.00000  bestvalidloss -1379.80562  last_update 2\n",
      "train: iter 476  trainloss -1360.68924  validloss -1058.42501±0.00000  bestvalidloss -1379.80562  last_update 3\n",
      "train: iter 477  trainloss -1422.67442  validloss -1296.45114±0.00000  bestvalidloss -1379.80562  last_update 4\n",
      "train: iter 478  trainloss -1460.27807  validloss -1294.21485±0.00000  bestvalidloss -1379.80562  last_update 5\n",
      "train: iter 479  trainloss -1474.03555  validloss -1323.70279±0.00000  bestvalidloss -1379.80562  last_update 6\n",
      "train: iter 480  trainloss -1421.66519  validloss -1200.87239±0.00000  bestvalidloss -1379.80562  last_update 7\n",
      "train: iter 481  trainloss -1375.51556  validloss -1272.26883±0.00000  bestvalidloss -1379.80562  last_update 8\n",
      "train: iter 482  trainloss -1269.96083  validloss -1337.61384±0.00000  bestvalidloss -1379.80562  last_update 9\n",
      "train: iter 483  trainloss -1335.20595  validloss -1177.23234±0.00000  bestvalidloss -1379.80562  last_update 10\n",
      "train: iter 484  trainloss -1421.75795  validloss -1271.50676±0.00000  bestvalidloss -1379.80562  last_update 11\n",
      "train: iter 485  trainloss -1436.22442  validloss -1227.11463±0.00000  bestvalidloss -1379.80562  last_update 12\n",
      "train: iter 486  trainloss -1452.14839  validloss -1315.88193±0.00000  bestvalidloss -1379.80562  last_update 13\n",
      "train: iter 487  trainloss -1364.19881  validloss -1317.55942±0.00000  bestvalidloss -1379.80562  last_update 14\n",
      "train: iter 488  trainloss -1399.05516  validloss -1223.49179±0.00000  bestvalidloss -1379.80562  last_update 15\n",
      "train: iter 489  trainloss -1400.01126  validloss -1343.03793±0.00000  bestvalidloss -1379.80562  last_update 16\n",
      "train: iter 490  trainloss -1332.31233  validloss -1159.61597±0.00000  bestvalidloss -1379.80562  last_update 17\n",
      "train: iter 491  trainloss -1410.90087  validloss -1309.11082±0.00000  bestvalidloss -1379.80562  last_update 18\n",
      "train: iter 492  trainloss -1372.68858  validloss -1231.21852±0.00000  bestvalidloss -1379.80562  last_update 19\n",
      "train: iter 493  trainloss -1426.97546  validloss -1208.13060±0.00000  bestvalidloss -1379.80562  last_update 20\n",
      "train: iter 494  trainloss -1457.48734  validloss -1348.78051±0.00000  bestvalidloss -1379.80562  last_update 21\n",
      "train: iter 495  trainloss -1462.05385  validloss -1192.02789±0.00000  bestvalidloss -1379.80562  last_update 22\n",
      "train: iter 496  trainloss -1346.25454  validloss -1234.35878±0.00000  bestvalidloss -1379.80562  last_update 23\n",
      "train: iter 497  trainloss -1321.63119  validloss -1221.58656±0.00000  bestvalidloss -1379.80562  last_update 24\n",
      "train: iter 498  trainloss -1401.90025  validloss -1109.93255±0.00000  bestvalidloss -1379.80562  last_update 25\n",
      "train: iter 499  trainloss -1446.88879  validloss -1351.42485±0.00000  bestvalidloss -1379.80562  last_update 26\n",
      "train: iter 500  trainloss -1485.59591  validloss -1376.48436±0.00000  bestvalidloss -1379.80562  last_update 27\n",
      "train: iter 501  trainloss -1445.05359  validloss -1372.87516±0.00000  bestvalidloss -1379.80562  last_update 28\n",
      "train: iter 502  trainloss -1418.89514  validloss -1318.76684±0.00000  bestvalidloss -1379.80562  last_update 29\n",
      "train: iter 503  trainloss -1470.37865  validloss -1286.09304±0.00000  bestvalidloss -1379.80562  last_update 30\n",
      "train: iter 504  trainloss -1447.18648  validloss -1308.00742±0.00000  bestvalidloss -1379.80562  last_update 31\n",
      "train: iter 505  trainloss -1323.52951  validloss -697.52658±0.00000  bestvalidloss -1379.80562  last_update 32\n",
      "train: iter 506  trainloss -1423.86342  validloss -1093.05389±0.00000  bestvalidloss -1379.80562  last_update 33\n",
      "train: iter 507  trainloss -1328.44478  validloss -1329.55855±0.00000  bestvalidloss -1379.80562  last_update 34\n",
      "train: iter 508  trainloss -787.67776  validloss -411.63855±0.00000  bestvalidloss -1379.80562  last_update 35\n",
      "train: iter 509  trainloss -1241.59010  validloss -1105.88549±0.00000  bestvalidloss -1379.80562  last_update 36\n",
      "train: iter 510  trainloss -1386.95584  validloss -1267.31483±0.00000  bestvalidloss -1379.80562  last_update 37\n",
      "train: iter 511  trainloss -1418.64651  validloss -1316.49602±0.00000  bestvalidloss -1379.80562  last_update 38\n",
      "train: iter 512  trainloss -1373.78112  validloss -1331.59329±0.00000  bestvalidloss -1379.80562  last_update 39\n",
      "train: iter 513  trainloss -1408.82140  validloss -1325.19592±0.00000  bestvalidloss -1379.80562  last_update 40\n",
      "train: iter 514  trainloss -1384.70595  validloss -883.95872±0.00000  bestvalidloss -1379.80562  last_update 41\n",
      "train: iter 515  trainloss -1320.35385  validloss -1331.25538±0.00000  bestvalidloss -1379.80562  last_update 42\n",
      "train: iter 516  trainloss -1362.39022  validloss -1323.17333±0.00000  bestvalidloss -1379.80562  last_update 43\n",
      "train: iter 517  trainloss -1464.56452  validloss -1323.56618±0.00000  bestvalidloss -1379.80562  last_update 44\n",
      "train: iter 518  trainloss -1472.81223  validloss -1343.36086±0.00000  bestvalidloss -1379.80562  last_update 45\n",
      "train: iter 519  trainloss -1464.74050  validloss -1285.91680±0.00000  bestvalidloss -1379.80562  last_update 46\n",
      "train: iter 520  trainloss -1383.82084  validloss -1376.79762±0.00000  bestvalidloss -1379.80562  last_update 47\n",
      "train: iter 521  trainloss -1347.10420  validloss -1135.94572±0.00000  bestvalidloss -1379.80562  last_update 48\n",
      "train: iter 522  trainloss -1415.41298  validloss -1354.86550±0.00000  bestvalidloss -1379.80562  last_update 49\n",
      "train: iter 523  trainloss -1222.67344  validloss -1137.36987±0.00000  bestvalidloss -1379.80562  last_update 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 524  trainloss -1325.11859  validloss -1057.73204±0.00000  bestvalidloss -1379.80562  last_update 51\n",
      "train: iter 525  trainloss -1462.95916  validloss -1221.13919±0.00000  bestvalidloss -1379.80562  last_update 52\n",
      "train: iter 526  trainloss -1442.53823  validloss -1335.80157±0.00000  bestvalidloss -1379.80562  last_update 53\n",
      "train: iter 527  trainloss -1466.50842  validloss -1235.69377±0.00000  bestvalidloss -1379.80562  last_update 54\n",
      "train: iter 528  trainloss -1518.88713  validloss -1394.26135±0.00000  bestvalidloss -1394.26135  last_update 0\n",
      "train: iter 529  trainloss -1430.71881  validloss -1360.86528±0.00000  bestvalidloss -1394.26135  last_update 1\n",
      "train: iter 530  trainloss -1449.82442  validloss -878.03965±0.00000  bestvalidloss -1394.26135  last_update 2\n",
      "train: iter 531  trainloss -1492.00967  validloss -1343.47507±0.00000  bestvalidloss -1394.26135  last_update 3\n",
      "train: iter 532  trainloss -1489.85442  validloss -1363.20376±0.00000  bestvalidloss -1394.26135  last_update 4\n",
      "train: iter 533  trainloss -1279.74657  validloss -735.48870±0.00000  bestvalidloss -1394.26135  last_update 5\n",
      "train: iter 534  trainloss -1478.63443  validloss -1236.90532±0.00000  bestvalidloss -1394.26135  last_update 6\n",
      "train: iter 535  trainloss -1477.28683  validloss -1266.91555±0.00000  bestvalidloss -1394.26135  last_update 7\n",
      "train: iter 536  trainloss -1470.87585  validloss -1333.79053±0.00000  bestvalidloss -1394.26135  last_update 8\n",
      "train: iter 537  trainloss -1407.75955  validloss -1317.43489±0.00000  bestvalidloss -1394.26135  last_update 9\n",
      "train: iter 538  trainloss -1409.09983  validloss -1283.72075±0.00000  bestvalidloss -1394.26135  last_update 10\n",
      "train: iter 539  trainloss -1321.51822  validloss -1199.09289±0.00000  bestvalidloss -1394.26135  last_update 11\n",
      "train: iter 540  trainloss -1441.95015  validloss -1202.60953±0.00000  bestvalidloss -1394.26135  last_update 12\n",
      "train: iter 541  trainloss -1370.90603  validloss -1331.26498±0.00000  bestvalidloss -1394.26135  last_update 13\n",
      "train: iter 542  trainloss -1425.19373  validloss -1132.88404±0.00000  bestvalidloss -1394.26135  last_update 14\n",
      "train: iter 543  trainloss -1443.60101  validloss -1298.68140±0.00000  bestvalidloss -1394.26135  last_update 15\n",
      "train: iter 544  trainloss -1421.56001  validloss -1231.50872±0.00000  bestvalidloss -1394.26135  last_update 16\n",
      "train: iter 545  trainloss -1506.97417  validloss -1388.43259±0.00000  bestvalidloss -1394.26135  last_update 17\n",
      "train: iter 546  trainloss -1482.95563  validloss -1364.91591±0.00000  bestvalidloss -1394.26135  last_update 18\n",
      "train: iter 547  trainloss -1463.85625  validloss -1377.79236±0.00000  bestvalidloss -1394.26135  last_update 19\n",
      "train: iter 548  trainloss -1445.45075  validloss -1351.09632±0.00000  bestvalidloss -1394.26135  last_update 20\n",
      "train: iter 549  trainloss -1486.75627  validloss -1230.80908±0.00000  bestvalidloss -1394.26135  last_update 21\n",
      "train: iter 550  trainloss -1475.15671  validloss -1280.71397±0.00000  bestvalidloss -1394.26135  last_update 22\n",
      "train: iter 551  trainloss -1433.04706  validloss -1057.19898±0.00000  bestvalidloss -1394.26135  last_update 23\n",
      "train: iter 552  trainloss -1421.11508  validloss -1289.14591±0.00000  bestvalidloss -1394.26135  last_update 24\n",
      "train: iter 553  trainloss -1448.91036  validloss -1290.77038±0.00000  bestvalidloss -1394.26135  last_update 25\n",
      "train: iter 554  trainloss -1494.82012  validloss -1285.15110±0.00000  bestvalidloss -1394.26135  last_update 26\n",
      "train: iter 555  trainloss -1443.52388  validloss -1356.98657±0.00000  bestvalidloss -1394.26135  last_update 27\n",
      "train: iter 556  trainloss -1340.55046  validloss -1276.74703±0.00000  bestvalidloss -1394.26135  last_update 28\n",
      "train: iter 557  trainloss -1417.47388  validloss -1223.17283±0.00000  bestvalidloss -1394.26135  last_update 29\n",
      "train: iter 558  trainloss -1512.75207  validloss -1408.97267±0.00000  bestvalidloss -1408.97267  last_update 0\n",
      "train: iter 559  trainloss -1435.22763  validloss -1355.56620±0.00000  bestvalidloss -1408.97267  last_update 1\n",
      "train: iter 560  trainloss -1449.37315  validloss -1197.89301±0.00000  bestvalidloss -1408.97267  last_update 2\n",
      "train: iter 561  trainloss -1467.10175  validloss -1269.21156±0.00000  bestvalidloss -1408.97267  last_update 3\n",
      "train: iter 562  trainloss -1443.82206  validloss -1269.24121±0.00000  bestvalidloss -1408.97267  last_update 4\n",
      "train: iter 563  trainloss -1383.66791  validloss -1317.66924±0.00000  bestvalidloss -1408.97267  last_update 5\n",
      "train: iter 564  trainloss -1429.28055  validloss -1387.15408±0.00000  bestvalidloss -1408.97267  last_update 6\n",
      "train: iter 565  trainloss -1416.84575  validloss -1304.20693±0.00000  bestvalidloss -1408.97267  last_update 7\n",
      "train: iter 566  trainloss -1503.18645  validloss -1369.12758±0.00000  bestvalidloss -1408.97267  last_update 8\n",
      "train: iter 567  trainloss -1344.90492  validloss -1407.46384±0.00000  bestvalidloss -1408.97267  last_update 9\n",
      "train: iter 568  trainloss -1496.25308  validloss -1286.51704±0.00000  bestvalidloss -1408.97267  last_update 10\n",
      "train: iter 569  trainloss -1488.09481  validloss -1293.82046±0.00000  bestvalidloss -1408.97267  last_update 11\n",
      "train: iter 570  trainloss -1263.03118  validloss -1352.44561±0.00000  bestvalidloss -1408.97267  last_update 12\n",
      "train: iter 571  trainloss -1436.04332  validloss -1312.03816±0.00000  bestvalidloss -1408.97267  last_update 13\n",
      "train: iter 572  trainloss -1478.74316  validloss -1392.09916±0.00000  bestvalidloss -1408.97267  last_update 14\n",
      "train: iter 573  trainloss -1430.95587  validloss -1384.77504±0.00000  bestvalidloss -1408.97267  last_update 15\n",
      "train: iter 574  trainloss -1360.65274  validloss -977.13843±0.00000  bestvalidloss -1408.97267  last_update 16\n",
      "train: iter 575  trainloss -1494.75675  validloss -1330.34254±0.00000  bestvalidloss -1408.97267  last_update 17\n",
      "train: iter 576  trainloss -1505.45627  validloss -1367.00540±0.00000  bestvalidloss -1408.97267  last_update 18\n",
      "train: iter 577  trainloss -1498.68643  validloss -1391.39520±0.00000  bestvalidloss -1408.97267  last_update 19\n",
      "train: iter 578  trainloss -1495.50667  validloss -1323.67605±0.00000  bestvalidloss -1408.97267  last_update 20\n",
      "train: iter 579  trainloss -1530.98261  validloss -1333.90108±0.00000  bestvalidloss -1408.97267  last_update 21\n",
      "train: iter 580  trainloss -1449.56549  validloss -1377.17266±0.00000  bestvalidloss -1408.97267  last_update 22\n",
      "train: iter 581  trainloss -1507.14816  validloss -1297.91166±0.00000  bestvalidloss -1408.97267  last_update 23\n",
      "train: iter 582  trainloss -1470.09169  validloss -1397.75537±0.00000  bestvalidloss -1408.97267  last_update 24\n",
      "train: iter 583  trainloss -1417.93956  validloss -1358.40441±0.00000  bestvalidloss -1408.97267  last_update 25\n",
      "train: iter 584  trainloss -1416.05399  validloss -1358.15392±0.00000  bestvalidloss -1408.97267  last_update 26\n",
      "train: iter 585  trainloss -1463.93557  validloss -1166.81628±0.00000  bestvalidloss -1408.97267  last_update 27\n",
      "train: iter 586  trainloss -1520.84624  validloss -1347.87067±0.00000  bestvalidloss -1408.97267  last_update 28\n",
      "train: iter 587  trainloss -1375.03659  validloss -1381.83321±0.00000  bestvalidloss -1408.97267  last_update 29\n",
      "train: iter 588  trainloss -1384.56895  validloss -1267.60326±0.00000  bestvalidloss -1408.97267  last_update 30\n",
      "train: iter 589  trainloss -1448.15494  validloss -1373.30643±0.00000  bestvalidloss -1408.97267  last_update 31\n",
      "train: iter 590  trainloss -1170.11755  validloss -1280.49919±0.00000  bestvalidloss -1408.97267  last_update 32\n",
      "train: iter 591  trainloss -1368.87564  validloss -1199.22872±0.00000  bestvalidloss -1408.97267  last_update 33\n",
      "train: iter 592  trainloss -1237.28616  validloss -1321.46064±0.00000  bestvalidloss -1408.97267  last_update 34\n",
      "train: iter 593  trainloss -1428.65213  validloss -1216.04866±0.00000  bestvalidloss -1408.97267  last_update 35\n",
      "train: iter 594  trainloss -1509.68513  validloss -1353.14397±0.00000  bestvalidloss -1408.97267  last_update 36\n",
      "train: iter 595  trainloss -1517.07482  validloss -1393.07613±0.00000  bestvalidloss -1408.97267  last_update 37\n",
      "train: iter 596  trainloss -1471.71195  validloss -1157.71112±0.00000  bestvalidloss -1408.97267  last_update 38\n",
      "train: iter 597  trainloss -1467.90169  validloss -1197.03278±0.00000  bestvalidloss -1408.97267  last_update 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 598  trainloss -1490.13426  validloss -1427.13416±0.00000  bestvalidloss -1427.13416  last_update 0\n",
      "train: iter 599  trainloss -1476.54737  validloss -1403.03454±0.00000  bestvalidloss -1427.13416  last_update 1\n",
      "train: iter 600  trainloss -1519.57632  validloss -1370.44739±0.00000  bestvalidloss -1427.13416  last_update 2\n",
      "train: iter 601  trainloss -1386.52071  validloss -1350.90118±0.00000  bestvalidloss -1427.13416  last_update 3\n",
      "train: iter 602  trainloss -1476.07959  validloss -1327.13976±0.00000  bestvalidloss -1427.13416  last_update 4\n",
      "train: iter 603  trainloss -1486.40433  validloss -1396.30607±0.00000  bestvalidloss -1427.13416  last_update 5\n",
      "train: iter 604  trainloss -1441.51075  validloss -1325.21377±0.00000  bestvalidloss -1427.13416  last_update 6\n",
      "train: iter 605  trainloss -1519.62363  validloss -1347.78353±0.00000  bestvalidloss -1427.13416  last_update 7\n",
      "train: iter 606  trainloss -1521.59136  validloss -1424.03809±0.00000  bestvalidloss -1427.13416  last_update 8\n",
      "train: iter 607  trainloss -1299.98350  validloss -1313.54310±0.00000  bestvalidloss -1427.13416  last_update 9\n",
      "train: iter 608  trainloss -1482.15044  validloss -1367.67561±0.00000  bestvalidloss -1427.13416  last_update 10\n",
      "train: iter 609  trainloss -1495.14307  validloss -1366.87950±0.00000  bestvalidloss -1427.13416  last_update 11\n",
      "train: iter 610  trainloss -1458.93750  validloss -1256.89057±0.00000  bestvalidloss -1427.13416  last_update 12\n",
      "train: iter 611  trainloss -1475.44295  validloss -1288.71753±0.00000  bestvalidloss -1427.13416  last_update 13\n",
      "train: iter 612  trainloss -1494.66670  validloss -1377.98165±0.00000  bestvalidloss -1427.13416  last_update 14\n",
      "train: iter 613  trainloss -1525.17743  validloss -1318.99725±0.00000  bestvalidloss -1427.13416  last_update 15\n",
      "train: iter 614  trainloss -1489.98206  validloss -1393.44942±0.00000  bestvalidloss -1427.13416  last_update 16\n",
      "train: iter 615  trainloss -1414.56107  validloss -1373.03364±0.00000  bestvalidloss -1427.13416  last_update 17\n",
      "train: iter 616  trainloss -1493.10869  validloss -1335.30765±0.00000  bestvalidloss -1427.13416  last_update 18\n",
      "train: iter 617  trainloss -1495.20245  validloss -1415.13450±0.00000  bestvalidloss -1427.13416  last_update 19\n",
      "train: iter 618  trainloss -1459.21284  validloss -1305.41354±0.00000  bestvalidloss -1427.13416  last_update 20\n",
      "train: iter 619  trainloss -1504.71817  validloss -1325.65322±0.00000  bestvalidloss -1427.13416  last_update 21\n",
      "train: iter 620  trainloss -1440.94083  validloss -1339.10238±0.00000  bestvalidloss -1427.13416  last_update 22\n",
      "train: iter 621  trainloss -1294.27743  validloss -1245.80512±0.00000  bestvalidloss -1427.13416  last_update 23\n",
      "train: iter 622  trainloss -1293.31013  validloss -278.95424±0.00000  bestvalidloss -1427.13416  last_update 24\n",
      "train: iter 623  trainloss -1463.75805  validloss -1257.12627±0.00000  bestvalidloss -1427.13416  last_update 25\n",
      "train: iter 624  trainloss -1517.96244  validloss -1339.66388±0.00000  bestvalidloss -1427.13416  last_update 26\n",
      "train: iter 625  trainloss -1480.94145  validloss -1422.54881±0.00000  bestvalidloss -1427.13416  last_update 27\n",
      "train: iter 626  trainloss -1439.04395  validloss -1336.96720±0.00000  bestvalidloss -1427.13416  last_update 28\n",
      "train: iter 627  trainloss -1541.62918  validloss -1428.31422±0.00000  bestvalidloss -1428.31422  last_update 0\n",
      "train: iter 628  trainloss -1413.25251  validloss -1383.44961±0.00000  bestvalidloss -1428.31422  last_update 1\n",
      "train: iter 629  trainloss -1461.03122  validloss -1314.28264±0.00000  bestvalidloss -1428.31422  last_update 2\n",
      "train: iter 630  trainloss -1500.57476  validloss -1354.69573±0.00000  bestvalidloss -1428.31422  last_update 3\n",
      "train: iter 631  trainloss -1516.32412  validloss -1396.65242±0.00000  bestvalidloss -1428.31422  last_update 4\n",
      "train: iter 632  trainloss -1514.10543  validloss -1381.01512±0.00000  bestvalidloss -1428.31422  last_update 5\n",
      "train: iter 633  trainloss -1327.66373  validloss -1425.34845±0.00000  bestvalidloss -1428.31422  last_update 6\n",
      "train: iter 634  trainloss -1502.88013  validloss -1322.66378±0.00000  bestvalidloss -1428.31422  last_update 7\n",
      "train: iter 635  trainloss -1469.80874  validloss -1316.49982±0.00000  bestvalidloss -1428.31422  last_update 8\n",
      "train: iter 636  trainloss -1526.55833  validloss -1367.57575±0.00000  bestvalidloss -1428.31422  last_update 9\n",
      "train: iter 637  trainloss -1465.77569  validloss -1388.12020±0.00000  bestvalidloss -1428.31422  last_update 10\n",
      "train: iter 638  trainloss -1506.67828  validloss -1338.90698±0.00000  bestvalidloss -1428.31422  last_update 11\n",
      "train: iter 639  trainloss -1542.38513  validloss -1431.39866±0.00000  bestvalidloss -1431.39866  last_update 0\n",
      "train: iter 640  trainloss -1462.61846  validloss -1280.09923±0.00000  bestvalidloss -1431.39866  last_update 1\n",
      "train: iter 641  trainloss -1094.04760  validloss -1060.53519±0.00000  bestvalidloss -1431.39866  last_update 2\n",
      "train: iter 642  trainloss -1463.14560  validloss -1264.87610±0.00000  bestvalidloss -1431.39866  last_update 3\n",
      "train: iter 643  trainloss -1493.89835  validloss -1370.95210±0.00000  bestvalidloss -1431.39866  last_update 4\n",
      "train: iter 644  trainloss -1524.69761  validloss -1353.31712±0.00000  bestvalidloss -1431.39866  last_update 5\n",
      "train: iter 645  trainloss -1552.64789  validloss -1426.72849±0.00000  bestvalidloss -1431.39866  last_update 6\n",
      "train: iter 646  trainloss -1486.77529  validloss -1368.70245±0.00000  bestvalidloss -1431.39866  last_update 7\n",
      "train: iter 647  trainloss -1499.55138  validloss -1392.63206±0.00000  bestvalidloss -1431.39866  last_update 8\n",
      "train: iter 648  trainloss -1520.89980  validloss -1404.77471±0.00000  bestvalidloss -1431.39866  last_update 9\n",
      "train: iter 649  trainloss -1376.71707  validloss -1313.08979±0.00000  bestvalidloss -1431.39866  last_update 10\n",
      "train: iter 650  trainloss -1468.13807  validloss -1266.20607±0.00000  bestvalidloss -1431.39866  last_update 11\n",
      "train: iter 651  trainloss -1450.90833  validloss -1299.29372±0.00000  bestvalidloss -1431.39866  last_update 12\n",
      "train: iter 652  trainloss -1470.08663  validloss -1311.83878±0.00000  bestvalidloss -1431.39866  last_update 13\n",
      "train: iter 653  trainloss -1524.42192  validloss -1401.78790±0.00000  bestvalidloss -1431.39866  last_update 14\n",
      "train: iter 654  trainloss -1488.32051  validloss -1345.19816±0.00000  bestvalidloss -1431.39866  last_update 15\n",
      "train: iter 655  trainloss -1448.49130  validloss -1224.63774±0.00000  bestvalidloss -1431.39866  last_update 16\n",
      "train: iter 656  trainloss -1273.44575  validloss -1208.14413±0.00000  bestvalidloss -1431.39866  last_update 17\n",
      "train: iter 657  trainloss -1473.59937  validloss -1293.08201±0.00000  bestvalidloss -1431.39866  last_update 18\n",
      "train: iter 658  trainloss -1531.70662  validloss -1345.92929±0.00000  bestvalidloss -1431.39866  last_update 19\n",
      "train: iter 659  trainloss -1407.55608  validloss -1422.54523±0.00000  bestvalidloss -1431.39866  last_update 20\n",
      "train: iter 660  trainloss -1329.35844  validloss -1115.52351±0.00000  bestvalidloss -1431.39866  last_update 21\n",
      "train: iter 661  trainloss -1465.60299  validloss -1296.67657±0.00000  bestvalidloss -1431.39866  last_update 22\n",
      "train: iter 662  trainloss -1489.42154  validloss -1393.64348±0.00000  bestvalidloss -1431.39866  last_update 23\n",
      "train: iter 663  trainloss -1465.48050  validloss -1336.64689±0.00000  bestvalidloss -1431.39866  last_update 24\n",
      "train: iter 664  trainloss -1538.34602  validloss -1414.80971±0.00000  bestvalidloss -1431.39866  last_update 25\n",
      "train: iter 665  trainloss -1489.03367  validloss -1412.92193±0.00000  bestvalidloss -1431.39866  last_update 26\n",
      "train: iter 666  trainloss -1530.73310  validloss -1383.21089±0.00000  bestvalidloss -1431.39866  last_update 27\n",
      "train: iter 667  trainloss -1503.39884  validloss -1395.60578±0.00000  bestvalidloss -1431.39866  last_update 28\n",
      "train: iter 668  trainloss -1507.42812  validloss -1421.20716±0.00000  bestvalidloss -1431.39866  last_update 29\n",
      "train: iter 669  trainloss -1500.82090  validloss -1308.62463±0.00000  bestvalidloss -1431.39866  last_update 30\n",
      "train: iter 670  trainloss -1518.25449  validloss -1387.07231±0.00000  bestvalidloss -1431.39866  last_update 31\n",
      "train: iter 671  trainloss -1482.63028  validloss -1383.10474±0.00000  bestvalidloss -1431.39866  last_update 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 672  trainloss -1528.40088  validloss -1393.68754±0.00000  bestvalidloss -1431.39866  last_update 33\n",
      "train: iter 673  trainloss -1488.88099  validloss -1393.66424±0.00000  bestvalidloss -1431.39866  last_update 34\n",
      "train: iter 674  trainloss -1255.70102  validloss -1235.07675±0.00000  bestvalidloss -1431.39866  last_update 35\n",
      "train: iter 675  trainloss -1472.09094  validloss -1300.08483±0.00000  bestvalidloss -1431.39866  last_update 36\n",
      "train: iter 676  trainloss -1523.96345  validloss -1305.82239±0.00000  bestvalidloss -1431.39866  last_update 37\n",
      "train: iter 677  trainloss -1473.00525  validloss -1412.60100±0.00000  bestvalidloss -1431.39866  last_update 38\n",
      "train: iter 678  trainloss -1401.15603  validloss -835.49695±0.00000  bestvalidloss -1431.39866  last_update 39\n",
      "train: iter 679  trainloss -1478.56290  validloss -1170.74912±0.00000  bestvalidloss -1431.39866  last_update 40\n",
      "train: iter 680  trainloss -1515.18352  validloss -1380.57902±0.00000  bestvalidloss -1431.39866  last_update 41\n",
      "train: iter 681  trainloss -1424.98669  validloss -1365.74648±0.00000  bestvalidloss -1431.39866  last_update 42\n",
      "train: iter 682  trainloss -1516.23309  validloss -1418.05283±0.00000  bestvalidloss -1431.39866  last_update 43\n",
      "train: iter 683  trainloss -1516.25036  validloss -1364.56506±0.00000  bestvalidloss -1431.39866  last_update 44\n",
      "train: iter 684  trainloss -1500.54229  validloss -1269.89401±0.00000  bestvalidloss -1431.39866  last_update 45\n",
      "train: iter 685  trainloss -1435.70444  validloss -1402.23305±0.00000  bestvalidloss -1431.39866  last_update 46\n",
      "train: iter 686  trainloss -1498.98851  validloss -1251.83975±0.00000  bestvalidloss -1431.39866  last_update 47\n",
      "train: iter 687  trainloss -1481.71163  validloss -1380.83945±0.00000  bestvalidloss -1431.39866  last_update 48\n",
      "train: iter 688  trainloss -1504.37128  validloss -1431.60631±0.00000  bestvalidloss -1431.60631  last_update 0\n",
      "train: iter 689  trainloss -1564.46899  validloss -1432.22599±0.00000  bestvalidloss -1432.22599  last_update 0\n",
      "train: iter 690  trainloss -1163.61651  validloss -1449.15685±0.00000  bestvalidloss -1449.15685  last_update 0\n",
      "train: iter 691  trainloss -1381.94275  validloss -1083.76359±0.00000  bestvalidloss -1449.15685  last_update 1\n",
      "train: iter 692  trainloss -1438.40746  validloss -1284.32799±0.00000  bestvalidloss -1449.15685  last_update 2\n",
      "train: iter 693  trainloss -1502.01046  validloss -1341.36945±0.00000  bestvalidloss -1449.15685  last_update 3\n",
      "train: iter 694  trainloss -1532.07310  validloss -1341.38445±0.00000  bestvalidloss -1449.15685  last_update 4\n",
      "train: iter 695  trainloss -1516.28529  validloss -1322.63142±0.00000  bestvalidloss -1449.15685  last_update 5\n",
      "train: iter 696  trainloss -1518.37416  validloss -1393.48327±0.00000  bestvalidloss -1449.15685  last_update 6\n",
      "train: iter 697  trainloss -1487.11399  validloss -1357.42857±0.00000  bestvalidloss -1449.15685  last_update 7\n",
      "train: iter 698  trainloss -1545.23956  validloss -1377.71495±0.00000  bestvalidloss -1449.15685  last_update 8\n",
      "train: iter 699  trainloss -1541.79930  validloss -1430.42757±0.00000  bestvalidloss -1449.15685  last_update 9\n",
      "train: iter 700  trainloss -1485.82415  validloss -1345.39689±0.00000  bestvalidloss -1449.15685  last_update 10\n",
      "train: iter 701  trainloss -1519.21730  validloss -1399.53895±0.00000  bestvalidloss -1449.15685  last_update 11\n",
      "train: iter 702  trainloss -1507.21758  validloss -1330.95428±0.00000  bestvalidloss -1449.15685  last_update 12\n",
      "train: iter 703  trainloss -1509.76703  validloss -1426.21328±0.00000  bestvalidloss -1449.15685  last_update 13\n",
      "train: iter 704  trainloss -1537.84579  validloss -1375.28345±0.00000  bestvalidloss -1449.15685  last_update 14\n",
      "train: iter 705  trainloss -1521.92330  validloss -1454.08419±0.00000  bestvalidloss -1454.08419  last_update 0\n",
      "train: iter 706  trainloss -1382.92919  validloss -910.95128±0.00000  bestvalidloss -1454.08419  last_update 1\n",
      "train: iter 707  trainloss -1512.40577  validloss -1305.09440±0.00000  bestvalidloss -1454.08419  last_update 2\n",
      "train: iter 708  trainloss -1455.18225  validloss -1311.48177±0.00000  bestvalidloss -1454.08419  last_update 3\n",
      "train: iter 709  trainloss -1523.54118  validloss -1360.52214±0.00000  bestvalidloss -1454.08419  last_update 4\n",
      "train: iter 710  trainloss -1534.46040  validloss -1403.39675±0.00000  bestvalidloss -1454.08419  last_update 5\n",
      "train: iter 711  trainloss -1499.42141  validloss -1261.38218±0.00000  bestvalidloss -1454.08419  last_update 6\n",
      "train: iter 712  trainloss -1504.90212  validloss -1365.85899±0.00000  bestvalidloss -1454.08419  last_update 7\n",
      "train: iter 713  trainloss -1520.01748  validloss -1412.79219±0.00000  bestvalidloss -1454.08419  last_update 8\n",
      "train: iter 714  trainloss -1536.90620  validloss -1405.12416±0.00000  bestvalidloss -1454.08419  last_update 9\n",
      "train: iter 715  trainloss -1341.81745  validloss -1402.50126±0.00000  bestvalidloss -1454.08419  last_update 10\n",
      "train: iter 716  trainloss -1511.53885  validloss -1397.24267±0.00000  bestvalidloss -1454.08419  last_update 11\n",
      "train: iter 717  trainloss -1520.81500  validloss -1335.66116±0.00000  bestvalidloss -1454.08419  last_update 12\n",
      "train: iter 718  trainloss -1547.60480  validloss -1434.96965±0.00000  bestvalidloss -1454.08419  last_update 13\n",
      "train: iter 719  trainloss -1477.05483  validloss -1415.72648±0.00000  bestvalidloss -1454.08419  last_update 14\n",
      "train: iter 720  trainloss -1269.28023  validloss -1216.08677±0.00000  bestvalidloss -1454.08419  last_update 15\n",
      "train: iter 721  trainloss -1516.00358  validloss -1311.36908±0.00000  bestvalidloss -1454.08419  last_update 16\n",
      "train: iter 722  trainloss -1514.30334  validloss -1404.74846±0.00000  bestvalidloss -1454.08419  last_update 17\n",
      "train: iter 723  trainloss -1547.53819  validloss -1352.24556±0.00000  bestvalidloss -1454.08419  last_update 18\n",
      "train: iter 724  trainloss -1527.91384  validloss -1430.54873±0.00000  bestvalidloss -1454.08419  last_update 19\n",
      "train: iter 725  trainloss -1510.24467  validloss -1388.21510±0.00000  bestvalidloss -1454.08419  last_update 20\n",
      "train: iter 726  trainloss -1499.83854  validloss -1243.84870±0.00000  bestvalidloss -1454.08419  last_update 21\n",
      "train: iter 727  trainloss -1549.45201  validloss -1334.64931±0.00000  bestvalidloss -1454.08419  last_update 22\n",
      "train: iter 728  trainloss -1510.68268  validloss -1424.90444±0.00000  bestvalidloss -1454.08419  last_update 23\n",
      "train: iter 729  trainloss -1494.94232  validloss -1326.76933±0.00000  bestvalidloss -1454.08419  last_update 24\n",
      "train: iter 730  trainloss -1488.40921  validloss -1348.07405±0.00000  bestvalidloss -1454.08419  last_update 25\n",
      "train: iter 731  trainloss -1544.95729  validloss -1379.95617±0.00000  bestvalidloss -1454.08419  last_update 26\n",
      "train: iter 732  trainloss -1478.87556  validloss -1377.96120±0.00000  bestvalidloss -1454.08419  last_update 27\n",
      "train: iter 733  trainloss -1448.02138  validloss -1354.56409±0.00000  bestvalidloss -1454.08419  last_update 28\n",
      "train: iter 734  trainloss -1532.51472  validloss -1410.16423±0.00000  bestvalidloss -1454.08419  last_update 29\n",
      "train: iter 735  trainloss -1478.51965  validloss -1388.60486±0.00000  bestvalidloss -1454.08419  last_update 30\n",
      "train: iter 736  trainloss -1481.01163  validloss -1247.03131±0.00000  bestvalidloss -1454.08419  last_update 31\n",
      "train: iter 737  trainloss -1453.38719  validloss -1240.04743±0.00000  bestvalidloss -1454.08419  last_update 32\n",
      "train: iter 738  trainloss -1417.93143  validloss -1271.23460±0.00000  bestvalidloss -1454.08419  last_update 33\n",
      "train: iter 739  trainloss -1509.47311  validloss -1365.47266±0.00000  bestvalidloss -1454.08419  last_update 34\n",
      "train: iter 740  trainloss -1482.75665  validloss -1423.73581±0.00000  bestvalidloss -1454.08419  last_update 35\n",
      "train: iter 741  trainloss -1546.26414  validloss -1396.29220±0.00000  bestvalidloss -1454.08419  last_update 36\n",
      "train: iter 742  trainloss -1510.45599  validloss -1395.74869±0.00000  bestvalidloss -1454.08419  last_update 37\n",
      "train: iter 743  trainloss -1490.15965  validloss -1315.94830±0.00000  bestvalidloss -1454.08419  last_update 38\n",
      "train: iter 744  trainloss -1563.93746  validloss -1391.15892±0.00000  bestvalidloss -1454.08419  last_update 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 745  trainloss -1487.77628  validloss -1429.21886±0.00000  bestvalidloss -1454.08419  last_update 40\n",
      "train: iter 746  trainloss -1400.72972  validloss -1362.08542±0.00000  bestvalidloss -1454.08419  last_update 41\n",
      "train: iter 747  trainloss -1529.89171  validloss -1361.87965±0.00000  bestvalidloss -1454.08419  last_update 42\n",
      "train: iter 748  trainloss -1547.89001  validloss -1365.14509±0.00000  bestvalidloss -1454.08419  last_update 43\n",
      "train: iter 749  trainloss -1513.91082  validloss -1426.97173±0.00000  bestvalidloss -1454.08419  last_update 44\n",
      "train: iter 750  trainloss -1354.33827  validloss -1142.03307±0.00000  bestvalidloss -1454.08419  last_update 45\n",
      "train: iter 751  trainloss -1459.67200  validloss -1126.84791±0.00000  bestvalidloss -1454.08419  last_update 46\n",
      "train: iter 752  trainloss -1546.77452  validloss -1398.51673±0.00000  bestvalidloss -1454.08419  last_update 47\n",
      "train: iter 753  trainloss -1527.99028  validloss -1311.99622±0.00000  bestvalidloss -1454.08419  last_update 48\n",
      "train: iter 754  trainloss -1521.05938  validloss -1405.01300±0.00000  bestvalidloss -1454.08419  last_update 49\n",
      "train: iter 755  trainloss -1520.44863  validloss -1429.77702±0.00000  bestvalidloss -1454.08419  last_update 50\n",
      "train: iter 756  trainloss -1521.98099  validloss -1414.40544±0.00000  bestvalidloss -1454.08419  last_update 51\n",
      "train: iter 757  trainloss -1543.93916  validloss -1369.56537±0.00000  bestvalidloss -1454.08419  last_update 52\n",
      "train: iter 758  trainloss -1562.80062  validloss -1436.61624±0.00000  bestvalidloss -1454.08419  last_update 53\n",
      "train: iter 759  trainloss -1519.80993  validloss -1313.79952±0.00000  bestvalidloss -1454.08419  last_update 54\n",
      "train: iter 760  trainloss -1325.32379  validloss -865.58986±0.00000  bestvalidloss -1454.08419  last_update 55\n",
      "train: iter 761  trainloss -1447.69329  validloss -1366.98285±0.00000  bestvalidloss -1454.08419  last_update 56\n",
      "train: iter 762  trainloss -1474.74476  validloss -1343.39802±0.00000  bestvalidloss -1454.08419  last_update 57\n",
      "train: iter 763  trainloss -1478.07956  validloss -1251.19361±0.00000  bestvalidloss -1454.08419  last_update 58\n",
      "train: iter 764  trainloss -1519.13560  validloss -1444.57416±0.00000  bestvalidloss -1454.08419  last_update 59\n",
      "train: iter 765  trainloss -1489.29548  validloss -1394.35328±0.00000  bestvalidloss -1454.08419  last_update 60\n",
      "train: iter 766  trainloss -1546.18869  validloss -1330.36582±0.00000  bestvalidloss -1454.08419  last_update 61\n",
      "train: iter 767  trainloss -1383.25482  validloss -1392.96398±0.00000  bestvalidloss -1454.08419  last_update 62\n",
      "train: iter 768  trainloss -1492.41726  validloss -1100.80451±0.00000  bestvalidloss -1454.08419  last_update 63\n",
      "train: iter 769  trainloss -1478.17439  validloss -1372.57223±0.00000  bestvalidloss -1454.08419  last_update 64\n",
      "train: iter 770  trainloss -1253.86161  validloss -1316.86837±0.00000  bestvalidloss -1454.08419  last_update 65\n",
      "train: iter 771  trainloss -1430.22439  validloss -1257.51481±0.00000  bestvalidloss -1454.08419  last_update 66\n",
      "train: iter 772  trainloss -1521.38809  validloss -1375.57666±0.00000  bestvalidloss -1454.08419  last_update 67\n",
      "train: iter 773  trainloss -1454.80158  validloss -1407.26879±0.00000  bestvalidloss -1454.08419  last_update 68\n",
      "train: iter 774  trainloss -1371.60087  validloss -1237.62220±0.00000  bestvalidloss -1454.08419  last_update 69\n",
      "train: iter 775  trainloss -1482.99151  validloss -1356.02162±0.00000  bestvalidloss -1454.08419  last_update 70\n",
      "train: iter 776  trainloss -1515.45344  validloss -1353.44951±0.00000  bestvalidloss -1454.08419  last_update 71\n",
      "train: iter 777  trainloss -1547.43631  validloss -1379.17927±0.00000  bestvalidloss -1454.08419  last_update 72\n",
      "train: iter 778  trainloss -1524.05955  validloss -1386.84175±0.00000  bestvalidloss -1454.08419  last_update 73\n",
      "train: iter 779  trainloss -1560.45870  validloss -1399.53099±0.00000  bestvalidloss -1454.08419  last_update 74\n",
      "train: iter 780  trainloss -1498.75997  validloss -1417.64170±0.00000  bestvalidloss -1454.08419  last_update 75\n",
      "train: iter 781  trainloss -1558.70867  validloss -1417.52095±0.00000  bestvalidloss -1454.08419  last_update 76\n",
      "train: iter 782  trainloss -1480.35370  validloss -1179.65777±0.00000  bestvalidloss -1454.08419  last_update 77\n",
      "train: iter 783  trainloss -1430.90183  validloss -1372.10492±0.00000  bestvalidloss -1454.08419  last_update 78\n",
      "train: iter 784  trainloss -1544.48657  validloss -1226.86647±0.00000  bestvalidloss -1454.08419  last_update 79\n",
      "train: iter 785  trainloss -1536.63552  validloss -1397.83726±0.00000  bestvalidloss -1454.08419  last_update 80\n",
      "train: iter 786  trainloss -1532.46838  validloss -1437.92883±0.00000  bestvalidloss -1454.08419  last_update 81\n",
      "train: iter 787  trainloss -1569.32924  validloss -1355.82506±0.00000  bestvalidloss -1454.08419  last_update 82\n",
      "train: iter 788  trainloss -1566.79785  validloss -1431.05556±0.00000  bestvalidloss -1454.08419  last_update 83\n",
      "train: iter 789  trainloss -1531.65042  validloss -1451.31819±0.00000  bestvalidloss -1454.08419  last_update 84\n",
      "train: iter 790  trainloss -1513.34230  validloss -1111.85201±0.00000  bestvalidloss -1454.08419  last_update 85\n",
      "train: iter 791  trainloss -1479.34448  validloss -1383.99605±0.00000  bestvalidloss -1454.08419  last_update 86\n",
      "train: iter 792  trainloss -1363.41278  validloss -185.95946±0.00000  bestvalidloss -1454.08419  last_update 87\n",
      "train: iter 793  trainloss -1525.20866  validloss -1248.62906±0.00000  bestvalidloss -1454.08419  last_update 88\n",
      "train: iter 794  trainloss -1536.65534  validloss -1403.52771±0.00000  bestvalidloss -1454.08419  last_update 89\n",
      "train: iter 795  trainloss -1536.75382  validloss -1299.51254±0.00000  bestvalidloss -1454.08419  last_update 90\n",
      "train: iter 796  trainloss -1427.29563  validloss -1404.22405±0.00000  bestvalidloss -1454.08419  last_update 91\n",
      "train: iter 797  trainloss -1477.70458  validloss -1334.15105±0.00000  bestvalidloss -1454.08419  last_update 92\n",
      "train: iter 798  trainloss -1540.18752  validloss -1418.52494±0.00000  bestvalidloss -1454.08419  last_update 93\n",
      "train: iter 799  trainloss -1496.39064  validloss -1358.86593±0.00000  bestvalidloss -1454.08419  last_update 94\n",
      "train: iter 800  trainloss -1548.86035  validloss -1343.14957±0.00000  bestvalidloss -1454.08419  last_update 95\n",
      "train: iter 801  trainloss -1538.70301  validloss -1431.18113±0.00000  bestvalidloss -1454.08419  last_update 96\n",
      "train: iter 802  trainloss -1361.49821  validloss -926.60300±0.00000  bestvalidloss -1454.08419  last_update 97\n",
      "train: iter 803  trainloss -1519.60653  validloss -1384.59266±0.00000  bestvalidloss -1454.08419  last_update 98\n",
      "train: iter 804  trainloss -1443.66836  validloss -1349.64716±0.00000  bestvalidloss -1454.08419  last_update 99\n",
      "train: iter 805  trainloss -1552.04329  validloss -1395.75910±0.00000  bestvalidloss -1454.08419  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.4772) penalty_target_max tensor(42.2647)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.60148  validloss 10.04462±0.00000  bestvalidloss 10.04462  last_update 0\n",
      "train: iter 1  trainloss 8.77352  validloss 9.17064±0.00000  bestvalidloss 9.17064  last_update 0\n",
      "train: iter 2  trainloss 8.09014  validloss 8.38891±0.00000  bestvalidloss 8.38891  last_update 0\n",
      "train: iter 3  trainloss 7.50745  validloss 7.77532±0.00000  bestvalidloss 7.77532  last_update 0\n",
      "train: iter 4  trainloss 7.01821  validloss 7.26225±0.00000  bestvalidloss 7.26225  last_update 0\n",
      "train: iter 5  trainloss 6.59395  validloss 6.79888±0.00000  bestvalidloss 6.79888  last_update 0\n",
      "train: iter 6  trainloss 6.20966  validloss 6.40390±0.00000  bestvalidloss 6.40390  last_update 0\n",
      "train: iter 7  trainloss 5.88730  validloss 6.05110±0.00000  bestvalidloss 6.05110  last_update 0\n",
      "train: iter 8  trainloss 5.61037  validloss 5.73199±0.00000  bestvalidloss 5.73199  last_update 0\n",
      "train: iter 9  trainloss 5.35470  validloss 5.48423±0.00000  bestvalidloss 5.48423  last_update 0\n",
      "train: iter 10  trainloss 5.12960  validloss 5.23581±0.00000  bestvalidloss 5.23581  last_update 0\n",
      "train: iter 11  trainloss 4.91736  validloss 5.02524±0.00000  bestvalidloss 5.02524  last_update 0\n",
      "train: iter 12  trainloss 4.72807  validloss 4.82922±0.00000  bestvalidloss 4.82922  last_update 0\n",
      "train: iter 13  trainloss 4.55842  validloss 4.64386±0.00000  bestvalidloss 4.64386  last_update 0\n",
      "train: iter 14  trainloss 4.39691  validloss 4.48488±0.00000  bestvalidloss 4.48488  last_update 0\n",
      "train: iter 15  trainloss 4.25531  validloss 4.33696±0.00000  bestvalidloss 4.33696  last_update 0\n",
      "train: iter 16  trainloss 4.12119  validloss 4.19785±0.00000  bestvalidloss 4.19785  last_update 0\n",
      "train: iter 17  trainloss 4.00126  validloss 4.06394±0.00000  bestvalidloss 4.06394  last_update 0\n",
      "train: iter 18  trainloss 3.88813  validloss 3.95965±0.00000  bestvalidloss 3.95965  last_update 0\n",
      "train: iter 19  trainloss 3.77643  validloss 3.84060±0.00000  bestvalidloss 3.84060  last_update 0\n",
      "train: iter 20  trainloss 3.68472  validloss 3.74580±0.00000  bestvalidloss 3.74580  last_update 0\n",
      "train: iter 21  trainloss 3.59120  validloss 3.65097±0.00000  bestvalidloss 3.65097  last_update 0\n",
      "train: iter 22  trainloss 3.50606  validloss 3.56048±0.00000  bestvalidloss 3.56048  last_update 0\n",
      "train: iter 23  trainloss 3.43188  validloss 3.48650±0.00000  bestvalidloss 3.48650  last_update 0\n",
      "train: iter 24  trainloss 3.35486  validloss 3.40103±0.00000  bestvalidloss 3.40103  last_update 0\n",
      "train: iter 25  trainloss 3.28926  validloss 3.34046±0.00000  bestvalidloss 3.34046  last_update 0\n",
      "train: iter 26  trainloss 3.22967  validloss 3.28225±0.00000  bestvalidloss 3.28225  last_update 0\n",
      "train: iter 27  trainloss 3.17706  validloss 3.22389±0.00000  bestvalidloss 3.22389  last_update 0\n",
      "train: iter 28  trainloss 3.12028  validloss 3.16985±0.00000  bestvalidloss 3.16985  last_update 0\n",
      "train: iter 29  trainloss 3.06691  validloss 3.11767±0.00000  bestvalidloss 3.11767  last_update 0\n",
      "train: iter 30  trainloss 3.03006  validloss 3.08547±0.00000  bestvalidloss 3.08547  last_update 0\n",
      "train: iter 31  trainloss 2.99455  validloss 3.04733±0.00000  bestvalidloss 3.04733  last_update 0\n",
      "train: iter 32  trainloss 2.95526  validloss 2.99050±0.00000  bestvalidloss 2.99050  last_update 0\n",
      "train: iter 33  trainloss 2.92056  validloss 2.96211±0.00000  bestvalidloss 2.96211  last_update 0\n",
      "train: iter 34  trainloss 2.88873  validloss 2.94740±0.00000  bestvalidloss 2.94740  last_update 0\n",
      "train: iter 35  trainloss 2.84822  validloss 2.91012±0.00000  bestvalidloss 2.91012  last_update 0\n",
      "train: iter 36  trainloss 2.82276  validloss 2.89077±0.00000  bestvalidloss 2.89077  last_update 0\n",
      "train: iter 37  trainloss 2.79157  validloss 2.84571±0.00000  bestvalidloss 2.84571  last_update 0\n",
      "train: iter 38  trainloss 2.78114  validloss 2.82257±0.00000  bestvalidloss 2.82257  last_update 0\n",
      "train: iter 39  trainloss 2.73760  validloss 2.79300±0.00000  bestvalidloss 2.79300  last_update 0\n",
      "train: iter 40  trainloss 2.71900  validloss 2.75569±0.00000  bestvalidloss 2.75569  last_update 0\n",
      "train: iter 41  trainloss 2.69150  validloss 2.73592±0.00000  bestvalidloss 2.73592  last_update 0\n",
      "train: iter 42  trainloss 2.66645  validloss 2.72532±0.00000  bestvalidloss 2.72532  last_update 0\n",
      "train: iter 43  trainloss 2.64476  validloss 2.68569±0.00000  bestvalidloss 2.68569  last_update 0\n",
      "train: iter 44  trainloss 2.62457  validloss 2.66374±0.00000  bestvalidloss 2.66374  last_update 0\n",
      "train: iter 45  trainloss 2.58505  validloss 2.65558±0.00000  bestvalidloss 2.65558  last_update 0\n",
      "train: iter 46  trainloss 2.57801  validloss 2.62151±0.00000  bestvalidloss 2.62151  last_update 0\n",
      "train: iter 47  trainloss 2.54099  validloss 2.62902±0.00000  bestvalidloss 2.62151  last_update 1\n",
      "train: iter 48  trainloss 2.50310  validloss 2.55819±0.00000  bestvalidloss 2.55819  last_update 0\n",
      "train: iter 49  trainloss 2.48675  validloss 2.54173±0.00000  bestvalidloss 2.54173  last_update 0\n",
      "train: iter 50  trainloss 2.45594  validloss 2.50848±0.00000  bestvalidloss 2.50848  last_update 0\n",
      "train: iter 51  trainloss 2.42528  validloss 2.50312±0.00000  bestvalidloss 2.50312  last_update 0\n",
      "train: iter 52  trainloss 2.40545  validloss 2.47376±0.00000  bestvalidloss 2.47376  last_update 0\n",
      "train: iter 53  trainloss 2.37666  validloss 2.45489±0.00000  bestvalidloss 2.45489  last_update 0\n",
      "train: iter 54  trainloss 2.33453  validloss 2.39439±0.00000  bestvalidloss 2.39439  last_update 0\n",
      "train: iter 55  trainloss 2.31370  validloss 2.37702±0.00000  bestvalidloss 2.37702  last_update 0\n",
      "train: iter 56  trainloss 2.28122  validloss 2.34785±0.00000  bestvalidloss 2.34785  last_update 0\n",
      "train: iter 57  trainloss 2.23350  validloss 2.28862±0.00000  bestvalidloss 2.28862  last_update 0\n",
      "train: iter 58  trainloss 2.20307  validloss 2.27994±0.00000  bestvalidloss 2.27994  last_update 0\n",
      "train: iter 59  trainloss 2.16683  validloss 2.23530±0.00000  bestvalidloss 2.23530  last_update 0\n",
      "train: iter 60  trainloss 2.12844  validloss 2.19839±0.00000  bestvalidloss 2.19839  last_update 0\n",
      "train: iter 61  trainloss 2.08947  validloss 2.13280±0.00000  bestvalidloss 2.13280  last_update 0\n",
      "train: iter 62  trainloss 2.03294  validloss 2.12624±0.00000  bestvalidloss 2.12624  last_update 0\n",
      "train: iter 63  trainloss 1.99568  validloss 2.09060±0.00000  bestvalidloss 2.09060  last_update 0\n",
      "train: iter 64  trainloss 1.96301  validloss 2.02854±0.00000  bestvalidloss 2.02854  last_update 0\n",
      "train: iter 65  trainloss 1.90680  validloss 1.97039±0.00000  bestvalidloss 1.97039  last_update 0\n",
      "train: iter 66  trainloss 1.85477  validloss 1.94058±0.00000  bestvalidloss 1.94058  last_update 0\n",
      "train: iter 67  trainloss 1.81326  validloss 1.88589±0.00000  bestvalidloss 1.88589  last_update 0\n",
      "train: iter 68  trainloss 1.77795  validloss 1.83569±0.00000  bestvalidloss 1.83569  last_update 0\n",
      "train: iter 69  trainloss 1.72941  validloss 1.80385±0.00000  bestvalidloss 1.80385  last_update 0\n",
      "train: iter 70  trainloss 1.68333  validloss 1.77148±0.00000  bestvalidloss 1.77148  last_update 0\n",
      "train: iter 71  trainloss 1.64858  validloss 1.72671±0.00000  bestvalidloss 1.72671  last_update 0\n",
      "train: iter 72  trainloss 1.60415  validloss 1.67696±0.00000  bestvalidloss 1.67696  last_update 0\n",
      "train: iter 73  trainloss 1.55642  validloss 1.63879±0.00000  bestvalidloss 1.63879  last_update 0\n",
      "train: iter 74  trainloss 1.51109  validloss 1.57160±0.00000  bestvalidloss 1.57160  last_update 0\n",
      "train: iter 75  trainloss 1.47141  validloss 1.55501±0.00000  bestvalidloss 1.55501  last_update 0\n",
      "train: iter 76  trainloss 1.42932  validloss 1.49776±0.00000  bestvalidloss 1.49776  last_update 0\n",
      "train: iter 77  trainloss 1.39776  validloss 1.45259±0.00000  bestvalidloss 1.45259  last_update 0\n",
      "train: iter 78  trainloss 1.35502  validloss 1.44488±0.00000  bestvalidloss 1.44488  last_update 0\n",
      "train: iter 79  trainloss 1.31027  validloss 1.39469±0.00000  bestvalidloss 1.39469  last_update 0\n",
      "train: iter 80  trainloss 1.28493  validloss 1.36477±0.00000  bestvalidloss 1.36477  last_update 0\n",
      "train: iter 81  trainloss 1.25087  validloss 1.29644±0.00000  bestvalidloss 1.29644  last_update 0\n",
      "train: iter 82  trainloss 1.22325  validloss 1.28511±0.00000  bestvalidloss 1.28511  last_update 0\n",
      "train: iter 83  trainloss 1.17558  validloss 1.26088±0.00000  bestvalidloss 1.26088  last_update 0\n",
      "train: iter 84  trainloss 1.14768  validloss 1.19601±0.00000  bestvalidloss 1.19601  last_update 0\n",
      "train: iter 85  trainloss 1.10808  validloss 1.18615±0.00000  bestvalidloss 1.18615  last_update 0\n",
      "train: iter 86  trainloss 1.07341  validloss 1.15595±0.00000  bestvalidloss 1.15595  last_update 0\n",
      "train: iter 87  trainloss 1.06257  validloss 1.13162±0.00000  bestvalidloss 1.13162  last_update 0\n",
      "train: iter 88  trainloss 1.02101  validloss 1.10454±0.00000  bestvalidloss 1.10454  last_update 0\n",
      "train: iter 89  trainloss 0.99164  validloss 1.06570±0.00000  bestvalidloss 1.06570  last_update 0\n",
      "train: iter 90  trainloss 0.95908  validloss 1.05951±0.00000  bestvalidloss 1.05951  last_update 0\n",
      "train: iter 91  trainloss 0.93221  validloss 0.97704±0.00000  bestvalidloss 0.97704  last_update 0\n",
      "train: iter 92  trainloss 0.89417  validloss 0.99443±0.00000  bestvalidloss 0.97704  last_update 1\n",
      "train: iter 93  trainloss 0.86569  validloss 0.94673±0.00000  bestvalidloss 0.94673  last_update 0\n",
      "train: iter 94  trainloss 0.84297  validloss 0.94519±0.00000  bestvalidloss 0.94519  last_update 0\n",
      "train: iter 95  trainloss 0.83020  validloss 0.88753±0.00000  bestvalidloss 0.88753  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 96  trainloss 0.78953  validloss 0.88332±0.00000  bestvalidloss 0.88332  last_update 0\n",
      "train: iter 97  trainloss 0.78918  validloss 0.87951±0.00000  bestvalidloss 0.87951  last_update 0\n",
      "train: iter 98  trainloss 0.75373  validloss 0.81552±0.00000  bestvalidloss 0.81552  last_update 0\n",
      "train: iter 99  trainloss 0.73041  validloss 0.83198±0.00000  bestvalidloss 0.81552  last_update 1\n",
      "train: iter 100  trainloss 0.71931  validloss 0.83027±0.00000  bestvalidloss 0.81552  last_update 2\n",
      "train: iter 101  trainloss 0.70091  validloss 0.78334±0.00000  bestvalidloss 0.78334  last_update 0\n",
      "train: iter 102  trainloss 0.69122  validloss 0.75338±0.00000  bestvalidloss 0.75338  last_update 0\n",
      "train: iter 103  trainloss 0.66663  validloss 0.73890±0.00000  bestvalidloss 0.73890  last_update 0\n",
      "train: iter 104  trainloss 0.64066  validloss 0.73558±0.00000  bestvalidloss 0.73558  last_update 0\n",
      "train: iter 105  trainloss 0.65072  validloss 0.70706±0.00000  bestvalidloss 0.70706  last_update 0\n",
      "train: iter 106  trainloss 0.62394  validloss 0.67729±0.00000  bestvalidloss 0.67729  last_update 0\n",
      "train: iter 107  trainloss 0.61598  validloss 0.74513±0.00000  bestvalidloss 0.67729  last_update 1\n",
      "train: iter 108  trainloss 0.60980  validloss 0.69495±0.00000  bestvalidloss 0.67729  last_update 2\n",
      "train: iter 109  trainloss 0.59645  validloss 0.64700±0.00000  bestvalidloss 0.64700  last_update 0\n",
      "train: iter 110  trainloss 0.60418  validloss 0.67263±0.00000  bestvalidloss 0.64700  last_update 1\n",
      "train: iter 111  trainloss 0.59481  validloss 0.68294±0.00000  bestvalidloss 0.64700  last_update 2\n",
      "train: iter 112  trainloss 0.58265  validloss 0.62181±0.00000  bestvalidloss 0.62181  last_update 0\n",
      "train: iter 113  trainloss 0.56117  validloss 0.68602±0.00000  bestvalidloss 0.62181  last_update 1\n",
      "train: iter 114  trainloss 0.53815  validloss 0.60769±0.00000  bestvalidloss 0.60769  last_update 0\n",
      "train: iter 115  trainloss 0.55529  validloss 0.67328±0.00000  bestvalidloss 0.60769  last_update 1\n",
      "train: iter 116  trainloss 0.55842  validloss 0.67190±0.00000  bestvalidloss 0.60769  last_update 2\n",
      "train: iter 117  trainloss 0.54700  validloss 0.63423±0.00000  bestvalidloss 0.60769  last_update 3\n",
      "train: iter 118  trainloss 0.54819  validloss 0.59698±0.00000  bestvalidloss 0.59698  last_update 0\n",
      "train: iter 119  trainloss 0.53694  validloss 0.69613±0.00000  bestvalidloss 0.59698  last_update 1\n",
      "train: iter 120  trainloss 0.53569  validloss 0.63289±0.00000  bestvalidloss 0.59698  last_update 2\n",
      "train: iter 121  trainloss 0.51380  validloss 0.59829±0.00000  bestvalidloss 0.59698  last_update 3\n",
      "train: iter 122  trainloss 0.54017  validloss 0.60612±0.00000  bestvalidloss 0.59698  last_update 4\n",
      "train: iter 123  trainloss 0.50790  validloss 0.63905±0.00000  bestvalidloss 0.59698  last_update 5\n",
      "train: iter 124  trainloss 0.53633  validloss 0.65395±0.00000  bestvalidloss 0.59698  last_update 6\n",
      "train: iter 125  trainloss 0.52383  validloss 0.62370±0.00000  bestvalidloss 0.59698  last_update 7\n",
      "train: iter 126  trainloss 0.53459  validloss 0.60164±0.00000  bestvalidloss 0.59698  last_update 8\n",
      "train: iter 127  trainloss 0.53064  validloss 0.66173±0.00000  bestvalidloss 0.59698  last_update 9\n",
      "train: iter 128  trainloss 0.53523  validloss 0.56671±0.00000  bestvalidloss 0.56671  last_update 0\n",
      "train: iter 129  trainloss 0.51210  validloss 0.62542±0.00000  bestvalidloss 0.56671  last_update 1\n",
      "train: iter 130  trainloss 0.53668  validloss 0.66889±0.00000  bestvalidloss 0.56671  last_update 2\n",
      "train: iter 131  trainloss 0.54425  validloss 0.61504±0.00000  bestvalidloss 0.56671  last_update 3\n",
      "train: iter 132  trainloss 0.49812  validloss 0.58469±0.00000  bestvalidloss 0.56671  last_update 4\n",
      "train: iter 133  trainloss 0.52396  validloss 0.66858±0.00000  bestvalidloss 0.56671  last_update 5\n",
      "train: iter 134  trainloss 0.51950  validloss 0.59785±0.00000  bestvalidloss 0.56671  last_update 6\n",
      "train: iter 135  trainloss 0.53535  validloss 0.62787±0.00000  bestvalidloss 0.56671  last_update 7\n",
      "train: iter 136  trainloss 0.53405  validloss 0.64712±0.00000  bestvalidloss 0.56671  last_update 8\n",
      "train: iter 137  trainloss 0.49349  validloss 0.62739±0.00000  bestvalidloss 0.56671  last_update 9\n",
      "train: iter 138  trainloss 0.52241  validloss 0.66754±0.00000  bestvalidloss 0.56671  last_update 10\n",
      "train: iter 139  trainloss 0.51494  validloss 0.58963±0.00000  bestvalidloss 0.56671  last_update 11\n",
      "train: iter 140  trainloss 0.53433  validloss 0.70293±0.00000  bestvalidloss 0.56671  last_update 12\n",
      "train: iter 141  trainloss 0.55295  validloss 0.60672±0.00000  bestvalidloss 0.56671  last_update 13\n",
      "train: iter 142  trainloss 0.53788  validloss 0.63375±0.00000  bestvalidloss 0.56671  last_update 14\n",
      "train: iter 143  trainloss 0.50287  validloss 0.63474±0.00000  bestvalidloss 0.56671  last_update 15\n",
      "train: iter 144  trainloss 0.53774  validloss 0.65894±0.00000  bestvalidloss 0.56671  last_update 16\n",
      "train: iter 145  trainloss 0.54133  validloss 0.64472±0.00000  bestvalidloss 0.56671  last_update 17\n",
      "train: iter 146  trainloss 0.52686  validloss 0.59864±0.00000  bestvalidloss 0.56671  last_update 18\n",
      "train: iter 147  trainloss 0.53649  validloss 0.64515±0.00000  bestvalidloss 0.56671  last_update 19\n",
      "train: iter 148  trainloss 0.52612  validloss 0.65127±0.00000  bestvalidloss 0.56671  last_update 20\n",
      "train: iter 149  trainloss 0.52305  validloss 0.66170±0.00000  bestvalidloss 0.56671  last_update 21\n",
      "train: iter 150  trainloss 0.54095  validloss 0.66463±0.00000  bestvalidloss 0.56671  last_update 22\n",
      "train: iter 151  trainloss 0.51314  validloss 0.60592±0.00000  bestvalidloss 0.56671  last_update 23\n",
      "train: iter 152  trainloss 0.54158  validloss 0.70462±0.00000  bestvalidloss 0.56671  last_update 24\n",
      "train: iter 153  trainloss 0.55885  validloss 0.65186±0.00000  bestvalidloss 0.56671  last_update 25\n",
      "train: iter 154  trainloss 0.51825  validloss 0.67307±0.00000  bestvalidloss 0.56671  last_update 26\n",
      "train: iter 155  trainloss 0.52170  validloss 0.57509±0.00000  bestvalidloss 0.56671  last_update 27\n",
      "train: iter 156  trainloss 0.52736  validloss 0.60679±0.00000  bestvalidloss 0.56671  last_update 28\n",
      "train: iter 157  trainloss 0.52937  validloss 0.60585±0.00000  bestvalidloss 0.56671  last_update 29\n",
      "train: iter 158  trainloss 0.50461  validloss 0.67026±0.00000  bestvalidloss 0.56671  last_update 30\n",
      "train: iter 159  trainloss 0.54344  validloss 0.64340±0.00000  bestvalidloss 0.56671  last_update 31\n",
      "train: iter 160  trainloss 0.54216  validloss 0.59145±0.00000  bestvalidloss 0.56671  last_update 32\n",
      "train: iter 161  trainloss 0.52881  validloss 0.63765±0.00000  bestvalidloss 0.56671  last_update 33\n",
      "train: iter 162  trainloss 0.53594  validloss 0.59127±0.00000  bestvalidloss 0.56671  last_update 34\n",
      "train: iter 163  trainloss 0.53666  validloss 0.61071±0.00000  bestvalidloss 0.56671  last_update 35\n",
      "train: iter 164  trainloss 0.53729  validloss 0.65474±0.00000  bestvalidloss 0.56671  last_update 36\n",
      "train: iter 165  trainloss 0.51791  validloss 0.64655±0.00000  bestvalidloss 0.56671  last_update 37\n",
      "train: iter 166  trainloss 0.54626  validloss 0.61828±0.00000  bestvalidloss 0.56671  last_update 38\n",
      "train: iter 167  trainloss 0.53789  validloss 0.68677±0.00000  bestvalidloss 0.56671  last_update 39\n",
      "train: iter 168  trainloss 0.51032  validloss 0.58745±0.00000  bestvalidloss 0.56671  last_update 40\n",
      "train: iter 169  trainloss 0.49653  validloss 0.68054±0.00000  bestvalidloss 0.56671  last_update 41\n",
      "train: iter 170  trainloss 0.50837  validloss 0.62219±0.00000  bestvalidloss 0.56671  last_update 42\n",
      "train: iter 171  trainloss 0.53491  validloss 0.65827±0.00000  bestvalidloss 0.56671  last_update 43\n",
      "train: iter 172  trainloss 0.52232  validloss 0.60241±0.00000  bestvalidloss 0.56671  last_update 44\n",
      "train: iter 173  trainloss 0.49738  validloss 0.62716±0.00000  bestvalidloss 0.56671  last_update 45\n",
      "train: iter 174  trainloss 0.52107  validloss 0.66608±0.00000  bestvalidloss 0.56671  last_update 46\n",
      "train: iter 175  trainloss 0.51554  validloss 0.61723±0.00000  bestvalidloss 0.56671  last_update 47\n",
      "train: iter 176  trainloss 0.51959  validloss 0.63798±0.00000  bestvalidloss 0.56671  last_update 48\n",
      "train: iter 177  trainloss 0.55575  validloss 0.61785±0.00000  bestvalidloss 0.56671  last_update 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 178  trainloss 0.50975  validloss 0.61630±0.00000  bestvalidloss 0.56671  last_update 50\n",
      "train: iter 179  trainloss 0.52732  validloss 0.63989±0.00000  bestvalidloss 0.56671  last_update 51\n",
      "train: iter 180  trainloss 0.53886  validloss 0.64010±0.00000  bestvalidloss 0.56671  last_update 52\n",
      "train: iter 181  trainloss 0.53522  validloss 0.60828±0.00000  bestvalidloss 0.56671  last_update 53\n",
      "train: iter 182  trainloss 0.52568  validloss 0.68039±0.00000  bestvalidloss 0.56671  last_update 54\n",
      "train: iter 183  trainloss 0.52349  validloss 0.68283±0.00000  bestvalidloss 0.56671  last_update 55\n",
      "train: iter 184  trainloss 0.50414  validloss 0.62340±0.00000  bestvalidloss 0.56671  last_update 56\n",
      "train: iter 185  trainloss 0.53049  validloss 0.59547±0.00000  bestvalidloss 0.56671  last_update 57\n",
      "train: iter 186  trainloss 0.49306  validloss 0.73650±0.00000  bestvalidloss 0.56671  last_update 58\n",
      "train: iter 187  trainloss 0.50338  validloss 0.64914±0.00000  bestvalidloss 0.56671  last_update 59\n",
      "train: iter 188  trainloss 0.51942  validloss 0.63697±0.00000  bestvalidloss 0.56671  last_update 60\n",
      "train: iter 189  trainloss 0.48284  validloss 0.66296±0.00000  bestvalidloss 0.56671  last_update 61\n",
      "train: iter 190  trainloss 0.53337  validloss 0.65280±0.00000  bestvalidloss 0.56671  last_update 62\n",
      "train: iter 191  trainloss 0.53992  validloss 0.61081±0.00000  bestvalidloss 0.56671  last_update 63\n",
      "train: iter 192  trainloss 0.52907  validloss 0.64646±0.00000  bestvalidloss 0.56671  last_update 64\n",
      "train: iter 193  trainloss 0.54725  validloss 0.60917±0.00000  bestvalidloss 0.56671  last_update 65\n",
      "train: iter 194  trainloss 0.50839  validloss 0.69440±0.00000  bestvalidloss 0.56671  last_update 66\n",
      "train: iter 195  trainloss 0.52461  validloss 0.68008±0.00000  bestvalidloss 0.56671  last_update 67\n",
      "train: iter 196  trainloss 0.53800  validloss 0.62690±0.00000  bestvalidloss 0.56671  last_update 68\n",
      "train: iter 197  trainloss 0.53417  validloss 0.70495±0.00000  bestvalidloss 0.56671  last_update 69\n",
      "train: iter 198  trainloss 0.52874  validloss 0.61567±0.00000  bestvalidloss 0.56671  last_update 70\n",
      "train: iter 199  trainloss 0.53881  validloss 0.62759±0.00000  bestvalidloss 0.56671  last_update 71\n",
      "train: iter 200  trainloss 0.50875  validloss 0.68619±0.00000  bestvalidloss 0.56671  last_update 72\n",
      "train: iter 201  trainloss 0.53183  validloss 0.67782±0.00000  bestvalidloss 0.56671  last_update 73\n",
      "train: iter 202  trainloss 0.56364  validloss 0.67470±0.00000  bestvalidloss 0.56671  last_update 74\n",
      "train: iter 203  trainloss 0.51537  validloss 0.57997±0.00000  bestvalidloss 0.56671  last_update 75\n",
      "train: iter 204  trainloss 0.51692  validloss 0.63919±0.00000  bestvalidloss 0.56671  last_update 76\n",
      "train: iter 205  trainloss 0.55281  validloss 0.61539±0.00000  bestvalidloss 0.56671  last_update 77\n",
      "train: iter 206  trainloss 0.51226  validloss 0.70224±0.00000  bestvalidloss 0.56671  last_update 78\n",
      "train: iter 207  trainloss 0.50949  validloss 0.58219±0.00000  bestvalidloss 0.56671  last_update 79\n",
      "train: iter 208  trainloss 0.53421  validloss 0.59685±0.00000  bestvalidloss 0.56671  last_update 80\n",
      "train: iter 209  trainloss 0.51119  validloss 0.63738±0.00000  bestvalidloss 0.56671  last_update 81\n",
      "train: iter 210  trainloss 0.54164  validloss 0.65764±0.00000  bestvalidloss 0.56671  last_update 82\n",
      "train: iter 211  trainloss 0.50730  validloss 0.66139±0.00000  bestvalidloss 0.56671  last_update 83\n",
      "train: iter 212  trainloss 0.54074  validloss 0.58302±0.00000  bestvalidloss 0.56671  last_update 84\n",
      "train: iter 213  trainloss 0.52504  validloss 0.61731±0.00000  bestvalidloss 0.56671  last_update 85\n",
      "train: iter 214  trainloss 0.53600  validloss 0.64470±0.00000  bestvalidloss 0.56671  last_update 86\n",
      "train: iter 215  trainloss 0.52558  validloss 0.61980±0.00000  bestvalidloss 0.56671  last_update 87\n",
      "train: iter 216  trainloss 0.49584  validloss 0.59089±0.00000  bestvalidloss 0.56671  last_update 88\n",
      "train: iter 217  trainloss 0.53566  validloss 0.67952±0.00000  bestvalidloss 0.56671  last_update 89\n",
      "train: iter 218  trainloss 0.51670  validloss 0.64032±0.00000  bestvalidloss 0.56671  last_update 90\n",
      "train: iter 219  trainloss 0.53223  validloss 0.56527±0.00000  bestvalidloss 0.56527  last_update 0\n",
      "train: iter 220  trainloss 0.50637  validloss 0.66378±0.00000  bestvalidloss 0.56527  last_update 1\n",
      "train: iter 221  trainloss 0.50092  validloss 0.69243±0.00000  bestvalidloss 0.56527  last_update 2\n",
      "train: iter 222  trainloss 0.49003  validloss 0.66603±0.00000  bestvalidloss 0.56527  last_update 3\n",
      "train: iter 223  trainloss 0.52083  validloss 0.68502±0.00000  bestvalidloss 0.56527  last_update 4\n",
      "train: iter 224  trainloss 0.54079  validloss 0.71392±0.00000  bestvalidloss 0.56527  last_update 5\n",
      "train: iter 225  trainloss 0.53885  validloss 0.62506±0.00000  bestvalidloss 0.56527  last_update 6\n",
      "train: iter 226  trainloss 0.49579  validloss 0.63686±0.00000  bestvalidloss 0.56527  last_update 7\n",
      "train: iter 227  trainloss 0.51576  validloss 0.66592±0.00000  bestvalidloss 0.56527  last_update 8\n",
      "train: iter 228  trainloss 0.52037  validloss 0.64666±0.00000  bestvalidloss 0.56527  last_update 9\n",
      "train: iter 229  trainloss 0.52772  validloss 0.64504±0.00000  bestvalidloss 0.56527  last_update 10\n",
      "train: iter 230  trainloss 0.53717  validloss 0.63600±0.00000  bestvalidloss 0.56527  last_update 11\n",
      "train: iter 231  trainloss 0.50535  validloss 0.63741±0.00000  bestvalidloss 0.56527  last_update 12\n",
      "train: iter 232  trainloss 0.54294  validloss 0.65640±0.00000  bestvalidloss 0.56527  last_update 13\n",
      "train: iter 233  trainloss 0.51805  validloss 0.71511±0.00000  bestvalidloss 0.56527  last_update 14\n",
      "train: iter 234  trainloss 0.49651  validloss 0.71219±0.00000  bestvalidloss 0.56527  last_update 15\n",
      "train: iter 235  trainloss 0.50050  validloss 0.64229±0.00000  bestvalidloss 0.56527  last_update 16\n",
      "train: iter 236  trainloss 0.51566  validloss 0.69923±0.00000  bestvalidloss 0.56527  last_update 17\n",
      "train: iter 237  trainloss 0.53545  validloss 0.63669±0.00000  bestvalidloss 0.56527  last_update 18\n",
      "train: iter 238  trainloss 0.51705  validloss 0.63941±0.00000  bestvalidloss 0.56527  last_update 19\n",
      "train: iter 239  trainloss 0.53224  validloss 0.65037±0.00000  bestvalidloss 0.56527  last_update 20\n",
      "train: iter 240  trainloss 0.50065  validloss 0.63881±0.00000  bestvalidloss 0.56527  last_update 21\n",
      "train: iter 241  trainloss 0.52178  validloss 0.63471±0.00000  bestvalidloss 0.56527  last_update 22\n",
      "train: iter 242  trainloss 0.51440  validloss 0.63437±0.00000  bestvalidloss 0.56527  last_update 23\n",
      "train: iter 243  trainloss 0.49296  validloss 0.68898±0.00000  bestvalidloss 0.56527  last_update 24\n",
      "train: iter 244  trainloss 0.53431  validloss 0.67307±0.00000  bestvalidloss 0.56527  last_update 25\n",
      "train: iter 245  trainloss 0.53385  validloss 0.61085±0.00000  bestvalidloss 0.56527  last_update 26\n",
      "train: iter 246  trainloss 0.52761  validloss 0.65660±0.00000  bestvalidloss 0.56527  last_update 27\n",
      "train: iter 247  trainloss 0.53448  validloss 0.63130±0.00000  bestvalidloss 0.56527  last_update 28\n",
      "train: iter 248  trainloss 0.51906  validloss 0.68646±0.00000  bestvalidloss 0.56527  last_update 29\n",
      "train: iter 249  trainloss 0.49833  validloss 0.73115±0.00000  bestvalidloss 0.56527  last_update 30\n",
      "train: iter 250  trainloss 0.51244  validloss 0.64697±0.00000  bestvalidloss 0.56527  last_update 31\n",
      "train: iter 251  trainloss 0.52850  validloss 0.63471±0.00000  bestvalidloss 0.56527  last_update 32\n",
      "train: iter 252  trainloss 0.51951  validloss 0.66749±0.00000  bestvalidloss 0.56527  last_update 33\n",
      "train: iter 253  trainloss 0.52385  validloss 0.68024±0.00000  bestvalidloss 0.56527  last_update 34\n",
      "train: iter 254  trainloss 0.52259  validloss 0.66069±0.00000  bestvalidloss 0.56527  last_update 35\n",
      "train: iter 255  trainloss 0.51539  validloss 0.62189±0.00000  bestvalidloss 0.56527  last_update 36\n",
      "train: iter 256  trainloss 0.51176  validloss 0.67817±0.00000  bestvalidloss 0.56527  last_update 37\n",
      "train: iter 257  trainloss 0.53178  validloss 0.63926±0.00000  bestvalidloss 0.56527  last_update 38\n",
      "train: iter 258  trainloss 0.55262  validloss 0.61845±0.00000  bestvalidloss 0.56527  last_update 39\n",
      "train: iter 259  trainloss 0.47984  validloss 0.67952±0.00000  bestvalidloss 0.56527  last_update 40\n",
      "train: iter 260  trainloss 0.51540  validloss 0.67616±0.00000  bestvalidloss 0.56527  last_update 41\n",
      "train: iter 261  trainloss 0.51092  validloss 0.67584±0.00000  bestvalidloss 0.56527  last_update 42\n",
      "train: iter 262  trainloss 0.52829  validloss 0.64778±0.00000  bestvalidloss 0.56527  last_update 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 263  trainloss 0.54287  validloss 0.60871±0.00000  bestvalidloss 0.56527  last_update 44\n",
      "train: iter 264  trainloss 0.51573  validloss 0.66282±0.00000  bestvalidloss 0.56527  last_update 45\n",
      "train: iter 265  trainloss 0.50987  validloss 0.55694±0.00000  bestvalidloss 0.55694  last_update 0\n",
      "train: iter 266  trainloss 0.52149  validloss 0.63448±0.00000  bestvalidloss 0.55694  last_update 1\n",
      "train: iter 267  trainloss 0.50105  validloss 0.62100±0.00000  bestvalidloss 0.55694  last_update 2\n",
      "train: iter 268  trainloss 0.52079  validloss 0.66904±0.00000  bestvalidloss 0.55694  last_update 3\n",
      "train: iter 269  trainloss 0.50438  validloss 0.60659±0.00000  bestvalidloss 0.55694  last_update 4\n",
      "train: iter 270  trainloss 0.54003  validloss 0.65212±0.00000  bestvalidloss 0.55694  last_update 5\n",
      "train: iter 271  trainloss 0.50946  validloss 0.68425±0.00000  bestvalidloss 0.55694  last_update 6\n",
      "train: iter 272  trainloss 0.52287  validloss 0.61933±0.00000  bestvalidloss 0.55694  last_update 7\n",
      "train: iter 273  trainloss 0.51981  validloss 0.64177±0.00000  bestvalidloss 0.55694  last_update 8\n",
      "train: iter 274  trainloss 0.50363  validloss 0.63312±0.00000  bestvalidloss 0.55694  last_update 9\n",
      "train: iter 275  trainloss 0.51561  validloss 0.69027±0.00000  bestvalidloss 0.55694  last_update 10\n",
      "train: iter 276  trainloss 0.51787  validloss 0.70937±0.00000  bestvalidloss 0.55694  last_update 11\n",
      "train: iter 277  trainloss 0.52697  validloss 0.69153±0.00000  bestvalidloss 0.55694  last_update 12\n",
      "train: iter 278  trainloss 0.50859  validloss 0.69272±0.00000  bestvalidloss 0.55694  last_update 13\n",
      "train: iter 279  trainloss 0.52300  validloss 0.77109±0.00000  bestvalidloss 0.55694  last_update 14\n",
      "train: iter 280  trainloss 0.54535  validloss 0.66971±0.00000  bestvalidloss 0.55694  last_update 15\n",
      "train: iter 281  trainloss 0.54077  validloss 0.63992±0.00000  bestvalidloss 0.55694  last_update 16\n",
      "train: iter 282  trainloss 0.54196  validloss 0.66524±0.00000  bestvalidloss 0.55694  last_update 17\n",
      "train: iter 283  trainloss 0.53689  validloss 0.57346±0.00000  bestvalidloss 0.55694  last_update 18\n",
      "train: iter 284  trainloss 0.50753  validloss 0.65702±0.00000  bestvalidloss 0.55694  last_update 19\n",
      "train: iter 285  trainloss 0.52686  validloss 0.63341±0.00000  bestvalidloss 0.55694  last_update 20\n",
      "train: iter 286  trainloss 0.55153  validloss 0.61083±0.00000  bestvalidloss 0.55694  last_update 21\n",
      "train: iter 287  trainloss 0.53615  validloss 0.68035±0.00000  bestvalidloss 0.55694  last_update 22\n",
      "train: iter 288  trainloss 0.51515  validloss 0.60810±0.00000  bestvalidloss 0.55694  last_update 23\n",
      "train: iter 289  trainloss 0.51296  validloss 0.58193±0.00000  bestvalidloss 0.55694  last_update 24\n",
      "train: iter 290  trainloss 0.53678  validloss 0.64569±0.00000  bestvalidloss 0.55694  last_update 25\n",
      "train: iter 291  trainloss 0.50860  validloss 0.62060±0.00000  bestvalidloss 0.55694  last_update 26\n",
      "train: iter 292  trainloss 0.52762  validloss 0.61387±0.00000  bestvalidloss 0.55694  last_update 27\n",
      "train: iter 293  trainloss 0.54006  validloss 0.64719±0.00000  bestvalidloss 0.55694  last_update 28\n",
      "train: iter 294  trainloss 0.50621  validloss 0.65684±0.00000  bestvalidloss 0.55694  last_update 29\n",
      "train: iter 295  trainloss 0.52477  validloss 0.74283±0.00000  bestvalidloss 0.55694  last_update 30\n",
      "train: iter 296  trainloss 0.53736  validloss 0.60743±0.00000  bestvalidloss 0.55694  last_update 31\n",
      "train: iter 297  trainloss 0.50839  validloss 0.65737±0.00000  bestvalidloss 0.55694  last_update 32\n",
      "train: iter 298  trainloss 0.52126  validloss 0.62635±0.00000  bestvalidloss 0.55694  last_update 33\n",
      "train: iter 299  trainloss 0.49952  validloss 0.66412±0.00000  bestvalidloss 0.55694  last_update 34\n",
      "train: iter 300  trainloss 0.49708  validloss 0.58671±0.00000  bestvalidloss 0.55694  last_update 35\n",
      "train: iter 301  trainloss 0.57141  validloss 0.64054±0.00000  bestvalidloss 0.55694  last_update 36\n",
      "train: iter 302  trainloss 0.53704  validloss 0.61817±0.00000  bestvalidloss 0.55694  last_update 37\n",
      "train: iter 303  trainloss 0.52524  validloss 0.61642±0.00000  bestvalidloss 0.55694  last_update 38\n",
      "train: iter 304  trainloss 0.51454  validloss 0.56281±0.00000  bestvalidloss 0.55694  last_update 39\n",
      "train: iter 305  trainloss 0.54771  validloss 0.65558±0.00000  bestvalidloss 0.55694  last_update 40\n",
      "train: iter 306  trainloss 0.52926  validloss 0.68991±0.00000  bestvalidloss 0.55694  last_update 41\n",
      "train: iter 307  trainloss 0.50038  validloss 0.68252±0.00000  bestvalidloss 0.55694  last_update 42\n",
      "train: iter 308  trainloss 0.53634  validloss 0.61281±0.00000  bestvalidloss 0.55694  last_update 43\n",
      "train: iter 309  trainloss 0.51368  validloss 0.66321±0.00000  bestvalidloss 0.55694  last_update 44\n",
      "train: iter 310  trainloss 0.52959  validloss 0.62260±0.00000  bestvalidloss 0.55694  last_update 45\n",
      "train: iter 311  trainloss 0.51438  validloss 0.65110±0.00000  bestvalidloss 0.55694  last_update 46\n",
      "train: iter 312  trainloss 0.50862  validloss 0.64738±0.00000  bestvalidloss 0.55694  last_update 47\n",
      "train: iter 313  trainloss 0.50029  validloss 0.68819±0.00000  bestvalidloss 0.55694  last_update 48\n",
      "train: iter 314  trainloss 0.50388  validloss 0.61242±0.00000  bestvalidloss 0.55694  last_update 49\n",
      "train: iter 315  trainloss 0.51559  validloss 0.66756±0.00000  bestvalidloss 0.55694  last_update 50\n",
      "train: iter 316  trainloss 0.50187  validloss 0.61617±0.00000  bestvalidloss 0.55694  last_update 51\n",
      "train: iter 317  trainloss 0.52427  validloss 0.60745±0.00000  bestvalidloss 0.55694  last_update 52\n",
      "train: iter 318  trainloss 0.53796  validloss 0.67064±0.00000  bestvalidloss 0.55694  last_update 53\n",
      "train: iter 319  trainloss 0.51975  validloss 0.72648±0.00000  bestvalidloss 0.55694  last_update 54\n",
      "train: iter 320  trainloss 0.52507  validloss 0.61256±0.00000  bestvalidloss 0.55694  last_update 55\n",
      "train: iter 321  trainloss 0.51153  validloss 0.65173±0.00000  bestvalidloss 0.55694  last_update 56\n",
      "train: iter 322  trainloss 0.52324  validloss 0.58519±0.00000  bestvalidloss 0.55694  last_update 57\n",
      "train: iter 323  trainloss 0.52484  validloss 0.71540±0.00000  bestvalidloss 0.55694  last_update 58\n",
      "train: iter 324  trainloss 0.53350  validloss 0.66533±0.00000  bestvalidloss 0.55694  last_update 59\n",
      "train: iter 325  trainloss 0.54395  validloss 0.59173±0.00000  bestvalidloss 0.55694  last_update 60\n",
      "train: iter 326  trainloss 0.52956  validloss 0.66956±0.00000  bestvalidloss 0.55694  last_update 61\n",
      "train: iter 327  trainloss 0.49570  validloss 0.66195±0.00000  bestvalidloss 0.55694  last_update 62\n",
      "train: iter 328  trainloss 0.50850  validloss 0.69458±0.00000  bestvalidloss 0.55694  last_update 63\n",
      "train: iter 329  trainloss 0.52633  validloss 0.64006±0.00000  bestvalidloss 0.55694  last_update 64\n",
      "train: iter 330  trainloss 0.55238  validloss 0.71171±0.00000  bestvalidloss 0.55694  last_update 65\n",
      "train: iter 331  trainloss 0.51567  validloss 0.63970±0.00000  bestvalidloss 0.55694  last_update 66\n",
      "train: iter 332  trainloss 0.52553  validloss 0.63919±0.00000  bestvalidloss 0.55694  last_update 67\n",
      "train: iter 333  trainloss 0.54653  validloss 0.64390±0.00000  bestvalidloss 0.55694  last_update 68\n",
      "train: iter 334  trainloss 0.53942  validloss 0.67218±0.00000  bestvalidloss 0.55694  last_update 69\n",
      "train: iter 335  trainloss 0.54769  validloss 0.58904±0.00000  bestvalidloss 0.55694  last_update 70\n",
      "train: iter 336  trainloss 0.52761  validloss 0.67434±0.00000  bestvalidloss 0.55694  last_update 71\n",
      "train: iter 337  trainloss 0.53269  validloss 0.63666±0.00000  bestvalidloss 0.55694  last_update 72\n",
      "train: iter 338  trainloss 0.55354  validloss 0.69064±0.00000  bestvalidloss 0.55694  last_update 73\n",
      "train: iter 339  trainloss 0.52115  validloss 0.65841±0.00000  bestvalidloss 0.55694  last_update 74\n",
      "train: iter 340  trainloss 0.52761  validloss 0.64343±0.00000  bestvalidloss 0.55694  last_update 75\n",
      "train: iter 341  trainloss 0.52023  validloss 0.68620±0.00000  bestvalidloss 0.55694  last_update 76\n",
      "train: iter 342  trainloss 0.52062  validloss 0.57980±0.00000  bestvalidloss 0.55694  last_update 77\n",
      "train: iter 343  trainloss 0.49211  validloss 0.65732±0.00000  bestvalidloss 0.55694  last_update 78\n",
      "train: iter 344  trainloss 0.54777  validloss 0.70067±0.00000  bestvalidloss 0.55694  last_update 79\n",
      "train: iter 345  trainloss 0.53340  validloss 0.63154±0.00000  bestvalidloss 0.55694  last_update 80\n",
      "train: iter 346  trainloss 0.52592  validloss 0.62165±0.00000  bestvalidloss 0.55694  last_update 81\n",
      "train: iter 347  trainloss 0.54380  validloss 0.66282±0.00000  bestvalidloss 0.55694  last_update 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 348  trainloss 0.49895  validloss 0.62634±0.00000  bestvalidloss 0.55694  last_update 83\n",
      "train: iter 349  trainloss 0.51863  validloss 0.58473±0.00000  bestvalidloss 0.55694  last_update 84\n",
      "train: iter 350  trainloss 0.53004  validloss 0.74006±0.00000  bestvalidloss 0.55694  last_update 85\n",
      "train: iter 351  trainloss 0.51515  validloss 0.63845±0.00000  bestvalidloss 0.55694  last_update 86\n",
      "train: iter 352  trainloss 0.52257  validloss 0.72851±0.00000  bestvalidloss 0.55694  last_update 87\n",
      "train: iter 353  trainloss 0.52244  validloss 0.63936±0.00000  bestvalidloss 0.55694  last_update 88\n",
      "train: iter 354  trainloss 0.52061  validloss 0.64891±0.00000  bestvalidloss 0.55694  last_update 89\n",
      "train: iter 355  trainloss 0.53832  validloss 0.66746±0.00000  bestvalidloss 0.55694  last_update 90\n",
      "train: iter 356  trainloss 0.52010  validloss 0.72139±0.00000  bestvalidloss 0.55694  last_update 91\n",
      "train: iter 357  trainloss 0.54345  validloss 0.67839±0.00000  bestvalidloss 0.55694  last_update 92\n",
      "train: iter 358  trainloss 0.53389  validloss 0.58691±0.00000  bestvalidloss 0.55694  last_update 93\n",
      "train: iter 359  trainloss 0.51755  validloss 0.71497±0.00000  bestvalidloss 0.55694  last_update 94\n",
      "train: iter 360  trainloss 0.53301  validloss 0.69301±0.00000  bestvalidloss 0.55694  last_update 95\n",
      "train: iter 361  trainloss 0.52928  validloss 0.63840±0.00000  bestvalidloss 0.55694  last_update 96\n",
      "train: iter 362  trainloss 0.52636  validloss 0.65692±0.00000  bestvalidloss 0.55694  last_update 97\n",
      "train: iter 363  trainloss 0.50832  validloss 0.64786±0.00000  bestvalidloss 0.55694  last_update 98\n",
      "train: iter 364  trainloss 0.55537  validloss 0.63341±0.00000  bestvalidloss 0.55694  last_update 99\n",
      "train: iter 365  trainloss 0.54909  validloss 0.65824±0.00000  bestvalidloss 0.55694  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.4259, -3.7522, -1.3210, -3.3112], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 69.72273  validloss 72.58598±0.00000  bestvalidloss 72.58598  last_update 0\n",
      "train: iter 1  trainloss 49.55155  validloss 57.78816±0.00000  bestvalidloss 57.78816  last_update 0\n",
      "train: iter 2  trainloss 33.21339  validloss 38.87244±0.00000  bestvalidloss 38.87244  last_update 0\n",
      "train: iter 3  trainloss 24.27480  validloss 28.91572±0.00000  bestvalidloss 28.91572  last_update 0\n",
      "train: iter 4  trainloss 19.02547  validloss 22.99849±0.00000  bestvalidloss 22.99849  last_update 0\n",
      "train: iter 5  trainloss 15.52152  validloss 19.69577±0.00000  bestvalidloss 19.69577  last_update 0\n",
      "train: iter 6  trainloss 13.08680  validloss 16.97206±0.00000  bestvalidloss 16.97206  last_update 0\n",
      "train: iter 7  trainloss 11.28497  validloss 15.53086±0.00000  bestvalidloss 15.53086  last_update 0\n",
      "train: iter 8  trainloss 10.01069  validloss 14.13333±0.00000  bestvalidloss 14.13333  last_update 0\n",
      "train: iter 9  trainloss 9.06958  validloss 13.86066±0.00000  bestvalidloss 13.86066  last_update 0\n",
      "train: iter 10  trainloss 8.29422  validloss 12.31807±0.00000  bestvalidloss 12.31807  last_update 0\n",
      "train: iter 11  trainloss 7.60498  validloss 11.98483±0.00000  bestvalidloss 11.98483  last_update 0\n",
      "train: iter 12  trainloss 7.05243  validloss 12.25165±0.00000  bestvalidloss 11.98483  last_update 1\n",
      "train: iter 13  trainloss 6.69274  validloss 11.29882±0.00000  bestvalidloss 11.29882  last_update 0\n",
      "train: iter 14  trainloss 6.28794  validloss 12.00035±0.00000  bestvalidloss 11.29882  last_update 1\n",
      "train: iter 15  trainloss 6.01334  validloss 12.41204±0.00000  bestvalidloss 11.29882  last_update 2\n",
      "train: iter 16  trainloss 5.60487  validloss 11.52776±0.00000  bestvalidloss 11.29882  last_update 3\n",
      "train: iter 17  trainloss 5.27040  validloss 11.60775±0.00000  bestvalidloss 11.29882  last_update 4\n",
      "train: iter 18  trainloss 4.97877  validloss 10.55196±0.00000  bestvalidloss 10.55196  last_update 0\n",
      "train: iter 19  trainloss 4.71289  validloss 10.29865±0.00000  bestvalidloss 10.29865  last_update 0\n",
      "train: iter 20  trainloss 4.42814  validloss 10.03444±0.00000  bestvalidloss 10.03444  last_update 0\n",
      "train: iter 21  trainloss 4.26129  validloss 9.25871±0.00000  bestvalidloss 9.25871  last_update 0\n",
      "train: iter 22  trainloss 4.01196  validloss 8.48245±0.00000  bestvalidloss 8.48245  last_update 0\n",
      "train: iter 23  trainloss 3.85839  validloss 8.94783±0.00000  bestvalidloss 8.48245  last_update 1\n",
      "train: iter 24  trainloss 3.68582  validloss 9.06422±0.00000  bestvalidloss 8.48245  last_update 2\n",
      "train: iter 25  trainloss 3.62973  validloss 9.22191±0.00000  bestvalidloss 8.48245  last_update 3\n",
      "train: iter 26  trainloss 3.50916  validloss 8.51805±0.00000  bestvalidloss 8.48245  last_update 4\n",
      "train: iter 27  trainloss 3.40788  validloss 8.34783±0.00000  bestvalidloss 8.34783  last_update 0\n",
      "train: iter 28  trainloss 3.41002  validloss 7.79976±0.00000  bestvalidloss 7.79976  last_update 0\n",
      "train: iter 29  trainloss 3.35130  validloss 7.89391±0.00000  bestvalidloss 7.79976  last_update 1\n",
      "train: iter 30  trainloss 3.32770  validloss 7.94510±0.00000  bestvalidloss 7.79976  last_update 2\n",
      "train: iter 31  trainloss 3.31577  validloss 7.77458±0.00000  bestvalidloss 7.77458  last_update 0\n",
      "train: iter 32  trainloss 3.30220  validloss 8.30991±0.00000  bestvalidloss 7.77458  last_update 1\n",
      "train: iter 33  trainloss 3.29742  validloss 7.87710±0.00000  bestvalidloss 7.77458  last_update 2\n",
      "train: iter 34  trainloss 3.27250  validloss 8.54382±0.00000  bestvalidloss 7.77458  last_update 3\n",
      "train: iter 35  trainloss 3.26490  validloss 7.28682±0.00000  bestvalidloss 7.28682  last_update 0\n",
      "train: iter 36  trainloss 3.25423  validloss 8.83601±0.00000  bestvalidloss 7.28682  last_update 1\n",
      "train: iter 37  trainloss 3.21647  validloss 8.21846±0.00000  bestvalidloss 7.28682  last_update 2\n",
      "train: iter 38  trainloss 3.22007  validloss 7.82583±0.00000  bestvalidloss 7.28682  last_update 3\n",
      "train: iter 39  trainloss 3.24046  validloss 7.32780±0.00000  bestvalidloss 7.28682  last_update 4\n",
      "train: iter 40  trainloss 3.18687  validloss 9.16611±0.00000  bestvalidloss 7.28682  last_update 5\n",
      "train: iter 41  trainloss 3.17997  validloss 8.32359±0.00000  bestvalidloss 7.28682  last_update 6\n",
      "train: iter 42  trainloss 3.18395  validloss 7.25645±0.00000  bestvalidloss 7.25645  last_update 0\n",
      "train: iter 43  trainloss 3.19958  validloss 8.01960±0.00000  bestvalidloss 7.25645  last_update 1\n",
      "train: iter 44  trainloss 3.15020  validloss 8.28281±0.00000  bestvalidloss 7.25645  last_update 2\n",
      "train: iter 45  trainloss 3.14510  validloss 8.98652±0.00000  bestvalidloss 7.25645  last_update 3\n",
      "train: iter 46  trainloss 3.19233  validloss 7.67296±0.00000  bestvalidloss 7.25645  last_update 4\n",
      "train: iter 47  trainloss 3.16310  validloss 7.71764±0.00000  bestvalidloss 7.25645  last_update 5\n",
      "train: iter 48  trainloss 3.16903  validloss 8.13165±0.00000  bestvalidloss 7.25645  last_update 6\n",
      "train: iter 49  trainloss 3.17031  validloss 8.39602±0.00000  bestvalidloss 7.25645  last_update 7\n",
      "train: iter 50  trainloss 3.14766  validloss 8.45858±0.00000  bestvalidloss 7.25645  last_update 8\n",
      "train: iter 51  trainloss 3.15379  validloss 8.44055±0.00000  bestvalidloss 7.25645  last_update 9\n",
      "train: iter 52  trainloss 3.17323  validloss 7.80219±0.00000  bestvalidloss 7.25645  last_update 10\n",
      "train: iter 53  trainloss 3.10461  validloss 8.16239±0.00000  bestvalidloss 7.25645  last_update 11\n",
      "train: iter 54  trainloss 3.09676  validloss 7.80616±0.00000  bestvalidloss 7.25645  last_update 12\n",
      "train: iter 55  trainloss 3.16317  validloss 7.76557±0.00000  bestvalidloss 7.25645  last_update 13\n",
      "train: iter 56  trainloss 3.17816  validloss 8.39431±0.00000  bestvalidloss 7.25645  last_update 14\n",
      "train: iter 57  trainloss 3.14800  validloss 7.70998±0.00000  bestvalidloss 7.25645  last_update 15\n",
      "train: iter 58  trainloss 3.09428  validloss 8.61246±0.00000  bestvalidloss 7.25645  last_update 16\n",
      "train: iter 59  trainloss 3.15097  validloss 8.10088±0.00000  bestvalidloss 7.25645  last_update 17\n",
      "train: iter 60  trainloss 3.13856  validloss 8.35665±0.00000  bestvalidloss 7.25645  last_update 18\n",
      "train: iter 61  trainloss 3.14285  validloss 7.68650±0.00000  bestvalidloss 7.25645  last_update 19\n",
      "train: iter 62  trainloss 3.11232  validloss 8.88120±0.00000  bestvalidloss 7.25645  last_update 20\n",
      "train: iter 63  trainloss 3.08424  validloss 7.58211±0.00000  bestvalidloss 7.25645  last_update 21\n",
      "train: iter 64  trainloss 3.08325  validloss 7.92043±0.00000  bestvalidloss 7.25645  last_update 22\n",
      "train: iter 65  trainloss 3.07291  validloss 8.80624±0.00000  bestvalidloss 7.25645  last_update 23\n",
      "train: iter 66  trainloss 3.08848  validloss 7.78797±0.00000  bestvalidloss 7.25645  last_update 24\n",
      "train: iter 67  trainloss 3.11081  validloss 8.86286±0.00000  bestvalidloss 7.25645  last_update 25\n",
      "train: iter 68  trainloss 3.13253  validloss 8.24555±0.00000  bestvalidloss 7.25645  last_update 26\n",
      "train: iter 69  trainloss 3.15536  validloss 7.97748±0.00000  bestvalidloss 7.25645  last_update 27\n",
      "train: iter 70  trainloss 3.10135  validloss 8.73103±0.00000  bestvalidloss 7.25645  last_update 28\n",
      "train: iter 71  trainloss 3.08733  validloss 8.24248±0.00000  bestvalidloss 7.25645  last_update 29\n",
      "train: iter 72  trainloss 3.10295  validloss 7.50066±0.00000  bestvalidloss 7.25645  last_update 30\n",
      "train: iter 73  trainloss 3.08846  validloss 7.42548±0.00000  bestvalidloss 7.25645  last_update 31\n",
      "train: iter 74  trainloss 3.07959  validloss 7.49483±0.00000  bestvalidloss 7.25645  last_update 32\n",
      "train: iter 75  trainloss 3.05116  validloss 7.88155±0.00000  bestvalidloss 7.25645  last_update 33\n",
      "train: iter 76  trainloss 3.12508  validloss 8.22000±0.00000  bestvalidloss 7.25645  last_update 34\n",
      "train: iter 77  trainloss 3.09987  validloss 7.95135±0.00000  bestvalidloss 7.25645  last_update 35\n",
      "train: iter 78  trainloss 3.06780  validloss 7.79745±0.00000  bestvalidloss 7.25645  last_update 36\n",
      "train: iter 79  trainloss 3.07928  validloss 7.56384±0.00000  bestvalidloss 7.25645  last_update 37\n",
      "train: iter 80  trainloss 3.06687  validloss 7.90878±0.00000  bestvalidloss 7.25645  last_update 38\n",
      "train: iter 81  trainloss 3.11897  validloss 8.24106±0.00000  bestvalidloss 7.25645  last_update 39\n",
      "train: iter 82  trainloss 3.11829  validloss 8.12130±0.00000  bestvalidloss 7.25645  last_update 40\n",
      "train: iter 83  trainloss 3.11533  validloss 8.19490±0.00000  bestvalidloss 7.25645  last_update 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 3.12930  validloss 7.86295±0.00000  bestvalidloss 7.25645  last_update 42\n",
      "train: iter 85  trainloss 3.06025  validloss 7.53966±0.00000  bestvalidloss 7.25645  last_update 43\n",
      "train: iter 86  trainloss 3.12058  validloss 7.62332±0.00000  bestvalidloss 7.25645  last_update 44\n",
      "train: iter 87  trainloss 3.06312  validloss 7.32204±0.00000  bestvalidloss 7.25645  last_update 45\n",
      "train: iter 88  trainloss 3.11885  validloss 7.88683±0.00000  bestvalidloss 7.25645  last_update 46\n",
      "train: iter 89  trainloss 3.10165  validloss 8.11257±0.00000  bestvalidloss 7.25645  last_update 47\n",
      "train: iter 90  trainloss 3.05809  validloss 7.65519±0.00000  bestvalidloss 7.25645  last_update 48\n",
      "train: iter 91  trainloss 3.13899  validloss 8.50577±0.00000  bestvalidloss 7.25645  last_update 49\n",
      "train: iter 92  trainloss 3.05846  validloss 8.11226±0.00000  bestvalidloss 7.25645  last_update 50\n",
      "train: iter 93  trainloss 3.06881  validloss 8.03467±0.00000  bestvalidloss 7.25645  last_update 51\n",
      "train: iter 94  trainloss 3.05083  validloss 8.21476±0.00000  bestvalidloss 7.25645  last_update 52\n",
      "train: iter 95  trainloss 3.10138  validloss 7.68271±0.00000  bestvalidloss 7.25645  last_update 53\n",
      "train: iter 96  trainloss 3.02997  validloss 8.25686±0.00000  bestvalidloss 7.25645  last_update 54\n",
      "train: iter 97  trainloss 3.07792  validloss 7.65547±0.00000  bestvalidloss 7.25645  last_update 55\n",
      "train: iter 98  trainloss 3.05908  validloss 7.32909±0.00000  bestvalidloss 7.25645  last_update 56\n",
      "train: iter 99  trainloss 3.11800  validloss 8.08585±0.00000  bestvalidloss 7.25645  last_update 57\n",
      "train: iter 100  trainloss 3.10628  validloss 8.52045±0.00000  bestvalidloss 7.25645  last_update 58\n",
      "train: iter 101  trainloss 3.07127  validloss 7.94619±0.00000  bestvalidloss 7.25645  last_update 59\n",
      "train: iter 102  trainloss 3.05945  validloss 7.62567±0.00000  bestvalidloss 7.25645  last_update 60\n",
      "train: iter 103  trainloss 3.11950  validloss 8.41052±0.00000  bestvalidloss 7.25645  last_update 61\n",
      "train: iter 104  trainloss 3.05400  validloss 9.10658±0.00000  bestvalidloss 7.25645  last_update 62\n",
      "train: iter 105  trainloss 3.04733  validloss 8.35028±0.00000  bestvalidloss 7.25645  last_update 63\n",
      "train: iter 106  trainloss 3.05231  validloss 7.15129±0.00000  bestvalidloss 7.15129  last_update 0\n",
      "train: iter 107  trainloss 3.04804  validloss 7.59999±0.00000  bestvalidloss 7.15129  last_update 1\n",
      "train: iter 108  trainloss 3.08775  validloss 7.71829±0.00000  bestvalidloss 7.15129  last_update 2\n",
      "train: iter 109  trainloss 3.09195  validloss 8.45000±0.00000  bestvalidloss 7.15129  last_update 3\n",
      "train: iter 110  trainloss 3.04691  validloss 7.57001±0.00000  bestvalidloss 7.15129  last_update 4\n",
      "train: iter 111  trainloss 3.12763  validloss 8.97482±0.00000  bestvalidloss 7.15129  last_update 5\n",
      "train: iter 112  trainloss 3.05477  validloss 8.02360±0.00000  bestvalidloss 7.15129  last_update 6\n",
      "train: iter 113  trainloss 3.00432  validloss 8.43614±0.00000  bestvalidloss 7.15129  last_update 7\n",
      "train: iter 114  trainloss 3.08013  validloss 8.09989±0.00000  bestvalidloss 7.15129  last_update 8\n",
      "train: iter 115  trainloss 3.07705  validloss 7.50391±0.00000  bestvalidloss 7.15129  last_update 9\n",
      "train: iter 116  trainloss 3.11693  validloss 8.19890±0.00000  bestvalidloss 7.15129  last_update 10\n",
      "train: iter 117  trainloss 3.04183  validloss 7.72313±0.00000  bestvalidloss 7.15129  last_update 11\n",
      "train: iter 118  trainloss 3.05853  validloss 7.86351±0.00000  bestvalidloss 7.15129  last_update 12\n",
      "train: iter 119  trainloss 3.08655  validloss 7.66485±0.00000  bestvalidloss 7.15129  last_update 13\n",
      "train: iter 120  trainloss 3.07447  validloss 8.83739±0.00000  bestvalidloss 7.15129  last_update 14\n",
      "train: iter 121  trainloss 3.01147  validloss 9.18301±0.00000  bestvalidloss 7.15129  last_update 15\n",
      "train: iter 122  trainloss 3.09184  validloss 8.41852±0.00000  bestvalidloss 7.15129  last_update 16\n",
      "train: iter 123  trainloss 3.05846  validloss 8.39341±0.00000  bestvalidloss 7.15129  last_update 17\n",
      "train: iter 124  trainloss 3.01812  validloss 9.12905±0.00000  bestvalidloss 7.15129  last_update 18\n",
      "train: iter 125  trainloss 3.13010  validloss 8.14882±0.00000  bestvalidloss 7.15129  last_update 19\n",
      "train: iter 126  trainloss 3.09311  validloss 8.87448±0.00000  bestvalidloss 7.15129  last_update 20\n",
      "train: iter 127  trainloss 3.06077  validloss 7.73663±0.00000  bestvalidloss 7.15129  last_update 21\n",
      "train: iter 128  trainloss 3.07119  validloss 7.09811±0.00000  bestvalidloss 7.09811  last_update 0\n",
      "train: iter 129  trainloss 3.08346  validloss 9.09087±0.00000  bestvalidloss 7.09811  last_update 1\n",
      "train: iter 130  trainloss 3.06927  validloss 7.05717±0.00000  bestvalidloss 7.05717  last_update 0\n",
      "train: iter 131  trainloss 3.05433  validloss 7.72449±0.00000  bestvalidloss 7.05717  last_update 1\n",
      "train: iter 132  trainloss 3.08007  validloss 8.89703±0.00000  bestvalidloss 7.05717  last_update 2\n",
      "train: iter 133  trainloss 3.04357  validloss 7.92054±0.00000  bestvalidloss 7.05717  last_update 3\n",
      "train: iter 134  trainloss 3.04301  validloss 8.10985±0.00000  bestvalidloss 7.05717  last_update 4\n",
      "train: iter 135  trainloss 3.06022  validloss 8.40076±0.00000  bestvalidloss 7.05717  last_update 5\n",
      "train: iter 136  trainloss 3.02529  validloss 7.84946±0.00000  bestvalidloss 7.05717  last_update 6\n",
      "train: iter 137  trainloss 3.04131  validloss 8.00966±0.00000  bestvalidloss 7.05717  last_update 7\n",
      "train: iter 138  trainloss 3.08863  validloss 9.02483±0.00000  bestvalidloss 7.05717  last_update 8\n",
      "train: iter 139  trainloss 3.06432  validloss 8.67925±0.00000  bestvalidloss 7.05717  last_update 9\n",
      "train: iter 140  trainloss 3.03308  validloss 7.54695±0.00000  bestvalidloss 7.05717  last_update 10\n",
      "train: iter 141  trainloss 3.05854  validloss 7.32468±0.00000  bestvalidloss 7.05717  last_update 11\n",
      "train: iter 142  trainloss 3.05114  validloss 8.53966±0.00000  bestvalidloss 7.05717  last_update 12\n",
      "train: iter 143  trainloss 3.08329  validloss 8.38071±0.00000  bestvalidloss 7.05717  last_update 13\n",
      "train: iter 144  trainloss 3.03571  validloss 7.60569±0.00000  bestvalidloss 7.05717  last_update 14\n",
      "train: iter 145  trainloss 3.10654  validloss 7.15440±0.00000  bestvalidloss 7.05717  last_update 15\n",
      "train: iter 146  trainloss 3.04633  validloss 8.42498±0.00000  bestvalidloss 7.05717  last_update 16\n",
      "train: iter 147  trainloss 3.03262  validloss 8.13153±0.00000  bestvalidloss 7.05717  last_update 17\n",
      "train: iter 148  trainloss 3.04667  validloss 8.50114±0.00000  bestvalidloss 7.05717  last_update 18\n",
      "train: iter 149  trainloss 3.09304  validloss 9.84438±0.00000  bestvalidloss 7.05717  last_update 19\n",
      "train: iter 150  trainloss 3.06286  validloss 8.68815±0.00000  bestvalidloss 7.05717  last_update 20\n",
      "train: iter 151  trainloss 3.04390  validloss 7.86261±0.00000  bestvalidloss 7.05717  last_update 21\n",
      "train: iter 152  trainloss 2.98462  validloss 7.85049±0.00000  bestvalidloss 7.05717  last_update 22\n",
      "train: iter 153  trainloss 3.06634  validloss 9.25989±0.00000  bestvalidloss 7.05717  last_update 23\n",
      "train: iter 154  trainloss 3.03729  validloss 8.03555±0.00000  bestvalidloss 7.05717  last_update 24\n",
      "train: iter 155  trainloss 3.06906  validloss 7.73099±0.00000  bestvalidloss 7.05717  last_update 25\n",
      "train: iter 156  trainloss 3.04780  validloss 8.12577±0.00000  bestvalidloss 7.05717  last_update 26\n",
      "train: iter 157  trainloss 3.03995  validloss 7.76520±0.00000  bestvalidloss 7.05717  last_update 27\n",
      "train: iter 158  trainloss 3.02881  validloss 7.62164±0.00000  bestvalidloss 7.05717  last_update 28\n",
      "train: iter 159  trainloss 2.99613  validloss 7.93658±0.00000  bestvalidloss 7.05717  last_update 29\n",
      "train: iter 160  trainloss 3.01570  validloss 7.33070±0.00000  bestvalidloss 7.05717  last_update 30\n",
      "train: iter 161  trainloss 2.98971  validloss 8.43669±0.00000  bestvalidloss 7.05717  last_update 31\n",
      "train: iter 162  trainloss 3.07628  validloss 8.83853±0.00000  bestvalidloss 7.05717  last_update 32\n",
      "train: iter 163  trainloss 3.01162  validloss 8.27133±0.00000  bestvalidloss 7.05717  last_update 33\n",
      "train: iter 164  trainloss 3.05348  validloss 8.36001±0.00000  bestvalidloss 7.05717  last_update 34\n",
      "train: iter 165  trainloss 2.98936  validloss 8.48645±0.00000  bestvalidloss 7.05717  last_update 35\n",
      "train: iter 166  trainloss 3.06101  validloss 8.06974±0.00000  bestvalidloss 7.05717  last_update 36\n",
      "train: iter 167  trainloss 3.03363  validloss 8.45796±0.00000  bestvalidloss 7.05717  last_update 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 3.10677  validloss 8.27201±0.00000  bestvalidloss 7.05717  last_update 38\n",
      "train: iter 169  trainloss 3.05081  validloss 8.56088±0.00000  bestvalidloss 7.05717  last_update 39\n",
      "train: iter 170  trainloss 3.02537  validloss 8.74994±0.00000  bestvalidloss 7.05717  last_update 40\n",
      "train: iter 171  trainloss 3.06407  validloss 7.88426±0.00000  bestvalidloss 7.05717  last_update 41\n",
      "train: iter 172  trainloss 3.01794  validloss 7.94479±0.00000  bestvalidloss 7.05717  last_update 42\n",
      "train: iter 173  trainloss 3.00006  validloss 9.10317±0.00000  bestvalidloss 7.05717  last_update 43\n",
      "train: iter 174  trainloss 3.03110  validloss 7.55641±0.00000  bestvalidloss 7.05717  last_update 44\n",
      "train: iter 175  trainloss 3.01760  validloss 8.36659±0.00000  bestvalidloss 7.05717  last_update 45\n",
      "train: iter 176  trainloss 3.04320  validloss 7.43391±0.00000  bestvalidloss 7.05717  last_update 46\n",
      "train: iter 177  trainloss 3.02559  validloss 8.48109±0.00000  bestvalidloss 7.05717  last_update 47\n",
      "train: iter 178  trainloss 3.05080  validloss 7.95057±0.00000  bestvalidloss 7.05717  last_update 48\n",
      "train: iter 179  trainloss 3.07507  validloss 8.81989±0.00000  bestvalidloss 7.05717  last_update 49\n",
      "train: iter 180  trainloss 3.05990  validloss 8.29252±0.00000  bestvalidloss 7.05717  last_update 50\n",
      "train: iter 181  trainloss 3.05703  validloss 8.47111±0.00000  bestvalidloss 7.05717  last_update 51\n",
      "train: iter 182  trainloss 3.03877  validloss 8.31559±0.00000  bestvalidloss 7.05717  last_update 52\n",
      "train: iter 183  trainloss 3.05260  validloss 9.28718±0.00000  bestvalidloss 7.05717  last_update 53\n",
      "train: iter 184  trainloss 3.03208  validloss 8.75063±0.00000  bestvalidloss 7.05717  last_update 54\n",
      "train: iter 185  trainloss 3.03517  validloss 8.71406±0.00000  bestvalidloss 7.05717  last_update 55\n",
      "train: iter 186  trainloss 3.03862  validloss 8.03977±0.00000  bestvalidloss 7.05717  last_update 56\n",
      "train: iter 187  trainloss 3.09804  validloss 8.15594±0.00000  bestvalidloss 7.05717  last_update 57\n",
      "train: iter 188  trainloss 3.03388  validloss 7.83854±0.00000  bestvalidloss 7.05717  last_update 58\n",
      "train: iter 189  trainloss 3.00572  validloss 7.86721±0.00000  bestvalidloss 7.05717  last_update 59\n",
      "train: iter 190  trainloss 3.00703  validloss 7.05454±0.00000  bestvalidloss 7.05454  last_update 0\n",
      "train: iter 191  trainloss 3.01210  validloss 7.86750±0.00000  bestvalidloss 7.05454  last_update 1\n",
      "train: iter 192  trainloss 3.10455  validloss 7.95346±0.00000  bestvalidloss 7.05454  last_update 2\n",
      "train: iter 193  trainloss 3.02939  validloss 8.50733±0.00000  bestvalidloss 7.05454  last_update 3\n",
      "train: iter 194  trainloss 3.04511  validloss 7.91442±0.00000  bestvalidloss 7.05454  last_update 4\n",
      "train: iter 195  trainloss 3.01095  validloss 7.41439±0.00000  bestvalidloss 7.05454  last_update 5\n",
      "train: iter 196  trainloss 3.05516  validloss 7.43406±0.00000  bestvalidloss 7.05454  last_update 6\n",
      "train: iter 197  trainloss 3.05819  validloss 8.85998±0.00000  bestvalidloss 7.05454  last_update 7\n",
      "train: iter 198  trainloss 2.99933  validloss 7.79756±0.00000  bestvalidloss 7.05454  last_update 8\n",
      "train: iter 199  trainloss 2.99458  validloss 7.73017±0.00000  bestvalidloss 7.05454  last_update 9\n",
      "train: iter 200  trainloss 2.99073  validloss 7.71211±0.00000  bestvalidloss 7.05454  last_update 10\n",
      "train: iter 201  trainloss 2.98430  validloss 7.56784±0.00000  bestvalidloss 7.05454  last_update 11\n",
      "train: iter 202  trainloss 3.03424  validloss 8.76034±0.00000  bestvalidloss 7.05454  last_update 12\n",
      "train: iter 203  trainloss 2.98623  validloss 8.38535±0.00000  bestvalidloss 7.05454  last_update 13\n",
      "train: iter 204  trainloss 2.98175  validloss 7.98313±0.00000  bestvalidloss 7.05454  last_update 14\n",
      "train: iter 205  trainloss 3.00450  validloss 8.56829±0.00000  bestvalidloss 7.05454  last_update 15\n",
      "train: iter 206  trainloss 3.07642  validloss 9.15387±0.00000  bestvalidloss 7.05454  last_update 16\n",
      "train: iter 207  trainloss 2.99546  validloss 8.79288±0.00000  bestvalidloss 7.05454  last_update 17\n",
      "train: iter 208  trainloss 3.01794  validloss 8.92247±0.00000  bestvalidloss 7.05454  last_update 18\n",
      "train: iter 209  trainloss 3.02264  validloss 8.07526±0.00000  bestvalidloss 7.05454  last_update 19\n",
      "train: iter 210  trainloss 3.00434  validloss 7.86893±0.00000  bestvalidloss 7.05454  last_update 20\n",
      "train: iter 211  trainloss 3.02180  validloss 8.19909±0.00000  bestvalidloss 7.05454  last_update 21\n",
      "train: iter 212  trainloss 3.02824  validloss 7.63025±0.00000  bestvalidloss 7.05454  last_update 22\n",
      "train: iter 213  trainloss 2.95294  validloss 8.16414±0.00000  bestvalidloss 7.05454  last_update 23\n",
      "train: iter 214  trainloss 2.98231  validloss 7.92919±0.00000  bestvalidloss 7.05454  last_update 24\n",
      "train: iter 215  trainloss 2.99063  validloss 7.66753±0.00000  bestvalidloss 7.05454  last_update 25\n",
      "train: iter 216  trainloss 3.00055  validloss 8.03788±0.00000  bestvalidloss 7.05454  last_update 26\n",
      "train: iter 217  trainloss 3.02229  validloss 8.03768±0.00000  bestvalidloss 7.05454  last_update 27\n",
      "train: iter 218  trainloss 3.01779  validloss 8.50250±0.00000  bestvalidloss 7.05454  last_update 28\n",
      "train: iter 219  trainloss 3.04696  validloss 7.81741±0.00000  bestvalidloss 7.05454  last_update 29\n",
      "train: iter 220  trainloss 3.03748  validloss 8.06961±0.00000  bestvalidloss 7.05454  last_update 30\n",
      "train: iter 221  trainloss 3.02814  validloss 8.52947±0.00000  bestvalidloss 7.05454  last_update 31\n",
      "train: iter 222  trainloss 3.00301  validloss 8.30271±0.00000  bestvalidloss 7.05454  last_update 32\n",
      "train: iter 223  trainloss 2.98664  validloss 8.06033±0.00000  bestvalidloss 7.05454  last_update 33\n",
      "train: iter 224  trainloss 3.01648  validloss 7.27557±0.00000  bestvalidloss 7.05454  last_update 34\n",
      "train: iter 225  trainloss 3.03099  validloss 7.52938±0.00000  bestvalidloss 7.05454  last_update 35\n",
      "train: iter 226  trainloss 3.04597  validloss 8.78372±0.00000  bestvalidloss 7.05454  last_update 36\n",
      "train: iter 227  trainloss 3.04462  validloss 7.20715±0.00000  bestvalidloss 7.05454  last_update 37\n",
      "train: iter 228  trainloss 2.96519  validloss 7.53950±0.00000  bestvalidloss 7.05454  last_update 38\n",
      "train: iter 229  trainloss 3.07358  validloss 8.67904±0.00000  bestvalidloss 7.05454  last_update 39\n",
      "train: iter 230  trainloss 2.99984  validloss 8.06799±0.00000  bestvalidloss 7.05454  last_update 40\n",
      "train: iter 231  trainloss 3.01626  validloss 7.68201±0.00000  bestvalidloss 7.05454  last_update 41\n",
      "train: iter 232  trainloss 3.00960  validloss 7.68008±0.00000  bestvalidloss 7.05454  last_update 42\n",
      "train: iter 233  trainloss 2.98406  validloss 7.47352±0.00000  bestvalidloss 7.05454  last_update 43\n",
      "train: iter 234  trainloss 3.02095  validloss 7.98270±0.00000  bestvalidloss 7.05454  last_update 44\n",
      "train: iter 235  trainloss 3.07064  validloss 9.19255±0.00000  bestvalidloss 7.05454  last_update 45\n",
      "train: iter 236  trainloss 3.00795  validloss 8.47964±0.00000  bestvalidloss 7.05454  last_update 46\n",
      "train: iter 237  trainloss 3.05506  validloss 8.30862±0.00000  bestvalidloss 7.05454  last_update 47\n",
      "train: iter 238  trainloss 3.01716  validloss 7.98678±0.00000  bestvalidloss 7.05454  last_update 48\n",
      "train: iter 239  trainloss 3.07480  validloss 7.91873±0.00000  bestvalidloss 7.05454  last_update 49\n",
      "train: iter 240  trainloss 2.99842  validloss 7.50213±0.00000  bestvalidloss 7.05454  last_update 50\n",
      "train: iter 241  trainloss 3.01051  validloss 7.67303±0.00000  bestvalidloss 7.05454  last_update 51\n",
      "train: iter 242  trainloss 3.03254  validloss 8.76097±0.00000  bestvalidloss 7.05454  last_update 52\n",
      "train: iter 243  trainloss 3.03864  validloss 8.66040±0.00000  bestvalidloss 7.05454  last_update 53\n",
      "train: iter 244  trainloss 3.00569  validloss 7.16367±0.00000  bestvalidloss 7.05454  last_update 54\n",
      "train: iter 245  trainloss 2.99867  validloss 7.60896±0.00000  bestvalidloss 7.05454  last_update 55\n",
      "train: iter 246  trainloss 3.07161  validloss 8.12711±0.00000  bestvalidloss 7.05454  last_update 56\n",
      "train: iter 247  trainloss 2.99397  validloss 7.70918±0.00000  bestvalidloss 7.05454  last_update 57\n",
      "train: iter 248  trainloss 2.99081  validloss 8.89421±0.00000  bestvalidloss 7.05454  last_update 58\n",
      "train: iter 249  trainloss 3.00402  validloss 7.65517±0.00000  bestvalidloss 7.05454  last_update 59\n",
      "train: iter 250  trainloss 3.03764  validloss 7.89525±0.00000  bestvalidloss 7.05454  last_update 60\n",
      "train: iter 251  trainloss 3.00532  validloss 7.41711±0.00000  bestvalidloss 7.05454  last_update 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 252  trainloss 3.00798  validloss 8.01954±0.00000  bestvalidloss 7.05454  last_update 62\n",
      "train: iter 253  trainloss 3.01564  validloss 8.14182±0.00000  bestvalidloss 7.05454  last_update 63\n",
      "train: iter 254  trainloss 3.01412  validloss 8.20175±0.00000  bestvalidloss 7.05454  last_update 64\n",
      "train: iter 255  trainloss 2.99279  validloss 7.31842±0.00000  bestvalidloss 7.05454  last_update 65\n",
      "train: iter 256  trainloss 2.97890  validloss 7.57285±0.00000  bestvalidloss 7.05454  last_update 66\n",
      "train: iter 257  trainloss 3.04164  validloss 7.26924±0.00000  bestvalidloss 7.05454  last_update 67\n",
      "train: iter 258  trainloss 3.03878  validloss 7.53906±0.00000  bestvalidloss 7.05454  last_update 68\n",
      "train: iter 259  trainloss 2.98124  validloss 7.95993±0.00000  bestvalidloss 7.05454  last_update 69\n",
      "train: iter 260  trainloss 2.98200  validloss 8.72865±0.00000  bestvalidloss 7.05454  last_update 70\n",
      "train: iter 261  trainloss 3.03131  validloss 7.74581±0.00000  bestvalidloss 7.05454  last_update 71\n",
      "train: iter 262  trainloss 3.02613  validloss 7.92984±0.00000  bestvalidloss 7.05454  last_update 72\n",
      "train: iter 263  trainloss 2.98832  validloss 8.04132±0.00000  bestvalidloss 7.05454  last_update 73\n",
      "train: iter 264  trainloss 3.00306  validloss 7.80758±0.00000  bestvalidloss 7.05454  last_update 74\n",
      "train: iter 265  trainloss 3.02390  validloss 9.19354±0.00000  bestvalidloss 7.05454  last_update 75\n",
      "train: iter 266  trainloss 3.02191  validloss 7.70560±0.00000  bestvalidloss 7.05454  last_update 76\n",
      "train: iter 267  trainloss 2.97901  validloss 8.15721±0.00000  bestvalidloss 7.05454  last_update 77\n",
      "train: iter 268  trainloss 3.00819  validloss 7.65752±0.00000  bestvalidloss 7.05454  last_update 78\n",
      "train: iter 269  trainloss 2.95841  validloss 8.79446±0.00000  bestvalidloss 7.05454  last_update 79\n",
      "train: iter 270  trainloss 3.02242  validloss 8.69644±0.00000  bestvalidloss 7.05454  last_update 80\n",
      "train: iter 271  trainloss 2.98627  validloss 7.91010±0.00000  bestvalidloss 7.05454  last_update 81\n",
      "train: iter 272  trainloss 2.99767  validloss 7.41956±0.00000  bestvalidloss 7.05454  last_update 82\n",
      "train: iter 273  trainloss 3.03117  validloss 7.31318±0.00000  bestvalidloss 7.05454  last_update 83\n",
      "train: iter 274  trainloss 3.02468  validloss 7.70738±0.00000  bestvalidloss 7.05454  last_update 84\n",
      "train: iter 275  trainloss 2.99957  validloss 8.77626±0.00000  bestvalidloss 7.05454  last_update 85\n",
      "train: iter 276  trainloss 3.02182  validloss 7.67868±0.00000  bestvalidloss 7.05454  last_update 86\n",
      "train: iter 277  trainloss 3.01746  validloss 7.72706±0.00000  bestvalidloss 7.05454  last_update 87\n",
      "train: iter 278  trainloss 2.99717  validloss 9.42688±0.00000  bestvalidloss 7.05454  last_update 88\n",
      "train: iter 279  trainloss 3.03651  validloss 7.03491±0.00000  bestvalidloss 7.03491  last_update 0\n",
      "train: iter 280  trainloss 2.96279  validloss 7.96764±0.00000  bestvalidloss 7.03491  last_update 1\n",
      "train: iter 281  trainloss 2.98554  validloss 8.60364±0.00000  bestvalidloss 7.03491  last_update 2\n",
      "train: iter 282  trainloss 3.01873  validloss 9.05122±0.00000  bestvalidloss 7.03491  last_update 3\n",
      "train: iter 283  trainloss 3.02087  validloss 7.91088±0.00000  bestvalidloss 7.03491  last_update 4\n",
      "train: iter 284  trainloss 3.01207  validloss 7.49124±0.00000  bestvalidloss 7.03491  last_update 5\n",
      "train: iter 285  trainloss 2.99828  validloss 9.37109±0.00000  bestvalidloss 7.03491  last_update 6\n",
      "train: iter 286  trainloss 2.97764  validloss 7.47654±0.00000  bestvalidloss 7.03491  last_update 7\n",
      "train: iter 287  trainloss 3.01008  validloss 8.15083±0.00000  bestvalidloss 7.03491  last_update 8\n",
      "train: iter 288  trainloss 3.01012  validloss 7.67302±0.00000  bestvalidloss 7.03491  last_update 9\n",
      "train: iter 289  trainloss 2.99180  validloss 8.52850±0.00000  bestvalidloss 7.03491  last_update 10\n",
      "train: iter 290  trainloss 2.99954  validloss 7.62522±0.00000  bestvalidloss 7.03491  last_update 11\n",
      "train: iter 291  trainloss 2.99564  validloss 8.08831±0.00000  bestvalidloss 7.03491  last_update 12\n",
      "train: iter 292  trainloss 2.98140  validloss 7.29867±0.00000  bestvalidloss 7.03491  last_update 13\n",
      "train: iter 293  trainloss 2.99652  validloss 8.53710±0.00000  bestvalidloss 7.03491  last_update 14\n",
      "train: iter 294  trainloss 2.99210  validloss 7.35581±0.00000  bestvalidloss 7.03491  last_update 15\n",
      "train: iter 295  trainloss 2.97306  validloss 7.67863±0.00000  bestvalidloss 7.03491  last_update 16\n",
      "train: iter 296  trainloss 2.99383  validloss 7.71842±0.00000  bestvalidloss 7.03491  last_update 17\n",
      "train: iter 297  trainloss 2.98615  validloss 8.27308±0.00000  bestvalidloss 7.03491  last_update 18\n",
      "train: iter 298  trainloss 3.05025  validloss 8.31496±0.00000  bestvalidloss 7.03491  last_update 19\n",
      "train: iter 299  trainloss 3.03857  validloss 8.90744±0.00000  bestvalidloss 7.03491  last_update 20\n",
      "train: iter 300  trainloss 2.99864  validloss 8.21026±0.00000  bestvalidloss 7.03491  last_update 21\n",
      "train: iter 301  trainloss 2.98856  validloss 8.20702±0.00000  bestvalidloss 7.03491  last_update 22\n",
      "train: iter 302  trainloss 3.00579  validloss 8.30826±0.00000  bestvalidloss 7.03491  last_update 23\n",
      "train: iter 303  trainloss 2.97258  validloss 7.66074±0.00000  bestvalidloss 7.03491  last_update 24\n",
      "train: iter 304  trainloss 2.95741  validloss 7.84302±0.00000  bestvalidloss 7.03491  last_update 25\n",
      "train: iter 305  trainloss 2.95179  validloss 8.42429±0.00000  bestvalidloss 7.03491  last_update 26\n",
      "train: iter 306  trainloss 3.01183  validloss 7.57980±0.00000  bestvalidloss 7.03491  last_update 27\n",
      "train: iter 307  trainloss 2.97783  validloss 8.18301±0.00000  bestvalidloss 7.03491  last_update 28\n",
      "train: iter 308  trainloss 2.98826  validloss 7.37349±0.00000  bestvalidloss 7.03491  last_update 29\n",
      "train: iter 309  trainloss 2.96311  validloss 8.70698±0.00000  bestvalidloss 7.03491  last_update 30\n",
      "train: iter 310  trainloss 3.00813  validloss 7.17148±0.00000  bestvalidloss 7.03491  last_update 31\n",
      "train: iter 311  trainloss 3.00232  validloss 7.89340±0.00000  bestvalidloss 7.03491  last_update 32\n",
      "train: iter 312  trainloss 3.01870  validloss 7.44569±0.00000  bestvalidloss 7.03491  last_update 33\n",
      "train: iter 313  trainloss 2.97621  validloss 8.64414±0.00000  bestvalidloss 7.03491  last_update 34\n",
      "train: iter 314  trainloss 3.00700  validloss 7.52321±0.00000  bestvalidloss 7.03491  last_update 35\n",
      "train: iter 315  trainloss 2.98402  validloss 7.76931±0.00000  bestvalidloss 7.03491  last_update 36\n",
      "train: iter 316  trainloss 3.01496  validloss 8.74814±0.00000  bestvalidloss 7.03491  last_update 37\n",
      "train: iter 317  trainloss 3.02544  validloss 8.58812±0.00000  bestvalidloss 7.03491  last_update 38\n",
      "train: iter 318  trainloss 3.01419  validloss 8.03522±0.00000  bestvalidloss 7.03491  last_update 39\n",
      "train: iter 319  trainloss 3.00001  validloss 8.31292±0.00000  bestvalidloss 7.03491  last_update 40\n",
      "train: iter 320  trainloss 3.02881  validloss 7.20996±0.00000  bestvalidloss 7.03491  last_update 41\n",
      "train: iter 321  trainloss 3.02115  validloss 9.22853±0.00000  bestvalidloss 7.03491  last_update 42\n",
      "train: iter 322  trainloss 2.98828  validloss 8.76088±0.00000  bestvalidloss 7.03491  last_update 43\n",
      "train: iter 323  trainloss 3.03526  validloss 8.01793±0.00000  bestvalidloss 7.03491  last_update 44\n",
      "train: iter 324  trainloss 2.99574  validloss 7.72520±0.00000  bestvalidloss 7.03491  last_update 45\n",
      "train: iter 325  trainloss 2.99561  validloss 8.52661±0.00000  bestvalidloss 7.03491  last_update 46\n",
      "train: iter 326  trainloss 3.02668  validloss 7.32960±0.00000  bestvalidloss 7.03491  last_update 47\n",
      "train: iter 327  trainloss 2.99617  validloss 8.97957±0.00000  bestvalidloss 7.03491  last_update 48\n",
      "train: iter 328  trainloss 3.00544  validloss 7.38725±0.00000  bestvalidloss 7.03491  last_update 49\n",
      "train: iter 329  trainloss 3.03035  validloss 7.29195±0.00000  bestvalidloss 7.03491  last_update 50\n",
      "train: iter 330  trainloss 3.01178  validloss 7.40347±0.00000  bestvalidloss 7.03491  last_update 51\n",
      "train: iter 331  trainloss 2.97387  validloss 8.14043±0.00000  bestvalidloss 7.03491  last_update 52\n",
      "train: iter 332  trainloss 3.02325  validloss 8.02327±0.00000  bestvalidloss 7.03491  last_update 53\n",
      "train: iter 333  trainloss 3.01095  validloss 7.97351±0.00000  bestvalidloss 7.03491  last_update 54\n",
      "train: iter 334  trainloss 2.97442  validloss 7.58863±0.00000  bestvalidloss 7.03491  last_update 55\n",
      "train: iter 335  trainloss 2.95624  validloss 8.21561±0.00000  bestvalidloss 7.03491  last_update 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 336  trainloss 3.03056  validloss 7.81259±0.00000  bestvalidloss 7.03491  last_update 57\n",
      "train: iter 337  trainloss 3.00761  validloss 8.13863±0.00000  bestvalidloss 7.03491  last_update 58\n",
      "train: iter 338  trainloss 2.97179  validloss 8.65542±0.00000  bestvalidloss 7.03491  last_update 59\n",
      "train: iter 339  trainloss 2.98862  validloss 8.25876±0.00000  bestvalidloss 7.03491  last_update 60\n",
      "train: iter 340  trainloss 2.98889  validloss 8.67430±0.00000  bestvalidloss 7.03491  last_update 61\n",
      "train: iter 341  trainloss 3.00088  validloss 8.13116±0.00000  bestvalidloss 7.03491  last_update 62\n",
      "train: iter 342  trainloss 2.98851  validloss 8.14847±0.00000  bestvalidloss 7.03491  last_update 63\n",
      "train: iter 343  trainloss 2.96447  validloss 8.46005±0.00000  bestvalidloss 7.03491  last_update 64\n",
      "train: iter 344  trainloss 2.97605  validloss 8.02377±0.00000  bestvalidloss 7.03491  last_update 65\n",
      "train: iter 345  trainloss 3.06875  validloss 7.62188±0.00000  bestvalidloss 7.03491  last_update 66\n",
      "train: iter 346  trainloss 3.00561  validloss 8.30056±0.00000  bestvalidloss 7.03491  last_update 67\n",
      "train: iter 347  trainloss 3.04167  validloss 8.91761±0.00000  bestvalidloss 7.03491  last_update 68\n",
      "train: iter 348  trainloss 2.95984  validloss 8.15499±0.00000  bestvalidloss 7.03491  last_update 69\n",
      "train: iter 349  trainloss 2.97560  validloss 7.40032±0.00000  bestvalidloss 7.03491  last_update 70\n",
      "train: iter 350  trainloss 2.98271  validloss 8.00973±0.00000  bestvalidloss 7.03491  last_update 71\n",
      "train: iter 351  trainloss 2.99358  validloss 8.09819±0.00000  bestvalidloss 7.03491  last_update 72\n",
      "train: iter 352  trainloss 2.99547  validloss 8.26825±0.00000  bestvalidloss 7.03491  last_update 73\n",
      "train: iter 353  trainloss 2.97988  validloss 7.95888±0.00000  bestvalidloss 7.03491  last_update 74\n",
      "train: iter 354  trainloss 3.03756  validloss 8.61618±0.00000  bestvalidloss 7.03491  last_update 75\n",
      "train: iter 355  trainloss 3.02441  validloss 7.12886±0.00000  bestvalidloss 7.03491  last_update 76\n",
      "train: iter 356  trainloss 2.97523  validloss 7.93572±0.00000  bestvalidloss 7.03491  last_update 77\n",
      "train: iter 357  trainloss 3.02344  validloss 7.53279±0.00000  bestvalidloss 7.03491  last_update 78\n",
      "train: iter 358  trainloss 2.99566  validloss 7.87797±0.00000  bestvalidloss 7.03491  last_update 79\n",
      "train: iter 359  trainloss 2.96897  validloss 6.99795±0.00000  bestvalidloss 6.99795  last_update 0\n",
      "train: iter 360  trainloss 3.02240  validloss 9.27805±0.00000  bestvalidloss 6.99795  last_update 1\n",
      "train: iter 361  trainloss 2.99650  validloss 8.57883±0.00000  bestvalidloss 6.99795  last_update 2\n",
      "train: iter 362  trainloss 2.99545  validloss 7.18873±0.00000  bestvalidloss 6.99795  last_update 3\n",
      "train: iter 363  trainloss 3.00498  validloss 7.92627±0.00000  bestvalidloss 6.99795  last_update 4\n",
      "train: iter 364  trainloss 2.97412  validloss 8.16945±0.00000  bestvalidloss 6.99795  last_update 5\n",
      "train: iter 365  trainloss 2.97870  validloss 8.75761±0.00000  bestvalidloss 6.99795  last_update 6\n",
      "train: iter 366  trainloss 3.03902  validloss 8.30880±0.00000  bestvalidloss 6.99795  last_update 7\n",
      "train: iter 367  trainloss 3.01383  validloss 8.62257±0.00000  bestvalidloss 6.99795  last_update 8\n",
      "train: iter 368  trainloss 2.96042  validloss 7.78537±0.00000  bestvalidloss 6.99795  last_update 9\n",
      "train: iter 369  trainloss 2.96252  validloss 8.18840±0.00000  bestvalidloss 6.99795  last_update 10\n",
      "train: iter 370  trainloss 2.98597  validloss 7.54075±0.00000  bestvalidloss 6.99795  last_update 11\n",
      "train: iter 371  trainloss 2.97995  validloss 8.68276±0.00000  bestvalidloss 6.99795  last_update 12\n",
      "train: iter 372  trainloss 2.96623  validloss 8.28604±0.00000  bestvalidloss 6.99795  last_update 13\n",
      "train: iter 373  trainloss 2.98733  validloss 7.97873±0.00000  bestvalidloss 6.99795  last_update 14\n",
      "train: iter 374  trainloss 3.00763  validloss 9.03830±0.00000  bestvalidloss 6.99795  last_update 15\n",
      "train: iter 375  trainloss 2.95727  validloss 7.62061±0.00000  bestvalidloss 6.99795  last_update 16\n",
      "train: iter 376  trainloss 2.99557  validloss 8.12701±0.00000  bestvalidloss 6.99795  last_update 17\n",
      "train: iter 377  trainloss 3.00259  validloss 7.68263±0.00000  bestvalidloss 6.99795  last_update 18\n",
      "train: iter 378  trainloss 3.00938  validloss 8.41532±0.00000  bestvalidloss 6.99795  last_update 19\n",
      "train: iter 379  trainloss 3.00213  validloss 7.53214±0.00000  bestvalidloss 6.99795  last_update 20\n",
      "train: iter 380  trainloss 2.99781  validloss 8.72977±0.00000  bestvalidloss 6.99795  last_update 21\n",
      "train: iter 381  trainloss 3.00108  validloss 8.36769±0.00000  bestvalidloss 6.99795  last_update 22\n",
      "train: iter 382  trainloss 2.98895  validloss 7.73086±0.00000  bestvalidloss 6.99795  last_update 23\n",
      "train: iter 383  trainloss 2.99402  validloss 7.89445±0.00000  bestvalidloss 6.99795  last_update 24\n",
      "train: iter 384  trainloss 2.98702  validloss 8.47833±0.00000  bestvalidloss 6.99795  last_update 25\n",
      "train: iter 385  trainloss 2.97342  validloss 7.44547±0.00000  bestvalidloss 6.99795  last_update 26\n",
      "train: iter 386  trainloss 3.02537  validloss 7.62083±0.00000  bestvalidloss 6.99795  last_update 27\n",
      "train: iter 387  trainloss 2.96323  validloss 8.29159±0.00000  bestvalidloss 6.99795  last_update 28\n",
      "train: iter 388  trainloss 3.00813  validloss 7.57113±0.00000  bestvalidloss 6.99795  last_update 29\n",
      "train: iter 389  trainloss 2.96925  validloss 7.79145±0.00000  bestvalidloss 6.99795  last_update 30\n",
      "train: iter 390  trainloss 2.98361  validloss 7.85194±0.00000  bestvalidloss 6.99795  last_update 31\n",
      "train: iter 391  trainloss 3.01922  validloss 7.31485±0.00000  bestvalidloss 6.99795  last_update 32\n",
      "train: iter 392  trainloss 3.02211  validloss 8.48898±0.00000  bestvalidloss 6.99795  last_update 33\n",
      "train: iter 393  trainloss 3.01820  validloss 7.15549±0.00000  bestvalidloss 6.99795  last_update 34\n",
      "train: iter 394  trainloss 2.98191  validloss 7.97636±0.00000  bestvalidloss 6.99795  last_update 35\n",
      "train: iter 395  trainloss 2.98743  validloss 8.36353±0.00000  bestvalidloss 6.99795  last_update 36\n",
      "train: iter 396  trainloss 2.98154  validloss 7.26248±0.00000  bestvalidloss 6.99795  last_update 37\n",
      "train: iter 397  trainloss 2.98599  validloss 7.70213±0.00000  bestvalidloss 6.99795  last_update 38\n",
      "train: iter 398  trainloss 2.97629  validloss 7.32935±0.00000  bestvalidloss 6.99795  last_update 39\n",
      "train: iter 399  trainloss 2.99988  validloss 9.05209±0.00000  bestvalidloss 6.99795  last_update 40\n",
      "train: iter 400  trainloss 2.95653  validloss 8.68908±0.00000  bestvalidloss 6.99795  last_update 41\n",
      "train: iter 401  trainloss 3.02345  validloss 8.26790±0.00000  bestvalidloss 6.99795  last_update 42\n",
      "train: iter 402  trainloss 2.98300  validloss 6.99105±0.00000  bestvalidloss 6.99105  last_update 0\n",
      "train: iter 403  trainloss 2.99395  validloss 7.43811±0.00000  bestvalidloss 6.99105  last_update 1\n",
      "train: iter 404  trainloss 2.97376  validloss 9.57296±0.00000  bestvalidloss 6.99105  last_update 2\n",
      "train: iter 405  trainloss 2.99635  validloss 7.98133±0.00000  bestvalidloss 6.99105  last_update 3\n",
      "train: iter 406  trainloss 2.98850  validloss 8.07693±0.00000  bestvalidloss 6.99105  last_update 4\n",
      "train: iter 407  trainloss 3.02120  validloss 7.50482±0.00000  bestvalidloss 6.99105  last_update 5\n",
      "train: iter 408  trainloss 3.02977  validloss 8.15967±0.00000  bestvalidloss 6.99105  last_update 6\n",
      "train: iter 409  trainloss 2.96164  validloss 8.32675±0.00000  bestvalidloss 6.99105  last_update 7\n",
      "train: iter 410  trainloss 3.01060  validloss 7.75555±0.00000  bestvalidloss 6.99105  last_update 8\n",
      "train: iter 411  trainloss 2.97272  validloss 8.95310±0.00000  bestvalidloss 6.99105  last_update 9\n",
      "train: iter 412  trainloss 2.94589  validloss 8.16116±0.00000  bestvalidloss 6.99105  last_update 10\n",
      "train: iter 413  trainloss 2.96259  validloss 8.19542±0.00000  bestvalidloss 6.99105  last_update 11\n",
      "train: iter 414  trainloss 3.01744  validloss 7.83739±0.00000  bestvalidloss 6.99105  last_update 12\n",
      "train: iter 415  trainloss 2.97878  validloss 9.04271±0.00000  bestvalidloss 6.99105  last_update 13\n",
      "train: iter 416  trainloss 2.97790  validloss 8.17064±0.00000  bestvalidloss 6.99105  last_update 14\n",
      "train: iter 417  trainloss 3.01852  validloss 9.36254±0.00000  bestvalidloss 6.99105  last_update 15\n",
      "train: iter 418  trainloss 3.01319  validloss 8.67242±0.00000  bestvalidloss 6.99105  last_update 16\n",
      "train: iter 419  trainloss 2.98990  validloss 7.71914±0.00000  bestvalidloss 6.99105  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 420  trainloss 3.04984  validloss 8.69166±0.00000  bestvalidloss 6.99105  last_update 18\n",
      "train: iter 421  trainloss 3.00962  validloss 7.92201±0.00000  bestvalidloss 6.99105  last_update 19\n",
      "train: iter 422  trainloss 2.98225  validloss 8.43540±0.00000  bestvalidloss 6.99105  last_update 20\n",
      "train: iter 423  trainloss 3.00331  validloss 8.52131±0.00000  bestvalidloss 6.99105  last_update 21\n",
      "train: iter 424  trainloss 3.01123  validloss 8.54802±0.00000  bestvalidloss 6.99105  last_update 22\n",
      "train: iter 425  trainloss 3.02324  validloss 8.81806±0.00000  bestvalidloss 6.99105  last_update 23\n",
      "train: iter 426  trainloss 2.99931  validloss 8.39381±0.00000  bestvalidloss 6.99105  last_update 24\n",
      "train: iter 427  trainloss 2.97457  validloss 7.67850±0.00000  bestvalidloss 6.99105  last_update 25\n",
      "train: iter 428  trainloss 2.97227  validloss 8.00216±0.00000  bestvalidloss 6.99105  last_update 26\n",
      "train: iter 429  trainloss 2.93636  validloss 7.93615±0.00000  bestvalidloss 6.99105  last_update 27\n",
      "train: iter 430  trainloss 2.97797  validloss 9.06790±0.00000  bestvalidloss 6.99105  last_update 28\n",
      "train: iter 431  trainloss 3.01157  validloss 8.52311±0.00000  bestvalidloss 6.99105  last_update 29\n",
      "train: iter 432  trainloss 2.99166  validloss 8.24019±0.00000  bestvalidloss 6.99105  last_update 30\n",
      "train: iter 433  trainloss 3.00128  validloss 8.89645±0.00000  bestvalidloss 6.99105  last_update 31\n",
      "train: iter 434  trainloss 2.94753  validloss 7.23316±0.00000  bestvalidloss 6.99105  last_update 32\n",
      "train: iter 435  trainloss 2.95513  validloss 7.83786±0.00000  bestvalidloss 6.99105  last_update 33\n",
      "train: iter 436  trainloss 3.00262  validloss 8.79655±0.00000  bestvalidloss 6.99105  last_update 34\n",
      "train: iter 437  trainloss 2.99019  validloss 8.16218±0.00000  bestvalidloss 6.99105  last_update 35\n",
      "train: iter 438  trainloss 3.01243  validloss 7.41104±0.00000  bestvalidloss 6.99105  last_update 36\n",
      "train: iter 439  trainloss 2.97219  validloss 7.39314±0.00000  bestvalidloss 6.99105  last_update 37\n",
      "train: iter 440  trainloss 2.99563  validloss 8.43766±0.00000  bestvalidloss 6.99105  last_update 38\n",
      "train: iter 441  trainloss 2.99503  validloss 8.41654±0.00000  bestvalidloss 6.99105  last_update 39\n",
      "train: iter 442  trainloss 3.05055  validloss 8.78953±0.00000  bestvalidloss 6.99105  last_update 40\n",
      "train: iter 443  trainloss 2.97505  validloss 7.46729±0.00000  bestvalidloss 6.99105  last_update 41\n",
      "train: iter 444  trainloss 3.00740  validloss 9.06536±0.00000  bestvalidloss 6.99105  last_update 42\n",
      "train: iter 445  trainloss 2.95430  validloss 7.84839±0.00000  bestvalidloss 6.99105  last_update 43\n",
      "train: iter 446  trainloss 3.01179  validloss 7.95753±0.00000  bestvalidloss 6.99105  last_update 44\n",
      "train: iter 447  trainloss 2.92915  validloss 8.57641±0.00000  bestvalidloss 6.99105  last_update 45\n",
      "train: iter 448  trainloss 2.95453  validloss 8.17147±0.00000  bestvalidloss 6.99105  last_update 46\n",
      "train: iter 449  trainloss 2.99769  validloss 8.18178±0.00000  bestvalidloss 6.99105  last_update 47\n",
      "train: iter 450  trainloss 2.98139  validloss 8.22417±0.00000  bestvalidloss 6.99105  last_update 48\n",
      "train: iter 451  trainloss 2.93259  validloss 7.84246±0.00000  bestvalidloss 6.99105  last_update 49\n",
      "train: iter 452  trainloss 2.95457  validloss 8.63686±0.00000  bestvalidloss 6.99105  last_update 50\n",
      "train: iter 453  trainloss 2.98942  validloss 8.70568±0.00000  bestvalidloss 6.99105  last_update 51\n",
      "train: iter 454  trainloss 2.97438  validloss 8.44685±0.00000  bestvalidloss 6.99105  last_update 52\n",
      "train: iter 455  trainloss 2.96939  validloss 7.94695±0.00000  bestvalidloss 6.99105  last_update 53\n",
      "train: iter 456  trainloss 2.99059  validloss 8.75080±0.00000  bestvalidloss 6.99105  last_update 54\n",
      "train: iter 457  trainloss 3.01146  validloss 8.40601±0.00000  bestvalidloss 6.99105  last_update 55\n",
      "train: iter 458  trainloss 2.96716  validloss 7.63268±0.00000  bestvalidloss 6.99105  last_update 56\n",
      "train: iter 459  trainloss 2.98677  validloss 7.57594±0.00000  bestvalidloss 6.99105  last_update 57\n",
      "train: iter 460  trainloss 2.94422  validloss 7.98968±0.00000  bestvalidloss 6.99105  last_update 58\n",
      "train: iter 461  trainloss 2.99155  validloss 7.79364±0.00000  bestvalidloss 6.99105  last_update 59\n",
      "train: iter 462  trainloss 2.93738  validloss 8.31642±0.00000  bestvalidloss 6.99105  last_update 60\n",
      "train: iter 463  trainloss 2.99051  validloss 7.78861±0.00000  bestvalidloss 6.99105  last_update 61\n",
      "train: iter 464  trainloss 2.96602  validloss 8.10646±0.00000  bestvalidloss 6.99105  last_update 62\n",
      "train: iter 465  trainloss 2.96130  validloss 8.26634±0.00000  bestvalidloss 6.99105  last_update 63\n",
      "train: iter 466  trainloss 2.96734  validloss 7.87265±0.00000  bestvalidloss 6.99105  last_update 64\n",
      "train: iter 467  trainloss 2.99559  validloss 8.65170±0.00000  bestvalidloss 6.99105  last_update 65\n",
      "train: iter 468  trainloss 2.96229  validloss 8.29673±0.00000  bestvalidloss 6.99105  last_update 66\n",
      "train: iter 469  trainloss 3.00055  validloss 7.55827±0.00000  bestvalidloss 6.99105  last_update 67\n",
      "train: iter 470  trainloss 2.96718  validloss 8.26565±0.00000  bestvalidloss 6.99105  last_update 68\n",
      "train: iter 471  trainloss 2.98214  validloss 7.80724±0.00000  bestvalidloss 6.99105  last_update 69\n",
      "train: iter 472  trainloss 2.98973  validloss 8.10555±0.00000  bestvalidloss 6.99105  last_update 70\n",
      "train: iter 473  trainloss 2.99459  validloss 8.57140±0.00000  bestvalidloss 6.99105  last_update 71\n",
      "train: iter 474  trainloss 2.99969  validloss 8.59746±0.00000  bestvalidloss 6.99105  last_update 72\n",
      "train: iter 475  trainloss 2.98552  validloss 8.57972±0.00000  bestvalidloss 6.99105  last_update 73\n",
      "train: iter 476  trainloss 2.99305  validloss 7.43912±0.00000  bestvalidloss 6.99105  last_update 74\n",
      "train: iter 477  trainloss 2.97524  validloss 8.34351±0.00000  bestvalidloss 6.99105  last_update 75\n",
      "train: iter 478  trainloss 2.98678  validloss 8.41330±0.00000  bestvalidloss 6.99105  last_update 76\n",
      "train: iter 479  trainloss 2.97411  validloss 8.13939±0.00000  bestvalidloss 6.99105  last_update 77\n",
      "train: iter 480  trainloss 2.97413  validloss 7.95745±0.00000  bestvalidloss 6.99105  last_update 78\n",
      "train: iter 481  trainloss 2.99977  validloss 8.53589±0.00000  bestvalidloss 6.99105  last_update 79\n",
      "train: iter 482  trainloss 2.93889  validloss 7.56420±0.00000  bestvalidloss 6.99105  last_update 80\n",
      "train: iter 483  trainloss 2.97572  validloss 7.38186±0.00000  bestvalidloss 6.99105  last_update 81\n",
      "train: iter 484  trainloss 3.01029  validloss 8.06592±0.00000  bestvalidloss 6.99105  last_update 82\n",
      "train: iter 485  trainloss 3.00577  validloss 8.36591±0.00000  bestvalidloss 6.99105  last_update 83\n",
      "train: iter 486  trainloss 2.92861  validloss 8.19435±0.00000  bestvalidloss 6.99105  last_update 84\n",
      "train: iter 487  trainloss 2.97855  validloss 7.89392±0.00000  bestvalidloss 6.99105  last_update 85\n",
      "train: iter 488  trainloss 2.97918  validloss 9.19292±0.00000  bestvalidloss 6.99105  last_update 86\n",
      "train: iter 489  trainloss 2.99150  validloss 7.98301±0.00000  bestvalidloss 6.99105  last_update 87\n",
      "train: iter 490  trainloss 2.99556  validloss 8.86917±0.00000  bestvalidloss 6.99105  last_update 88\n",
      "train: iter 491  trainloss 2.97228  validloss 8.53793±0.00000  bestvalidloss 6.99105  last_update 89\n",
      "train: iter 492  trainloss 3.02701  validloss 7.60215±0.00000  bestvalidloss 6.99105  last_update 90\n",
      "train: iter 493  trainloss 2.95041  validloss 8.00861±0.00000  bestvalidloss 6.99105  last_update 91\n",
      "train: iter 494  trainloss 2.97294  validloss 8.81513±0.00000  bestvalidloss 6.99105  last_update 92\n",
      "train: iter 495  trainloss 2.98484  validloss 7.69412±0.00000  bestvalidloss 6.99105  last_update 93\n",
      "train: iter 496  trainloss 3.01808  validloss 7.26652±0.00000  bestvalidloss 6.99105  last_update 94\n",
      "train: iter 497  trainloss 3.01536  validloss 9.15879±0.00000  bestvalidloss 6.99105  last_update 95\n",
      "train: iter 498  trainloss 2.94887  validloss 7.95276±0.00000  bestvalidloss 6.99105  last_update 96\n",
      "train: iter 499  trainloss 2.96168  validloss 8.06473±0.00000  bestvalidloss 6.99105  last_update 97\n",
      "train: iter 500  trainloss 2.97168  validloss 8.82903±0.00000  bestvalidloss 6.99105  last_update 98\n",
      "train: iter 501  trainloss 2.97829  validloss 7.44824±0.00000  bestvalidloss 6.99105  last_update 99\n",
      "train: iter 502  trainloss 2.97229  validloss 8.97450±0.00000  bestvalidloss 6.99105  last_update 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-6.9585)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-4.0745)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21929953144475964\n",
      "tensor([-1.3513])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143360d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2417b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef080d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62244c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
