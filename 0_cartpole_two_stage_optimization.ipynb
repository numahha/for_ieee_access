{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(2045.2968)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 113522.55601  validloss 143892.41613±0.00000  bestvalidloss 143892.41613  last_update 0\n",
      "train: iter 1  trainloss 31330.23639  validloss 14649.43673±0.00000  bestvalidloss 14649.43673  last_update 0\n",
      "train: iter 2  trainloss 1847.21850  validloss 8632.87393±0.00000  bestvalidloss 8632.87393  last_update 0\n",
      "train: iter 3  trainloss 2247.37085  validloss 1304.73202±0.00000  bestvalidloss 1304.73202  last_update 0\n",
      "train: iter 4  trainloss 1054.67973  validloss 1213.58877±0.00000  bestvalidloss 1213.58877  last_update 0\n",
      "train: iter 5  trainloss 902.64808  validloss 1049.15751±0.00000  bestvalidloss 1049.15751  last_update 0\n",
      "train: iter 6  trainloss 814.79386  validloss 990.97498±0.00000  bestvalidloss 990.97498  last_update 0\n",
      "train: iter 7  trainloss 763.01707  validloss 929.21352±0.00000  bestvalidloss 929.21352  last_update 0\n",
      "train: iter 8  trainloss 724.43533  validloss 913.24624±0.00000  bestvalidloss 913.24624  last_update 0\n",
      "train: iter 9  trainloss 670.37887  validloss 861.57471±0.00000  bestvalidloss 861.57471  last_update 0\n",
      "train: iter 10  trainloss 602.94024  validloss 835.01262±0.00000  bestvalidloss 835.01262  last_update 0\n",
      "train: iter 11  trainloss 559.94853  validloss 741.12312±0.00000  bestvalidloss 741.12312  last_update 0\n",
      "train: iter 12  trainloss 521.30911  validloss 708.98187±0.00000  bestvalidloss 708.98187  last_update 0\n",
      "train: iter 13  trainloss 430.90850  validloss 553.68157±0.00000  bestvalidloss 553.68157  last_update 0\n",
      "train: iter 14  trainloss 355.89967  validloss 432.45275±0.00000  bestvalidloss 432.45275  last_update 0\n",
      "train: iter 15  trainloss 316.83177  validloss 375.91371±0.00000  bestvalidloss 375.91371  last_update 0\n",
      "train: iter 16  trainloss 252.54835  validloss 292.31644±0.00000  bestvalidloss 292.31644  last_update 0\n",
      "train: iter 17  trainloss 234.49037  validloss 259.36036±0.00000  bestvalidloss 259.36036  last_update 0\n",
      "train: iter 18  trainloss 174.37967  validloss 216.71660±0.00000  bestvalidloss 216.71660  last_update 0\n",
      "train: iter 19  trainloss 212.55228  validloss 146.18861±0.00000  bestvalidloss 146.18861  last_update 0\n",
      "train: iter 20  trainloss 120.09681  validloss 160.32862±0.00000  bestvalidloss 146.18861  last_update 1\n",
      "train: iter 21  trainloss 70.99932  validloss 87.27044±0.00000  bestvalidloss 87.27044  last_update 0\n",
      "train: iter 22  trainloss 39.16616  validloss 53.19543±0.00000  bestvalidloss 53.19543  last_update 0\n",
      "train: iter 23  trainloss 5.23621  validloss 45.11893±0.00000  bestvalidloss 45.11893  last_update 0\n",
      "train: iter 24  trainloss -5.61805  validloss 13.28624±0.00000  bestvalidloss 13.28624  last_update 0\n",
      "train: iter 25  trainloss -26.30587  validloss -9.50776±0.00000  bestvalidloss -9.50776  last_update 0\n",
      "train: iter 26  trainloss -41.28854  validloss -28.76310±0.00000  bestvalidloss -28.76310  last_update 0\n",
      "train: iter 27  trainloss -64.09907  validloss -66.37991±0.00000  bestvalidloss -66.37991  last_update 0\n",
      "train: iter 28  trainloss -90.09834  validloss -45.78505±0.00000  bestvalidloss -66.37991  last_update 1\n",
      "train: iter 29  trainloss -90.92960  validloss -85.26009±0.00000  bestvalidloss -85.26009  last_update 0\n",
      "train: iter 30  trainloss -116.12980  validloss -143.11662±0.00000  bestvalidloss -143.11662  last_update 0\n",
      "train: iter 31  trainloss -141.30128  validloss -77.09306±0.00000  bestvalidloss -143.11662  last_update 1\n",
      "train: iter 32  trainloss -157.59882  validloss -128.19182±0.00000  bestvalidloss -143.11662  last_update 2\n",
      "train: iter 33  trainloss -143.21479  validloss -72.42177±0.00000  bestvalidloss -143.11662  last_update 3\n",
      "train: iter 34  trainloss -163.14954  validloss -187.76951±0.00000  bestvalidloss -187.76951  last_update 0\n",
      "train: iter 35  trainloss -187.48531  validloss -144.26741±0.00000  bestvalidloss -187.76951  last_update 1\n",
      "train: iter 36  trainloss -186.73091  validloss -165.38967±0.00000  bestvalidloss -187.76951  last_update 2\n",
      "train: iter 37  trainloss -192.96937  validloss -170.78040±0.00000  bestvalidloss -187.76951  last_update 3\n",
      "train: iter 38  trainloss -242.14140  validloss -193.32160±0.00000  bestvalidloss -193.32160  last_update 0\n",
      "train: iter 39  trainloss -261.86475  validloss -215.21129±0.00000  bestvalidloss -215.21129  last_update 0\n",
      "train: iter 40  trainloss -229.11450  validloss -184.25032±0.00000  bestvalidloss -215.21129  last_update 1\n",
      "train: iter 41  trainloss -262.27266  validloss -228.21952±0.00000  bestvalidloss -228.21952  last_update 0\n",
      "train: iter 42  trainloss -281.00993  validloss -215.26391±0.00000  bestvalidloss -228.21952  last_update 1\n",
      "train: iter 43  trainloss -275.95592  validloss -259.65211±0.00000  bestvalidloss -259.65211  last_update 0\n",
      "train: iter 44  trainloss -233.97906  validloss -184.89440±0.00000  bestvalidloss -259.65211  last_update 1\n",
      "train: iter 45  trainloss -319.00220  validloss -248.32828±0.00000  bestvalidloss -259.65211  last_update 2\n",
      "train: iter 46  trainloss -337.02728  validloss -320.80492±0.00000  bestvalidloss -320.80492  last_update 0\n",
      "train: iter 47  trainloss -317.73530  validloss -250.72409±0.00000  bestvalidloss -320.80492  last_update 1\n",
      "train: iter 48  trainloss -312.27009  validloss -42.62951±0.00000  bestvalidloss -320.80492  last_update 2\n",
      "train: iter 49  trainloss -337.60825  validloss -295.24263±0.00000  bestvalidloss -320.80492  last_update 3\n",
      "train: iter 50  trainloss -351.42757  validloss -329.32400±0.00000  bestvalidloss -329.32400  last_update 0\n",
      "train: iter 51  trainloss -401.63115  validloss -350.66959±0.00000  bestvalidloss -350.66959  last_update 0\n",
      "train: iter 52  trainloss -364.07596  validloss -284.10007±0.00000  bestvalidloss -350.66959  last_update 1\n",
      "train: iter 53  trainloss -352.04421  validloss -351.54392±0.00000  bestvalidloss -351.54392  last_update 0\n",
      "train: iter 54  trainloss -397.21471  validloss -337.93443±0.00000  bestvalidloss -351.54392  last_update 1\n",
      "train: iter 55  trainloss -420.32035  validloss -380.10598±0.00000  bestvalidloss -380.10598  last_update 0\n",
      "train: iter 56  trainloss -423.86173  validloss -265.53221±0.00000  bestvalidloss -380.10598  last_update 1\n",
      "train: iter 57  trainloss -397.15923  validloss -403.59957±0.00000  bestvalidloss -403.59957  last_update 0\n",
      "train: iter 58  trainloss -380.97056  validloss -378.84284±0.00000  bestvalidloss -403.59957  last_update 1\n",
      "train: iter 59  trainloss -449.02674  validloss -391.48667±0.00000  bestvalidloss -403.59957  last_update 2\n",
      "train: iter 60  trainloss -447.87733  validloss -442.80234±0.00000  bestvalidloss -442.80234  last_update 0\n",
      "train: iter 61  trainloss -440.27860  validloss -356.74655±0.00000  bestvalidloss -442.80234  last_update 1\n",
      "train: iter 62  trainloss -437.98812  validloss -472.28164±0.00000  bestvalidloss -472.28164  last_update 0\n",
      "train: iter 63  trainloss -444.20138  validloss -397.40473±0.00000  bestvalidloss -472.28164  last_update 1\n",
      "train: iter 64  trainloss -488.69534  validloss -448.46882±0.00000  bestvalidloss -472.28164  last_update 2\n",
      "train: iter 65  trainloss -477.56240  validloss -461.14941±0.00000  bestvalidloss -472.28164  last_update 3\n",
      "train: iter 66  trainloss -467.96740  validloss -473.59984±0.00000  bestvalidloss -473.59984  last_update 0\n",
      "train: iter 67  trainloss -492.63090  validloss -464.36233±0.00000  bestvalidloss -473.59984  last_update 1\n",
      "train: iter 68  trainloss -462.68930  validloss -425.50030±0.00000  bestvalidloss -473.59984  last_update 2\n",
      "train: iter 69  trainloss -521.76428  validloss -525.40738±0.00000  bestvalidloss -525.40738  last_update 0\n",
      "train: iter 70  trainloss -507.62939  validloss -507.57819±0.00000  bestvalidloss -525.40738  last_update 1\n",
      "train: iter 71  trainloss -522.22881  validloss -547.57417±0.00000  bestvalidloss -547.57417  last_update 0\n",
      "train: iter 72  trainloss -530.69223  validloss -514.93152±0.00000  bestvalidloss -547.57417  last_update 1\n",
      "train: iter 73  trainloss -525.37301  validloss -541.57104±0.00000  bestvalidloss -547.57417  last_update 2\n",
      "train: iter 74  trainloss -501.11620  validloss -574.85494±0.00000  bestvalidloss -574.85494  last_update 0\n",
      "train: iter 75  trainloss -545.40612  validloss -486.12864±0.00000  bestvalidloss -574.85494  last_update 1\n",
      "train: iter 76  trainloss -530.54141  validloss -514.38172±0.00000  bestvalidloss -574.85494  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -526.92172  validloss -392.43672±0.00000  bestvalidloss -574.85494  last_update 3\n",
      "train: iter 78  trainloss -481.02459  validloss -476.64849±0.00000  bestvalidloss -574.85494  last_update 4\n",
      "train: iter 79  trainloss -480.65699  validloss -524.05471±0.00000  bestvalidloss -574.85494  last_update 5\n",
      "train: iter 80  trainloss -534.19246  validloss -520.10402±0.00000  bestvalidloss -574.85494  last_update 6\n",
      "train: iter 81  trainloss -523.57766  validloss -580.69927±0.00000  bestvalidloss -580.69927  last_update 0\n",
      "train: iter 82  trainloss -522.06410  validloss -443.13655±0.00000  bestvalidloss -580.69927  last_update 1\n",
      "train: iter 83  trainloss -575.81715  validloss -580.55641±0.00000  bestvalidloss -580.69927  last_update 2\n",
      "train: iter 84  trainloss -577.10173  validloss -600.71945±0.00000  bestvalidloss -600.71945  last_update 0\n",
      "train: iter 85  trainloss -567.73551  validloss -544.94814±0.00000  bestvalidloss -600.71945  last_update 1\n",
      "train: iter 86  trainloss -616.39281  validloss -597.36772±0.00000  bestvalidloss -600.71945  last_update 2\n",
      "train: iter 87  trainloss -590.00524  validloss -670.86332±0.00000  bestvalidloss -670.86332  last_update 0\n",
      "train: iter 88  trainloss -598.98571  validloss -624.75098±0.00000  bestvalidloss -670.86332  last_update 1\n",
      "train: iter 89  trainloss -593.66070  validloss -564.12607±0.00000  bestvalidloss -670.86332  last_update 2\n",
      "train: iter 90  trainloss -576.62756  validloss -621.81261±0.00000  bestvalidloss -670.86332  last_update 3\n",
      "train: iter 91  trainloss -581.55050  validloss -615.86090±0.00000  bestvalidloss -670.86332  last_update 4\n",
      "train: iter 92  trainloss -503.74091  validloss -650.86628±0.00000  bestvalidloss -670.86332  last_update 5\n",
      "train: iter 93  trainloss -584.04561  validloss -567.81332±0.00000  bestvalidloss -670.86332  last_update 6\n",
      "train: iter 94  trainloss -609.76906  validloss -639.65476±0.00000  bestvalidloss -670.86332  last_update 7\n",
      "train: iter 95  trainloss -588.43371  validloss -493.47170±0.00000  bestvalidloss -670.86332  last_update 8\n",
      "train: iter 96  trainloss -641.55023  validloss -659.77548±0.00000  bestvalidloss -670.86332  last_update 9\n",
      "train: iter 97  trainloss -588.42225  validloss -656.11323±0.00000  bestvalidloss -670.86332  last_update 10\n",
      "train: iter 98  trainloss -646.03701  validloss -620.27817±0.00000  bestvalidloss -670.86332  last_update 11\n",
      "train: iter 99  trainloss -646.24400  validloss -644.22522±0.00000  bestvalidloss -670.86332  last_update 12\n",
      "train: iter 100  trainloss -595.91012  validloss -637.91882±0.00000  bestvalidloss -670.86332  last_update 13\n",
      "train: iter 101  trainloss -639.33499  validloss -564.10917±0.00000  bestvalidloss -670.86332  last_update 14\n",
      "train: iter 102  trainloss -628.35279  validloss -661.12367±0.00000  bestvalidloss -670.86332  last_update 15\n",
      "train: iter 103  trainloss -584.57694  validloss -656.37716±0.00000  bestvalidloss -670.86332  last_update 16\n",
      "train: iter 104  trainloss -649.09655  validloss -538.85549±0.00000  bestvalidloss -670.86332  last_update 17\n",
      "train: iter 105  trainloss -658.93797  validloss -693.02812±0.00000  bestvalidloss -693.02812  last_update 0\n",
      "train: iter 106  trainloss -675.97379  validloss -667.60939±0.00000  bestvalidloss -693.02812  last_update 1\n",
      "train: iter 107  trainloss -577.44979  validloss -679.53170±0.00000  bestvalidloss -693.02812  last_update 2\n",
      "train: iter 108  trainloss -649.36182  validloss -477.29378±0.00000  bestvalidloss -693.02812  last_update 3\n",
      "train: iter 109  trainloss -698.66869  validloss -780.09059±0.00000  bestvalidloss -780.09059  last_update 0\n",
      "train: iter 110  trainloss -652.27491  validloss -731.17501±0.00000  bestvalidloss -780.09059  last_update 1\n",
      "train: iter 111  trainloss -689.79724  validloss -703.33640±0.00000  bestvalidloss -780.09059  last_update 2\n",
      "train: iter 112  trainloss -636.45149  validloss -699.06998±0.00000  bestvalidloss -780.09059  last_update 3\n",
      "train: iter 113  trainloss -677.79096  validloss -620.31743±0.00000  bestvalidloss -780.09059  last_update 4\n",
      "train: iter 114  trainloss -682.99307  validloss -604.00446±0.00000  bestvalidloss -780.09059  last_update 5\n",
      "train: iter 115  trainloss -640.37753  validloss -713.53307±0.00000  bestvalidloss -780.09059  last_update 6\n",
      "train: iter 116  trainloss -694.88439  validloss -721.17500±0.00000  bestvalidloss -780.09059  last_update 7\n",
      "train: iter 117  trainloss -669.41008  validloss -732.21556±0.00000  bestvalidloss -780.09059  last_update 8\n",
      "train: iter 118  trainloss -611.46318  validloss -579.54615±0.00000  bestvalidloss -780.09059  last_update 9\n",
      "train: iter 119  trainloss -552.29549  validloss -706.13130±0.00000  bestvalidloss -780.09059  last_update 10\n",
      "train: iter 120  trainloss -571.30241  validloss -662.69526±0.00000  bestvalidloss -780.09059  last_update 11\n",
      "train: iter 121  trainloss -607.21901  validloss -613.57306±0.00000  bestvalidloss -780.09059  last_update 12\n",
      "train: iter 122  trainloss -638.41971  validloss -722.69084±0.00000  bestvalidloss -780.09059  last_update 13\n",
      "train: iter 123  trainloss -695.40292  validloss -597.62275±0.00000  bestvalidloss -780.09059  last_update 14\n",
      "train: iter 124  trainloss -755.74474  validloss -718.46769±0.00000  bestvalidloss -780.09059  last_update 15\n",
      "train: iter 125  trainloss -690.42606  validloss -783.08110±0.00000  bestvalidloss -783.08110  last_update 0\n",
      "train: iter 126  trainloss -747.32333  validloss -811.17355±0.00000  bestvalidloss -811.17355  last_update 0\n",
      "train: iter 127  trainloss -741.43341  validloss -756.33372±0.00000  bestvalidloss -811.17355  last_update 1\n",
      "train: iter 128  trainloss -753.06860  validloss -654.46292±0.00000  bestvalidloss -811.17355  last_update 2\n",
      "train: iter 129  trainloss -532.15697  validloss -753.92272±0.00000  bestvalidloss -811.17355  last_update 3\n",
      "train: iter 130  trainloss -597.66916  validloss -590.32393±0.00000  bestvalidloss -811.17355  last_update 4\n",
      "train: iter 131  trainloss -734.73715  validloss -750.17255±0.00000  bestvalidloss -811.17355  last_update 5\n",
      "train: iter 132  trainloss -644.76607  validloss -704.96404±0.00000  bestvalidloss -811.17355  last_update 6\n",
      "train: iter 133  trainloss -728.37692  validloss -798.82775±0.00000  bestvalidloss -811.17355  last_update 7\n",
      "train: iter 134  trainloss -702.89659  validloss -595.18731±0.00000  bestvalidloss -811.17355  last_update 8\n",
      "train: iter 135  trainloss -768.25373  validloss -689.96735±0.00000  bestvalidloss -811.17355  last_update 9\n",
      "train: iter 136  trainloss -518.22952  validloss -846.80351±0.00000  bestvalidloss -846.80351  last_update 0\n",
      "train: iter 137  trainloss -733.49718  validloss -710.30135±0.00000  bestvalidloss -846.80351  last_update 1\n",
      "train: iter 138  trainloss -783.99632  validloss -780.97748±0.00000  bestvalidloss -846.80351  last_update 2\n",
      "train: iter 139  trainloss -770.21364  validloss -654.79806±0.00000  bestvalidloss -846.80351  last_update 3\n",
      "train: iter 140  trainloss -780.24619  validloss -830.85569±0.00000  bestvalidloss -846.80351  last_update 4\n",
      "train: iter 141  trainloss -754.07318  validloss -815.68429±0.00000  bestvalidloss -846.80351  last_update 5\n",
      "train: iter 142  trainloss -810.38871  validloss -864.93851±0.00000  bestvalidloss -864.93851  last_update 0\n",
      "train: iter 143  trainloss -812.08208  validloss -840.46526±0.00000  bestvalidloss -864.93851  last_update 1\n",
      "train: iter 144  trainloss -831.48098  validloss -887.37098±0.00000  bestvalidloss -887.37098  last_update 0\n",
      "train: iter 145  trainloss -646.57839  validloss -877.00700±0.00000  bestvalidloss -887.37098  last_update 1\n",
      "train: iter 146  trainloss -762.31826  validloss -739.52739±0.00000  bestvalidloss -887.37098  last_update 2\n",
      "train: iter 147  trainloss -806.67799  validloss -858.44902±0.00000  bestvalidloss -887.37098  last_update 3\n",
      "train: iter 148  trainloss -811.21866  validloss -898.58594±0.00000  bestvalidloss -898.58594  last_update 0\n",
      "train: iter 149  trainloss -828.68075  validloss -849.71827±0.00000  bestvalidloss -898.58594  last_update 1\n",
      "train: iter 150  trainloss -723.52008  validloss -772.54970±0.00000  bestvalidloss -898.58594  last_update 2\n",
      "train: iter 151  trainloss -712.73043  validloss -635.90814±0.00000  bestvalidloss -898.58594  last_update 3\n",
      "train: iter 152  trainloss -821.29631  validloss -853.89513±0.00000  bestvalidloss -898.58594  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -865.13499  validloss -808.09555±0.00000  bestvalidloss -898.58594  last_update 5\n",
      "train: iter 154  trainloss -830.64957  validloss -958.61745±0.00000  bestvalidloss -958.61745  last_update 0\n",
      "train: iter 155  trainloss -715.25670  validloss -792.75645±0.00000  bestvalidloss -958.61745  last_update 1\n",
      "train: iter 156  trainloss -887.78640  validloss -920.63229±0.00000  bestvalidloss -958.61745  last_update 2\n",
      "train: iter 157  trainloss -898.88458  validloss -1014.71410±0.00000  bestvalidloss -1014.71410  last_update 0\n",
      "train: iter 158  trainloss -755.96653  validloss -849.00810±0.00000  bestvalidloss -1014.71410  last_update 1\n",
      "train: iter 159  trainloss -749.62258  validloss -669.89983±0.00000  bestvalidloss -1014.71410  last_update 2\n",
      "train: iter 160  trainloss -783.03880  validloss -838.08035±0.00000  bestvalidloss -1014.71410  last_update 3\n",
      "train: iter 161  trainloss -744.78457  validloss -788.50943±0.00000  bestvalidloss -1014.71410  last_update 4\n",
      "train: iter 162  trainloss -856.23638  validloss -899.30099±0.00000  bestvalidloss -1014.71410  last_update 5\n",
      "train: iter 163  trainloss -876.07944  validloss -939.73759±0.00000  bestvalidloss -1014.71410  last_update 6\n",
      "train: iter 164  trainloss -878.44601  validloss -797.14386±0.00000  bestvalidloss -1014.71410  last_update 7\n",
      "train: iter 165  trainloss -917.68345  validloss -949.61335±0.00000  bestvalidloss -1014.71410  last_update 8\n",
      "train: iter 166  trainloss -782.07188  validloss -1022.04463±0.00000  bestvalidloss -1022.04463  last_update 0\n",
      "train: iter 167  trainloss -771.00571  validloss -802.74541±0.00000  bestvalidloss -1022.04463  last_update 1\n",
      "train: iter 168  trainloss -908.89208  validloss -967.57508±0.00000  bestvalidloss -1022.04463  last_update 2\n",
      "train: iter 169  trainloss -517.40850  validloss -858.71582±0.00000  bestvalidloss -1022.04463  last_update 3\n",
      "train: iter 170  trainloss -526.85589  validloss -347.98439±0.00000  bestvalidloss -1022.04463  last_update 4\n",
      "train: iter 171  trainloss -869.91850  validloss -941.17720±0.00000  bestvalidloss -1022.04463  last_update 5\n",
      "train: iter 172  trainloss -802.49095  validloss -681.77301±0.00000  bestvalidloss -1022.04463  last_update 6\n",
      "train: iter 173  trainloss -828.08116  validloss -695.58108±0.00000  bestvalidloss -1022.04463  last_update 7\n",
      "train: iter 174  trainloss -963.06468  validloss -999.28947±0.00000  bestvalidloss -1022.04463  last_update 8\n",
      "train: iter 175  trainloss -878.15975  validloss -1002.82851±0.00000  bestvalidloss -1022.04463  last_update 9\n",
      "train: iter 176  trainloss -783.34238  validloss -856.21822±0.00000  bestvalidloss -1022.04463  last_update 10\n",
      "train: iter 177  trainloss -943.09070  validloss -976.14567±0.00000  bestvalidloss -1022.04463  last_update 11\n",
      "train: iter 178  trainloss -942.21623  validloss -939.12583±0.00000  bestvalidloss -1022.04463  last_update 12\n",
      "train: iter 179  trainloss -867.69899  validloss -872.05827±0.00000  bestvalidloss -1022.04463  last_update 13\n",
      "train: iter 180  trainloss -709.26116  validloss -681.04572±0.00000  bestvalidloss -1022.04463  last_update 14\n",
      "train: iter 181  trainloss -910.09210  validloss -893.73891±0.00000  bestvalidloss -1022.04463  last_update 15\n",
      "train: iter 182  trainloss -907.58871  validloss -992.40997±0.00000  bestvalidloss -1022.04463  last_update 16\n",
      "train: iter 183  trainloss -893.27746  validloss -993.54978±0.00000  bestvalidloss -1022.04463  last_update 17\n",
      "train: iter 184  trainloss -979.89058  validloss -1034.95447±0.00000  bestvalidloss -1034.95447  last_update 0\n",
      "train: iter 185  trainloss -1001.65841  validloss -1021.18235±0.00000  bestvalidloss -1034.95447  last_update 1\n",
      "train: iter 186  trainloss -985.10574  validloss -1116.45727±0.00000  bestvalidloss -1116.45727  last_update 0\n",
      "train: iter 187  trainloss -1037.20642  validloss -933.01253±0.00000  bestvalidloss -1116.45727  last_update 1\n",
      "train: iter 188  trainloss -952.65360  validloss -1114.39202±0.00000  bestvalidloss -1116.45727  last_update 2\n",
      "train: iter 189  trainloss -901.30317  validloss -981.81002±0.00000  bestvalidloss -1116.45727  last_update 3\n",
      "train: iter 190  trainloss -952.37304  validloss -1091.23839±0.00000  bestvalidloss -1116.45727  last_update 4\n",
      "train: iter 191  trainloss -980.43614  validloss -1098.16075±0.00000  bestvalidloss -1116.45727  last_update 5\n",
      "train: iter 192  trainloss -1036.69104  validloss -993.56477±0.00000  bestvalidloss -1116.45727  last_update 6\n",
      "train: iter 193  trainloss -820.20734  validloss -1128.40208±0.00000  bestvalidloss -1128.40208  last_update 0\n",
      "train: iter 194  trainloss -759.29982  validloss -999.64844±0.00000  bestvalidloss -1128.40208  last_update 1\n",
      "train: iter 195  trainloss -986.95419  validloss -973.41351±0.00000  bestvalidloss -1128.40208  last_update 2\n",
      "train: iter 196  trainloss -973.25879  validloss -1073.25915±0.00000  bestvalidloss -1128.40208  last_update 3\n",
      "train: iter 197  trainloss -894.81190  validloss -1051.62964±0.00000  bestvalidloss -1128.40208  last_update 4\n",
      "train: iter 198  trainloss -1010.09727  validloss -1144.64527±0.00000  bestvalidloss -1144.64527  last_update 0\n",
      "train: iter 199  trainloss -998.43578  validloss -994.53648±0.00000  bestvalidloss -1144.64527  last_update 1\n",
      "train: iter 200  trainloss -983.23066  validloss -1132.01714±0.00000  bestvalidloss -1144.64527  last_update 2\n",
      "train: iter 201  trainloss -890.29821  validloss -789.88927±0.00000  bestvalidloss -1144.64527  last_update 3\n",
      "train: iter 202  trainloss -882.13762  validloss -1096.84670±0.00000  bestvalidloss -1144.64527  last_update 4\n",
      "train: iter 203  trainloss -1031.15228  validloss -1032.04716±0.00000  bestvalidloss -1144.64527  last_update 5\n",
      "train: iter 204  trainloss -1066.30454  validloss -1151.11136±0.00000  bestvalidloss -1151.11136  last_update 0\n",
      "train: iter 205  trainloss -953.32025  validloss -1155.01499±0.00000  bestvalidloss -1155.01499  last_update 0\n",
      "train: iter 206  trainloss -908.44858  validloss -954.15513±0.00000  bestvalidloss -1155.01499  last_update 1\n",
      "train: iter 207  trainloss -1061.04912  validloss -1081.91424±0.00000  bestvalidloss -1155.01499  last_update 2\n",
      "train: iter 208  trainloss -1050.64270  validloss -1183.37924±0.00000  bestvalidloss -1183.37924  last_update 0\n",
      "train: iter 209  trainloss -898.40713  validloss -1171.22755±0.00000  bestvalidloss -1183.37924  last_update 1\n",
      "train: iter 210  trainloss -985.34805  validloss -1158.85783±0.00000  bestvalidloss -1183.37924  last_update 2\n",
      "train: iter 211  trainloss -1056.65853  validloss -1129.82098±0.00000  bestvalidloss -1183.37924  last_update 3\n",
      "train: iter 212  trainloss -976.68846  validloss -1053.58573±0.00000  bestvalidloss -1183.37924  last_update 4\n",
      "train: iter 213  trainloss -913.90293  validloss -856.95811±0.00000  bestvalidloss -1183.37924  last_update 5\n",
      "train: iter 214  trainloss -817.56424  validloss -1116.03362±0.00000  bestvalidloss -1183.37924  last_update 6\n",
      "train: iter 215  trainloss -959.37354  validloss -998.64370±0.00000  bestvalidloss -1183.37924  last_update 7\n",
      "train: iter 216  trainloss -951.14746  validloss -995.76537±0.00000  bestvalidloss -1183.37924  last_update 8\n",
      "train: iter 217  trainloss -1075.93108  validloss -1003.97032±0.00000  bestvalidloss -1183.37924  last_update 9\n",
      "train: iter 218  trainloss -1018.15226  validloss -1136.30124±0.00000  bestvalidloss -1183.37924  last_update 10\n",
      "train: iter 219  trainloss -900.45934  validloss -894.03623±0.00000  bestvalidloss -1183.37924  last_update 11\n",
      "train: iter 220  trainloss -1023.53326  validloss -1089.81930±0.00000  bestvalidloss -1183.37924  last_update 12\n",
      "train: iter 221  trainloss -1018.42446  validloss -1130.79841±0.00000  bestvalidloss -1183.37924  last_update 13\n",
      "train: iter 222  trainloss -804.81517  validloss -640.26138±0.00000  bestvalidloss -1183.37924  last_update 14\n",
      "train: iter 223  trainloss -1063.94641  validloss -1052.89389±0.00000  bestvalidloss -1183.37924  last_update 15\n",
      "train: iter 224  trainloss -1077.61211  validloss -1029.25621±0.00000  bestvalidloss -1183.37924  last_update 16\n",
      "train: iter 225  trainloss -1028.85076  validloss -1202.06586±0.00000  bestvalidloss -1202.06586  last_update 0\n",
      "train: iter 226  trainloss -1130.72180  validloss -1144.86238±0.00000  bestvalidloss -1202.06586  last_update 1\n",
      "train: iter 227  trainloss -1024.91585  validloss -1160.85811±0.00000  bestvalidloss -1202.06586  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1008.00082  validloss -862.85973±0.00000  bestvalidloss -1202.06586  last_update 3\n",
      "train: iter 229  trainloss -1115.08493  validloss -1123.98249±0.00000  bestvalidloss -1202.06586  last_update 4\n",
      "train: iter 230  trainloss -1048.97427  validloss -1076.66908±0.00000  bestvalidloss -1202.06586  last_update 5\n",
      "train: iter 231  trainloss -1034.50217  validloss -1031.86526±0.00000  bestvalidloss -1202.06586  last_update 6\n",
      "train: iter 232  trainloss -1138.27797  validloss -1182.85042±0.00000  bestvalidloss -1202.06586  last_update 7\n",
      "train: iter 233  trainloss -1111.51888  validloss -1243.61586±0.00000  bestvalidloss -1243.61586  last_update 0\n",
      "train: iter 234  trainloss -1049.74680  validloss -1232.50574±0.00000  bestvalidloss -1243.61586  last_update 1\n",
      "train: iter 235  trainloss -945.68738  validloss -822.90735±0.00000  bestvalidloss -1243.61586  last_update 2\n",
      "train: iter 236  trainloss -1086.74283  validloss -1165.43701±0.00000  bestvalidloss -1243.61586  last_update 3\n",
      "train: iter 237  trainloss -985.60125  validloss -1051.31103±0.00000  bestvalidloss -1243.61586  last_update 4\n",
      "train: iter 238  trainloss -1057.66780  validloss -1207.05879±0.00000  bestvalidloss -1243.61586  last_update 5\n",
      "train: iter 239  trainloss -1037.31387  validloss -1118.84268±0.00000  bestvalidloss -1243.61586  last_update 6\n",
      "train: iter 240  trainloss -1077.90441  validloss -1205.24384±0.00000  bestvalidloss -1243.61586  last_update 7\n",
      "train: iter 241  trainloss -918.06846  validloss -1242.12029±0.00000  bestvalidloss -1243.61586  last_update 8\n",
      "train: iter 242  trainloss -1101.17092  validloss -1019.14610±0.00000  bestvalidloss -1243.61586  last_update 9\n",
      "train: iter 243  trainloss -1104.07379  validloss -1229.70910±0.00000  bestvalidloss -1243.61586  last_update 10\n",
      "train: iter 244  trainloss -809.34953  validloss -915.65282±0.00000  bestvalidloss -1243.61586  last_update 11\n",
      "train: iter 245  trainloss -1036.75787  validloss -1080.45672±0.00000  bestvalidloss -1243.61586  last_update 12\n",
      "train: iter 246  trainloss -1041.66661  validloss -1166.78275±0.00000  bestvalidloss -1243.61586  last_update 13\n",
      "train: iter 247  trainloss -1084.55695  validloss -1162.10589±0.00000  bestvalidloss -1243.61586  last_update 14\n",
      "train: iter 248  trainloss -1007.22612  validloss -1024.52744±0.00000  bestvalidloss -1243.61586  last_update 15\n",
      "train: iter 249  trainloss -1136.98964  validloss -1208.90167±0.00000  bestvalidloss -1243.61586  last_update 16\n",
      "train: iter 250  trainloss -1067.54262  validloss -1227.67221±0.00000  bestvalidloss -1243.61586  last_update 17\n",
      "train: iter 251  trainloss -1067.67205  validloss -1124.62476±0.00000  bestvalidloss -1243.61586  last_update 18\n",
      "train: iter 252  trainloss -916.98289  validloss -1166.99483±0.00000  bestvalidloss -1243.61586  last_update 19\n",
      "train: iter 253  trainloss -613.06325  validloss -646.24974±0.00000  bestvalidloss -1243.61586  last_update 20\n",
      "train: iter 254  trainloss -946.57038  validloss -746.51574±0.00000  bestvalidloss -1243.61586  last_update 21\n",
      "train: iter 255  trainloss -1046.73717  validloss -1126.45006±0.00000  bestvalidloss -1243.61586  last_update 22\n",
      "train: iter 256  trainloss -903.29719  validloss -869.52423±0.00000  bestvalidloss -1243.61586  last_update 23\n",
      "train: iter 257  trainloss -1044.30557  validloss -1168.41804±0.00000  bestvalidloss -1243.61586  last_update 24\n",
      "train: iter 258  trainloss -1192.24846  validloss -1236.94934±0.00000  bestvalidloss -1243.61586  last_update 25\n",
      "train: iter 259  trainloss -828.75827  validloss -1279.03972±0.00000  bestvalidloss -1279.03972  last_update 0\n",
      "train: iter 260  trainloss -948.25161  validloss -977.72403±0.00000  bestvalidloss -1279.03972  last_update 1\n",
      "train: iter 261  trainloss -978.00916  validloss -888.06549±0.00000  bestvalidloss -1279.03972  last_update 2\n",
      "train: iter 262  trainloss -1168.68057  validloss -1205.99151±0.00000  bestvalidloss -1279.03972  last_update 3\n",
      "train: iter 263  trainloss -1201.47310  validloss -1281.01643±0.00000  bestvalidloss -1281.01643  last_update 0\n",
      "train: iter 264  trainloss -1080.93630  validloss -1286.55016±0.00000  bestvalidloss -1286.55016  last_update 0\n",
      "train: iter 265  trainloss -988.89680  validloss -615.94895±0.00000  bestvalidloss -1286.55016  last_update 1\n",
      "train: iter 266  trainloss -1181.09549  validloss -1280.91083±0.00000  bestvalidloss -1286.55016  last_update 2\n",
      "train: iter 267  trainloss -1000.94225  validloss -1225.74136±0.00000  bestvalidloss -1286.55016  last_update 3\n",
      "train: iter 268  trainloss -1165.47252  validloss -1243.49797±0.00000  bestvalidloss -1286.55016  last_update 4\n",
      "train: iter 269  trainloss -1161.59820  validloss -1073.12167±0.00000  bestvalidloss -1286.55016  last_update 5\n",
      "train: iter 270  trainloss -1083.25601  validloss -1250.21698±0.00000  bestvalidloss -1286.55016  last_update 6\n",
      "train: iter 271  trainloss -712.61272  validloss -750.97599±0.00000  bestvalidloss -1286.55016  last_update 7\n",
      "train: iter 272  trainloss -537.78802  validloss -832.56590±0.00000  bestvalidloss -1286.55016  last_update 8\n",
      "train: iter 273  trainloss -1041.40469  validloss -1058.50582±0.00000  bestvalidloss -1286.55016  last_update 9\n",
      "train: iter 274  trainloss -981.97544  validloss -1187.92970±0.00000  bestvalidloss -1286.55016  last_update 10\n",
      "train: iter 275  trainloss -1094.36543  validloss -790.96821±0.00000  bestvalidloss -1286.55016  last_update 11\n",
      "train: iter 276  trainloss -1076.57200  validloss -1199.26756±0.00000  bestvalidloss -1286.55016  last_update 12\n",
      "train: iter 277  trainloss -1200.97091  validloss -1255.16622±0.00000  bestvalidloss -1286.55016  last_update 13\n",
      "train: iter 278  trainloss -1115.67743  validloss -1274.99460±0.00000  bestvalidloss -1286.55016  last_update 14\n",
      "train: iter 279  trainloss -1156.60297  validloss -1177.10993±0.00000  bestvalidloss -1286.55016  last_update 15\n",
      "train: iter 280  trainloss -1092.41956  validloss -1290.75932±0.00000  bestvalidloss -1290.75932  last_update 0\n",
      "train: iter 281  trainloss -1183.03960  validloss -1168.24179±0.00000  bestvalidloss -1290.75932  last_update 1\n",
      "train: iter 282  trainloss -1196.72848  validloss -1253.56030±0.00000  bestvalidloss -1290.75932  last_update 2\n",
      "train: iter 283  trainloss -1097.80359  validloss -1225.65411±0.00000  bestvalidloss -1290.75932  last_update 3\n",
      "train: iter 284  trainloss -1161.80742  validloss -1059.96183±0.00000  bestvalidloss -1290.75932  last_update 4\n",
      "train: iter 285  trainloss -1123.63980  validloss -1253.20549±0.00000  bestvalidloss -1290.75932  last_update 5\n",
      "train: iter 286  trainloss -1194.67444  validloss -1263.86471±0.00000  bestvalidloss -1290.75932  last_update 6\n",
      "train: iter 287  trainloss -1041.86255  validloss -1161.53298±0.00000  bestvalidloss -1290.75932  last_update 7\n",
      "train: iter 288  trainloss -1196.66087  validloss -1164.66098±0.00000  bestvalidloss -1290.75932  last_update 8\n",
      "train: iter 289  trainloss -1180.91328  validloss -1250.41771±0.00000  bestvalidloss -1290.75932  last_update 9\n",
      "train: iter 290  trainloss -1057.56054  validloss -1206.29216±0.00000  bestvalidloss -1290.75932  last_update 10\n",
      "train: iter 291  trainloss -1186.49888  validloss -1216.57015±0.00000  bestvalidloss -1290.75932  last_update 11\n",
      "train: iter 292  trainloss -1173.85885  validloss -1298.25354±0.00000  bestvalidloss -1298.25354  last_update 0\n",
      "train: iter 293  trainloss -1199.59849  validloss -1244.73843±0.00000  bestvalidloss -1298.25354  last_update 1\n",
      "train: iter 294  trainloss -1138.06072  validloss -1279.06023±0.00000  bestvalidloss -1298.25354  last_update 2\n",
      "train: iter 295  trainloss -1083.29767  validloss -1307.98776±0.00000  bestvalidloss -1307.98776  last_update 0\n",
      "train: iter 296  trainloss -1167.94023  validloss -1159.48397±0.00000  bestvalidloss -1307.98776  last_update 1\n",
      "train: iter 297  trainloss -1100.40054  validloss -1186.08206±0.00000  bestvalidloss -1307.98776  last_update 2\n",
      "train: iter 298  trainloss -1184.45788  validloss -1205.88459±0.00000  bestvalidloss -1307.98776  last_update 3\n",
      "train: iter 299  trainloss -1185.32910  validloss -1283.22727±0.00000  bestvalidloss -1307.98776  last_update 4\n",
      "train: iter 300  trainloss -1137.66519  validloss -1148.65804±0.00000  bestvalidloss -1307.98776  last_update 5\n",
      "train: iter 301  trainloss -1096.51849  validloss -1076.99722±0.00000  bestvalidloss -1307.98776  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 302  trainloss -1215.17852  validloss -1271.84320±0.00000  bestvalidloss -1307.98776  last_update 7\n",
      "train: iter 303  trainloss -1030.29071  validloss -1301.69517±0.00000  bestvalidloss -1307.98776  last_update 8\n",
      "train: iter 304  trainloss -1220.65766  validloss -1278.61556±0.00000  bestvalidloss -1307.98776  last_update 9\n",
      "train: iter 305  trainloss -1185.52255  validloss -1332.94366±0.00000  bestvalidloss -1332.94366  last_update 0\n",
      "train: iter 306  trainloss -1039.76170  validloss -1252.97495±0.00000  bestvalidloss -1332.94366  last_update 1\n",
      "train: iter 307  trainloss -1185.48412  validloss -1307.26214±0.00000  bestvalidloss -1332.94366  last_update 2\n",
      "train: iter 308  trainloss -1201.03962  validloss -1343.34011±0.00000  bestvalidloss -1343.34011  last_update 0\n",
      "train: iter 309  trainloss -1180.32177  validloss -1251.95608±0.00000  bestvalidloss -1343.34011  last_update 1\n",
      "train: iter 310  trainloss -1092.28162  validloss -1253.33223±0.00000  bestvalidloss -1343.34011  last_update 2\n",
      "train: iter 311  trainloss -1171.14560  validloss -1018.23452±0.00000  bestvalidloss -1343.34011  last_update 3\n",
      "train: iter 312  trainloss -1220.76259  validloss -1312.38147±0.00000  bestvalidloss -1343.34011  last_update 4\n",
      "train: iter 313  trainloss -954.14428  validloss -968.60755±0.00000  bestvalidloss -1343.34011  last_update 5\n",
      "train: iter 314  trainloss -1175.49986  validloss -1080.59920±0.00000  bestvalidloss -1343.34011  last_update 6\n",
      "train: iter 315  trainloss -1224.22385  validloss -1321.33941±0.00000  bestvalidloss -1343.34011  last_update 7\n",
      "train: iter 316  trainloss -1125.31028  validloss -1339.95956±0.00000  bestvalidloss -1343.34011  last_update 8\n",
      "train: iter 317  trainloss -984.06430  validloss -1066.90667±0.00000  bestvalidloss -1343.34011  last_update 9\n",
      "train: iter 318  trainloss -1135.21972  validloss -1183.74736±0.00000  bestvalidloss -1343.34011  last_update 10\n",
      "train: iter 319  trainloss -1200.55887  validloss -1265.25995±0.00000  bestvalidloss -1343.34011  last_update 11\n",
      "train: iter 320  trainloss -1071.11683  validloss -1210.90532±0.00000  bestvalidloss -1343.34011  last_update 12\n",
      "train: iter 321  trainloss -1198.54611  validloss -1260.44973±0.00000  bestvalidloss -1343.34011  last_update 13\n",
      "train: iter 322  trainloss -1198.24248  validloss -1312.19484±0.00000  bestvalidloss -1343.34011  last_update 14\n",
      "train: iter 323  trainloss -1190.58940  validloss -1270.67451±0.00000  bestvalidloss -1343.34011  last_update 15\n",
      "train: iter 324  trainloss -1208.56182  validloss -1261.93484±0.00000  bestvalidloss -1343.34011  last_update 16\n",
      "train: iter 325  trainloss -1266.39815  validloss -1333.51452±0.00000  bestvalidloss -1343.34011  last_update 17\n",
      "train: iter 326  trainloss -1174.64604  validloss -1320.16945±0.00000  bestvalidloss -1343.34011  last_update 18\n",
      "train: iter 327  trainloss -1236.73166  validloss -1250.94314±0.00000  bestvalidloss -1343.34011  last_update 19\n",
      "train: iter 328  trainloss -1162.79233  validloss -1290.51571±0.00000  bestvalidloss -1343.34011  last_update 20\n",
      "train: iter 329  trainloss -1121.42905  validloss -1096.87482±0.00000  bestvalidloss -1343.34011  last_update 21\n",
      "train: iter 330  trainloss -1168.22079  validloss -1285.67025±0.00000  bestvalidloss -1343.34011  last_update 22\n",
      "train: iter 331  trainloss -1171.49667  validloss -1328.16709±0.00000  bestvalidloss -1343.34011  last_update 23\n",
      "train: iter 332  trainloss -1261.99975  validloss -1116.71190±0.00000  bestvalidloss -1343.34011  last_update 24\n",
      "train: iter 333  trainloss -1232.38421  validloss -1369.92939±0.00000  bestvalidloss -1369.92939  last_update 0\n",
      "train: iter 334  trainloss -1174.87793  validloss -1362.38977±0.00000  bestvalidloss -1369.92939  last_update 1\n",
      "train: iter 335  trainloss -1154.44982  validloss -1325.50778±0.00000  bestvalidloss -1369.92939  last_update 2\n",
      "train: iter 336  trainloss -1218.38182  validloss -1274.60545±0.00000  bestvalidloss -1369.92939  last_update 3\n",
      "train: iter 337  trainloss -1310.04437  validloss -1390.17772±0.00000  bestvalidloss -1390.17772  last_update 0\n",
      "train: iter 338  trainloss -1169.82458  validloss -1381.02157±0.00000  bestvalidloss -1390.17772  last_update 1\n",
      "train: iter 339  trainloss -1251.25084  validloss -1330.55434±0.00000  bestvalidloss -1390.17772  last_update 2\n",
      "train: iter 340  trainloss -1275.09728  validloss -1305.51795±0.00000  bestvalidloss -1390.17772  last_update 3\n",
      "train: iter 341  trainloss -1115.07884  validloss -1390.08998±0.00000  bestvalidloss -1390.17772  last_update 4\n",
      "train: iter 342  trainloss -1196.97894  validloss -1238.35040±0.00000  bestvalidloss -1390.17772  last_update 5\n",
      "train: iter 343  trainloss -1203.65342  validloss -1337.02027±0.00000  bestvalidloss -1390.17772  last_update 6\n",
      "train: iter 344  trainloss -1225.71450  validloss -1325.30718±0.00000  bestvalidloss -1390.17772  last_update 7\n",
      "train: iter 345  trainloss -1081.85236  validloss -1325.55972±0.00000  bestvalidloss -1390.17772  last_update 8\n",
      "train: iter 346  trainloss -1094.72281  validloss -1138.88499±0.00000  bestvalidloss -1390.17772  last_update 9\n",
      "train: iter 347  trainloss -1107.10017  validloss -1178.48822±0.00000  bestvalidloss -1390.17772  last_update 10\n",
      "train: iter 348  trainloss -1284.31873  validloss -1285.38841±0.00000  bestvalidloss -1390.17772  last_update 11\n",
      "train: iter 349  trainloss -1237.08125  validloss -1356.13207±0.00000  bestvalidloss -1390.17772  last_update 12\n",
      "train: iter 350  trainloss -1305.53674  validloss -1387.90917±0.00000  bestvalidloss -1390.17772  last_update 13\n",
      "train: iter 351  trainloss -1188.24139  validloss -1420.34845±0.00000  bestvalidloss -1420.34845  last_update 0\n",
      "train: iter 352  trainloss -1223.46491  validloss -1230.63906±0.00000  bestvalidloss -1420.34845  last_update 1\n",
      "train: iter 353  trainloss -1281.54925  validloss -1290.78088±0.00000  bestvalidloss -1420.34845  last_update 2\n",
      "train: iter 354  trainloss -1247.84078  validloss -1280.77122±0.00000  bestvalidloss -1420.34845  last_update 3\n",
      "train: iter 355  trainloss -1158.62242  validloss -1144.78777±0.00000  bestvalidloss -1420.34845  last_update 4\n",
      "train: iter 356  trainloss -1196.11624  validloss -1262.17851±0.00000  bestvalidloss -1420.34845  last_update 5\n",
      "train: iter 357  trainloss -972.28388  validloss -1393.89887±0.00000  bestvalidloss -1420.34845  last_update 6\n",
      "train: iter 358  trainloss -866.04984  validloss -596.30287±0.00000  bestvalidloss -1420.34845  last_update 7\n",
      "train: iter 359  trainloss -1062.74247  validloss -1086.40384±0.00000  bestvalidloss -1420.34845  last_update 8\n",
      "train: iter 360  trainloss -1146.39874  validloss -1233.16956±0.00000  bestvalidloss -1420.34845  last_update 9\n",
      "train: iter 361  trainloss -1170.37481  validloss -1283.00184±0.00000  bestvalidloss -1420.34845  last_update 10\n",
      "train: iter 362  trainloss -1209.95609  validloss -1286.36940±0.00000  bestvalidloss -1420.34845  last_update 11\n",
      "train: iter 363  trainloss -1290.41937  validloss -1323.88329±0.00000  bestvalidloss -1420.34845  last_update 12\n",
      "train: iter 364  trainloss -1269.30361  validloss -1394.20101±0.00000  bestvalidloss -1420.34845  last_update 13\n",
      "train: iter 365  trainloss -1238.12131  validloss -1319.26036±0.00000  bestvalidloss -1420.34845  last_update 14\n",
      "train: iter 366  trainloss -1220.79167  validloss -1316.38350±0.00000  bestvalidloss -1420.34845  last_update 15\n",
      "train: iter 367  trainloss -1284.26164  validloss -1376.34600±0.00000  bestvalidloss -1420.34845  last_update 16\n",
      "train: iter 368  trainloss -1184.21605  validloss -1353.25795±0.00000  bestvalidloss -1420.34845  last_update 17\n",
      "train: iter 369  trainloss -1265.91946  validloss -1364.34763±0.00000  bestvalidloss -1420.34845  last_update 18\n",
      "train: iter 370  trainloss -1302.92872  validloss -1406.71777±0.00000  bestvalidloss -1420.34845  last_update 19\n",
      "train: iter 371  trainloss -1233.71476  validloss -1341.79261±0.00000  bestvalidloss -1420.34845  last_update 20\n",
      "train: iter 372  trainloss -1244.72500  validloss -1417.84636±0.00000  bestvalidloss -1420.34845  last_update 21\n",
      "train: iter 373  trainloss -1300.09499  validloss -1307.86770±0.00000  bestvalidloss -1420.34845  last_update 22\n",
      "train: iter 374  trainloss -1219.52144  validloss -1425.25679±0.00000  bestvalidloss -1425.25679  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 375  trainloss -1309.67616  validloss -1352.72422±0.00000  bestvalidloss -1425.25679  last_update 1\n",
      "train: iter 376  trainloss -1167.35248  validloss -1429.07184±0.00000  bestvalidloss -1429.07184  last_update 0\n",
      "train: iter 377  trainloss -1056.73863  validloss -897.30530±0.00000  bestvalidloss -1429.07184  last_update 1\n",
      "train: iter 378  trainloss -952.32247  validloss -1087.83738±0.00000  bestvalidloss -1429.07184  last_update 2\n",
      "train: iter 379  trainloss -1150.32927  validloss -1270.36426±0.00000  bestvalidloss -1429.07184  last_update 3\n",
      "train: iter 380  trainloss -1149.15733  validloss -1150.01053±0.00000  bestvalidloss -1429.07184  last_update 4\n",
      "train: iter 381  trainloss -1274.24087  validloss -1291.20472±0.00000  bestvalidloss -1429.07184  last_update 5\n",
      "train: iter 382  trainloss -1321.47423  validloss -1427.76474±0.00000  bestvalidloss -1429.07184  last_update 6\n",
      "train: iter 383  trainloss -1156.01778  validloss -1151.60936±0.00000  bestvalidloss -1429.07184  last_update 7\n",
      "train: iter 384  trainloss -1192.84679  validloss -1314.29888±0.00000  bestvalidloss -1429.07184  last_update 8\n",
      "train: iter 385  trainloss -1332.79424  validloss -1392.55382±0.00000  bestvalidloss -1429.07184  last_update 9\n",
      "train: iter 386  trainloss -1319.62906  validloss -1411.60721±0.00000  bestvalidloss -1429.07184  last_update 10\n",
      "train: iter 387  trainloss -1309.94197  validloss -1385.27193±0.00000  bestvalidloss -1429.07184  last_update 11\n",
      "train: iter 388  trainloss -1347.81291  validloss -1385.40988±0.00000  bestvalidloss -1429.07184  last_update 12\n",
      "train: iter 389  trainloss -1304.73408  validloss -1409.43617±0.00000  bestvalidloss -1429.07184  last_update 13\n",
      "train: iter 390  trainloss -1080.72373  validloss -1388.18118±0.00000  bestvalidloss -1429.07184  last_update 14\n",
      "train: iter 391  trainloss -1209.41053  validloss -1255.32461±0.00000  bestvalidloss -1429.07184  last_update 15\n",
      "train: iter 392  trainloss -1305.06486  validloss -1289.27223±0.00000  bestvalidloss -1429.07184  last_update 16\n",
      "train: iter 393  trainloss -1317.43570  validloss -1422.58336±0.00000  bestvalidloss -1429.07184  last_update 17\n",
      "train: iter 394  trainloss -1324.38655  validloss -1429.68165±0.00000  bestvalidloss -1429.68165  last_update 0\n",
      "train: iter 395  trainloss -1241.17753  validloss -1123.00880±0.00000  bestvalidloss -1429.68165  last_update 1\n",
      "train: iter 396  trainloss -1302.89819  validloss -1415.15599±0.00000  bestvalidloss -1429.68165  last_update 2\n",
      "train: iter 397  trainloss -1358.89088  validloss -1399.36339±0.00000  bestvalidloss -1429.68165  last_update 3\n",
      "train: iter 398  trainloss -1346.33820  validloss -1458.94446±0.00000  bestvalidloss -1458.94446  last_update 0\n",
      "train: iter 399  trainloss -1248.68493  validloss -1295.86185±0.00000  bestvalidloss -1458.94446  last_update 1\n",
      "train: iter 400  trainloss -1294.74208  validloss -1415.60760±0.00000  bestvalidloss -1458.94446  last_update 2\n",
      "train: iter 401  trainloss -1310.16088  validloss -1329.33877±0.00000  bestvalidloss -1458.94446  last_update 3\n",
      "train: iter 402  trainloss -1231.47924  validloss -1433.30340±0.00000  bestvalidloss -1458.94446  last_update 4\n",
      "train: iter 403  trainloss -1277.65695  validloss -1332.08921±0.00000  bestvalidloss -1458.94446  last_update 5\n",
      "train: iter 404  trainloss -1272.82886  validloss -1346.85572±0.00000  bestvalidloss -1458.94446  last_update 6\n",
      "train: iter 405  trainloss -1251.78865  validloss -1344.18157±0.00000  bestvalidloss -1458.94446  last_update 7\n",
      "train: iter 406  trainloss -1329.08766  validloss -1368.85858±0.00000  bestvalidloss -1458.94446  last_update 8\n",
      "train: iter 407  trainloss -1380.68727  validloss -1415.03904±0.00000  bestvalidloss -1458.94446  last_update 9\n",
      "train: iter 408  trainloss -1190.03319  validloss -1478.97294±0.00000  bestvalidloss -1478.97294  last_update 0\n",
      "train: iter 409  trainloss -1223.60666  validloss -1073.52004±0.00000  bestvalidloss -1478.97294  last_update 1\n",
      "train: iter 410  trainloss -1328.10060  validloss -1443.60896±0.00000  bestvalidloss -1478.97294  last_update 2\n",
      "train: iter 411  trainloss -1230.00517  validloss -1377.94067±0.00000  bestvalidloss -1478.97294  last_update 3\n",
      "train: iter 412  trainloss -1367.59513  validloss -1395.03990±0.00000  bestvalidloss -1478.97294  last_update 4\n",
      "train: iter 413  trainloss -1271.18804  validloss -1423.69617±0.00000  bestvalidloss -1478.97294  last_update 5\n",
      "train: iter 414  trainloss -1256.96383  validloss -1359.70597±0.00000  bestvalidloss -1478.97294  last_update 6\n",
      "train: iter 415  trainloss -1343.90031  validloss -1429.47916±0.00000  bestvalidloss -1478.97294  last_update 7\n",
      "train: iter 416  trainloss -1351.71357  validloss -1348.68744±0.00000  bestvalidloss -1478.97294  last_update 8\n",
      "train: iter 417  trainloss -1308.95253  validloss -1452.77286±0.00000  bestvalidloss -1478.97294  last_update 9\n",
      "train: iter 418  trainloss -817.09830  validloss -731.79523±0.00000  bestvalidloss -1478.97294  last_update 10\n",
      "train: iter 419  trainloss -1191.36229  validloss -1314.86241±0.00000  bestvalidloss -1478.97294  last_update 11\n",
      "train: iter 420  trainloss -1321.65210  validloss -1356.40941±0.00000  bestvalidloss -1478.97294  last_update 12\n",
      "train: iter 421  trainloss -1357.44362  validloss -1421.34206±0.00000  bestvalidloss -1478.97294  last_update 13\n",
      "train: iter 422  trainloss -964.03559  validloss -1409.05137±0.00000  bestvalidloss -1478.97294  last_update 14\n",
      "train: iter 423  trainloss -858.27293  validloss -426.63691±0.00000  bestvalidloss -1478.97294  last_update 15\n",
      "train: iter 424  trainloss -1168.96906  validloss -1168.04510±0.00000  bestvalidloss -1478.97294  last_update 16\n",
      "train: iter 425  trainloss -1203.06697  validloss -1300.77975±0.00000  bestvalidloss -1478.97294  last_update 17\n",
      "train: iter 426  trainloss -1297.06467  validloss -1315.77668±0.00000  bestvalidloss -1478.97294  last_update 18\n",
      "train: iter 427  trainloss -1201.61534  validloss -1374.37875±0.00000  bestvalidloss -1478.97294  last_update 19\n",
      "train: iter 428  trainloss -1354.24871  validloss -1312.93156±0.00000  bestvalidloss -1478.97294  last_update 20\n",
      "train: iter 429  trainloss -1285.24560  validloss -1448.51342±0.00000  bestvalidloss -1478.97294  last_update 21\n",
      "train: iter 430  trainloss -1263.91849  validloss -1367.79339±0.00000  bestvalidloss -1478.97294  last_update 22\n",
      "train: iter 431  trainloss -1342.13962  validloss -1417.77257±0.00000  bestvalidloss -1478.97294  last_update 23\n",
      "train: iter 432  trainloss -1316.35069  validloss -1397.32852±0.00000  bestvalidloss -1478.97294  last_update 24\n",
      "train: iter 433  trainloss -1328.11086  validloss -1334.67721±0.00000  bestvalidloss -1478.97294  last_update 25\n",
      "train: iter 434  trainloss -1169.58672  validloss -1438.95559±0.00000  bestvalidloss -1478.97294  last_update 26\n",
      "train: iter 435  trainloss -1341.19376  validloss -1364.04294±0.00000  bestvalidloss -1478.97294  last_update 27\n",
      "train: iter 436  trainloss -1386.57857  validloss -1463.65857±0.00000  bestvalidloss -1478.97294  last_update 28\n",
      "train: iter 437  trainloss -1355.01964  validloss -1480.95705±0.00000  bestvalidloss -1480.95705  last_update 0\n",
      "train: iter 438  trainloss -1336.20394  validloss -1423.17613±0.00000  bestvalidloss -1480.95705  last_update 1\n",
      "train: iter 439  trainloss -1250.21632  validloss -1326.04654±0.00000  bestvalidloss -1480.95705  last_update 2\n",
      "train: iter 440  trainloss -1365.93076  validloss -1369.18095±0.00000  bestvalidloss -1480.95705  last_update 3\n",
      "train: iter 441  trainloss -1329.10452  validloss -1353.12616±0.00000  bestvalidloss -1480.95705  last_update 4\n",
      "train: iter 442  trainloss -1345.30189  validloss -1360.76660±0.00000  bestvalidloss -1480.95705  last_update 5\n",
      "train: iter 443  trainloss -1282.90546  validloss -1451.44065±0.00000  bestvalidloss -1480.95705  last_update 6\n",
      "train: iter 444  trainloss -1243.84478  validloss -1357.38908±0.00000  bestvalidloss -1480.95705  last_update 7\n",
      "train: iter 445  trainloss -1317.78243  validloss -1365.99734±0.00000  bestvalidloss -1480.95705  last_update 8\n",
      "train: iter 446  trainloss -1306.18546  validloss -1276.39062±0.00000  bestvalidloss -1480.95705  last_update 9\n",
      "train: iter 447  trainloss -1386.16690  validloss -1463.92244±0.00000  bestvalidloss -1480.95705  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 448  trainloss -1282.80399  validloss -1503.10193±0.00000  bestvalidloss -1503.10193  last_update 0\n",
      "train: iter 449  trainloss -1348.24128  validloss -1378.22310±0.00000  bestvalidloss -1503.10193  last_update 1\n",
      "train: iter 450  trainloss -1364.62637  validloss -1321.70271±0.00000  bestvalidloss -1503.10193  last_update 2\n",
      "train: iter 451  trainloss -1265.40135  validloss -1457.79438±0.00000  bestvalidloss -1503.10193  last_update 3\n",
      "train: iter 452  trainloss -1325.54236  validloss -1425.04695±0.00000  bestvalidloss -1503.10193  last_update 4\n",
      "train: iter 453  trainloss -1322.53686  validloss -1404.46719±0.00000  bestvalidloss -1503.10193  last_update 5\n",
      "train: iter 454  trainloss -1391.64263  validloss -1397.26319±0.00000  bestvalidloss -1503.10193  last_update 6\n",
      "train: iter 455  trainloss -1405.11169  validloss -1452.34982±0.00000  bestvalidloss -1503.10193  last_update 7\n",
      "train: iter 456  trainloss -1332.04660  validloss -1451.53696±0.00000  bestvalidloss -1503.10193  last_update 8\n",
      "train: iter 457  trainloss -1359.26097  validloss -1457.30278±0.00000  bestvalidloss -1503.10193  last_update 9\n",
      "train: iter 458  trainloss -1351.36843  validloss -1398.27149±0.00000  bestvalidloss -1503.10193  last_update 10\n",
      "train: iter 459  trainloss -1424.12083  validloss -1475.71880±0.00000  bestvalidloss -1503.10193  last_update 11\n",
      "train: iter 460  trainloss -1237.99834  validloss -1496.69615±0.00000  bestvalidloss -1503.10193  last_update 12\n",
      "train: iter 461  trainloss -1314.39666  validloss -1451.93426±0.00000  bestvalidloss -1503.10193  last_update 13\n",
      "train: iter 462  trainloss -1315.01156  validloss -1309.12894±0.00000  bestvalidloss -1503.10193  last_update 14\n",
      "train: iter 463  trainloss -1387.97868  validloss -1465.36537±0.00000  bestvalidloss -1503.10193  last_update 15\n",
      "train: iter 464  trainloss -1231.11640  validloss -1369.01130±0.00000  bestvalidloss -1503.10193  last_update 16\n",
      "train: iter 465  trainloss -1314.91128  validloss -1376.43889±0.00000  bestvalidloss -1503.10193  last_update 17\n",
      "train: iter 466  trainloss -1315.80132  validloss -1411.32113±0.00000  bestvalidloss -1503.10193  last_update 18\n",
      "train: iter 467  trainloss -1420.52610  validloss -1415.20324±0.00000  bestvalidloss -1503.10193  last_update 19\n",
      "train: iter 468  trainloss -1273.36399  validloss -1137.16124±0.00000  bestvalidloss -1503.10193  last_update 20\n",
      "train: iter 469  trainloss -1423.99632  validloss -1472.68988±0.00000  bestvalidloss -1503.10193  last_update 21\n",
      "train: iter 470  trainloss -1431.50053  validloss -1534.20666±0.00000  bestvalidloss -1534.20666  last_update 0\n",
      "train: iter 471  trainloss -1260.63752  validloss -1460.70793±0.00000  bestvalidloss -1534.20666  last_update 1\n",
      "train: iter 472  trainloss -1348.28629  validloss -1438.58090±0.00000  bestvalidloss -1534.20666  last_update 2\n",
      "train: iter 473  trainloss -1319.79983  validloss -1426.45491±0.00000  bestvalidloss -1534.20666  last_update 3\n",
      "train: iter 474  trainloss -1406.42087  validloss -1433.86462±0.00000  bestvalidloss -1534.20666  last_update 4\n",
      "train: iter 475  trainloss -1321.83807  validloss -1454.84337±0.00000  bestvalidloss -1534.20666  last_update 5\n",
      "train: iter 476  trainloss -1417.98619  validloss -1480.08422±0.00000  bestvalidloss -1534.20666  last_update 6\n",
      "train: iter 477  trainloss -1303.65231  validloss -1471.58687±0.00000  bestvalidloss -1534.20666  last_update 7\n",
      "train: iter 478  trainloss -1330.40565  validloss -1284.22638±0.00000  bestvalidloss -1534.20666  last_update 8\n",
      "train: iter 479  trainloss -1409.74552  validloss -1453.66018±0.00000  bestvalidloss -1534.20666  last_update 9\n",
      "train: iter 480  trainloss -1252.28019  validloss -1475.97686±0.00000  bestvalidloss -1534.20666  last_update 10\n",
      "train: iter 481  trainloss -1269.17344  validloss -1432.95132±0.00000  bestvalidloss -1534.20666  last_update 11\n",
      "train: iter 482  trainloss -1318.97621  validloss -1280.99693±0.00000  bestvalidloss -1534.20666  last_update 12\n",
      "train: iter 483  trainloss -1399.29849  validloss -1419.09556±0.00000  bestvalidloss -1534.20666  last_update 13\n",
      "train: iter 484  trainloss -1333.25699  validloss -1481.90742±0.00000  bestvalidloss -1534.20666  last_update 14\n",
      "train: iter 485  trainloss -1386.18385  validloss -1135.31729±0.00000  bestvalidloss -1534.20666  last_update 15\n",
      "train: iter 486  trainloss -1324.97976  validloss -1462.53480±0.00000  bestvalidloss -1534.20666  last_update 16\n",
      "train: iter 487  trainloss -1428.43158  validloss -1395.15715±0.00000  bestvalidloss -1534.20666  last_update 17\n",
      "train: iter 488  trainloss -1397.16604  validloss -1419.71618±0.00000  bestvalidloss -1534.20666  last_update 18\n",
      "train: iter 489  trainloss -1342.60536  validloss -1409.82835±0.00000  bestvalidloss -1534.20666  last_update 19\n",
      "train: iter 490  trainloss -1408.41826  validloss -1466.61885±0.00000  bestvalidloss -1534.20666  last_update 20\n",
      "train: iter 491  trainloss -1444.47898  validloss -1504.99577±0.00000  bestvalidloss -1534.20666  last_update 21\n",
      "train: iter 492  trainloss -1442.69370  validloss -1501.08766±0.00000  bestvalidloss -1534.20666  last_update 22\n",
      "train: iter 493  trainloss -1392.89454  validloss -1493.79121±0.00000  bestvalidloss -1534.20666  last_update 23\n",
      "train: iter 494  trainloss -1431.66257  validloss -1519.71861±0.00000  bestvalidloss -1534.20666  last_update 24\n",
      "train: iter 495  trainloss -1259.60864  validloss -1493.98971±0.00000  bestvalidloss -1534.20666  last_update 25\n",
      "train: iter 496  trainloss -1352.25436  validloss -1427.91632±0.00000  bestvalidloss -1534.20666  last_update 26\n",
      "train: iter 497  trainloss -1338.70615  validloss -1315.31819±0.00000  bestvalidloss -1534.20666  last_update 27\n",
      "train: iter 498  trainloss -1403.87908  validloss -1420.97722±0.00000  bestvalidloss -1534.20666  last_update 28\n",
      "train: iter 499  trainloss -1438.86769  validloss -1468.43298±0.00000  bestvalidloss -1534.20666  last_update 29\n",
      "train: iter 500  trainloss -1430.60709  validloss -1536.45503±0.00000  bestvalidloss -1536.45503  last_update 0\n",
      "train: iter 501  trainloss -1351.03201  validloss -1422.30658±0.00000  bestvalidloss -1536.45503  last_update 1\n",
      "train: iter 502  trainloss -1365.72301  validloss -1445.79575±0.00000  bestvalidloss -1536.45503  last_update 2\n",
      "train: iter 503  trainloss -1459.78258  validloss -1477.35442±0.00000  bestvalidloss -1536.45503  last_update 3\n",
      "train: iter 504  trainloss -1215.75252  validloss -1446.42967±0.00000  bestvalidloss -1536.45503  last_update 4\n",
      "train: iter 505  trainloss -1301.85754  validloss -1442.14350±0.00000  bestvalidloss -1536.45503  last_update 5\n",
      "train: iter 506  trainloss -1402.60701  validloss -1413.21722±0.00000  bestvalidloss -1536.45503  last_update 6\n",
      "train: iter 507  trainloss -1428.32454  validloss -1463.71391±0.00000  bestvalidloss -1536.45503  last_update 7\n",
      "train: iter 508  trainloss -1370.87253  validloss -1510.45766±0.00000  bestvalidloss -1536.45503  last_update 8\n",
      "train: iter 509  trainloss -1433.59579  validloss -1489.78154±0.00000  bestvalidloss -1536.45503  last_update 9\n",
      "train: iter 510  trainloss -1346.35722  validloss -1521.54480±0.00000  bestvalidloss -1536.45503  last_update 10\n",
      "train: iter 511  trainloss -1391.61550  validloss -1331.37842±0.00000  bestvalidloss -1536.45503  last_update 11\n",
      "train: iter 512  trainloss -1426.28467  validloss -1538.09392±0.00000  bestvalidloss -1538.09392  last_update 0\n",
      "train: iter 513  trainloss -1312.04772  validloss -1450.28250±0.00000  bestvalidloss -1538.09392  last_update 1\n",
      "train: iter 514  trainloss -1440.02129  validloss -1472.03788±0.00000  bestvalidloss -1538.09392  last_update 2\n",
      "train: iter 515  trainloss -1331.31512  validloss -1540.27160±0.00000  bestvalidloss -1540.27160  last_update 0\n",
      "train: iter 516  trainloss -1219.85843  validloss -1336.95315±0.00000  bestvalidloss -1540.27160  last_update 1\n",
      "train: iter 517  trainloss -1402.31598  validloss -1484.36570±0.00000  bestvalidloss -1540.27160  last_update 2\n",
      "train: iter 518  trainloss -1427.99886  validloss -1497.39650±0.00000  bestvalidloss -1540.27160  last_update 3\n",
      "train: iter 519  trainloss -1243.11501  validloss -1316.58647±0.00000  bestvalidloss -1540.27160  last_update 4\n",
      "train: iter 520  trainloss -1430.86147  validloss -1441.89551±0.00000  bestvalidloss -1540.27160  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 521  trainloss -1364.94045  validloss -1515.65520±0.00000  bestvalidloss -1540.27160  last_update 6\n",
      "train: iter 522  trainloss -1367.32768  validloss -811.60732±0.00000  bestvalidloss -1540.27160  last_update 7\n",
      "train: iter 523  trainloss -1449.10947  validloss -1470.63532±0.00000  bestvalidloss -1540.27160  last_update 8\n",
      "train: iter 524  trainloss -1386.44403  validloss -1468.12665±0.00000  bestvalidloss -1540.27160  last_update 9\n",
      "train: iter 525  trainloss -1348.31945  validloss -1344.46869±0.00000  bestvalidloss -1540.27160  last_update 10\n",
      "train: iter 526  trainloss -1465.45162  validloss -1508.89241±0.00000  bestvalidloss -1540.27160  last_update 11\n",
      "train: iter 527  trainloss -1442.23978  validloss -1562.14303±0.00000  bestvalidloss -1562.14303  last_update 0\n",
      "train: iter 528  trainloss -1333.52825  validloss -1462.12671±0.00000  bestvalidloss -1562.14303  last_update 1\n",
      "train: iter 529  trainloss -1435.21326  validloss -1525.82425±0.00000  bestvalidloss -1562.14303  last_update 2\n",
      "train: iter 530  trainloss -1419.09365  validloss -1497.18091±0.00000  bestvalidloss -1562.14303  last_update 3\n",
      "train: iter 531  trainloss -1377.66760  validloss -1314.98390±0.00000  bestvalidloss -1562.14303  last_update 4\n",
      "train: iter 532  trainloss -1323.23482  validloss -1432.99782±0.00000  bestvalidloss -1562.14303  last_update 5\n",
      "train: iter 533  trainloss -1370.04789  validloss -1271.48215±0.00000  bestvalidloss -1562.14303  last_update 6\n",
      "train: iter 534  trainloss -1304.19393  validloss -1442.88078±0.00000  bestvalidloss -1562.14303  last_update 7\n",
      "train: iter 535  trainloss -1405.33259  validloss -1395.45680±0.00000  bestvalidloss -1562.14303  last_update 8\n",
      "train: iter 536  trainloss -1138.46356  validloss -1277.89745±0.00000  bestvalidloss -1562.14303  last_update 9\n",
      "train: iter 537  trainloss -1410.56489  validloss -1470.23321±0.00000  bestvalidloss -1562.14303  last_update 10\n",
      "train: iter 538  trainloss -1468.53496  validloss -1505.84257±0.00000  bestvalidloss -1562.14303  last_update 11\n",
      "train: iter 539  trainloss -1445.31015  validloss -1550.49072±0.00000  bestvalidloss -1562.14303  last_update 12\n",
      "train: iter 540  trainloss -1460.66149  validloss -1492.54785±0.00000  bestvalidloss -1562.14303  last_update 13\n",
      "train: iter 541  trainloss -1020.50145  validloss -1575.68353±0.00000  bestvalidloss -1575.68353  last_update 0\n",
      "train: iter 542  trainloss -1053.66179  validloss -408.04887±0.00000  bestvalidloss -1575.68353  last_update 1\n",
      "train: iter 543  trainloss -1378.37500  validloss -1099.97694±0.00000  bestvalidloss -1575.68353  last_update 2\n",
      "train: iter 544  trainloss -1469.21918  validloss -1486.99139±0.00000  bestvalidloss -1575.68353  last_update 3\n",
      "train: iter 545  trainloss -1436.88821  validloss -1532.55689±0.00000  bestvalidloss -1575.68353  last_update 4\n",
      "train: iter 546  trainloss -1408.75522  validloss -1518.65386±0.00000  bestvalidloss -1575.68353  last_update 5\n",
      "train: iter 547  trainloss -1448.32264  validloss -1400.92511±0.00000  bestvalidloss -1575.68353  last_update 6\n",
      "train: iter 548  trainloss -1293.38905  validloss -1553.28542±0.00000  bestvalidloss -1575.68353  last_update 7\n",
      "train: iter 549  trainloss -1423.15685  validloss -1473.97062±0.00000  bestvalidloss -1575.68353  last_update 8\n",
      "train: iter 550  trainloss -1388.61717  validloss -1454.49321±0.00000  bestvalidloss -1575.68353  last_update 9\n",
      "train: iter 551  trainloss -1445.63660  validloss -1507.35819±0.00000  bestvalidloss -1575.68353  last_update 10\n",
      "train: iter 552  trainloss -1290.14450  validloss -1444.78253±0.00000  bestvalidloss -1575.68353  last_update 11\n",
      "train: iter 553  trainloss -1451.74828  validloss -1279.83121±0.00000  bestvalidloss -1575.68353  last_update 12\n",
      "train: iter 554  trainloss -1472.82910  validloss -1551.25534±0.00000  bestvalidloss -1575.68353  last_update 13\n",
      "train: iter 555  trainloss -1468.81080  validloss -1529.08919±0.00000  bestvalidloss -1575.68353  last_update 14\n",
      "train: iter 556  trainloss -1461.64175  validloss -1575.17081±0.00000  bestvalidloss -1575.68353  last_update 15\n",
      "train: iter 557  trainloss -918.99632  validloss -1462.04692±0.00000  bestvalidloss -1575.68353  last_update 16\n",
      "train: iter 558  trainloss -1346.92239  validloss -1334.66518±0.00000  bestvalidloss -1575.68353  last_update 17\n",
      "train: iter 559  trainloss -1193.87232  validloss -1361.01421±0.00000  bestvalidloss -1575.68353  last_update 18\n",
      "train: iter 560  trainloss -1402.73732  validloss -1416.80288±0.00000  bestvalidloss -1575.68353  last_update 19\n",
      "train: iter 561  trainloss -1213.75004  validloss -1469.15717±0.00000  bestvalidloss -1575.68353  last_update 20\n",
      "train: iter 562  trainloss -1392.31532  validloss -1198.19854±0.00000  bestvalidloss -1575.68353  last_update 21\n",
      "train: iter 563  trainloss -1446.69576  validloss -1451.37376±0.00000  bestvalidloss -1575.68353  last_update 22\n",
      "train: iter 564  trainloss -1481.20404  validloss -1524.97981±0.00000  bestvalidloss -1575.68353  last_update 23\n",
      "train: iter 565  trainloss -1436.89903  validloss -1499.44216±0.00000  bestvalidloss -1575.68353  last_update 24\n",
      "train: iter 566  trainloss -1492.57557  validloss -1551.95350±0.00000  bestvalidloss -1575.68353  last_update 25\n",
      "train: iter 567  trainloss -1409.92747  validloss -1563.73174±0.00000  bestvalidloss -1575.68353  last_update 26\n",
      "train: iter 568  trainloss -1375.96686  validloss -1368.31974±0.00000  bestvalidloss -1575.68353  last_update 27\n",
      "train: iter 569  trainloss -1408.53220  validloss -1531.20032±0.00000  bestvalidloss -1575.68353  last_update 28\n",
      "train: iter 570  trainloss -1355.19713  validloss -1324.55943±0.00000  bestvalidloss -1575.68353  last_update 29\n",
      "train: iter 571  trainloss -1477.81038  validloss -1519.65556±0.00000  bestvalidloss -1575.68353  last_update 30\n",
      "train: iter 572  trainloss -1469.92891  validloss -1520.96103±0.00000  bestvalidloss -1575.68353  last_update 31\n",
      "train: iter 573  trainloss -1497.89039  validloss -1559.01602±0.00000  bestvalidloss -1575.68353  last_update 32\n",
      "train: iter 574  trainloss -1379.59494  validloss -1545.28117±0.00000  bestvalidloss -1575.68353  last_update 33\n",
      "train: iter 575  trainloss -1409.56356  validloss -1242.57784±0.00000  bestvalidloss -1575.68353  last_update 34\n",
      "train: iter 576  trainloss -1507.21895  validloss -1547.22888±0.00000  bestvalidloss -1575.68353  last_update 35\n",
      "train: iter 577  trainloss -1338.45804  validloss -1560.99195±0.00000  bestvalidloss -1575.68353  last_update 36\n",
      "train: iter 578  trainloss -1296.71694  validloss -1524.61005±0.00000  bestvalidloss -1575.68353  last_update 37\n",
      "train: iter 579  trainloss -1083.84051  validloss -804.56058±0.00000  bestvalidloss -1575.68353  last_update 38\n",
      "train: iter 580  trainloss -1398.91151  validloss -1380.73472±0.00000  bestvalidloss -1575.68353  last_update 39\n",
      "train: iter 581  trainloss -1443.44788  validloss -1462.61512±0.00000  bestvalidloss -1575.68353  last_update 40\n",
      "train: iter 582  trainloss -1457.38090  validloss -1490.05809±0.00000  bestvalidloss -1575.68353  last_update 41\n",
      "train: iter 583  trainloss -1392.81040  validloss -1541.70850±0.00000  bestvalidloss -1575.68353  last_update 42\n",
      "train: iter 584  trainloss -1083.49121  validloss -1456.06253±0.00000  bestvalidloss -1575.68353  last_update 43\n",
      "train: iter 585  trainloss -1418.52207  validloss -1323.42354±0.00000  bestvalidloss -1575.68353  last_update 44\n",
      "train: iter 586  trainloss -1476.95521  validloss -1523.07876±0.00000  bestvalidloss -1575.68353  last_update 45\n",
      "train: iter 587  trainloss -1492.32121  validloss -1560.64187±0.00000  bestvalidloss -1575.68353  last_update 46\n",
      "train: iter 588  trainloss -1466.14749  validloss -1532.22600±0.00000  bestvalidloss -1575.68353  last_update 47\n",
      "train: iter 589  trainloss -1337.99656  validloss -1543.67561±0.00000  bestvalidloss -1575.68353  last_update 48\n",
      "train: iter 590  trainloss -1375.76932  validloss -1071.29949±0.00000  bestvalidloss -1575.68353  last_update 49\n",
      "train: iter 591  trainloss -1502.08564  validloss -1564.92187±0.00000  bestvalidloss -1575.68353  last_update 50\n",
      "train: iter 592  trainloss -1452.30975  validloss -1588.80149±0.00000  bestvalidloss -1588.80149  last_update 0\n",
      "train: iter 593  trainloss -1490.19877  validloss -1498.31338±0.00000  bestvalidloss -1588.80149  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 594  trainloss -1467.77020  validloss -1480.04492±0.00000  bestvalidloss -1588.80149  last_update 2\n",
      "train: iter 595  trainloss -1408.44543  validloss -1570.63739±0.00000  bestvalidloss -1588.80149  last_update 3\n",
      "train: iter 596  trainloss -1451.83095  validloss -1521.16741±0.00000  bestvalidloss -1588.80149  last_update 4\n",
      "train: iter 597  trainloss -1468.18555  validloss -1407.70219±0.00000  bestvalidloss -1588.80149  last_update 5\n",
      "train: iter 598  trainloss -1470.90140  validloss -1549.38893±0.00000  bestvalidloss -1588.80149  last_update 6\n",
      "train: iter 599  trainloss -1448.04319  validloss -1473.24128±0.00000  bestvalidloss -1588.80149  last_update 7\n",
      "train: iter 600  trainloss -1395.68131  validloss -1541.96991±0.00000  bestvalidloss -1588.80149  last_update 8\n",
      "train: iter 601  trainloss -1422.69765  validloss -1499.18702±0.00000  bestvalidloss -1588.80149  last_update 9\n",
      "train: iter 602  trainloss -1473.68074  validloss -1496.70462±0.00000  bestvalidloss -1588.80149  last_update 10\n",
      "train: iter 603  trainloss -1405.55561  validloss -1534.26283±0.00000  bestvalidloss -1588.80149  last_update 11\n",
      "train: iter 604  trainloss -1319.44877  validloss -1513.33651±0.00000  bestvalidloss -1588.80149  last_update 12\n",
      "train: iter 605  trainloss -1407.73988  validloss -1421.68622±0.00000  bestvalidloss -1588.80149  last_update 13\n",
      "train: iter 606  trainloss -1309.34945  validloss -1553.39680±0.00000  bestvalidloss -1588.80149  last_update 14\n",
      "train: iter 607  trainloss -1454.29894  validloss -1450.35676±0.00000  bestvalidloss -1588.80149  last_update 15\n",
      "train: iter 608  trainloss -1359.98526  validloss -1492.34374±0.00000  bestvalidloss -1588.80149  last_update 16\n",
      "train: iter 609  trainloss -1501.71161  validloss -1537.65535±0.00000  bestvalidloss -1588.80149  last_update 17\n",
      "train: iter 610  trainloss -1404.22774  validloss -1570.73963±0.00000  bestvalidloss -1588.80149  last_update 18\n",
      "train: iter 611  trainloss -1488.80550  validloss -1507.91844±0.00000  bestvalidloss -1588.80149  last_update 19\n",
      "train: iter 612  trainloss -1468.63636  validloss -1523.52947±0.00000  bestvalidloss -1588.80149  last_update 20\n",
      "train: iter 613  trainloss -1456.37128  validloss -1458.77268±0.00000  bestvalidloss -1588.80149  last_update 21\n",
      "train: iter 614  trainloss -1352.64686  validloss -1496.43947±0.00000  bestvalidloss -1588.80149  last_update 22\n",
      "train: iter 615  trainloss -1388.06794  validloss -1187.95222±0.00000  bestvalidloss -1588.80149  last_update 23\n",
      "train: iter 616  trainloss -1513.96180  validloss -1558.34317±0.00000  bestvalidloss -1588.80149  last_update 24\n",
      "train: iter 617  trainloss -1507.62660  validloss -1545.78914±0.00000  bestvalidloss -1588.80149  last_update 25\n",
      "train: iter 618  trainloss -1436.17169  validloss -1565.40433±0.00000  bestvalidloss -1588.80149  last_update 26\n",
      "train: iter 619  trainloss -1288.54635  validloss -1186.26007±0.00000  bestvalidloss -1588.80149  last_update 27\n",
      "train: iter 620  trainloss -1467.96116  validloss -1498.47417±0.00000  bestvalidloss -1588.80149  last_update 28\n",
      "train: iter 621  trainloss -1461.55507  validloss -1483.42198±0.00000  bestvalidloss -1588.80149  last_update 29\n",
      "train: iter 622  trainloss -1505.66204  validloss -1481.09081±0.00000  bestvalidloss -1588.80149  last_update 30\n",
      "train: iter 623  trainloss -1447.43490  validloss -1592.08175±0.00000  bestvalidloss -1592.08175  last_update 0\n",
      "train: iter 624  trainloss -1472.21589  validloss -1485.75714±0.00000  bestvalidloss -1592.08175  last_update 1\n",
      "train: iter 625  trainloss -1522.69746  validloss -1494.38046±0.00000  bestvalidloss -1592.08175  last_update 2\n",
      "train: iter 626  trainloss -1308.18963  validloss -1546.53286±0.00000  bestvalidloss -1592.08175  last_update 3\n",
      "train: iter 627  trainloss -1452.27317  validloss -1407.05026±0.00000  bestvalidloss -1592.08175  last_update 4\n",
      "train: iter 628  trainloss -1265.04546  validloss -1395.06657±0.00000  bestvalidloss -1592.08175  last_update 5\n",
      "train: iter 629  trainloss -1301.70975  validloss -1257.81201±0.00000  bestvalidloss -1592.08175  last_update 6\n",
      "train: iter 630  trainloss -1406.11018  validloss -1485.65056±0.00000  bestvalidloss -1592.08175  last_update 7\n",
      "train: iter 631  trainloss -1405.80149  validloss -1452.84659±0.00000  bestvalidloss -1592.08175  last_update 8\n",
      "train: iter 632  trainloss -1321.76231  validloss -1554.53723±0.00000  bestvalidloss -1592.08175  last_update 9\n",
      "train: iter 633  trainloss -1401.44449  validloss -1462.68227±0.00000  bestvalidloss -1592.08175  last_update 10\n",
      "train: iter 634  trainloss -1152.30562  validloss -1423.37510±0.00000  bestvalidloss -1592.08175  last_update 11\n",
      "train: iter 635  trainloss -1428.81455  validloss -1414.71196±0.00000  bestvalidloss -1592.08175  last_update 12\n",
      "train: iter 636  trainloss -1483.93876  validloss -1522.40555±0.00000  bestvalidloss -1592.08175  last_update 13\n",
      "train: iter 637  trainloss -1454.79988  validloss -1564.10146±0.00000  bestvalidloss -1592.08175  last_update 14\n",
      "train: iter 638  trainloss -1436.60755  validloss -1469.07073±0.00000  bestvalidloss -1592.08175  last_update 15\n",
      "train: iter 639  trainloss -1398.58276  validloss -1528.07573±0.00000  bestvalidloss -1592.08175  last_update 16\n",
      "train: iter 640  trainloss -1491.56952  validloss -1523.94679±0.00000  bestvalidloss -1592.08175  last_update 17\n",
      "train: iter 641  trainloss -1472.13350  validloss -1514.99230±0.00000  bestvalidloss -1592.08175  last_update 18\n",
      "train: iter 642  trainloss -1504.50390  validloss -1587.95194±0.00000  bestvalidloss -1592.08175  last_update 19\n",
      "train: iter 643  trainloss -1427.69299  validloss -1503.64676±0.00000  bestvalidloss -1592.08175  last_update 20\n",
      "train: iter 644  trainloss -1480.19932  validloss -1280.20163±0.00000  bestvalidloss -1592.08175  last_update 21\n",
      "train: iter 645  trainloss -1524.83593  validloss -1351.26157±0.00000  bestvalidloss -1592.08175  last_update 22\n",
      "train: iter 646  trainloss -1500.55088  validloss -1563.29259±0.00000  bestvalidloss -1592.08175  last_update 23\n",
      "train: iter 647  trainloss -1497.23267  validloss -1615.78582±0.00000  bestvalidloss -1615.78582  last_update 0\n",
      "train: iter 648  trainloss -1372.19599  validloss -1501.04929±0.00000  bestvalidloss -1615.78582  last_update 1\n",
      "train: iter 649  trainloss -1413.92335  validloss -1119.78488±0.00000  bestvalidloss -1615.78582  last_update 2\n",
      "train: iter 650  trainloss -1525.56946  validloss -1577.28687±0.00000  bestvalidloss -1615.78582  last_update 3\n",
      "train: iter 651  trainloss -1372.23233  validloss -1593.58070±0.00000  bestvalidloss -1615.78582  last_update 4\n",
      "train: iter 652  trainloss -1448.88685  validloss -1451.59169±0.00000  bestvalidloss -1615.78582  last_update 5\n",
      "train: iter 653  trainloss -1444.01404  validloss -1353.84790±0.00000  bestvalidloss -1615.78582  last_update 6\n",
      "train: iter 654  trainloss -1503.49246  validloss -1554.20729±0.00000  bestvalidloss -1615.78582  last_update 7\n",
      "train: iter 655  trainloss -1193.63821  validloss -1547.72993±0.00000  bestvalidloss -1615.78582  last_update 8\n",
      "train: iter 656  trainloss -1412.44102  validloss -1429.50737±0.00000  bestvalidloss -1615.78582  last_update 9\n",
      "train: iter 657  trainloss -1485.02968  validloss -1513.77867±0.00000  bestvalidloss -1615.78582  last_update 10\n",
      "train: iter 658  trainloss -1499.95166  validloss -1533.94992±0.00000  bestvalidloss -1615.78582  last_update 11\n",
      "train: iter 659  trainloss -1500.01813  validloss -1586.63701±0.00000  bestvalidloss -1615.78582  last_update 12\n",
      "train: iter 660  trainloss -1445.48942  validloss -1569.15261±0.00000  bestvalidloss -1615.78582  last_update 13\n",
      "train: iter 661  trainloss -1435.27927  validloss -1122.73869±0.00000  bestvalidloss -1615.78582  last_update 14\n",
      "train: iter 662  trainloss -1534.69692  validloss -1580.00406±0.00000  bestvalidloss -1615.78582  last_update 15\n",
      "train: iter 663  trainloss -1533.89251  validloss -1601.18686±0.00000  bestvalidloss -1615.78582  last_update 16\n",
      "train: iter 664  trainloss -1512.03070  validloss -1605.53479±0.00000  bestvalidloss -1615.78582  last_update 17\n",
      "train: iter 665  trainloss -1468.20880  validloss -1593.48350±0.00000  bestvalidloss -1615.78582  last_update 18\n",
      "train: iter 666  trainloss -1521.69825  validloss -1571.58476±0.00000  bestvalidloss -1615.78582  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 667  trainloss -1508.87249  validloss -1589.07654±0.00000  bestvalidloss -1615.78582  last_update 20\n",
      "train: iter 668  trainloss -1407.26314  validloss -1461.26087±0.00000  bestvalidloss -1615.78582  last_update 21\n",
      "train: iter 669  trainloss -1512.57272  validloss -1529.97120±0.00000  bestvalidloss -1615.78582  last_update 22\n",
      "train: iter 670  trainloss -1524.62451  validloss -1603.88149±0.00000  bestvalidloss -1615.78582  last_update 23\n",
      "train: iter 671  trainloss -1524.54937  validloss -1544.90123±0.00000  bestvalidloss -1615.78582  last_update 24\n",
      "train: iter 672  trainloss -1422.48935  validloss -1531.89069±0.00000  bestvalidloss -1615.78582  last_update 25\n",
      "train: iter 673  trainloss -1434.16115  validloss -1499.79527±0.00000  bestvalidloss -1615.78582  last_update 26\n",
      "train: iter 674  trainloss -1546.31237  validloss -1554.71781±0.00000  bestvalidloss -1615.78582  last_update 27\n",
      "train: iter 675  trainloss -1314.10303  validloss -1528.96110±0.00000  bestvalidloss -1615.78582  last_update 28\n",
      "train: iter 676  trainloss -1428.42659  validloss -1373.60719±0.00000  bestvalidloss -1615.78582  last_update 29\n",
      "train: iter 677  trainloss -1512.65117  validloss -1546.63175±0.00000  bestvalidloss -1615.78582  last_update 30\n",
      "train: iter 678  trainloss -1413.02896  validloss -1556.02251±0.00000  bestvalidloss -1615.78582  last_update 31\n",
      "train: iter 679  trainloss -1456.22612  validloss -1426.71374±0.00000  bestvalidloss -1615.78582  last_update 32\n",
      "train: iter 680  trainloss -1549.27127  validloss -1608.45732±0.00000  bestvalidloss -1615.78582  last_update 33\n",
      "train: iter 681  trainloss -1395.25942  validloss -1520.45836±0.00000  bestvalidloss -1615.78582  last_update 34\n",
      "train: iter 682  trainloss -1534.74548  validloss -1557.74159±0.00000  bestvalidloss -1615.78582  last_update 35\n",
      "train: iter 683  trainloss -1521.39606  validloss -1615.43971±0.00000  bestvalidloss -1615.78582  last_update 36\n",
      "train: iter 684  trainloss -1335.52233  validloss -1599.25602±0.00000  bestvalidloss -1615.78582  last_update 37\n",
      "train: iter 685  trainloss -1508.21825  validloss -1497.88034±0.00000  bestvalidloss -1615.78582  last_update 38\n",
      "train: iter 686  trainloss -1465.37953  validloss -1568.82043±0.00000  bestvalidloss -1615.78582  last_update 39\n",
      "train: iter 687  trainloss -1469.10061  validloss -1302.75506±0.00000  bestvalidloss -1615.78582  last_update 40\n",
      "train: iter 688  trainloss -1546.24431  validloss -1619.15670±0.00000  bestvalidloss -1619.15670  last_update 0\n",
      "train: iter 689  trainloss -1538.57885  validloss -1603.16482±0.00000  bestvalidloss -1619.15670  last_update 1\n",
      "train: iter 690  trainloss -1257.96034  validloss -1544.54859±0.00000  bestvalidloss -1619.15670  last_update 2\n",
      "train: iter 691  trainloss -1405.40215  validloss -1412.52552±0.00000  bestvalidloss -1619.15670  last_update 3\n",
      "train: iter 692  trainloss -1518.99128  validloss -1555.85270±0.00000  bestvalidloss -1619.15670  last_update 4\n",
      "train: iter 693  trainloss -1546.21111  validloss -1552.68931±0.00000  bestvalidloss -1619.15670  last_update 5\n",
      "train: iter 694  trainloss -1511.77905  validloss -1601.11673±0.00000  bestvalidloss -1619.15670  last_update 6\n",
      "train: iter 695  trainloss -1406.07875  validloss -1399.64957±0.00000  bestvalidloss -1619.15670  last_update 7\n",
      "train: iter 696  trainloss -1498.07540  validloss -1491.08553±0.00000  bestvalidloss -1619.15670  last_update 8\n",
      "train: iter 697  trainloss -1475.78225  validloss -1613.82271±0.00000  bestvalidloss -1619.15670  last_update 9\n",
      "train: iter 698  trainloss -1467.87154  validloss -1511.52944±0.00000  bestvalidloss -1619.15670  last_update 10\n",
      "train: iter 699  trainloss -1514.15085  validloss -1478.89295±0.00000  bestvalidloss -1619.15670  last_update 11\n",
      "train: iter 700  trainloss -1539.85904  validloss -1608.89363±0.00000  bestvalidloss -1619.15670  last_update 12\n",
      "train: iter 701  trainloss -1472.70187  validloss -1462.28863±0.00000  bestvalidloss -1619.15670  last_update 13\n",
      "train: iter 702  trainloss -1391.80732  validloss -1568.25989±0.00000  bestvalidloss -1619.15670  last_update 14\n",
      "train: iter 703  trainloss -1492.67015  validloss -1512.92372±0.00000  bestvalidloss -1619.15670  last_update 15\n",
      "train: iter 704  trainloss -1527.70016  validloss -1571.14605±0.00000  bestvalidloss -1619.15670  last_update 16\n",
      "train: iter 705  trainloss -1483.16861  validloss -1526.44836±0.00000  bestvalidloss -1619.15670  last_update 17\n",
      "train: iter 706  trainloss -1419.27314  validloss -1556.77590±0.00000  bestvalidloss -1619.15670  last_update 18\n",
      "train: iter 707  trainloss -1433.05766  validloss -1030.74361±0.00000  bestvalidloss -1619.15670  last_update 19\n",
      "train: iter 708  trainloss -1536.90781  validloss -1579.69905±0.00000  bestvalidloss -1619.15670  last_update 20\n",
      "train: iter 709  trainloss -1519.72261  validloss -1584.52792±0.00000  bestvalidloss -1619.15670  last_update 21\n",
      "train: iter 710  trainloss -1221.83926  validloss -1478.76222±0.00000  bestvalidloss -1619.15670  last_update 22\n",
      "train: iter 711  trainloss -1203.80330  validloss -998.81210±0.00000  bestvalidloss -1619.15670  last_update 23\n",
      "train: iter 712  trainloss -1358.87932  validloss -1221.40530±0.00000  bestvalidloss -1619.15670  last_update 24\n",
      "train: iter 713  trainloss -1447.81289  validloss -1566.13086±0.00000  bestvalidloss -1619.15670  last_update 25\n",
      "train: iter 714  trainloss -1413.99467  validloss -1288.68921±0.00000  bestvalidloss -1619.15670  last_update 26\n",
      "train: iter 715  trainloss -1513.86841  validloss -1549.23581±0.00000  bestvalidloss -1619.15670  last_update 27\n",
      "train: iter 716  trainloss -1456.53201  validloss -1596.42816±0.00000  bestvalidloss -1619.15670  last_update 28\n",
      "train: iter 717  trainloss -1496.62646  validloss -1470.34768±0.00000  bestvalidloss -1619.15670  last_update 29\n",
      "train: iter 718  trainloss -1543.96522  validloss -1586.89532±0.00000  bestvalidloss -1619.15670  last_update 30\n",
      "train: iter 719  trainloss -1435.52733  validloss -1269.88870±0.00000  bestvalidloss -1619.15670  last_update 31\n",
      "train: iter 720  trainloss -1534.04135  validloss -1549.70226±0.00000  bestvalidloss -1619.15670  last_update 32\n",
      "train: iter 721  trainloss -1490.38543  validloss -1612.39385±0.00000  bestvalidloss -1619.15670  last_update 33\n",
      "train: iter 722  trainloss -1524.69815  validloss -1569.45830±0.00000  bestvalidloss -1619.15670  last_update 34\n",
      "train: iter 723  trainloss -1445.67684  validloss -1574.94446±0.00000  bestvalidloss -1619.15670  last_update 35\n",
      "train: iter 724  trainloss -1448.92905  validloss -1554.96405±0.00000  bestvalidloss -1619.15670  last_update 36\n",
      "train: iter 725  trainloss -1488.69561  validloss -1541.55916±0.00000  bestvalidloss -1619.15670  last_update 37\n",
      "train: iter 726  trainloss -1527.15286  validloss -1558.01294±0.00000  bestvalidloss -1619.15670  last_update 38\n",
      "train: iter 727  trainloss -1561.96638  validloss -1615.60559±0.00000  bestvalidloss -1619.15670  last_update 39\n",
      "train: iter 728  trainloss -1348.67377  validloss -1594.33517±0.00000  bestvalidloss -1619.15670  last_update 40\n",
      "train: iter 729  trainloss -1470.39425  validloss -1337.47790±0.00000  bestvalidloss -1619.15670  last_update 41\n",
      "train: iter 730  trainloss -1560.40929  validloss -1557.48477±0.00000  bestvalidloss -1619.15670  last_update 42\n",
      "train: iter 731  trainloss -1543.56094  validloss -1586.59439±0.00000  bestvalidloss -1619.15670  last_update 43\n",
      "train: iter 732  trainloss -1397.49229  validloss -1489.63722±0.00000  bestvalidloss -1619.15670  last_update 44\n",
      "train: iter 733  trainloss -1527.40926  validloss -1537.51460±0.00000  bestvalidloss -1619.15670  last_update 45\n",
      "train: iter 734  trainloss -1542.34392  validloss -1594.19990±0.00000  bestvalidloss -1619.15670  last_update 46\n",
      "train: iter 735  trainloss -1370.95541  validloss -1607.50804±0.00000  bestvalidloss -1619.15670  last_update 47\n",
      "train: iter 736  trainloss -1428.05008  validloss -1223.63024±0.00000  bestvalidloss -1619.15670  last_update 48\n",
      "train: iter 737  trainloss -1484.74784  validloss -1549.88241±0.00000  bestvalidloss -1619.15670  last_update 49\n",
      "train: iter 738  trainloss -1556.06147  validloss -1570.44935±0.00000  bestvalidloss -1619.15670  last_update 50\n",
      "train: iter 739  trainloss -1465.83200  validloss -1586.35526±0.00000  bestvalidloss -1619.15670  last_update 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 740  trainloss -1517.05243  validloss -1525.16734±0.00000  bestvalidloss -1619.15670  last_update 52\n",
      "train: iter 741  trainloss -1543.63915  validloss -1605.64901±0.00000  bestvalidloss -1619.15670  last_update 53\n",
      "train: iter 742  trainloss -1533.30640  validloss -1541.62758±0.00000  bestvalidloss -1619.15670  last_update 54\n",
      "train: iter 743  trainloss -1123.87678  validloss -1514.23188±0.00000  bestvalidloss -1619.15670  last_update 55\n",
      "train: iter 744  trainloss -1443.82805  validloss -1253.53335±0.00000  bestvalidloss -1619.15670  last_update 56\n",
      "train: iter 745  trainloss -1526.79252  validloss -1544.00060±0.00000  bestvalidloss -1619.15670  last_update 57\n",
      "train: iter 746  trainloss -1544.49980  validloss -1586.29376±0.00000  bestvalidloss -1619.15670  last_update 58\n",
      "train: iter 747  trainloss -1537.80665  validloss -1580.89391±0.00000  bestvalidloss -1619.15670  last_update 59\n",
      "train: iter 748  trainloss -1402.37923  validloss -1463.31099±0.00000  bestvalidloss -1619.15670  last_update 60\n",
      "train: iter 749  trainloss -1455.25772  validloss -1412.22602±0.00000  bestvalidloss -1619.15670  last_update 61\n",
      "train: iter 750  trainloss -1533.93891  validloss -1562.85462±0.00000  bestvalidloss -1619.15670  last_update 62\n",
      "train: iter 751  trainloss -1530.04357  validloss -1588.98535±0.00000  bestvalidloss -1619.15670  last_update 63\n",
      "train: iter 752  trainloss -1424.83048  validloss -1493.42884±0.00000  bestvalidloss -1619.15670  last_update 64\n",
      "train: iter 753  trainloss -1517.92291  validloss -1467.92491±0.00000  bestvalidloss -1619.15670  last_update 65\n",
      "train: iter 754  trainloss -1482.82412  validloss -1585.67577±0.00000  bestvalidloss -1619.15670  last_update 66\n",
      "train: iter 755  trainloss -1406.65002  validloss -1493.62371±0.00000  bestvalidloss -1619.15670  last_update 67\n",
      "train: iter 756  trainloss -1547.50483  validloss -1576.31147±0.00000  bestvalidloss -1619.15670  last_update 68\n",
      "train: iter 757  trainloss -1449.06803  validloss -1581.39014±0.00000  bestvalidloss -1619.15670  last_update 69\n",
      "train: iter 758  trainloss -1497.11472  validloss -1487.59245±0.00000  bestvalidloss -1619.15670  last_update 70\n",
      "train: iter 759  trainloss -1571.72016  validloss -1566.45168±0.00000  bestvalidloss -1619.15670  last_update 71\n",
      "train: iter 760  trainloss -1572.98383  validloss -1626.17075±0.00000  bestvalidloss -1626.17075  last_update 0\n",
      "train: iter 761  trainloss -1416.55770  validloss -1582.79132±0.00000  bestvalidloss -1626.17075  last_update 1\n",
      "train: iter 762  trainloss -1475.83279  validloss -1531.38299±0.00000  bestvalidloss -1626.17075  last_update 2\n",
      "train: iter 763  trainloss -1549.71019  validloss -1578.66120±0.00000  bestvalidloss -1626.17075  last_update 3\n",
      "train: iter 764  trainloss -1297.48705  validloss -1376.72463±0.00000  bestvalidloss -1626.17075  last_update 4\n",
      "train: iter 765  trainloss -1466.74174  validloss -1525.36420±0.00000  bestvalidloss -1626.17075  last_update 5\n",
      "train: iter 766  trainloss -1530.27370  validloss -1542.17457±0.00000  bestvalidloss -1626.17075  last_update 6\n",
      "train: iter 767  trainloss -1008.47196  validloss -1565.40632±0.00000  bestvalidloss -1626.17075  last_update 7\n",
      "train: iter 768  trainloss -1313.56301  validloss -1126.47126±0.00000  bestvalidloss -1626.17075  last_update 8\n",
      "train: iter 769  trainloss -1427.87873  validloss -1304.63191±0.00000  bestvalidloss -1626.17075  last_update 9\n",
      "train: iter 770  trainloss -1500.60249  validloss -1508.62594±0.00000  bestvalidloss -1626.17075  last_update 10\n",
      "train: iter 771  trainloss -1532.91892  validloss -1573.07233±0.00000  bestvalidloss -1626.17075  last_update 11\n",
      "train: iter 772  trainloss -1543.94822  validloss -1588.24970±0.00000  bestvalidloss -1626.17075  last_update 12\n",
      "train: iter 773  trainloss -1471.32746  validloss -1600.39984±0.00000  bestvalidloss -1626.17075  last_update 13\n",
      "train: iter 774  trainloss -1468.85657  validloss -1547.68159±0.00000  bestvalidloss -1626.17075  last_update 14\n",
      "train: iter 775  trainloss -1484.61905  validloss -1446.48230±0.00000  bestvalidloss -1626.17075  last_update 15\n",
      "train: iter 776  trainloss -1545.31511  validloss -1587.59955±0.00000  bestvalidloss -1626.17075  last_update 16\n",
      "train: iter 777  trainloss -1537.71370  validloss -1513.45595±0.00000  bestvalidloss -1626.17075  last_update 17\n",
      "train: iter 778  trainloss -1535.32671  validloss -1559.95650±0.00000  bestvalidloss -1626.17075  last_update 18\n",
      "train: iter 779  trainloss -1556.61075  validloss -1554.89856±0.00000  bestvalidloss -1626.17075  last_update 19\n",
      "train: iter 780  trainloss -1371.22134  validloss -1588.41926±0.00000  bestvalidloss -1626.17075  last_update 20\n",
      "train: iter 781  trainloss -1462.46066  validloss -1339.35143±0.00000  bestvalidloss -1626.17075  last_update 21\n",
      "train: iter 782  trainloss -1531.98477  validloss -1615.21624±0.00000  bestvalidloss -1626.17075  last_update 22\n",
      "train: iter 783  trainloss -1495.17024  validloss -1286.58581±0.00000  bestvalidloss -1626.17075  last_update 23\n",
      "train: iter 784  trainloss -1563.34947  validloss -1598.32746±0.00000  bestvalidloss -1626.17075  last_update 24\n",
      "train: iter 785  trainloss -1388.24535  validloss -1343.91562±0.00000  bestvalidloss -1626.17075  last_update 25\n",
      "train: iter 786  trainloss -1479.54592  validloss -1565.38586±0.00000  bestvalidloss -1626.17075  last_update 26\n",
      "train: iter 787  trainloss -1268.58477  validloss -1596.36565±0.00000  bestvalidloss -1626.17075  last_update 27\n",
      "train: iter 788  trainloss -1463.77486  validloss -1457.13557±0.00000  bestvalidloss -1626.17075  last_update 28\n",
      "train: iter 789  trainloss -1545.67721  validloss -1564.33968±0.00000  bestvalidloss -1626.17075  last_update 29\n",
      "train: iter 790  trainloss -1561.47877  validloss -1544.92481±0.00000  bestvalidloss -1626.17075  last_update 30\n",
      "train: iter 791  trainloss -1562.18045  validloss -1581.88249±0.00000  bestvalidloss -1626.17075  last_update 31\n",
      "train: iter 792  trainloss -1536.48512  validloss -1586.05811±0.00000  bestvalidloss -1626.17075  last_update 32\n",
      "train: iter 793  trainloss -1504.53356  validloss -1606.53215±0.00000  bestvalidloss -1626.17075  last_update 33\n",
      "train: iter 794  trainloss -1062.41584  validloss -1356.40745±0.00000  bestvalidloss -1626.17075  last_update 34\n",
      "train: iter 795  trainloss -1219.08597  validloss -1371.65631±0.00000  bestvalidloss -1626.17075  last_update 35\n",
      "train: iter 796  trainloss -1386.52934  validloss -1261.36698±0.00000  bestvalidloss -1626.17075  last_update 36\n",
      "train: iter 797  trainloss -1496.95925  validloss -1473.89241±0.00000  bestvalidloss -1626.17075  last_update 37\n",
      "train: iter 798  trainloss -1541.47623  validloss -1546.36377±0.00000  bestvalidloss -1626.17075  last_update 38\n",
      "train: iter 799  trainloss -1495.71349  validloss -1584.87933±0.00000  bestvalidloss -1626.17075  last_update 39\n",
      "train: iter 800  trainloss -1453.56081  validloss -1507.11182±0.00000  bestvalidloss -1626.17075  last_update 40\n",
      "train: iter 801  trainloss -1489.65152  validloss -1466.58150±0.00000  bestvalidloss -1626.17075  last_update 41\n",
      "train: iter 802  trainloss -1562.06363  validloss -1579.05851±0.00000  bestvalidloss -1626.17075  last_update 42\n",
      "train: iter 803  trainloss -1561.53570  validloss -1589.31068±0.00000  bestvalidloss -1626.17075  last_update 43\n",
      "train: iter 804  trainloss -1559.09160  validloss -1590.91657±0.00000  bestvalidloss -1626.17075  last_update 44\n",
      "train: iter 805  trainloss -1537.26960  validloss -1555.68213±0.00000  bestvalidloss -1626.17075  last_update 45\n",
      "train: iter 806  trainloss -1388.48200  validloss -1599.35399±0.00000  bestvalidloss -1626.17075  last_update 46\n",
      "train: iter 807  trainloss -1501.32552  validloss -1370.93036±0.00000  bestvalidloss -1626.17075  last_update 47\n",
      "train: iter 808  trainloss -1530.04901  validloss -1577.14539±0.00000  bestvalidloss -1626.17075  last_update 48\n",
      "train: iter 809  trainloss -1540.55603  validloss -1518.39767±0.00000  bestvalidloss -1626.17075  last_update 49\n",
      "train: iter 810  trainloss -1461.02217  validloss -1559.71795±0.00000  bestvalidloss -1626.17075  last_update 50\n",
      "train: iter 811  trainloss -1509.75696  validloss -1552.58660±0.00000  bestvalidloss -1626.17075  last_update 51\n",
      "train: iter 812  trainloss -1531.26050  validloss -1551.89927±0.00000  bestvalidloss -1626.17075  last_update 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 813  trainloss -1513.47163  validloss -1549.18488±0.00000  bestvalidloss -1626.17075  last_update 53\n",
      "train: iter 814  trainloss -1569.26107  validloss -1584.59594±0.00000  bestvalidloss -1626.17075  last_update 54\n",
      "train: iter 815  trainloss -1443.18254  validloss -1628.11915±0.00000  bestvalidloss -1628.11915  last_update 0\n",
      "train: iter 816  trainloss -1571.50899  validloss -1578.85719±0.00000  bestvalidloss -1628.11915  last_update 1\n",
      "train: iter 817  trainloss -1499.10105  validloss -1569.69215±0.00000  bestvalidloss -1628.11915  last_update 2\n",
      "train: iter 818  trainloss -1519.86056  validloss -1521.10340±0.00000  bestvalidloss -1628.11915  last_update 3\n",
      "train: iter 819  trainloss -1508.04144  validloss -1392.51624±0.00000  bestvalidloss -1628.11915  last_update 4\n",
      "train: iter 820  trainloss -1582.18585  validloss -1612.30936±0.00000  bestvalidloss -1628.11915  last_update 5\n",
      "train: iter 821  trainloss -1559.80519  validloss -1558.20304±0.00000  bestvalidloss -1628.11915  last_update 6\n",
      "train: iter 822  trainloss -1391.00921  validloss -1619.31862±0.00000  bestvalidloss -1628.11915  last_update 7\n",
      "train: iter 823  trainloss -1510.30436  validloss -1398.13475±0.00000  bestvalidloss -1628.11915  last_update 8\n",
      "train: iter 824  trainloss -1526.49697  validloss -1586.51289±0.00000  bestvalidloss -1628.11915  last_update 9\n",
      "train: iter 825  trainloss -1541.44869  validloss -1500.66670±0.00000  bestvalidloss -1628.11915  last_update 10\n",
      "train: iter 826  trainloss -1601.61576  validloss -1622.69934±0.00000  bestvalidloss -1628.11915  last_update 11\n",
      "train: iter 827  trainloss -1515.60166  validloss -1633.04060±0.00000  bestvalidloss -1633.04060  last_update 0\n",
      "train: iter 828  trainloss -1352.24099  validloss -1547.12370±0.00000  bestvalidloss -1633.04060  last_update 1\n",
      "train: iter 829  trainloss -1490.73204  validloss -1230.98353±0.00000  bestvalidloss -1633.04060  last_update 2\n",
      "train: iter 830  trainloss -1567.75064  validloss -1585.55100±0.00000  bestvalidloss -1633.04060  last_update 3\n",
      "train: iter 831  trainloss -1426.04767  validloss -1595.96230±0.00000  bestvalidloss -1633.04060  last_update 4\n",
      "train: iter 832  trainloss -1501.72843  validloss -1380.55616±0.00000  bestvalidloss -1633.04060  last_update 5\n",
      "train: iter 833  trainloss -1547.80956  validloss -1591.04999±0.00000  bestvalidloss -1633.04060  last_update 6\n",
      "train: iter 834  trainloss -1552.99931  validloss -1597.11290±0.00000  bestvalidloss -1633.04060  last_update 7\n",
      "train: iter 835  trainloss -1580.10934  validloss -1588.57112±0.00000  bestvalidloss -1633.04060  last_update 8\n",
      "train: iter 836  trainloss -1493.64548  validloss -1558.01364±0.00000  bestvalidloss -1633.04060  last_update 9\n",
      "train: iter 837  trainloss -1507.75799  validloss -1429.40847±0.00000  bestvalidloss -1633.04060  last_update 10\n",
      "train: iter 838  trainloss -1510.54735  validloss -1508.64127±0.00000  bestvalidloss -1633.04060  last_update 11\n",
      "train: iter 839  trainloss -1508.48789  validloss -1552.55069±0.00000  bestvalidloss -1633.04060  last_update 12\n",
      "train: iter 840  trainloss -1519.32110  validloss -1582.30059±0.00000  bestvalidloss -1633.04060  last_update 13\n",
      "train: iter 841  trainloss -1544.18121  validloss -1441.99026±0.00000  bestvalidloss -1633.04060  last_update 14\n",
      "train: iter 842  trainloss -1551.01838  validloss -1589.86464±0.00000  bestvalidloss -1633.04060  last_update 15\n",
      "train: iter 843  trainloss -1501.59694  validloss -1568.02797±0.00000  bestvalidloss -1633.04060  last_update 16\n",
      "train: iter 844  trainloss -1524.55207  validloss -1560.17495±0.00000  bestvalidloss -1633.04060  last_update 17\n",
      "train: iter 845  trainloss -1581.75630  validloss -1583.22263±0.00000  bestvalidloss -1633.04060  last_update 18\n",
      "train: iter 846  trainloss -1496.98512  validloss -1594.42403±0.00000  bestvalidloss -1633.04060  last_update 19\n",
      "train: iter 847  trainloss -1499.82896  validloss -1533.56313±0.00000  bestvalidloss -1633.04060  last_update 20\n",
      "train: iter 848  trainloss -1584.96003  validloss -1580.35089±0.00000  bestvalidloss -1633.04060  last_update 21\n",
      "train: iter 849  trainloss -1286.39315  validloss -1560.13065±0.00000  bestvalidloss -1633.04060  last_update 22\n",
      "train: iter 850  trainloss -1505.07254  validloss -1479.50323±0.00000  bestvalidloss -1633.04060  last_update 23\n",
      "train: iter 851  trainloss -1568.90616  validloss -1572.72830±0.00000  bestvalidloss -1633.04060  last_update 24\n",
      "train: iter 852  trainloss -1546.71853  validloss -1576.54850±0.00000  bestvalidloss -1633.04060  last_update 25\n",
      "train: iter 853  trainloss -1433.48003  validloss -1528.78962±0.00000  bestvalidloss -1633.04060  last_update 26\n",
      "train: iter 854  trainloss -1456.35395  validloss -1568.83073±0.00000  bestvalidloss -1633.04060  last_update 27\n",
      "train: iter 855  trainloss -1566.01072  validloss -1476.70114±0.00000  bestvalidloss -1633.04060  last_update 28\n",
      "train: iter 856  trainloss -1605.57972  validloss -1607.07814±0.00000  bestvalidloss -1633.04060  last_update 29\n",
      "train: iter 857  trainloss -1566.11256  validloss -1632.75375±0.00000  bestvalidloss -1633.04060  last_update 30\n",
      "train: iter 858  trainloss -1504.10901  validloss -1599.67375±0.00000  bestvalidloss -1633.04060  last_update 31\n",
      "train: iter 859  trainloss -1498.99861  validloss -1222.44755±0.00000  bestvalidloss -1633.04060  last_update 32\n",
      "train: iter 860  trainloss -1528.63076  validloss -1591.31438±0.00000  bestvalidloss -1633.04060  last_update 33\n",
      "train: iter 861  trainloss -1527.26902  validloss -1540.03231±0.00000  bestvalidloss -1633.04060  last_update 34\n",
      "train: iter 862  trainloss -1563.73079  validloss -1572.71599±0.00000  bestvalidloss -1633.04060  last_update 35\n",
      "train: iter 863  trainloss -1405.22794  validloss -1609.52409±0.00000  bestvalidloss -1633.04060  last_update 36\n",
      "train: iter 864  trainloss -1557.66151  validloss -1549.96790±0.00000  bestvalidloss -1633.04060  last_update 37\n",
      "train: iter 865  trainloss -1555.60112  validloss -1560.20172±0.00000  bestvalidloss -1633.04060  last_update 38\n",
      "train: iter 866  trainloss -1596.91270  validloss -1611.94044±0.00000  bestvalidloss -1633.04060  last_update 39\n",
      "train: iter 867  trainloss -1452.74529  validloss -1640.22418±0.00000  bestvalidloss -1640.22418  last_update 0\n",
      "train: iter 868  trainloss -1570.72618  validloss -1523.79387±0.00000  bestvalidloss -1640.22418  last_update 1\n",
      "train: iter 869  trainloss -1546.15092  validloss -1611.35840±0.00000  bestvalidloss -1640.22418  last_update 2\n",
      "train: iter 870  trainloss -1482.26366  validloss -1276.85186±0.00000  bestvalidloss -1640.22418  last_update 3\n",
      "train: iter 871  trainloss -1606.57429  validloss -1610.71455±0.00000  bestvalidloss -1640.22418  last_update 4\n",
      "train: iter 872  trainloss -1428.59734  validloss -1602.59307±0.00000  bestvalidloss -1640.22418  last_update 5\n",
      "train: iter 873  trainloss -1576.01724  validloss -1567.25853±0.00000  bestvalidloss -1640.22418  last_update 6\n",
      "train: iter 874  trainloss -1192.07923  validloss -1612.54921±0.00000  bestvalidloss -1640.22418  last_update 7\n",
      "train: iter 875  trainloss -1488.83729  validloss -1329.04399±0.00000  bestvalidloss -1640.22418  last_update 8\n",
      "train: iter 876  trainloss -1573.89165  validloss -1564.54882±0.00000  bestvalidloss -1640.22418  last_update 9\n",
      "train: iter 877  trainloss -1512.53178  validloss -1595.37093±0.00000  bestvalidloss -1640.22418  last_update 10\n",
      "train: iter 878  trainloss -1519.82470  validloss -1450.31340±0.00000  bestvalidloss -1640.22418  last_update 11\n",
      "train: iter 879  trainloss -1511.48549  validloss -1538.76372±0.00000  bestvalidloss -1640.22418  last_update 12\n",
      "train: iter 880  trainloss -1562.14712  validloss -1557.98518±0.00000  bestvalidloss -1640.22418  last_update 13\n",
      "train: iter 881  trainloss -1606.53090  validloss -1614.65298±0.00000  bestvalidloss -1640.22418  last_update 14\n",
      "train: iter 882  trainloss -1512.13734  validloss -1613.70511±0.00000  bestvalidloss -1640.22418  last_update 15\n",
      "train: iter 883  trainloss -1566.28617  validloss -1542.33131±0.00000  bestvalidloss -1640.22418  last_update 16\n",
      "train: iter 884  trainloss -1615.04891  validloss -1640.64712±0.00000  bestvalidloss -1640.64712  last_update 0\n",
      "train: iter 885  trainloss -1467.08696  validloss -1599.90332±0.00000  bestvalidloss -1640.64712  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 886  trainloss -1451.56789  validloss -1464.34619±0.00000  bestvalidloss -1640.64712  last_update 2\n",
      "train: iter 887  trainloss -1515.44129  validloss -1562.45448±0.00000  bestvalidloss -1640.64712  last_update 3\n",
      "train: iter 888  trainloss -1508.36842  validloss -1477.22550±0.00000  bestvalidloss -1640.64712  last_update 4\n",
      "train: iter 889  trainloss -1563.56164  validloss -1483.44422±0.00000  bestvalidloss -1640.64712  last_update 5\n",
      "train: iter 890  trainloss -1166.90194  validloss -1578.06179±0.00000  bestvalidloss -1640.64712  last_update 6\n",
      "train: iter 891  trainloss -1363.97298  validloss -991.52390±0.00000  bestvalidloss -1640.64712  last_update 7\n",
      "train: iter 892  trainloss -1555.56133  validloss -1562.01673±0.00000  bestvalidloss -1640.64712  last_update 8\n",
      "train: iter 893  trainloss -1516.48762  validloss -1570.25361±0.00000  bestvalidloss -1640.64712  last_update 9\n",
      "train: iter 894  trainloss -1556.44796  validloss -1517.03088±0.00000  bestvalidloss -1640.64712  last_update 10\n",
      "train: iter 895  trainloss -1560.08671  validloss -1589.36898±0.00000  bestvalidloss -1640.64712  last_update 11\n",
      "train: iter 896  trainloss -1553.50148  validloss -1550.93764±0.00000  bestvalidloss -1640.64712  last_update 12\n",
      "train: iter 897  trainloss -1547.38161  validloss -1566.96044±0.00000  bestvalidloss -1640.64712  last_update 13\n",
      "train: iter 898  trainloss -1506.77008  validloss -1523.56273±0.00000  bestvalidloss -1640.64712  last_update 14\n",
      "train: iter 899  trainloss -1494.94295  validloss -1503.02005±0.00000  bestvalidloss -1640.64712  last_update 15\n",
      "train: iter 900  trainloss -1558.93131  validloss -1543.65173±0.00000  bestvalidloss -1640.64712  last_update 16\n",
      "train: iter 901  trainloss -1603.62086  validloss -1608.89351±0.00000  bestvalidloss -1640.64712  last_update 17\n",
      "train: iter 902  trainloss -1417.97570  validloss -1565.10715±0.00000  bestvalidloss -1640.64712  last_update 18\n",
      "train: iter 903  trainloss -1531.29067  validloss -1502.46546±0.00000  bestvalidloss -1640.64712  last_update 19\n",
      "train: iter 904  trainloss -1581.35816  validloss -1618.66396±0.00000  bestvalidloss -1640.64712  last_update 20\n",
      "train: iter 905  trainloss -1585.38100  validloss -1623.66309±0.00000  bestvalidloss -1640.64712  last_update 21\n",
      "train: iter 906  trainloss -1308.18095  validloss -1466.64675±0.00000  bestvalidloss -1640.64712  last_update 22\n",
      "train: iter 907  trainloss -1547.46492  validloss -1531.67074±0.00000  bestvalidloss -1640.64712  last_update 23\n",
      "train: iter 908  trainloss -1555.09054  validloss -1550.18878±0.00000  bestvalidloss -1640.64712  last_update 24\n",
      "train: iter 909  trainloss -1533.65576  validloss -1633.06896±0.00000  bestvalidloss -1640.64712  last_update 25\n",
      "train: iter 910  trainloss -1431.48726  validloss -1522.67869±0.00000  bestvalidloss -1640.64712  last_update 26\n",
      "train: iter 911  trainloss -1531.16941  validloss -1530.11839±0.00000  bestvalidloss -1640.64712  last_update 27\n",
      "train: iter 912  trainloss -1568.03028  validloss -1534.60448±0.00000  bestvalidloss -1640.64712  last_update 28\n",
      "train: iter 913  trainloss -1505.47931  validloss -1505.54005±0.00000  bestvalidloss -1640.64712  last_update 29\n",
      "train: iter 914  trainloss -1579.08482  validloss -1498.97371±0.00000  bestvalidloss -1640.64712  last_update 30\n",
      "train: iter 915  trainloss -1589.04485  validloss -1619.93041±0.00000  bestvalidloss -1640.64712  last_update 31\n",
      "train: iter 916  trainloss -1498.93177  validloss -1517.36060±0.00000  bestvalidloss -1640.64712  last_update 32\n",
      "train: iter 917  trainloss -1534.38139  validloss -1536.07366±0.00000  bestvalidloss -1640.64712  last_update 33\n",
      "train: iter 918  trainloss -1601.67800  validloss -1623.54890±0.00000  bestvalidloss -1640.64712  last_update 34\n",
      "train: iter 919  trainloss -1600.34747  validloss -1624.58541±0.00000  bestvalidloss -1640.64712  last_update 35\n",
      "train: iter 920  trainloss -1460.08414  validloss -1392.67152±0.00000  bestvalidloss -1640.64712  last_update 36\n",
      "train: iter 921  trainloss -1557.95579  validloss -1608.05742±0.00000  bestvalidloss -1640.64712  last_update 37\n",
      "train: iter 922  trainloss -1400.67247  validloss -1515.97580±0.00000  bestvalidloss -1640.64712  last_update 38\n",
      "train: iter 923  trainloss -1410.79842  validloss -1498.15910±0.00000  bestvalidloss -1640.64712  last_update 39\n",
      "train: iter 924  trainloss -1591.24595  validloss -1579.48085±0.00000  bestvalidloss -1640.64712  last_update 40\n",
      "train: iter 925  trainloss -1471.69628  validloss -1624.85292±0.00000  bestvalidloss -1640.64712  last_update 41\n",
      "train: iter 926  trainloss -1461.29479  validloss -1337.19273±0.00000  bestvalidloss -1640.64712  last_update 42\n",
      "train: iter 927  trainloss -1540.61514  validloss -1537.54525±0.00000  bestvalidloss -1640.64712  last_update 43\n",
      "train: iter 928  trainloss -1584.92037  validloss -1600.23949±0.00000  bestvalidloss -1640.64712  last_update 44\n",
      "train: iter 929  trainloss -1565.36668  validloss -1540.43930±0.00000  bestvalidloss -1640.64712  last_update 45\n",
      "train: iter 930  trainloss -1505.35445  validloss -1561.12144±0.00000  bestvalidloss -1640.64712  last_update 46\n",
      "train: iter 931  trainloss -1561.87144  validloss -1526.27140±0.00000  bestvalidloss -1640.64712  last_update 47\n",
      "train: iter 932  trainloss -1156.02254  validloss -1524.46905±0.00000  bestvalidloss -1640.64712  last_update 48\n",
      "train: iter 933  trainloss -1495.97118  validloss -1391.99287±0.00000  bestvalidloss -1640.64712  last_update 49\n",
      "train: iter 934  trainloss -1552.09435  validloss -1541.76842±0.00000  bestvalidloss -1640.64712  last_update 50\n",
      "train: iter 935  trainloss -1572.33710  validloss -1553.52661±0.00000  bestvalidloss -1640.64712  last_update 51\n",
      "train: iter 936  trainloss -1544.74144  validloss -1589.33546±0.00000  bestvalidloss -1640.64712  last_update 52\n",
      "train: iter 937  trainloss -1600.12684  validloss -1601.13825±0.00000  bestvalidloss -1640.64712  last_update 53\n",
      "train: iter 938  trainloss -1583.41695  validloss -1467.52483±0.00000  bestvalidloss -1640.64712  last_update 54\n",
      "train: iter 939  trainloss -1607.29961  validloss -1617.96318±0.00000  bestvalidloss -1640.64712  last_update 55\n",
      "train: iter 940  trainloss -1583.38717  validloss -1636.72014±0.00000  bestvalidloss -1640.64712  last_update 56\n",
      "train: iter 941  trainloss -1495.33294  validloss -1427.05867±0.00000  bestvalidloss -1640.64712  last_update 57\n",
      "train: iter 942  trainloss -1578.11708  validloss -1620.38746±0.00000  bestvalidloss -1640.64712  last_update 58\n",
      "train: iter 943  trainloss -1568.44416  validloss -1596.51815±0.00000  bestvalidloss -1640.64712  last_update 59\n",
      "train: iter 944  trainloss -975.23746  validloss -1439.26656±0.00000  bestvalidloss -1640.64712  last_update 60\n",
      "train: iter 945  trainloss -1444.81221  validloss -1390.40406±0.00000  bestvalidloss -1640.64712  last_update 61\n",
      "train: iter 946  trainloss -1538.60419  validloss -1526.89762±0.00000  bestvalidloss -1640.64712  last_update 62\n",
      "train: iter 947  trainloss -1472.53511  validloss -1463.37201±0.00000  bestvalidloss -1640.64712  last_update 63\n",
      "train: iter 948  trainloss -1564.29101  validloss -1500.12334±0.00000  bestvalidloss -1640.64712  last_update 64\n",
      "train: iter 949  trainloss -1569.65411  validloss -1574.63414±0.00000  bestvalidloss -1640.64712  last_update 65\n",
      "train: iter 950  trainloss -1602.46715  validloss -1620.48060±0.00000  bestvalidloss -1640.64712  last_update 66\n",
      "train: iter 951  trainloss -1486.44018  validloss -1602.72134±0.00000  bestvalidloss -1640.64712  last_update 67\n",
      "train: iter 952  trainloss -1494.30599  validloss -1288.16420±0.00000  bestvalidloss -1640.64712  last_update 68\n",
      "train: iter 953  trainloss -1580.08876  validloss -1525.38591±0.00000  bestvalidloss -1640.64712  last_update 69\n",
      "train: iter 954  trainloss -1589.30684  validloss -1621.94797±0.00000  bestvalidloss -1640.64712  last_update 70\n",
      "train: iter 955  trainloss -1571.19384  validloss -1541.52532±0.00000  bestvalidloss -1640.64712  last_update 71\n",
      "train: iter 956  trainloss -1558.87125  validloss -1612.45708±0.00000  bestvalidloss -1640.64712  last_update 72\n",
      "train: iter 957  trainloss -1470.77027  validloss -1596.50868±0.00000  bestvalidloss -1640.64712  last_update 73\n",
      "train: iter 958  trainloss -1393.78174  validloss -1249.67760±0.00000  bestvalidloss -1640.64712  last_update 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 959  trainloss -1583.51218  validloss -1587.69497±0.00000  bestvalidloss -1640.64712  last_update 75\n",
      "train: iter 960  trainloss -1598.83352  validloss -1583.42708±0.00000  bestvalidloss -1640.64712  last_update 76\n",
      "train: iter 961  trainloss -1532.11833  validloss -1612.00940±0.00000  bestvalidloss -1640.64712  last_update 77\n",
      "train: iter 962  trainloss -1559.42325  validloss -1546.30958±0.00000  bestvalidloss -1640.64712  last_update 78\n",
      "train: iter 963  trainloss -1584.04259  validloss -1597.58221±0.00000  bestvalidloss -1640.64712  last_update 79\n",
      "train: iter 964  trainloss -1558.40408  validloss -1599.74087±0.00000  bestvalidloss -1640.64712  last_update 80\n",
      "train: iter 965  trainloss -1586.43548  validloss -1583.51573±0.00000  bestvalidloss -1640.64712  last_update 81\n",
      "train: iter 966  trainloss -1592.99099  validloss -1527.77409±0.00000  bestvalidloss -1640.64712  last_update 82\n",
      "train: iter 967  trainloss -1129.77151  validloss -1454.75874±0.00000  bestvalidloss -1640.64712  last_update 83\n",
      "train: iter 968  trainloss -1422.32656  validloss -1459.81698±0.00000  bestvalidloss -1640.64712  last_update 84\n",
      "train: iter 969  trainloss -1546.86854  validloss -1478.25642±0.00000  bestvalidloss -1640.64712  last_update 85\n",
      "train: iter 970  trainloss -1533.86038  validloss -1572.11720±0.00000  bestvalidloss -1640.64712  last_update 86\n",
      "train: iter 971  trainloss -1575.73331  validloss -1544.12625±0.00000  bestvalidloss -1640.64712  last_update 87\n",
      "train: iter 972  trainloss -1410.78545  validloss -1586.22364±0.00000  bestvalidloss -1640.64712  last_update 88\n",
      "train: iter 973  trainloss -1513.53041  validloss -1336.46604±0.00000  bestvalidloss -1640.64712  last_update 89\n",
      "train: iter 974  trainloss -1569.45779  validloss -1608.85273±0.00000  bestvalidloss -1640.64712  last_update 90\n",
      "train: iter 975  trainloss -1541.82158  validloss -1582.94580±0.00000  bestvalidloss -1640.64712  last_update 91\n",
      "train: iter 976  trainloss -1570.38382  validloss -1492.39498±0.00000  bestvalidloss -1640.64712  last_update 92\n",
      "train: iter 977  trainloss -1549.11098  validloss -1322.68096±0.00000  bestvalidloss -1640.64712  last_update 93\n",
      "train: iter 978  trainloss -1593.11498  validloss -1576.68857±0.00000  bestvalidloss -1640.64712  last_update 94\n",
      "train: iter 979  trainloss -1547.41399  validloss -1612.25177±0.00000  bestvalidloss -1640.64712  last_update 95\n",
      "train: iter 980  trainloss -1595.40970  validloss -1584.14316±0.00000  bestvalidloss -1640.64712  last_update 96\n",
      "train: iter 981  trainloss -1550.34526  validloss -1626.71414±0.00000  bestvalidloss -1640.64712  last_update 97\n",
      "train: iter 982  trainloss -1542.57792  validloss -1558.20114±0.00000  bestvalidloss -1640.64712  last_update 98\n",
      "train: iter 983  trainloss -1589.94159  validloss -1605.92934±0.00000  bestvalidloss -1640.64712  last_update 99\n",
      "train: iter 984  trainloss -1568.10619  validloss -1471.96548±0.00000  bestvalidloss -1640.64712  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.5524) penalty_target_max tensor(5.3255)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGdCAYAAAASUnlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACc+klEQVR4nO2dd3wU1drHf7O72U0CBBACAeliAaWjGGyoaFQseBU7L2C7IFyliIIFLBfxiujlXgt27GLXC0iRoiIRBAlSpChgEAgdQiDJljnvH5PdnXKmbd/N8/18MLszZ86cmV3n/PZ5nvM8AmOMgSAIgiAIohbgSPYACIIgCIIgEgUJH4IgCIIgag0kfAiCIAiCqDWQ8CEIgiAIotZAwocgCIIgiFoDCR+CIAiCIGoNJHwIgiAIgqg1kPAhCIIgCKLW4Er2AFIFURSxa9cu1KtXD4IgJHs4BEEQBEFYgDGGo0ePonnz5nA4zO05JHxq2LVrF1q2bJnsYRAEQRAEEQE7duxAixYtTNuR8KmhXr16AKQbl5eXl+TR8Dlj4jy0EPZirmd8eGPXW4F6zYEfpkjvx/+VnMERBEEQRBIoLy9Hy5YtQ/O4GSR8agi6t/Ly8lJW+Dg8uWCohzyPzBWXkwXU8QDBbSk6doIgCIKIJ1bDVEj4pBFulwM+v+oj27MO8B5LzoAIgiAIIs2gVV1pxCsDe8ALp3LjzlXAuk+TMyCCIAiCSDNI+KQRF57aBCOLTk/2MAiCIAgibSHhk2YITk+yh0AQBEEQaQsJnzTD5aKwLIIgCIKIFBI+aYbL5TRvRBAEQRAEFxI+aUaWkz4ygiAIgogUmkXTjCwnldMgCIIgiEgh4ZNmuCzUISEIgiAIgg/NommGy8ziI4qJGQhBEARBpCEkfNIMU1cXCyRmIARBEASRhpDwSTPquE2Ws4skfAiCIAhCDxI+aUZ+PQ+uqX4Cz/uu4zcgiw9BEARB6ELCJ83Ir+fBGtYe/w1cy29AFh+CIAiC0IWET5pR1yO5ukS9j44sPgRBEAShCwmfNEMQaFUXQRAEQUQKCZ80ZGzRqfo7yeJDEARBELpQxcs0ZPiF7XHGifWBDzg7RX/CxxMXvMeka8mun+yREARBEBkECZ80pUXDHP6OTAlufqq59Peh3YA7N7ljIQiCIDIGcnWlKSc2yEGJ2E67IxNcXYyFXx/+M3njIAiCIDIOEj5pSnaWEyPEsfhJ7KDcsfgp4NPbKciZIAiCIDiQ8EljjmY1xk3eR5Ubf50JrPsM2PFTcgYVC+QWH4IgCIKIISR80hjDul3+6sQNJOaQ8CEIgiDiAwmfNOa41yCeR0jjj5YsPgRBEEScSOPZkQiIBgLBLNFhSiO/rnS+DoIgCCLVIOGTxoiGlpE0Fgxk8SEIgiDiBAmfNMbY4pPOHy0JH4IgCCI+pPPsWOsJ6p4qlqXdmdauLoIgCIKIDyR8MoC+3me1G9PZXZTOYycIgiBSmpQQPtXV1ejatSsEQUBJSYli36+//orzzjsP2dnZaNmyJZ555hnN8Z988glOO+00ZGdno1OnTpgzZ06CRp4a/MXytRt5NbvEALB/SxoIi1QfH0EQBJGupITweeCBB9C8eXPN9vLyclx66aVo3bo1Vq1ahSlTpuCxxx7Dq6++GmqzbNky3HzzzbjjjjuwevVq9O/fH/3798e6desSeQmpB0/4zBoJvNATWD494cOxRcoLM4IgCCJdSbrw+eabbzB//nw8+6zWXfP+++/D6/XizTffxOmnn46bbroJ9957L5577rlQm2nTpuGyyy7D2LFj0aFDBzz55JPo3r07XnjhhUReRurx8SCtgPjlHenv4qcSPx5byMZNsUoEQRBEDEmq8NmzZw/uuusuvPvuu8jN1VbgLi4uxvnnnw+32x3aVlRUhE2bNuHQoUOhNn379lUcV1RUhOLiYsNzV1dXo7y8XPEvo/AeBY7u5u9LdYtKqo+PIAiCSFuSJnwYYxg8eDCGDh2Knj17ctuUlZWhadOmim3B92VlZYZtgvv1mDx5MurXrx/617Jly0gvJWkMveAk4wY8dxcAsFQvYCoTPiSCiFRHNMigThBEyhFz4TNu3DgIgmD4b+PGjfjvf/+Lo0ePYvz48bEegiXGjx+PI0eOhP7t2LEjKeOIhrFFp+LrEedAEID7vPdoG+gJHwoeJojYsHE28FRzYP2XyR4JQRAWccW6wzFjxmDw4MGGbdq1a4dFixahuLgYHo9Hsa9nz5649dZb8fbbb6OgoAB79uxR7A++LygoCP3ltQnu18Pj8WjOnW44HQI6t2iAhrlufHXsXDzBZqC+cDzcQK9QaapbfBjF+BBpwke3SH8/GQScfiS5YyEIwhIxFz75+fnIz+csr1bxn//8B//85z9D73ft2oWioiLMnDkTvXr1AgAUFhbi4Ycfhs/nQ1aWlKRvwYIFOPXUU9GwYcNQm4ULF2LkyJGhvhYsWIDCwsIYXlVq43JI4sAPp3KHv4p/QKoLH7JIEQRBEHEi5sLHKq1atVK8r1u3LgDgpJNOQosWLQAAt9xyCx5//HHccccdePDBB7Fu3TpMmzYNzz//fOi4++67DxdccAGmTp2Kfv364aOPPsLKlSsVS94zHWeN8BHVnkufnvBJcWGR6uMjCIIg0pakL2c3on79+pg/fz62bduGHj16YMyYMZgwYQLuvvvuUJvevXvjgw8+wKuvvoouXbrg008/xZdffokzzjgjiSNPLHU9kn7VWHyO7ga2fa8VEmTxIRKNKJKgJQgiJUiaxUdNmzZtwDgPxs6dO+OHH34wPHbAgAEYMGBAvIaW8jzZ/wzc9OpPCKh17KdDpL9/ex3oLL8/KT4BKb4HFOOT9ogiMP1cICsbuHMhxW0RBJFUUtriQ1jj7HaN8P3YCyEynQll4yzl+5S3+MhJcZFGmHOkFNi7Hti5Sj/ujCAIIkGQ8MkQWjXKhSg4+Ttd6b16jcggyN1FEESSIeGTQWhcXUGcWYkdSLSQq4sgCIKIEyR8Mghdi4+TY/FZNAn4a2V8BxQxZBUgCIIg4gMJnwziQ18f/g6eq+v7Z4DXL47reCJGYfEhEUQQBEHEDhI+GcSMQBF/h9PN356ykNghCIIg4gMJnwzixrNaoxx1tDvSLbiZUZHSzILitAiCSB1I+GQQT13bCfXcnI/UkWbBzSBXF0EQBBEfSPhkEIIgQODk6BF1q7SnAWTxyTDo8yQIIrmQ8Mk0OMJny+7DiR9HNJDYIQiCIOIECZ9MgyN8tu87koSBRAO5ugiCIIj4QMIn49AKBbeQTiUqQMHNmYa8Nhd9ngRBJBkSPpnG+Q9oNmVFK3z8XmDdZ0DFvuj6sQxZfAiCIIj4QMIn0zhvDO4/4QX0q34qtClLCETX5w/PAp/eDrx+UZSDswhZBTIY+mwJgkguJHwyDYcDSyuaYz1rg6m+6wEALkQpfDZ8Lf09XBrl4KxCri6CIAgiPpDwyUDKyqsAAAFItbuyBBH4bVYUPSZTfJDwyShIyBIEkWRI+GQgpzatBwDw1QgfQfQDM2+1drDfq92W6MmKgpsJgiCIOEHCJwN58dbuqJ+TFbL4wGoCw12rgX/mAwsmxm9wliCxk7nQZ0sQRHIh4ZOBtG9SF788egn8wY9X9IE5LdTrmv+o9PfHf6t2JNHiQxNlBkDL2QmCSB1I+GQoToeAi08/UXojBlApOg3bl1f5UF6VKqUtyNVFEARBxAcSPhmM0yUVJ82v2Ijjosuwbf8XfsS6nToZnpMZ40NkGPTZEgSRXIxnQyKtcTilj7eA7VN4G3hs3X8Mgm4Rd1rVRRAEQWQGZPHJYJwud2w6SqYFhnRPZkHWPIIgkgwJnwwmYGWOkU1EghC7Sam8yoev1+zCca/9uKGDFdWydzRREgRBELGDhE8G4604aN6IU82d08j2uYe+uwr3frgaj3y5zvaxr//wh+1jCIIgCMIKJHwymKauY+aNRAvlLCJwTyz74wAA4PNfdto+dm95ZVTnJlIY+jwJgkgyJHwymFM7dDZvxMLCR0gRt1K7xnVDr6t9qbLEnogYwSSyniAIIoGQ8MlgHJ2u12z7j7+/coMVi49FQfT95n2Y8NU6VPmiK4raIDe82DCSGCEilUkNcU0QRO2FlrNnMg4ncMrlwOZvQpsqWI6yjcziw/TWvFt0T/zfmysAAE3zsu2NU3O+cNxROk6Th455US/bBZeTfldoIFcXQRBJhp7MmQ5TWl+OQyVKRANXl/cY8OblwOE/bZ3yzwMWYosMkM+NQppNlL/vrUC3JxdgwCvFyR5K6pBmnyFBEJkNCZ9MR7Vq6xhTCZ8jO/SPXfkmULrM9in9YnQTHZMJMJZmNp/Pf/kLALC69HByB5KypNfnSRBE5kHCJ9NRxfAcU1t8XjkfOLaff6z3eESn9FtKIGSA7HBRtLLcPnWIUvNlKHRTCIJIHUj4ZDptz1O8/cdl3TRNWNlanYP1JyzGGH7bXc4NZPZHLVbSS+zIYeTWMYbuD0EQSYaET6ZT+A+gXZ/Q205tm2ma6FpoDCapeev34PJpP4QCmi31ZxG5eEg3IZFeo00QafYZEgSR2ZDwyXRcbuCckeH3Tm39Lr/eknaDrM6frJRig1Zs02aHjjbGBwrhk17WH5F8XSbQ/SEIIrnQcvbagKde+LVTW4I94K2GA0y7qstfqWkbpF62/lfHF4hSrMgtBGk2T6bZcBMPWX8IgkgyJHxqA+5wJmQ4tMKn7ue34gt3O6XwWfYCsOy/ul3m5YT7YYxBkGXnDURt9ZBbfKLsKsGI6TbghED3hCCI1IGET23AIxM+Tv5H3sWxVblh/sOGXcotPhXVftTLDguhaGN85OKBpVmgM+keM+gGEQSRXCjGpzYgt/jEaGZ2yiw8+yu8in2+aFd1pXNwc5qNNyHQPSEIIoUg4VMbkMf4xChYuNof7qe80qfYF3UeHxnpJiQottmENPs8CYLIPEj41AYcTqBwBND5JqBR+5h0efaO1zDP/QDycAzHqpWFRKMNblaInTSbKCnGhwfTeU0QBJF4KMantlA0KabdXbj7DcABDHbOQ0X1+Yp90Qc3y4qUppmQSK/REgRB1D6SbvGZPXs2evXqhZycHDRs2BD9+/dX7C8tLUW/fv2Qm5uLJk2aYOzYsfD7lRaGJUuWoHv37vB4PGjfvj1mzJiRuAtIR0atj1lXWYIfx7zhz8MBMeo8PkIaW3zSTaglhDT+PAmCyDySKnw+++wzDBw4EEOGDMGaNWvw448/4pZbbgntDwQC6NevH7xeL5YtW4a3334bM2bMwIQJE0Jttm3bhn79+uHCCy9ESUkJRo4ciTvvvBPz5s1LxiWlB/VbxKwrAQwV1VICxDbCbqz13IEhVe9E1Wc6O0ZoXicIgkhtkubq8vv9uO+++zBlyhTccccdoe0dO3YMvZ4/fz42bNiAb7/9Fk2bNkXXrl3x5JNP4sEHH8Rjjz0Gt9uN6dOno23btpg6dSoAoEOHDli6dCmef/55FBUVJfy60gZ3PcB7NCZdVVZKxUzvd32COkI1/s//GU7I2omX/VdjPWtju790LlmR8jE++7cA+zYCHa5K0gBS/P4QBJHxJM3i88svv2Dnzp1wOBzo1q0bmjVrhssvvxzr1q0LtSkuLkanTp3QtGnT0LaioiKUl5dj/fr1oTZ9+/ZV9F1UVITi4uLEXEi6Il/pFQX9nT/i7u/OBko+UGy/0vkTZnseiqxThXhIrzw+Kb+q64WewMzbgD8WJ+f8qS4MCYLIeJImfLZulRLmPfbYY3jkkUcwa9YsNGzYEH369MHBg1L9p7KyMoXoARB6X1ZWZtimvLwclZX6JReqq6tRXl6u+FeraHJaZMdVHgY2zw+9bSHsl158OSz6MdUgt/KkW+2rlLf4BNm1OtkjIAiCSAoxFz7jxo2DIAiG/zZu3AixJsndww8/jOuuuw49evTAW2+9BUEQ8Mknn8R6WBomT56M+vXrh/61bNky7udMKa5+IbLj3rka+GBAbMeiIU3EA480HnrcYOkctUUQRKYR8xifMWPGYPDgwYZt2rVrh927dwNQxvR4PB60a9cOpaWlAICCggKsWLFCceyePXtC+4J/g9vkbfLy8pCTk6M7hvHjx2P06NGh9+Xl5bVL/NQ/EVOEIRjL3rJ33O418RmPHIrxSQDpMk6CIIjYEnPhk5+fj/z8fNN2PXr0gMfjwaZNm3DuuecCAHw+H7Zv347WrVsDAAoLCzFp0iTs3bsXTZo0AQAsWLAAeXl5IcFUWFiIOXPmKPpesGABCgsLDc/v8Xjg8XhsX18mUSk6AcG8XeJJ3eXPD376K/48eAzv33k2nA7ZzTt2AMg9geQEl9T9PAmCqH0kLcYnLy8PQ4cOxcSJEzF//nxs2rQJw4ZJcSIDBkiulEsvvRQdO3bEwIEDsWbNGsybNw+PPPIIhg8fHhItQ4cOxdatW/HAAw9g48aNeOmll/Dxxx9j1KhRybq0tMEvpGj+SkWR0tSaKGeu3IGfth7E6tJD4Y0lHwJT2gHfTkz94GaCIIhaTlJnvilTpsDlcmHgwIGorKxEr169sGjRIjRs2BAA4HQ6MWvWLAwbNgyFhYWoU6cOBg0ahCeeeCLUR9u2bTF79myMGjUK06ZNQ4sWLfD666/TUnYL3HbOycCPyR6FFkVESIoqCcWw5j4o/f1xGtgp/ZMxnNSGYnwIgkghkip8srKy8Oyzz+LZZ5/VbdO6dWuNK0tNnz59sHo1rVKxyynNTkj2EPiksTskjYeeGOgGEQSRZJJesoJIIk53skfAh8lrdaVbHp80mdjTZZwEQRAxhoRPbcaZlewRcFE4RtJsfk4b4ZNQ6J4QBJE6kPCpzSRL+GyeB7x/A3B0D3c3S4PMzYLOarj00T1pM1CCIIiYQsKnNpMsV9cHNwBb5gFzx3F3C3L3VjyUBGPAD88BG2fbPEyeX4jfJkVjsZMLVWcnCCKFSNH1zERCiLHwsT2lVew1bRIXIVFaDCx8XHr92BHLh0lzttmA0mRiT9ow0+T+EASRsZDFpzYTY1eXUS7E9buO4KKpSzB3XZnsAP4RLN5BPkd3R3SYyBhezXoOc93j4GA+nTbRDCxToZtCEETqQMKnNpNAV9c97/+CrfuOYeh7qyy0lq3qSqFJkwG41LkKpzl2oO4e/nWkW4mNhEP3hyCIJEOurtpMjIXPlc6fNNuecL0FrKnAcW8j7QGCju5O0ZgQxYotFtBpk6DBpBMp9BkSBEGQxac2I3d1DfkGGFYcfq8nSmzyf64FwBd3891geq4u+esUmjTlQxF0hU/qjNeYZI0zXe4PQRCZCgmf2ozc4pPTEGjaMfz+jOtjeiq+xkmvNeHyYTl0hE+KDj11oBtEEESSIVdXbUYufFzZ0t8b3wP2bQTOHg7sWQ/sXR+TUzl4ykc3GY48c3PqTJSKeCM94UMWDQ50TwiCSB3I4lObcbi0rztcBZw/FnDnAvcsi9mp+BKnZuuK14Dlr3JbxKdkhdH6M30Uri6RPy6dzalH0gQliSCCIJILWXxqM3KLj7tOXE8lcC0+DqCqHJhzv/S+y41Adn1losD4DCaiw+TxOwLzc9uQxYdDClntCIIgSPjUZty5wJX/BkQ/kBvfSu1crSEIQMAbfh8I5sZJzVVdipGI6b6qK0kDTaHPkyCI2gm5umo7PYcAZ90V99NEGtxcf+9K6cWxA8Ds+4FdJbEemmXkXje9VV2pFJOUOtA9IQgidSDhQyQEW8HNMlpseVeyBH0zFvj5NeDVC+IwOmvI3Vj6y9kTNZp0hW4QQRDJhYQPkRB0g5t5yQrVAc3lu6QVZklGFM2FD1l8OKRoQsrYEFm8GEEQyYOED5EQdIObFZXYg69Vk+Ph0pSYMOUrzHSFT6IGEy0pcD8JgiCSAQkfIiHoBjcrhE+NmFDPyUd2xGtYtsis4OZkQTeIIIjkQsKHMOaOBcCZ0Qc/6zoE5JYTPYtPxd6ozx8LRHmSHp3l7OljSUnkONPlnkRAhKkRCIJIHiR8CGNangVc+FDU3fBdXSqLT40VhanNJjFPYhjhZCUXNXoJDDN4jo8JaSMMCYLIVEj4EObE4FetEzyhIChdRiHrj3pyZJxtiUce3AyREhhaRiF26P4QBJFcSPgQFohe+HC/aJoYH6b8K9te6ePH1CQSBq11Sg2VrCAIgkhtSPgQ5uhZfNx1LXfhErSK4M+DVViysSy8IejqUlsFGMO+o9WWzxUvFBYf3Tw+JCi0ZPJydoIg0g0SPoQ5gs7XxEZ9L6egnfB+3XkE/5y1LrxBR0ykiqtLnqNH0LH4ELUNCm4miHSDhA9hAdnDvfGp4dcVeyz34ORYfBgEOBTWAKmNoA5mjkuFdvsokhPqijRCA8X4EASRQpDwIcyRW3w89QCnx3YXYYEjr7wuKIOeQ64uFfF0j9jpm5kHN6cPJEAIgqidkPAhzJHH+GTnAY3ah96uOft5S10EBY5DIXzAtfhoJmUmQoiX+LHRL+MsvSdMUEd7Z1qMD+XxIYi0g4QPYY7a4tOoXejtoTb9LHXhqonxkVt4RDjgAC9zM285e7yw3rc8tlm/Vle040kQiRjo/i3AlJOApXJxnC43iCCITIWED2EB2a/arFygT01Cw663wp3lRDVzmfbgqBE+cqHDVO9D1gHOcvaYIv+VbsfiI3JEmrqN3KKVNiooTswdB1QeBH77OtkjIQiCCGE+YxGE3OLjdANNOwLjSgF3PXh2HIYPLnhgHPPigIj/ZL2IlsI+ecfKGB+9IGYmxthOIBc+1gOn5S2trOpiLJU9IUkSZbVcCxIEkXxI+BDmyGdvV7b0N7s+AMDjcsJr4WuUBRFXO4sV2xgECLKZ8NcdB9G5FThiJDVcXbzyGjHqmUhbUlbZEgShA7m6CAvIhY9bsSfL6YAXWaY9ZAlaocCYMuZn0qz1wT2qhnFczm4ruFmex8cXj9FkGDxRQHKQIIjkQsKHMIdn8ZHt8lqI8cniuMIYhFDsDwA4grl+NLHNqWHxURZP5R/Xx/sdPndPQAEOUIwP7x7V+ntCEESyIeFDmKMQPsocPgJgyeKzcecBbbdgiuDmsPWHs5zd6ljtYsfiowrM5vFQ5VR0d/yOx7LeIdsGQRBECkLCh7CHKnlho7oe+CzE+LigdXU5BKbI4+OAWFMPy55k+GzVX3ineLutY8LYWM4us/iY6aWGwtHUNm4kZHC1wNWVutHrBEHoQMKHsIfK1XVCHTda5DcIb+gznnuYm+PqEsAUMT4OiAgwZsvVJYoMYz5ZgwlfrUfZkSrT4WuwZfGx3taFgK32BEEQRGIg4UPYQxXcDAD16siKleoULuXF+DggKlxdDjAERAblwnHUBDfzRYQ3EG5b5Yskm7INcaIYlvFxTgRS2+KTtOXsKX1TCIKoBZDwIeyhsvgAkHL7BHHX5R6WJfCEjzbGp8oXwNZ9FaqW+pNltT98vMsZgdshwlVdZrrBpRZvRA0kfAiCSC4kfAh7OLUWH0XAs57w4cX4cFxdzy3YrD3YYDm7Vy58HBa/zoq4DDslK+TBzcbHuVLd4pPSg0snKMaHININEj6EPVycyuxyMeTREz68GB9RkcDQAYYPlpcqtgEwnKTlrq6IYmriZPHhXW+tgxf4S4KLIIgkQ8KHsIeZ8NGx+HBXdaksPk6I8IvaibHK59edMKtlcT2cQy0QWeZmM5HlhEjBzQRBECkICR/CGqdfCzQ5HWhzvnafwtVlJ7hZu5wd0DoPPl1ZWhP0rEVu8REjUT42LBCK6uxmri4hxV1dSYNuCkEQySWpwmfz5s245ppr0LhxY+Tl5eHcc8/F4sWLFW1KS0vRr18/5ObmokmTJhg7diz8fuUkumTJEnTv3h0ejwft27fHjBkzEngVtYQBM4BhP3JXdSmsPJ563MPdFoKbh7u+AqAVFQ6DyVIe48MYgCN/AZu+iZNLRV5Q1bilG34w77E4jIFIKSiPD0GkHUkVPldeeSX8fj8WLVqEVatWoUuXLrjyyitRVlYGAAgEAujXrx+8Xi+WLVuGt99+GzNmzMCECRNCfWzbtg39+vXDhRdeiJKSEowcORJ33nkn5s2bl6zLylz0HvLZeeHXNiw+Fzt+wRjXJ6H3pzr+kk6jTeSja2GRCx+RMeD504EPbwJ++5o/VjV2LD5y3WNSP6yJcBh1p7YCKvZa7j+x0HJ2giBqJ0kTPvv378eWLVswbtw4dO7cGSeffDKefvppHD9+HOvWrQMAzJ8/Hxs2bMB7772Hrl274vLLL8eTTz6JF198EV6vFwAwffp0tG3bFlOnTkWHDh0wYsQIXH/99Xj++eeTdWm1D7nY4S13h37m5tYOpTC41vGDIu4HMF43oxE+QbYvNThKjp0Ynwgm7U1z7B+T0ZDwIQgiuSRN+DRq1Ainnnoq3nnnHRw7dgx+vx+vvPIKmjRpgh49egAAiouL0alTJzRt2jR0XFFREcrLy7F+/fpQm759+yr6LioqQnFxseH5q6urUV5ervhHRIhc7OgIH17mZh7Pu1/Grc5vFduMXF3V8hgfq3OqYnVWZMvZ095yke7jJwiCiJCkCR9BEPDtt99i9erVqFevHrKzs/Hcc89h7ty5aNiwIQCgrKxMIXoAhN4H3WF6bcrLy1FZWal7/smTJ6N+/fqhfy1btozl5dUu5Ku6XB7glMs0TXgWHz06OHYo3gsWXV3Wq6GbV1nnHyYXTJSg0JzasJw9BjE+xw8Cv7wLVNGPL4JIBDEXPuPGjYMgCIb/Nm7cCMYYhg8fjiZNmuCHH37AihUr0L9/f1x11VXYvXt3rIelYfz48Thy5Ejo344dO8wPIvjIrTwOJ3DzR5om0eS1cQjWMjcrLD4GE+zuwzJBbCJgyqt8qPRKoo1FKphSknQffwbxwY3A1yOAr/+R7JEQRK3AvKy2TcaMGYPBgwcbtmnXrh0WLVqEWbNm4dChQ8jLk4JjX3rpJSxYsABvv/02xo0bh4KCAqxYsUJx7J49ewAABQUFob/BbfI2eXl5yMnJ0R2Dx+OBx8PJSUPYR53bhxMEzStZYRWjpeO6MT4G7DxciWbBNwbHVHoD6PzYfDgEYOvkfmBiJgmfZJFG923vRmDj/4Cz79EN2o8Jf9U84zZ8Gb9zEAQRIubCJz8/H/n5+abtjh8/DgBwqMoMOBwOiDXLZwoLCzFp0iTs3bsXTZo0AQAsWLAAeXl56NixY6jNnDnKANIFCxagsLAw6mshLHJiD9MmpwmRW9RiLXysWm627T9W06/kRmMRxgYRMtLpvr3US/p7/BBw2VPJHQtBEDEjaTE+hYWFaNiwIQYNGoQ1a9Zg8+bNGDt2bGh5OgBceuml6NixIwYOHIg1a9Zg3rx5eOSRRzB8+PCQtWbo0KHYunUrHnjgAWzcuBEvvfQSPv74Y4waNSpZl1b7aHQScOci4L41uk2KnCsj7l6K8eHj9Ydjh4zm1GfmbsSFzy7BkUofBIsCRm64YkxdsiKNJvAkUV7lS/YQYsNfP+vvozw+BJF2JE34NG7cGHPnzkVFRQUuuugi9OzZE0uXLsVXX32FLl26AACcTidmzZoFp9OJwsJC3Hbbbfi///s/PPHEE6F+2rZti9mzZ2PBggXo0qULpk6ditdffx1FRUXJurTaSYseQMM2cena0OIT0LP4KI95ackf2Lb/GN5f/id0g5sZA1a+BexQuleDfWdUjE8ChNsf+47zThz38xIEQRgRc1eXHXr27GmaaLB169YaV5aaPn36YPXq1bEcGpFCOAyqXsl0j6Xl7IwBusvZ/1gEzBopvX7siOLHvMgAJmbQcvYEIBgEpacVZNUhiIyCanURKY+Rq0tu5bGynF2aw3QsNwd+1z2OgSmaBsQALn3+Ozw15zfTcxIy0lEwpuOYCYLQhYQPkfIYubrkYseKxccpCBElMGQMYLKM0rsOHcfmPRV49futJkfWZmsB79ozTUTU5s+XINITEj5EymMkfESFhjGfVB2CoOpP/lp/EhMZi3A5e6ZN9LUQcnURREZBwodIeRxgyngRhZXHnsVHbfAxXNUlE0IisyqR0oRkuW/IbUQQRJIh4UOkPBqRwfjZmq3k8XE6BERSskJkTFGR3cgKRRAEQaQuJHyI+OKMPju2RmQwfn0uUSd2R95GcnWB205zXnkeHxEKV1faW3ySRhoKRiNBTW4wgkg7SPgQ8eHWz4ATTgIG/S/qrjTV2Rk/d4/e/OSXCRaHQ1BYbqwiqjI3k8XHHLpDBEGkIknN40NkMCf3BU7+JSZdXeJcpdxg09Xl8wdwvmMNNoqt4BBUosUwxkfdt0xApf20nqwYn+ScNirIqkMQGQUJHyLtYGIgJEqsBDezjbPxjvtf8DMHPhXWQD77MiZaclsF63XJerU77FqI9s5avd8pBQVkE0RGQa4uIu0QRXmMj2y7zgTl2LoQAOASROnHu/yYwzuA964H/lis+WWvXiqvdHWlISlQa8wXsO9mTG3S8ptAELUaEj5E2iGKAdlrvczNsu2yNtK8K3NZfXUP8PsC4N3+mvPIC2WoLT4O2fL6dLQHeBMgQHiSgLxGBEEkGxI+RPy5YJxmkyhE7mWVW3wUMT46c7ncEhSQyqyH3gsVZQbnUfUhiy3q4fsFhY71FkabQjO97Lo37zma7CEQBEEkBRI+RPzp9XfNJkdWdsTdMZG/qkvP1SW3Cokiszz7Ki0+THPYjKx/WeonFbGS5TqTzksQBBGEhA8Rf7JytNtckQsfuavLSq0uhcXHSnrnUN/K12phlX4ruxIbo8S7O5GkEiAIgoglJHyI+MMTOTwxZBGms5xdPtXuq6gOt9FYiKwXJlW8VgkfpnmR4qSAtSUFhhBbKGiJINIOEj5E/OFNDlEIn0BAFtysY/GZty4cuyOfbCWLj/UyFfLXItdawdJG98hJyHzNOQdZfAiCSDaUx4dIDlG4umzH+GiCmy2eR9OH8kC3EMDPnmFwVJdb7CXZpPlyfIIgiBhAFh8iMVz4CNCgVfh9Vm7EXX35y47Qa/nKq9KDx0OvtVmXJZzeCrTc9Q2/Y00eH5U1iSOs8gWl6EmX9HyJ8dBwEhjaiLFKD9Lj8yYIIgwJHyIxXDAWuPmj8PsoVnW99v3vqPRK7i65OHlm7iZN27IjVajyhV1jF2+ciCYHVlg6jzLGh1lakZTSMSxWEzCWfAhsXRKfIcSlV4IgCOuQ8CESh9y95Yo8xseJAKr9AXyx+i9s3X9Mt92hY16cPXkhfvrjQGhb+4NLLJ9HvWLMyqTN0sQCoGvx2bMB+HIo8M41cTkvLWcnCCLZUIwPkThOaAd0vgnIaQAc+SviblwI4PNfduKJWRsM222qSdIXaSV1dYwP08uQqDgmdYWPvE6W7j0p3xX3MRAEQSQTEj5E4hAE4G+vSK9n3hZxNy4EsExmxdHjte+3RnwOQJX4UJXxWQ+t8EkdIeQXGbLMGqXOcAmCIOICubqItMMFEX4L1peFG/dGdR5F5S9NdXa9Y1JXOQRk90zQG6cQ30eC3sq7tCV1P26CIHQgiw+Rdrjgt5WBOVJXl8gYbnYuRAXLgcjOgZUon1Se1v0BufDRIc7CJ6VvEEEQtQKy+BBphxMifCbVxeVix/rS7XDDNTsO4/7XZmNy1hv4r/sFTXV2PVLa4hOwck/iO/7aFNy8uvQQ7v9kDfYerUr2UAiCkEEWHyI1yMoFfMfN2wHIQgD+QHwn0L+/uwoNhPB4mBhQxPzokcrCxy+rcaZreomhxYd/JzItuFn/8772pWUAgMPHvXh90JmJGhBBECaQxYdIEqoJw0YJC6cQgC/Orq5Kr1+5qksULVp8UhdL7kG5KShK6wxPBKanwSe6QW/dp59ygSCIxEPCh0gNbGRyliw+8bYciBDl/3uIfkWx03REHtysL+Lkwie66+UJztrk6iIIIjUh4UOkBjYsPnVRiX8fvhfjXB9aPMLiZCuzdjhUxUeZKFpakSSm8P9SfgueLoWrS+Eaiw3pqXuic1+m5SUTRAaTuk9pIrNRR9faED7XO7/DyeJWDHX9z9qp7IwrdAxTuGpEMWAp+R7HxhHB2eODX1bVXremvFz4RGnxYZwI6vS0+KTjmAmC0IOED5Ea5DS03lTwxnEgfKwGN6dyYpeATHToChBFjE/sLT4ZF9ycmGqvBEHEEBI+RJJQTRhdb7V8pAtWJmT7v9LlFh5BE+MTsOTqSmXbQEAWF6U7zhhafHikpcGHIIiMgoQPkRpk5QI3KWN2jtY/hdvUBb9OJ/xZ1eqqri17K2THqGp1iYEI8/ikjkXAWtLH2AU386BaXQRBJBsSPkRq4HBK/2QcbtSN29Sp4y5RJC0EcKpQCgdEy8JnX3k40Zz6GCaKllZ1xTKPD2MMv+0uj9kKNr9iVZdOI5nrZl+5tbxKevDuROYZfFJH2BIEYQ0SPkRyUMdGCA7AqSyhqSci9FxdDtm0erNrMeZ5xuFJ11uWhySflAWmPDtjiXd1vfL9Vlw+7QeM/fTXmPQXkK/S0o3xCT8Snpn7W1Tn435+tdDXlZ4B3QSRuZDwIZKDQ5U0XHACTrdiE9P5erosWHyC3OpaaPk3ucrGo+zP8qqu2FkAXlz0OwDgi9U7Y9KfPNu17qouGXuOVMbkvHJIAxAEkWxI+BDJ4eIJyveCoBE+oqB0fQXRi/GJpdNBUAkfFgiApXnJCkWMj64CCW/XE5jRQcqHIIjkQsKHSA4NWgF3LQ6/dzg1rq6CBvxsznoTssOGJYiH3CUhqI6TXF2WulH3GslBAACX4Ecfx2rUQWwsL35RbvHRQXYPnELsRQoFNxMEkWyoSCmRPORCh+PqymnZFVilPcwlaGN83PDpniaSWl2C2nbDrAU3a84VhW/nXnyIIe7/YVmgI4DrI+4niCiL8dGPO4md8OEGN2eawYfy+BBE2kEWHyJ5yON8BIdS+HQfBOSfyj1MHdzc37EUm7MH4SpncVTDUeTxYaLSgiT6LcXFaEVW5DP9dVgEAOjt3BBxH3IUFe0tDEtv9Vw01MZA39p3xUSmUO0P4D8Lt2DNjsPJHkpMIeFDJA+HzOKjdnW1PR96UTtq4fNv90sAgGezXonh4JQWH1Fkltw0mhFHMdEHYvy/p1x06Lu6wi/j4uqKeY8EQcSLN5Zuw3MLNuOaF39M9lBiCgkfInk4DSw+gqB1I/QYIh0mEz7XO7+L2XDkGkUd3AzRbym4OZYWH7n0Kj0QXU4dQCV8EuDqqh3L2cnVRWQum8qOJnsIcYGED5E8FK4ubYyPonxC0WTAXQeAMrjZipXH+nL28KRc5fUr8gIxJlqq1RXLGB9RNvLzpyzGRytKI+4LgGr8OuOSjdcVB/tMbXR1EQSRWsRV+EyaNAm9e/dGbm4uGjRowG1TWlqKfv36ITc3F02aNMHYsWPh9yuXKy9ZsgTdu3eHx+NB+/btMWPGDE0/L774Itq0aYPs7Gz06tULK1asiMMVETFF7uoSBKWrSxShkCwOZ0go6S1nr2ZZ3O2WrS4Ki49qgxiwGOOj7jMa4aP833Pawi0R9yUNRS7kdFuFXjni4Oqqjb4u0npE3GAMOLgtbt1nqj0zrsLH6/ViwIABGDZsGHd/IBBAv3794PV6sWzZMrz99tuYMWMGJkwI53jZtm0b+vXrhwsvvBAlJSUYOXIk7rzzTsybNy/UZubMmRg9ejQmTpyIX375BV26dEFRURH27t0bz8sjosWpFj4yi4/oV1p8ZJmd3ZxVXQDgEfRXdllCFsMjgCktPpars8fO1RXrGB/RUoyPzNUVrUrherpq33J2K4KZICJizv3Af7oCP01P9kjSirgKn8cffxyjRo1Cp06duPvnz5+PDRs24L333kPXrl1x+eWX48knn8SLL74Ir9cLAJg+fTratm2LqVOnokOHDhgxYgSuv/56PP/886F+nnvuOdx1110YMmQIOnbsiOnTpyM3NxdvvvlmPC+PiBZ5bS4mcoSPyuLTpGNEp7G+nF3pClLk8RFFiJFM2lH83NfLXB1xf/KxWBiXQ4jDqq6Y90ikJeW7gGMHkj2K9Ofn16W/i55M7jjSjKTG+BQXF6NTp05o2rRpaFtRURHKy8uxfv36UJu+ffsqjisqKkJxsbR02ev1YtWqVYo2DocDffv2DbXhUV1djfLycsU/IsE4VK4tuRBSW3wgAKdfG9fhyLWAQy18mLXMzVojR6pafCwEN0ctUzh3I9P8PpTHxz5V5cBzHYAp7ZI9EqKWklThU1ZWphA9AELvy8rKDNuUl5ejsrIS+/fvRyAQ4LYJ9sFj8uTJqF+/fuhfy5YtY3FJhB3kri61NUX0S9mdg1QfBQQBoivH9mmsT036ri6rtbpiG9ycBItPTDM3c45PR+GTjmNOZQ7/mewREBYRMlTY236yjhs3DoIgGP7buHFjPMYaU8aPH48jR46E/u3YsSPZQ6p9yFd1aYRPQFrF9bfXgZZnA51vlA6pWdllB8uuLoOSFa8s+R2rSw9FcK7UtPhYqdUVlwSGMe+RSD9kk2kcReWBimpM/God1u86ErdzEOmJ7ZIVY8aMweDBgw3btGtnzYRZUFCgWX21Z8+e0L7g3+A2eZu8vDzk5OTA6XTC6XRy2wT74OHxeODxeCyNk4gT8l8TPIsPAHQeIP0LksWv3xWT4SiEj9LV5bQY7xLLVV3qPDjR/vaSW6ys1eqK8oRcV1caBjcb/uo1v0lkMFIhd2EzUUplEQce+mIt5q3fg7eL/8T2p/vF5RyZTsa5pmuwLXzy8/ORn58fk5MXFhZi0qRJ2Lt3L5o0aQIAWLBgAfLy8tCxY8dQmzlz5iiOW7BgAQoLCwEAbrcbPXr0wMKFC9G/f38AgCiKWLhwIUaMGBGTcRIJQCN8dFZoueMnfORxLw5BKXyk8hXJS2AIRG92VjzDLFh89Iq+1joy9OGfNDQ/eOIjfH7bnZnJ94joiWuMT2lpKUpKSlBaWopAIICSkhKUlJSgoqICAHDppZeiY8eOGDhwINasWYN58+bhkUcewfDhw0PWmKFDh2Lr1q144IEHsHHjRrz00kv4+OOPMWrUqNB5Ro8ejddeew1vv/02fvvtNwwbNgzHjh3DkCFD4nl5RCxocx5QrznQ4kzl9gA/Vw+y4hfjoyxCynB/1iehdw5+HmLOuWIU41O2Fu0RW/erIrjZwrhccanOnlkiwmcpxQGhxMDSG8uzZGZ4SkLJ1BifuFZnnzBhAt5+++3Q+27dugEAFi9ejD59+sDpdGLWrFkYNmwYCgsLUadOHQwaNAhPPPFE6Ji2bdti9uzZGDVqFKZNm4YWLVrg9ddfR1FRUajNjTfeiH379mHChAkoKytD165dMXfuXE3AM5GCDPqfFM/jVH0VRR3h4z1m+xRWY3wYU8a3nO34LfT+TMdG/MXMLZ0xW9U1a5R5G5so52jz4GYhHhafDNMJh497kZ+Zc0P8MHJxE0QCiKvwmTFjBjfLspzWrVtrXFlq+vTpg9WrVxu2GTFiBLm20hFBUIqes+4G1n8JnHUXv/3+zfZPYXG2lVt81IVQ73V9afu8ACK3+MTDMiKfZHT6ZyxcKCMuFp9MUz5EBCTI4hO3nlOQDLOkxpu4Ch+CsM0VU4DL/gU4YueFtfoAzD/+e+i1I+IJOvIYn3/O2gCnU8D4yztEeG5jFHmIdB6UoshCERfRL2fPkOBmHRhjFh2gRIhfPwE2zQ6/j6uriz6baMnUO0jCh0g9Yih6AOsum+4Hw5bHSJdyRxrjs7+iGq8vlWru/OOik1E3DpYRURndzG0TEMWQ8HHEY1LKoB+mVn9k049xGZ/fqXxPFp/YQCLPFlSdnUgvmnWxfUgkIiZy4aPC4oPdHwjPjpvKjsZFH1hJYBiQbXfE4VmaSa6uzLmSJJJBFkAifSDhQ6QXA942b6MiEreVE/xCqGYYLWc/ctyHh75Yi1V/GidCvO7lZTh0rDqi8xuh1Dp6Fh95gHdk98D6GNIEnV/TkquLiIq0/EKkIHQfbUHCh0gv8prbPsR6kdIwsXN1hV9OmrMBHywvxXUvLzPtZ9/ReAgf8wSGYiAsdiKPczIcROz7jDd6geAJHkZGEk+LD3l/oidD7yEJHyK9kBc2tXpIRK6uSC0+SuRi4499+kvxE2E7UCxnNwhuDreJR4xP5siFDLqU5EExPrGBYnxsQcKHSC8iCHyOxHLxpnuK7WMAKeOzHDGFZkelxUc/uDncKMpJifMsTp27ET3k6IoBtKqLSAIkfIiMx2qdLTl5QmVMzq3MBh3mhy37FO/V+oj3yI72OS4/h6Br8ZFVqI96UuIpn8wRCxl0KcmDgptjA30ZbUHCh8h4sqCTBToBhFZSrf0Ujxx6BPUhlWsZ+MYKHDrmDbVLhGVItJDHJ6Bwh8U+uFnMMCsJ5fGJkhRzdR33+lHpjf33Pl0RMvT7TcKHyHhObuRO2rlDFpTP7kA37yqMdH0W2ne4MlyIVWvxiW+dLD03jSjKHvoU42NIBl1K8kghi48vIKLjhHk4feJcxerGtIDcerYg4UNkPPUcOpXeE4C6KGdDgV8x2uxBu9RzL04Wt0Y1FtFCHh+5VSguWZYzSC1QjE8MSKEipfsrpJWUIpMsP2lFnP6/ytTvOAkfIvPxxSZeJxJEiw92M1dXC2E/JlY+gw9XlEY+GHlws66rSx7jE4HJ/+gew4dwJj1GGbPm6oqoIv2e9cCHNwNl6yIYWRqRQkLYIVNK6WbwIexBwofIfHzHk3bqap9SPOhOlJWH0QTGiQ1zhGqM/3xtxGNRhvjo5KaRN7L79F/1NjD1FODbiTUbMjy4OZ6dz+gHbJoDvHV5PM+SfOIa42PP5KMoGp9B39NooBgfgkhX/FVJO/XsX3dZatfuzdOxIns48mqCn3nTaiT5iOQoYnz0LD6KVWjK8+08XImKagMXwNxx0t8fp+mPIYNsPnGdHCtrRHB1efzOkQrE8R7adXWltcWHYnxsQcKHyHyS6Ooqr/Qq3sstPpv3HMWr3/+BKplVqK1QptuXnXxELy7+HZc89x0OVIQzQFuy+Mi2y11dfx06jnOeXoSe/1xgeQz8/qM6PKWIx6XM/LkUW/bw48AykhQKbpZLh1TKv2WJdBtvkqHq7EQtIHkPBaPfYX9/dxUA4HiVFyNrtgVqfovwjrMjfKbM2wQAeP7bzfhn/07SRisxPjqZm5dvPQgAqPJFO1FlzgM6HnPNg59Jrszt2bHvOyVJIeEjJ+2ET5zIVEMSWXwIIo44wBQWHR7rSveHXgfgrHkVG1fXVlmZDOWqLn5fimBseaBzrB6AmTShMGsyLoOuOPakkPCRf046eUeJDIGED0HEFYbTHp0re6fFLYTjZvw1wkcdFA1Elttn5+Gwm0/PjSWH6Vh8IhI+nIMyKWg0k+KVkkYKlayQfzUDGfQ9JbSQ8CGIOGJFrMgzS4sGzjGFq0sMAO9eC8wdb9j3X4dkwkc+Lj2Lj07JCoelSUTVhjN5ZNJ8ormWTLq4RJFCmZvlQlZMu+hmwg4kfAgijlh5+P60JRzQbCSUFMJn+1Lgj0XATy8Z9i2P2ZFbc3QtPjqurojgXnw6Tig6geBQpScg4WOfFEpgKP+Y0y5zc5zI0BAfEj4EEU+0Qkb7KMmSubqMApid8hifgHE26uys8P/a1X5J5MhFjaATLxSQb5aJo8gqXWe4q4sxVV6mzLm2hJGiMT7k6spsSPgQRByx4uryICxigsKHW51dLlZMdEjD3HB9sqC7Sz7FWLH4yCu4OzL1p58l+Bev+WRpsrRPCt0z+VDI1ZXZkPAhiDiinjJ5mZuzEBYhRiu3rC5nZ4wpTPXHq7UWH4fuqi6d4GbZuKOy2qTQL3zr6OU8irQdESKFXF3yGB+y+GQ2JHwIIo7YDW4OCh/ecbrCZ+nzgF9KlPjJyh3o/uQC7D0aTlwYfIjLn+V6ri5FcDPkwc2yNtHonsgPTTk0q7posrRPCpWsUKzqIosPAMrjQxCpQ6OTkz0Cy9gXPsH2HOEj6PT17WPAilcAAGM//RWHjivjf8SQ8JG5rnRcXQoTv8hfzu63mOSEO9q0FAc6T38GMJYBMT4H/gA+GQzs/jXx504pi08YyuOT2ZDwIdKP2+cBN7wLPLofyG1k8SABGPJNXIdlBd6877YY3Bzug2nEjVEV76CYUQgfiNw4BrmrS2kVCs8iju+eAd7pH7Iy6Q+UN3bjQ1ITo1Vd8g1peXHABzcC678AXrtQuf2TIdLnHKvr4vVjU/gcOubFk7M24Lfdsa9hJv//g1xdEpl6G0j4EOlHnUZAx6sBZ5b1Y+o2AQo6xW9MOkTq6jJCZEDpQesV54P6Ri5qnGDwcX7Wiool73xXV9YPTwNbFwO/fW1yZk4en3S1inCwGuOT8hzYIv0VZQVoGQPWfy59zvu3xOY8MRA+j3y1Dm8s3YbLp/1g2lYAMMU1HR9m/VPKe2VjeOTqigx/ID1MZSR8iPSmxVnW2jmyAEfiS9PFQ/j4RdHWHBvQsfj4A7wEgzYSGJpUvde3k2QGDAyi/BGqV/g1Ha9ZcS2xGn/0wmf9ziO22g9wfY9C5wZg5y+2jqNaXRJ23IWP/289Ok6ch9ID1n+UJQsSPkR6c80LwDn3Aefdb9wuKwcQnLq7RRafKD5rq7q0ri6j0Ui6x/qDmXFifJwQ4eP8OtNd1RXR7eEcFMv5xCiX0YE/gO+nAFX2Jko7MKZ2daXHr11rxGHij4HFJ7J8UlBas3Qgi090vPXjdnj9Il5c/Huyh2IKCR8ivanTGLjkCaDxKeFtJ12sbZedBzhkwufmjyQrUA0+6IuiaLBiwXHLhY9eALOMAGPalVWqCSEb1Rjt+hhnCFtDbdUWHx/P4qOzqisSeFfCYiUOtn4HPNkYWPYCf//LvYFF/zQt6REJVb4AHvz0VyzYsEe1J4Mmy0RZPOIpFgV7gedUsiI2pIOFk4QPkRkIsq9y2/O0+z01wqfvY8C5o4FTL1cIIcEZHzeYXYuPELL46D88AgEGL0e0yBnq+h/udX2JWZ5HZMvZVa4uXoyPopCpKNvOOYl6crTwazxm8+mXw6S/8x/m7w+64f5cFqMThpmxbDtmrtyBiV+vz+CSFfG4lsRGuyu+jTbPQ8HNEnZTAqQLiQ96IIh4ILfm8Fxa2XnS33NHhbfJYlSystxAtXHMSiRYivERwoGXTgtWlgBj3Ortck4W/gq9FhkDKg/j4e1DFOfhxfiIOtXZYxfzEMcVQgmi7Ije9ySDJst43N9YuLrstFUqH9P25OqKDemgGcniQ2QGp14B5HcAug3kBzF78gwPF+IW+KxZ9KwhkuBmX0AtfJRTQhXCJStEkQGr31XsdwgsVMNLMVrZU+tG35c4vHMLIIqRZWtOhQdgnDOwWbH4pMpEYO8zTJTFx57wiXhUFs6jyOOTKh8aERdI+BCZQVY2cE+xFOzMW+aeXd/4eDtL420gQJmbh/c45Scw1EcUgSqf8kG+49Bx7D0atkRUs/D18H68OiHiSKU2OFhUub8avNYT+PyuiLI1p0QCw4SeL3Uny9/3HsWZkxbirR+3WTsgRS0+drDr6lLk8cmkOHUbZFIRYSNI+BCZQ/DXfZtztftMLD7xegALYIZWnCz4Fe4tKzE+flGE16/sc/m2g7jxlZ9C76tlFh+e2d4JEYfVSRCh8+Bb92nMfgFn9IM1ha/t0S/XY39FNR7/3waLR6SmxSdy+52V4OYwtdHV9fQ3G9H76UU4UBEudxOJwTQd7hwJHyLzaNIB6Pu4clu2ifA5ti8uQxGgjNu5ybUEJ0I6Vz4OYZVnKB7Jej+030qMjygCXr92ee62/cdCr+WuLsYY9shqdwGSS02T/RmAqFu81HRYGrjx0Pa7sdF74rGSxycVsB2smwGrupQWHwuuLtkl10ZX1/Tv/sDuI1V4Y6lFq2AaQ8KHyEzOHQl0uCr8Pq+5cfum8cnqzLP4/Jh9HxwQcbNzMfIEZbKvcJFSffyiCJ8quFn9nK5G2NUVEAPYvl95Hsnioy05wXQUTswsNRk2oTCDdymF7aGlqKvLhgVC4Ta29L2Tu7pS+LOMM9FeeTr8L07Ch8hc5AHLJ7TTbyc4gCanxWUIAhgecn2g2d5a2INj8HDbmyEyBn/AOCFbFQtbfAR/FVwO5YyhG+Oj89SK5Bcw/5Dwxt/3HsXGstjXXEoaupmb05C4zF6JjvGRn8/eqq50sPjIy0Ok/mhTCxI+RObiDbt+0LCNfrtWhYZZnTWcN8Zy086OrRjo+laz3QMfKpCr2W4luDkgAqKJ8JFbfATfcThVwkdydXEsPnrCJ0bzUzBBoi8gou9z3+Oyf/+AY9XmWXW1HaXGo155V1NjTLEhRS0+NlDmL8y8GJ+dhyvj0q/8VkUW45P6946ED5G5HN4Rfu2pp9/O4VLmAeIhF0Zn3ml5CKc6/uJud8GPCpaj2W4lxue7zXuxYtsBy2Nw+I7D6VT+r+6EiGPV2uXsehlrY/ULOGipqpYFZ/MEWFqSImIsJiTM4mPvPLby+Nh0daVbHp9MTS6YCEj4EJnL4VJr7ZxuZeZnHvJfpk63fjuLZCHALZMRrtWl/+B9as5GjWVInRFavl/P4nPcq7W0MB3hFVkaH+2D2V8TlJ1Wq7ssjzWNrsmUDLD4KE9k2l5RsiINvp9xTlEVOal/60j4EBmM75h5G0DK4WNm8ZH/3xyDnD8uBLhuLav1scyFj6yyeqBaIzScEHHcGwBjDPPXl4UqKusFN1tbFaQt0KHG7/dp9kRWeDI1nq52rQppQyas6hKisfjEYUAxxm5maiIMCR8icznjOulvt9uM2zlc/GzPeji1Qcl2cQkBrlvLisUHMHeJyYXRjgNHse+o0p3kEkRUegNYtHEv7n53Fc6fshiA/nL2Sq9xiQyrBIIWH9lpUt76Y1WY6dy7hFzen8XA9h+Bt67QL9xqi9QMbrYjkhWTm83l7OlQqyviSvUmRBujk/p3Ls7CZ9KkSejduzdyc3PRoEEDzf41a9bg5ptvRsuWLZGTk4MOHTpg2rRpmnZLlixB9+7d4fF40L59e8yYMUPT5sUXX0SbNm2QnZ2NXr16YcWKFXG4IiKtuGoacMO7wBXPGrdzZtkTMzFwdblViQtDXQvWJgK1ZUj9sJELnzlrduD7Lfs1fVRW+/Dz9kOKbXpBzBUWApCrNWU0tI/AoPBJh4klRKq7uo4fBN66DJhxBfDnj9zCrbYnswzI3Kz8PGy6ulIkxkcUGX4pPcR1SwsG7whj4ip8vF4vBgwYgGHDhnH3r1q1Ck2aNMF7772H9evX4+GHH8b48ePxwgvhXyzbtm1Dv379cOGFF6KkpAQjR47EnXfeiXnz5oXazJw5E6NHj8bEiRPxyy+/oEuXLigqKsLevXvjeXlEquOpB3S8GsjSBhErcGQBLhtixmH+vw3L0q7YkuOCn5vR2cpydsB89Ze8b5eOmKr28TI389serdK2VU8mXj8z2g0ACNQEN6dD8KgVrLi69ldUK7LhxpyKPTHr6qMVpbj6haXYVxH7gr1JXc6epsHNH6woxd9eWoZbX1+u2Zeqrq6Ut+AiztXZH39cyp7Ls9AAwO233654365dOxQXF+Pzzz/HiBEjAADTp09H27ZtMXXqVABAhw4dsHTpUjz//PMoKioCADz33HO46667MGTIkNAxs2fPxptvvolx48bF49KITMLpion7So5w8QRgrv53zwVjV5cZdoSPEwFu62qvV+PF0XtohVdh2XmocSw+NcJHHjwa0XMykVYYyy4F/rnq4jg2vTUMvfsPBVqeFf14NKeN3UQz7vO1AIAXFm7B4yZtbZPg6ux2XV1yUiW4+eOV0srU1aWHNfsUq7piOdzUuPS4knIxPkeOHMEJJ5wQel9cXIy+ffsq2hQVFaG4uBiAZFVatWqVoo3D4UDfvn1DbXhUV1ejvLxc8Y+opdi1+FjBZJVYFgJwcCwxVqqzA+Aeq+wn/PRy6fRZ7fNpJhK9B74vwDT9RsLR49X4/Je/FOdJlV/XulidBHXajXXNRO8DnwFvXBLDQcWXKkVMVxzdKKnk6kpBi4914jVe+599Oty5lBI+y5Ytw8yZM3H33XeHtpWVlaFp06aKdk2bNkV5eTkqKyuxf/9+BAIBbpuysjLdc02ePBn169cP/WvZsmVsL4ZIH9pdALiyY9unycqvJ077E12a19UeZhq0LNb8NVnVJSgtPjy8Xp/WmKEzEQWzxFp1xenhQgCjP16jmFji++s6kbEP/OtoL+xK4BhihT3REJvzxBalxcdejE+qxKAZfXvl42UptLY9RW6dIbaFz7hx4yAIguG/jRs32h7IunXrcM0112DixIm49NJLbR9vl/Hjx+PIkSOhfzt27DA/iMgsRq4Fbnwf6NjffsCyWd4fEyF1wtavcVsHrac5KCxancCPSxp7QQEAc8uQ0uLDFz6iGIBf9cs2oPPQCrazZfHhPAGD45YHUUcmfFIw4DiFn/j2h6ZYdhe3QbBYpQTn4BDsiTdFyYo0sPik6hBTdFgKbMf4jBkzBoMHDzZs066dQV0kDhs2bMDFF1+Mu+++G4888ohiX0FBAfbsUQbv7dmzB3l5ecjJyYHT6YTT6eS2KSgo0D2nx+OBxxPbuA4izWjQSvoHAC7Zd6FZV2B3ifGxjiwgYBCw6rLw3Sr7VdttzWPDqfMDbvAvA/AvvGjZMgRIViSeUHJCVLk0oLusyxcji09w3PJf1Kn6ALeC3XpQ8SEeK7Di0T9H+DAxbjY5ZckKC8vZZa/VPwhSEUU8XpxEdwoZkmKKbeGTn5+P/Pz8mA1g/fr1uOiiizBo0CBMmjRJs7+wsBBz5sxRbFuwYAEKCwsBAG63Gz169MDChQvRv39/AIAoili4cGEoQJogTJEHN3e5SSt8nB6l0HGaCB8rwdIH/tBsClVn13ng5Pik5edqAaJ+7DlVFh/u0nkw+FQPeD3riz9gLb+QHF7boAsuFWJ8xn/+KzbvqcDMu8+GyxkDr38KW3zsE4dJNQYWHzsTsf1VXam3nN2IVP26pcOqrrjG+JSWlqKkpASlpaUIBAIoKSlBSUkJKioqAEjurQsvvBCXXnopRo8ejbKyMpSVlWHfvn2hPoYOHYqtW7figQcewMaNG/HSSy/h448/xqhRo0JtRo8ejddeew1vv/02fvvtNwwbNgzHjh0LrfIiCFMUwc2cp2tOQ+V7s4SHVmKGDv+p2RQSPiYPDzOXk6Cy+Dh5IgQiPlgeLuuxfOsB/L73KLc/v2hs8eE/7LTbXCFXV6JifPT5cMUOrPrzEH7aejC0beu+CtwwvRjfb95ncKQOafDAt4ziWuJn8RHF2CTG5GHXWCEfXcJjfCoP862tVpVepppm4kRchc+ECRPQrVs3TJw4ERUVFejWrRu6deuGlStXAgA+/fRT7Nu3D++99x6aNWsW+nfmmWeG+mjbti1mz56NBQsWoEuXLpg6dSpef/310FJ2ALjxxhvx7LPPYsKECejatStKSkowd+5cTcAzQegit9DwHiK5jVTtTcpWWHF1BbTFOR1guOlM80B7WzE+QoAb4Ky2At346k+6k4XPxOITEK2lyOO6uiIJ84jhxOST1ScY8cFqrNh+EP/3prUEqKnh6oo9cSnFwbX4WBA+fywGZlzJtZAaobwGm5mbE1myYt9m4F+tgXevsXVYvLSZXrdWLTnp8H9BXPP4zJgxQzeHDwA89thjeOyxx0z76dOnD1avXm3YZsSIEeTaIiJHIVR4wucE5XuHmfCJbJXY37o1R5urTgdeNm5nJnycGouPTpZo1VNKT9gELT56liauZ8AguDlxq7rMkZ9/79EoEg3qXEc6TARqWIIEnV6JFAXv9pf+fjIYArThEHrYXdUlv86EfidXvyP93fa9ZpfVVV1xi/GRn49ljmEppZazE0TScBlYfJwe4Mw7pNfNu9dsM3N1RRY436FpHeS4zQqm8gSIcsxN6oVdd5c5VmBU1mecPqz/rNWz+KzYdhCjZ5Zgvyoz8aer/uL2E1xhFmldpGPVfgx5awWq/LH7Sa6MMbI3gditAB4X4l1eImb98yw+NvqusJuJP/JVXRHHnc2+H/jynsiOtUmify9YPl0aKP24WnwIIm1QuLpUvweGfAOc2B24cxGQf4q0LRYxPjxY0PSv//Rw6lR2l3PhKY2ANTWvnWu4bXjL3HUtPqFVXUpueEVKEnqk0ofnZdvv/2QNZjawaPGxMcnMWLYdizftwzGPD9kx+vWptD5F0VEKx/jYHVlcXHg8V5edBIY2zQ22g5tlryMSPr4q4OfXpNd9xgMNos8NZ3TJif62Sa6uzDD5kPAhCEAZ3Bxc4h6kRQ/lX8A870+kmaAtPKA98OkKHxf8eDNrCuqsWWvajxtmhQ/DBJf3qoujBtmyt0LbF+daIl3OHhAZbnilGKv+PGTe2CaiYn6MSvlEPZZUQRnbHEeLj52+GbO3qsvucnbZUKLOLcXiF7QdOoVijLETJHqfidU7Em1190RAri6CAJQWnMYnAyZFRs2FT6QWn5oHtMGDNxtejZsqmLn5EscqnO80Fz0A4IE2uFrP4hN2dYWRV2z3WYwGdXJWdQV/XXv9IuatL8OR49qCqOt2HolM9FiYwKLJKWQ3gFbB0T3Ap3fYOyZBJMziE8cEhsr4FHMhIp/w06FkBTN4F5fzpf4tsQwJH4IAlEKlfkvg8mek173/wW9vVvE9whgfK5OnZPFRCx8JN3hV1Plkc9sau7rk5123M1zfThI+5r86Q8KHY2WZtnAz/v7uKgyeoV1RFeugSr2cLVEFtdo9dtYoYN2nkZ8vniQqxieOs6ncKmpFYMlHEtH3IMHKINH5cqxactJBIJGriyAAoNFJwBXPAnknAg4n0H0g0L4vUE8n+7eZRSdSi09wee8R/RIq2YIXFzpLuPvUNbuMyBa8nFVdfMKurjCfr/4LwMkAgP0VXsBj/sRzCtoYn+KtBzB77W58sXonAH4laodK+ehbpkT4AwwhWaqjmHQDWaN6aNs8+NC2aE4W+XktIRcKcVzVZSuPj91x2LPGRR/cHB/Xk+7ZYvW1jeB8AICl/wZ2rgQGvC09M9MIEj4EEeSsu5Tv85rptzWz+FjJ3Myj5APgh2cNmzTGEXR3/K6z14bw4bi69PAFRNRBJbo7ttg4Ey/GR5ro5L+o/7tI71pkxzmsXdeA6cVYu/MI/gh6Ii3EKyhdXXZXdZlbRuyI0Xhh1zqgGHHMDD48i4/9bkY4v0Bz4QDArjA0BSotPhZcXfIipUnOLRXEeDm71Zb2sHwZ306U/m6aA3S4yv7xSYSED0FEgp5Fp9dQ4Ox7AIeBFzmrDuA7xt931LyS9wmCNrtycHK1U/nIw3F1GVlSPnI/iU6O7aZtgxw57gVUPwSDri6rMUFBXBaFT8mOw7r7jlX74XQIyM5yKgSO3NUV3TObf3S09c2iomwtUPIh6orn2zsuwszN63cdwdx1ZRjW5yTkutXTS5SrugAIgoD7sz6R3uxeAzTvqt/W7nmiDW62G+MVJcohxuc7JteVurfEVxmXc8cTivEhiEjQEz6tewMNWxsfe8a1UZ16pEubkyeILeEjWA9u9geYQvQANiu1h44JCh+bFgjVZcnfjvtMW+xVTbU/gNMnzkPnx+eDMaYUPlFMeErLSJIEjtF5p58L/PQi7jxqkhFT26m1/lX0+89S/HfR73hu/mZOlzGO8fFXGe4WbFt8pP+Odn2MHofmmLTW7yGWCAYWrVRdPZWq45JDwocgIiFLR/joCSJ5pufj0S3J7uAo1d0n2vhfmufq0i9ZYT3nTxjt/mCtrrveWWl4pCgyvLj4dyz7fT8AY9fDRz/vQJXPeGLbfViaJL1+Ed6AqJtAMbrFPElydVmwNLTxRxNPZP+mrNt1xFI/lkpWREgky9m7Cn/gXteXuK3sX/ZPmPDg5oSeLi0EjVVI+BBEJLh0YnyMlrn3GALUbQp0vCY+Y4K9KYovfPg9iJxVMdq21ld1mTF3fRmmzNuEW15fLp3f5Clvtl8eIxQQma6rK6pne9KCG/jn3VhWbtLCqEvZ5xTBdVktYcIYAwI+YONs4PhBzkGRo/h+6qzqqvIFMHpmCf63ZhcYGBpy3MiWidjVFZkwVt7O+IhrQdav1a9BOsT4kPAhiEjQtfgYBDVf9W9g9Eb9lWLRDAd+5KAKdh6AvBgfPVgEFh/efqtlMnYcPK54byZs9F1nNavRZLfFLzLdFTymv2pLPsSotdeig/BnTb/xWPZtE50Jt9oX3m7HEljTqc5ri0dbLWjJGPD9s8BHtwAz+pk1Vm0w/q7Lr1jPsvT+8lJ8vnon/vHhajBmr4xL7Ijse5OIWl3K82UOJHwIIhL0LD5m+XscDvPK7no066K76ybXEvyWfTvqwHqgYTY3xoePX9RmeTaL8eH1ZWbxaY79mOh6Gw2qlLW+zNKw+AOiYekLeayEP6CO8bHh6vpyKOr79uAz92OcBJDJEj78zdlZ4chy+y68KMO8uYfzXF0snMto74ZIO+aiiPHREYfyGnMMkcWthTuIoWhiDFj5Ftr7Nhk2SSSZVJ2dhA9BRIKexUe+jP02nSBks8ruuuesY9qkp4MTVKqDkavL71AKOAfnoR7JaiUnpz6YnDfdUzDENQ9XrB6q2K62+KjP7Ze5rzoJWxUtAeVD2x8QFUJAYfEJtTO+tlyhGnPc45Ubg8ce3AZ8dlfIKhR3dCZchXuPdznbfwQWPsE9Vm7IiszVxTkm2lpdsO4qBeyv6mKMRSl8Yjjlb54HzBqJfx0cGbs+LWJsO+XtYEZvUxISPgQRCZ1v5G/PbRR+3b4vv02kFh8L2aADNv6XzgVvVUzN2hZBuQ6dN+GYW3y0+80mrtMcUuLGelXKZf3mri4R4o7luN35Df7neUS2p+Z6ZIf7RKYsTxBhcPNJjt2qLTUHf3QrsPZjfO1+RHNMfNAJqlZcI6fBjCuAH6bqdBmdq8vqfbQnfJhNsW0e46MQR4g29UB090zBvt/Mzyb3dMU6tXkNlpaza0h95UPChyAioV4B8NBu4J6fwtvOvMsg6aHsYRCp8LHwcLOznL2Pc42m6GjoaFX1eZ7IUU8SVh53DsH+Q1G9/Jx3bn+AwT3jMkzIepfbh9yqEwgoY3x4LrKIalUFO61x2WQJ8S9UqTivCrmg89v0wkQbP8J1i3C21d1dHLH7yryt7NTqGB/GgA9uRNHWp2TboozxUQSE6/fz9Dcbcclz3+FoVTDGLjLRIv9/glcQOOYwAOW7gJVvAV5ZDF6cRFc8oQSGBBEp7lwg/zSgoBNw5C/g4gnWjlNZU1A4Qurn6xFRD8lOEGtz4SAa4Sj2o354aEELiSoFPW9CiCS42WXi6uLhCzBTC4LfJAhIPkn4RFHxnrdU3uqjXC2QvH4Rbo0gTM5ydvktsSOIAfX1x8riwxE++9fY6FWwJZyVgeeqe7RnHbB5LqSouRtrRqdydTFmb1K3WN9s+nd/AABm/rwDd57Xznr/6tNFfKRJvzodMzDgtYuAo7uBfRttH59KkMWHIKJBEIC7lgAj1wHZedr93QdJf/uMC2/jVYpu0jEuw9PD55SCsx+8qCV6tG6obaCy+PBcVD0cm9FZ+CP0Xj1FRBLczMNrErgMmCdElAsdv0pImYkmqzLole9+xymPfGOpbWzhX7v8mu3HNke7nD0esx9TCnATUaIUMarPmBOsL63qisbSZa+9P/QljOxesWg+34jOB0n0AMCW+aod6QUJH4KIFqcL8NTl77vyeWDYMuC8+8Pb1GZ333G+aIqALGgf6Nx22dJ4B3RuiCxneAIJWjAEC66uy50/42vPo3BZPKfUj33hU+0LKNw2PPymwif82hcQlcHOMXJ1LdxQZqldzNGz+CjumV2LTxxifGIwQVq1+Dy/YDN+rEl+CegvZ6/ZK/2XQen6tbtKK0qxaJdEyw3F+QyuLx1kEAkfgognDifQ9HTlr1N1SQvvcfOip4Clh6nbqghx16wQ8x1HljP8GAiOUnCqhY/+JKB3zli5utSZlnn4TKw2ihgfUWXx4fi6rMaSyNslLdJBJ55GmZcxitFZncTXzMQljpU1h3CVT+RjqMHq5zJt4RZVAVn970fIvQsTK5EZNgPCo9VGyV3OLnudhjE+JHwIItFk1wdGrg2/9x0H6jSJSdc3uL6z1jC4NN5bgbPbSSvRclCFBkIFAK3Fx8hFZceKUw+VtixEgFRmQhvcrGT++j2GfShcXaKoCN61WzdMD8Fu4HbMZi6+8PHKIprtu7psWnzKdwFf3I3X3M9pD+f2GQGM2QriVdbqMhI+we6ZZbHEH18U1qKIML8XlV77PzT0knjqno1cXQRBWKJBq/BrlwdwuYHLpyTu/EGLj/c47jqvHSZc2RHrc/+O211zAXAsPgaTukP2i1kON3OzwFAgHLI1VK9fREBkcMGPN7KmYJjza02bb9apl5Yrkc976mDpANfVZZ9EVWH3B0T848PVeLd4u7SBM8kGRBE3vFIcem83c7NSAFi4rkr5Z6pdhRfcHi0R59mxavExCog2P4nspQWLT6h9LEpWaHnky7XoMGEufv3rcET9G57PyNWVBkKIhA9BJItrXwGadwP6Pia9r9PIsLk64DgqQsLnGNwuB24/ty0cYriEhTbGR38SMEtKqGaBeyzyUGG5fbVfcnVd4ViBi52r8WDWR5o22S4n58gwwYm4AY4i4K1SBEsHg5sf/NSkyntAa6mKysgfoYtg9trd+N+aXXj0q/XSBs5Ec/h4teK93VVdyl/9yv73Hq3CWz9uw5FKWckT+dJqPZtBDCZEO1ehzNys/x0NCXemFnw2rSVR5j6yi9kZ3vtJKmY87dstkZ8j9TVMRJDwIYhk0eUm4O4lQP0W0nv1Mnc1lzweu3MHhc8XdwOLn9IkeFNbfIxcXe8M7m7r1DmCF8NdX1luX11j8ckWqnXbuF06j7KaB3eAMTREOUqy/44zvzhXmdCwxtU1c+WO0EFTsqZr+5ozxnCcibL4HKhQZdy2kFXbboyPkcVn0Js/4/H/bcDYT/hL0QXEa1WXWoAbX5Nir6GrK7y6KnauLjsxPpGu6oroMJ2+9NxbjPtagUrAp4NWIuFDEKmCoPrfse/jQKcbwu8bnQyM3YqY4JaVv/juX9pftyoRZhSU3Kl5Pe52IyFQD8d19wUZ4FwCN3w4WuWDyNRTt7LvtTuPGPbFGAuV83BXH1Tl8VH21ULYj/7OZdpOVs3QbFIGN8cxZqeGKl8AT8xS17TiuOpiGjmr7Ou33VLV9/kb+HFVApjOpJy4VV3BcYTOrBEx2pWM2uXsMUpmGCdiWTvLUldM543RwUf3AD7r9QMTBQkfgkgVVEkDIfql2J8ggqB8Hw1ZudpzKcaitPgYrhbj5EQBjIWAPOYkF1U1+YCU7adkvYphzq8x9tNfNcujrdovqmoCfNULt+Td+VQ77bru7I4Jfy4DvhqhiouReMj1PpZ5/qF7aMmOw9qNFkSG7VVdimR8lg4IvXLoxfjEwkRhw52kDG5Wf0e1glW7qstusLr8exR/u4f9wrP66HWl+zUwOHfomMOlwNRTgGldoxpbPKDMzQSRKqhdXQGvsvaX4FAWQfXUB6qNLR26mAkfVVkNw5VYZWv19+ngR/haP3Y/gTMc2zHCq53wz3WuxbSj1RG7TvZXVKEFtK4XdUJDOZEu/ba8uu2ty3V33e2abf/EHOuC2sIhsmiikezdeyFuwc32XFHKkhUWgpuZ6jOMZjm7JVeXteDmHsImNBUOAeinPD6G4krf1SVvo7dHhy0LpL8VScpvZQBZfAgiVVC7uvzVQG5j5X65IOk+MPJzqS1HAZ/yvcriY5gY8aNbUOT4WSMYjB7nAZnwOcOxHQAwwKldih9sN2XeJoPezFFnftYkMCz5EJ+5JyIfh7iP9L1HeQVdreTxie0vf6suJFE10cs/G2suksiT8Qlg/JCaWCQwtDEu4+Xs4fsRXpXIohM+USZ91OMzz+N4yf0fYK+qTITFU1j5vPUEjtLiY010Ms6rVIOED0GkCuoCp/5qoE5++L0gKAMJO14D9Boa2bmcKuHjV03sKrebWcHNV9zP2zp9V8fvWO65B5c7lofPwRFXPiaNY9v+Y1HF0IhMOfnLhYFfFIEvh6KHYwseznofFzi0q7vOmrTQ9By88S1034/znfYtYrawYPHR/+XOx07m5h0Hj2PS7HDckf7nZOPz81UCh3doNivEpanFRx7jo//9lVt8XAnM3GxbBx5R3g+1nTIi/F5gxwowzopFNVaXswMAfv82bPFJQcjVRRCpQkEnKZfPN2Ol9wGV8AlyyRPA0TKgxZnAgT+0+4OcdDHwh86Era4Q7z2mfK+y+HigsgjxutRUetd/OPZwSEtsX3ZPC21zccSV3DIUDeqSFywQPpfc1dXfuYwf2KyD2XqWkxzG+YViAmcSYmoLl1z0MQaHiXvFziQ34sPV8P21H6jxwuq7umzwwpnSRD8snIsITGWRMY3xkbVUl6xY9p/QS3keKkV8V1SurjgEN6u/w3bDsHjMGgmUvA9Hr2EAzuOdlH8Og+tzBaqA966LdEQJgSw+BJFK9Lo7/NpfDeSfqm1zzn3AZZNrLEAG/wv3m6q/T23xefdvyveqeCMPVEuoOdQTlKs37EaV8AKofZaFj/6j/5bXfsLRKp/ShiHLWWRapHTXajREuekIkleyQjt+UWPxkbm6LHRpZ4HynweUojkmwc1B68YmZcyTvVVXOq6ugA9Y91nobVfH7zXDY7Gz+Fi4y9G6hJSup4i6AEreBwC4lr/MP4fC7WXt3mdZeFYkG7L4EESq4a4LeCuAky4CGrQEbvlYufxcjl4SvBZnKgOjAUkkBR9Y8iBpADhSqnyvsvhkR/AwayYcsNWet2RebvExWjpuZF1a9scBeP0i6su2yU37lT7zCW6+5wHTNonI48MPaDWP8VHss7t22UJ7QfE6hsvZ5YcIgq1x6S5nV1l/3nH/C22qPgAQpcUnFkLEav+wriOjGYp+vLZ+r1GnUkgAJHwIItX4xypg969A+77S+1OK9NvqWXyYqLXqON3hWB61q0uNKsbHI5i7uuScLmxHG4dx/Sw1bo47za9j8VGXLjArZXC0yq8QPq8s3hx6vWbHYSDbeGz5At/iE588PvpoVqDp1K9SB/PK0wdY0z2RB+pKCQzN+tRn1Z8H0UNnTA6l/8p0HCEMq7PXNGFM6W61KXwYE23Z1cK3I8KSFREdFSMsBTenLuTqIohUo14BcMqlgMPC/556Fh8masWNQ/ZeLYrUqITPDV0a6zTk09+51FZ7ADjFsVOzzS97RMmvVL103CizNCBZSuTHf78p9ktsI64jZQO1W05kwJJNWoGpFT7yVV36/X+Q9U+0EPZF5bYTIEZVnf3TVX/p923DnaS/qot/XEAE6kLmrrUpfD5ZKbOaplACw6jOobCayXeoXKmynbFcZh8vSPgQRFpjIHwcTmWsjrwMhZnwUS1v73lijq1RtRL22mqvOwxdi4/1QGpAemjLxZFRJupISYTFR11J3hcQ8fHPpZp2mmBuhS1Cf5y9nRsw2fUa7C9nl1u+dNxplm+Pwqyj2mM9xkfX1aVzHAv4cafrG9kGe5/nzBWyVVe2ipRGRry+bQoRo/De6d/7NPBuKSDhQxDpjJGrC1DGBsktPnYzQPv4eWz0KHKutNe/3mkZX/ioLTxmyQNFxhTxG7ETPsoJ37x5dDOE2tV146s/cS1NYiCgGJu8hVnG30bCUVvL2dXX7YAYVVZhh+6NZKrgZuN+dJe+6wgfh1flzrRptVGW00iANSYhFh/5+XR2qN/G39gVNSR8CCKd0RM+QdO+R1ZHS27lMbP4qB/6/uTU29GL8XGqajaZu7qUOVqcJnmJrGK7PGOULhC1q2vNjsNcS5MvEFDcE/VydiNECAYznjn6RUqt9eMwqFofscVHNI/d8auzW9v8rJw2A8JtFyk1WM5u47DYYODqEtJA+ZDwIYh0pkIngDiYsM1dN7zNjqtL/dC3afGJFXrCR41pfA1TWoVcMXo4y/u0ZPHZYL0qPQ+vXztuF8dEIoqiSgxai/EBgvFA9qwXmiDvKIKbFbpHdYxx4VH9MVlJLijP7aQ55mgZcPyg4flgQ5SpWkdEvAw+gsD/rigXdeknyEyHVV0kfAginVEvWQ/COBYfRXCzyaou9cMrSRYfveXsakxjfKBMkBhpIVI1ToXwsfDA/3RIVOfzc3xIHs7aXL8/oLhGZXCzBYuPifXiKscyFDrWh94rA8+jq9Ult/hUqwrIOoTwe6Ml+5ozy9p+XcIPnhZVK79CVqKqcmDqqcAzbQ3P4bApFsNYDSVXx23pv4sGvUBlozw+tut4JRkSPgSRznS4CrjsaSnnjxye8JGLHXUeHzUaV1d15GMMoi6MagGrhT/NXF1SjE/sLT6JX86uHXcWx+LjV1l8mC2Lj8MwoKOdsAv/db+AD92TAEgWAnVG5WiWs8sprwwH2TMADotJ9Po4SvBY1tuytmFRM2Xub9xjNCvhgu8PGmRHl+EwsFTxTxhlcHOCLSvGsotcXQRBJApnFnD2MKBZF+X2kPCpq2zLe81D4+qKgcWn8422D7FqUTFzdVX7REVAczwsPolYzq5e1QUAbo430B8IKMSIMrjZzOLjULmJlO15iSkdiokvdjE+DkF9jI4FQsUM9zPo7NgW3iATNS4dA4smVYANixKg+n5+8yBwbL+t4wHYEkNqJ2Bc0PsaGIhOEj4EQSQGtUUmaKb35IW3yV1dBgGkEqoH8IYvIx1ZGGcWUDjC3iHygGSDB6rZw7ZK5fqJ1aouR6ItPpzJOMvJifEJ6Ft8RAbDCTbaGB8HxKjuhNxy4hCULjqHQvjYmGBlbbViSkItdNSur5qT6p5CIXz3rge+vpdzOH+lHW+cZlit1WX3s9D/5PWsbapM3bU9xmfSpEno3bs3cnNz0aBBA8O2Bw4cQIsWLSAIAg4fPqzYt2TJEnTv3h0ejwft27fHjBkzNMe/+OKLaNOmDbKzs9GrVy+sWLEidhdCEKnOvk3K98GHj1vH4iOnSUftNtG8WnNEOOwli3dYFD5mrq4qX0Dh3oqd8LEZ3BwlPIsPz9UVEEXlKiMZDMxwcmIRrOoSVBYfrjUmguBm9ZXJBa494SMTvTrr5dWFTMWaYOdDx33yRrqnENSCquxX7TnMboFRA82++Ivu8OdoXdzU+uBmr9eLAQMGYNiwYaZt77jjDnTu3Fmzfdu2bejXrx8uvPBClJSUYOTIkbjzzjsxb968UJuZM2di9OjRmDhxIn755Rd06dIFRUVF2Ls3NknUCCLlqTqifB/M06MX4yOfUlyceg2BeAgfQZMR2gylK0l/0jFzM1X5RJXFJzbmeKcqtiXeqPP4AEAW5ykeCCgtXEpLCQwn8ABzwO61OFQWH3mMD2MM077dgl9KzVZF1Rwvt/LIdzDVhGVngpVdb5ZDJ4GhjsXnn7M2yDbKxNHxg/Cu/gh3v/E93li6zZL4MNcONlxdFptqRChjwOZ50ko1GR54McL5BZpW/q7Y/rjrLSz13AehWpbnSLVKzjS4OcXEUFyFz+OPP45Ro0ahU6dOhu1efvllHD58GPfff79m3/Tp09G2bVtMnToVHTp0wIgRI3D99dfj+eefD7V57rnncNddd2HIkCHo2LEjpk+fjtzcXLz55psxvyaCSEmKJgF1C4BTrwAatAKur/nuy4UPT+DobRft1eayjGBP+GQLXjTAUQDGVh0990ULYT/q4TiA+OTxSaSra/76MrxTvF2znXfegCq4WRHvYyJ8zFZ1ye0lc9fuxsFjXqXFR1DG+MxbvwfPf7sZT8/hBxVrkJ3A5w9/TlLZEdl12InBkV0vP8aHaVxbwfcb91Rw+8EHN8D91d9x0bapeHLWBkufv2mBWMP9+uHFzI69ce0nwAc3ANOUcYH/cH2B+7M+wfCNgxTnGORaIP1/tOlT7tmPe/2K4GbuD5QElPCwQ9KLlG7YsAFPPPEEli9fjq1bt2r2FxcXo2/fvoptRUVFGDlyJADJqrRq1SqMHz8+tN/hcKBv374oLi6O69gJImVodTZw/ybtdnlw80WPAns3Aj0HAwWdgIZtpbpgPCtMPFxd6uraFrjaWYwix0osF0/D+c61uu2MrEFjXTMxwT9ElccnRsJHJrgaCUfhQpxchADufncVdzsvvskfEFFXqJS1CfPQF2txehM3xuicR4RD5a7Q/8yGv/8zAKcma3E2qwJ+ehk4rR/+OuTXjMEIucXngxWlGBmcpZg6j48d64hc9Gr3C2AQVUvRxFBeH9kB8gn8r58BADe5lqCr4w/MwLUWxiF7zU92ZHCsUt6Yiig9fv9W+utX5ubqLGjnX8V4day1G3cfwalyDcW9rNSy+CRV+FRXV+Pmm2/GlClT0KpVK67wKSsrQ9OmTRXbmjZtivLyclRWVuLQoUMIBALcNhs3bjQ8d3V1OCC0vJxffZkg0hp5jE/9FsAomXgYsVISPe/21x4XF1cXIvrl5xF8hqIHMBY+JwtS8VPlqq7Y/wKdkPUu/ub8Ieb9AsaTvNwqEkQURbQWwskt5eJo0ca9WLaxGmN0DIAMguGqLmUgM0OAs+1B10fA3PnAkslgvZdIx+lY5dTolaxgULooPli+HdVH/sCwPieZ9inIV3U5tOOQcg+pLD6876rO9/c0xw4Mx0zTcZiJFSYGdAWiWvjIu4pXXI1iNaCDn/TUoZJw6WDxse3qGjduHARBMPxnJDjkjB8/Hh06dMBtt91me+DRMnnyZNSvXz/0r2XLlgkfA0HEHXnuHPVKLqdL2sYLOA544zAYIU4PQGYY45MrSL9s5e6teBQpBYAzHNtj3ueRY174fl+ChuD/ONt/VJtV2x8IoI0QjuFQ3x+j+8Vb1fXHvgp8/stfGqtIcJJT5zM617FOelN1JDQtWnUFCrLpXV0SRC7gSkoP4V9zpblmztrdeHGxMjZFeaixq8sBpnGdMU7OJKPvbzbs5briaZWzn1qIj1aUgmcf0w9tjmN0mXwVmsBfHOEQ1MI89YWPbYvPmDFjMHjwYMM27dq1s9TXokWLsHbtWnz6qeQ7DN68xo0b4+GHH8bjjz+OgoIC7NmjTMu/Z88e5OXlIScnB06nE06nk9umoKBA99zjx4/H6NGjQ+/Ly8tJ/BCZh7xIqV5dr1MuC5u/g8QlxofF5QEogBlafLo4tiIb1coYnzTINRLk0UmP4z/uFzDfUx9nVr+s2c8TFEwUcaIQziOjFT4Gwc3q38OM4eKp30nHCYJCmAT7kffvQkDRh92CpUaZFhwqy1IeKsAYwz3v/wIAKDypEbq1bMCRDWYWH1EjfAI2LD7qselhZpgpr/Ji3OdrcdOVnM9UE6MsN/lEv6aQ9z1ysPBzQHTy5YJDtQjwWBXnR1O6C5/8/Hzk5+fH5OSfffYZKivDfuiff/4Zt99+O3744QecdJJkviwsLMScOXMUxy1YsACFhYUAALfbjR49emDhwoXo378/AMnMu3DhQowYoZ8zxOPxwOMxyV5LEOmOFeHT83ZgjmphQTxifFzZcen3vPaNUPbHTsM2VzuXcfP4/Mv1KlxC/OJyYsGlTimWJF84YtIyTEAU4ZbFG/Vq2wC9/vwTDXx7ME88y3CSZgaZm1eXHlK4opwh4ROe2BZ6xir6sxuLou/qUU7Oj2fNwL+F4/BtDpdtOXTMC5FBU+FN7upyckSCFOOjtvjw8vgY5ZKyF9zMa20kX5IRJeMSw1YsXYsPRMXX5c8DxwHN1FqLYnxKS0tx8OBBlJaWIhAIoKSkBADQvn171K1bNyRuguzfL/1C6dChQyjvz9ChQ/HCCy/ggQcewO23345Fixbh448/xuzZs0PHjR49GoMGDULPnj1x1lln4d///jeOHTuGIUOiq4tDEGmPwtWls6LK4QTqtwSO7Ahvk8f45DYGegyWMkRPMY+n0KV+C+DgtsiP16Gex4m9Jg9WP3PCJavz5EIAeTiGG11LYj6eWGM2ofKsNwFV5uYcJzBTGA+4gQurp+Igq6c5JnSsWvioY3zkCQZDri59godbdnXpWi+Yoo/6grRaz7H4CQAPApCKuF7y/HdYpDnWOIEhN8bHZgLDWCxnN+5DtapLp7Odhytr3GXRkyWGrTd6wc1OlWc0HWJ84ip8JkyYgLffDtdL6datGwBg8eLF6NOnj6U+2rZti9mzZ2PUqFGYNm0aWrRogddffx1FRUWhNjfeeCP27duHCRMmoKysDF27dsXcuXM1Ac8EUeuQW3yM6HQ9sDScIkLh6jpvNFA4PPqx5J0IHNCpeyQ4FUnm7CCAmScwhFth8bnauQw7WGws14mmvfAXrnYuw2v+K3EUuVzRoV7OjsN/hl7Ww3Echv73QoSgsn6EZ7Xf91XAKdsXtBxZKVNgVfg4DNw2Ds4EKgrhaWzxpr3Yuu8YoA7clufx4QofEUy9qit0nXIRaOTqUu3jKBsz65ehJU41Pv6qMGDg68uxdf8xw/Pw4H0+WUzmttJJHyAIyrFwr6E2CZ8ZM2Zwsyzr0adPH+7qhT59+mD16tWGx44YMcLQtUUQtZIGrSVrjrsukJWj367PeKXwCVjLVmuLE7sDW5fw92XlAN4K/j4OpY6WaCVKFqom1Tsw8boTgVn67T3wKYTARc4SXOQssXy+ZKKWAd96HgAANMNBjPUP5Vt8RBFOmYULh7aH98FhGtwckE9ysmfyj78fwPkyj+lJwi6sYqcaT9gsKI6soad7GOPv27Q/7I5xOnTcufLl7JwmUnAzvzq74toMxLmV6zNbzm4kDtWZqpVTZfjs5qKHP1LNVsZQ379P9p5/7Q5VVme+8EktVxfV6iKITMbpAu4tAYYuNQ6AdHmALjeH38tjcRQPrQiCKM+8E/j791LOID0RZbNye8tG4WX6E/66E/mzBhm0lpbEx6owaaLRmwy7Ov6o2a+FiaJuduosBAyFypXO5Wjhl7tK9FeEfeZ5HOc5fjWcsIOGCssWH4P1SgLn+3NItqjN4+JPaYJiVZe2DwEMAbXFh2njl2zF+AS8wPJXgP1bwoeb16zQ36OOQVI0NRJMJqfU4+t/4P6/ZPXGeK4/aJezc8eSYhYfEj4Ekek4XdI/M/o9F359xnVAh6ukpe5dbgpv7xlB3FzDNuHq8Xq/mK265GoQbNb8csMHd4yyNScaPakp1uzhCQq/qkipHCcCpiLk7/73dfepLUzXO783tiDZnnn12jPuPp/MccEr2AoohQ8vuNkBUfPdDAY3Ky0+Nlxdx/YC3zwAvNAzfLisq9Wlh/Hz9oOKHyTGPytM5QWXpb/vx+XTfkCVz+b3f/W7qtPzj2eMKQQdWXwIgkgf3LnAA9uA694ALnsauOFd4KFdQN0m4TZFk4HztKVl0PgU5fvr3gi/lv9S1Js4bAof6Lk0dPDAh6w4ZlWOJ3oixUj4iKKou2TdBf19PNRWCrWgYjCJTbFp8dH7jjCdfX7ZGi63jsVH4erSCW7WWFTEoIvOmvCxu6prxbaDGDC9GNU+eaFbAwGpdsXZEBO/7S7H3HVlhm1Mx69j8WGsFiQwJAgig8k9QQp0dudKv0RdqnWpWdnAxY8qt130CFD0lHJbgaw+n67bTIb6PGbYtPh44MMJnuh+de5lDaI6PlL0JyRj4aNr8RGMXV1qyiuVeVn4oil2MT66cyRj3Gv1yiw+eoHRSleX3qouVZFSFrT4WHR1GQmRysPS4ZxdR6vC8XSG4sMwxscctSvPNjqpKBgLmMf4pNhydhI+BEFEx/ljgZyGym1yYaKw+OiY2/UKqOphs9ipW/Ah2xGdxcetU9U73hgt7gb4E416ObscFwK6RV35J9KP8QmOw0hI+XmWEx3Kq3xgsu+I5hjObC+3+OiLAXkCQ+1eAUyTqTm4qkvt6io9cBy3vv6Tpg9DMfmv1sCyF7huP6/svOE+OJmb1RYpm2Ii6hyHepY4g5ImZscmCxI+BEFEj1OV3KyuLJWEXOzIH5J3yrKtOPl1gHTRySmihwc+NM6O7smflbTgaPuurq9LdhrE+Ii6fXLPo5q0tK4uwVDU+EOWBvNzdnl8Pmau2M7dx8APbvaxsMjefURbvgPB436aDrx4Nk4IHNDsl5LwqV1d0uet+NYwhlEfl+DH37V9mAq7+Q9zb4HXLxd6oRNpGxoGN5sTah+pAtJxdUFkChFGwocgiNqBU+aquu4NZVV4uYn8hLbh13L3VpwtPue1qYc2DaLL3hGqvH77PJRnJT8H0BmO7cjHIa5FyCi3kctkVZcavfpcQcxifLx+8ySHob4YcOAYv06c5EriBTeHvwuf/fKXTsciMPdBYN9vuO7I25rdvBgfscYS4xCUrq495TriylKMj3abUvhIDfZx6q/V+WYEsGMFAGDZ7/vxdvGfmjbRYPb5qJf7h7YzUZXAMPWDm5NanZ0giAzBJbPY5J+m3OfJC78uHAEcPwScernSHeaya/Gx95utYxMPsCe6wqsuViN8shsokubFG6MJdVzWh/hDbM49Rs/V5bQZ3BwQjS0+MHV12fu171BYD8LoWnwsTGPyBItZTFtM1C34wJjyO/XCos1oGdhoObjZyj3luae8itVW0v63lm7DA7wKETP6AY/uwy2vL5feZ8uPii9igF+/LxjcfK5jLS52/IIlYldOo9Sy+JDwIQgieuQWn6Ap/ZqXgI2zgLPuCu/LygEuqwmE3i+rpu3KBoYtA/5aCfxPljtED5sWH/iro644H8oDJDhCbqZEYHSmhqjAdc4fOMcw3Tw+di0+flXsi1PQurqMpl6f33qMD6AvIPTOY0n4ML6YCrLEMwYv+x5UjYPhxcV/4FxZUVMx4Nc1XvBWi6nhWXyqfWGLqKGrCwACXlT74+NyFUzGr2/xkRIYvueeDAC4SFzNOzjq8cUScnURBGGf066U/rbrI/3lrcrqditw84f6S9XluYVcHqDp6cBp/ZRtWpwJ3Pa59libMT7wV0UtfOTn9ifw0WkkGDzw4STHbu4xDk6iPsBaHh85/oCIe5xfYpF7NBrhiOZYxoxdXc0q1uMp1+s4QThq6Xx6fQngr+oSLXwWcouP3rVfdvQz1Ti0CQxvfGUZdh6uRKTwlqAHFDlwOAHVKvaWV8MBEbngu9zMKCvXWrwAc2Gat2eFzh5RYclq7dirbZJiwocsPgRB2Kf/y8Bvl4eFijy4WcckrsEhOyZoMZJXkD+5SBJODidwxvXAuk/D+/QqzesR8EpWn1ggCBBZ4iw+RtQR9OJNeC4pCSmPj3XhU+3z44GsjwEA97i+xhZ2omK/tKpLf2IbuX0o4AL6sx8tnpEfKOsLMOw8eAxQeUXd8KEBjuIw6mmODyKv8aWbHEA1OXdz/I4cwYudLFz9/VhVdOKZay0S5aIs+Ff/89l9pApfuh9FZ8c2w3O1FXbjXMdafBS4CD64Qj2WHjyOArOBHt6h2ZS/81tuUyYyCyE8qRXjQxYfgiDsk50HdLstvIxd7uqyKnzkS+ADNaJEHuTsrhO27KhXfVktmnreGOmvr9L6uMxIuKtLf9KoC771wWEQ3DzVPR09HJstn/+9n8JBtB54dVZ1mZMrWBOeRqKMdy8Gu+ajJPvvaCHs1T1evmJL736qC60OdH2LSVlv4mLHalmb6CZwnkDgjc3ofu4przIVPQCw2DMGT2bNwJ3OOXaHCfz7DMtNGRPN7wpjwJGdQPlu/dVhCYSED0EQ0SMXJqJFgeGW1eeqPCT9lRdS9cusGXKL0vVvhl1sZjTrKv31HQ+Lq2gRnGhUz6Dga4yRT4JnChsV+3QtPoJ+cDMAPJ31uo3zh6c1XmA0A3TdapFg19UVpMjxc83xnFpcEVh8gpwk7DIdm1V4wc2MaS1cRvez2m/vXvdy/FbTNxR/Y0ZNyYoKZrAyk4mSmHruNODYPv12CYKED0EQ0SNfZRWJZaUms60ix4ie8GnYxnq/QXHlPR67GB/BAU9unnm7INe8hJ2IfPm7fLL/xPOEYp+excdoOXs05+dZkszy+ERzPnW/RsLjGHJ02yhXZukIK53kmvIEiXZWw/EIBjdLgfIMk12v4ez94dii4NffSJyo0wuYEQzKD8USxVj5MCaCMaBS7YNUNBLDcT52FybEARI+BEHEFrvxN0BY+Mjxy4SKW5YXyE4l9+BxvmPK/uzgUK0rdjjt1RbLysEuNDFvp8MFzl9199UT+MLnH84vYih8wjgFbXwQQ2znUodKaCnHoj/pV7Ac3Tbye6FXukHP4iNfNRa1xYcxdBK2YoPndjyf9RJudi1WjiE0Tv3zcIu+GgwruLovEMqgHWNqxmOY4FOey8vuwoQ4QMKHIIjYcMGDUkX31udYP+bEHtLfTtdp98ktPnUah19ncdxM3W6TBNfQpcA9snICQZHkPaZ1dTVqD1w8wXyM6glRcCiFmBkOFxrm2SzCGiW9nRvQwVEak76UFhheDiDj4GZ7sIgtPsfhqWmjHYtDIXz4Y1XH+ASRW3yitWyJDJiU9QY8gg/XOrXB3laCmwM2kwE6BUmQ+KOt1aVD0OJjWARYbm1NAeFDq7oIgogNFz5k/5jbPgd2LAdOuki7Ty5UcuXCh2Pxueq/wKX/DAdMFz0F1GkStsxUH9UKmNP/BtRvaWGQqgnDtvBxom2ThkC59UNSC2WMD8/VFa0lJIhDlXixt2O9cr9B7Esvx28Y5foUz/hv0uxTurrANXvoFRn1xdDVpRZ2mjEEY3yMLD42BYyrxhITzMekV7EiUlHHmBS75DK0+Mj2pYCri4QPQRDJI6cBcEoRf598+bmnXvg1z+LjcChXiQVXfR0tk/76jnOOcVkrlcG1+Niw4DhccGbZzEydQihcXRzhI7WJjfARwBTns7J6KcjfXbMBAO+6n9bss+L207P4KPuJ3uJjPAbzZI92q6w7VK6u2Af5BMBEBo9gZPGRxf2lgMWHXF0EQaQmcuEjXwHmsrGiyiweiCeizLAtfJz2i7DGkubdozpc7XrirepyG7k5bKC2+KjHEallSVEGQydDsUMnuFkeuxLt6rVf/uTXVgtiZeWVkfCZ+NU6zbbg+H2B+AgfxhiYaPL5y1d6ksWHIAhCB7nwyWsRfu208dgyEihMtF8cFagJbrbh6hKc2gDpRBKl6JILnwLhEK7MWq7YzyBgQta7UZ1Dfi6j0gmRupocFspJ6FlZ5LEr0Vq2xn2+FrPd5tdnJPD0Skd4/SK3cKlk7WI4b+OTWFQi4MD+CvTg/C8U8bUxZr5iUmHxSb7sSP4ICIIgeMiDm/NPAa54FshtpN+eh5FZnYmRWXyycpXV503H4IpspVusiNK1ILcP9OQkPozV6jHpXGYxMLE5Bw89USUXPrGKZTLHKMZHK3wYgL8OHcdA53y0E3bjRGF/aJ8LAfQUNuGMsi8AAF8I/MUHEd9bJpoLH8WqruQ7mkj4EASRWpzaD9g0G+j1d+V2ebHTWMAC+hafTjcAaz/m77O7nN3h4scYJYooRZeZJSB2K7qkvvQTGMb2XGr0BFyWIHN1WVhuboaxq8s8xkcM8N1K2/dV4MmsGZrtDogodGwIvY+lUAUkV5dglrQ0aPFJATcXQDE+BEGkGte/AQyaBZz/QGz6u+RJ/nYmKn+JynGZuIeybMb4JFP4xDmY1BXDrM2SuLFXssL+Ofh9OHVWJfEsPtFYfqxYtIz6/23nYc5Whr0HD3LbuxBAMyG8T+86I4WBmefIClqEUiCwGSDhQxBEqpGVA7Q9z14sjxHn3MvfLgaABq34+5ycavNy7LjIHE4pc3SyiNriY0zsLT78/qRV6NELn+YCXyDoiQ1ejI/h0u0osGLxWfTbbv4OnVIQTkFEjqxOmkvn/kb8OTIGiGaurpr7lQLxPQAJH4IgaitMBHJPADpr876grkmmZSPhU9BZ+V5wSpmjk0WU7gUzsRGrFV3SuYz3GSbJixIrwueimoKl0Yk9c4uW0X3gWWyy4UWXVY9w27sQQB2E4+WKnCu57SIXPqJ5mRqRXF0EQRCJpU6NkJGvxgrm52neVdu+1dlA73uBq18AdxoyWibvVJe4cCXX4hN1cLOx8LnS+ZPhfnvn0o/xAYA8nRIdsUAv9kUu7Aa6vgUQncXHSNQEr70e9L8veuPs6OWXNmkqHMalzlWm44o09ocxZi58gvtTILAZIOFDEERtYODnwEkXA4NnhbcFze8nXaxtL/qBS58Eug/km+ezDJbBq9snPbg5OuETL7cOD6MA5lyhGve5Po/bua2s6goSnfAxtvjk4RhucH2n2yZeAd7NhQORHcgYBNNVXWTxIQiCSCwFnSTx07xbeFvQ4pN/CnDqFcr28iXDcotJq0Lpr5HFRyN8nJGV87CD0Xj0ahRYxCkkTvg4IMa+iKaNc/PI0lw/QzYiLHgL8+DmHpyUAXJivSorSCPhaGQHWlnOHlyJRjE+BEEQSUSeqbfRScp9irwjsof1TR9If41ifNSuJYcT6HoL0LBtZOO0wsmXWB+PTQyrbseYMZecHNcl60Y4dZIcqi0+bviRLUQmfE4RduAUx06DFsw0fDuWq+hiwerSQ9iwY79xo6DFh1Z1EQRBREGj9tLfes0iO15u1VFX7FYIH9nDOvcE6a+hxYcT4wMAjU+2P0arGLkQolzVFS8LA492jevErO5XrFALnxxUIxsmMS06zPc8aLhfAAMzmZaTIQxXiqfo7hPAMPOnLcYdUB4fgiCIGHDrJ0C3gcCg/9k7LriEveM14W3qVVxmKfbViQ9vn6/fPviwl5eOOP1aa2O1ipE7K8rJ5vyTGkR1vB06NfSjr+OXhJ2PR0BQfn7qeB5J+ETu6jLiUudKU9nXGEficm4jqph+yRUBDB4TIShScDNBEEQMOKEdcM0L9i0pQ38E/v490F4W1Nzr70CXW8Lv5bFA3OBmlaurQUv99sH38tVe8mrzgHkxVTldb9NuM7LqRGnxOa1JBGU9IqTuZzdjVNZnCTsfD1GVw0lt8ckVqiN2dZlxr+tLVX16LZ97HovLuY2ohn5CTw98iuXyPL5ctR0AECCLD0EQRBLIzgOadVFuy8oBrn0ZGLMJGLpUGfPDEz5GsQqaGJ+g8JFNHm618MkBBn7JX2Gm5kROtfWjZfrtzSpnmxHt8TYQjuxI2Ln0cLmV1jy3Kri50LEB+Tgct/PHM1dRxLj0E3re4lqE59zTDQ8vO1QBAKgOJCt0XUlqhFgTBEGkAvUKpH9yLP1KlT3QNcKn5vel3OLjVll4mAicdKFkafpXa/3TXPsq4K3Qbt/+A79963PDcUmRolMbKlMRsnIB6C/tnpT1JiqYQTqDKHnT/Wzc+o4Ur+CJpjxZyF0oUHAzQRBEGqD3sG7aib8970TV8TW/L+XuLHVCw8pD0l+j4qedBgBnXGevQKo8b1GkJNDikxKo3ZAc6grGrp1MwyeY1K4zIWjFElNEcqTGKAiCIFIVvdwjt6qqt1/7CtC+L3DBA0Dfx8Lbgxaj+i3C24JCR40667Oc616X6ped/jfg5EtNhy2dWwB63i69LtARamrUy+7NKm9nGvLs3gQAwOcwqV1nwhDXPAAAU6+eTBIkfAiCIIzQEz7qZetdbgJu+wzIrg80kLmrgsfLBcUpRZGPx+WWVrQ16xre1scgQWLT04EHtkkV780443rglpnKbWqLT7fbgAf/BOo1tzzktMJTe4WPyPgxOP4ohU+QuuUmy94TBAkfgiAII/rU5F5RFzOVW2fUVhF5IHNQ+DQ9Pbytw1XA/30F3PKJ5DK7TVaK4dJJwEkXmY9Lfv4LHjBum3uCJRcOXB7tUn11jE/dpkBOA+DMO8z7S0dqscVnkv9W7vaAIzpXl5wqX+ISYupBwc0EQRBGnH4t0OJMrYVDLjzURRoVwqfm92Wjk4ArnpVifRxOoF0fafspKrdV7xFAzyHAUyYWFbklShCA8+4Hil8A/DrxJw4ncOk/gaojwPdT+G0Eh3apftVh5fvgcm+WGm4LQwSH/XGqhV8tYYeYj7+y+IH1DfLqAzGqD3vgmBcnNkhcigQeZPEhCIIwo34LbfI1uatL7Q7Si9U56y6gG/9XtQIreX2Cwik4josfBcbtAPI76B/T+x/ARY/o7xcc2qXLf/6ofO+qEXVilL/cB7wd3fFWeLhMcs3ZIcq8R4kiHoHC7ly+VbBjq/yYneOE3NhZjyIlPT5hgiCIVEMhblSxEbmNoutbnYl52DJtm3NHSRakESvC21xRTiqCw9ziEbQ02bWknHU3cLIstqlZZ3vHR4LLA3jq2zvGKAt2lo0VdXFGnWgRiM4lxQDce1k37r5mjRta6uMD/4WmbXLcyV/STsKHIAgiEgQBKBwBdLlZmz26WWfg/LFAv+eiP0+LM5XxQUFcHsmCdEK76M8RJOBVuum41AgDZtPic/FEoNXZ4feJcinJs2pbwcjic8nj0Y1FTpTXX+XWiuuAK3JhJggCTm7RlLvPk20t7mkzs3mvkwQJH4IgiEgpmgRcO51vJbjokdgEAFdzEhbGi4q9xhYPILzfrsVHcCgFot5quVgx8Evpb7A2m1WMrv/MO22N+5irAXf7e/6LgYd24ccAR9BaxOtpIK0ilNWqE+2UPlEhCIJ+ALzFxINeGKRjSCHiJnwmTZqE3r17Izc3Fw0aNNBtN2PGDHTu3BnZ2dlo0qQJhg8frtj/66+/4rzzzkN2djZatmyJZ555RtPHJ598gtNOOw3Z2dno1KkT5syZE+vLIQiCSA68TM2GRJFit2KPhUY1wsBujI/DCbS/RHIX1WsGZDewOzrrON1SJmzAvvA5fhBo2Ea73VNfEkU26k3VqddQckeqmJY9DHA4EYhqChakvFFtzw9tYVG44vKys/STY1qMezrM6gDNOSVVUoy4CR+v14sBAwZg2LBhum2ee+45PPzwwxg3bhzWr1+Pb7/9FkVFYR9weXk5Lr30UrRu3RqrVq3ClClT8Nhjj+HVV18NtVm2bBluvvlm3HHHHVi9ejX69++P/v37Y926dfG6NIIgiPgTnNC63mLcLhJ6DOFvr9gr/S16St/lFbHFxwlkZQOj1wPDl0cXj3T5FElQBAO7T+wJ/ENW1V0+UddXu19MLFpHy6QitncuUm4PrpazE/yc2wjodL1m84LRFwBAVMKHMa3ArWrRO+L+6uW49N1vDid8zFzwlbETgBvfjXgMiSJuwufxxx/HqFGj0KkTP1vooUOH8Mgjj+Cdd97BLbfcgpNOOgmdO3fG1VdfHWrz/vvvw+v14s0338Tpp5+Om266Cffeey+eey7sN582bRouu+wyjB07Fh06dMCTTz6J7t2744UXXojXpREEQcSfmz4Abv1MihWyQ+9/SH9Pu1K/zZXPS0kI1cVSm3aU/hYOB275WHscEJ747QqfoLskp6GU5NGM7PpSmY4g8uvpdbcU33TfGuDG94E7FigLy8rFSU6D8OtOA4AJB43Pe/yAdO4WPZQrzwLV2r7NqNtEut7Ln1FYnhrUrGzyI4pAX/n9v+cn4Ipncbxr5K5VAYK+m09woNqCG2sPayitgKzLjxVKFZIW47NgwQKIooidO3eiQ4cOaNGiBW644Qbs2BGuzltcXIzzzz8fbnf4l0FRURE2bdqEQ4cOhdr07dtX0XdRURGKi4sNz19dXY3y8nLFP4IgiJTBUw84ua9xGQseXW8Fhv9svFxcECRBII/dOOvvwNWyH4zylWnyLNGRurrMYofUOD1AnSbGbeqfCHS4UptqQE+cHNuvbatGXk7k9P7a/XYKbbY8S/rb6++SOGl9rhTkXUM0S9IVFp8mHYCz7kJWdpxWnTmyLAmf14b3k15UpfZ8mjThs3XrVoiiiKeeegr//ve/8emnn+LgwYO45JJL4PV6AQBlZWVo2lSpHIPvy8rKDNsE9+sxefJk1K9fP/SvZcv0iEYnCIIwRBCA/FOkul5myAN1r3hGEhJB6shyt9SVCZBIXV08Rq4FbvqQHzDsqauMz+G4dnRRC5+cmuXYbc7Rtu37GDBSFhpRrZq0z6/Jin3JEzV9mwi4vo9LlroLHwbOlsWsuusAQ2YD540ObbLj6vq+izK+lXFiubLcUawU63gNAOBwFkds5jRAFUxck/mnoWPLmu+MP0bZDuOELeEzbtw4CIJg+G/jxo2W+hJFET6fD//5z39QVFSEs88+Gx9++CG2bNmCxYsXR3Qxdhg/fjyOHDkS+ie3NBEEQdQKjFYo1SsIv5aXcWhek+vFSPjc8I618zdoBZx2Bd965K6jFD5WSm4EUYuTv/8AXDUNKPyHtu25o4yXvF/4kCSMet9b07fJtNn4FMlSd8EDpnFMdoSP6Fa6BwMcC0zdOhGu6ip6CugzHgDgufMb7f6cE3BCjoml6/++iuzcScDWesIxY8Zg8ODBhm3atbOWU6JZs2YAgI4dO4a25efno3HjxigtLQUAFBQUYM8e5SqD4PuCggLDNsH9eng8Hng8sSm8RhAEkZYYudEEQVouveRpyXpx4UPAoe1Ai57S/hPa6h9bYz2wDsea48kLiywA6DsR2LdRWlJuhlqcNGgJ9BhsfMxV/wH+d68295IgKIWRmfAxzYMUpke7psCf1tp2bdcU+Dn83i9op++srAjntE43SIHnAHKatsdvOd3RoVIWLJ7TEDmBY8Z9yIVydn2pNIqa696IbHwxxpbwyc/PR35+bFJXn3OOZHLctGkTWrRoAQA4ePAg9u/fj9atpXohhYWFePjhh+Hz+ZCVJf0PumDBApx66qlo2LBhqM3ChQsxcuTIUN8LFixAYWFhTMZJEASRsZjlpGnfV/oXRJ6H56y7peXvy/5rfp5L/2m8v8npwN710pLx6poJ010XyGsG3LlQWm2U1xz4+3fm5wIiKzvRY5AU02MWeG0qfKxPq80LmoWFT/+XgfmPAsf3c9s2qKe0ePkFjmh15wIXPAh89y/zk9fJB47tk16rrumUpvWA7bINOQ0An4HwKVAtYhr0P6keXN0C4OfXwts5K9ySQdxifEpLS1FSUoLS0lIEAgGUlJSgpKQEFRVSTopTTjkF11xzDe677z4sW7YM69atw6BBg3Daaafhwgul/Au33HIL3G437rjjDqxfvx4zZ87EtGnTMHp02Ed63333Ye7cuZg6dSo2btyIxx57DCtXrsSIESPidWkEQRCZQTD4NhJcHmNBM2CG9PfK58MrzfS46X2gyy3AHfPC21rX/Hht0RMoOMPe2MzESTBVwCmXK7dbWW0m75uX08dhIxhdnsuo1dnAmE3K/QO/AE7/myQk6jWDfCm+rlvrwoeAxqean7tQNkeqXINOh8pVqGcZvG8NcO5o4OaPlNubdQFufE9yoaUgcUudOWHCBLz9dnhVQbduksly8eLF6NOnDwDgnXfewahRo9CvXz84HA5ccMEFmDt3bsi6U79+fcyfPx/Dhw9Hjx490LhxY0yYMAF33313qN/evXvjgw8+wCOPPIKHHnoIJ598Mr788kuccYbN/1EIgiBqG5f/S5pQO98YeR+D5wCHS4EfpwH7fgPOqPlVf/q1krDIshBwe0Jb4NqXpdd//x74/VvlxGwbkwDkG94BfpsFdLzauB23a5nwueEdYKaq6KydVXjZeeHX7npKa9EplwEnXST9CzL0B2D6uQCARnkGZSTcFmJ9jLI8c+qASfdU5pI85XIp0WPfiZy2NbjcQMuzgR0/mY8ngcRN+MyYMQMzZswwbJOXl4c33ngDb7yh7/fr3LkzfvjhB8N+BgwYgAEDBhi2IQiCIFTkNIy+/lSbcwCcA7Q9D1j/peQyCmJF9Khp1kX6Fw1mFp+chkD3gdH3fVo/oGiy5KZb/Z60zU4pDnk8kEclZLwc15LMpSS4DOJ5Tr8W2LVaue3u74CZA4EjUgwtsnLC+wJeZVt5KoOg1WbQ18D8R4Dda6T3Vqvex7s0SQRQrS6CIAgieuq3AHqPsLf6KtYEyyV0uSl+55C7wwQBKLxHyp0UxI7FR54TSJ012axUiVEQ9dn3aC1mzbsCI36WEkHWbwm06yPlZyropM2XVKdx+HVhzZL8tudL1riHy4BhyyTRZ4XWqRdvm3pSjCAIgiAi4bbPgO0/SG6iePG314BPBkmxNEHyTwu/9nu1x+ght4aol+B7jxsfaySwnFlSAd0964CtS8Lbs7KleKogdy0GwLRJHeXCR01WDtDURnHV8+6XAtXj+ZnYhIQPQRAEkRnknhDBUnqbFJwB/GOV9rzBGBijZf5qTr5U+tuko3Yfz9Ulx8qy+Z63S8KnZS/+fr0s1rkGwscuWdnAuSNj118MIOFTQzD9N5WuIAiCIGwztASorgD8LsDyPJILDF0jJWsMHlNdE0BcXs7vJ7i/ipmfp8WFwMCFQMPWNsYEoHEP6TzuevaOSxLBeZtXuJWHwKy2zHD++usvKltBEARBEGnKjh07QnkBjSDhU4Moiti1axfq1asHwW4xPQPKy8vRsmVL7NixA3l5eeYHEFFB9ztx0L1OLHS/Ewvd78QR7b1mjOHo0aNo3rw5HGZFaEGurhAOh8OSUoyUvLw8+p8ngdD9Thx0rxML3e/EQvc7cURzr+vXt5B8sgZazk4QBEEQRK2BhA9BEARBELUGEj5xxuPxYOLEiVQJPkHQ/U4cdK8TC93vxEL3O3Ek+l5TcDNBEARBELUGsvgQBEEQBFFrIOFDEARBEEStgYQPQRAEQRC1BhI+BEEQBEHUGkj4xJkXX3wRbdq0QXZ2Nnr16oUVK1Yke0hpx+TJk3HmmWeiXr16aNKkCfr3749NmzYp2lRVVWH48OFo1KgR6tati+uuuw579uxRtCktLUW/fv2Qm5uLJk2aYOzYsfD7/Ym8lLTj6aefhiAIGDlyZGgb3evYsnPnTtx2221o1KgRcnJy0KlTJ6xcuTK0nzGGCRMmoFmzZsjJyUHfvn2xZcsWRR8HDx7Erbfeiry8PDRo0AB33HEHKioqEn0pKU8gEMCjjz6Ktm3bIicnByeddBKefPJJRY0nut+R8f333+Oqq65C8+bNIQgCvvzyS8X+WN3XX3/9Feeddx6ys7PRsmVLPPPMM/YHy4i48dFHHzG3283efPNNtn79enbXXXexBg0asD179iR7aGlFUVERe+utt9i6detYSUkJu+KKK1irVq1YRUVFqM3QoUNZy5Yt2cKFC9nKlSvZ2WefzXr37h3a7/f72RlnnMH69u3LVq9ezebMmcMaN27Mxo8fn4xLSgtWrFjB2rRpwzp37szuu+++0Ha617Hj4MGDrHXr1mzw4MFs+fLlbOvWrWzevHns999/D7V5+umnWf369dmXX37J1qxZw66++mrWtm1bVllZGWpz2WWXsS5durCffvqJ/fDDD6x9+/bs5ptvTsYlpTSTJk1ijRo1YrNmzWLbtm1jn3zyCatbty6bNm1aqA3d78iYM2cOe/jhh9nnn3/OALAvvvhCsT8W9/XIkSOsadOm7NZbb2Xr1q1jH374IcvJyWGvvPKKrbGS8IkjZ511Fhs+fHjofSAQYM2bN2eTJ09O4qjSn7179zIA7LvvvmOMMXb48GGWlZXFPvnkk1Cb3377jQFgxcXFjDHpf0qHw8HKyspCbV5++WWWl5fHqqurE3sBacDRo0fZySefzBYsWMAuuOCCkPChex1bHnzwQXbuuefq7hdFkRUUFLApU6aEth0+fJh5PB724YcfMsYY27BhAwPAfv7551Cbb775hgmCwHbu3Bm/wach/fr1Y7fffrti29/+9jd26623MsbofscKtfCJ1X196aWXWMOGDRXPkQcffJCdeuqptsZHrq444fV6sWrVKvTt2ze0zeFwoG/fviguLk7iyNKfI0eOAABOOOEEAMCqVavg8/kU9/q0005Dq1atQve6uLgYnTp1QtOmTUNtioqKUF5ejvXr1ydw9OnB8OHD0a9fP8U9Behex5qvv/4aPXv2xIABA9CkSRN069YNr732Wmj/tm3bUFZWprjf9evXR69evRT3u0GDBujZs2eoTd++feFwOLB8+fLEXUwa0Lt3byxcuBCbN28GAKxZswZLly7F5ZdfDoDud7yI1X0tLi7G+eefD7fbHWpTVFSETZs24dChQ5bHQ0VK48T+/fsRCAQUD38AaNq0KTZu3JikUaU/oihi5MiROOecc3DGGWcAAMrKyuB2u9GgQQNF26ZNm6KsrCzUhvdZBPcRYT766CP88ssv+PnnnzX76F7Hlq1bt+Lll1/G6NGj8dBDD+Hnn3/GvffeC7fbjUGDBoXuF+9+yu93kyZNFPtdLhdOOOEEut8qxo0bh/Lycpx22mlwOp0IBAKYNGkSbr31VgCg+x0nYnVfy8rK0LZtW00fwX0NGza0NB4SPkRaMXz4cKxbtw5Lly5N9lAykh07duC+++7DggULkJ2dnezhZDyiKKJnz5546qmnAADdunXDunXrMH36dAwaNCjJo8s8Pv74Y7z//vv44IMPcPrpp6OkpAQjR45E8+bN6X7XIsjVFScaN24Mp9OpWe2yZ88eFBQUJGlU6c2IESMwa9YsLF68GC1atAhtLygogNfrxeHDhxXt5fe6oKCA+1kE9xESq1atwt69e9G9e3e4XC64XC589913+M9//gOXy4WmTZvSvY4hzZo1Q8eOHRXbOnTogNLSUgDh+2X0HCkoKMDevXsV+/1+Pw4ePEj3W8XYsWMxbtw43HTTTejUqRMGDhyIUaNGYfLkyQDofseLWN3XWD1bSPjECbfbjR49emDhwoWhbaIoYuHChSgsLEziyNIPxhhGjBiBL774AosWLdKYOnv06IGsrCzFvd60aRNKS0tD97qwsBBr165V/I+1YMEC5OXlaSae2szFF1+MtWvXoqSkJPSvZ8+euPXWW0Ov6V7HjnPOOUeTmmHz5s1o3bo1AKBt27YoKChQ3O/y8nIsX75ccb8PHz6MVatWhdosWrQIoiiiV69eCbiK9OH48eNwOJTTntPphCiKAOh+x4tY3dfCwkJ8//338Pl8oTYLFizAqaeeatnNBYCWs8eTjz76iHk8HjZjxgy2YcMGdvfdd7MGDRooVrsQ5gwbNozVr1+fLVmyhO3evTv07/jx46E2Q4cOZa1atWKLFi1iK1euZIWFhaywsDC0P7jE+tJLL2UlJSVs7ty5LD8/n5ZYW0C+qosxutexZMWKFczlcrFJkyaxLVu2sPfff5/l5uay9957L9Tm6aefZg0aNGBfffUV+/XXX9k111zDXQbcrVs3tnz5crZ06VJ28skn1/rl1TwGDRrETjzxxNBy9s8//5w1btyYPfDAA6E2dL8j4+jRo2z16tVs9erVDAB77rnn2OrVq9mff/7JGIvNfT18+DBr2rQpGzhwIFu3bh376KOPWG5uLi1nTzX++9//slatWjG3283OOuss9tNPPyV7SGkHAO6/t956K9SmsrKS3XPPPaxhw4YsNzeXXXvttWz37t2KfrZv384uv/xylpOTwxo3bszGjBnDfD5fgq8m/VALH7rXseV///sfO+OMM5jH42GnnXYae/XVVxX7RVFkjz76KGvatCnzeDzs4osvZps2bVK0OXDgALv55ptZ3bp1WV5eHhsyZAg7evRoIi8jLSgvL2f33Xcfa9WqFcvOzmbt2rVjDz/8sGJ5NN3vyFi8eDH3OT1o0CDGWOzu65o1a9i5557LPB4PO/HEE9nTTz9te6wCY7KUlQRBEARBEBkMxfgQBEEQBFFrIOFDEARBEEStgYQPQRAEQRC1BhI+BEEQBEHUGkj4EARBEARRayDhQxAEQRBErYGED0EQBEEQtQYSPgRBEARB1BpI+BAEQRAEUWsg4UMQBEEQRK2BhA9BEARBELUGEj4EQRAEQdQa/h/vNTZzro6nJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 7.20362  validloss 7.53789±0.00000  bestvalidloss 7.53789  last_update 0\n",
      "train: iter 1  trainloss 6.59052  validloss 6.84748±0.00000  bestvalidloss 6.84748  last_update 0\n",
      "train: iter 2  trainloss 6.06892  validloss 6.30317±0.00000  bestvalidloss 6.30317  last_update 0\n",
      "train: iter 3  trainloss 5.59843  validloss 5.82756±0.00000  bestvalidloss 5.82756  last_update 0\n",
      "train: iter 4  trainloss 5.22138  validloss 5.39637±0.00000  bestvalidloss 5.39637  last_update 0\n",
      "train: iter 5  trainloss 4.87980  validloss 5.04418±0.00000  bestvalidloss 5.04418  last_update 0\n",
      "train: iter 6  trainloss 4.59050  validloss 4.74203±0.00000  bestvalidloss 4.74203  last_update 0\n",
      "train: iter 7  trainloss 4.32564  validloss 4.45674±0.00000  bestvalidloss 4.45674  last_update 0\n",
      "train: iter 8  trainloss 4.10512  validloss 4.22275±0.00000  bestvalidloss 4.22275  last_update 0\n",
      "train: iter 9  trainloss 3.89825  validloss 4.00985±0.00000  bestvalidloss 4.00985  last_update 0\n",
      "train: iter 10  trainloss 3.71390  validloss 3.82161±0.00000  bestvalidloss 3.82161  last_update 0\n",
      "train: iter 11  trainloss 3.55624  validloss 3.65256±0.00000  bestvalidloss 3.65256  last_update 0\n",
      "train: iter 12  trainloss 3.40862  validloss 3.51717±0.00000  bestvalidloss 3.51717  last_update 0\n",
      "train: iter 13  trainloss 3.28401  validloss 3.38420±0.00000  bestvalidloss 3.38420  last_update 0\n",
      "train: iter 14  trainloss 3.16793  validloss 3.25977±0.00000  bestvalidloss 3.25977  last_update 0\n",
      "train: iter 15  trainloss 3.06390  validloss 3.14124±0.00000  bestvalidloss 3.14124  last_update 0\n",
      "train: iter 16  trainloss 2.96958  validloss 3.04117±0.00000  bestvalidloss 3.04117  last_update 0\n",
      "train: iter 17  trainloss 2.88639  validloss 2.97132±0.00000  bestvalidloss 2.97132  last_update 0\n",
      "train: iter 18  trainloss 2.79997  validloss 2.86825±0.00000  bestvalidloss 2.86825  last_update 0\n",
      "train: iter 19  trainloss 2.72521  validloss 2.78947±0.00000  bestvalidloss 2.78947  last_update 0\n",
      "train: iter 20  trainloss 2.66528  validloss 2.73737±0.00000  bestvalidloss 2.73737  last_update 0\n",
      "train: iter 21  trainloss 2.60647  validloss 2.66496±0.00000  bestvalidloss 2.66496  last_update 0\n",
      "train: iter 22  trainloss 2.56037  validloss 2.60735±0.00000  bestvalidloss 2.60735  last_update 0\n",
      "train: iter 23  trainloss 2.48921  validloss 2.57187±0.00000  bestvalidloss 2.57187  last_update 0\n",
      "train: iter 24  trainloss 2.45142  validloss 2.49840±0.00000  bestvalidloss 2.49840  last_update 0\n",
      "train: iter 25  trainloss 2.39515  validloss 2.46426±0.00000  bestvalidloss 2.46426  last_update 0\n",
      "train: iter 26  trainloss 2.37600  validloss 2.44813±0.00000  bestvalidloss 2.44813  last_update 0\n",
      "train: iter 27  trainloss 2.32053  validloss 2.39524±0.00000  bestvalidloss 2.39524  last_update 0\n",
      "train: iter 28  trainloss 2.28260  validloss 2.33080±0.00000  bestvalidloss 2.33080  last_update 0\n",
      "train: iter 29  trainloss 2.25028  validloss 2.30723±0.00000  bestvalidloss 2.30723  last_update 0\n",
      "train: iter 30  trainloss 2.20538  validloss 2.27359±0.00000  bestvalidloss 2.27359  last_update 0\n",
      "train: iter 31  trainloss 2.17356  validloss 2.25299±0.00000  bestvalidloss 2.25299  last_update 0\n",
      "train: iter 32  trainloss 2.14917  validloss 2.21592±0.00000  bestvalidloss 2.21592  last_update 0\n",
      "train: iter 33  trainloss 2.12696  validloss 2.19836±0.00000  bestvalidloss 2.19836  last_update 0\n",
      "train: iter 34  trainloss 2.09544  validloss 2.19557±0.00000  bestvalidloss 2.19557  last_update 0\n",
      "train: iter 35  trainloss 2.05384  validloss 2.13601±0.00000  bestvalidloss 2.13601  last_update 0\n",
      "train: iter 36  trainloss 2.03748  validloss 2.09449±0.00000  bestvalidloss 2.09449  last_update 0\n",
      "train: iter 37  trainloss 2.01476  validloss 2.07876±0.00000  bestvalidloss 2.07876  last_update 0\n",
      "train: iter 38  trainloss 1.97159  validloss 2.04769±0.00000  bestvalidloss 2.04769  last_update 0\n",
      "train: iter 39  trainloss 1.92990  validloss 2.04440±0.00000  bestvalidloss 2.04440  last_update 0\n",
      "train: iter 40  trainloss 1.92140  validloss 2.03833±0.00000  bestvalidloss 2.03833  last_update 0\n",
      "train: iter 41  trainloss 1.88572  validloss 1.95468±0.00000  bestvalidloss 1.95468  last_update 0\n",
      "train: iter 42  trainloss 1.85584  validloss 1.94583±0.00000  bestvalidloss 1.94583  last_update 0\n",
      "train: iter 43  trainloss 1.83687  validloss 1.90477±0.00000  bestvalidloss 1.90477  last_update 0\n",
      "train: iter 44  trainloss 1.78278  validloss 1.85059±0.00000  bestvalidloss 1.85059  last_update 0\n",
      "train: iter 45  trainloss 1.76008  validloss 1.83394±0.00000  bestvalidloss 1.83394  last_update 0\n",
      "train: iter 46  trainloss 1.73395  validloss 1.80750±0.00000  bestvalidloss 1.80750  last_update 0\n",
      "train: iter 47  trainloss 1.68918  validloss 1.81891±0.00000  bestvalidloss 1.80750  last_update 1\n",
      "train: iter 48  trainloss 1.65908  validloss 1.72420±0.00000  bestvalidloss 1.72420  last_update 0\n",
      "train: iter 49  trainloss 1.60412  validloss 1.70025±0.00000  bestvalidloss 1.70025  last_update 0\n",
      "train: iter 50  trainloss 1.58569  validloss 1.69314±0.00000  bestvalidloss 1.69314  last_update 0\n",
      "train: iter 51  trainloss 1.52608  validloss 1.61904±0.00000  bestvalidloss 1.61904  last_update 0\n",
      "train: iter 52  trainloss 1.49477  validloss 1.58137±0.00000  bestvalidloss 1.58137  last_update 0\n",
      "train: iter 53  trainloss 1.44213  validloss 1.55488±0.00000  bestvalidloss 1.55488  last_update 0\n",
      "train: iter 54  trainloss 1.41662  validloss 1.50359±0.00000  bestvalidloss 1.50359  last_update 0\n",
      "train: iter 55  trainloss 1.34976  validloss 1.40270±0.00000  bestvalidloss 1.40270  last_update 0\n",
      "train: iter 56  trainloss 1.31763  validloss 1.44765±0.00000  bestvalidloss 1.40270  last_update 1\n",
      "train: iter 57  trainloss 1.27204  validloss 1.38897±0.00000  bestvalidloss 1.38897  last_update 0\n",
      "train: iter 58  trainloss 1.20805  validloss 1.32634±0.00000  bestvalidloss 1.32634  last_update 0\n",
      "train: iter 59  trainloss 1.17949  validloss 1.25523±0.00000  bestvalidloss 1.25523  last_update 0\n",
      "train: iter 60  trainloss 1.16153  validloss 1.21814±0.00000  bestvalidloss 1.21814  last_update 0\n",
      "train: iter 61  trainloss 1.08472  validloss 1.18493±0.00000  bestvalidloss 1.18493  last_update 0\n",
      "train: iter 62  trainloss 1.03857  validloss 1.16698±0.00000  bestvalidloss 1.16698  last_update 0\n",
      "train: iter 63  trainloss 0.99260  validloss 1.05461±0.00000  bestvalidloss 1.05461  last_update 0\n",
      "train: iter 64  trainloss 0.96451  validloss 1.05664±0.00000  bestvalidloss 1.05461  last_update 1\n",
      "train: iter 65  trainloss 0.91814  validloss 0.99897±0.00000  bestvalidloss 0.99897  last_update 0\n",
      "train: iter 66  trainloss 0.88344  validloss 0.94927±0.00000  bestvalidloss 0.94927  last_update 0\n",
      "train: iter 67  trainloss 0.83737  validloss 0.94700±0.00000  bestvalidloss 0.94700  last_update 0\n",
      "train: iter 68  trainloss 0.79177  validloss 0.86077±0.00000  bestvalidloss 0.86077  last_update 0\n",
      "train: iter 69  trainloss 0.75662  validloss 0.89377±0.00000  bestvalidloss 0.86077  last_update 1\n",
      "train: iter 70  trainloss 0.74913  validloss 0.81206±0.00000  bestvalidloss 0.81206  last_update 0\n",
      "train: iter 71  trainloss 0.69349  validloss 0.78727±0.00000  bestvalidloss 0.78727  last_update 0\n",
      "train: iter 72  trainloss 0.64832  validloss 0.77972±0.00000  bestvalidloss 0.77972  last_update 0\n",
      "train: iter 73  trainloss 0.64005  validloss 0.65829±0.00000  bestvalidloss 0.65829  last_update 0\n",
      "train: iter 74  trainloss 0.58303  validloss 0.65852±0.00000  bestvalidloss 0.65829  last_update 1\n",
      "train: iter 75  trainloss 0.54184  validloss 0.62027±0.00000  bestvalidloss 0.62027  last_update 0\n",
      "train: iter 76  trainloss 0.51707  validloss 0.60100±0.00000  bestvalidloss 0.60100  last_update 0\n",
      "train: iter 77  trainloss 0.46909  validloss 0.59954±0.00000  bestvalidloss 0.59954  last_update 0\n",
      "train: iter 78  trainloss 0.43880  validloss 0.54444±0.00000  bestvalidloss 0.54444  last_update 0\n",
      "train: iter 79  trainloss 0.41391  validloss 0.50268±0.00000  bestvalidloss 0.50268  last_update 0\n",
      "train: iter 80  trainloss 0.37124  validloss 0.50337±0.00000  bestvalidloss 0.50268  last_update 1\n",
      "train: iter 81  trainloss 0.35330  validloss 0.45450±0.00000  bestvalidloss 0.45450  last_update 0\n",
      "train: iter 82  trainloss 0.33265  validloss 0.46059±0.00000  bestvalidloss 0.45450  last_update 1\n",
      "train: iter 83  trainloss 0.28463  validloss 0.40653±0.00000  bestvalidloss 0.40653  last_update 0\n",
      "train: iter 84  trainloss 0.26320  validloss 0.37702±0.00000  bestvalidloss 0.37702  last_update 0\n",
      "train: iter 85  trainloss 0.23980  validloss 0.36352±0.00000  bestvalidloss 0.36352  last_update 0\n",
      "train: iter 86  trainloss 0.22019  validloss 0.30064±0.00000  bestvalidloss 0.30064  last_update 0\n",
      "train: iter 87  trainloss 0.18266  validloss 0.32862±0.00000  bestvalidloss 0.30064  last_update 1\n",
      "train: iter 88  trainloss 0.15569  validloss 0.31996±0.00000  bestvalidloss 0.30064  last_update 2\n",
      "train: iter 89  trainloss 0.15341  validloss 0.22644±0.00000  bestvalidloss 0.22644  last_update 0\n",
      "train: iter 90  trainloss 0.14413  validloss 0.19963±0.00000  bestvalidloss 0.19963  last_update 0\n",
      "train: iter 91  trainloss 0.09204  validloss 0.23683±0.00000  bestvalidloss 0.19963  last_update 1\n",
      "train: iter 92  trainloss 0.08792  validloss 0.22818±0.00000  bestvalidloss 0.19963  last_update 2\n",
      "train: iter 93  trainloss 0.07537  validloss 0.19416±0.00000  bestvalidloss 0.19416  last_update 0\n",
      "train: iter 94  trainloss 0.03231  validloss 0.14780±0.00000  bestvalidloss 0.14780  last_update 0\n",
      "train: iter 95  trainloss 0.03508  validloss 0.16516±0.00000  bestvalidloss 0.14780  last_update 1\n",
      "train: iter 96  trainloss 0.01853  validloss 0.18712±0.00000  bestvalidloss 0.14780  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 97  trainloss 0.00613  validloss 0.14306±0.00000  bestvalidloss 0.14306  last_update 0\n",
      "train: iter 98  trainloss 0.00735  validloss 0.15947±0.00000  bestvalidloss 0.14306  last_update 1\n",
      "train: iter 99  trainloss -0.00673  validloss 0.15782±0.00000  bestvalidloss 0.14306  last_update 2\n",
      "train: iter 100  trainloss -0.03112  validloss 0.15175±0.00000  bestvalidloss 0.14306  last_update 3\n",
      "train: iter 101  trainloss -0.03609  validloss 0.12924±0.00000  bestvalidloss 0.12924  last_update 0\n",
      "train: iter 102  trainloss -0.06344  validloss 0.11264±0.00000  bestvalidloss 0.11264  last_update 0\n",
      "train: iter 103  trainloss -0.05532  validloss 0.11968±0.00000  bestvalidloss 0.11264  last_update 1\n",
      "train: iter 104  trainloss -0.05882  validloss 0.11539±0.00000  bestvalidloss 0.11264  last_update 2\n",
      "train: iter 105  trainloss -0.05810  validloss 0.13818±0.00000  bestvalidloss 0.11264  last_update 3\n",
      "train: iter 106  trainloss -0.06590  validloss 0.07110±0.00000  bestvalidloss 0.07110  last_update 0\n",
      "train: iter 107  trainloss -0.06202  validloss 0.16784±0.00000  bestvalidloss 0.07110  last_update 1\n",
      "train: iter 108  trainloss -0.06020  validloss 0.07891±0.00000  bestvalidloss 0.07110  last_update 2\n",
      "train: iter 109  trainloss -0.08173  validloss 0.09968±0.00000  bestvalidloss 0.07110  last_update 3\n",
      "train: iter 110  trainloss -0.06211  validloss 0.05965±0.00000  bestvalidloss 0.05965  last_update 0\n",
      "train: iter 111  trainloss -0.08911  validloss 0.08850±0.00000  bestvalidloss 0.05965  last_update 1\n",
      "train: iter 112  trainloss -0.09518  validloss 0.11001±0.00000  bestvalidloss 0.05965  last_update 2\n",
      "train: iter 113  trainloss -0.09805  validloss 0.14141±0.00000  bestvalidloss 0.05965  last_update 3\n",
      "train: iter 114  trainloss -0.11359  validloss 0.12356±0.00000  bestvalidloss 0.05965  last_update 4\n",
      "train: iter 115  trainloss -0.08075  validloss 0.10544±0.00000  bestvalidloss 0.05965  last_update 5\n",
      "train: iter 116  trainloss -0.11516  validloss 0.12031±0.00000  bestvalidloss 0.05965  last_update 6\n",
      "train: iter 117  trainloss -0.10984  validloss 0.06385±0.00000  bestvalidloss 0.05965  last_update 7\n",
      "train: iter 118  trainloss -0.10231  validloss 0.11726±0.00000  bestvalidloss 0.05965  last_update 8\n",
      "train: iter 119  trainloss -0.10039  validloss 0.10511±0.00000  bestvalidloss 0.05965  last_update 9\n",
      "train: iter 120  trainloss -0.12660  validloss 0.12309±0.00000  bestvalidloss 0.05965  last_update 10\n",
      "train: iter 121  trainloss -0.08027  validloss 0.10748±0.00000  bestvalidloss 0.05965  last_update 11\n",
      "train: iter 122  trainloss -0.10494  validloss 0.04669±0.00000  bestvalidloss 0.04669  last_update 0\n",
      "train: iter 123  trainloss -0.11569  validloss 0.08231±0.00000  bestvalidloss 0.04669  last_update 1\n",
      "train: iter 124  trainloss -0.09298  validloss 0.15037±0.00000  bestvalidloss 0.04669  last_update 2\n",
      "train: iter 125  trainloss -0.08402  validloss 0.13235±0.00000  bestvalidloss 0.04669  last_update 3\n",
      "train: iter 126  trainloss -0.11615  validloss 0.10252±0.00000  bestvalidloss 0.04669  last_update 4\n",
      "train: iter 127  trainloss -0.09497  validloss 0.12423±0.00000  bestvalidloss 0.04669  last_update 5\n",
      "train: iter 128  trainloss -0.08677  validloss 0.13687±0.00000  bestvalidloss 0.04669  last_update 6\n",
      "train: iter 129  trainloss -0.12536  validloss 0.19502±0.00000  bestvalidloss 0.04669  last_update 7\n",
      "train: iter 130  trainloss -0.10878  validloss 0.11950±0.00000  bestvalidloss 0.04669  last_update 8\n",
      "train: iter 131  trainloss -0.08683  validloss 0.15329±0.00000  bestvalidloss 0.04669  last_update 9\n",
      "train: iter 132  trainloss -0.09665  validloss 0.14650±0.00000  bestvalidloss 0.04669  last_update 10\n",
      "train: iter 133  trainloss -0.10564  validloss 0.15253±0.00000  bestvalidloss 0.04669  last_update 11\n",
      "train: iter 134  trainloss -0.08642  validloss 0.11633±0.00000  bestvalidloss 0.04669  last_update 12\n",
      "train: iter 135  trainloss -0.09192  validloss 0.11788±0.00000  bestvalidloss 0.04669  last_update 13\n",
      "train: iter 136  trainloss -0.11755  validloss 0.08434±0.00000  bestvalidloss 0.04669  last_update 14\n",
      "train: iter 137  trainloss -0.09417  validloss 0.14845±0.00000  bestvalidloss 0.04669  last_update 15\n",
      "train: iter 138  trainloss -0.08489  validloss 0.14555±0.00000  bestvalidloss 0.04669  last_update 16\n",
      "train: iter 139  trainloss -0.07522  validloss 0.15454±0.00000  bestvalidloss 0.04669  last_update 17\n",
      "train: iter 140  trainloss -0.12014  validloss 0.13804±0.00000  bestvalidloss 0.04669  last_update 18\n",
      "train: iter 141  trainloss -0.11982  validloss 0.12784±0.00000  bestvalidloss 0.04669  last_update 19\n",
      "train: iter 142  trainloss -0.07204  validloss 0.15798±0.00000  bestvalidloss 0.04669  last_update 20\n",
      "train: iter 143  trainloss -0.08411  validloss 0.16972±0.00000  bestvalidloss 0.04669  last_update 21\n",
      "train: iter 144  trainloss -0.10585  validloss 0.12676±0.00000  bestvalidloss 0.04669  last_update 22\n",
      "train: iter 145  trainloss -0.11181  validloss 0.09466±0.00000  bestvalidloss 0.04669  last_update 23\n",
      "train: iter 146  trainloss -0.06734  validloss 0.13782±0.00000  bestvalidloss 0.04669  last_update 24\n",
      "train: iter 147  trainloss -0.09597  validloss 0.09565±0.00000  bestvalidloss 0.04669  last_update 25\n",
      "train: iter 148  trainloss -0.07204  validloss 0.12330±0.00000  bestvalidloss 0.04669  last_update 26\n",
      "train: iter 149  trainloss -0.10086  validloss 0.11459±0.00000  bestvalidloss 0.04669  last_update 27\n",
      "train: iter 150  trainloss -0.11563  validloss 0.05145±0.00000  bestvalidloss 0.04669  last_update 28\n",
      "train: iter 151  trainloss -0.06674  validloss 0.15228±0.00000  bestvalidloss 0.04669  last_update 29\n",
      "train: iter 152  trainloss -0.11594  validloss 0.19644±0.00000  bestvalidloss 0.04669  last_update 30\n",
      "train: iter 153  trainloss -0.11742  validloss 0.17894±0.00000  bestvalidloss 0.04669  last_update 31\n",
      "train: iter 154  trainloss -0.08733  validloss 0.04107±0.00000  bestvalidloss 0.04107  last_update 0\n",
      "train: iter 155  trainloss -0.09283  validloss 0.18149±0.00000  bestvalidloss 0.04107  last_update 1\n",
      "train: iter 156  trainloss -0.11605  validloss 0.19365±0.00000  bestvalidloss 0.04107  last_update 2\n",
      "train: iter 157  trainloss -0.12175  validloss 0.13753±0.00000  bestvalidloss 0.04107  last_update 3\n",
      "train: iter 158  trainloss -0.08456  validloss 0.15925±0.00000  bestvalidloss 0.04107  last_update 4\n",
      "train: iter 159  trainloss -0.08656  validloss 0.13164±0.00000  bestvalidloss 0.04107  last_update 5\n",
      "train: iter 160  trainloss -0.07487  validloss 0.17774±0.00000  bestvalidloss 0.04107  last_update 6\n",
      "train: iter 161  trainloss -0.10865  validloss 0.12416±0.00000  bestvalidloss 0.04107  last_update 7\n",
      "train: iter 162  trainloss -0.12574  validloss 0.09845±0.00000  bestvalidloss 0.04107  last_update 8\n",
      "train: iter 163  trainloss -0.09065  validloss 0.10106±0.00000  bestvalidloss 0.04107  last_update 9\n",
      "train: iter 164  trainloss -0.11905  validloss 0.11206±0.00000  bestvalidloss 0.04107  last_update 10\n",
      "train: iter 165  trainloss -0.07932  validloss 0.14891±0.00000  bestvalidloss 0.04107  last_update 11\n",
      "train: iter 166  trainloss -0.08085  validloss 0.11657±0.00000  bestvalidloss 0.04107  last_update 12\n",
      "train: iter 167  trainloss -0.09151  validloss 0.13528±0.00000  bestvalidloss 0.04107  last_update 13\n",
      "train: iter 168  trainloss -0.10893  validloss 0.10080±0.00000  bestvalidloss 0.04107  last_update 14\n",
      "train: iter 169  trainloss -0.14762  validloss 0.14317±0.00000  bestvalidloss 0.04107  last_update 15\n",
      "train: iter 170  trainloss -0.07753  validloss 0.15697±0.00000  bestvalidloss 0.04107  last_update 16\n",
      "train: iter 171  trainloss -0.09330  validloss 0.16711±0.00000  bestvalidloss 0.04107  last_update 17\n",
      "train: iter 172  trainloss -0.10078  validloss 0.19616±0.00000  bestvalidloss 0.04107  last_update 18\n",
      "train: iter 173  trainloss -0.10699  validloss 0.12318±0.00000  bestvalidloss 0.04107  last_update 19\n",
      "train: iter 174  trainloss -0.12219  validloss 0.17890±0.00000  bestvalidloss 0.04107  last_update 20\n",
      "train: iter 175  trainloss -0.10337  validloss 0.16214±0.00000  bestvalidloss 0.04107  last_update 21\n",
      "train: iter 176  trainloss -0.10114  validloss 0.14693±0.00000  bestvalidloss 0.04107  last_update 22\n",
      "train: iter 177  trainloss -0.06175  validloss 0.11861±0.00000  bestvalidloss 0.04107  last_update 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 178  trainloss -0.10193  validloss 0.10247±0.00000  bestvalidloss 0.04107  last_update 24\n",
      "train: iter 179  trainloss -0.10870  validloss 0.11214±0.00000  bestvalidloss 0.04107  last_update 25\n",
      "train: iter 180  trainloss -0.08906  validloss 0.17805±0.00000  bestvalidloss 0.04107  last_update 26\n",
      "train: iter 181  trainloss -0.10056  validloss 0.11166±0.00000  bestvalidloss 0.04107  last_update 27\n",
      "train: iter 182  trainloss -0.07583  validloss 0.10043±0.00000  bestvalidloss 0.04107  last_update 28\n",
      "train: iter 183  trainloss -0.10163  validloss 0.07738±0.00000  bestvalidloss 0.04107  last_update 29\n",
      "train: iter 184  trainloss -0.09293  validloss 0.12864±0.00000  bestvalidloss 0.04107  last_update 30\n",
      "train: iter 185  trainloss -0.08867  validloss 0.11083±0.00000  bestvalidloss 0.04107  last_update 31\n",
      "train: iter 186  trainloss -0.08329  validloss 0.13446±0.00000  bestvalidloss 0.04107  last_update 32\n",
      "train: iter 187  trainloss -0.07433  validloss 0.16550±0.00000  bestvalidloss 0.04107  last_update 33\n",
      "train: iter 188  trainloss -0.10051  validloss 0.19552±0.00000  bestvalidloss 0.04107  last_update 34\n",
      "train: iter 189  trainloss -0.09741  validloss 0.13819±0.00000  bestvalidloss 0.04107  last_update 35\n",
      "train: iter 190  trainloss -0.09863  validloss 0.10842±0.00000  bestvalidloss 0.04107  last_update 36\n",
      "train: iter 191  trainloss -0.09896  validloss 0.13521±0.00000  bestvalidloss 0.04107  last_update 37\n",
      "train: iter 192  trainloss -0.11752  validloss 0.23436±0.00000  bestvalidloss 0.04107  last_update 38\n",
      "train: iter 193  trainloss -0.09509  validloss 0.18950±0.00000  bestvalidloss 0.04107  last_update 39\n",
      "train: iter 194  trainloss -0.10884  validloss 0.14733±0.00000  bestvalidloss 0.04107  last_update 40\n",
      "train: iter 195  trainloss -0.09951  validloss 0.10729±0.00000  bestvalidloss 0.04107  last_update 41\n",
      "train: iter 196  trainloss -0.10467  validloss 0.14079±0.00000  bestvalidloss 0.04107  last_update 42\n",
      "train: iter 197  trainloss -0.09890  validloss 0.12332±0.00000  bestvalidloss 0.04107  last_update 43\n",
      "train: iter 198  trainloss -0.10714  validloss 0.16101±0.00000  bestvalidloss 0.04107  last_update 44\n",
      "train: iter 199  trainloss -0.13353  validloss 0.12896±0.00000  bestvalidloss 0.04107  last_update 45\n",
      "train: iter 200  trainloss -0.11014  validloss 0.10818±0.00000  bestvalidloss 0.04107  last_update 46\n",
      "train: iter 201  trainloss -0.09736  validloss 0.20053±0.00000  bestvalidloss 0.04107  last_update 47\n",
      "train: iter 202  trainloss -0.10610  validloss 0.11989±0.00000  bestvalidloss 0.04107  last_update 48\n",
      "train: iter 203  trainloss -0.09468  validloss 0.13431±0.00000  bestvalidloss 0.04107  last_update 49\n",
      "train: iter 204  trainloss -0.09672  validloss 0.08961±0.00000  bestvalidloss 0.04107  last_update 50\n",
      "train: iter 205  trainloss -0.11021  validloss 0.14262±0.00000  bestvalidloss 0.04107  last_update 51\n",
      "train: iter 206  trainloss -0.10960  validloss 0.12213±0.00000  bestvalidloss 0.04107  last_update 52\n",
      "train: iter 207  trainloss -0.10328  validloss 0.14148±0.00000  bestvalidloss 0.04107  last_update 53\n",
      "train: iter 208  trainloss -0.11498  validloss 0.13880±0.00000  bestvalidloss 0.04107  last_update 54\n",
      "train: iter 209  trainloss -0.12840  validloss 0.11516±0.00000  bestvalidloss 0.04107  last_update 55\n",
      "train: iter 210  trainloss -0.09834  validloss 0.15679±0.00000  bestvalidloss 0.04107  last_update 56\n",
      "train: iter 211  trainloss -0.09649  validloss 0.20920±0.00000  bestvalidloss 0.04107  last_update 57\n",
      "train: iter 212  trainloss -0.09206  validloss 0.13328±0.00000  bestvalidloss 0.04107  last_update 58\n",
      "train: iter 213  trainloss -0.09321  validloss 0.18932±0.00000  bestvalidloss 0.04107  last_update 59\n",
      "train: iter 214  trainloss -0.10408  validloss 0.17641±0.00000  bestvalidloss 0.04107  last_update 60\n",
      "train: iter 215  trainloss -0.08806  validloss 0.09062±0.00000  bestvalidloss 0.04107  last_update 61\n",
      "train: iter 216  trainloss -0.12356  validloss 0.15038±0.00000  bestvalidloss 0.04107  last_update 62\n",
      "train: iter 217  trainloss -0.07424  validloss 0.10678±0.00000  bestvalidloss 0.04107  last_update 63\n",
      "train: iter 218  trainloss -0.09431  validloss 0.15350±0.00000  bestvalidloss 0.04107  last_update 64\n",
      "train: iter 219  trainloss -0.07345  validloss 0.15187±0.00000  bestvalidloss 0.04107  last_update 65\n",
      "train: iter 220  trainloss -0.09645  validloss 0.07833±0.00000  bestvalidloss 0.04107  last_update 66\n",
      "train: iter 221  trainloss -0.06927  validloss 0.17355±0.00000  bestvalidloss 0.04107  last_update 67\n",
      "train: iter 222  trainloss -0.09916  validloss 0.16522±0.00000  bestvalidloss 0.04107  last_update 68\n",
      "train: iter 223  trainloss -0.10821  validloss 0.07878±0.00000  bestvalidloss 0.04107  last_update 69\n",
      "train: iter 224  trainloss -0.08559  validloss 0.17233±0.00000  bestvalidloss 0.04107  last_update 70\n",
      "train: iter 225  trainloss -0.12578  validloss 0.15046±0.00000  bestvalidloss 0.04107  last_update 71\n",
      "train: iter 226  trainloss -0.09472  validloss 0.14649±0.00000  bestvalidloss 0.04107  last_update 72\n",
      "train: iter 227  trainloss -0.11397  validloss 0.13374±0.00000  bestvalidloss 0.04107  last_update 73\n",
      "train: iter 228  trainloss -0.08437  validloss 0.14727±0.00000  bestvalidloss 0.04107  last_update 74\n",
      "train: iter 229  trainloss -0.09657  validloss 0.15119±0.00000  bestvalidloss 0.04107  last_update 75\n",
      "train: iter 230  trainloss -0.10672  validloss 0.16984±0.00000  bestvalidloss 0.04107  last_update 76\n",
      "train: iter 231  trainloss -0.10049  validloss 0.10397±0.00000  bestvalidloss 0.04107  last_update 77\n",
      "train: iter 232  trainloss -0.11288  validloss 0.13250±0.00000  bestvalidloss 0.04107  last_update 78\n",
      "train: iter 233  trainloss -0.09176  validloss 0.11736±0.00000  bestvalidloss 0.04107  last_update 79\n",
      "train: iter 234  trainloss -0.12559  validloss 0.13354±0.00000  bestvalidloss 0.04107  last_update 80\n",
      "train: iter 235  trainloss -0.08988  validloss 0.11902±0.00000  bestvalidloss 0.04107  last_update 81\n",
      "train: iter 236  trainloss -0.09992  validloss 0.13953±0.00000  bestvalidloss 0.04107  last_update 82\n",
      "train: iter 237  trainloss -0.08702  validloss 0.12190±0.00000  bestvalidloss 0.04107  last_update 83\n",
      "train: iter 238  trainloss -0.09476  validloss 0.11050±0.00000  bestvalidloss 0.04107  last_update 84\n",
      "train: iter 239  trainloss -0.10916  validloss 0.13276±0.00000  bestvalidloss 0.04107  last_update 85\n",
      "train: iter 240  trainloss -0.09962  validloss 0.22029±0.00000  bestvalidloss 0.04107  last_update 86\n",
      "train: iter 241  trainloss -0.12595  validloss 0.08447±0.00000  bestvalidloss 0.04107  last_update 87\n",
      "train: iter 242  trainloss -0.09127  validloss 0.15623±0.00000  bestvalidloss 0.04107  last_update 88\n",
      "train: iter 243  trainloss -0.07238  validloss 0.07295±0.00000  bestvalidloss 0.04107  last_update 89\n",
      "train: iter 244  trainloss -0.08554  validloss 0.13526±0.00000  bestvalidloss 0.04107  last_update 90\n",
      "train: iter 245  trainloss -0.09467  validloss 0.09839±0.00000  bestvalidloss 0.04107  last_update 91\n",
      "train: iter 246  trainloss -0.09186  validloss 0.09641±0.00000  bestvalidloss 0.04107  last_update 92\n",
      "train: iter 247  trainloss -0.04775  validloss 0.15969±0.00000  bestvalidloss 0.04107  last_update 93\n",
      "train: iter 248  trainloss -0.07423  validloss 0.13034±0.00000  bestvalidloss 0.04107  last_update 94\n",
      "train: iter 249  trainloss -0.11578  validloss 0.18814±0.00000  bestvalidloss 0.04107  last_update 95\n",
      "train: iter 250  trainloss -0.08714  validloss 0.10406±0.00000  bestvalidloss 0.04107  last_update 96\n",
      "train: iter 251  trainloss -0.07900  validloss 0.09524±0.00000  bestvalidloss 0.04107  last_update 97\n",
      "train: iter 252  trainloss -0.12185  validloss 0.13805±0.00000  bestvalidloss 0.04107  last_update 98\n",
      "train: iter 253  trainloss -0.11386  validloss 0.16776±0.00000  bestvalidloss 0.04107  last_update 99\n",
      "train: iter 254  trainloss -0.08618  validloss 0.08588±0.00000  bestvalidloss 0.04107  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.2993, -0.6292, -3.5038, -2.3557], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 63.28616  validloss 74.18387±0.00000  bestvalidloss 74.18387  last_update 0\n",
      "train: iter 1  trainloss 44.56217  validloss 55.96145±0.00000  bestvalidloss 55.96145  last_update 0\n",
      "train: iter 2  trainloss 30.87823  validloss 38.14245±0.00000  bestvalidloss 38.14245  last_update 0\n",
      "train: iter 3  trainloss 22.60887  validloss 27.71569±0.00000  bestvalidloss 27.71569  last_update 0\n",
      "train: iter 4  trainloss 17.32296  validloss 20.93516±0.00000  bestvalidloss 20.93516  last_update 0\n",
      "train: iter 5  trainloss 13.84470  validloss 16.60685±0.00000  bestvalidloss 16.60685  last_update 0\n",
      "train: iter 6  trainloss 11.57926  validloss 13.86642±0.00000  bestvalidloss 13.86642  last_update 0\n",
      "train: iter 7  trainloss 9.99136  validloss 11.64424±0.00000  bestvalidloss 11.64424  last_update 0\n",
      "train: iter 8  trainloss 8.88369  validloss 10.12959±0.00000  bestvalidloss 10.12959  last_update 0\n",
      "train: iter 9  trainloss 8.13158  validloss 9.17035±0.00000  bestvalidloss 9.17035  last_update 0\n",
      "train: iter 10  trainloss 7.55311  validloss 8.32166±0.00000  bestvalidloss 8.32166  last_update 0\n",
      "train: iter 11  trainloss 7.04598  validloss 7.63852±0.00000  bestvalidloss 7.63852  last_update 0\n",
      "train: iter 12  trainloss 6.64239  validloss 7.08455±0.00000  bestvalidloss 7.08455  last_update 0\n",
      "train: iter 13  trainloss 6.38344  validloss 6.63492±0.00000  bestvalidloss 6.63492  last_update 0\n",
      "train: iter 14  trainloss 6.15628  validloss 6.19820±0.00000  bestvalidloss 6.19820  last_update 0\n",
      "train: iter 15  trainloss 5.98841  validloss 5.89224±0.00000  bestvalidloss 5.89224  last_update 0\n",
      "train: iter 16  trainloss 5.82340  validloss 5.53971±0.00000  bestvalidloss 5.53971  last_update 0\n",
      "train: iter 17  trainloss 5.69812  validloss 5.25922±0.00000  bestvalidloss 5.25922  last_update 0\n",
      "train: iter 18  trainloss 5.56393  validloss 5.05681±0.00000  bestvalidloss 5.05681  last_update 0\n",
      "train: iter 19  trainloss 5.44833  validloss 4.91158±0.00000  bestvalidloss 4.91158  last_update 0\n",
      "train: iter 20  trainloss 5.37684  validloss 4.77009±0.00000  bestvalidloss 4.77009  last_update 0\n",
      "train: iter 21  trainloss 5.29336  validloss 4.65731±0.00000  bestvalidloss 4.65731  last_update 0\n",
      "train: iter 22  trainloss 5.24130  validloss 4.51626±0.00000  bestvalidloss 4.51626  last_update 0\n",
      "train: iter 23  trainloss 5.08739  validloss 4.44975±0.00000  bestvalidloss 4.44975  last_update 0\n",
      "train: iter 24  trainloss 5.04756  validloss 4.32022±0.00000  bestvalidloss 4.32022  last_update 0\n",
      "train: iter 25  trainloss 4.95077  validloss 4.23410±0.00000  bestvalidloss 4.23410  last_update 0\n",
      "train: iter 26  trainloss 4.85276  validloss 4.15928±0.00000  bestvalidloss 4.15928  last_update 0\n",
      "train: iter 27  trainloss 4.75706  validloss 4.07398±0.00000  bestvalidloss 4.07398  last_update 0\n",
      "train: iter 28  trainloss 4.66601  validloss 4.05228±0.00000  bestvalidloss 4.05228  last_update 0\n",
      "train: iter 29  trainloss 4.59332  validloss 3.89949±0.00000  bestvalidloss 3.89949  last_update 0\n",
      "train: iter 30  trainloss 4.50093  validloss 3.83125±0.00000  bestvalidloss 3.83125  last_update 0\n",
      "train: iter 31  trainloss 4.38144  validloss 3.83571±0.00000  bestvalidloss 3.83125  last_update 1\n",
      "train: iter 32  trainloss 4.28992  validloss 3.75391±0.00000  bestvalidloss 3.75391  last_update 0\n",
      "train: iter 33  trainloss 4.18845  validloss 3.60821±0.00000  bestvalidloss 3.60821  last_update 0\n",
      "train: iter 34  trainloss 4.10565  validloss 3.53055±0.00000  bestvalidloss 3.53055  last_update 0\n",
      "train: iter 35  trainloss 4.06356  validloss 3.58015±0.00000  bestvalidloss 3.53055  last_update 1\n",
      "train: iter 36  trainloss 4.03848  validloss 3.50845±0.00000  bestvalidloss 3.50845  last_update 0\n",
      "train: iter 37  trainloss 3.98596  validloss 3.43659±0.00000  bestvalidloss 3.43659  last_update 0\n",
      "train: iter 38  trainloss 3.97429  validloss 3.32432±0.00000  bestvalidloss 3.32432  last_update 0\n",
      "train: iter 39  trainloss 3.96455  validloss 3.29580±0.00000  bestvalidloss 3.29580  last_update 0\n",
      "train: iter 40  trainloss 3.94478  validloss 3.33620±0.00000  bestvalidloss 3.29580  last_update 1\n",
      "train: iter 41  trainloss 3.89143  validloss 3.31934±0.00000  bestvalidloss 3.29580  last_update 2\n",
      "train: iter 42  trainloss 3.84489  validloss 3.29586±0.00000  bestvalidloss 3.29580  last_update 3\n",
      "train: iter 43  trainloss 3.81915  validloss 3.25591±0.00000  bestvalidloss 3.25591  last_update 0\n",
      "train: iter 44  trainloss 3.84295  validloss 3.27394±0.00000  bestvalidloss 3.25591  last_update 1\n",
      "train: iter 45  trainloss 3.85336  validloss 3.32885±0.00000  bestvalidloss 3.25591  last_update 2\n",
      "train: iter 46  trainloss 3.80838  validloss 3.24844±0.00000  bestvalidloss 3.24844  last_update 0\n",
      "train: iter 47  trainloss 3.76928  validloss 3.21851±0.00000  bestvalidloss 3.21851  last_update 0\n",
      "train: iter 48  trainloss 3.76851  validloss 3.21419±0.00000  bestvalidloss 3.21419  last_update 0\n",
      "train: iter 49  trainloss 3.73389  validloss 3.18374±0.00000  bestvalidloss 3.18374  last_update 0\n",
      "train: iter 50  trainloss 3.75541  validloss 3.26961±0.00000  bestvalidloss 3.18374  last_update 1\n",
      "train: iter 51  trainloss 3.73634  validloss 3.24329±0.00000  bestvalidloss 3.18374  last_update 2\n",
      "train: iter 52  trainloss 3.74492  validloss 3.28840±0.00000  bestvalidloss 3.18374  last_update 3\n",
      "train: iter 53  trainloss 3.71774  validloss 3.26807±0.00000  bestvalidloss 3.18374  last_update 4\n",
      "train: iter 54  trainloss 3.74088  validloss 3.33123±0.00000  bestvalidloss 3.18374  last_update 5\n",
      "train: iter 55  trainloss 3.77698  validloss 3.19284±0.00000  bestvalidloss 3.18374  last_update 6\n",
      "train: iter 56  trainloss 3.71129  validloss 3.19840±0.00000  bestvalidloss 3.18374  last_update 7\n",
      "train: iter 57  trainloss 3.70281  validloss 3.32992±0.00000  bestvalidloss 3.18374  last_update 8\n",
      "train: iter 58  trainloss 3.71190  validloss 3.20967±0.00000  bestvalidloss 3.18374  last_update 9\n",
      "train: iter 59  trainloss 3.72506  validloss 3.18827±0.00000  bestvalidloss 3.18374  last_update 10\n",
      "train: iter 60  trainloss 3.66504  validloss 3.18782±0.00000  bestvalidloss 3.18374  last_update 11\n",
      "train: iter 61  trainloss 3.74651  validloss 3.24927±0.00000  bestvalidloss 3.18374  last_update 12\n",
      "train: iter 62  trainloss 3.61723  validloss 3.20512±0.00000  bestvalidloss 3.18374  last_update 13\n",
      "train: iter 63  trainloss 3.71341  validloss 3.31537±0.00000  bestvalidloss 3.18374  last_update 14\n",
      "train: iter 64  trainloss 3.69773  validloss 3.22989±0.00000  bestvalidloss 3.18374  last_update 15\n",
      "train: iter 65  trainloss 3.68889  validloss 3.16144±0.00000  bestvalidloss 3.16144  last_update 0\n",
      "train: iter 66  trainloss 3.68459  validloss 3.27215±0.00000  bestvalidloss 3.16144  last_update 1\n",
      "train: iter 67  trainloss 3.69783  validloss 3.25497±0.00000  bestvalidloss 3.16144  last_update 2\n",
      "train: iter 68  trainloss 3.68649  validloss 3.29636±0.00000  bestvalidloss 3.16144  last_update 3\n",
      "train: iter 69  trainloss 3.64316  validloss 3.09345±0.00000  bestvalidloss 3.09345  last_update 0\n",
      "train: iter 70  trainloss 3.69407  validloss 3.32948±0.00000  bestvalidloss 3.09345  last_update 1\n",
      "train: iter 71  trainloss 3.65493  validloss 3.28584±0.00000  bestvalidloss 3.09345  last_update 2\n",
      "train: iter 72  trainloss 3.66774  validloss 3.18361±0.00000  bestvalidloss 3.09345  last_update 3\n",
      "train: iter 73  trainloss 3.65682  validloss 3.22864±0.00000  bestvalidloss 3.09345  last_update 4\n",
      "train: iter 74  trainloss 3.67038  validloss 3.18025±0.00000  bestvalidloss 3.09345  last_update 5\n",
      "train: iter 75  trainloss 3.66392  validloss 3.16918±0.00000  bestvalidloss 3.09345  last_update 6\n",
      "train: iter 76  trainloss 3.65042  validloss 3.26284±0.00000  bestvalidloss 3.09345  last_update 7\n",
      "train: iter 77  trainloss 3.66643  validloss 3.29013±0.00000  bestvalidloss 3.09345  last_update 8\n",
      "train: iter 78  trainloss 3.66471  validloss 3.26629±0.00000  bestvalidloss 3.09345  last_update 9\n",
      "train: iter 79  trainloss 3.64018  validloss 3.27676±0.00000  bestvalidloss 3.09345  last_update 10\n",
      "train: iter 80  trainloss 3.64084  validloss 3.33547±0.00000  bestvalidloss 3.09345  last_update 11\n",
      "train: iter 81  trainloss 3.59373  validloss 3.26159±0.00000  bestvalidloss 3.09345  last_update 12\n",
      "train: iter 82  trainloss 3.68146  validloss 3.29710±0.00000  bestvalidloss 3.09345  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 3.61622  validloss 3.32160±0.00000  bestvalidloss 3.09345  last_update 14\n",
      "train: iter 84  trainloss 3.63761  validloss 3.29752±0.00000  bestvalidloss 3.09345  last_update 15\n",
      "train: iter 85  trainloss 3.64274  validloss 3.17889±0.00000  bestvalidloss 3.09345  last_update 16\n",
      "train: iter 86  trainloss 3.64500  validloss 3.24871±0.00000  bestvalidloss 3.09345  last_update 17\n",
      "train: iter 87  trainloss 3.63319  validloss 3.21677±0.00000  bestvalidloss 3.09345  last_update 18\n",
      "train: iter 88  trainloss 3.63048  validloss 3.28840±0.00000  bestvalidloss 3.09345  last_update 19\n",
      "train: iter 89  trainloss 3.63608  validloss 3.24635±0.00000  bestvalidloss 3.09345  last_update 20\n",
      "train: iter 90  trainloss 3.64145  validloss 3.27306±0.00000  bestvalidloss 3.09345  last_update 21\n",
      "train: iter 91  trainloss 3.63377  validloss 3.10573±0.00000  bestvalidloss 3.09345  last_update 22\n",
      "train: iter 92  trainloss 3.64719  validloss 3.14548±0.00000  bestvalidloss 3.09345  last_update 23\n",
      "train: iter 93  trainloss 3.61537  validloss 3.30097±0.00000  bestvalidloss 3.09345  last_update 24\n",
      "train: iter 94  trainloss 3.62920  validloss 3.24242±0.00000  bestvalidloss 3.09345  last_update 25\n",
      "train: iter 95  trainloss 3.64441  validloss 3.20377±0.00000  bestvalidloss 3.09345  last_update 26\n",
      "train: iter 96  trainloss 3.62055  validloss 3.25030±0.00000  bestvalidloss 3.09345  last_update 27\n",
      "train: iter 97  trainloss 3.61796  validloss 3.22650±0.00000  bestvalidloss 3.09345  last_update 28\n",
      "train: iter 98  trainloss 3.64866  validloss 3.32825±0.00000  bestvalidloss 3.09345  last_update 29\n",
      "train: iter 99  trainloss 3.64297  validloss 3.19543±0.00000  bestvalidloss 3.09345  last_update 30\n",
      "train: iter 100  trainloss 3.63089  validloss 3.14422±0.00000  bestvalidloss 3.09345  last_update 31\n",
      "train: iter 101  trainloss 3.60806  validloss 3.32465±0.00000  bestvalidloss 3.09345  last_update 32\n",
      "train: iter 102  trainloss 3.60248  validloss 3.21067±0.00000  bestvalidloss 3.09345  last_update 33\n",
      "train: iter 103  trainloss 3.60615  validloss 3.21064±0.00000  bestvalidloss 3.09345  last_update 34\n",
      "train: iter 104  trainloss 3.57614  validloss 3.18291±0.00000  bestvalidloss 3.09345  last_update 35\n",
      "train: iter 105  trainloss 3.59587  validloss 3.24407±0.00000  bestvalidloss 3.09345  last_update 36\n",
      "train: iter 106  trainloss 3.65815  validloss 3.19884±0.00000  bestvalidloss 3.09345  last_update 37\n",
      "train: iter 107  trainloss 3.59022  validloss 3.29142±0.00000  bestvalidloss 3.09345  last_update 38\n",
      "train: iter 108  trainloss 3.59251  validloss 3.23179±0.00000  bestvalidloss 3.09345  last_update 39\n",
      "train: iter 109  trainloss 3.58733  validloss 3.21303±0.00000  bestvalidloss 3.09345  last_update 40\n",
      "train: iter 110  trainloss 3.61752  validloss 3.17438±0.00000  bestvalidloss 3.09345  last_update 41\n",
      "train: iter 111  trainloss 3.61554  validloss 3.22959±0.00000  bestvalidloss 3.09345  last_update 42\n",
      "train: iter 112  trainloss 3.65346  validloss 3.23903±0.00000  bestvalidloss 3.09345  last_update 43\n",
      "train: iter 113  trainloss 3.60389  validloss 3.21798±0.00000  bestvalidloss 3.09345  last_update 44\n",
      "train: iter 114  trainloss 3.56529  validloss 3.11223±0.00000  bestvalidloss 3.09345  last_update 45\n",
      "train: iter 115  trainloss 3.57228  validloss 3.17173±0.00000  bestvalidloss 3.09345  last_update 46\n",
      "train: iter 116  trainloss 3.59863  validloss 3.16206±0.00000  bestvalidloss 3.09345  last_update 47\n",
      "train: iter 117  trainloss 3.57984  validloss 3.22023±0.00000  bestvalidloss 3.09345  last_update 48\n",
      "train: iter 118  trainloss 3.56291  validloss 3.19729±0.00000  bestvalidloss 3.09345  last_update 49\n",
      "train: iter 119  trainloss 3.62002  validloss 3.23730±0.00000  bestvalidloss 3.09345  last_update 50\n",
      "train: iter 120  trainloss 3.59675  validloss 3.20115±0.00000  bestvalidloss 3.09345  last_update 51\n",
      "train: iter 121  trainloss 3.57267  validloss 3.24037±0.00000  bestvalidloss 3.09345  last_update 52\n",
      "train: iter 122  trainloss 3.59875  validloss 3.16077±0.00000  bestvalidloss 3.09345  last_update 53\n",
      "train: iter 123  trainloss 3.58605  validloss 3.31139±0.00000  bestvalidloss 3.09345  last_update 54\n",
      "train: iter 124  trainloss 3.60182  validloss 3.26446±0.00000  bestvalidloss 3.09345  last_update 55\n",
      "train: iter 125  trainloss 3.60071  validloss 3.20420±0.00000  bestvalidloss 3.09345  last_update 56\n",
      "train: iter 126  trainloss 3.59092  validloss 3.16350±0.00000  bestvalidloss 3.09345  last_update 57\n",
      "train: iter 127  trainloss 3.58085  validloss 3.17284±0.00000  bestvalidloss 3.09345  last_update 58\n",
      "train: iter 128  trainloss 3.62022  validloss 3.28223±0.00000  bestvalidloss 3.09345  last_update 59\n",
      "train: iter 129  trainloss 3.56966  validloss 3.19240±0.00000  bestvalidloss 3.09345  last_update 60\n",
      "train: iter 130  trainloss 3.57852  validloss 3.18785±0.00000  bestvalidloss 3.09345  last_update 61\n",
      "train: iter 131  trainloss 3.61369  validloss 3.24117±0.00000  bestvalidloss 3.09345  last_update 62\n",
      "train: iter 132  trainloss 3.56830  validloss 3.18871±0.00000  bestvalidloss 3.09345  last_update 63\n",
      "train: iter 133  trainloss 3.59130  validloss 3.19314±0.00000  bestvalidloss 3.09345  last_update 64\n",
      "train: iter 134  trainloss 3.60438  validloss 3.23378±0.00000  bestvalidloss 3.09345  last_update 65\n",
      "train: iter 135  trainloss 3.59933  validloss 3.10910±0.00000  bestvalidloss 3.09345  last_update 66\n",
      "train: iter 136  trainloss 3.57692  validloss 3.13097±0.00000  bestvalidloss 3.09345  last_update 67\n",
      "train: iter 137  trainloss 3.58627  validloss 3.21366±0.00000  bestvalidloss 3.09345  last_update 68\n",
      "train: iter 138  trainloss 3.58125  validloss 3.16368±0.00000  bestvalidloss 3.09345  last_update 69\n",
      "train: iter 139  trainloss 3.57468  validloss 3.13691±0.00000  bestvalidloss 3.09345  last_update 70\n",
      "train: iter 140  trainloss 3.53482  validloss 3.13977±0.00000  bestvalidloss 3.09345  last_update 71\n",
      "train: iter 141  trainloss 3.53953  validloss 3.20985±0.00000  bestvalidloss 3.09345  last_update 72\n",
      "train: iter 142  trainloss 3.56623  validloss 3.30464±0.00000  bestvalidloss 3.09345  last_update 73\n",
      "train: iter 143  trainloss 3.54356  validloss 3.23102±0.00000  bestvalidloss 3.09345  last_update 74\n",
      "train: iter 144  trainloss 3.57501  validloss 3.22384±0.00000  bestvalidloss 3.09345  last_update 75\n",
      "train: iter 145  trainloss 3.56316  validloss 3.14428±0.00000  bestvalidloss 3.09345  last_update 76\n",
      "train: iter 146  trainloss 3.55992  validloss 3.22254±0.00000  bestvalidloss 3.09345  last_update 77\n",
      "train: iter 147  trainloss 3.51817  validloss 3.21478±0.00000  bestvalidloss 3.09345  last_update 78\n",
      "train: iter 148  trainloss 3.56266  validloss 3.12353±0.00000  bestvalidloss 3.09345  last_update 79\n",
      "train: iter 149  trainloss 3.53611  validloss 3.09290±0.00000  bestvalidloss 3.09290  last_update 0\n",
      "train: iter 150  trainloss 3.54640  validloss 3.18058±0.00000  bestvalidloss 3.09290  last_update 1\n",
      "train: iter 151  trainloss 3.55007  validloss 3.14077±0.00000  bestvalidloss 3.09290  last_update 2\n",
      "train: iter 152  trainloss 3.58498  validloss 3.20743±0.00000  bestvalidloss 3.09290  last_update 3\n",
      "train: iter 153  trainloss 3.53992  validloss 3.14980±0.00000  bestvalidloss 3.09290  last_update 4\n",
      "train: iter 154  trainloss 3.56153  validloss 3.20603±0.00000  bestvalidloss 3.09290  last_update 5\n",
      "train: iter 155  trainloss 3.57831  validloss 3.15634±0.00000  bestvalidloss 3.09290  last_update 6\n",
      "train: iter 156  trainloss 3.53599  validloss 3.20170±0.00000  bestvalidloss 3.09290  last_update 7\n",
      "train: iter 157  trainloss 3.52365  validloss 3.17435±0.00000  bestvalidloss 3.09290  last_update 8\n",
      "train: iter 158  trainloss 3.57641  validloss 3.15663±0.00000  bestvalidloss 3.09290  last_update 9\n",
      "train: iter 159  trainloss 3.51145  validloss 3.23343±0.00000  bestvalidloss 3.09290  last_update 10\n",
      "train: iter 160  trainloss 3.57497  validloss 3.22658±0.00000  bestvalidloss 3.09290  last_update 11\n",
      "train: iter 161  trainloss 3.52634  validloss 3.19841±0.00000  bestvalidloss 3.09290  last_update 12\n",
      "train: iter 162  trainloss 3.50706  validloss 3.11531±0.00000  bestvalidloss 3.09290  last_update 13\n",
      "train: iter 163  trainloss 3.53468  validloss 3.02825±0.00000  bestvalidloss 3.02825  last_update 0\n",
      "train: iter 164  trainloss 3.54657  validloss 3.11520±0.00000  bestvalidloss 3.02825  last_update 1\n",
      "train: iter 165  trainloss 3.50070  validloss 3.15398±0.00000  bestvalidloss 3.02825  last_update 2\n",
      "train: iter 166  trainloss 3.54084  validloss 3.12337±0.00000  bestvalidloss 3.02825  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 3.54057  validloss 3.16289±0.00000  bestvalidloss 3.02825  last_update 4\n",
      "train: iter 168  trainloss 3.58526  validloss 3.17956±0.00000  bestvalidloss 3.02825  last_update 5\n",
      "train: iter 169  trainloss 3.55942  validloss 3.14101±0.00000  bestvalidloss 3.02825  last_update 6\n",
      "train: iter 170  trainloss 3.52459  validloss 3.09088±0.00000  bestvalidloss 3.02825  last_update 7\n",
      "train: iter 171  trainloss 3.56001  validloss 3.13107±0.00000  bestvalidloss 3.02825  last_update 8\n",
      "train: iter 172  trainloss 3.53561  validloss 3.15109±0.00000  bestvalidloss 3.02825  last_update 9\n",
      "train: iter 173  trainloss 3.54709  validloss 3.24475±0.00000  bestvalidloss 3.02825  last_update 10\n",
      "train: iter 174  trainloss 3.53116  validloss 3.09895±0.00000  bestvalidloss 3.02825  last_update 11\n",
      "train: iter 175  trainloss 3.49106  validloss 3.07678±0.00000  bestvalidloss 3.02825  last_update 12\n",
      "train: iter 176  trainloss 3.49896  validloss 3.25033±0.00000  bestvalidloss 3.02825  last_update 13\n",
      "train: iter 177  trainloss 3.53648  validloss 3.15663±0.00000  bestvalidloss 3.02825  last_update 14\n",
      "train: iter 178  trainloss 3.52262  validloss 3.15084±0.00000  bestvalidloss 3.02825  last_update 15\n",
      "train: iter 179  trainloss 3.51225  validloss 3.17877±0.00000  bestvalidloss 3.02825  last_update 16\n",
      "train: iter 180  trainloss 3.52522  validloss 3.16647±0.00000  bestvalidloss 3.02825  last_update 17\n",
      "train: iter 181  trainloss 3.56597  validloss 3.24087±0.00000  bestvalidloss 3.02825  last_update 18\n",
      "train: iter 182  trainloss 3.51798  validloss 3.11289±0.00000  bestvalidloss 3.02825  last_update 19\n",
      "train: iter 183  trainloss 3.54742  validloss 3.10517±0.00000  bestvalidloss 3.02825  last_update 20\n",
      "train: iter 184  trainloss 3.49528  validloss 3.19409±0.00000  bestvalidloss 3.02825  last_update 21\n",
      "train: iter 185  trainloss 3.54746  validloss 3.06264±0.00000  bestvalidloss 3.02825  last_update 22\n",
      "train: iter 186  trainloss 3.51517  validloss 3.11332±0.00000  bestvalidloss 3.02825  last_update 23\n",
      "train: iter 187  trainloss 3.50523  validloss 3.13026±0.00000  bestvalidloss 3.02825  last_update 24\n",
      "train: iter 188  trainloss 3.51632  validloss 3.13222±0.00000  bestvalidloss 3.02825  last_update 25\n",
      "train: iter 189  trainloss 3.51755  validloss 3.14411±0.00000  bestvalidloss 3.02825  last_update 26\n",
      "train: iter 190  trainloss 3.55452  validloss 3.10023±0.00000  bestvalidloss 3.02825  last_update 27\n",
      "train: iter 191  trainloss 3.54274  validloss 3.09401±0.00000  bestvalidloss 3.02825  last_update 28\n",
      "train: iter 192  trainloss 3.50649  validloss 3.23117±0.00000  bestvalidloss 3.02825  last_update 29\n",
      "train: iter 193  trainloss 3.49538  validloss 3.13276±0.00000  bestvalidloss 3.02825  last_update 30\n",
      "train: iter 194  trainloss 3.52820  validloss 3.06626±0.00000  bestvalidloss 3.02825  last_update 31\n",
      "train: iter 195  trainloss 3.50471  validloss 3.11663±0.00000  bestvalidloss 3.02825  last_update 32\n",
      "train: iter 196  trainloss 3.49425  validloss 3.11008±0.00000  bestvalidloss 3.02825  last_update 33\n",
      "train: iter 197  trainloss 3.48116  validloss 3.11833±0.00000  bestvalidloss 3.02825  last_update 34\n",
      "train: iter 198  trainloss 3.49450  validloss 3.15909±0.00000  bestvalidloss 3.02825  last_update 35\n",
      "train: iter 199  trainloss 3.51105  validloss 3.10971±0.00000  bestvalidloss 3.02825  last_update 36\n",
      "train: iter 200  trainloss 3.52189  validloss 3.15028±0.00000  bestvalidloss 3.02825  last_update 37\n",
      "train: iter 201  trainloss 3.50964  validloss 3.11450±0.00000  bestvalidloss 3.02825  last_update 38\n",
      "train: iter 202  trainloss 3.51388  validloss 3.20777±0.00000  bestvalidloss 3.02825  last_update 39\n",
      "train: iter 203  trainloss 3.53295  validloss 3.11312±0.00000  bestvalidloss 3.02825  last_update 40\n",
      "train: iter 204  trainloss 3.50085  validloss 3.12523±0.00000  bestvalidloss 3.02825  last_update 41\n",
      "train: iter 205  trainloss 3.48635  validloss 3.07929±0.00000  bestvalidloss 3.02825  last_update 42\n",
      "train: iter 206  trainloss 3.48833  validloss 3.12412±0.00000  bestvalidloss 3.02825  last_update 43\n",
      "train: iter 207  trainloss 3.47000  validloss 3.12560±0.00000  bestvalidloss 3.02825  last_update 44\n",
      "train: iter 208  trainloss 3.51191  validloss 3.09446±0.00000  bestvalidloss 3.02825  last_update 45\n",
      "train: iter 209  trainloss 3.48713  validloss 3.16384±0.00000  bestvalidloss 3.02825  last_update 46\n",
      "train: iter 210  trainloss 3.50643  validloss 3.09161±0.00000  bestvalidloss 3.02825  last_update 47\n",
      "train: iter 211  trainloss 3.51388  validloss 3.11934±0.00000  bestvalidloss 3.02825  last_update 48\n",
      "train: iter 212  trainloss 3.50822  validloss 3.15849±0.00000  bestvalidloss 3.02825  last_update 49\n",
      "train: iter 213  trainloss 3.49839  validloss 3.15393±0.00000  bestvalidloss 3.02825  last_update 50\n",
      "train: iter 214  trainloss 3.52382  validloss 3.15142±0.00000  bestvalidloss 3.02825  last_update 51\n",
      "train: iter 215  trainloss 3.46218  validloss 3.04160±0.00000  bestvalidloss 3.02825  last_update 52\n",
      "train: iter 216  trainloss 3.53345  validloss 3.17216±0.00000  bestvalidloss 3.02825  last_update 53\n",
      "train: iter 217  trainloss 3.50018  validloss 3.07943±0.00000  bestvalidloss 3.02825  last_update 54\n",
      "train: iter 218  trainloss 3.48002  validloss 3.05545±0.00000  bestvalidloss 3.02825  last_update 55\n",
      "train: iter 219  trainloss 3.48110  validloss 3.11435±0.00000  bestvalidloss 3.02825  last_update 56\n",
      "train: iter 220  trainloss 3.48050  validloss 3.12545±0.00000  bestvalidloss 3.02825  last_update 57\n",
      "train: iter 221  trainloss 3.48231  validloss 3.18976±0.00000  bestvalidloss 3.02825  last_update 58\n",
      "train: iter 222  trainloss 3.47391  validloss 3.12768±0.00000  bestvalidloss 3.02825  last_update 59\n",
      "train: iter 223  trainloss 3.48216  validloss 3.13464±0.00000  bestvalidloss 3.02825  last_update 60\n",
      "train: iter 224  trainloss 3.48604  validloss 3.22606±0.00000  bestvalidloss 3.02825  last_update 61\n",
      "train: iter 225  trainloss 3.48660  validloss 3.15581±0.00000  bestvalidloss 3.02825  last_update 62\n",
      "train: iter 226  trainloss 3.47539  validloss 3.05511±0.00000  bestvalidloss 3.02825  last_update 63\n",
      "train: iter 227  trainloss 3.50104  validloss 3.02902±0.00000  bestvalidloss 3.02825  last_update 64\n",
      "train: iter 228  trainloss 3.48325  validloss 3.07169±0.00000  bestvalidloss 3.02825  last_update 65\n",
      "train: iter 229  trainloss 3.49177  validloss 3.12529±0.00000  bestvalidloss 3.02825  last_update 66\n",
      "train: iter 230  trainloss 3.45472  validloss 3.17956±0.00000  bestvalidloss 3.02825  last_update 67\n",
      "train: iter 231  trainloss 3.52308  validloss 3.11470±0.00000  bestvalidloss 3.02825  last_update 68\n",
      "train: iter 232  trainloss 3.49221  validloss 3.11944±0.00000  bestvalidloss 3.02825  last_update 69\n",
      "train: iter 233  trainloss 3.48919  validloss 3.12036±0.00000  bestvalidloss 3.02825  last_update 70\n",
      "train: iter 234  trainloss 3.48460  validloss 3.10210±0.00000  bestvalidloss 3.02825  last_update 71\n",
      "train: iter 235  trainloss 3.49210  validloss 3.12075±0.00000  bestvalidloss 3.02825  last_update 72\n",
      "train: iter 236  trainloss 3.46336  validloss 3.12746±0.00000  bestvalidloss 3.02825  last_update 73\n",
      "train: iter 237  trainloss 3.49246  validloss 3.10126±0.00000  bestvalidloss 3.02825  last_update 74\n",
      "train: iter 238  trainloss 3.44362  validloss 3.17639±0.00000  bestvalidloss 3.02825  last_update 75\n",
      "train: iter 239  trainloss 3.48985  validloss 3.12175±0.00000  bestvalidloss 3.02825  last_update 76\n",
      "train: iter 240  trainloss 3.46630  validloss 3.02849±0.00000  bestvalidloss 3.02825  last_update 77\n",
      "train: iter 241  trainloss 3.46522  validloss 3.03867±0.00000  bestvalidloss 3.02825  last_update 78\n",
      "train: iter 242  trainloss 3.44669  validloss 3.09874±0.00000  bestvalidloss 3.02825  last_update 79\n",
      "train: iter 243  trainloss 3.49082  validloss 3.09976±0.00000  bestvalidloss 3.02825  last_update 80\n",
      "train: iter 244  trainloss 3.46509  validloss 3.08312±0.00000  bestvalidloss 3.02825  last_update 81\n",
      "train: iter 245  trainloss 3.48275  validloss 3.16997±0.00000  bestvalidloss 3.02825  last_update 82\n",
      "train: iter 246  trainloss 3.51262  validloss 3.06631±0.00000  bestvalidloss 3.02825  last_update 83\n",
      "train: iter 247  trainloss 3.48077  validloss 3.17884±0.00000  bestvalidloss 3.02825  last_update 84\n",
      "train: iter 248  trainloss 3.43577  validloss 3.04910±0.00000  bestvalidloss 3.02825  last_update 85\n",
      "train: iter 249  trainloss 3.52064  validloss 3.00265±0.00000  bestvalidloss 3.00265  last_update 0\n",
      "train: iter 250  trainloss 3.46585  validloss 3.07695±0.00000  bestvalidloss 3.00265  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 251  trainloss 3.47832  validloss 3.05565±0.00000  bestvalidloss 3.00265  last_update 2\n",
      "train: iter 252  trainloss 3.48889  validloss 3.17238±0.00000  bestvalidloss 3.00265  last_update 3\n",
      "train: iter 253  trainloss 3.47961  validloss 3.20089±0.00000  bestvalidloss 3.00265  last_update 4\n",
      "train: iter 254  trainloss 3.49228  validloss 3.13430±0.00000  bestvalidloss 3.00265  last_update 5\n",
      "train: iter 255  trainloss 3.45054  validloss 3.13670±0.00000  bestvalidloss 3.00265  last_update 6\n",
      "train: iter 256  trainloss 3.52530  validloss 3.11036±0.00000  bestvalidloss 3.00265  last_update 7\n",
      "train: iter 257  trainloss 3.44851  validloss 3.12242±0.00000  bestvalidloss 3.00265  last_update 8\n",
      "train: iter 258  trainloss 3.48303  validloss 2.99697±0.00000  bestvalidloss 2.99697  last_update 0\n",
      "train: iter 259  trainloss 3.46609  validloss 3.19830±0.00000  bestvalidloss 2.99697  last_update 1\n",
      "train: iter 260  trainloss 3.49909  validloss 3.14179±0.00000  bestvalidloss 2.99697  last_update 2\n",
      "train: iter 261  trainloss 3.46011  validloss 3.09035±0.00000  bestvalidloss 2.99697  last_update 3\n",
      "train: iter 262  trainloss 3.48280  validloss 3.11876±0.00000  bestvalidloss 2.99697  last_update 4\n",
      "train: iter 263  trainloss 3.46010  validloss 3.10403±0.00000  bestvalidloss 2.99697  last_update 5\n",
      "train: iter 264  trainloss 3.47976  validloss 3.18797±0.00000  bestvalidloss 2.99697  last_update 6\n",
      "train: iter 265  trainloss 3.44513  validloss 3.10727±0.00000  bestvalidloss 2.99697  last_update 7\n",
      "train: iter 266  trainloss 3.45342  validloss 3.06864±0.00000  bestvalidloss 2.99697  last_update 8\n",
      "train: iter 267  trainloss 3.46038  validloss 3.12610±0.00000  bestvalidloss 2.99697  last_update 9\n",
      "train: iter 268  trainloss 3.46994  validloss 3.00551±0.00000  bestvalidloss 2.99697  last_update 10\n",
      "train: iter 269  trainloss 3.45479  validloss 3.13034±0.00000  bestvalidloss 2.99697  last_update 11\n",
      "train: iter 270  trainloss 3.50010  validloss 3.10615±0.00000  bestvalidloss 2.99697  last_update 12\n",
      "train: iter 271  trainloss 3.45361  validloss 3.07295±0.00000  bestvalidloss 2.99697  last_update 13\n",
      "train: iter 272  trainloss 3.48428  validloss 3.10619±0.00000  bestvalidloss 2.99697  last_update 14\n",
      "train: iter 273  trainloss 3.47225  validloss 3.09663±0.00000  bestvalidloss 2.99697  last_update 15\n",
      "train: iter 274  trainloss 3.45760  validloss 3.06245±0.00000  bestvalidloss 2.99697  last_update 16\n",
      "train: iter 275  trainloss 3.46151  validloss 3.22395±0.00000  bestvalidloss 2.99697  last_update 17\n",
      "train: iter 276  trainloss 3.46318  validloss 3.11907±0.00000  bestvalidloss 2.99697  last_update 18\n",
      "train: iter 277  trainloss 3.45301  validloss 3.10194±0.00000  bestvalidloss 2.99697  last_update 19\n",
      "train: iter 278  trainloss 3.45313  validloss 3.14556±0.00000  bestvalidloss 2.99697  last_update 20\n",
      "train: iter 279  trainloss 3.47830  validloss 3.04431±0.00000  bestvalidloss 2.99697  last_update 21\n",
      "train: iter 280  trainloss 3.48349  validloss 3.19224±0.00000  bestvalidloss 2.99697  last_update 22\n",
      "train: iter 281  trainloss 3.45486  validloss 3.04619±0.00000  bestvalidloss 2.99697  last_update 23\n",
      "train: iter 282  trainloss 3.47519  validloss 3.10172±0.00000  bestvalidloss 2.99697  last_update 24\n",
      "train: iter 283  trainloss 3.48631  validloss 3.14677±0.00000  bestvalidloss 2.99697  last_update 25\n",
      "train: iter 284  trainloss 3.47838  validloss 3.08177±0.00000  bestvalidloss 2.99697  last_update 26\n",
      "train: iter 285  trainloss 3.46944  validloss 3.12079±0.00000  bestvalidloss 2.99697  last_update 27\n",
      "train: iter 286  trainloss 3.43800  validloss 3.15191±0.00000  bestvalidloss 2.99697  last_update 28\n",
      "train: iter 287  trainloss 3.48702  validloss 3.15584±0.00000  bestvalidloss 2.99697  last_update 29\n",
      "train: iter 288  trainloss 3.49317  validloss 3.08998±0.00000  bestvalidloss 2.99697  last_update 30\n",
      "train: iter 289  trainloss 3.46450  validloss 3.16058±0.00000  bestvalidloss 2.99697  last_update 31\n",
      "train: iter 290  trainloss 3.46085  validloss 3.16218±0.00000  bestvalidloss 2.99697  last_update 32\n",
      "train: iter 291  trainloss 3.44741  validloss 3.07963±0.00000  bestvalidloss 2.99697  last_update 33\n",
      "train: iter 292  trainloss 3.47030  validloss 3.09669±0.00000  bestvalidloss 2.99697  last_update 34\n",
      "train: iter 293  trainloss 3.46724  validloss 3.08136±0.00000  bestvalidloss 2.99697  last_update 35\n",
      "train: iter 294  trainloss 3.47336  validloss 3.07406±0.00000  bestvalidloss 2.99697  last_update 36\n",
      "train: iter 295  trainloss 3.47307  validloss 3.13324±0.00000  bestvalidloss 2.99697  last_update 37\n",
      "train: iter 296  trainloss 3.44501  validloss 3.17890±0.00000  bestvalidloss 2.99697  last_update 38\n",
      "train: iter 297  trainloss 3.47633  validloss 3.09901±0.00000  bestvalidloss 2.99697  last_update 39\n",
      "train: iter 298  trainloss 3.42893  validloss 3.01352±0.00000  bestvalidloss 2.99697  last_update 40\n",
      "train: iter 299  trainloss 3.45462  validloss 3.09537±0.00000  bestvalidloss 2.99697  last_update 41\n",
      "train: iter 300  trainloss 3.45047  validloss 3.02353±0.00000  bestvalidloss 2.99697  last_update 42\n",
      "train: iter 301  trainloss 3.46293  validloss 3.14963±0.00000  bestvalidloss 2.99697  last_update 43\n",
      "train: iter 302  trainloss 3.42477  validloss 3.07742±0.00000  bestvalidloss 2.99697  last_update 44\n",
      "train: iter 303  trainloss 3.46136  validloss 3.12304±0.00000  bestvalidloss 2.99697  last_update 45\n",
      "train: iter 304  trainloss 3.49978  validloss 3.11514±0.00000  bestvalidloss 2.99697  last_update 46\n",
      "train: iter 305  trainloss 3.44658  validloss 3.14659±0.00000  bestvalidloss 2.99697  last_update 47\n",
      "train: iter 306  trainloss 3.48851  validloss 3.16588±0.00000  bestvalidloss 2.99697  last_update 48\n",
      "train: iter 307  trainloss 3.43468  validloss 3.10638±0.00000  bestvalidloss 2.99697  last_update 49\n",
      "train: iter 308  trainloss 3.43438  validloss 3.13028±0.00000  bestvalidloss 2.99697  last_update 50\n",
      "train: iter 309  trainloss 3.46729  validloss 3.14825±0.00000  bestvalidloss 2.99697  last_update 51\n",
      "train: iter 310  trainloss 3.45869  validloss 3.10462±0.00000  bestvalidloss 2.99697  last_update 52\n",
      "train: iter 311  trainloss 3.45322  validloss 3.12013±0.00000  bestvalidloss 2.99697  last_update 53\n",
      "train: iter 312  trainloss 3.47611  validloss 3.13102±0.00000  bestvalidloss 2.99697  last_update 54\n",
      "train: iter 313  trainloss 3.50321  validloss 3.16618±0.00000  bestvalidloss 2.99697  last_update 55\n",
      "train: iter 314  trainloss 3.44911  validloss 3.09546±0.00000  bestvalidloss 2.99697  last_update 56\n",
      "train: iter 315  trainloss 3.43687  validloss 3.19493±0.00000  bestvalidloss 2.99697  last_update 57\n",
      "train: iter 316  trainloss 3.44689  validloss 3.09942±0.00000  bestvalidloss 2.99697  last_update 58\n",
      "train: iter 317  trainloss 3.43770  validloss 3.05956±0.00000  bestvalidloss 2.99697  last_update 59\n",
      "train: iter 318  trainloss 3.40165  validloss 3.04490±0.00000  bestvalidloss 2.99697  last_update 60\n",
      "train: iter 319  trainloss 3.42062  validloss 3.14504±0.00000  bestvalidloss 2.99697  last_update 61\n",
      "train: iter 320  trainloss 3.42390  validloss 3.07318±0.00000  bestvalidloss 2.99697  last_update 62\n",
      "train: iter 321  trainloss 3.47319  validloss 3.08650±0.00000  bestvalidloss 2.99697  last_update 63\n",
      "train: iter 322  trainloss 3.45745  validloss 3.07634±0.00000  bestvalidloss 2.99697  last_update 64\n",
      "train: iter 323  trainloss 3.42240  validloss 3.11879±0.00000  bestvalidloss 2.99697  last_update 65\n",
      "train: iter 324  trainloss 3.45850  validloss 3.03836±0.00000  bestvalidloss 2.99697  last_update 66\n",
      "train: iter 325  trainloss 3.46400  validloss 3.07145±0.00000  bestvalidloss 2.99697  last_update 67\n",
      "train: iter 326  trainloss 3.42693  validloss 3.12732±0.00000  bestvalidloss 2.99697  last_update 68\n",
      "train: iter 327  trainloss 3.45254  validloss 3.16573±0.00000  bestvalidloss 2.99697  last_update 69\n",
      "train: iter 328  trainloss 3.41349  validloss 3.01068±0.00000  bestvalidloss 2.99697  last_update 70\n",
      "train: iter 329  trainloss 3.47414  validloss 3.07883±0.00000  bestvalidloss 2.99697  last_update 71\n",
      "train: iter 330  trainloss 3.42943  validloss 3.11408±0.00000  bestvalidloss 2.99697  last_update 72\n",
      "train: iter 331  trainloss 3.46022  validloss 3.12531±0.00000  bestvalidloss 2.99697  last_update 73\n",
      "train: iter 332  trainloss 3.46413  validloss 3.12635±0.00000  bestvalidloss 2.99697  last_update 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 333  trainloss 3.43228  validloss 3.12986±0.00000  bestvalidloss 2.99697  last_update 75\n",
      "train: iter 334  trainloss 3.45432  validloss 2.96872±0.00000  bestvalidloss 2.96872  last_update 0\n",
      "train: iter 335  trainloss 3.45316  validloss 3.07765±0.00000  bestvalidloss 2.96872  last_update 1\n",
      "train: iter 336  trainloss 3.45001  validloss 3.07103±0.00000  bestvalidloss 2.96872  last_update 2\n",
      "train: iter 337  trainloss 3.45089  validloss 3.10476±0.00000  bestvalidloss 2.96872  last_update 3\n",
      "train: iter 338  trainloss 3.42415  validloss 3.03069±0.00000  bestvalidloss 2.96872  last_update 4\n",
      "train: iter 339  trainloss 3.42390  validloss 3.13781±0.00000  bestvalidloss 2.96872  last_update 5\n",
      "train: iter 340  trainloss 3.40322  validloss 3.15792±0.00000  bestvalidloss 2.96872  last_update 6\n",
      "train: iter 341  trainloss 3.44074  validloss 3.10639±0.00000  bestvalidloss 2.96872  last_update 7\n",
      "train: iter 342  trainloss 3.46810  validloss 3.03607±0.00000  bestvalidloss 2.96872  last_update 8\n",
      "train: iter 343  trainloss 3.45473  validloss 3.00422±0.00000  bestvalidloss 2.96872  last_update 9\n",
      "train: iter 344  trainloss 3.47808  validloss 3.10520±0.00000  bestvalidloss 2.96872  last_update 10\n",
      "train: iter 345  trainloss 3.40686  validloss 3.03051±0.00000  bestvalidloss 2.96872  last_update 11\n",
      "train: iter 346  trainloss 3.44374  validloss 3.08574±0.00000  bestvalidloss 2.96872  last_update 12\n",
      "train: iter 347  trainloss 3.42134  validloss 3.09864±0.00000  bestvalidloss 2.96872  last_update 13\n",
      "train: iter 348  trainloss 3.43180  validloss 3.15698±0.00000  bestvalidloss 2.96872  last_update 14\n",
      "train: iter 349  trainloss 3.45005  validloss 3.04112±0.00000  bestvalidloss 2.96872  last_update 15\n",
      "train: iter 350  trainloss 3.42157  validloss 3.04230±0.00000  bestvalidloss 2.96872  last_update 16\n",
      "train: iter 351  trainloss 3.41956  validloss 2.98739±0.00000  bestvalidloss 2.96872  last_update 17\n",
      "train: iter 352  trainloss 3.43961  validloss 3.17624±0.00000  bestvalidloss 2.96872  last_update 18\n",
      "train: iter 353  trainloss 3.41176  validloss 3.06737±0.00000  bestvalidloss 2.96872  last_update 19\n",
      "train: iter 354  trainloss 3.40601  validloss 3.16808±0.00000  bestvalidloss 2.96872  last_update 20\n",
      "train: iter 355  trainloss 3.42293  validloss 3.11633±0.00000  bestvalidloss 2.96872  last_update 21\n",
      "train: iter 356  trainloss 3.42196  validloss 3.16797±0.00000  bestvalidloss 2.96872  last_update 22\n",
      "train: iter 357  trainloss 3.43916  validloss 3.12574±0.00000  bestvalidloss 2.96872  last_update 23\n",
      "train: iter 358  trainloss 3.48712  validloss 3.03119±0.00000  bestvalidloss 2.96872  last_update 24\n",
      "train: iter 359  trainloss 3.44726  validloss 3.13563±0.00000  bestvalidloss 2.96872  last_update 25\n",
      "train: iter 360  trainloss 3.40989  validloss 3.11504±0.00000  bestvalidloss 2.96872  last_update 26\n",
      "train: iter 361  trainloss 3.44419  validloss 3.09020±0.00000  bestvalidloss 2.96872  last_update 27\n",
      "train: iter 362  trainloss 3.43899  validloss 3.14029±0.00000  bestvalidloss 2.96872  last_update 28\n",
      "train: iter 363  trainloss 3.43368  validloss 3.02562±0.00000  bestvalidloss 2.96872  last_update 29\n",
      "train: iter 364  trainloss 3.44398  validloss 3.04527±0.00000  bestvalidloss 2.96872  last_update 30\n",
      "train: iter 365  trainloss 3.43869  validloss 3.11676±0.00000  bestvalidloss 2.96872  last_update 31\n",
      "train: iter 366  trainloss 3.42664  validloss 3.14956±0.00000  bestvalidloss 2.96872  last_update 32\n",
      "train: iter 367  trainloss 3.40973  validloss 3.00374±0.00000  bestvalidloss 2.96872  last_update 33\n",
      "train: iter 368  trainloss 3.43831  validloss 3.09438±0.00000  bestvalidloss 2.96872  last_update 34\n",
      "train: iter 369  trainloss 3.47502  validloss 3.11854±0.00000  bestvalidloss 2.96872  last_update 35\n",
      "train: iter 370  trainloss 3.42888  validloss 3.04306±0.00000  bestvalidloss 2.96872  last_update 36\n",
      "train: iter 371  trainloss 3.39918  validloss 3.10169±0.00000  bestvalidloss 2.96872  last_update 37\n",
      "train: iter 372  trainloss 3.45023  validloss 2.98095±0.00000  bestvalidloss 2.96872  last_update 38\n",
      "train: iter 373  trainloss 3.43813  validloss 3.14677±0.00000  bestvalidloss 2.96872  last_update 39\n",
      "train: iter 374  trainloss 3.43260  validloss 3.08289±0.00000  bestvalidloss 2.96872  last_update 40\n",
      "train: iter 375  trainloss 3.46499  validloss 3.01312±0.00000  bestvalidloss 2.96872  last_update 41\n",
      "train: iter 376  trainloss 3.41660  validloss 3.03984±0.00000  bestvalidloss 2.96872  last_update 42\n",
      "train: iter 377  trainloss 3.41001  validloss 3.03972±0.00000  bestvalidloss 2.96872  last_update 43\n",
      "train: iter 378  trainloss 3.43554  validloss 3.08626±0.00000  bestvalidloss 2.96872  last_update 44\n",
      "train: iter 379  trainloss 3.41947  validloss 3.11151±0.00000  bestvalidloss 2.96872  last_update 45\n",
      "train: iter 380  trainloss 3.42652  validloss 3.15484±0.00000  bestvalidloss 2.96872  last_update 46\n",
      "train: iter 381  trainloss 3.41134  validloss 3.29938±0.00000  bestvalidloss 2.96872  last_update 47\n",
      "train: iter 382  trainloss 3.42182  validloss 3.11091±0.00000  bestvalidloss 2.96872  last_update 48\n",
      "train: iter 383  trainloss 3.40248  validloss 3.14812±0.00000  bestvalidloss 2.96872  last_update 49\n",
      "train: iter 384  trainloss 3.41066  validloss 3.05230±0.00000  bestvalidloss 2.96872  last_update 50\n",
      "train: iter 385  trainloss 3.43628  validloss 3.03181±0.00000  bestvalidloss 2.96872  last_update 51\n",
      "train: iter 386  trainloss 3.39448  validloss 3.12428±0.00000  bestvalidloss 2.96872  last_update 52\n",
      "train: iter 387  trainloss 3.44344  validloss 3.07954±0.00000  bestvalidloss 2.96872  last_update 53\n",
      "train: iter 388  trainloss 3.41232  validloss 3.05882±0.00000  bestvalidloss 2.96872  last_update 54\n",
      "train: iter 389  trainloss 3.40723  validloss 2.98314±0.00000  bestvalidloss 2.96872  last_update 55\n",
      "train: iter 390  trainloss 3.40805  validloss 3.13134±0.00000  bestvalidloss 2.96872  last_update 56\n",
      "train: iter 391  trainloss 3.43558  validloss 3.11291±0.00000  bestvalidloss 2.96872  last_update 57\n",
      "train: iter 392  trainloss 3.45221  validloss 3.10096±0.00000  bestvalidloss 2.96872  last_update 58\n",
      "train: iter 393  trainloss 3.43091  validloss 3.07999±0.00000  bestvalidloss 2.96872  last_update 59\n",
      "train: iter 394  trainloss 3.41261  validloss 3.10630±0.00000  bestvalidloss 2.96872  last_update 60\n",
      "train: iter 395  trainloss 3.43525  validloss 3.03209±0.00000  bestvalidloss 2.96872  last_update 61\n",
      "train: iter 396  trainloss 3.39808  validloss 3.07961±0.00000  bestvalidloss 2.96872  last_update 62\n",
      "train: iter 397  trainloss 3.42302  validloss 3.09743±0.00000  bestvalidloss 2.96872  last_update 63\n",
      "train: iter 398  trainloss 3.43204  validloss 2.96418±0.00000  bestvalidloss 2.96418  last_update 0\n",
      "train: iter 399  trainloss 3.38231  validloss 3.04629±0.00000  bestvalidloss 2.96418  last_update 1\n",
      "train: iter 400  trainloss 3.39296  validloss 3.10222±0.00000  bestvalidloss 2.96418  last_update 2\n",
      "train: iter 401  trainloss 3.41200  validloss 3.13029±0.00000  bestvalidloss 2.96418  last_update 3\n",
      "train: iter 402  trainloss 3.43406  validloss 3.11514±0.00000  bestvalidloss 2.96418  last_update 4\n",
      "train: iter 403  trainloss 3.45915  validloss 3.08192±0.00000  bestvalidloss 2.96418  last_update 5\n",
      "train: iter 404  trainloss 3.41701  validloss 2.97848±0.00000  bestvalidloss 2.96418  last_update 6\n",
      "train: iter 405  trainloss 3.43657  validloss 3.15584±0.00000  bestvalidloss 2.96418  last_update 7\n",
      "train: iter 406  trainloss 3.39931  validloss 3.14665±0.00000  bestvalidloss 2.96418  last_update 8\n",
      "train: iter 407  trainloss 3.39803  validloss 3.02854±0.00000  bestvalidloss 2.96418  last_update 9\n",
      "train: iter 408  trainloss 3.43060  validloss 3.03713±0.00000  bestvalidloss 2.96418  last_update 10\n",
      "train: iter 409  trainloss 3.40613  validloss 3.06807±0.00000  bestvalidloss 2.96418  last_update 11\n",
      "train: iter 410  trainloss 3.42473  validloss 3.09186±0.00000  bestvalidloss 2.96418  last_update 12\n",
      "train: iter 411  trainloss 3.40924  validloss 3.12706±0.00000  bestvalidloss 2.96418  last_update 13\n",
      "train: iter 412  trainloss 3.40982  validloss 3.03875±0.00000  bestvalidloss 2.96418  last_update 14\n",
      "train: iter 413  trainloss 3.40675  validloss 3.03514±0.00000  bestvalidloss 2.96418  last_update 15\n",
      "train: iter 414  trainloss 3.39856  validloss 3.09439±0.00000  bestvalidloss 2.96418  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 415  trainloss 3.42645  validloss 3.01262±0.00000  bestvalidloss 2.96418  last_update 17\n",
      "train: iter 416  trainloss 3.40426  validloss 3.07851±0.00000  bestvalidloss 2.96418  last_update 18\n",
      "train: iter 417  trainloss 3.41309  validloss 3.04765±0.00000  bestvalidloss 2.96418  last_update 19\n",
      "train: iter 418  trainloss 3.42223  validloss 2.99842±0.00000  bestvalidloss 2.96418  last_update 20\n",
      "train: iter 419  trainloss 3.41504  validloss 3.03489±0.00000  bestvalidloss 2.96418  last_update 21\n",
      "train: iter 420  trainloss 3.38576  validloss 3.00173±0.00000  bestvalidloss 2.96418  last_update 22\n",
      "train: iter 421  trainloss 3.42042  validloss 2.95228±0.00000  bestvalidloss 2.95228  last_update 0\n",
      "train: iter 422  trainloss 3.39486  validloss 3.11357±0.00000  bestvalidloss 2.95228  last_update 1\n",
      "train: iter 423  trainloss 3.40504  validloss 3.14378±0.00000  bestvalidloss 2.95228  last_update 2\n",
      "train: iter 424  trainloss 3.41908  validloss 2.99453±0.00000  bestvalidloss 2.95228  last_update 3\n",
      "train: iter 425  trainloss 3.42838  validloss 3.07099±0.00000  bestvalidloss 2.95228  last_update 4\n",
      "train: iter 426  trainloss 3.41008  validloss 3.12698±0.00000  bestvalidloss 2.95228  last_update 5\n",
      "train: iter 427  trainloss 3.40727  validloss 3.11765±0.00000  bestvalidloss 2.95228  last_update 6\n",
      "train: iter 428  trainloss 3.43790  validloss 3.12488±0.00000  bestvalidloss 2.95228  last_update 7\n",
      "train: iter 429  trainloss 3.43099  validloss 3.11494±0.00000  bestvalidloss 2.95228  last_update 8\n",
      "train: iter 430  trainloss 3.41816  validloss 3.07149±0.00000  bestvalidloss 2.95228  last_update 9\n",
      "train: iter 431  trainloss 3.39810  validloss 3.08077±0.00000  bestvalidloss 2.95228  last_update 10\n",
      "train: iter 432  trainloss 3.40798  validloss 3.09871±0.00000  bestvalidloss 2.95228  last_update 11\n",
      "train: iter 433  trainloss 3.38492  validloss 3.06910±0.00000  bestvalidloss 2.95228  last_update 12\n",
      "train: iter 434  trainloss 3.37402  validloss 3.08580±0.00000  bestvalidloss 2.95228  last_update 13\n",
      "train: iter 435  trainloss 3.41076  validloss 3.17866±0.00000  bestvalidloss 2.95228  last_update 14\n",
      "train: iter 436  trainloss 3.41521  validloss 3.07853±0.00000  bestvalidloss 2.95228  last_update 15\n",
      "train: iter 437  trainloss 3.42666  validloss 3.04099±0.00000  bestvalidloss 2.95228  last_update 16\n",
      "train: iter 438  trainloss 3.39786  validloss 3.05968±0.00000  bestvalidloss 2.95228  last_update 17\n",
      "train: iter 439  trainloss 3.39300  validloss 3.18329±0.00000  bestvalidloss 2.95228  last_update 18\n",
      "train: iter 440  trainloss 3.40042  validloss 3.14753±0.00000  bestvalidloss 2.95228  last_update 19\n",
      "train: iter 441  trainloss 3.40536  validloss 3.07694±0.00000  bestvalidloss 2.95228  last_update 20\n",
      "train: iter 442  trainloss 3.42409  validloss 3.11056±0.00000  bestvalidloss 2.95228  last_update 21\n",
      "train: iter 443  trainloss 3.40164  validloss 3.06216±0.00000  bestvalidloss 2.95228  last_update 22\n",
      "train: iter 444  trainloss 3.39475  validloss 2.99662±0.00000  bestvalidloss 2.95228  last_update 23\n",
      "train: iter 445  trainloss 3.40173  validloss 3.10995±0.00000  bestvalidloss 2.95228  last_update 24\n",
      "train: iter 446  trainloss 3.40448  validloss 3.15672±0.00000  bestvalidloss 2.95228  last_update 25\n",
      "train: iter 447  trainloss 3.45844  validloss 3.00590±0.00000  bestvalidloss 2.95228  last_update 26\n",
      "train: iter 448  trainloss 3.36747  validloss 3.08989±0.00000  bestvalidloss 2.95228  last_update 27\n",
      "train: iter 449  trainloss 3.39277  validloss 2.98529±0.00000  bestvalidloss 2.95228  last_update 28\n",
      "train: iter 450  trainloss 3.42210  validloss 3.04388±0.00000  bestvalidloss 2.95228  last_update 29\n",
      "train: iter 451  trainloss 3.37325  validloss 3.08580±0.00000  bestvalidloss 2.95228  last_update 30\n",
      "train: iter 452  trainloss 3.43242  validloss 2.97387±0.00000  bestvalidloss 2.95228  last_update 31\n",
      "train: iter 453  trainloss 3.41110  validloss 3.14164±0.00000  bestvalidloss 2.95228  last_update 32\n",
      "train: iter 454  trainloss 3.40425  validloss 3.01733±0.00000  bestvalidloss 2.95228  last_update 33\n",
      "train: iter 455  trainloss 3.36062  validloss 3.07261±0.00000  bestvalidloss 2.95228  last_update 34\n",
      "train: iter 456  trainloss 3.41374  validloss 3.16762±0.00000  bestvalidloss 2.95228  last_update 35\n",
      "train: iter 457  trainloss 3.43158  validloss 3.07380±0.00000  bestvalidloss 2.95228  last_update 36\n",
      "train: iter 458  trainloss 3.43230  validloss 3.14987±0.00000  bestvalidloss 2.95228  last_update 37\n",
      "train: iter 459  trainloss 3.38083  validloss 3.01861±0.00000  bestvalidloss 2.95228  last_update 38\n",
      "train: iter 460  trainloss 3.40356  validloss 3.11981±0.00000  bestvalidloss 2.95228  last_update 39\n",
      "train: iter 461  trainloss 3.37265  validloss 3.07196±0.00000  bestvalidloss 2.95228  last_update 40\n",
      "train: iter 462  trainloss 3.40409  validloss 2.99956±0.00000  bestvalidloss 2.95228  last_update 41\n",
      "train: iter 463  trainloss 3.39596  validloss 3.04817±0.00000  bestvalidloss 2.95228  last_update 42\n",
      "train: iter 464  trainloss 3.34560  validloss 3.13744±0.00000  bestvalidloss 2.95228  last_update 43\n",
      "train: iter 465  trainloss 3.39561  validloss 3.09722±0.00000  bestvalidloss 2.95228  last_update 44\n",
      "train: iter 466  trainloss 3.38197  validloss 3.05989±0.00000  bestvalidloss 2.95228  last_update 45\n",
      "train: iter 467  trainloss 3.42852  validloss 3.12510±0.00000  bestvalidloss 2.95228  last_update 46\n",
      "train: iter 468  trainloss 3.39483  validloss 3.00865±0.00000  bestvalidloss 2.95228  last_update 47\n",
      "train: iter 469  trainloss 3.40354  validloss 3.10187±0.00000  bestvalidloss 2.95228  last_update 48\n",
      "train: iter 470  trainloss 3.40623  validloss 3.02366±0.00000  bestvalidloss 2.95228  last_update 49\n",
      "train: iter 471  trainloss 3.39420  validloss 3.04313±0.00000  bestvalidloss 2.95228  last_update 50\n",
      "train: iter 472  trainloss 3.39574  validloss 3.03853±0.00000  bestvalidloss 2.95228  last_update 51\n",
      "train: iter 473  trainloss 3.37620  validloss 2.98610±0.00000  bestvalidloss 2.95228  last_update 52\n",
      "train: iter 474  trainloss 3.38239  validloss 2.99317±0.00000  bestvalidloss 2.95228  last_update 53\n",
      "train: iter 475  trainloss 3.37555  validloss 3.10867±0.00000  bestvalidloss 2.95228  last_update 54\n",
      "train: iter 476  trainloss 3.38804  validloss 2.97448±0.00000  bestvalidloss 2.95228  last_update 55\n",
      "train: iter 477  trainloss 3.38826  validloss 3.02238±0.00000  bestvalidloss 2.95228  last_update 56\n",
      "train: iter 478  trainloss 3.40028  validloss 3.28661±0.00000  bestvalidloss 2.95228  last_update 57\n",
      "train: iter 479  trainloss 3.37266  validloss 3.08743±0.00000  bestvalidloss 2.95228  last_update 58\n",
      "train: iter 480  trainloss 3.38151  validloss 3.14511±0.00000  bestvalidloss 2.95228  last_update 59\n",
      "train: iter 481  trainloss 3.39003  validloss 3.08143±0.00000  bestvalidloss 2.95228  last_update 60\n",
      "train: iter 482  trainloss 3.37675  validloss 3.03299±0.00000  bestvalidloss 2.95228  last_update 61\n",
      "train: iter 483  trainloss 3.39683  validloss 3.02267±0.00000  bestvalidloss 2.95228  last_update 62\n",
      "train: iter 484  trainloss 3.32825  validloss 3.07941±0.00000  bestvalidloss 2.95228  last_update 63\n",
      "train: iter 485  trainloss 3.35914  validloss 3.13851±0.00000  bestvalidloss 2.95228  last_update 64\n",
      "train: iter 486  trainloss 3.38414  validloss 3.08344±0.00000  bestvalidloss 2.95228  last_update 65\n",
      "train: iter 487  trainloss 3.43907  validloss 2.98235±0.00000  bestvalidloss 2.95228  last_update 66\n",
      "train: iter 488  trainloss 3.37388  validloss 3.02057±0.00000  bestvalidloss 2.95228  last_update 67\n",
      "train: iter 489  trainloss 3.36809  validloss 3.14369±0.00000  bestvalidloss 2.95228  last_update 68\n",
      "train: iter 490  trainloss 3.35086  validloss 3.01881±0.00000  bestvalidloss 2.95228  last_update 69\n",
      "train: iter 491  trainloss 3.42049  validloss 3.08181±0.00000  bestvalidloss 2.95228  last_update 70\n",
      "train: iter 492  trainloss 3.38666  validloss 3.10327±0.00000  bestvalidloss 2.95228  last_update 71\n",
      "train: iter 493  trainloss 3.38494  validloss 3.00055±0.00000  bestvalidloss 2.95228  last_update 72\n",
      "train: iter 494  trainloss 3.39080  validloss 3.08727±0.00000  bestvalidloss 2.95228  last_update 73\n",
      "train: iter 495  trainloss 3.40271  validloss 3.11714±0.00000  bestvalidloss 2.95228  last_update 74\n",
      "train: iter 496  trainloss 3.36463  validloss 3.07703±0.00000  bestvalidloss 2.95228  last_update 75\n",
      "train: iter 497  trainloss 3.39499  validloss 3.06505±0.00000  bestvalidloss 2.95228  last_update 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 498  trainloss 3.39196  validloss 3.10579±0.00000  bestvalidloss 2.95228  last_update 77\n",
      "train: iter 499  trainloss 3.37138  validloss 3.12845±0.00000  bestvalidloss 2.95228  last_update 78\n",
      "train: iter 500  trainloss 3.38974  validloss 3.07197±0.00000  bestvalidloss 2.95228  last_update 79\n",
      "train: iter 501  trainloss 3.38137  validloss 3.10422±0.00000  bestvalidloss 2.95228  last_update 80\n",
      "train: iter 502  trainloss 3.40226  validloss 3.06699±0.00000  bestvalidloss 2.95228  last_update 81\n",
      "train: iter 503  trainloss 3.37332  validloss 3.05025±0.00000  bestvalidloss 2.95228  last_update 82\n",
      "train: iter 504  trainloss 3.34005  validloss 3.02482±0.00000  bestvalidloss 2.95228  last_update 83\n",
      "train: iter 505  trainloss 3.37344  validloss 3.04000±0.00000  bestvalidloss 2.95228  last_update 84\n",
      "train: iter 506  trainloss 3.38624  validloss 3.04710±0.00000  bestvalidloss 2.95228  last_update 85\n",
      "train: iter 507  trainloss 3.37871  validloss 3.10803±0.00000  bestvalidloss 2.95228  last_update 86\n",
      "train: iter 508  trainloss 3.37281  validloss 3.01436±0.00000  bestvalidloss 2.95228  last_update 87\n",
      "train: iter 509  trainloss 3.35430  validloss 3.15526±0.00000  bestvalidloss 2.95228  last_update 88\n",
      "train: iter 510  trainloss 3.32950  validloss 3.02320±0.00000  bestvalidloss 2.95228  last_update 89\n",
      "train: iter 511  trainloss 3.39974  validloss 3.11434±0.00000  bestvalidloss 2.95228  last_update 90\n",
      "train: iter 512  trainloss 3.36683  validloss 3.04778±0.00000  bestvalidloss 2.95228  last_update 91\n",
      "train: iter 513  trainloss 3.39522  validloss 3.07625±0.00000  bestvalidloss 2.95228  last_update 92\n",
      "train: iter 514  trainloss 3.38662  validloss 3.06936±0.00000  bestvalidloss 2.95228  last_update 93\n",
      "train: iter 515  trainloss 3.41782  validloss 2.98366±0.00000  bestvalidloss 2.95228  last_update 94\n",
      "train: iter 516  trainloss 3.38836  validloss 3.01310±0.00000  bestvalidloss 2.95228  last_update 95\n",
      "train: iter 517  trainloss 3.37765  validloss 3.11198±0.00000  bestvalidloss 2.95228  last_update 96\n",
      "train: iter 518  trainloss 3.38134  validloss 3.06709±0.00000  bestvalidloss 2.95228  last_update 97\n",
      "train: iter 519  trainloss 3.40163  validloss 3.00580±0.00000  bestvalidloss 2.95228  last_update 98\n",
      "train: iter 520  trainloss 3.35545  validloss 3.06546±0.00000  bestvalidloss 2.95228  last_update 99\n",
      "train: iter 521  trainloss 3.32958  validloss 3.06518±0.00000  bestvalidloss 2.95228  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-9.7880)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(6.1169)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2691383849038021\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8317d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492078e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e2a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17d8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b33d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
