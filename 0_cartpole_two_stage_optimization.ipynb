{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(303.9796)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 674.58580  validloss 1064.34612±0.00000  bestvalidloss 1064.34612  last_update 0\n",
      "train: iter 1  trainloss 235.29732  validloss 767.41985±0.00000  bestvalidloss 767.41985  last_update 0\n",
      "train: iter 2  trainloss -109.86995  validloss -12.48948±0.00000  bestvalidloss -12.48948  last_update 0\n",
      "train: iter 3  trainloss -397.95858  validloss -297.35947±0.00000  bestvalidloss -297.35947  last_update 0\n",
      "train: iter 4  trainloss -551.59015  validloss -558.04159±0.00000  bestvalidloss -558.04159  last_update 0\n",
      "train: iter 5  trainloss -667.27192  validloss -540.78700±0.00000  bestvalidloss -558.04159  last_update 1\n",
      "train: iter 6  trainloss -774.59714  validloss -754.32381±0.00000  bestvalidloss -754.32381  last_update 0\n",
      "train: iter 7  trainloss -789.91110  validloss -705.72815±0.00000  bestvalidloss -754.32381  last_update 1\n",
      "train: iter 8  trainloss -839.96869  validloss -917.21870±0.00000  bestvalidloss -917.21870  last_update 0\n",
      "train: iter 9  trainloss -902.88203  validloss -983.57786±0.00000  bestvalidloss -983.57786  last_update 0\n",
      "train: iter 10  trainloss -898.44030  validloss -890.36709±0.00000  bestvalidloss -983.57786  last_update 1\n",
      "train: iter 11  trainloss -922.54093  validloss -533.57823±0.00000  bestvalidloss -983.57786  last_update 2\n",
      "train: iter 12  trainloss -938.91545  validloss -286.54257±0.00000  bestvalidloss -983.57786  last_update 3\n",
      "train: iter 13  trainloss -1083.63114  validloss 1545.54207±0.00000  bestvalidloss -983.57786  last_update 4\n",
      "train: iter 14  trainloss -1063.12247  validloss -209.00858±0.00000  bestvalidloss -983.57786  last_update 5\n",
      "train: iter 15  trainloss -1094.59875  validloss -134.56062±0.00000  bestvalidloss -983.57786  last_update 6\n",
      "train: iter 16  trainloss -1145.26993  validloss 933.76230±0.00000  bestvalidloss -983.57786  last_update 7\n",
      "train: iter 17  trainloss -1240.59152  validloss -260.28595±0.00000  bestvalidloss -983.57786  last_update 8\n",
      "train: iter 18  trainloss -1170.30846  validloss 1620.24425±0.00000  bestvalidloss -983.57786  last_update 9\n",
      "train: iter 19  trainloss -1262.33700  validloss 2111.04541±0.00000  bestvalidloss -983.57786  last_update 10\n",
      "train: iter 20  trainloss -1273.35754  validloss -1273.24451±0.00000  bestvalidloss -1273.24451  last_update 0\n",
      "train: iter 21  trainloss -1163.64544  validloss -1304.60408±0.00000  bestvalidloss -1304.60408  last_update 0\n",
      "train: iter 22  trainloss -1237.20462  validloss -1140.51680±0.00000  bestvalidloss -1304.60408  last_update 1\n",
      "train: iter 23  trainloss -1189.70113  validloss -1215.60527±0.00000  bestvalidloss -1304.60408  last_update 2\n",
      "train: iter 24  trainloss -1262.23112  validloss -1315.30099±0.00000  bestvalidloss -1315.30099  last_update 0\n",
      "train: iter 25  trainloss -1309.85824  validloss -799.77544±0.00000  bestvalidloss -1315.30099  last_update 1\n",
      "train: iter 26  trainloss -1330.08506  validloss -278.09474±0.00000  bestvalidloss -1315.30099  last_update 2\n",
      "train: iter 27  trainloss -1336.95327  validloss -1296.37183±0.00000  bestvalidloss -1315.30099  last_update 3\n",
      "train: iter 28  trainloss -1360.12891  validloss -1090.35473±0.00000  bestvalidloss -1315.30099  last_update 4\n",
      "train: iter 29  trainloss -1330.74735  validloss -989.48581±0.00000  bestvalidloss -1315.30099  last_update 5\n",
      "train: iter 30  trainloss -1394.96095  validloss -1347.84405±0.00000  bestvalidloss -1347.84405  last_update 0\n",
      "train: iter 31  trainloss -1346.94849  validloss -1124.54147±0.00000  bestvalidloss -1347.84405  last_update 1\n",
      "train: iter 32  trainloss -1193.88957  validloss -773.67907±0.00000  bestvalidloss -1347.84405  last_update 2\n",
      "train: iter 33  trainloss -1379.61190  validloss -854.02877±0.00000  bestvalidloss -1347.84405  last_update 3\n",
      "train: iter 34  trainloss -1433.59161  validloss -113.74721±0.00000  bestvalidloss -1347.84405  last_update 4\n",
      "train: iter 35  trainloss -1383.73564  validloss 104.02221±0.00000  bestvalidloss -1347.84405  last_update 5\n",
      "train: iter 36  trainloss -1407.06789  validloss -1407.67934±0.00000  bestvalidloss -1407.67934  last_update 0\n",
      "train: iter 37  trainloss -1406.39192  validloss -1475.45038±0.00000  bestvalidloss -1475.45038  last_update 0\n",
      "train: iter 38  trainloss -1439.64807  validloss -1459.98719±0.00000  bestvalidloss -1475.45038  last_update 1\n",
      "train: iter 39  trainloss -1430.34421  validloss -1461.99236±0.00000  bestvalidloss -1475.45038  last_update 2\n",
      "train: iter 40  trainloss -1415.39640  validloss -1489.19331±0.00000  bestvalidloss -1489.19331  last_update 0\n",
      "train: iter 41  trainloss -1419.48682  validloss -1408.99869±0.00000  bestvalidloss -1489.19331  last_update 1\n",
      "train: iter 42  trainloss -1444.83593  validloss -1437.65682±0.00000  bestvalidloss -1489.19331  last_update 2\n",
      "train: iter 43  trainloss -1438.05973  validloss -1512.55088±0.00000  bestvalidloss -1512.55088  last_update 0\n",
      "train: iter 44  trainloss -1463.08771  validloss -1496.49682±0.00000  bestvalidloss -1512.55088  last_update 1\n",
      "train: iter 45  trainloss -1477.20933  validloss -1465.30941±0.00000  bestvalidloss -1512.55088  last_update 2\n",
      "train: iter 46  trainloss -1492.36880  validloss -1542.78565±0.00000  bestvalidloss -1542.78565  last_update 0\n",
      "train: iter 47  trainloss -1394.74533  validloss -1460.39695±0.00000  bestvalidloss -1542.78565  last_update 1\n",
      "train: iter 48  trainloss -1478.41928  validloss -1513.85675±0.00000  bestvalidloss -1542.78565  last_update 2\n",
      "train: iter 49  trainloss -1498.81118  validloss -1540.93930±0.00000  bestvalidloss -1542.78565  last_update 3\n",
      "train: iter 50  trainloss -1498.50941  validloss -1519.33773±0.00000  bestvalidloss -1542.78565  last_update 4\n",
      "train: iter 51  trainloss -1448.33752  validloss -1491.12207±0.00000  bestvalidloss -1542.78565  last_update 5\n",
      "train: iter 52  trainloss -1501.55734  validloss -1464.75485±0.00000  bestvalidloss -1542.78565  last_update 6\n",
      "train: iter 53  trainloss -1532.11238  validloss -1525.35882±0.00000  bestvalidloss -1542.78565  last_update 7\n",
      "train: iter 54  trainloss -1506.85194  validloss -1539.36830±0.00000  bestvalidloss -1542.78565  last_update 8\n",
      "train: iter 55  trainloss -1538.21860  validloss -1567.85153±0.00000  bestvalidloss -1567.85153  last_update 0\n",
      "train: iter 56  trainloss -1530.55397  validloss -1572.03816±0.00000  bestvalidloss -1572.03816  last_update 0\n",
      "train: iter 57  trainloss -1500.44568  validloss -1553.82569±0.00000  bestvalidloss -1572.03816  last_update 1\n",
      "train: iter 58  trainloss -1474.30906  validloss -1550.07497±0.00000  bestvalidloss -1572.03816  last_update 2\n",
      "train: iter 59  trainloss -1546.97491  validloss -1422.60014±0.00000  bestvalidloss -1572.03816  last_update 3\n",
      "train: iter 60  trainloss -1462.79550  validloss -1613.81302±0.00000  bestvalidloss -1613.81302  last_update 0\n",
      "train: iter 61  trainloss -1378.68626  validloss -1507.00399±0.00000  bestvalidloss -1613.81302  last_update 1\n",
      "train: iter 62  trainloss -1552.96840  validloss -1433.19251±0.00000  bestvalidloss -1613.81302  last_update 2\n",
      "train: iter 63  trainloss -1570.87709  validloss -1568.04574±0.00000  bestvalidloss -1613.81302  last_update 3\n",
      "train: iter 64  trainloss -1542.52587  validloss -1583.05938±0.00000  bestvalidloss -1613.81302  last_update 4\n",
      "train: iter 65  trainloss -1467.84057  validloss -1558.85511±0.00000  bestvalidloss -1613.81302  last_update 5\n",
      "train: iter 66  trainloss -1577.59080  validloss -1592.01496±0.00000  bestvalidloss -1613.81302  last_update 6\n",
      "train: iter 67  trainloss -1605.20916  validloss -1565.90777±0.00000  bestvalidloss -1613.81302  last_update 7\n",
      "train: iter 68  trainloss -1595.57930  validloss -1484.69205±0.00000  bestvalidloss -1613.81302  last_update 8\n",
      "train: iter 69  trainloss -1555.00389  validloss -1583.89164±0.00000  bestvalidloss -1613.81302  last_update 9\n",
      "train: iter 70  trainloss -1593.97475  validloss -1603.93640±0.00000  bestvalidloss -1613.81302  last_update 10\n",
      "train: iter 71  trainloss -1623.10174  validloss -1643.88758±0.00000  bestvalidloss -1643.88758  last_update 0\n",
      "train: iter 72  trainloss -1612.55545  validloss -1540.00305±0.00000  bestvalidloss -1643.88758  last_update 1\n",
      "train: iter 73  trainloss -1607.28103  validloss -1561.40906±0.00000  bestvalidloss -1643.88758  last_update 2\n",
      "train: iter 74  trainloss -1620.12790  validloss -1607.12659±0.00000  bestvalidloss -1643.88758  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1570.29905  validloss -1588.29250±0.00000  bestvalidloss -1643.88758  last_update 4\n",
      "train: iter 76  trainloss -1572.98740  validloss -1498.09268±0.00000  bestvalidloss -1643.88758  last_update 5\n",
      "train: iter 77  trainloss -1595.25038  validloss -1486.95387±0.00000  bestvalidloss -1643.88758  last_update 6\n",
      "train: iter 78  trainloss -1666.73355  validloss -1628.14987±0.00000  bestvalidloss -1643.88758  last_update 7\n",
      "train: iter 79  trainloss -1656.97860  validloss -1695.37507±0.00000  bestvalidloss -1695.37507  last_update 0\n",
      "train: iter 80  trainloss -1560.12282  validloss -1622.78748±0.00000  bestvalidloss -1695.37507  last_update 1\n",
      "train: iter 81  trainloss -1591.79169  validloss -1608.58890±0.00000  bestvalidloss -1695.37507  last_update 2\n",
      "train: iter 82  trainloss -1541.84200  validloss -1357.27310±0.00000  bestvalidloss -1695.37507  last_update 3\n",
      "train: iter 83  trainloss -1714.32925  validloss -1693.29493±0.00000  bestvalidloss -1695.37507  last_update 4\n",
      "train: iter 84  trainloss -1719.79986  validloss -1670.38813±0.00000  bestvalidloss -1695.37507  last_update 5\n",
      "train: iter 85  trainloss -1713.25724  validloss -1591.17893±0.00000  bestvalidloss -1695.37507  last_update 6\n",
      "train: iter 86  trainloss -1721.23883  validloss -1580.89553±0.00000  bestvalidloss -1695.37507  last_update 7\n",
      "train: iter 87  trainloss -1637.49537  validloss -1656.08659±0.00000  bestvalidloss -1695.37507  last_update 8\n",
      "train: iter 88  trainloss -1717.48068  validloss -1644.14463±0.00000  bestvalidloss -1695.37507  last_update 9\n",
      "train: iter 89  trainloss -1731.88282  validloss -1689.42006±0.00000  bestvalidloss -1695.37507  last_update 10\n",
      "train: iter 90  trainloss -1703.29686  validloss -1703.16660±0.00000  bestvalidloss -1703.16660  last_update 0\n",
      "train: iter 91  trainloss -1694.80587  validloss -1137.23018±0.00000  bestvalidloss -1703.16660  last_update 1\n",
      "train: iter 92  trainloss -1758.73082  validloss -1704.68085±0.00000  bestvalidloss -1704.68085  last_update 0\n",
      "train: iter 93  trainloss -1750.69790  validloss -1731.91452±0.00000  bestvalidloss -1731.91452  last_update 0\n",
      "train: iter 94  trainloss -1725.39275  validloss -1694.77110±0.00000  bestvalidloss -1731.91452  last_update 1\n",
      "train: iter 95  trainloss -1714.45693  validloss -1759.43234±0.00000  bestvalidloss -1759.43234  last_update 0\n",
      "train: iter 96  trainloss -1762.61163  validloss -1592.53442±0.00000  bestvalidloss -1759.43234  last_update 1\n",
      "train: iter 97  trainloss -1800.35254  validloss -1799.38653±0.00000  bestvalidloss -1799.38653  last_update 0\n",
      "train: iter 98  trainloss -1790.77592  validloss -1799.44001±0.00000  bestvalidloss -1799.44001  last_update 0\n",
      "train: iter 99  trainloss -1716.94582  validloss -1769.96452±0.00000  bestvalidloss -1799.44001  last_update 1\n",
      "train: iter 100  trainloss -1665.70205  validloss -1685.16369±0.00000  bestvalidloss -1799.44001  last_update 2\n",
      "train: iter 101  trainloss -1818.72474  validloss -1800.88304±0.00000  bestvalidloss -1800.88304  last_update 0\n",
      "train: iter 102  trainloss -1804.07061  validloss -1811.89156±0.00000  bestvalidloss -1811.89156  last_update 0\n",
      "train: iter 103  trainloss -1798.02913  validloss -1779.19074±0.00000  bestvalidloss -1811.89156  last_update 1\n",
      "train: iter 104  trainloss -1815.54774  validloss -1788.51813±0.00000  bestvalidloss -1811.89156  last_update 2\n",
      "train: iter 105  trainloss -1831.64198  validloss -1782.60392±0.00000  bestvalidloss -1811.89156  last_update 3\n",
      "train: iter 106  trainloss -1721.31662  validloss -1856.77427±0.00000  bestvalidloss -1856.77427  last_update 0\n",
      "train: iter 107  trainloss -1794.64625  validloss -1660.83898±0.00000  bestvalidloss -1856.77427  last_update 1\n",
      "train: iter 108  trainloss -1848.37674  validloss -1834.37530±0.00000  bestvalidloss -1856.77427  last_update 2\n",
      "train: iter 109  trainloss -1840.96585  validloss -1869.33567±0.00000  bestvalidloss -1869.33567  last_update 0\n",
      "train: iter 110  trainloss -1761.26436  validloss -1791.66760±0.00000  bestvalidloss -1869.33567  last_update 1\n",
      "train: iter 111  trainloss -1631.16485  validloss -1662.75578±0.00000  bestvalidloss -1869.33567  last_update 2\n",
      "train: iter 112  trainloss -1830.68237  validloss -1781.82921±0.00000  bestvalidloss -1869.33567  last_update 3\n",
      "train: iter 113  trainloss -1818.13894  validloss -1813.02537±0.00000  bestvalidloss -1869.33567  last_update 4\n",
      "train: iter 114  trainloss -1819.38296  validloss -1733.91412±0.00000  bestvalidloss -1869.33567  last_update 5\n",
      "train: iter 115  trainloss -1851.32170  validloss -1850.77980±0.00000  bestvalidloss -1869.33567  last_update 6\n",
      "train: iter 116  trainloss -1844.96674  validloss -1864.39524±0.00000  bestvalidloss -1869.33567  last_update 7\n",
      "train: iter 117  trainloss -1838.82149  validloss -1851.99585±0.00000  bestvalidloss -1869.33567  last_update 8\n",
      "train: iter 118  trainloss -1829.41017  validloss -1854.21672±0.00000  bestvalidloss -1869.33567  last_update 9\n",
      "train: iter 119  trainloss -1868.18806  validloss -1826.93142±0.00000  bestvalidloss -1869.33567  last_update 10\n",
      "train: iter 120  trainloss -1782.56526  validloss -1797.05477±0.00000  bestvalidloss -1869.33567  last_update 11\n",
      "train: iter 121  trainloss -1836.70308  validloss -1839.96356±0.00000  bestvalidloss -1869.33567  last_update 12\n",
      "train: iter 122  trainloss -1868.56693  validloss -1878.74203±0.00000  bestvalidloss -1878.74203  last_update 0\n",
      "train: iter 123  trainloss -1860.43985  validloss -1875.56787±0.00000  bestvalidloss -1878.74203  last_update 1\n",
      "train: iter 124  trainloss -1811.52863  validloss -1838.10562±0.00000  bestvalidloss -1878.74203  last_update 2\n",
      "train: iter 125  trainloss -1872.23118  validloss -1864.65026±0.00000  bestvalidloss -1878.74203  last_update 3\n",
      "train: iter 126  trainloss -1866.97828  validloss -1893.63196±0.00000  bestvalidloss -1893.63196  last_update 0\n",
      "train: iter 127  trainloss -1867.29660  validloss -1797.16194±0.00000  bestvalidloss -1893.63196  last_update 1\n",
      "train: iter 128  trainloss -1785.00599  validloss -1743.34559±0.00000  bestvalidloss -1893.63196  last_update 2\n",
      "train: iter 129  trainloss -1782.56572  validloss -1768.46099±0.00000  bestvalidloss -1893.63196  last_update 3\n",
      "train: iter 130  trainloss -1877.74281  validloss -1843.67629±0.00000  bestvalidloss -1893.63196  last_update 4\n",
      "train: iter 131  trainloss -1879.44107  validloss -1901.66382±0.00000  bestvalidloss -1901.66382  last_update 0\n",
      "train: iter 132  trainloss -1894.07378  validloss -1859.95148±0.00000  bestvalidloss -1901.66382  last_update 1\n",
      "train: iter 133  trainloss -1831.79535  validloss -1864.77239±0.00000  bestvalidloss -1901.66382  last_update 2\n",
      "train: iter 134  trainloss -1889.70809  validloss -1813.88037±0.00000  bestvalidloss -1901.66382  last_update 3\n",
      "train: iter 135  trainloss -1895.59655  validloss -1890.36289±0.00000  bestvalidloss -1901.66382  last_update 4\n",
      "train: iter 136  trainloss -1861.81024  validloss -1870.04950±0.00000  bestvalidloss -1901.66382  last_update 5\n",
      "train: iter 137  trainloss -1748.86493  validloss -1769.83328±0.00000  bestvalidloss -1901.66382  last_update 6\n",
      "train: iter 138  trainloss -1805.51432  validloss -1822.18924±0.00000  bestvalidloss -1901.66382  last_update 7\n",
      "train: iter 139  trainloss -1897.48526  validloss -1854.49823±0.00000  bestvalidloss -1901.66382  last_update 8\n",
      "train: iter 140  trainloss -1873.47079  validloss -1876.83963±0.00000  bestvalidloss -1901.66382  last_update 9\n",
      "train: iter 141  trainloss -1833.81436  validloss -1868.87768±0.00000  bestvalidloss -1901.66382  last_update 10\n",
      "train: iter 142  trainloss -1872.49868  validloss -1863.18625±0.00000  bestvalidloss -1901.66382  last_update 11\n",
      "train: iter 143  trainloss -1882.17568  validloss -1793.84575±0.00000  bestvalidloss -1901.66382  last_update 12\n",
      "train: iter 144  trainloss -1877.43017  validloss -1913.68180±0.00000  bestvalidloss -1913.68180  last_update 0\n",
      "train: iter 145  trainloss -1867.06867  validloss -1771.26678±0.00000  bestvalidloss -1913.68180  last_update 1\n",
      "train: iter 146  trainloss -1887.19010  validloss -1814.85787±0.00000  bestvalidloss -1913.68180  last_update 2\n",
      "train: iter 147  trainloss -1905.75820  validloss -1885.98720±0.00000  bestvalidloss -1913.68180  last_update 3\n",
      "train: iter 148  trainloss -1883.45537  validloss -1895.25838±0.00000  bestvalidloss -1913.68180  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -1874.60366  validloss -1877.21951±0.00000  bestvalidloss -1913.68180  last_update 5\n",
      "train: iter 150  trainloss -1646.08826  validloss -1696.02517±0.00000  bestvalidloss -1913.68180  last_update 6\n",
      "train: iter 151  trainloss -1880.83571  validloss -1799.21061±0.00000  bestvalidloss -1913.68180  last_update 7\n",
      "train: iter 152  trainloss -1901.90379  validloss -1849.33004±0.00000  bestvalidloss -1913.68180  last_update 8\n",
      "train: iter 153  trainloss -1895.31542  validloss -1866.57547±0.00000  bestvalidloss -1913.68180  last_update 9\n",
      "train: iter 154  trainloss -1880.54166  validloss -1760.14192±0.00000  bestvalidloss -1913.68180  last_update 10\n",
      "train: iter 155  trainloss -1909.18823  validloss -1902.66487±0.00000  bestvalidloss -1913.68180  last_update 11\n",
      "train: iter 156  trainloss -1910.18237  validloss -1858.19767±0.00000  bestvalidloss -1913.68180  last_update 12\n",
      "train: iter 157  trainloss -1903.14185  validloss -1864.02241±0.00000  bestvalidloss -1913.68180  last_update 13\n",
      "train: iter 158  trainloss -1861.73861  validloss -1713.85513±0.00000  bestvalidloss -1913.68180  last_update 14\n",
      "train: iter 159  trainloss -1906.32769  validloss -1853.69194±0.00000  bestvalidloss -1913.68180  last_update 15\n",
      "train: iter 160  trainloss -1907.84442  validloss -1906.37488±0.00000  bestvalidloss -1913.68180  last_update 16\n",
      "train: iter 161  trainloss -1880.57528  validloss -1875.04551±0.00000  bestvalidloss -1913.68180  last_update 17\n",
      "train: iter 162  trainloss -1748.29652  validloss -1560.77220±0.00000  bestvalidloss -1913.68180  last_update 18\n",
      "train: iter 163  trainloss -1883.26989  validloss -1685.03046±0.00000  bestvalidloss -1913.68180  last_update 19\n",
      "train: iter 164  trainloss -1921.27244  validloss -1900.41578±0.00000  bestvalidloss -1913.68180  last_update 20\n",
      "train: iter 165  trainloss -1867.71901  validloss -1915.27172±0.00000  bestvalidloss -1915.27172  last_update 0\n",
      "train: iter 166  trainloss -1859.05474  validloss -1673.75062±0.00000  bestvalidloss -1915.27172  last_update 1\n",
      "train: iter 167  trainloss -1917.72906  validloss -1832.89159±0.00000  bestvalidloss -1915.27172  last_update 2\n",
      "train: iter 168  trainloss -1918.99848  validloss -1881.22925±0.00000  bestvalidloss -1915.27172  last_update 3\n",
      "train: iter 169  trainloss -1860.61195  validloss -1906.78387±0.00000  bestvalidloss -1915.27172  last_update 4\n",
      "train: iter 170  trainloss -1911.96116  validloss -1915.92217±0.00000  bestvalidloss -1915.92217  last_update 0\n",
      "train: iter 171  trainloss -1916.21807  validloss -1917.80297±0.00000  bestvalidloss -1917.80297  last_update 0\n",
      "train: iter 172  trainloss -1927.37728  validloss -1874.58559±0.00000  bestvalidloss -1917.80297  last_update 1\n",
      "train: iter 173  trainloss -1688.00999  validloss -1797.62146±0.00000  bestvalidloss -1917.80297  last_update 2\n",
      "train: iter 174  trainloss -1797.05664  validloss -1565.14557±0.00000  bestvalidloss -1917.80297  last_update 3\n",
      "train: iter 175  trainloss -1905.49843  validloss -1713.41174±0.00000  bestvalidloss -1917.80297  last_update 4\n",
      "train: iter 176  trainloss -1918.96031  validloss -1897.61130±0.00000  bestvalidloss -1917.80297  last_update 5\n",
      "train: iter 177  trainloss -1866.09261  validloss -1821.06744±0.00000  bestvalidloss -1917.80297  last_update 6\n",
      "train: iter 178  trainloss -1890.61653  validloss -1877.63043±0.00000  bestvalidloss -1917.80297  last_update 7\n",
      "train: iter 179  trainloss -1915.75828  validloss -1891.57979±0.00000  bestvalidloss -1917.80297  last_update 8\n",
      "train: iter 180  trainloss -1882.45412  validloss -1835.70358±0.00000  bestvalidloss -1917.80297  last_update 9\n",
      "train: iter 181  trainloss -1910.74116  validloss -1899.48518±0.00000  bestvalidloss -1917.80297  last_update 10\n",
      "train: iter 182  trainloss -1886.76713  validloss -1870.82925±0.00000  bestvalidloss -1917.80297  last_update 11\n",
      "train: iter 183  trainloss -1860.10552  validloss -1775.75754±0.00000  bestvalidloss -1917.80297  last_update 12\n",
      "train: iter 184  trainloss -1863.79361  validloss -1702.21884±0.00000  bestvalidloss -1917.80297  last_update 13\n",
      "train: iter 185  trainloss -1924.01529  validloss -1805.92246±0.00000  bestvalidloss -1917.80297  last_update 14\n",
      "train: iter 186  trainloss -1918.93033  validloss -1944.24754±0.00000  bestvalidloss -1944.24754  last_update 0\n",
      "train: iter 187  trainloss -1927.68598  validloss -1886.99706±0.00000  bestvalidloss -1944.24754  last_update 1\n",
      "train: iter 188  trainloss -1891.24768  validloss -1925.04786±0.00000  bestvalidloss -1944.24754  last_update 2\n",
      "train: iter 189  trainloss -1902.80947  validloss -1906.06874±0.00000  bestvalidloss -1944.24754  last_update 3\n",
      "train: iter 190  trainloss -1890.29565  validloss -1899.93571±0.00000  bestvalidloss -1944.24754  last_update 4\n",
      "train: iter 191  trainloss -1802.77953  validloss -1886.18553±0.00000  bestvalidloss -1944.24754  last_update 5\n",
      "train: iter 192  trainloss -1908.84750  validloss -1810.02966±0.00000  bestvalidloss -1944.24754  last_update 6\n",
      "train: iter 193  trainloss -1938.69861  validloss -1897.77210±0.00000  bestvalidloss -1944.24754  last_update 7\n",
      "train: iter 194  trainloss -1944.65926  validloss -1926.35520±0.00000  bestvalidloss -1944.24754  last_update 8\n",
      "train: iter 195  trainloss -1940.65962  validloss -1960.63770±0.00000  bestvalidloss -1960.63770  last_update 0\n",
      "train: iter 196  trainloss -1942.64330  validloss -1922.44889±0.00000  bestvalidloss -1960.63770  last_update 1\n",
      "train: iter 197  trainloss -1871.65709  validloss -1877.43198±0.00000  bestvalidloss -1960.63770  last_update 2\n",
      "train: iter 198  trainloss -1906.11390  validloss -1831.46328±0.00000  bestvalidloss -1960.63770  last_update 3\n",
      "train: iter 199  trainloss -1896.03575  validloss -1899.12682±0.00000  bestvalidloss -1960.63770  last_update 4\n",
      "train: iter 200  trainloss -1917.78790  validloss -1867.20905±0.00000  bestvalidloss -1960.63770  last_update 5\n",
      "train: iter 201  trainloss -1950.57365  validloss -1916.75234±0.00000  bestvalidloss -1960.63770  last_update 6\n",
      "train: iter 202  trainloss -1936.40314  validloss -1933.75280±0.00000  bestvalidloss -1960.63770  last_update 7\n",
      "train: iter 203  trainloss -1942.55951  validloss -1934.91065±0.00000  bestvalidloss -1960.63770  last_update 8\n",
      "train: iter 204  trainloss -1890.77211  validloss -1922.46337±0.00000  bestvalidloss -1960.63770  last_update 9\n",
      "train: iter 205  trainloss -1812.18052  validloss -1847.11607±0.00000  bestvalidloss -1960.63770  last_update 10\n",
      "train: iter 206  trainloss -1934.86563  validloss -1916.75001±0.00000  bestvalidloss -1960.63770  last_update 11\n",
      "train: iter 207  trainloss -1945.94181  validloss -1932.39420±0.00000  bestvalidloss -1960.63770  last_update 12\n",
      "train: iter 208  trainloss -1850.31003  validloss -1909.69134±0.00000  bestvalidloss -1960.63770  last_update 13\n",
      "train: iter 209  trainloss -1915.07151  validloss -1709.69664±0.00000  bestvalidloss -1960.63770  last_update 14\n",
      "train: iter 210  trainloss -1955.27290  validloss -1928.49808±0.00000  bestvalidloss -1960.63770  last_update 15\n",
      "train: iter 211  trainloss -1951.03270  validloss -1937.74147±0.00000  bestvalidloss -1960.63770  last_update 16\n",
      "train: iter 212  trainloss -1952.04018  validloss -1960.97092±0.00000  bestvalidloss -1960.97092  last_update 0\n",
      "train: iter 213  trainloss -1809.65228  validloss -1902.70831±0.00000  bestvalidloss -1960.97092  last_update 1\n",
      "train: iter 214  trainloss -1904.50568  validloss -1883.38844±0.00000  bestvalidloss -1960.97092  last_update 2\n",
      "train: iter 215  trainloss -1934.61132  validloss -1909.18049±0.00000  bestvalidloss -1960.97092  last_update 3\n",
      "train: iter 216  trainloss -1950.32515  validloss -1916.54915±0.00000  bestvalidloss -1960.97092  last_update 4\n",
      "train: iter 217  trainloss -1956.45313  validloss -1907.06253±0.00000  bestvalidloss -1960.97092  last_update 5\n",
      "train: iter 218  trainloss -1915.97222  validloss -1968.11472±0.00000  bestvalidloss -1968.11472  last_update 0\n",
      "train: iter 219  trainloss -1917.70493  validloss -1865.37779±0.00000  bestvalidloss -1968.11472  last_update 1\n",
      "train: iter 220  trainloss -1935.58623  validloss -1923.09508±0.00000  bestvalidloss -1968.11472  last_update 2\n",
      "train: iter 221  trainloss -1872.25278  validloss -1881.25404±0.00000  bestvalidloss -1968.11472  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 222  trainloss -1901.88302  validloss -1886.35216±0.00000  bestvalidloss -1968.11472  last_update 4\n",
      "train: iter 223  trainloss -1938.32099  validloss -1917.28100±0.00000  bestvalidloss -1968.11472  last_update 5\n",
      "train: iter 224  trainloss -1950.13902  validloss -1921.65060±0.00000  bestvalidloss -1968.11472  last_update 6\n",
      "train: iter 225  trainloss -1944.46089  validloss -1952.30479±0.00000  bestvalidloss -1968.11472  last_update 7\n",
      "train: iter 226  trainloss -1939.15576  validloss -1861.95072±0.00000  bestvalidloss -1968.11472  last_update 8\n",
      "train: iter 227  trainloss -1863.53372  validloss -1828.69249±0.00000  bestvalidloss -1968.11472  last_update 9\n",
      "train: iter 228  trainloss -1943.81457  validloss -1887.59629±0.00000  bestvalidloss -1968.11472  last_update 10\n",
      "train: iter 229  trainloss -1950.49563  validloss -1953.97581±0.00000  bestvalidloss -1968.11472  last_update 11\n",
      "train: iter 230  trainloss -1960.30510  validloss -1961.74941±0.00000  bestvalidloss -1968.11472  last_update 12\n",
      "train: iter 231  trainloss -1866.33811  validloss -1875.74277±0.00000  bestvalidloss -1968.11472  last_update 13\n",
      "train: iter 232  trainloss -1898.80837  validloss -1692.46932±0.00000  bestvalidloss -1968.11472  last_update 14\n",
      "train: iter 233  trainloss -1955.23999  validloss -1897.15502±0.00000  bestvalidloss -1968.11472  last_update 15\n",
      "train: iter 234  trainloss -1917.14236  validloss -1921.66962±0.00000  bestvalidloss -1968.11472  last_update 16\n",
      "train: iter 235  trainloss -1958.77723  validloss -1904.97440±0.00000  bestvalidloss -1968.11472  last_update 17\n",
      "train: iter 236  trainloss -1965.57812  validloss -1944.23704±0.00000  bestvalidloss -1968.11472  last_update 18\n",
      "train: iter 237  trainloss -1926.19836  validloss -1934.01885±0.00000  bestvalidloss -1968.11472  last_update 19\n",
      "train: iter 238  trainloss -1922.67807  validloss -1949.70802±0.00000  bestvalidloss -1968.11472  last_update 20\n",
      "train: iter 239  trainloss -1950.82502  validloss -1966.01556±0.00000  bestvalidloss -1968.11472  last_update 21\n",
      "train: iter 240  trainloss -1971.85555  validloss -1950.57898±0.00000  bestvalidloss -1968.11472  last_update 22\n",
      "train: iter 241  trainloss -1974.45886  validloss -1966.62428±0.00000  bestvalidloss -1968.11472  last_update 23\n",
      "train: iter 242  trainloss -1964.53573  validloss -1959.07995±0.00000  bestvalidloss -1968.11472  last_update 24\n",
      "train: iter 243  trainloss -1720.85964  validloss -1875.30712±0.00000  bestvalidloss -1968.11472  last_update 25\n",
      "train: iter 244  trainloss -1930.43293  validloss -1890.44368±0.00000  bestvalidloss -1968.11472  last_update 26\n",
      "train: iter 245  trainloss -1910.75982  validloss -1925.47129±0.00000  bestvalidloss -1968.11472  last_update 27\n",
      "train: iter 246  trainloss -1959.63020  validloss -1921.36077±0.00000  bestvalidloss -1968.11472  last_update 28\n",
      "train: iter 247  trainloss -1954.37342  validloss -1950.36523±0.00000  bestvalidloss -1968.11472  last_update 29\n",
      "train: iter 248  trainloss -1970.84580  validloss -1956.64372±0.00000  bestvalidloss -1968.11472  last_update 30\n",
      "train: iter 249  trainloss -1953.18829  validloss -1954.16148±0.00000  bestvalidloss -1968.11472  last_update 31\n",
      "train: iter 250  trainloss -1909.93613  validloss -1949.77461±0.00000  bestvalidloss -1968.11472  last_update 32\n",
      "train: iter 251  trainloss -1867.41053  validloss -1854.45388±0.00000  bestvalidloss -1968.11472  last_update 33\n",
      "train: iter 252  trainloss -1950.21676  validloss -1916.64680±0.00000  bestvalidloss -1968.11472  last_update 34\n",
      "train: iter 253  trainloss -1962.42809  validloss -1923.18000±0.00000  bestvalidloss -1968.11472  last_update 35\n",
      "train: iter 254  trainloss -1963.99370  validloss -1950.80287±0.00000  bestvalidloss -1968.11472  last_update 36\n",
      "train: iter 255  trainloss -1960.22461  validloss -1953.17680±0.00000  bestvalidloss -1968.11472  last_update 37\n",
      "train: iter 256  trainloss -1965.62259  validloss -1955.77942±0.00000  bestvalidloss -1968.11472  last_update 38\n",
      "train: iter 257  trainloss -1970.73417  validloss -1939.11226±0.00000  bestvalidloss -1968.11472  last_update 39\n",
      "train: iter 258  trainloss -1952.46347  validloss -1895.29780±0.00000  bestvalidloss -1968.11472  last_update 40\n",
      "train: iter 259  trainloss -1874.65819  validloss -1923.08439±0.00000  bestvalidloss -1968.11472  last_update 41\n",
      "train: iter 260  trainloss -1958.12982  validloss -1848.36218±0.00000  bestvalidloss -1968.11472  last_update 42\n",
      "train: iter 261  trainloss -1960.28369  validloss -1977.85455±0.00000  bestvalidloss -1977.85455  last_update 0\n",
      "train: iter 262  trainloss -1938.20429  validloss -1916.70099±0.00000  bestvalidloss -1977.85455  last_update 1\n",
      "train: iter 263  trainloss -1975.74783  validloss -1967.68663±0.00000  bestvalidloss -1977.85455  last_update 2\n",
      "train: iter 264  trainloss -1980.29364  validloss -1965.00344±0.00000  bestvalidloss -1977.85455  last_update 3\n",
      "train: iter 265  trainloss -1946.80934  validloss -1985.74491±0.00000  bestvalidloss -1985.74491  last_update 0\n",
      "train: iter 266  trainloss -1858.77087  validloss -1881.03268±0.00000  bestvalidloss -1985.74491  last_update 1\n",
      "train: iter 267  trainloss -1951.80951  validloss -1891.62295±0.00000  bestvalidloss -1985.74491  last_update 2\n",
      "train: iter 268  trainloss -1969.23811  validloss -1864.05453±0.00000  bestvalidloss -1985.74491  last_update 3\n",
      "train: iter 269  trainloss -1969.75904  validloss -1962.96720±0.00000  bestvalidloss -1985.74491  last_update 4\n",
      "train: iter 270  trainloss -1860.94981  validloss -1899.84338±0.00000  bestvalidloss -1985.74491  last_update 5\n",
      "train: iter 271  trainloss -1961.95981  validloss -1910.15502±0.00000  bestvalidloss -1985.74491  last_update 6\n",
      "train: iter 272  trainloss -1962.57488  validloss -1945.11522±0.00000  bestvalidloss -1985.74491  last_update 7\n",
      "train: iter 273  trainloss -1936.60360  validloss -1946.34008±0.00000  bestvalidloss -1985.74491  last_update 8\n",
      "train: iter 274  trainloss -1957.47731  validloss -1932.63013±0.00000  bestvalidloss -1985.74491  last_update 9\n",
      "train: iter 275  trainloss -1918.01660  validloss -1946.28676±0.00000  bestvalidloss -1985.74491  last_update 10\n",
      "train: iter 276  trainloss -1960.29021  validloss -1972.01164±0.00000  bestvalidloss -1985.74491  last_update 11\n",
      "train: iter 277  trainloss -1969.30491  validloss -1895.90722±0.00000  bestvalidloss -1985.74491  last_update 12\n",
      "train: iter 278  trainloss -1975.46992  validloss -1990.32164±0.00000  bestvalidloss -1990.32164  last_update 0\n",
      "train: iter 279  trainloss -1963.46947  validloss -1867.14309±0.00000  bestvalidloss -1990.32164  last_update 1\n",
      "train: iter 280  trainloss -1950.41737  validloss -1909.45009±0.00000  bestvalidloss -1990.32164  last_update 2\n",
      "train: iter 281  trainloss -1972.37896  validloss -1914.45867±0.00000  bestvalidloss -1990.32164  last_update 3\n",
      "train: iter 282  trainloss -1963.98007  validloss -1968.48251±0.00000  bestvalidloss -1990.32164  last_update 4\n",
      "train: iter 283  trainloss -1946.42976  validloss -1956.08651±0.00000  bestvalidloss -1990.32164  last_update 5\n",
      "train: iter 284  trainloss -1930.77969  validloss -1893.67978±0.00000  bestvalidloss -1990.32164  last_update 6\n",
      "train: iter 285  trainloss -1981.73158  validloss -1959.37310±0.00000  bestvalidloss -1990.32164  last_update 7\n",
      "train: iter 286  trainloss -1978.97104  validloss -1908.04920±0.00000  bestvalidloss -1990.32164  last_update 8\n",
      "train: iter 287  trainloss -1963.56732  validloss -1969.95125±0.00000  bestvalidloss -1990.32164  last_update 9\n",
      "train: iter 288  trainloss -1938.90675  validloss -1959.77398±0.00000  bestvalidloss -1990.32164  last_update 10\n",
      "train: iter 289  trainloss -1988.20465  validloss -1943.82103±0.00000  bestvalidloss -1990.32164  last_update 11\n",
      "train: iter 290  trainloss -1962.55872  validloss -1981.11529±0.00000  bestvalidloss -1990.32164  last_update 12\n",
      "train: iter 291  trainloss -1983.95333  validloss -1946.87356±0.00000  bestvalidloss -1990.32164  last_update 13\n",
      "train: iter 292  trainloss -1957.36615  validloss -1985.93934±0.00000  bestvalidloss -1990.32164  last_update 14\n",
      "train: iter 293  trainloss -1945.98244  validloss -1976.81107±0.00000  bestvalidloss -1990.32164  last_update 15\n",
      "train: iter 294  trainloss -1903.40341  validloss -1936.74062±0.00000  bestvalidloss -1990.32164  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 295  trainloss -1895.45388  validloss -1941.05961±0.00000  bestvalidloss -1990.32164  last_update 17\n",
      "train: iter 296  trainloss -1865.10325  validloss -1589.05537±0.00000  bestvalidloss -1990.32164  last_update 18\n",
      "train: iter 297  trainloss -1980.70187  validloss -1923.47702±0.00000  bestvalidloss -1990.32164  last_update 19\n",
      "train: iter 298  trainloss -1982.50336  validloss -1948.76805±0.00000  bestvalidloss -1990.32164  last_update 20\n",
      "train: iter 299  trainloss -2000.99903  validloss -1964.55305±0.00000  bestvalidloss -1990.32164  last_update 21\n",
      "train: iter 300  trainloss -1984.72677  validloss -1974.20242±0.00000  bestvalidloss -1990.32164  last_update 22\n",
      "train: iter 301  trainloss -1891.40801  validloss -1965.65036±0.00000  bestvalidloss -1990.32164  last_update 23\n",
      "train: iter 302  trainloss -1991.63286  validloss -1939.32804±0.00000  bestvalidloss -1990.32164  last_update 24\n",
      "train: iter 303  trainloss -1973.63171  validloss -1915.02602±0.00000  bestvalidloss -1990.32164  last_update 25\n",
      "train: iter 304  trainloss -1956.23791  validloss -1980.57415±0.00000  bestvalidloss -1990.32164  last_update 26\n",
      "train: iter 305  trainloss -1882.94555  validloss -1931.82473±0.00000  bestvalidloss -1990.32164  last_update 27\n",
      "train: iter 306  trainloss -1985.70582  validloss -1943.64431±0.00000  bestvalidloss -1990.32164  last_update 28\n",
      "train: iter 307  trainloss -1995.06568  validloss -1974.82927±0.00000  bestvalidloss -1990.32164  last_update 29\n",
      "train: iter 308  trainloss -1957.83674  validloss -1943.42578±0.00000  bestvalidloss -1990.32164  last_update 30\n",
      "train: iter 309  trainloss -1994.81136  validloss -1944.60804±0.00000  bestvalidloss -1990.32164  last_update 31\n",
      "train: iter 310  trainloss -1990.08626  validloss -1980.61475±0.00000  bestvalidloss -1990.32164  last_update 32\n",
      "train: iter 311  trainloss -1982.41523  validloss -1953.73894±0.00000  bestvalidloss -1990.32164  last_update 33\n",
      "train: iter 312  trainloss -1957.26245  validloss -1931.87609±0.00000  bestvalidloss -1990.32164  last_update 34\n",
      "train: iter 313  trainloss -1963.98736  validloss -1984.21614±0.00000  bestvalidloss -1990.32164  last_update 35\n",
      "train: iter 314  trainloss -1980.49396  validloss -1951.49842±0.00000  bestvalidloss -1990.32164  last_update 36\n",
      "train: iter 315  trainloss -1869.55849  validloss -1951.08288±0.00000  bestvalidloss -1990.32164  last_update 37\n",
      "train: iter 316  trainloss -1965.11438  validloss -1823.85000±0.00000  bestvalidloss -1990.32164  last_update 38\n",
      "train: iter 317  trainloss -1968.36074  validloss -1960.33355±0.00000  bestvalidloss -1990.32164  last_update 39\n",
      "train: iter 318  trainloss -1999.45653  validloss -1952.26753±0.00000  bestvalidloss -1990.32164  last_update 40\n",
      "train: iter 319  trainloss -1975.15043  validloss -1986.37574±0.00000  bestvalidloss -1990.32164  last_update 41\n",
      "train: iter 320  trainloss -1962.91861  validloss -1944.52240±0.00000  bestvalidloss -1990.32164  last_update 42\n",
      "train: iter 321  trainloss -1855.27389  validloss -1798.33081±0.00000  bestvalidloss -1990.32164  last_update 43\n",
      "train: iter 322  trainloss -1977.73337  validloss -1947.94527±0.00000  bestvalidloss -1990.32164  last_update 44\n",
      "train: iter 323  trainloss -1947.74544  validloss -1971.03070±0.00000  bestvalidloss -1990.32164  last_update 45\n",
      "train: iter 324  trainloss -1904.19488  validloss -1866.95083±0.00000  bestvalidloss -1990.32164  last_update 46\n",
      "train: iter 325  trainloss -1980.36231  validloss -1927.68817±0.00000  bestvalidloss -1990.32164  last_update 47\n",
      "train: iter 326  trainloss -1974.07736  validloss -1938.44867±0.00000  bestvalidloss -1990.32164  last_update 48\n",
      "train: iter 327  trainloss -1998.47113  validloss -1994.85054±0.00000  bestvalidloss -1994.85054  last_update 0\n",
      "train: iter 328  trainloss -1952.08136  validloss -1973.75939±0.00000  bestvalidloss -1994.85054  last_update 1\n",
      "train: iter 329  trainloss -1998.35703  validloss -1958.78090±0.00000  bestvalidloss -1994.85054  last_update 2\n",
      "train: iter 330  trainloss -1967.25585  validloss -1929.52331±0.00000  bestvalidloss -1994.85054  last_update 3\n",
      "train: iter 331  trainloss -1893.53422  validloss -1955.24101±0.00000  bestvalidloss -1994.85054  last_update 4\n",
      "train: iter 332  trainloss -1974.25231  validloss -1912.94369±0.00000  bestvalidloss -1994.85054  last_update 5\n",
      "train: iter 333  trainloss -1986.14046  validloss -1943.57400±0.00000  bestvalidloss -1994.85054  last_update 6\n",
      "train: iter 334  trainloss -1970.31074  validloss -1919.63907±0.00000  bestvalidloss -1994.85054  last_update 7\n",
      "train: iter 335  trainloss -1992.78653  validloss -1948.96539±0.00000  bestvalidloss -1994.85054  last_update 8\n",
      "train: iter 336  trainloss -1950.74488  validloss -1946.50785±0.00000  bestvalidloss -1994.85054  last_update 9\n",
      "train: iter 337  trainloss -1996.33278  validloss -1968.37781±0.00000  bestvalidloss -1994.85054  last_update 10\n",
      "train: iter 338  trainloss -2000.58792  validloss -1997.27487±0.00000  bestvalidloss -1997.27487  last_update 0\n",
      "train: iter 339  trainloss -1997.13195  validloss -1978.95285±0.00000  bestvalidloss -1997.27487  last_update 1\n",
      "train: iter 340  trainloss -1907.43762  validloss -1962.26046±0.00000  bestvalidloss -1997.27487  last_update 2\n",
      "train: iter 341  trainloss -1953.15616  validloss -1790.37596±0.00000  bestvalidloss -1997.27487  last_update 3\n",
      "train: iter 342  trainloss -1990.58949  validloss -1995.34387±0.00000  bestvalidloss -1997.27487  last_update 4\n",
      "train: iter 343  trainloss -2011.59575  validloss -1979.51826±0.00000  bestvalidloss -1997.27487  last_update 5\n",
      "train: iter 344  trainloss -1990.89023  validloss -2009.35154±0.00000  bestvalidloss -2009.35154  last_update 0\n",
      "train: iter 345  trainloss -1894.70036  validloss -1934.92224±0.00000  bestvalidloss -2009.35154  last_update 1\n",
      "train: iter 346  trainloss -1956.14569  validloss -1958.99357±0.00000  bestvalidloss -2009.35154  last_update 2\n",
      "train: iter 347  trainloss -2008.92668  validloss -1985.69060±0.00000  bestvalidloss -2009.35154  last_update 3\n",
      "train: iter 348  trainloss -1987.97739  validloss -2000.74074±0.00000  bestvalidloss -2009.35154  last_update 4\n",
      "train: iter 349  trainloss -1936.89517  validloss -1864.98157±0.00000  bestvalidloss -2009.35154  last_update 5\n",
      "train: iter 350  trainloss -1992.98491  validloss -1969.07391±0.00000  bestvalidloss -2009.35154  last_update 6\n",
      "train: iter 351  trainloss -2000.20350  validloss -1982.25460±0.00000  bestvalidloss -2009.35154  last_update 7\n",
      "train: iter 352  trainloss -1997.68812  validloss -1976.84055±0.00000  bestvalidloss -2009.35154  last_update 8\n",
      "train: iter 353  trainloss -1892.37007  validloss -1823.21856±0.00000  bestvalidloss -2009.35154  last_update 9\n",
      "train: iter 354  trainloss -1976.73768  validloss -1934.68123±0.00000  bestvalidloss -2009.35154  last_update 10\n",
      "train: iter 355  trainloss -1992.65553  validloss -1961.04863±0.00000  bestvalidloss -2009.35154  last_update 11\n",
      "train: iter 356  trainloss -1999.21532  validloss -1998.33046±0.00000  bestvalidloss -2009.35154  last_update 12\n",
      "train: iter 357  trainloss -1999.05968  validloss -2002.02919±0.00000  bestvalidloss -2009.35154  last_update 13\n",
      "train: iter 358  trainloss -1993.45268  validloss -1956.65598±0.00000  bestvalidloss -2009.35154  last_update 14\n",
      "train: iter 359  trainloss -1962.07194  validloss -1981.73990±0.00000  bestvalidloss -2009.35154  last_update 15\n",
      "train: iter 360  trainloss -1977.95591  validloss -1962.44917±0.00000  bestvalidloss -2009.35154  last_update 16\n",
      "train: iter 361  trainloss -1991.87292  validloss -1961.41443±0.00000  bestvalidloss -2009.35154  last_update 17\n",
      "train: iter 362  trainloss -1936.27223  validloss -1982.10201±0.00000  bestvalidloss -2009.35154  last_update 18\n",
      "train: iter 363  trainloss -1944.32882  validloss -1969.29615±0.00000  bestvalidloss -2009.35154  last_update 19\n",
      "train: iter 364  trainloss -1904.11546  validloss -1885.23560±0.00000  bestvalidloss -2009.35154  last_update 20\n",
      "train: iter 365  trainloss -2002.28082  validloss -1972.16455±0.00000  bestvalidloss -2009.35154  last_update 21\n",
      "train: iter 366  trainloss -1983.27202  validloss -1950.72436±0.00000  bestvalidloss -2009.35154  last_update 22\n",
      "train: iter 367  trainloss -1992.36609  validloss -1882.31900±0.00000  bestvalidloss -2009.35154  last_update 23\n",
      "train: iter 368  trainloss -1999.82963  validloss -1979.47963±0.00000  bestvalidloss -2009.35154  last_update 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -1984.94149  validloss -1988.11587±0.00000  bestvalidloss -2009.35154  last_update 25\n",
      "train: iter 370  trainloss -1975.55690  validloss -1945.06042±0.00000  bestvalidloss -2009.35154  last_update 26\n",
      "train: iter 371  trainloss -1885.83261  validloss -1879.93480±0.00000  bestvalidloss -2009.35154  last_update 27\n",
      "train: iter 372  trainloss -1943.16150  validloss -1922.65999±0.00000  bestvalidloss -2009.35154  last_update 28\n",
      "train: iter 373  trainloss -1958.70732  validloss -1941.38593±0.00000  bestvalidloss -2009.35154  last_update 29\n",
      "train: iter 374  trainloss -1988.84681  validloss -1937.93634±0.00000  bestvalidloss -2009.35154  last_update 30\n",
      "train: iter 375  trainloss -2019.62839  validloss -2014.03885±0.00000  bestvalidloss -2014.03885  last_update 0\n",
      "train: iter 376  trainloss -1898.27861  validloss -2005.79256±0.00000  bestvalidloss -2014.03885  last_update 1\n",
      "train: iter 377  trainloss -1995.74217  validloss -1931.55918±0.00000  bestvalidloss -2014.03885  last_update 2\n",
      "train: iter 378  trainloss -1995.31886  validloss -1992.71575±0.00000  bestvalidloss -2014.03885  last_update 3\n",
      "train: iter 379  trainloss -2001.48694  validloss -1960.04062±0.00000  bestvalidloss -2014.03885  last_update 4\n",
      "train: iter 380  trainloss -1924.99761  validloss -1827.44185±0.00000  bestvalidloss -2014.03885  last_update 5\n",
      "train: iter 381  trainloss -1996.72472  validloss -1966.95195±0.00000  bestvalidloss -2014.03885  last_update 6\n",
      "train: iter 382  trainloss -1996.78164  validloss -1979.68230±0.00000  bestvalidloss -2014.03885  last_update 7\n",
      "train: iter 383  trainloss -2000.62097  validloss -1959.96773±0.00000  bestvalidloss -2014.03885  last_update 8\n",
      "train: iter 384  trainloss -1983.94031  validloss -1977.82138±0.00000  bestvalidloss -2014.03885  last_update 9\n",
      "train: iter 385  trainloss -1990.53893  validloss -1977.94211±0.00000  bestvalidloss -2014.03885  last_update 10\n",
      "train: iter 386  trainloss -1987.34142  validloss -1969.12014±0.00000  bestvalidloss -2014.03885  last_update 11\n",
      "train: iter 387  trainloss -2003.42943  validloss -2011.30063±0.00000  bestvalidloss -2014.03885  last_update 12\n",
      "train: iter 388  trainloss -2022.13122  validloss -1992.74489±0.00000  bestvalidloss -2014.03885  last_update 13\n",
      "train: iter 389  trainloss -1985.37454  validloss -1953.23451±0.00000  bestvalidloss -2014.03885  last_update 14\n",
      "train: iter 390  trainloss -1974.52654  validloss -1927.35195±0.00000  bestvalidloss -2014.03885  last_update 15\n",
      "train: iter 391  trainloss -2000.25663  validloss -1996.49032±0.00000  bestvalidloss -2014.03885  last_update 16\n",
      "train: iter 392  trainloss -2003.07901  validloss -1981.91331±0.00000  bestvalidloss -2014.03885  last_update 17\n",
      "train: iter 393  trainloss -1941.21313  validloss -2013.46823±0.00000  bestvalidloss -2014.03885  last_update 18\n",
      "train: iter 394  trainloss -1936.45055  validloss -1897.83010±0.00000  bestvalidloss -2014.03885  last_update 19\n",
      "train: iter 395  trainloss -1985.63454  validloss -1927.59579±0.00000  bestvalidloss -2014.03885  last_update 20\n",
      "train: iter 396  trainloss -2015.97717  validloss -1971.22340±0.00000  bestvalidloss -2014.03885  last_update 21\n",
      "train: iter 397  trainloss -2017.10298  validloss -1985.99560±0.00000  bestvalidloss -2014.03885  last_update 22\n",
      "train: iter 398  trainloss -2023.26153  validloss -2017.38920±0.00000  bestvalidloss -2017.38920  last_update 0\n",
      "train: iter 399  trainloss -1967.19728  validloss -1919.42276±0.00000  bestvalidloss -2017.38920  last_update 1\n",
      "train: iter 400  trainloss -1943.97240  validloss -1949.54623±0.00000  bestvalidloss -2017.38920  last_update 2\n",
      "train: iter 401  trainloss -1969.19299  validloss -2006.28471±0.00000  bestvalidloss -2017.38920  last_update 3\n",
      "train: iter 402  trainloss -1891.39318  validloss -1922.27786±0.00000  bestvalidloss -2017.38920  last_update 4\n",
      "train: iter 403  trainloss -1945.65336  validloss -1790.34973±0.00000  bestvalidloss -2017.38920  last_update 5\n",
      "train: iter 404  trainloss -2018.95237  validloss -1999.51483±0.00000  bestvalidloss -2017.38920  last_update 6\n",
      "train: iter 405  trainloss -1980.12730  validloss -1980.49201±0.00000  bestvalidloss -2017.38920  last_update 7\n",
      "train: iter 406  trainloss -1988.02473  validloss -1982.50002±0.00000  bestvalidloss -2017.38920  last_update 8\n",
      "train: iter 407  trainloss -2004.87786  validloss -1979.10883±0.00000  bestvalidloss -2017.38920  last_update 9\n",
      "train: iter 408  trainloss -2011.30429  validloss -1961.31879±0.00000  bestvalidloss -2017.38920  last_update 10\n",
      "train: iter 409  trainloss -2007.52616  validloss -1990.22437±0.00000  bestvalidloss -2017.38920  last_update 11\n",
      "train: iter 410  trainloss -1972.72284  validloss -1960.48597±0.00000  bestvalidloss -2017.38920  last_update 12\n",
      "train: iter 411  trainloss -1992.79776  validloss -1959.72054±0.00000  bestvalidloss -2017.38920  last_update 13\n",
      "train: iter 412  trainloss -1987.19806  validloss -1998.30936±0.00000  bestvalidloss -2017.38920  last_update 14\n",
      "train: iter 413  trainloss -1972.55289  validloss -1942.72909±0.00000  bestvalidloss -2017.38920  last_update 15\n",
      "train: iter 414  trainloss -1980.95560  validloss -1979.59464±0.00000  bestvalidloss -2017.38920  last_update 16\n",
      "train: iter 415  trainloss -1987.86305  validloss -1904.11136±0.00000  bestvalidloss -2017.38920  last_update 17\n",
      "train: iter 416  trainloss -2004.18991  validloss -1999.07840±0.00000  bestvalidloss -2017.38920  last_update 18\n",
      "train: iter 417  trainloss -2008.83642  validloss -1997.97893±0.00000  bestvalidloss -2017.38920  last_update 19\n",
      "train: iter 418  trainloss -1963.20100  validloss -2014.11420±0.00000  bestvalidloss -2017.38920  last_update 20\n",
      "train: iter 419  trainloss -1986.41892  validloss -1892.93580±0.00000  bestvalidloss -2017.38920  last_update 21\n",
      "train: iter 420  trainloss -1984.29863  validloss -1940.60428±0.00000  bestvalidloss -2017.38920  last_update 22\n",
      "train: iter 421  trainloss -1994.64080  validloss -1984.23170±0.00000  bestvalidloss -2017.38920  last_update 23\n",
      "train: iter 422  trainloss -2006.47150  validloss -1976.84003±0.00000  bestvalidloss -2017.38920  last_update 24\n",
      "train: iter 423  trainloss -1982.21219  validloss -1971.23379±0.00000  bestvalidloss -2017.38920  last_update 25\n",
      "train: iter 424  trainloss -1998.59238  validloss -1983.43078±0.00000  bestvalidloss -2017.38920  last_update 26\n",
      "train: iter 425  trainloss -2001.31408  validloss -1975.67124±0.00000  bestvalidloss -2017.38920  last_update 27\n",
      "train: iter 426  trainloss -1983.98384  validloss -1955.30363±0.00000  bestvalidloss -2017.38920  last_update 28\n",
      "train: iter 427  trainloss -1997.55021  validloss -1978.50438±0.00000  bestvalidloss -2017.38920  last_update 29\n",
      "train: iter 428  trainloss -1981.46559  validloss -1966.95985±0.00000  bestvalidloss -2017.38920  last_update 30\n",
      "train: iter 429  trainloss -1967.87212  validloss -1941.55101±0.00000  bestvalidloss -2017.38920  last_update 31\n",
      "train: iter 430  trainloss -1958.66425  validloss -1927.30624±0.00000  bestvalidloss -2017.38920  last_update 32\n",
      "train: iter 431  trainloss -1978.24671  validloss -1917.89544±0.00000  bestvalidloss -2017.38920  last_update 33\n",
      "train: iter 432  trainloss -2020.57649  validloss -2019.43346±0.00000  bestvalidloss -2019.43346  last_update 0\n",
      "train: iter 433  trainloss -2015.78385  validloss -2025.47830±0.00000  bestvalidloss -2025.47830  last_update 0\n",
      "train: iter 434  trainloss -1997.21561  validloss -1970.91084±0.00000  bestvalidloss -2025.47830  last_update 1\n",
      "train: iter 435  trainloss -2012.65269  validloss -1972.94023±0.00000  bestvalidloss -2025.47830  last_update 2\n",
      "train: iter 436  trainloss -2002.80055  validloss -1986.53758±0.00000  bestvalidloss -2025.47830  last_update 3\n",
      "train: iter 437  trainloss -1925.21801  validloss -1784.82446±0.00000  bestvalidloss -2025.47830  last_update 4\n",
      "train: iter 438  trainloss -1993.64509  validloss -1981.15189±0.00000  bestvalidloss -2025.47830  last_update 5\n",
      "train: iter 439  trainloss -1986.90336  validloss -1995.36855±0.00000  bestvalidloss -2025.47830  last_update 6\n",
      "train: iter 440  trainloss -2011.87784  validloss -1951.08410±0.00000  bestvalidloss -2025.47830  last_update 7\n",
      "train: iter 441  trainloss -1959.61194  validloss -1895.49434±0.00000  bestvalidloss -2025.47830  last_update 8\n",
      "train: iter 442  trainloss -1974.66693  validloss -1861.04305±0.00000  bestvalidloss -2025.47830  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 443  trainloss -1990.49928  validloss -2001.14132±0.00000  bestvalidloss -2025.47830  last_update 10\n",
      "train: iter 444  trainloss -2009.77590  validloss -1994.08670±0.00000  bestvalidloss -2025.47830  last_update 11\n",
      "train: iter 445  trainloss -2013.23269  validloss -1984.73304±0.00000  bestvalidloss -2025.47830  last_update 12\n",
      "train: iter 446  trainloss -2013.47975  validloss -1988.31255±0.00000  bestvalidloss -2025.47830  last_update 13\n",
      "train: iter 447  trainloss -2011.18760  validloss -2011.76757±0.00000  bestvalidloss -2025.47830  last_update 14\n",
      "train: iter 448  trainloss -1966.50404  validloss -1982.72828±0.00000  bestvalidloss -2025.47830  last_update 15\n",
      "train: iter 449  trainloss -1988.19489  validloss -1978.59741±0.00000  bestvalidloss -2025.47830  last_update 16\n",
      "train: iter 450  trainloss -1990.00418  validloss -1959.79876±0.00000  bestvalidloss -2025.47830  last_update 17\n",
      "train: iter 451  trainloss -2022.19600  validloss -1986.20446±0.00000  bestvalidloss -2025.47830  last_update 18\n",
      "train: iter 452  trainloss -2003.84855  validloss -2026.59408±0.00000  bestvalidloss -2026.59408  last_update 0\n",
      "train: iter 453  trainloss -1916.94377  validloss -1939.46920±0.00000  bestvalidloss -2026.59408  last_update 1\n",
      "train: iter 454  trainloss -2006.82637  validloss -1954.09200±0.00000  bestvalidloss -2026.59408  last_update 2\n",
      "train: iter 455  trainloss -1920.89034  validloss -1960.03682±0.00000  bestvalidloss -2026.59408  last_update 3\n",
      "train: iter 456  trainloss -2012.28795  validloss -1971.32394±0.00000  bestvalidloss -2026.59408  last_update 4\n",
      "train: iter 457  trainloss -2018.03587  validloss -2004.73142±0.00000  bestvalidloss -2026.59408  last_update 5\n",
      "train: iter 458  trainloss -2002.49716  validloss -2002.46686±0.00000  bestvalidloss -2026.59408  last_update 6\n",
      "train: iter 459  trainloss -2016.08766  validloss -1992.52969±0.00000  bestvalidloss -2026.59408  last_update 7\n",
      "train: iter 460  trainloss -1980.15290  validloss -1939.42986±0.00000  bestvalidloss -2026.59408  last_update 8\n",
      "train: iter 461  trainloss -1977.07323  validloss -2022.30976±0.00000  bestvalidloss -2026.59408  last_update 9\n",
      "train: iter 462  trainloss -1856.69258  validloss -1968.21215±0.00000  bestvalidloss -2026.59408  last_update 10\n",
      "train: iter 463  trainloss -2017.84708  validloss -1981.57541±0.00000  bestvalidloss -2026.59408  last_update 11\n",
      "train: iter 464  trainloss -2027.08554  validloss -2028.93376±0.00000  bestvalidloss -2028.93376  last_update 0\n",
      "train: iter 465  trainloss -2025.37128  validloss -1993.77092±0.00000  bestvalidloss -2028.93376  last_update 1\n",
      "train: iter 466  trainloss -2035.88366  validloss -2007.82923±0.00000  bestvalidloss -2028.93376  last_update 2\n",
      "train: iter 467  trainloss -1936.66800  validloss -1964.34953±0.00000  bestvalidloss -2028.93376  last_update 3\n",
      "train: iter 468  trainloss -1893.96110  validloss -1888.02684±0.00000  bestvalidloss -2028.93376  last_update 4\n",
      "train: iter 469  trainloss -2015.20721  validloss -1940.57482±0.00000  bestvalidloss -2028.93376  last_update 5\n",
      "train: iter 470  trainloss -1980.63730  validloss -2010.74561±0.00000  bestvalidloss -2028.93376  last_update 6\n",
      "train: iter 471  trainloss -2016.04006  validloss -1985.72853±0.00000  bestvalidloss -2028.93376  last_update 7\n",
      "train: iter 472  trainloss -2026.59100  validloss -1978.26763±0.00000  bestvalidloss -2028.93376  last_update 8\n",
      "train: iter 473  trainloss -1995.79007  validloss -1983.42567±0.00000  bestvalidloss -2028.93376  last_update 9\n",
      "train: iter 474  trainloss -1921.88647  validloss -1750.44145±0.00000  bestvalidloss -2028.93376  last_update 10\n",
      "train: iter 475  trainloss -2033.35993  validloss -1999.26846±0.00000  bestvalidloss -2028.93376  last_update 11\n",
      "train: iter 476  trainloss -2030.89886  validloss -2006.01164±0.00000  bestvalidloss -2028.93376  last_update 12\n",
      "train: iter 477  trainloss -2033.73165  validloss -2000.42540±0.00000  bestvalidloss -2028.93376  last_update 13\n",
      "train: iter 478  trainloss -2004.87149  validloss -2030.19946±0.00000  bestvalidloss -2030.19946  last_update 0\n",
      "train: iter 479  trainloss -1969.17744  validloss -1984.63702±0.00000  bestvalidloss -2030.19946  last_update 1\n",
      "train: iter 480  trainloss -1950.61367  validloss -1828.56821±0.00000  bestvalidloss -2030.19946  last_update 2\n",
      "train: iter 481  trainloss -1996.28746  validloss -1936.71286±0.00000  bestvalidloss -2030.19946  last_update 3\n",
      "train: iter 482  trainloss -2014.09102  validloss -2008.27289±0.00000  bestvalidloss -2030.19946  last_update 4\n",
      "train: iter 483  trainloss -2023.03477  validloss -1933.94928±0.00000  bestvalidloss -2030.19946  last_update 5\n",
      "train: iter 484  trainloss -2016.75011  validloss -2005.67163±0.00000  bestvalidloss -2030.19946  last_update 6\n",
      "train: iter 485  trainloss -1965.28699  validloss -1960.11603±0.00000  bestvalidloss -2030.19946  last_update 7\n",
      "train: iter 486  trainloss -2031.65869  validloss -1988.53448±0.00000  bestvalidloss -2030.19946  last_update 8\n",
      "train: iter 487  trainloss -2006.78949  validloss -1951.83224±0.00000  bestvalidloss -2030.19946  last_update 9\n",
      "train: iter 488  trainloss -2026.41153  validloss -2008.46169±0.00000  bestvalidloss -2030.19946  last_update 10\n",
      "train: iter 489  trainloss -2026.59085  validloss -1978.60673±0.00000  bestvalidloss -2030.19946  last_update 11\n",
      "train: iter 490  trainloss -2002.55938  validloss -2032.93687±0.00000  bestvalidloss -2032.93687  last_update 0\n",
      "train: iter 491  trainloss -2035.11252  validloss -1968.43343±0.00000  bestvalidloss -2032.93687  last_update 1\n",
      "train: iter 492  trainloss -1990.05293  validloss -2006.51912±0.00000  bestvalidloss -2032.93687  last_update 2\n",
      "train: iter 493  trainloss -2001.07680  validloss -2021.29739±0.00000  bestvalidloss -2032.93687  last_update 3\n",
      "train: iter 494  trainloss -2018.21174  validloss -1931.87624±0.00000  bestvalidloss -2032.93687  last_update 4\n",
      "train: iter 495  trainloss -2035.23522  validloss -2032.88754±0.00000  bestvalidloss -2032.93687  last_update 5\n",
      "train: iter 496  trainloss -2008.29996  validloss -1997.66763±0.00000  bestvalidloss -2032.93687  last_update 6\n",
      "train: iter 497  trainloss -1998.69395  validloss -1947.45667±0.00000  bestvalidloss -2032.93687  last_update 7\n",
      "train: iter 498  trainloss -1989.94923  validloss -2010.88801±0.00000  bestvalidloss -2032.93687  last_update 8\n",
      "train: iter 499  trainloss -1869.19192  validloss -1932.57577±0.00000  bestvalidloss -2032.93687  last_update 9\n",
      "train: iter 500  trainloss -2016.02624  validloss -1991.76131±0.00000  bestvalidloss -2032.93687  last_update 10\n",
      "train: iter 501  trainloss -2031.08816  validloss -2014.90153±0.00000  bestvalidloss -2032.93687  last_update 11\n",
      "train: iter 502  trainloss -2032.65195  validloss -2017.29185±0.00000  bestvalidloss -2032.93687  last_update 12\n",
      "train: iter 503  trainloss -2028.85085  validloss -1955.09174±0.00000  bestvalidloss -2032.93687  last_update 13\n",
      "train: iter 504  trainloss -1877.79651  validloss -1978.34087±0.00000  bestvalidloss -2032.93687  last_update 14\n",
      "train: iter 505  trainloss -1981.49712  validloss -1916.97745±0.00000  bestvalidloss -2032.93687  last_update 15\n",
      "train: iter 506  trainloss -2021.26441  validloss -1978.69299±0.00000  bestvalidloss -2032.93687  last_update 16\n",
      "train: iter 507  trainloss -2036.83305  validloss -1979.91508±0.00000  bestvalidloss -2032.93687  last_update 17\n",
      "train: iter 508  trainloss -2043.15630  validloss -1958.86788±0.00000  bestvalidloss -2032.93687  last_update 18\n",
      "train: iter 509  trainloss -2038.78807  validloss -2003.15787±0.00000  bestvalidloss -2032.93687  last_update 19\n",
      "train: iter 510  trainloss -2034.58257  validloss -1960.39765±0.00000  bestvalidloss -2032.93687  last_update 20\n",
      "train: iter 511  trainloss -1988.98458  validloss -1732.19767±0.00000  bestvalidloss -2032.93687  last_update 21\n",
      "train: iter 512  trainloss -2003.68524  validloss -1995.42176±0.00000  bestvalidloss -2032.93687  last_update 22\n",
      "train: iter 513  trainloss -2039.16549  validloss -1987.10829±0.00000  bestvalidloss -2032.93687  last_update 23\n",
      "train: iter 514  trainloss -2029.03985  validloss -2010.34016±0.00000  bestvalidloss -2032.93687  last_update 24\n",
      "train: iter 515  trainloss -2051.66882  validloss -1982.53114±0.00000  bestvalidloss -2032.93687  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 516  trainloss -2036.21777  validloss -1996.95404±0.00000  bestvalidloss -2032.93687  last_update 26\n",
      "train: iter 517  trainloss -2042.93039  validloss -1919.49337±0.00000  bestvalidloss -2032.93687  last_update 27\n",
      "train: iter 518  trainloss -2035.87366  validloss -1982.19860±0.00000  bestvalidloss -2032.93687  last_update 28\n",
      "train: iter 519  trainloss -2012.82878  validloss -1898.59127±0.00000  bestvalidloss -2032.93687  last_update 29\n",
      "train: iter 520  trainloss -1961.89883  validloss -1978.34655±0.00000  bestvalidloss -2032.93687  last_update 30\n",
      "train: iter 521  trainloss -1985.96670  validloss -1800.04666±0.00000  bestvalidloss -2032.93687  last_update 31\n",
      "train: iter 522  trainloss -2021.34591  validloss -1958.22567±0.00000  bestvalidloss -2032.93687  last_update 32\n",
      "train: iter 523  trainloss -2034.96917  validloss -2027.98725±0.00000  bestvalidloss -2032.93687  last_update 33\n",
      "train: iter 524  trainloss -2051.02910  validloss -1981.95929±0.00000  bestvalidloss -2032.93687  last_update 34\n",
      "train: iter 525  trainloss -2031.91368  validloss -1994.44645±0.00000  bestvalidloss -2032.93687  last_update 35\n",
      "train: iter 526  trainloss -1994.97514  validloss -1946.05316±0.00000  bestvalidloss -2032.93687  last_update 36\n",
      "train: iter 527  trainloss -2052.86310  validloss -1999.89601±0.00000  bestvalidloss -2032.93687  last_update 37\n",
      "train: iter 528  trainloss -2045.68039  validloss -2013.94268±0.00000  bestvalidloss -2032.93687  last_update 38\n",
      "train: iter 529  trainloss -1995.72789  validloss -2002.53092±0.00000  bestvalidloss -2032.93687  last_update 39\n",
      "train: iter 530  trainloss -2024.20073  validloss -1999.91021±0.00000  bestvalidloss -2032.93687  last_update 40\n",
      "train: iter 531  trainloss -1941.90423  validloss -1983.01206±0.00000  bestvalidloss -2032.93687  last_update 41\n",
      "train: iter 532  trainloss -1945.54019  validloss -1838.24029±0.00000  bestvalidloss -2032.93687  last_update 42\n",
      "train: iter 533  trainloss -2040.04220  validloss -2006.31327±0.00000  bestvalidloss -2032.93687  last_update 43\n",
      "train: iter 534  trainloss -2043.47217  validloss -1980.39308±0.00000  bestvalidloss -2032.93687  last_update 44\n",
      "train: iter 535  trainloss -2061.42339  validloss -2019.56875±0.00000  bestvalidloss -2032.93687  last_update 45\n",
      "train: iter 536  trainloss -2042.99105  validloss -2009.66088±0.00000  bestvalidloss -2032.93687  last_update 46\n",
      "train: iter 537  trainloss -2052.78850  validloss -2039.56786±0.00000  bestvalidloss -2039.56786  last_update 0\n",
      "train: iter 538  trainloss -2028.46525  validloss -1951.69115±0.00000  bestvalidloss -2039.56786  last_update 1\n",
      "train: iter 539  trainloss -1963.78004  validloss -1987.06983±0.00000  bestvalidloss -2039.56786  last_update 2\n",
      "train: iter 540  trainloss -2035.62413  validloss -1949.88205±0.00000  bestvalidloss -2039.56786  last_update 3\n",
      "train: iter 541  trainloss -2059.43320  validloss -2029.06386±0.00000  bestvalidloss -2039.56786  last_update 4\n",
      "train: iter 542  trainloss -2056.73947  validloss -1942.64587±0.00000  bestvalidloss -2039.56786  last_update 5\n",
      "train: iter 543  trainloss -2050.82747  validloss -2026.35216±0.00000  bestvalidloss -2039.56786  last_update 6\n",
      "train: iter 544  trainloss -2037.60283  validloss -2000.28911±0.00000  bestvalidloss -2039.56786  last_update 7\n",
      "train: iter 545  trainloss -1988.13511  validloss -1910.10543±0.00000  bestvalidloss -2039.56786  last_update 8\n",
      "train: iter 546  trainloss -2042.51914  validloss -1942.28570±0.00000  bestvalidloss -2039.56786  last_update 9\n",
      "train: iter 547  trainloss -2036.19131  validloss -2010.81783±0.00000  bestvalidloss -2039.56786  last_update 10\n",
      "train: iter 548  trainloss -2047.20262  validloss -2017.13636±0.00000  bestvalidloss -2039.56786  last_update 11\n",
      "train: iter 549  trainloss -2038.06426  validloss -1978.75251±0.00000  bestvalidloss -2039.56786  last_update 12\n",
      "train: iter 550  trainloss -2047.88971  validloss -1969.96321±0.00000  bestvalidloss -2039.56786  last_update 13\n",
      "train: iter 551  trainloss -1894.57586  validloss -2000.19528±0.00000  bestvalidloss -2039.56786  last_update 14\n",
      "train: iter 552  trainloss -1983.24209  validloss -1767.80555±0.00000  bestvalidloss -2039.56786  last_update 15\n",
      "train: iter 553  trainloss -2012.44813  validloss -1942.07947±0.00000  bestvalidloss -2039.56786  last_update 16\n",
      "train: iter 554  trainloss -2045.95772  validloss -1938.00081±0.00000  bestvalidloss -2039.56786  last_update 17\n",
      "train: iter 555  trainloss -2048.19419  validloss -2021.15269±0.00000  bestvalidloss -2039.56786  last_update 18\n",
      "train: iter 556  trainloss -2028.15443  validloss -2008.28737±0.00000  bestvalidloss -2039.56786  last_update 19\n",
      "train: iter 557  trainloss -2047.16545  validloss -1992.52868±0.00000  bestvalidloss -2039.56786  last_update 20\n",
      "train: iter 558  trainloss -2063.18675  validloss -2015.97858±0.00000  bestvalidloss -2039.56786  last_update 21\n",
      "train: iter 559  trainloss -2005.68835  validloss -1964.74064±0.00000  bestvalidloss -2039.56786  last_update 22\n",
      "train: iter 560  trainloss -2054.15072  validloss -1984.21475±0.00000  bestvalidloss -2039.56786  last_update 23\n",
      "train: iter 561  trainloss -2058.61741  validloss -2033.70836±0.00000  bestvalidloss -2039.56786  last_update 24\n",
      "train: iter 562  trainloss -1967.95061  validloss -1951.13064±0.00000  bestvalidloss -2039.56786  last_update 25\n",
      "train: iter 563  trainloss -2007.48274  validloss -1969.80768±0.00000  bestvalidloss -2039.56786  last_update 26\n",
      "train: iter 564  trainloss -2062.51164  validloss -2022.65564±0.00000  bestvalidloss -2039.56786  last_update 27\n",
      "train: iter 565  trainloss -2050.49192  validloss -2020.25269±0.00000  bestvalidloss -2039.56786  last_update 28\n",
      "train: iter 566  trainloss -2016.19828  validloss -1971.98738±0.00000  bestvalidloss -2039.56786  last_update 29\n",
      "train: iter 567  trainloss -2029.13099  validloss -1996.07024±0.00000  bestvalidloss -2039.56786  last_update 30\n",
      "train: iter 568  trainloss -2054.22871  validloss -1995.15845±0.00000  bestvalidloss -2039.56786  last_update 31\n",
      "train: iter 569  trainloss -2070.73821  validloss -1993.32386±0.00000  bestvalidloss -2039.56786  last_update 32\n",
      "train: iter 570  trainloss -2054.22869  validloss -2025.29678±0.00000  bestvalidloss -2039.56786  last_update 33\n",
      "train: iter 571  trainloss -2058.96269  validloss -2035.50838±0.00000  bestvalidloss -2039.56786  last_update 34\n",
      "train: iter 572  trainloss -1900.10996  validloss -1985.88787±0.00000  bestvalidloss -2039.56786  last_update 35\n",
      "train: iter 573  trainloss -1916.65184  validloss -1783.13398±0.00000  bestvalidloss -2039.56786  last_update 36\n",
      "train: iter 574  trainloss -2037.75750  validloss -1939.08300±0.00000  bestvalidloss -2039.56786  last_update 37\n",
      "train: iter 575  trainloss -2043.00161  validloss -1994.61411±0.00000  bestvalidloss -2039.56786  last_update 38\n",
      "train: iter 576  trainloss -2051.15354  validloss -1983.92486±0.00000  bestvalidloss -2039.56786  last_update 39\n",
      "train: iter 577  trainloss -2019.49667  validloss -2000.63427±0.00000  bestvalidloss -2039.56786  last_update 40\n",
      "train: iter 578  trainloss -2021.67226  validloss -1984.12484±0.00000  bestvalidloss -2039.56786  last_update 41\n",
      "train: iter 579  trainloss -2061.04955  validloss -2030.10670±0.00000  bestvalidloss -2039.56786  last_update 42\n",
      "train: iter 580  trainloss -2066.91678  validloss -2002.24302±0.00000  bestvalidloss -2039.56786  last_update 43\n",
      "train: iter 581  trainloss -2050.33303  validloss -2011.31280±0.00000  bestvalidloss -2039.56786  last_update 44\n",
      "train: iter 582  trainloss -1981.48612  validloss -1990.84827±0.00000  bestvalidloss -2039.56786  last_update 45\n",
      "train: iter 583  trainloss -2034.06017  validloss -1840.54767±0.00000  bestvalidloss -2039.56786  last_update 46\n",
      "train: iter 584  trainloss -2023.08998  validloss -1979.42864±0.00000  bestvalidloss -2039.56786  last_update 47\n",
      "train: iter 585  trainloss -2050.20223  validloss -1992.84569±0.00000  bestvalidloss -2039.56786  last_update 48\n",
      "train: iter 586  trainloss -2064.09693  validloss -1968.13429±0.00000  bestvalidloss -2039.56786  last_update 49\n",
      "train: iter 587  trainloss -2069.18821  validloss -2036.14178±0.00000  bestvalidloss -2039.56786  last_update 50\n",
      "train: iter 588  trainloss -1924.19998  validloss -1956.71338±0.00000  bestvalidloss -2039.56786  last_update 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 589  trainloss -2038.17225  validloss -1976.90012±0.00000  bestvalidloss -2039.56786  last_update 52\n",
      "train: iter 590  trainloss -1933.69071  validloss -1963.63023±0.00000  bestvalidloss -2039.56786  last_update 53\n",
      "train: iter 591  trainloss -1917.98277  validloss -1913.20652±0.00000  bestvalidloss -2039.56786  last_update 54\n",
      "train: iter 592  trainloss -2065.11181  validloss -1983.66186±0.00000  bestvalidloss -2039.56786  last_update 55\n",
      "train: iter 593  trainloss -2061.81615  validloss -1982.69359±0.00000  bestvalidloss -2039.56786  last_update 56\n",
      "train: iter 594  trainloss -2047.73196  validloss -2014.51388±0.00000  bestvalidloss -2039.56786  last_update 57\n",
      "train: iter 595  trainloss -2055.36653  validloss -1929.31615±0.00000  bestvalidloss -2039.56786  last_update 58\n",
      "train: iter 596  trainloss -2018.98198  validloss -1970.38081±0.00000  bestvalidloss -2039.56786  last_update 59\n",
      "train: iter 597  trainloss -2050.60270  validloss -2026.08550±0.00000  bestvalidloss -2039.56786  last_update 60\n",
      "train: iter 598  trainloss -2070.98784  validloss -1998.21728±0.00000  bestvalidloss -2039.56786  last_update 61\n",
      "train: iter 599  trainloss -1956.13285  validloss -1984.72189±0.00000  bestvalidloss -2039.56786  last_update 62\n",
      "train: iter 600  trainloss -2043.26840  validloss -1961.91454±0.00000  bestvalidloss -2039.56786  last_update 63\n",
      "train: iter 601  trainloss -2059.12299  validloss -1981.07088±0.00000  bestvalidloss -2039.56786  last_update 64\n",
      "train: iter 602  trainloss -2057.95734  validloss -2006.25251±0.00000  bestvalidloss -2039.56786  last_update 65\n",
      "train: iter 603  trainloss -2038.26601  validloss -1819.22430±0.00000  bestvalidloss -2039.56786  last_update 66\n",
      "train: iter 604  trainloss -2042.25643  validloss -1976.66734±0.00000  bestvalidloss -2039.56786  last_update 67\n",
      "train: iter 605  trainloss -2064.70338  validloss -2006.58199±0.00000  bestvalidloss -2039.56786  last_update 68\n",
      "train: iter 606  trainloss -2045.44288  validloss -2000.98859±0.00000  bestvalidloss -2039.56786  last_update 69\n",
      "train: iter 607  trainloss -2052.94042  validloss -2015.57850±0.00000  bestvalidloss -2039.56786  last_update 70\n",
      "train: iter 608  trainloss -2056.15433  validloss -1976.44315±0.00000  bestvalidloss -2039.56786  last_update 71\n",
      "train: iter 609  trainloss -2028.09736  validloss -1932.11443±0.00000  bestvalidloss -2039.56786  last_update 72\n",
      "train: iter 610  trainloss -2060.36034  validloss -2027.22154±0.00000  bestvalidloss -2039.56786  last_update 73\n",
      "train: iter 611  trainloss -1853.81420  validloss -1482.58219±0.00000  bestvalidloss -2039.56786  last_update 74\n",
      "train: iter 612  trainloss -2028.20258  validloss -1945.95956±0.00000  bestvalidloss -2039.56786  last_update 75\n",
      "train: iter 613  trainloss -2051.70717  validloss -1965.72020±0.00000  bestvalidloss -2039.56786  last_update 76\n",
      "train: iter 614  trainloss -2054.49761  validloss -1978.69144±0.00000  bestvalidloss -2039.56786  last_update 77\n",
      "train: iter 615  trainloss -2040.44323  validloss -1918.95867±0.00000  bestvalidloss -2039.56786  last_update 78\n",
      "train: iter 616  trainloss -2066.09093  validloss -2018.47910±0.00000  bestvalidloss -2039.56786  last_update 79\n",
      "train: iter 617  trainloss -2051.41355  validloss -2010.38424±0.00000  bestvalidloss -2039.56786  last_update 80\n",
      "train: iter 618  trainloss -2066.79257  validloss -2025.67252±0.00000  bestvalidloss -2039.56786  last_update 81\n",
      "train: iter 619  trainloss -2055.75538  validloss -2020.52807±0.00000  bestvalidloss -2039.56786  last_update 82\n",
      "train: iter 620  trainloss -2058.94445  validloss -2036.24306±0.00000  bestvalidloss -2039.56786  last_update 83\n",
      "train: iter 621  trainloss -2053.96783  validloss -1945.96884±0.00000  bestvalidloss -2039.56786  last_update 84\n",
      "train: iter 622  trainloss -2072.23202  validloss -1948.19624±0.00000  bestvalidloss -2039.56786  last_update 85\n",
      "train: iter 623  trainloss -2068.49292  validloss -1925.25093±0.00000  bestvalidloss -2039.56786  last_update 86\n",
      "train: iter 624  trainloss -2033.73615  validloss -2008.02816±0.00000  bestvalidloss -2039.56786  last_update 87\n",
      "train: iter 625  trainloss -1911.93393  validloss -772.12521±0.00000  bestvalidloss -2039.56786  last_update 88\n",
      "train: iter 626  trainloss -2048.21838  validloss -1941.80274±0.00000  bestvalidloss -2039.56786  last_update 89\n",
      "train: iter 627  trainloss -2067.16233  validloss -1994.19712±0.00000  bestvalidloss -2039.56786  last_update 90\n",
      "train: iter 628  trainloss -2048.76439  validloss -2012.64864±0.00000  bestvalidloss -2039.56786  last_update 91\n",
      "train: iter 629  trainloss -2070.90480  validloss -2017.94982±0.00000  bestvalidloss -2039.56786  last_update 92\n",
      "train: iter 630  trainloss -2006.96680  validloss -2012.92098±0.00000  bestvalidloss -2039.56786  last_update 93\n",
      "train: iter 631  trainloss -2036.06854  validloss -1883.80587±0.00000  bestvalidloss -2039.56786  last_update 94\n",
      "train: iter 632  trainloss -1969.14849  validloss -2030.28249±0.00000  bestvalidloss -2039.56786  last_update 95\n",
      "train: iter 633  trainloss -1885.19287  validloss -1867.00038±0.00000  bestvalidloss -2039.56786  last_update 96\n",
      "train: iter 634  trainloss -2073.78185  validloss -1999.97527±0.00000  bestvalidloss -2039.56786  last_update 97\n",
      "train: iter 635  trainloss -2054.49021  validloss -2018.09220±0.00000  bestvalidloss -2039.56786  last_update 98\n",
      "train: iter 636  trainloss -2071.29885  validloss -2031.81973±0.00000  bestvalidloss -2039.56786  last_update 99\n",
      "train: iter 637  trainloss -2001.49664  validloss -2050.05174±0.00000  bestvalidloss -2050.05174  last_update 0\n",
      "train: iter 638  trainloss -1963.73133  validloss -1867.74538±0.00000  bestvalidloss -2050.05174  last_update 1\n",
      "train: iter 639  trainloss -2051.56595  validloss -1903.14572±0.00000  bestvalidloss -2050.05174  last_update 2\n",
      "train: iter 640  trainloss -2049.65627  validloss -1975.10642±0.00000  bestvalidloss -2050.05174  last_update 3\n",
      "train: iter 641  trainloss -2059.55654  validloss -1993.34935±0.00000  bestvalidloss -2050.05174  last_update 4\n",
      "train: iter 642  trainloss -2059.61090  validloss -2021.94841±0.00000  bestvalidloss -2050.05174  last_update 5\n",
      "train: iter 643  trainloss -2055.52143  validloss -1990.99854±0.00000  bestvalidloss -2050.05174  last_update 6\n",
      "train: iter 644  trainloss -2059.54084  validloss -1961.49169±0.00000  bestvalidloss -2050.05174  last_update 7\n",
      "train: iter 645  trainloss -2059.93481  validloss -1990.38235±0.00000  bestvalidloss -2050.05174  last_update 8\n",
      "train: iter 646  trainloss -2075.15958  validloss -2042.58826±0.00000  bestvalidloss -2050.05174  last_update 9\n",
      "train: iter 647  trainloss -2062.18662  validloss -1983.96953±0.00000  bestvalidloss -2050.05174  last_update 10\n",
      "train: iter 648  trainloss -2060.93457  validloss -1938.08872±0.00000  bestvalidloss -2050.05174  last_update 11\n",
      "train: iter 649  trainloss -2081.60094  validloss -1985.11682±0.00000  bestvalidloss -2050.05174  last_update 12\n",
      "train: iter 650  trainloss -2002.12977  validloss -2012.51858±0.00000  bestvalidloss -2050.05174  last_update 13\n",
      "train: iter 651  trainloss -2076.21602  validloss -1988.89036±0.00000  bestvalidloss -2050.05174  last_update 14\n",
      "train: iter 652  trainloss -2064.51077  validloss -1993.51859±0.00000  bestvalidloss -2050.05174  last_update 15\n",
      "train: iter 653  trainloss -2033.40895  validloss -2006.00865±0.00000  bestvalidloss -2050.05174  last_update 16\n",
      "train: iter 654  trainloss -2055.17103  validloss -1986.59814±0.00000  bestvalidloss -2050.05174  last_update 17\n",
      "train: iter 655  trainloss -2055.77599  validloss -1960.87822±0.00000  bestvalidloss -2050.05174  last_update 18\n",
      "train: iter 656  trainloss -2037.67111  validloss -1798.14042±0.00000  bestvalidloss -2050.05174  last_update 19\n",
      "train: iter 657  trainloss -2052.38352  validloss -1968.79626±0.00000  bestvalidloss -2050.05174  last_update 20\n",
      "train: iter 658  trainloss -2026.39925  validloss -1789.42847±0.00000  bestvalidloss -2050.05174  last_update 21\n",
      "train: iter 659  trainloss -2069.43929  validloss -1966.07531±0.00000  bestvalidloss -2050.05174  last_update 22\n",
      "train: iter 660  trainloss -2072.60396  validloss -2035.48482±0.00000  bestvalidloss -2050.05174  last_update 23\n",
      "train: iter 661  trainloss -2056.00914  validloss -2016.71891±0.00000  bestvalidloss -2050.05174  last_update 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 662  trainloss -2068.63482  validloss -1984.98596±0.00000  bestvalidloss -2050.05174  last_update 25\n",
      "train: iter 663  trainloss -2004.39430  validloss -1951.21024±0.00000  bestvalidloss -2050.05174  last_update 26\n",
      "train: iter 664  trainloss -2009.95665  validloss -2003.17084±0.00000  bestvalidloss -2050.05174  last_update 27\n",
      "train: iter 665  trainloss -2056.24649  validloss -1914.34137±0.00000  bestvalidloss -2050.05174  last_update 28\n",
      "train: iter 666  trainloss -2050.89587  validloss -1988.36988±0.00000  bestvalidloss -2050.05174  last_update 29\n",
      "train: iter 667  trainloss -2068.44890  validloss -2006.89299±0.00000  bestvalidloss -2050.05174  last_update 30\n",
      "train: iter 668  trainloss -2088.14980  validloss -2015.52525±0.00000  bestvalidloss -2050.05174  last_update 31\n",
      "train: iter 669  trainloss -2068.75910  validloss -1995.06208±0.00000  bestvalidloss -2050.05174  last_update 32\n",
      "train: iter 670  trainloss -2043.18433  validloss -1992.77594±0.00000  bestvalidloss -2050.05174  last_update 33\n",
      "train: iter 671  trainloss -2031.17013  validloss -1870.42398±0.00000  bestvalidloss -2050.05174  last_update 34\n",
      "train: iter 672  trainloss -2065.25784  validloss -1945.20153±0.00000  bestvalidloss -2050.05174  last_update 35\n",
      "train: iter 673  trainloss -2032.59607  validloss -1884.86056±0.00000  bestvalidloss -2050.05174  last_update 36\n",
      "train: iter 674  trainloss -2006.73669  validloss -2006.70255±0.00000  bestvalidloss -2050.05174  last_update 37\n",
      "train: iter 675  trainloss -1981.87135  validloss -1933.20738±0.00000  bestvalidloss -2050.05174  last_update 38\n",
      "train: iter 676  trainloss -2066.54886  validloss -1982.93141±0.00000  bestvalidloss -2050.05174  last_update 39\n",
      "train: iter 677  trainloss -2077.77766  validloss -2012.90544±0.00000  bestvalidloss -2050.05174  last_update 40\n",
      "train: iter 678  trainloss -2072.20111  validloss -1988.18852±0.00000  bestvalidloss -2050.05174  last_update 41\n",
      "train: iter 679  trainloss -1909.54967  validloss -1836.46028±0.00000  bestvalidloss -2050.05174  last_update 42\n",
      "train: iter 680  trainloss -2067.05529  validloss -1988.85901±0.00000  bestvalidloss -2050.05174  last_update 43\n",
      "train: iter 681  trainloss -2071.04721  validloss -1997.19867±0.00000  bestvalidloss -2050.05174  last_update 44\n",
      "train: iter 682  trainloss -2077.24274  validloss -1983.62927±0.00000  bestvalidloss -2050.05174  last_update 45\n",
      "train: iter 683  trainloss -2079.04383  validloss -2011.28985±0.00000  bestvalidloss -2050.05174  last_update 46\n",
      "train: iter 684  trainloss -2076.69615  validloss -2011.30955±0.00000  bestvalidloss -2050.05174  last_update 47\n",
      "train: iter 685  trainloss -2075.64270  validloss -2018.83488±0.00000  bestvalidloss -2050.05174  last_update 48\n",
      "train: iter 686  trainloss -2038.59677  validloss -2018.70522±0.00000  bestvalidloss -2050.05174  last_update 49\n",
      "train: iter 687  trainloss -2063.44901  validloss -2021.80303±0.00000  bestvalidloss -2050.05174  last_update 50\n",
      "train: iter 688  trainloss -2059.95625  validloss -2051.92550±0.00000  bestvalidloss -2051.92550  last_update 0\n",
      "train: iter 689  trainloss -2058.56546  validloss -1872.27957±0.00000  bestvalidloss -2051.92550  last_update 1\n",
      "train: iter 690  trainloss -2054.36681  validloss -2034.06309±0.00000  bestvalidloss -2051.92550  last_update 2\n",
      "train: iter 691  trainloss -2071.36740  validloss -2028.56689±0.00000  bestvalidloss -2051.92550  last_update 3\n",
      "train: iter 692  trainloss -2079.18594  validloss -2013.46875±0.00000  bestvalidloss -2051.92550  last_update 4\n",
      "train: iter 693  trainloss -2060.42158  validloss -2019.37993±0.00000  bestvalidloss -2051.92550  last_update 5\n",
      "train: iter 694  trainloss -2051.65734  validloss -1939.28678±0.00000  bestvalidloss -2051.92550  last_update 6\n",
      "train: iter 695  trainloss -2025.74246  validloss -2021.21694±0.00000  bestvalidloss -2051.92550  last_update 7\n",
      "train: iter 696  trainloss -2065.51217  validloss -1874.67248±0.00000  bestvalidloss -2051.92550  last_update 8\n",
      "train: iter 697  trainloss -2057.48717  validloss -1982.68867±0.00000  bestvalidloss -2051.92550  last_update 9\n",
      "train: iter 698  trainloss -2034.86935  validloss -1916.94598±0.00000  bestvalidloss -2051.92550  last_update 10\n",
      "train: iter 699  trainloss -2060.30531  validloss -2008.42676±0.00000  bestvalidloss -2051.92550  last_update 11\n",
      "train: iter 700  trainloss -2077.16224  validloss -2002.44931±0.00000  bestvalidloss -2051.92550  last_update 12\n",
      "train: iter 701  trainloss -2079.43576  validloss -1980.20547±0.00000  bestvalidloss -2051.92550  last_update 13\n",
      "train: iter 702  trainloss -2035.33393  validloss -1977.12581±0.00000  bestvalidloss -2051.92550  last_update 14\n",
      "train: iter 703  trainloss -2058.50764  validloss -1971.33165±0.00000  bestvalidloss -2051.92550  last_update 15\n",
      "train: iter 704  trainloss -2048.00274  validloss -2008.62480±0.00000  bestvalidloss -2051.92550  last_update 16\n",
      "train: iter 705  trainloss -2066.99218  validloss -1957.78881±0.00000  bestvalidloss -2051.92550  last_update 17\n",
      "train: iter 706  trainloss -2082.34134  validloss -1971.93700±0.00000  bestvalidloss -2051.92550  last_update 18\n",
      "train: iter 707  trainloss -2053.75672  validloss -2019.26689±0.00000  bestvalidloss -2051.92550  last_update 19\n",
      "train: iter 708  trainloss -2008.71891  validloss -1967.24321±0.00000  bestvalidloss -2051.92550  last_update 20\n",
      "train: iter 709  trainloss -2061.11164  validloss -2002.02121±0.00000  bestvalidloss -2051.92550  last_update 21\n",
      "train: iter 710  trainloss -2064.38238  validloss -2007.36633±0.00000  bestvalidloss -2051.92550  last_update 22\n",
      "train: iter 711  trainloss -2023.33405  validloss -1841.65852±0.00000  bestvalidloss -2051.92550  last_update 23\n",
      "train: iter 712  trainloss -2076.17132  validloss -2027.07034±0.00000  bestvalidloss -2051.92550  last_update 24\n",
      "train: iter 713  trainloss -2049.87639  validloss -2004.99536±0.00000  bestvalidloss -2051.92550  last_update 25\n",
      "train: iter 714  trainloss -2085.65338  validloss -2012.78613±0.00000  bestvalidloss -2051.92550  last_update 26\n",
      "train: iter 715  trainloss -2046.34767  validloss -1949.62516±0.00000  bestvalidloss -2051.92550  last_update 27\n",
      "train: iter 716  trainloss -2076.68145  validloss -1977.35261±0.00000  bestvalidloss -2051.92550  last_update 28\n",
      "train: iter 717  trainloss -2089.83823  validloss -2043.94023±0.00000  bestvalidloss -2051.92550  last_update 29\n",
      "train: iter 718  trainloss -2083.81598  validloss -1966.94994±0.00000  bestvalidloss -2051.92550  last_update 30\n",
      "train: iter 719  trainloss -2069.86375  validloss -1989.67635±0.00000  bestvalidloss -2051.92550  last_update 31\n",
      "train: iter 720  trainloss -1979.32656  validloss -1782.20599±0.00000  bestvalidloss -2051.92550  last_update 32\n",
      "train: iter 721  trainloss -1975.22319  validloss -1918.56514±0.00000  bestvalidloss -2051.92550  last_update 33\n",
      "train: iter 722  trainloss -2049.36634  validloss -1947.82528±0.00000  bestvalidloss -2051.92550  last_update 34\n",
      "train: iter 723  trainloss -2058.35487  validloss -1950.25046±0.00000  bestvalidloss -2051.92550  last_update 35\n",
      "train: iter 724  trainloss -2064.25759  validloss -2011.65819±0.00000  bestvalidloss -2051.92550  last_update 36\n",
      "train: iter 725  trainloss -2073.38830  validloss -1975.18960±0.00000  bestvalidloss -2051.92550  last_update 37\n",
      "train: iter 726  trainloss -2071.08846  validloss -1985.67417±0.00000  bestvalidloss -2051.92550  last_update 38\n",
      "train: iter 727  trainloss -2063.63267  validloss -1953.21664±0.00000  bestvalidloss -2051.92550  last_update 39\n",
      "train: iter 728  trainloss -2068.21718  validloss -2015.43528±0.00000  bestvalidloss -2051.92550  last_update 40\n",
      "train: iter 729  trainloss -2072.72767  validloss -2001.76718±0.00000  bestvalidloss -2051.92550  last_update 41\n",
      "train: iter 730  trainloss -2077.35871  validloss -1997.19799±0.00000  bestvalidloss -2051.92550  last_update 42\n",
      "train: iter 731  trainloss -2076.83848  validloss -2000.18310±0.00000  bestvalidloss -2051.92550  last_update 43\n",
      "train: iter 732  trainloss -2079.42987  validloss -1971.61702±0.00000  bestvalidloss -2051.92550  last_update 44\n",
      "train: iter 733  trainloss -2090.25800  validloss -2038.41691±0.00000  bestvalidloss -2051.92550  last_update 45\n",
      "train: iter 734  trainloss -2011.02697  validloss -2009.85816±0.00000  bestvalidloss -2051.92550  last_update 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 735  trainloss -2086.44770  validloss -1991.43826±0.00000  bestvalidloss -2051.92550  last_update 47\n",
      "train: iter 736  trainloss -2065.42527  validloss -2020.63242±0.00000  bestvalidloss -2051.92550  last_update 48\n",
      "train: iter 737  trainloss -2048.76043  validloss -2025.86824±0.00000  bestvalidloss -2051.92550  last_update 49\n",
      "train: iter 738  trainloss -2022.15868  validloss -1970.96944±0.00000  bestvalidloss -2051.92550  last_update 50\n",
      "train: iter 739  trainloss -2009.61467  validloss -1899.11528±0.00000  bestvalidloss -2051.92550  last_update 51\n",
      "train: iter 740  trainloss -2047.96124  validloss -1925.76416±0.00000  bestvalidloss -2051.92550  last_update 52\n",
      "train: iter 741  trainloss -2085.63247  validloss -2027.76093±0.00000  bestvalidloss -2051.92550  last_update 53\n",
      "train: iter 742  trainloss -2084.12411  validloss -2041.88917±0.00000  bestvalidloss -2051.92550  last_update 54\n",
      "train: iter 743  trainloss -2077.67901  validloss -1983.86909±0.00000  bestvalidloss -2051.92550  last_update 55\n",
      "train: iter 744  trainloss -1975.99554  validloss -1995.13401±0.00000  bestvalidloss -2051.92550  last_update 56\n",
      "train: iter 745  trainloss -2064.07275  validloss -1963.31571±0.00000  bestvalidloss -2051.92550  last_update 57\n",
      "train: iter 746  trainloss -2090.22020  validloss -2022.63980±0.00000  bestvalidloss -2051.92550  last_update 58\n",
      "train: iter 747  trainloss -2084.39875  validloss -2018.93513±0.00000  bestvalidloss -2051.92550  last_update 59\n",
      "train: iter 748  trainloss -1958.79008  validloss -2030.92534±0.00000  bestvalidloss -2051.92550  last_update 60\n",
      "train: iter 749  trainloss -2079.61579  validloss -1993.41293±0.00000  bestvalidloss -2051.92550  last_update 61\n",
      "train: iter 750  trainloss -2075.45403  validloss -1981.98940±0.00000  bestvalidloss -2051.92550  last_update 62\n",
      "train: iter 751  trainloss -2040.66625  validloss -1974.91566±0.00000  bestvalidloss -2051.92550  last_update 63\n",
      "train: iter 752  trainloss -2056.91562  validloss -1964.17196±0.00000  bestvalidloss -2051.92550  last_update 64\n",
      "train: iter 753  trainloss -2082.26210  validloss -2010.73374±0.00000  bestvalidloss -2051.92550  last_update 65\n",
      "train: iter 754  trainloss -2078.92261  validloss -2022.13383±0.00000  bestvalidloss -2051.92550  last_update 66\n",
      "train: iter 755  trainloss -2075.79619  validloss -1904.05130±0.00000  bestvalidloss -2051.92550  last_update 67\n",
      "train: iter 756  trainloss -2063.82274  validloss -1939.72325±0.00000  bestvalidloss -2051.92550  last_update 68\n",
      "train: iter 757  trainloss -2081.56478  validloss -1969.90403±0.00000  bestvalidloss -2051.92550  last_update 69\n",
      "train: iter 758  trainloss -2091.54758  validloss -1980.25449±0.00000  bestvalidloss -2051.92550  last_update 70\n",
      "train: iter 759  trainloss -2055.98215  validloss -2007.75905±0.00000  bestvalidloss -2051.92550  last_update 71\n",
      "train: iter 760  trainloss -2032.46533  validloss -1963.14336±0.00000  bestvalidloss -2051.92550  last_update 72\n",
      "train: iter 761  trainloss -2062.40675  validloss -1949.87934±0.00000  bestvalidloss -2051.92550  last_update 73\n",
      "train: iter 762  trainloss -2058.76579  validloss -2042.86375±0.00000  bestvalidloss -2051.92550  last_update 74\n",
      "train: iter 763  trainloss -2060.19593  validloss -2021.64204±0.00000  bestvalidloss -2051.92550  last_update 75\n",
      "train: iter 764  trainloss -2073.22572  validloss -1945.46902±0.00000  bestvalidloss -2051.92550  last_update 76\n",
      "train: iter 765  trainloss -2075.42675  validloss -2006.58364±0.00000  bestvalidloss -2051.92550  last_update 77\n",
      "train: iter 766  trainloss -2076.21871  validloss -2001.81840±0.00000  bestvalidloss -2051.92550  last_update 78\n",
      "train: iter 767  trainloss -2000.61047  validloss -1984.35240±0.00000  bestvalidloss -2051.92550  last_update 79\n",
      "train: iter 768  trainloss -2070.19633  validloss -1961.04346±0.00000  bestvalidloss -2051.92550  last_update 80\n",
      "train: iter 769  trainloss -2082.02627  validloss -1942.49709±0.00000  bestvalidloss -2051.92550  last_update 81\n",
      "train: iter 770  trainloss -2090.10953  validloss -1975.08196±0.00000  bestvalidloss -2051.92550  last_update 82\n",
      "train: iter 771  trainloss -2058.71435  validloss -2036.19335±0.00000  bestvalidloss -2051.92550  last_update 83\n",
      "train: iter 772  trainloss -2083.39133  validloss -1983.91005±0.00000  bestvalidloss -2051.92550  last_update 84\n",
      "train: iter 773  trainloss -2059.77396  validloss -2000.74826±0.00000  bestvalidloss -2051.92550  last_update 85\n",
      "train: iter 774  trainloss -2055.91898  validloss -1965.30936±0.00000  bestvalidloss -2051.92550  last_update 86\n",
      "train: iter 775  trainloss -2082.62405  validloss -2003.09962±0.00000  bestvalidloss -2051.92550  last_update 87\n",
      "train: iter 776  trainloss -2086.34913  validloss -2007.43001±0.00000  bestvalidloss -2051.92550  last_update 88\n",
      "train: iter 777  trainloss -2082.04535  validloss -2001.27160±0.00000  bestvalidloss -2051.92550  last_update 89\n",
      "train: iter 778  trainloss -2073.98345  validloss -2005.07615±0.00000  bestvalidloss -2051.92550  last_update 90\n",
      "train: iter 779  trainloss -2088.38028  validloss -2023.75890±0.00000  bestvalidloss -2051.92550  last_update 91\n",
      "train: iter 780  trainloss -2012.16685  validloss -1994.54373±0.00000  bestvalidloss -2051.92550  last_update 92\n",
      "train: iter 781  trainloss -2088.14327  validloss -2000.02632±0.00000  bestvalidloss -2051.92550  last_update 93\n",
      "train: iter 782  trainloss -2076.13047  validloss -2010.73036±0.00000  bestvalidloss -2051.92550  last_update 94\n",
      "train: iter 783  trainloss -2080.08096  validloss -2002.71642±0.00000  bestvalidloss -2051.92550  last_update 95\n",
      "train: iter 784  trainloss -2072.57975  validloss -2028.89328±0.00000  bestvalidloss -2051.92550  last_update 96\n",
      "train: iter 785  trainloss -2045.58296  validloss -2012.13787±0.00000  bestvalidloss -2051.92550  last_update 97\n",
      "train: iter 786  trainloss -2030.08068  validloss -1979.44916±0.00000  bestvalidloss -2051.92550  last_update 98\n",
      "train: iter 787  trainloss -2018.57699  validloss -1952.00426±0.00000  bestvalidloss -2051.92550  last_update 99\n",
      "train: iter 788  trainloss -2079.42584  validloss -1932.86753±0.00000  bestvalidloss -2051.92550  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3059) penalty_target_max tensor(0.5540)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 6.09687  validloss 6.41901±0.00000  bestvalidloss 6.41901  last_update 0\n",
      "train: iter 1  trainloss 5.59938  validloss 5.86044±0.00000  bestvalidloss 5.86044  last_update 0\n",
      "train: iter 2  trainloss 5.20181  validloss 5.41756±0.00000  bestvalidloss 5.41756  last_update 0\n",
      "train: iter 3  trainloss 4.86845  validloss 5.04573±0.00000  bestvalidloss 5.04573  last_update 0\n",
      "train: iter 4  trainloss 4.59207  validloss 4.76539±0.00000  bestvalidloss 4.76539  last_update 0\n",
      "train: iter 5  trainloss 4.36134  validloss 4.50642±0.00000  bestvalidloss 4.50642  last_update 0\n",
      "train: iter 6  trainloss 4.16570  validloss 4.28699±0.00000  bestvalidloss 4.28699  last_update 0\n",
      "train: iter 7  trainloss 3.99661  validloss 4.08984±0.00000  bestvalidloss 4.08984  last_update 0\n",
      "train: iter 8  trainloss 3.84717  validloss 3.93059±0.00000  bestvalidloss 3.93059  last_update 0\n",
      "train: iter 9  trainloss 3.70799  validloss 3.79465±0.00000  bestvalidloss 3.79465  last_update 0\n",
      "train: iter 10  trainloss 3.58434  validloss 3.65644±0.00000  bestvalidloss 3.65644  last_update 0\n",
      "train: iter 11  trainloss 3.47070  validloss 3.53159±0.00000  bestvalidloss 3.53159  last_update 0\n",
      "train: iter 12  trainloss 3.36130  validloss 3.41569±0.00000  bestvalidloss 3.41569  last_update 0\n",
      "train: iter 13  trainloss 3.25196  validloss 3.31160±0.00000  bestvalidloss 3.31160  last_update 0\n",
      "train: iter 14  trainloss 3.14949  validloss 3.20272±0.00000  bestvalidloss 3.20272  last_update 0\n",
      "train: iter 15  trainloss 3.04636  validloss 3.10408±0.00000  bestvalidloss 3.10408  last_update 0\n",
      "train: iter 16  trainloss 2.94640  validloss 2.99991±0.00000  bestvalidloss 2.99991  last_update 0\n",
      "train: iter 17  trainloss 2.84668  validloss 2.90076±0.00000  bestvalidloss 2.90076  last_update 0\n",
      "train: iter 18  trainloss 2.74758  validloss 2.78609±0.00000  bestvalidloss 2.78609  last_update 0\n",
      "train: iter 19  trainloss 2.64469  validloss 2.68980±0.00000  bestvalidloss 2.68980  last_update 0\n",
      "train: iter 20  trainloss 2.54226  validloss 2.59471±0.00000  bestvalidloss 2.59471  last_update 0\n",
      "train: iter 21  trainloss 2.44312  validloss 2.48583±0.00000  bestvalidloss 2.48583  last_update 0\n",
      "train: iter 22  trainloss 2.34682  validloss 2.38622±0.00000  bestvalidloss 2.38622  last_update 0\n",
      "train: iter 23  trainloss 2.24834  validloss 2.28927±0.00000  bestvalidloss 2.28927  last_update 0\n",
      "train: iter 24  trainloss 2.15900  validloss 2.19787±0.00000  bestvalidloss 2.19787  last_update 0\n",
      "train: iter 25  trainloss 2.06673  validloss 2.10530±0.00000  bestvalidloss 2.10530  last_update 0\n",
      "train: iter 26  trainloss 1.98350  validloss 2.01697±0.00000  bestvalidloss 2.01697  last_update 0\n",
      "train: iter 27  trainloss 1.90223  validloss 1.93321±0.00000  bestvalidloss 1.93321  last_update 0\n",
      "train: iter 28  trainloss 1.81900  validloss 1.84693±0.00000  bestvalidloss 1.84693  last_update 0\n",
      "train: iter 29  trainloss 1.73745  validloss 1.76829±0.00000  bestvalidloss 1.76829  last_update 0\n",
      "train: iter 30  trainloss 1.65690  validloss 1.68583±0.00000  bestvalidloss 1.68583  last_update 0\n",
      "train: iter 31  trainloss 1.58133  validloss 1.59963±0.00000  bestvalidloss 1.59963  last_update 0\n",
      "train: iter 32  trainloss 1.50514  validloss 1.52975±0.00000  bestvalidloss 1.52975  last_update 0\n",
      "train: iter 33  trainloss 1.42574  validloss 1.43842±0.00000  bestvalidloss 1.43842  last_update 0\n",
      "train: iter 34  trainloss 1.34552  validloss 1.35941±0.00000  bestvalidloss 1.35941  last_update 0\n",
      "train: iter 35  trainloss 1.26653  validloss 1.27137±0.00000  bestvalidloss 1.27137  last_update 0\n",
      "train: iter 36  trainloss 1.18488  validloss 1.19090±0.00000  bestvalidloss 1.19090  last_update 0\n",
      "train: iter 37  trainloss 1.10730  validloss 1.10388±0.00000  bestvalidloss 1.10388  last_update 0\n",
      "train: iter 38  trainloss 1.03402  validloss 1.02381±0.00000  bestvalidloss 1.02381  last_update 0\n",
      "train: iter 39  trainloss 0.94671  validloss 0.93667±0.00000  bestvalidloss 0.93667  last_update 0\n",
      "train: iter 40  trainloss 0.86915  validloss 0.85425±0.00000  bestvalidloss 0.85425  last_update 0\n",
      "train: iter 41  trainloss 0.79743  validloss 0.77482±0.00000  bestvalidloss 0.77482  last_update 0\n",
      "train: iter 42  trainloss 0.72250  validloss 0.68971±0.00000  bestvalidloss 0.68971  last_update 0\n",
      "train: iter 43  trainloss 0.64909  validloss 0.60462±0.00000  bestvalidloss 0.60462  last_update 0\n",
      "train: iter 44  trainloss 0.57572  validloss 0.51952±0.00000  bestvalidloss 0.51952  last_update 0\n",
      "train: iter 45  trainloss 0.51019  validloss 0.44976±0.00000  bestvalidloss 0.44976  last_update 0\n",
      "train: iter 46  trainloss 0.44766  validloss 0.36375±0.00000  bestvalidloss 0.36375  last_update 0\n",
      "train: iter 47  trainloss 0.39137  validloss 0.31099±0.00000  bestvalidloss 0.31099  last_update 0\n",
      "train: iter 48  trainloss 0.33213  validloss 0.23628±0.00000  bestvalidloss 0.23628  last_update 0\n",
      "train: iter 49  trainloss 0.26747  validloss 0.17597±0.00000  bestvalidloss 0.17597  last_update 0\n",
      "train: iter 50  trainloss 0.22808  validloss 0.10741±0.00000  bestvalidloss 0.10741  last_update 0\n",
      "train: iter 51  trainloss 0.17221  validloss 0.03818±0.00000  bestvalidloss 0.03818  last_update 0\n",
      "train: iter 52  trainloss 0.12800  validloss -0.03077±0.00000  bestvalidloss -0.03077  last_update 0\n",
      "train: iter 53  trainloss 0.08273  validloss -0.07013±0.00000  bestvalidloss -0.07013  last_update 0\n",
      "train: iter 54  trainloss 0.02603  validloss -0.11201±0.00000  bestvalidloss -0.11201  last_update 0\n",
      "train: iter 55  trainloss -0.01196  validloss -0.18343±0.00000  bestvalidloss -0.18343  last_update 0\n",
      "train: iter 56  trainloss -0.06131  validloss -0.23935±0.00000  bestvalidloss -0.23935  last_update 0\n",
      "train: iter 57  trainloss -0.09049  validloss -0.28625±0.00000  bestvalidloss -0.28625  last_update 0\n",
      "train: iter 58  trainloss -0.12987  validloss -0.33784±0.00000  bestvalidloss -0.33784  last_update 0\n",
      "train: iter 59  trainloss -0.16282  validloss -0.37861±0.00000  bestvalidloss -0.37861  last_update 0\n",
      "train: iter 60  trainloss -0.21986  validloss -0.41224±0.00000  bestvalidloss -0.41224  last_update 0\n",
      "train: iter 61  trainloss -0.25242  validloss -0.45737±0.00000  bestvalidloss -0.45737  last_update 0\n",
      "train: iter 62  trainloss -0.26376  validloss -0.52660±0.00000  bestvalidloss -0.52660  last_update 0\n",
      "train: iter 63  trainloss -0.30667  validloss -0.53117±0.00000  bestvalidloss -0.53117  last_update 0\n",
      "train: iter 64  trainloss -0.34166  validloss -0.61287±0.00000  bestvalidloss -0.61287  last_update 0\n",
      "train: iter 65  trainloss -0.34625  validloss -0.61658±0.00000  bestvalidloss -0.61658  last_update 0\n",
      "train: iter 66  trainloss -0.38896  validloss -0.64803±0.00000  bestvalidloss -0.64803  last_update 0\n",
      "train: iter 67  trainloss -0.39947  validloss -0.67812±0.00000  bestvalidloss -0.67812  last_update 0\n",
      "train: iter 68  trainloss -0.42126  validloss -0.73157±0.00000  bestvalidloss -0.73157  last_update 0\n",
      "train: iter 69  trainloss -0.45642  validloss -0.75912±0.00000  bestvalidloss -0.75912  last_update 0\n",
      "train: iter 70  trainloss -0.49006  validloss -0.80064±0.00000  bestvalidloss -0.80064  last_update 0\n",
      "train: iter 71  trainloss -0.50495  validloss -0.81641±0.00000  bestvalidloss -0.81641  last_update 0\n",
      "train: iter 72  trainloss -0.51786  validloss -0.84986±0.00000  bestvalidloss -0.84986  last_update 0\n",
      "train: iter 73  trainloss -0.54208  validloss -0.87811±0.00000  bestvalidloss -0.87811  last_update 0\n",
      "train: iter 74  trainloss -0.56951  validloss -0.92159±0.00000  bestvalidloss -0.92159  last_update 0\n",
      "train: iter 75  trainloss -0.55700  validloss -0.94763±0.00000  bestvalidloss -0.94763  last_update 0\n",
      "train: iter 76  trainloss -0.59771  validloss -0.96323±0.00000  bestvalidloss -0.96323  last_update 0\n",
      "train: iter 77  trainloss -0.58672  validloss -1.00083±0.00000  bestvalidloss -1.00083  last_update 0\n",
      "train: iter 78  trainloss -0.59481  validloss -0.99666±0.00000  bestvalidloss -1.00083  last_update 1\n",
      "train: iter 79  trainloss -0.60400  validloss -0.99506±0.00000  bestvalidloss -1.00083  last_update 2\n",
      "train: iter 80  trainloss -0.60745  validloss -1.04509±0.00000  bestvalidloss -1.04509  last_update 0\n",
      "train: iter 81  trainloss -0.64196  validloss -1.04683±0.00000  bestvalidloss -1.04683  last_update 0\n",
      "train: iter 82  trainloss -0.63869  validloss -1.04362±0.00000  bestvalidloss -1.04683  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss -0.65844  validloss -1.09087±0.00000  bestvalidloss -1.09087  last_update 0\n",
      "train: iter 84  trainloss -0.63941  validloss -1.07189±0.00000  bestvalidloss -1.09087  last_update 1\n",
      "train: iter 85  trainloss -0.64901  validloss -1.11448±0.00000  bestvalidloss -1.11448  last_update 0\n",
      "train: iter 86  trainloss -0.65554  validloss -1.14055±0.00000  bestvalidloss -1.14055  last_update 0\n",
      "train: iter 87  trainloss -0.66118  validloss -1.10248±0.00000  bestvalidloss -1.14055  last_update 1\n",
      "train: iter 88  trainloss -0.65445  validloss -1.11846±0.00000  bestvalidloss -1.14055  last_update 2\n",
      "train: iter 89  trainloss -0.68511  validloss -1.13637±0.00000  bestvalidloss -1.14055  last_update 3\n",
      "train: iter 90  trainloss -0.67537  validloss -1.13444±0.00000  bestvalidloss -1.14055  last_update 4\n",
      "train: iter 91  trainloss -0.68107  validloss -1.17204±0.00000  bestvalidloss -1.17204  last_update 0\n",
      "train: iter 92  trainloss -0.67149  validloss -1.13607±0.00000  bestvalidloss -1.17204  last_update 1\n",
      "train: iter 93  trainloss -0.66527  validloss -1.17205±0.00000  bestvalidloss -1.17205  last_update 0\n",
      "train: iter 94  trainloss -0.66336  validloss -1.18032±0.00000  bestvalidloss -1.18032  last_update 0\n",
      "train: iter 95  trainloss -0.68021  validloss -1.16443±0.00000  bestvalidloss -1.18032  last_update 1\n",
      "train: iter 96  trainloss -0.68013  validloss -1.21019±0.00000  bestvalidloss -1.21019  last_update 0\n",
      "train: iter 97  trainloss -0.65790  validloss -1.19218±0.00000  bestvalidloss -1.21019  last_update 1\n",
      "train: iter 98  trainloss -0.69472  validloss -1.20616±0.00000  bestvalidloss -1.21019  last_update 2\n",
      "train: iter 99  trainloss -0.69574  validloss -1.21893±0.00000  bestvalidloss -1.21893  last_update 0\n",
      "train: iter 100  trainloss -0.66775  validloss -1.21492±0.00000  bestvalidloss -1.21893  last_update 1\n",
      "train: iter 101  trainloss -0.69714  validloss -1.21339±0.00000  bestvalidloss -1.21893  last_update 2\n",
      "train: iter 102  trainloss -0.67984  validloss -1.20139±0.00000  bestvalidloss -1.21893  last_update 3\n",
      "train: iter 103  trainloss -0.69085  validloss -1.19811±0.00000  bestvalidloss -1.21893  last_update 4\n",
      "train: iter 104  trainloss -0.68278  validloss -1.19428±0.00000  bestvalidloss -1.21893  last_update 5\n",
      "train: iter 105  trainloss -0.66977  validloss -1.21129±0.00000  bestvalidloss -1.21893  last_update 6\n",
      "train: iter 106  trainloss -0.67324  validloss -1.17722±0.00000  bestvalidloss -1.21893  last_update 7\n",
      "train: iter 107  trainloss -0.67872  validloss -1.21205±0.00000  bestvalidloss -1.21893  last_update 8\n",
      "train: iter 108  trainloss -0.67652  validloss -1.19994±0.00000  bestvalidloss -1.21893  last_update 9\n",
      "train: iter 109  trainloss -0.69736  validloss -1.22282±0.00000  bestvalidloss -1.22282  last_update 0\n",
      "train: iter 110  trainloss -0.67434  validloss -1.20839±0.00000  bestvalidloss -1.22282  last_update 1\n",
      "train: iter 111  trainloss -0.72183  validloss -1.19685±0.00000  bestvalidloss -1.22282  last_update 2\n",
      "train: iter 112  trainloss -0.69353  validloss -1.24150±0.00000  bestvalidloss -1.24150  last_update 0\n",
      "train: iter 113  trainloss -0.70984  validloss -1.21283±0.00000  bestvalidloss -1.24150  last_update 1\n",
      "train: iter 114  trainloss -0.69310  validloss -1.21198±0.00000  bestvalidloss -1.24150  last_update 2\n",
      "train: iter 115  trainloss -0.68036  validloss -1.21369±0.00000  bestvalidloss -1.24150  last_update 3\n",
      "train: iter 116  trainloss -0.67859  validloss -1.21833±0.00000  bestvalidloss -1.24150  last_update 4\n",
      "train: iter 117  trainloss -0.69772  validloss -1.21713±0.00000  bestvalidloss -1.24150  last_update 5\n",
      "train: iter 118  trainloss -0.68005  validloss -1.21715±0.00000  bestvalidloss -1.24150  last_update 6\n",
      "train: iter 119  trainloss -0.68983  validloss -1.27777±0.00000  bestvalidloss -1.27777  last_update 0\n",
      "train: iter 120  trainloss -0.67346  validloss -1.22051±0.00000  bestvalidloss -1.27777  last_update 1\n",
      "train: iter 121  trainloss -0.68351  validloss -1.20631±0.00000  bestvalidloss -1.27777  last_update 2\n",
      "train: iter 122  trainloss -0.68727  validloss -1.23671±0.00000  bestvalidloss -1.27777  last_update 3\n",
      "train: iter 123  trainloss -0.68944  validloss -1.24997±0.00000  bestvalidloss -1.27777  last_update 4\n",
      "train: iter 124  trainloss -0.65643  validloss -1.17149±0.00000  bestvalidloss -1.27777  last_update 5\n",
      "train: iter 125  trainloss -0.68508  validloss -1.24669±0.00000  bestvalidloss -1.27777  last_update 6\n",
      "train: iter 126  trainloss -0.66915  validloss -1.20218±0.00000  bestvalidloss -1.27777  last_update 7\n",
      "train: iter 127  trainloss -0.67874  validloss -1.22836±0.00000  bestvalidloss -1.27777  last_update 8\n",
      "train: iter 128  trainloss -0.65995  validloss -1.20630±0.00000  bestvalidloss -1.27777  last_update 9\n",
      "train: iter 129  trainloss -0.66403  validloss -1.22623±0.00000  bestvalidloss -1.27777  last_update 10\n",
      "train: iter 130  trainloss -0.67168  validloss -1.19641±0.00000  bestvalidloss -1.27777  last_update 11\n",
      "train: iter 131  trainloss -0.70574  validloss -1.23973±0.00000  bestvalidloss -1.27777  last_update 12\n",
      "train: iter 132  trainloss -0.68024  validloss -1.22741±0.00000  bestvalidloss -1.27777  last_update 13\n",
      "train: iter 133  trainloss -0.68535  validloss -1.26688±0.00000  bestvalidloss -1.27777  last_update 14\n",
      "train: iter 134  trainloss -0.67266  validloss -1.21934±0.00000  bestvalidloss -1.27777  last_update 15\n",
      "train: iter 135  trainloss -0.67693  validloss -1.22052±0.00000  bestvalidloss -1.27777  last_update 16\n",
      "train: iter 136  trainloss -0.70699  validloss -1.21463±0.00000  bestvalidloss -1.27777  last_update 17\n",
      "train: iter 137  trainloss -0.65828  validloss -1.22501±0.00000  bestvalidloss -1.27777  last_update 18\n",
      "train: iter 138  trainloss -0.70837  validloss -1.21473±0.00000  bestvalidloss -1.27777  last_update 19\n",
      "train: iter 139  trainloss -0.68002  validloss -1.21339±0.00000  bestvalidloss -1.27777  last_update 20\n",
      "train: iter 140  trainloss -0.68432  validloss -1.21313±0.00000  bestvalidloss -1.27777  last_update 21\n",
      "train: iter 141  trainloss -0.66610  validloss -1.23634±0.00000  bestvalidloss -1.27777  last_update 22\n",
      "train: iter 142  trainloss -0.64549  validloss -1.25011±0.00000  bestvalidloss -1.27777  last_update 23\n",
      "train: iter 143  trainloss -0.67736  validloss -1.22760±0.00000  bestvalidloss -1.27777  last_update 24\n",
      "train: iter 144  trainloss -0.67020  validloss -1.18656±0.00000  bestvalidloss -1.27777  last_update 25\n",
      "train: iter 145  trainloss -0.67020  validloss -1.22446±0.00000  bestvalidloss -1.27777  last_update 26\n",
      "train: iter 146  trainloss -0.67938  validloss -1.19240±0.00000  bestvalidloss -1.27777  last_update 27\n",
      "train: iter 147  trainloss -0.69088  validloss -1.25368±0.00000  bestvalidloss -1.27777  last_update 28\n",
      "train: iter 148  trainloss -0.66635  validloss -1.24628±0.00000  bestvalidloss -1.27777  last_update 29\n",
      "train: iter 149  trainloss -0.70308  validloss -1.23713±0.00000  bestvalidloss -1.27777  last_update 30\n",
      "train: iter 150  trainloss -0.68735  validloss -1.21243±0.00000  bestvalidloss -1.27777  last_update 31\n",
      "train: iter 151  trainloss -0.70341  validloss -1.21687±0.00000  bestvalidloss -1.27777  last_update 32\n",
      "train: iter 152  trainloss -0.71370  validloss -1.16720±0.00000  bestvalidloss -1.27777  last_update 33\n",
      "train: iter 153  trainloss -0.67785  validloss -1.26565±0.00000  bestvalidloss -1.27777  last_update 34\n",
      "train: iter 154  trainloss -0.66335  validloss -1.24678±0.00000  bestvalidloss -1.27777  last_update 35\n",
      "train: iter 155  trainloss -0.67918  validloss -1.24810±0.00000  bestvalidloss -1.27777  last_update 36\n",
      "train: iter 156  trainloss -0.66303  validloss -1.20518±0.00000  bestvalidloss -1.27777  last_update 37\n",
      "train: iter 157  trainloss -0.67365  validloss -1.24844±0.00000  bestvalidloss -1.27777  last_update 38\n",
      "train: iter 158  trainloss -0.71048  validloss -1.23573±0.00000  bestvalidloss -1.27777  last_update 39\n",
      "train: iter 159  trainloss -0.69065  validloss -1.22050±0.00000  bestvalidloss -1.27777  last_update 40\n",
      "train: iter 160  trainloss -0.71557  validloss -1.24953±0.00000  bestvalidloss -1.27777  last_update 41\n",
      "train: iter 161  trainloss -0.68762  validloss -1.25753±0.00000  bestvalidloss -1.27777  last_update 42\n",
      "train: iter 162  trainloss -0.69354  validloss -1.25642±0.00000  bestvalidloss -1.27777  last_update 43\n",
      "train: iter 163  trainloss -0.66644  validloss -1.22615±0.00000  bestvalidloss -1.27777  last_update 44\n",
      "train: iter 164  trainloss -0.67781  validloss -1.23261±0.00000  bestvalidloss -1.27777  last_update 45\n",
      "train: iter 165  trainloss -0.70567  validloss -1.23186±0.00000  bestvalidloss -1.27777  last_update 46\n",
      "train: iter 166  trainloss -0.65558  validloss -1.19325±0.00000  bestvalidloss -1.27777  last_update 47\n",
      "train: iter 167  trainloss -0.70951  validloss -1.21924±0.00000  bestvalidloss -1.27777  last_update 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss -0.69583  validloss -1.25002±0.00000  bestvalidloss -1.27777  last_update 49\n",
      "train: iter 169  trainloss -0.68534  validloss -1.21312±0.00000  bestvalidloss -1.27777  last_update 50\n",
      "train: iter 170  trainloss -0.66222  validloss -1.18424±0.00000  bestvalidloss -1.27777  last_update 51\n",
      "train: iter 171  trainloss -0.67203  validloss -1.22251±0.00000  bestvalidloss -1.27777  last_update 52\n",
      "train: iter 172  trainloss -0.68721  validloss -1.23821±0.00000  bestvalidloss -1.27777  last_update 53\n",
      "train: iter 173  trainloss -0.67859  validloss -1.23796±0.00000  bestvalidloss -1.27777  last_update 54\n",
      "train: iter 174  trainloss -0.66330  validloss -1.23103±0.00000  bestvalidloss -1.27777  last_update 55\n",
      "train: iter 175  trainloss -0.65644  validloss -1.21617±0.00000  bestvalidloss -1.27777  last_update 56\n",
      "train: iter 176  trainloss -0.70296  validloss -1.22424±0.00000  bestvalidloss -1.27777  last_update 57\n",
      "train: iter 177  trainloss -0.68932  validloss -1.23622±0.00000  bestvalidloss -1.27777  last_update 58\n",
      "train: iter 178  trainloss -0.65037  validloss -1.22487±0.00000  bestvalidloss -1.27777  last_update 59\n",
      "train: iter 179  trainloss -0.69342  validloss -1.23412±0.00000  bestvalidloss -1.27777  last_update 60\n",
      "train: iter 180  trainloss -0.67386  validloss -1.24132±0.00000  bestvalidloss -1.27777  last_update 61\n",
      "train: iter 181  trainloss -0.67380  validloss -1.21036±0.00000  bestvalidloss -1.27777  last_update 62\n",
      "train: iter 182  trainloss -0.69732  validloss -1.21505±0.00000  bestvalidloss -1.27777  last_update 63\n",
      "train: iter 183  trainloss -0.67883  validloss -1.24862±0.00000  bestvalidloss -1.27777  last_update 64\n",
      "train: iter 184  trainloss -0.69759  validloss -1.23061±0.00000  bestvalidloss -1.27777  last_update 65\n",
      "train: iter 185  trainloss -0.67150  validloss -1.23053±0.00000  bestvalidloss -1.27777  last_update 66\n",
      "train: iter 186  trainloss -0.69985  validloss -1.26500±0.00000  bestvalidloss -1.27777  last_update 67\n",
      "train: iter 187  trainloss -0.68281  validloss -1.24627±0.00000  bestvalidloss -1.27777  last_update 68\n",
      "train: iter 188  trainloss -0.69271  validloss -1.26200±0.00000  bestvalidloss -1.27777  last_update 69\n",
      "train: iter 189  trainloss -0.70012  validloss -1.24158±0.00000  bestvalidloss -1.27777  last_update 70\n",
      "train: iter 190  trainloss -0.69491  validloss -1.21441±0.00000  bestvalidloss -1.27777  last_update 71\n",
      "train: iter 191  trainloss -0.71698  validloss -1.20629±0.00000  bestvalidloss -1.27777  last_update 72\n",
      "train: iter 192  trainloss -0.68680  validloss -1.24698±0.00000  bestvalidloss -1.27777  last_update 73\n",
      "train: iter 193  trainloss -0.66106  validloss -1.26412±0.00000  bestvalidloss -1.27777  last_update 74\n",
      "train: iter 194  trainloss -0.69396  validloss -1.23857±0.00000  bestvalidloss -1.27777  last_update 75\n",
      "train: iter 195  trainloss -0.69393  validloss -1.25243±0.00000  bestvalidloss -1.27777  last_update 76\n",
      "train: iter 196  trainloss -0.65848  validloss -1.24037±0.00000  bestvalidloss -1.27777  last_update 77\n",
      "train: iter 197  trainloss -0.67493  validloss -1.25717±0.00000  bestvalidloss -1.27777  last_update 78\n",
      "train: iter 198  trainloss -0.67915  validloss -1.22052±0.00000  bestvalidloss -1.27777  last_update 79\n",
      "train: iter 199  trainloss -0.69042  validloss -1.16883±0.00000  bestvalidloss -1.27777  last_update 80\n",
      "train: iter 200  trainloss -0.66679  validloss -1.24292±0.00000  bestvalidloss -1.27777  last_update 81\n",
      "train: iter 201  trainloss -0.68210  validloss -1.26192±0.00000  bestvalidloss -1.27777  last_update 82\n",
      "train: iter 202  trainloss -0.69097  validloss -1.25609±0.00000  bestvalidloss -1.27777  last_update 83\n",
      "train: iter 203  trainloss -0.65778  validloss -1.23450±0.00000  bestvalidloss -1.27777  last_update 84\n",
      "train: iter 204  trainloss -0.70486  validloss -1.22759±0.00000  bestvalidloss -1.27777  last_update 85\n",
      "train: iter 205  trainloss -0.68253  validloss -1.23665±0.00000  bestvalidloss -1.27777  last_update 86\n",
      "train: iter 206  trainloss -0.68369  validloss -1.23065±0.00000  bestvalidloss -1.27777  last_update 87\n",
      "train: iter 207  trainloss -0.68145  validloss -1.25725±0.00000  bestvalidloss -1.27777  last_update 88\n",
      "train: iter 208  trainloss -0.68787  validloss -1.23899±0.00000  bestvalidloss -1.27777  last_update 89\n",
      "train: iter 209  trainloss -0.64703  validloss -1.21006±0.00000  bestvalidloss -1.27777  last_update 90\n",
      "train: iter 210  trainloss -0.71380  validloss -1.19653±0.00000  bestvalidloss -1.27777  last_update 91\n",
      "train: iter 211  trainloss -0.67670  validloss -1.28247±0.00000  bestvalidloss -1.28247  last_update 0\n",
      "train: iter 212  trainloss -0.68021  validloss -1.24597±0.00000  bestvalidloss -1.28247  last_update 1\n",
      "train: iter 213  trainloss -0.67608  validloss -1.22377±0.00000  bestvalidloss -1.28247  last_update 2\n",
      "train: iter 214  trainloss -0.70503  validloss -1.22465±0.00000  bestvalidloss -1.28247  last_update 3\n",
      "train: iter 215  trainloss -0.70229  validloss -1.22763±0.00000  bestvalidloss -1.28247  last_update 4\n",
      "train: iter 216  trainloss -0.68020  validloss -1.19513±0.00000  bestvalidloss -1.28247  last_update 5\n",
      "train: iter 217  trainloss -0.69092  validloss -1.25395±0.00000  bestvalidloss -1.28247  last_update 6\n",
      "train: iter 218  trainloss -0.67264  validloss -1.18997±0.00000  bestvalidloss -1.28247  last_update 7\n",
      "train: iter 219  trainloss -0.67215  validloss -1.26834±0.00000  bestvalidloss -1.28247  last_update 8\n",
      "train: iter 220  trainloss -0.69018  validloss -1.26852±0.00000  bestvalidloss -1.28247  last_update 9\n",
      "train: iter 221  trainloss -0.69951  validloss -1.21742±0.00000  bestvalidloss -1.28247  last_update 10\n",
      "train: iter 222  trainloss -0.67368  validloss -1.26718±0.00000  bestvalidloss -1.28247  last_update 11\n",
      "train: iter 223  trainloss -0.69348  validloss -1.24301±0.00000  bestvalidloss -1.28247  last_update 12\n",
      "train: iter 224  trainloss -0.67488  validloss -1.24102±0.00000  bestvalidloss -1.28247  last_update 13\n",
      "train: iter 225  trainloss -0.66145  validloss -1.23278±0.00000  bestvalidloss -1.28247  last_update 14\n",
      "train: iter 226  trainloss -0.68350  validloss -1.22823±0.00000  bestvalidloss -1.28247  last_update 15\n",
      "train: iter 227  trainloss -0.69247  validloss -1.25756±0.00000  bestvalidloss -1.28247  last_update 16\n",
      "train: iter 228  trainloss -0.69506  validloss -1.23740±0.00000  bestvalidloss -1.28247  last_update 17\n",
      "train: iter 229  trainloss -0.65700  validloss -1.19880±0.00000  bestvalidloss -1.28247  last_update 18\n",
      "train: iter 230  trainloss -0.69872  validloss -1.19210±0.00000  bestvalidloss -1.28247  last_update 19\n",
      "train: iter 231  trainloss -0.66224  validloss -1.22254±0.00000  bestvalidloss -1.28247  last_update 20\n",
      "train: iter 232  trainloss -0.69224  validloss -1.25845±0.00000  bestvalidloss -1.28247  last_update 21\n",
      "train: iter 233  trainloss -0.70613  validloss -1.24568±0.00000  bestvalidloss -1.28247  last_update 22\n",
      "train: iter 234  trainloss -0.68293  validloss -1.24752±0.00000  bestvalidloss -1.28247  last_update 23\n",
      "train: iter 235  trainloss -0.69296  validloss -1.25692±0.00000  bestvalidloss -1.28247  last_update 24\n",
      "train: iter 236  trainloss -0.67706  validloss -1.20159±0.00000  bestvalidloss -1.28247  last_update 25\n",
      "train: iter 237  trainloss -0.69665  validloss -1.21966±0.00000  bestvalidloss -1.28247  last_update 26\n",
      "train: iter 238  trainloss -0.69980  validloss -1.21072±0.00000  bestvalidloss -1.28247  last_update 27\n",
      "train: iter 239  trainloss -0.67919  validloss -1.20547±0.00000  bestvalidloss -1.28247  last_update 28\n",
      "train: iter 240  trainloss -0.68741  validloss -1.22460±0.00000  bestvalidloss -1.28247  last_update 29\n",
      "train: iter 241  trainloss -0.68516  validloss -1.25573±0.00000  bestvalidloss -1.28247  last_update 30\n",
      "train: iter 242  trainloss -0.70507  validloss -1.26450±0.00000  bestvalidloss -1.28247  last_update 31\n",
      "train: iter 243  trainloss -0.69454  validloss -1.25410±0.00000  bestvalidloss -1.28247  last_update 32\n",
      "train: iter 244  trainloss -0.66271  validloss -1.22872±0.00000  bestvalidloss -1.28247  last_update 33\n",
      "train: iter 245  trainloss -0.65431  validloss -1.24276±0.00000  bestvalidloss -1.28247  last_update 34\n",
      "train: iter 246  trainloss -0.68879  validloss -1.20951±0.00000  bestvalidloss -1.28247  last_update 35\n",
      "train: iter 247  trainloss -0.69089  validloss -1.22146±0.00000  bestvalidloss -1.28247  last_update 36\n",
      "train: iter 248  trainloss -0.68354  validloss -1.22333±0.00000  bestvalidloss -1.28247  last_update 37\n",
      "train: iter 249  trainloss -0.67866  validloss -1.23447±0.00000  bestvalidloss -1.28247  last_update 38\n",
      "train: iter 250  trainloss -0.67800  validloss -1.23215±0.00000  bestvalidloss -1.28247  last_update 39\n",
      "train: iter 251  trainloss -0.66263  validloss -1.25024±0.00000  bestvalidloss -1.28247  last_update 40\n",
      "train: iter 252  trainloss -0.67990  validloss -1.23439±0.00000  bestvalidloss -1.28247  last_update 41\n",
      "train: iter 253  trainloss -0.66558  validloss -1.22493±0.00000  bestvalidloss -1.28247  last_update 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 254  trainloss -0.71584  validloss -1.21116±0.00000  bestvalidloss -1.28247  last_update 43\n",
      "train: iter 255  trainloss -0.67758  validloss -1.23285±0.00000  bestvalidloss -1.28247  last_update 44\n",
      "train: iter 256  trainloss -0.67615  validloss -1.21546±0.00000  bestvalidloss -1.28247  last_update 45\n",
      "train: iter 257  trainloss -0.69718  validloss -1.24808±0.00000  bestvalidloss -1.28247  last_update 46\n",
      "train: iter 258  trainloss -0.65616  validloss -1.23088±0.00000  bestvalidloss -1.28247  last_update 47\n",
      "train: iter 259  trainloss -0.69827  validloss -1.17728±0.00000  bestvalidloss -1.28247  last_update 48\n",
      "train: iter 260  trainloss -0.69997  validloss -1.25267±0.00000  bestvalidloss -1.28247  last_update 49\n",
      "train: iter 261  trainloss -0.67613  validloss -1.22893±0.00000  bestvalidloss -1.28247  last_update 50\n",
      "train: iter 262  trainloss -0.68467  validloss -1.23012±0.00000  bestvalidloss -1.28247  last_update 51\n",
      "train: iter 263  trainloss -0.66668  validloss -1.24613±0.00000  bestvalidloss -1.28247  last_update 52\n",
      "train: iter 264  trainloss -0.72059  validloss -1.22611±0.00000  bestvalidloss -1.28247  last_update 53\n",
      "train: iter 265  trainloss -0.69656  validloss -1.19123±0.00000  bestvalidloss -1.28247  last_update 54\n",
      "train: iter 266  trainloss -0.70576  validloss -1.25820±0.00000  bestvalidloss -1.28247  last_update 55\n",
      "train: iter 267  trainloss -0.66206  validloss -1.24178±0.00000  bestvalidloss -1.28247  last_update 56\n",
      "train: iter 268  trainloss -0.66389  validloss -1.23926±0.00000  bestvalidloss -1.28247  last_update 57\n",
      "train: iter 269  trainloss -0.66411  validloss -1.24275±0.00000  bestvalidloss -1.28247  last_update 58\n",
      "train: iter 270  trainloss -0.67525  validloss -1.25947±0.00000  bestvalidloss -1.28247  last_update 59\n",
      "train: iter 271  trainloss -0.65849  validloss -1.27322±0.00000  bestvalidloss -1.28247  last_update 60\n",
      "train: iter 272  trainloss -0.65450  validloss -1.23314±0.00000  bestvalidloss -1.28247  last_update 61\n",
      "train: iter 273  trainloss -0.66881  validloss -1.23533±0.00000  bestvalidloss -1.28247  last_update 62\n",
      "train: iter 274  trainloss -0.71508  validloss -1.24165±0.00000  bestvalidloss -1.28247  last_update 63\n",
      "train: iter 275  trainloss -0.67825  validloss -1.24006±0.00000  bestvalidloss -1.28247  last_update 64\n",
      "train: iter 276  trainloss -0.67883  validloss -1.22704±0.00000  bestvalidloss -1.28247  last_update 65\n",
      "train: iter 277  trainloss -0.68167  validloss -1.17297±0.00000  bestvalidloss -1.28247  last_update 66\n",
      "train: iter 278  trainloss -0.69229  validloss -1.21801±0.00000  bestvalidloss -1.28247  last_update 67\n",
      "train: iter 279  trainloss -0.68166  validloss -1.26235±0.00000  bestvalidloss -1.28247  last_update 68\n",
      "train: iter 280  trainloss -0.69886  validloss -1.22594±0.00000  bestvalidloss -1.28247  last_update 69\n",
      "train: iter 281  trainloss -0.68096  validloss -1.22713±0.00000  bestvalidloss -1.28247  last_update 70\n",
      "train: iter 282  trainloss -0.70269  validloss -1.23873±0.00000  bestvalidloss -1.28247  last_update 71\n",
      "train: iter 283  trainloss -0.71857  validloss -1.21336±0.00000  bestvalidloss -1.28247  last_update 72\n",
      "train: iter 284  trainloss -0.69400  validloss -1.25012±0.00000  bestvalidloss -1.28247  last_update 73\n",
      "train: iter 285  trainloss -0.66156  validloss -1.24657±0.00000  bestvalidloss -1.28247  last_update 74\n",
      "train: iter 286  trainloss -0.68655  validloss -1.21784±0.00000  bestvalidloss -1.28247  last_update 75\n",
      "train: iter 287  trainloss -0.66590  validloss -1.21055±0.00000  bestvalidloss -1.28247  last_update 76\n",
      "train: iter 288  trainloss -0.66423  validloss -1.24182±0.00000  bestvalidloss -1.28247  last_update 77\n",
      "train: iter 289  trainloss -0.71394  validloss -1.25481±0.00000  bestvalidloss -1.28247  last_update 78\n",
      "train: iter 290  trainloss -0.64698  validloss -1.26552±0.00000  bestvalidloss -1.28247  last_update 79\n",
      "train: iter 291  trainloss -0.69401  validloss -1.24819±0.00000  bestvalidloss -1.28247  last_update 80\n",
      "train: iter 292  trainloss -0.65208  validloss -1.19192±0.00000  bestvalidloss -1.28247  last_update 81\n",
      "train: iter 293  trainloss -0.69076  validloss -1.26511±0.00000  bestvalidloss -1.28247  last_update 82\n",
      "train: iter 294  trainloss -0.68439  validloss -1.25880±0.00000  bestvalidloss -1.28247  last_update 83\n",
      "train: iter 295  trainloss -0.68015  validloss -1.22571±0.00000  bestvalidloss -1.28247  last_update 84\n",
      "train: iter 296  trainloss -0.68402  validloss -1.24980±0.00000  bestvalidloss -1.28247  last_update 85\n",
      "train: iter 297  trainloss -0.70592  validloss -1.19001±0.00000  bestvalidloss -1.28247  last_update 86\n",
      "train: iter 298  trainloss -0.66841  validloss -1.21318±0.00000  bestvalidloss -1.28247  last_update 87\n",
      "train: iter 299  trainloss -0.68141  validloss -1.19992±0.00000  bestvalidloss -1.28247  last_update 88\n",
      "train: iter 300  trainloss -0.66853  validloss -1.24771±0.00000  bestvalidloss -1.28247  last_update 89\n",
      "train: iter 301  trainloss -0.71697  validloss -1.22605±0.00000  bestvalidloss -1.28247  last_update 90\n",
      "train: iter 302  trainloss -0.67607  validloss -1.23457±0.00000  bestvalidloss -1.28247  last_update 91\n",
      "train: iter 303  trainloss -0.65972  validloss -1.25602±0.00000  bestvalidloss -1.28247  last_update 92\n",
      "train: iter 304  trainloss -0.67878  validloss -1.22565±0.00000  bestvalidloss -1.28247  last_update 93\n",
      "train: iter 305  trainloss -0.69348  validloss -1.21792±0.00000  bestvalidloss -1.28247  last_update 94\n",
      "train: iter 306  trainloss -0.66717  validloss -1.24661±0.00000  bestvalidloss -1.28247  last_update 95\n",
      "train: iter 307  trainloss -0.68747  validloss -1.26951±0.00000  bestvalidloss -1.28247  last_update 96\n",
      "train: iter 308  trainloss -0.66671  validloss -1.25961±0.00000  bestvalidloss -1.28247  last_update 97\n",
      "train: iter 309  trainloss -0.69390  validloss -1.24987±0.00000  bestvalidloss -1.28247  last_update 98\n",
      "train: iter 310  trainloss -0.69412  validloss -1.28301±0.00000  bestvalidloss -1.28301  last_update 0\n",
      "train: iter 311  trainloss -0.68905  validloss -1.21685±0.00000  bestvalidloss -1.28301  last_update 1\n",
      "train: iter 312  trainloss -0.66359  validloss -1.25325±0.00000  bestvalidloss -1.28301  last_update 2\n",
      "train: iter 313  trainloss -0.65505  validloss -1.24572±0.00000  bestvalidloss -1.28301  last_update 3\n",
      "train: iter 314  trainloss -0.69784  validloss -1.22569±0.00000  bestvalidloss -1.28301  last_update 4\n",
      "train: iter 315  trainloss -0.66477  validloss -1.22722±0.00000  bestvalidloss -1.28301  last_update 5\n",
      "train: iter 316  trainloss -0.67613  validloss -1.26987±0.00000  bestvalidloss -1.28301  last_update 6\n",
      "train: iter 317  trainloss -0.69850  validloss -1.20247±0.00000  bestvalidloss -1.28301  last_update 7\n",
      "train: iter 318  trainloss -0.67062  validloss -1.25631±0.00000  bestvalidloss -1.28301  last_update 8\n",
      "train: iter 319  trainloss -0.70508  validloss -1.21011±0.00000  bestvalidloss -1.28301  last_update 9\n",
      "train: iter 320  trainloss -0.67262  validloss -1.19207±0.00000  bestvalidloss -1.28301  last_update 10\n",
      "train: iter 321  trainloss -0.67849  validloss -1.24637±0.00000  bestvalidloss -1.28301  last_update 11\n",
      "train: iter 322  trainloss -0.68691  validloss -1.25945±0.00000  bestvalidloss -1.28301  last_update 12\n",
      "train: iter 323  trainloss -0.68172  validloss -1.24098±0.00000  bestvalidloss -1.28301  last_update 13\n",
      "train: iter 324  trainloss -0.71195  validloss -1.26107±0.00000  bestvalidloss -1.28301  last_update 14\n",
      "train: iter 325  trainloss -0.68752  validloss -1.25621±0.00000  bestvalidloss -1.28301  last_update 15\n",
      "train: iter 326  trainloss -0.67266  validloss -1.25297±0.00000  bestvalidloss -1.28301  last_update 16\n",
      "train: iter 327  trainloss -0.69731  validloss -1.25851±0.00000  bestvalidloss -1.28301  last_update 17\n",
      "train: iter 328  trainloss -0.68392  validloss -1.25803±0.00000  bestvalidloss -1.28301  last_update 18\n",
      "train: iter 329  trainloss -0.69535  validloss -1.24565±0.00000  bestvalidloss -1.28301  last_update 19\n",
      "train: iter 330  trainloss -0.67829  validloss -1.23428±0.00000  bestvalidloss -1.28301  last_update 20\n",
      "train: iter 331  trainloss -0.71718  validloss -1.25658±0.00000  bestvalidloss -1.28301  last_update 21\n",
      "train: iter 332  trainloss -0.69307  validloss -1.23169±0.00000  bestvalidloss -1.28301  last_update 22\n",
      "train: iter 333  trainloss -0.67985  validloss -1.21127±0.00000  bestvalidloss -1.28301  last_update 23\n",
      "train: iter 334  trainloss -0.69431  validloss -1.25413±0.00000  bestvalidloss -1.28301  last_update 24\n",
      "train: iter 335  trainloss -0.67078  validloss -1.27336±0.00000  bestvalidloss -1.28301  last_update 25\n",
      "train: iter 336  trainloss -0.70711  validloss -1.24775±0.00000  bestvalidloss -1.28301  last_update 26\n",
      "train: iter 337  trainloss -0.67800  validloss -1.25299±0.00000  bestvalidloss -1.28301  last_update 27\n",
      "train: iter 338  trainloss -0.67427  validloss -1.20648±0.00000  bestvalidloss -1.28301  last_update 28\n",
      "train: iter 339  trainloss -0.68832  validloss -1.21377±0.00000  bestvalidloss -1.28301  last_update 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 340  trainloss -0.68963  validloss -1.23133±0.00000  bestvalidloss -1.28301  last_update 30\n",
      "train: iter 341  trainloss -0.67932  validloss -1.25521±0.00000  bestvalidloss -1.28301  last_update 31\n",
      "train: iter 342  trainloss -0.65709  validloss -1.26665±0.00000  bestvalidloss -1.28301  last_update 32\n",
      "train: iter 343  trainloss -0.70856  validloss -1.24307±0.00000  bestvalidloss -1.28301  last_update 33\n",
      "train: iter 344  trainloss -0.67645  validloss -1.23770±0.00000  bestvalidloss -1.28301  last_update 34\n",
      "train: iter 345  trainloss -0.65680  validloss -1.25384±0.00000  bestvalidloss -1.28301  last_update 35\n",
      "train: iter 346  trainloss -0.69790  validloss -1.24324±0.00000  bestvalidloss -1.28301  last_update 36\n",
      "train: iter 347  trainloss -0.66056  validloss -1.23094±0.00000  bestvalidloss -1.28301  last_update 37\n",
      "train: iter 348  trainloss -0.69209  validloss -1.21145±0.00000  bestvalidloss -1.28301  last_update 38\n",
      "train: iter 349  trainloss -0.70599  validloss -1.23029±0.00000  bestvalidloss -1.28301  last_update 39\n",
      "train: iter 350  trainloss -0.72476  validloss -1.23291±0.00000  bestvalidloss -1.28301  last_update 40\n",
      "train: iter 351  trainloss -0.71153  validloss -1.24252±0.00000  bestvalidloss -1.28301  last_update 41\n",
      "train: iter 352  trainloss -0.68023  validloss -1.20658±0.00000  bestvalidloss -1.28301  last_update 42\n",
      "train: iter 353  trainloss -0.66868  validloss -1.25452±0.00000  bestvalidloss -1.28301  last_update 43\n",
      "train: iter 354  trainloss -0.67060  validloss -1.27016±0.00000  bestvalidloss -1.28301  last_update 44\n",
      "train: iter 355  trainloss -0.68347  validloss -1.23296±0.00000  bestvalidloss -1.28301  last_update 45\n",
      "train: iter 356  trainloss -0.69251  validloss -1.26494±0.00000  bestvalidloss -1.28301  last_update 46\n",
      "train: iter 357  trainloss -0.68567  validloss -1.24659±0.00000  bestvalidloss -1.28301  last_update 47\n",
      "train: iter 358  trainloss -0.67580  validloss -1.27913±0.00000  bestvalidloss -1.28301  last_update 48\n",
      "train: iter 359  trainloss -0.65129  validloss -1.20447±0.00000  bestvalidloss -1.28301  last_update 49\n",
      "train: iter 360  trainloss -0.71708  validloss -1.23297±0.00000  bestvalidloss -1.28301  last_update 50\n",
      "train: iter 361  trainloss -0.70662  validloss -1.28493±0.00000  bestvalidloss -1.28493  last_update 0\n",
      "train: iter 362  trainloss -0.69284  validloss -1.25890±0.00000  bestvalidloss -1.28493  last_update 1\n",
      "train: iter 363  trainloss -0.70804  validloss -1.19333±0.00000  bestvalidloss -1.28493  last_update 2\n",
      "train: iter 364  trainloss -0.66091  validloss -1.24020±0.00000  bestvalidloss -1.28493  last_update 3\n",
      "train: iter 365  trainloss -0.70357  validloss -1.26066±0.00000  bestvalidloss -1.28493  last_update 4\n",
      "train: iter 366  trainloss -0.68538  validloss -1.26040±0.00000  bestvalidloss -1.28493  last_update 5\n",
      "train: iter 367  trainloss -0.69841  validloss -1.22733±0.00000  bestvalidloss -1.28493  last_update 6\n",
      "train: iter 368  trainloss -0.69199  validloss -1.22635±0.00000  bestvalidloss -1.28493  last_update 7\n",
      "train: iter 369  trainloss -0.69654  validloss -1.22462±0.00000  bestvalidloss -1.28493  last_update 8\n",
      "train: iter 370  trainloss -0.65324  validloss -1.23532±0.00000  bestvalidloss -1.28493  last_update 9\n",
      "train: iter 371  trainloss -0.71286  validloss -1.26923±0.00000  bestvalidloss -1.28493  last_update 10\n",
      "train: iter 372  trainloss -0.68110  validloss -1.29265±0.00000  bestvalidloss -1.29265  last_update 0\n",
      "train: iter 373  trainloss -0.69372  validloss -1.25851±0.00000  bestvalidloss -1.29265  last_update 1\n",
      "train: iter 374  trainloss -0.69630  validloss -1.26307±0.00000  bestvalidloss -1.29265  last_update 2\n",
      "train: iter 375  trainloss -0.66983  validloss -1.23636±0.00000  bestvalidloss -1.29265  last_update 3\n",
      "train: iter 376  trainloss -0.64886  validloss -1.26890±0.00000  bestvalidloss -1.29265  last_update 4\n",
      "train: iter 377  trainloss -0.70859  validloss -1.23891±0.00000  bestvalidloss -1.29265  last_update 5\n",
      "train: iter 378  trainloss -0.68508  validloss -1.20303±0.00000  bestvalidloss -1.29265  last_update 6\n",
      "train: iter 379  trainloss -0.67754  validloss -1.24586±0.00000  bestvalidloss -1.29265  last_update 7\n",
      "train: iter 380  trainloss -0.64486  validloss -1.26022±0.00000  bestvalidloss -1.29265  last_update 8\n",
      "train: iter 381  trainloss -0.67071  validloss -1.27963±0.00000  bestvalidloss -1.29265  last_update 9\n",
      "train: iter 382  trainloss -0.69613  validloss -1.23186±0.00000  bestvalidloss -1.29265  last_update 10\n",
      "train: iter 383  trainloss -0.66874  validloss -1.20864±0.00000  bestvalidloss -1.29265  last_update 11\n",
      "train: iter 384  trainloss -0.65999  validloss -1.22238±0.00000  bestvalidloss -1.29265  last_update 12\n",
      "train: iter 385  trainloss -0.69512  validloss -1.24957±0.00000  bestvalidloss -1.29265  last_update 13\n",
      "train: iter 386  trainloss -0.67167  validloss -1.24674±0.00000  bestvalidloss -1.29265  last_update 14\n",
      "train: iter 387  trainloss -0.67021  validloss -1.24882±0.00000  bestvalidloss -1.29265  last_update 15\n",
      "train: iter 388  trainloss -0.68206  validloss -1.23339±0.00000  bestvalidloss -1.29265  last_update 16\n",
      "train: iter 389  trainloss -0.66926  validloss -1.25714±0.00000  bestvalidloss -1.29265  last_update 17\n",
      "train: iter 390  trainloss -0.67484  validloss -1.20195±0.00000  bestvalidloss -1.29265  last_update 18\n",
      "train: iter 391  trainloss -0.68559  validloss -1.24110±0.00000  bestvalidloss -1.29265  last_update 19\n",
      "train: iter 392  trainloss -0.67385  validloss -1.18541±0.00000  bestvalidloss -1.29265  last_update 20\n",
      "train: iter 393  trainloss -0.67066  validloss -1.23271±0.00000  bestvalidloss -1.29265  last_update 21\n",
      "train: iter 394  trainloss -0.67392  validloss -1.24051±0.00000  bestvalidloss -1.29265  last_update 22\n",
      "train: iter 395  trainloss -0.66039  validloss -1.23437±0.00000  bestvalidloss -1.29265  last_update 23\n",
      "train: iter 396  trainloss -0.70173  validloss -1.21593±0.00000  bestvalidloss -1.29265  last_update 24\n",
      "train: iter 397  trainloss -0.64862  validloss -1.22823±0.00000  bestvalidloss -1.29265  last_update 25\n",
      "train: iter 398  trainloss -0.69799  validloss -1.21192±0.00000  bestvalidloss -1.29265  last_update 26\n",
      "train: iter 399  trainloss -0.70222  validloss -1.23603±0.00000  bestvalidloss -1.29265  last_update 27\n",
      "train: iter 400  trainloss -0.69450  validloss -1.22469±0.00000  bestvalidloss -1.29265  last_update 28\n",
      "train: iter 401  trainloss -0.69023  validloss -1.24097±0.00000  bestvalidloss -1.29265  last_update 29\n",
      "train: iter 402  trainloss -0.66424  validloss -1.24159±0.00000  bestvalidloss -1.29265  last_update 30\n",
      "train: iter 403  trainloss -0.67055  validloss -1.22720±0.00000  bestvalidloss -1.29265  last_update 31\n",
      "train: iter 404  trainloss -0.68668  validloss -1.22768±0.00000  bestvalidloss -1.29265  last_update 32\n",
      "train: iter 405  trainloss -0.71188  validloss -1.26484±0.00000  bestvalidloss -1.29265  last_update 33\n",
      "train: iter 406  trainloss -0.70112  validloss -1.19713±0.00000  bestvalidloss -1.29265  last_update 34\n",
      "train: iter 407  trainloss -0.68351  validloss -1.21724±0.00000  bestvalidloss -1.29265  last_update 35\n",
      "train: iter 408  trainloss -0.66192  validloss -1.23612±0.00000  bestvalidloss -1.29265  last_update 36\n",
      "train: iter 409  trainloss -0.72053  validloss -1.25400±0.00000  bestvalidloss -1.29265  last_update 37\n",
      "train: iter 410  trainloss -0.68307  validloss -1.25051±0.00000  bestvalidloss -1.29265  last_update 38\n",
      "train: iter 411  trainloss -0.68215  validloss -1.22875±0.00000  bestvalidloss -1.29265  last_update 39\n",
      "train: iter 412  trainloss -0.71061  validloss -1.23609±0.00000  bestvalidloss -1.29265  last_update 40\n",
      "train: iter 413  trainloss -0.69417  validloss -1.25183±0.00000  bestvalidloss -1.29265  last_update 41\n",
      "train: iter 414  trainloss -0.69401  validloss -1.22334±0.00000  bestvalidloss -1.29265  last_update 42\n",
      "train: iter 415  trainloss -0.68772  validloss -1.23753±0.00000  bestvalidloss -1.29265  last_update 43\n",
      "train: iter 416  trainloss -0.68939  validloss -1.22536±0.00000  bestvalidloss -1.29265  last_update 44\n",
      "train: iter 417  trainloss -0.68058  validloss -1.22018±0.00000  bestvalidloss -1.29265  last_update 45\n",
      "train: iter 418  trainloss -0.67385  validloss -1.22006±0.00000  bestvalidloss -1.29265  last_update 46\n",
      "train: iter 419  trainloss -0.66630  validloss -1.25464±0.00000  bestvalidloss -1.29265  last_update 47\n",
      "train: iter 420  trainloss -0.66576  validloss -1.20187±0.00000  bestvalidloss -1.29265  last_update 48\n",
      "train: iter 421  trainloss -0.67696  validloss -1.24287±0.00000  bestvalidloss -1.29265  last_update 49\n",
      "train: iter 422  trainloss -0.68818  validloss -1.23166±0.00000  bestvalidloss -1.29265  last_update 50\n",
      "train: iter 423  trainloss -0.68483  validloss -1.24930±0.00000  bestvalidloss -1.29265  last_update 51\n",
      "train: iter 424  trainloss -0.71368  validloss -1.21942±0.00000  bestvalidloss -1.29265  last_update 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 425  trainloss -0.69674  validloss -1.25576±0.00000  bestvalidloss -1.29265  last_update 53\n",
      "train: iter 426  trainloss -0.65571  validloss -1.25477±0.00000  bestvalidloss -1.29265  last_update 54\n",
      "train: iter 427  trainloss -0.71213  validloss -1.22783±0.00000  bestvalidloss -1.29265  last_update 55\n",
      "train: iter 428  trainloss -0.66081  validloss -1.26211±0.00000  bestvalidloss -1.29265  last_update 56\n",
      "train: iter 429  trainloss -0.67645  validloss -1.24845±0.00000  bestvalidloss -1.29265  last_update 57\n",
      "train: iter 430  trainloss -0.68188  validloss -1.24652±0.00000  bestvalidloss -1.29265  last_update 58\n",
      "train: iter 431  trainloss -0.66861  validloss -1.22117±0.00000  bestvalidloss -1.29265  last_update 59\n",
      "train: iter 432  trainloss -0.67948  validloss -1.23655±0.00000  bestvalidloss -1.29265  last_update 60\n",
      "train: iter 433  trainloss -0.65687  validloss -1.23246±0.00000  bestvalidloss -1.29265  last_update 61\n",
      "train: iter 434  trainloss -0.67391  validloss -1.25827±0.00000  bestvalidloss -1.29265  last_update 62\n",
      "train: iter 435  trainloss -0.69000  validloss -1.24894±0.00000  bestvalidloss -1.29265  last_update 63\n",
      "train: iter 436  trainloss -0.66546  validloss -1.22512±0.00000  bestvalidloss -1.29265  last_update 64\n",
      "train: iter 437  trainloss -0.69387  validloss -1.28757±0.00000  bestvalidloss -1.29265  last_update 65\n",
      "train: iter 438  trainloss -0.68075  validloss -1.26677±0.00000  bestvalidloss -1.29265  last_update 66\n",
      "train: iter 439  trainloss -0.67879  validloss -1.21681±0.00000  bestvalidloss -1.29265  last_update 67\n",
      "train: iter 440  trainloss -0.67050  validloss -1.23160±0.00000  bestvalidloss -1.29265  last_update 68\n",
      "train: iter 441  trainloss -0.69785  validloss -1.21321±0.00000  bestvalidloss -1.29265  last_update 69\n",
      "train: iter 442  trainloss -0.69689  validloss -1.25479±0.00000  bestvalidloss -1.29265  last_update 70\n",
      "train: iter 443  trainloss -0.66498  validloss -1.25703±0.00000  bestvalidloss -1.29265  last_update 71\n",
      "train: iter 444  trainloss -0.67138  validloss -1.23371±0.00000  bestvalidloss -1.29265  last_update 72\n",
      "train: iter 445  trainloss -0.65597  validloss -1.18093±0.00000  bestvalidloss -1.29265  last_update 73\n",
      "train: iter 446  trainloss -0.66702  validloss -1.23160±0.00000  bestvalidloss -1.29265  last_update 74\n",
      "train: iter 447  trainloss -0.68707  validloss -1.19989±0.00000  bestvalidloss -1.29265  last_update 75\n",
      "train: iter 448  trainloss -0.68337  validloss -1.24225±0.00000  bestvalidloss -1.29265  last_update 76\n",
      "train: iter 449  trainloss -0.65041  validloss -1.24401±0.00000  bestvalidloss -1.29265  last_update 77\n",
      "train: iter 450  trainloss -0.67074  validloss -1.19858±0.00000  bestvalidloss -1.29265  last_update 78\n",
      "train: iter 451  trainloss -0.69314  validloss -1.20093±0.00000  bestvalidloss -1.29265  last_update 79\n",
      "train: iter 452  trainloss -0.68128  validloss -1.22768±0.00000  bestvalidloss -1.29265  last_update 80\n",
      "train: iter 453  trainloss -0.69816  validloss -1.20668±0.00000  bestvalidloss -1.29265  last_update 81\n",
      "train: iter 454  trainloss -0.68722  validloss -1.24101±0.00000  bestvalidloss -1.29265  last_update 82\n",
      "train: iter 455  trainloss -0.65494  validloss -1.24444±0.00000  bestvalidloss -1.29265  last_update 83\n",
      "train: iter 456  trainloss -0.69599  validloss -1.20445±0.00000  bestvalidloss -1.29265  last_update 84\n",
      "train: iter 457  trainloss -0.64976  validloss -1.24883±0.00000  bestvalidloss -1.29265  last_update 85\n",
      "train: iter 458  trainloss -0.66913  validloss -1.25586±0.00000  bestvalidloss -1.29265  last_update 86\n",
      "train: iter 459  trainloss -0.66828  validloss -1.18860±0.00000  bestvalidloss -1.29265  last_update 87\n",
      "train: iter 460  trainloss -0.67171  validloss -1.26346±0.00000  bestvalidloss -1.29265  last_update 88\n",
      "train: iter 461  trainloss -0.73744  validloss -1.20495±0.00000  bestvalidloss -1.29265  last_update 89\n",
      "train: iter 462  trainloss -0.68038  validloss -1.24365±0.00000  bestvalidloss -1.29265  last_update 90\n",
      "train: iter 463  trainloss -0.66190  validloss -1.20501±0.00000  bestvalidloss -1.29265  last_update 91\n",
      "train: iter 464  trainloss -0.69083  validloss -1.26061±0.00000  bestvalidloss -1.29265  last_update 92\n",
      "train: iter 465  trainloss -0.68354  validloss -1.23674±0.00000  bestvalidloss -1.29265  last_update 93\n",
      "train: iter 466  trainloss -0.68811  validloss -1.21640±0.00000  bestvalidloss -1.29265  last_update 94\n",
      "train: iter 467  trainloss -0.73252  validloss -1.22737±0.00000  bestvalidloss -1.29265  last_update 95\n",
      "train: iter 468  trainloss -0.66712  validloss -1.23224±0.00000  bestvalidloss -1.29265  last_update 96\n",
      "train: iter 469  trainloss -0.68130  validloss -1.22603±0.00000  bestvalidloss -1.29265  last_update 97\n",
      "train: iter 470  trainloss -0.70389  validloss -1.24173±0.00000  bestvalidloss -1.29265  last_update 98\n",
      "train: iter 471  trainloss -0.70561  validloss -1.25795±0.00000  bestvalidloss -1.29265  last_update 99\n",
      "train: iter 472  trainloss -0.70386  validloss -1.21301±0.00000  bestvalidloss -1.29265  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.6403, -2.5155, -3.5667, -3.4846], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 101.79769  validloss 108.85218±0.00000  bestvalidloss 108.85218  last_update 0\n",
      "train: iter 1  trainloss 74.43710  validloss 86.17017±0.00000  bestvalidloss 86.17017  last_update 0\n",
      "train: iter 2  trainloss 54.25235  validloss 60.77871±0.00000  bestvalidloss 60.77871  last_update 0\n",
      "train: iter 3  trainloss 42.32756  validloss 46.25454±0.00000  bestvalidloss 46.25454  last_update 0\n",
      "train: iter 4  trainloss 33.78776  validloss 36.72074±0.00000  bestvalidloss 36.72074  last_update 0\n",
      "train: iter 5  trainloss 27.16332  validloss 29.46685±0.00000  bestvalidloss 29.46685  last_update 0\n",
      "train: iter 6  trainloss 21.78824  validloss 23.98567±0.00000  bestvalidloss 23.98567  last_update 0\n",
      "train: iter 7  trainloss 17.56485  validloss 19.42706±0.00000  bestvalidloss 19.42706  last_update 0\n",
      "train: iter 8  trainloss 14.15065  validloss 15.83057±0.00000  bestvalidloss 15.83057  last_update 0\n",
      "train: iter 9  trainloss 11.38684  validloss 12.94424±0.00000  bestvalidloss 12.94424  last_update 0\n",
      "train: iter 10  trainloss 9.24055  validloss 10.60301±0.00000  bestvalidloss 10.60301  last_update 0\n",
      "train: iter 11  trainloss 7.50175  validloss 8.89154±0.00000  bestvalidloss 8.89154  last_update 0\n",
      "train: iter 12  trainloss 6.25185  validloss 7.62636±0.00000  bestvalidloss 7.62636  last_update 0\n",
      "train: iter 13  trainloss 5.24278  validloss 6.54842±0.00000  bestvalidloss 6.54842  last_update 0\n",
      "train: iter 14  trainloss 4.52987  validloss 5.77475±0.00000  bestvalidloss 5.77475  last_update 0\n",
      "train: iter 15  trainloss 3.99541  validloss 5.24033±0.00000  bestvalidloss 5.24033  last_update 0\n",
      "train: iter 16  trainloss 3.55741  validloss 4.90661±0.00000  bestvalidloss 4.90661  last_update 0\n",
      "train: iter 17  trainloss 3.28119  validloss 4.52681±0.00000  bestvalidloss 4.52681  last_update 0\n",
      "train: iter 18  trainloss 3.12065  validloss 4.33174±0.00000  bestvalidloss 4.33174  last_update 0\n",
      "train: iter 19  trainloss 2.99291  validloss 4.24061±0.00000  bestvalidloss 4.24061  last_update 0\n",
      "train: iter 20  trainloss 2.90976  validloss 4.18267±0.00000  bestvalidloss 4.18267  last_update 0\n",
      "train: iter 21  trainloss 2.82615  validloss 4.16015±0.00000  bestvalidloss 4.16015  last_update 0\n",
      "train: iter 22  trainloss 2.77950  validloss 4.10676±0.00000  bestvalidloss 4.10676  last_update 0\n",
      "train: iter 23  trainloss 2.76904  validloss 4.03828±0.00000  bestvalidloss 4.03828  last_update 0\n",
      "train: iter 24  trainloss 2.73389  validloss 4.06721±0.00000  bestvalidloss 4.03828  last_update 1\n",
      "train: iter 25  trainloss 2.74804  validloss 4.05367±0.00000  bestvalidloss 4.03828  last_update 2\n",
      "train: iter 26  trainloss 2.72676  validloss 4.08260±0.00000  bestvalidloss 4.03828  last_update 3\n",
      "train: iter 27  trainloss 2.70108  validloss 4.07301±0.00000  bestvalidloss 4.03828  last_update 4\n",
      "train: iter 28  trainloss 2.73560  validloss 4.16237±0.00000  bestvalidloss 4.03828  last_update 5\n",
      "train: iter 29  trainloss 2.69136  validloss 4.04662±0.00000  bestvalidloss 4.03828  last_update 6\n",
      "train: iter 30  trainloss 2.66763  validloss 4.24688±0.00000  bestvalidloss 4.03828  last_update 7\n",
      "train: iter 31  trainloss 2.67687  validloss 4.41090±0.00000  bestvalidloss 4.03828  last_update 8\n",
      "train: iter 32  trainloss 2.65888  validloss 3.95851±0.00000  bestvalidloss 3.95851  last_update 0\n",
      "train: iter 33  trainloss 2.67468  validloss 3.96977±0.00000  bestvalidloss 3.95851  last_update 1\n",
      "train: iter 34  trainloss 2.66237  validloss 3.73848±0.00000  bestvalidloss 3.73848  last_update 0\n",
      "train: iter 35  trainloss 2.64898  validloss 3.99665±0.00000  bestvalidloss 3.73848  last_update 1\n",
      "train: iter 36  trainloss 2.62624  validloss 3.62060±0.00000  bestvalidloss 3.62060  last_update 0\n",
      "train: iter 37  trainloss 2.62504  validloss 3.51479±0.00000  bestvalidloss 3.51479  last_update 0\n",
      "train: iter 38  trainloss 2.62957  validloss 3.51005±0.00000  bestvalidloss 3.51005  last_update 0\n",
      "train: iter 39  trainloss 2.58908  validloss 3.39632±0.00000  bestvalidloss 3.39632  last_update 0\n",
      "train: iter 40  trainloss 2.60695  validloss 3.43791±0.00000  bestvalidloss 3.39632  last_update 1\n",
      "train: iter 41  trainloss 2.55663  validloss 3.43148±0.00000  bestvalidloss 3.39632  last_update 2\n",
      "train: iter 42  trainloss 2.58070  validloss 3.44371±0.00000  bestvalidloss 3.39632  last_update 3\n",
      "train: iter 43  trainloss 2.56775  validloss 3.24336±0.00000  bestvalidloss 3.24336  last_update 0\n",
      "train: iter 44  trainloss 2.57376  validloss 3.37219±0.00000  bestvalidloss 3.24336  last_update 1\n",
      "train: iter 45  trainloss 2.53290  validloss 3.38758±0.00000  bestvalidloss 3.24336  last_update 2\n",
      "train: iter 46  trainloss 2.56386  validloss 3.33821±0.00000  bestvalidloss 3.24336  last_update 3\n",
      "train: iter 47  trainloss 2.53291  validloss 3.46826±0.00000  bestvalidloss 3.24336  last_update 4\n",
      "train: iter 48  trainloss 2.51682  validloss 3.51431±0.00000  bestvalidloss 3.24336  last_update 5\n",
      "train: iter 49  trainloss 2.55092  validloss 3.52223±0.00000  bestvalidloss 3.24336  last_update 6\n",
      "train: iter 50  trainloss 2.51116  validloss 3.24935±0.00000  bestvalidloss 3.24336  last_update 7\n",
      "train: iter 51  trainloss 2.53592  validloss 3.28227±0.00000  bestvalidloss 3.24336  last_update 8\n",
      "train: iter 52  trainloss 2.54365  validloss 3.27282±0.00000  bestvalidloss 3.24336  last_update 9\n",
      "train: iter 53  trainloss 2.50572  validloss 3.44370±0.00000  bestvalidloss 3.24336  last_update 10\n",
      "train: iter 54  trainloss 2.46135  validloss 3.17483±0.00000  bestvalidloss 3.17483  last_update 0\n",
      "train: iter 55  trainloss 2.46011  validloss 3.37443±0.00000  bestvalidloss 3.17483  last_update 1\n",
      "train: iter 56  trainloss 2.45281  validloss 3.49248±0.00000  bestvalidloss 3.17483  last_update 2\n",
      "train: iter 57  trainloss 2.45019  validloss 3.22182±0.00000  bestvalidloss 3.17483  last_update 3\n",
      "train: iter 58  trainloss 2.29838  validloss 3.59234±0.00000  bestvalidloss 3.17483  last_update 4\n",
      "train: iter 59  trainloss 2.20074  validloss 3.34446±0.00000  bestvalidloss 3.17483  last_update 5\n",
      "train: iter 60  trainloss 2.12528  validloss 3.47574±0.00000  bestvalidloss 3.17483  last_update 6\n",
      "train: iter 61  trainloss 2.13933  validloss 3.30460±0.00000  bestvalidloss 3.17483  last_update 7\n",
      "train: iter 62  trainloss 2.08612  validloss 3.17335±0.00000  bestvalidloss 3.17335  last_update 0\n",
      "train: iter 63  trainloss 2.04755  validloss 3.28292±0.00000  bestvalidloss 3.17335  last_update 1\n",
      "train: iter 64  trainloss 2.04635  validloss 3.26093±0.00000  bestvalidloss 3.17335  last_update 2\n",
      "train: iter 65  trainloss 1.99508  validloss 3.37590±0.00000  bestvalidloss 3.17335  last_update 3\n",
      "train: iter 66  trainloss 1.99766  validloss 3.34678±0.00000  bestvalidloss 3.17335  last_update 4\n",
      "train: iter 67  trainloss 2.00349  validloss 3.28008±0.00000  bestvalidloss 3.17335  last_update 5\n",
      "train: iter 68  trainloss 1.96826  validloss 3.19488±0.00000  bestvalidloss 3.17335  last_update 6\n",
      "train: iter 69  trainloss 1.95253  validloss 3.12256±0.00000  bestvalidloss 3.12256  last_update 0\n",
      "train: iter 70  trainloss 1.93713  validloss 3.43947±0.00000  bestvalidloss 3.12256  last_update 1\n",
      "train: iter 71  trainloss 1.95904  validloss 3.22840±0.00000  bestvalidloss 3.12256  last_update 2\n",
      "train: iter 72  trainloss 1.92724  validloss 3.34748±0.00000  bestvalidloss 3.12256  last_update 3\n",
      "train: iter 73  trainloss 1.94544  validloss 3.34849±0.00000  bestvalidloss 3.12256  last_update 4\n",
      "train: iter 74  trainloss 1.91534  validloss 3.34905±0.00000  bestvalidloss 3.12256  last_update 5\n",
      "train: iter 75  trainloss 1.86543  validloss 3.22930±0.00000  bestvalidloss 3.12256  last_update 6\n",
      "train: iter 76  trainloss 1.82741  validloss 3.34021±0.00000  bestvalidloss 3.12256  last_update 7\n",
      "train: iter 77  trainloss 1.86879  validloss 3.40446±0.00000  bestvalidloss 3.12256  last_update 8\n",
      "train: iter 78  trainloss 1.80897  validloss 3.33349±0.00000  bestvalidloss 3.12256  last_update 9\n",
      "train: iter 79  trainloss 1.83428  validloss 3.32385±0.00000  bestvalidloss 3.12256  last_update 10\n",
      "train: iter 80  trainloss 1.80120  validloss 3.52768±0.00000  bestvalidloss 3.12256  last_update 11\n",
      "train: iter 81  trainloss 1.82492  validloss 3.51756±0.00000  bestvalidloss 3.12256  last_update 12\n",
      "train: iter 82  trainloss 1.86425  validloss 3.38042±0.00000  bestvalidloss 3.12256  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.84023  validloss 3.08071±0.00000  bestvalidloss 3.08071  last_update 0\n",
      "train: iter 84  trainloss 1.76721  validloss 3.28928±0.00000  bestvalidloss 3.08071  last_update 1\n",
      "train: iter 85  trainloss 1.74978  validloss 3.44538±0.00000  bestvalidloss 3.08071  last_update 2\n",
      "train: iter 86  trainloss 1.79661  validloss 3.50831±0.00000  bestvalidloss 3.08071  last_update 3\n",
      "train: iter 87  trainloss 1.77506  validloss 3.43880±0.00000  bestvalidloss 3.08071  last_update 4\n",
      "train: iter 88  trainloss 1.79906  validloss 3.35720±0.00000  bestvalidloss 3.08071  last_update 5\n",
      "train: iter 89  trainloss 1.77502  validloss 3.31375±0.00000  bestvalidloss 3.08071  last_update 6\n",
      "train: iter 90  trainloss 1.79176  validloss 3.53544±0.00000  bestvalidloss 3.08071  last_update 7\n",
      "train: iter 91  trainloss 1.77860  validloss 3.39907±0.00000  bestvalidloss 3.08071  last_update 8\n",
      "train: iter 92  trainloss 1.75737  validloss 3.29450±0.00000  bestvalidloss 3.08071  last_update 9\n",
      "train: iter 93  trainloss 1.77160  validloss 3.32876±0.00000  bestvalidloss 3.08071  last_update 10\n",
      "train: iter 94  trainloss 1.76039  validloss 3.30011±0.00000  bestvalidloss 3.08071  last_update 11\n",
      "train: iter 95  trainloss 1.76655  validloss 3.48642±0.00000  bestvalidloss 3.08071  last_update 12\n",
      "train: iter 96  trainloss 1.77510  validloss 3.18061±0.00000  bestvalidloss 3.08071  last_update 13\n",
      "train: iter 97  trainloss 1.75423  validloss 3.35068±0.00000  bestvalidloss 3.08071  last_update 14\n",
      "train: iter 98  trainloss 1.80490  validloss 3.23765±0.00000  bestvalidloss 3.08071  last_update 15\n",
      "train: iter 99  trainloss 1.74240  validloss 3.30250±0.00000  bestvalidloss 3.08071  last_update 16\n",
      "train: iter 100  trainloss 1.75808  validloss 3.43312±0.00000  bestvalidloss 3.08071  last_update 17\n",
      "train: iter 101  trainloss 1.77204  validloss 3.44009±0.00000  bestvalidloss 3.08071  last_update 18\n",
      "train: iter 102  trainloss 1.76107  validloss 3.24008±0.00000  bestvalidloss 3.08071  last_update 19\n",
      "train: iter 103  trainloss 1.75572  validloss 3.40967±0.00000  bestvalidloss 3.08071  last_update 20\n",
      "train: iter 104  trainloss 1.79672  validloss 3.44367±0.00000  bestvalidloss 3.08071  last_update 21\n",
      "train: iter 105  trainloss 1.74594  validloss 3.35011±0.00000  bestvalidloss 3.08071  last_update 22\n",
      "train: iter 106  trainloss 1.79637  validloss 3.41270±0.00000  bestvalidloss 3.08071  last_update 23\n",
      "train: iter 107  trainloss 1.80332  validloss 3.22725±0.00000  bestvalidloss 3.08071  last_update 24\n",
      "train: iter 108  trainloss 1.73834  validloss 3.29542±0.00000  bestvalidloss 3.08071  last_update 25\n",
      "train: iter 109  trainloss 1.76126  validloss 3.20078±0.00000  bestvalidloss 3.08071  last_update 26\n",
      "train: iter 110  trainloss 1.72976  validloss 3.22052±0.00000  bestvalidloss 3.08071  last_update 27\n",
      "train: iter 111  trainloss 1.74963  validloss 3.29532±0.00000  bestvalidloss 3.08071  last_update 28\n",
      "train: iter 112  trainloss 1.74908  validloss 3.28436±0.00000  bestvalidloss 3.08071  last_update 29\n",
      "train: iter 113  trainloss 1.76457  validloss 3.21015±0.00000  bestvalidloss 3.08071  last_update 30\n",
      "train: iter 114  trainloss 1.77332  validloss 3.27406±0.00000  bestvalidloss 3.08071  last_update 31\n",
      "train: iter 115  trainloss 1.73163  validloss 3.23107±0.00000  bestvalidloss 3.08071  last_update 32\n",
      "train: iter 116  trainloss 1.73610  validloss 3.48225±0.00000  bestvalidloss 3.08071  last_update 33\n",
      "train: iter 117  trainloss 1.71378  validloss 3.45356±0.00000  bestvalidloss 3.08071  last_update 34\n",
      "train: iter 118  trainloss 1.75403  validloss 3.44539±0.00000  bestvalidloss 3.08071  last_update 35\n",
      "train: iter 119  trainloss 1.75600  validloss 3.20932±0.00000  bestvalidloss 3.08071  last_update 36\n",
      "train: iter 120  trainloss 1.77812  validloss 3.21127±0.00000  bestvalidloss 3.08071  last_update 37\n",
      "train: iter 121  trainloss 1.76240  validloss 3.40548±0.00000  bestvalidloss 3.08071  last_update 38\n",
      "train: iter 122  trainloss 1.72762  validloss 3.22465±0.00000  bestvalidloss 3.08071  last_update 39\n",
      "train: iter 123  trainloss 1.74190  validloss 3.20020±0.00000  bestvalidloss 3.08071  last_update 40\n",
      "train: iter 124  trainloss 1.73991  validloss 3.49457±0.00000  bestvalidloss 3.08071  last_update 41\n",
      "train: iter 125  trainloss 1.74295  validloss 3.40702±0.00000  bestvalidloss 3.08071  last_update 42\n",
      "train: iter 126  trainloss 1.71258  validloss 3.52947±0.00000  bestvalidloss 3.08071  last_update 43\n",
      "train: iter 127  trainloss 1.74306  validloss 3.07591±0.00000  bestvalidloss 3.07591  last_update 0\n",
      "train: iter 128  trainloss 1.76290  validloss 3.55680±0.00000  bestvalidloss 3.07591  last_update 1\n",
      "train: iter 129  trainloss 1.73270  validloss 3.14978±0.00000  bestvalidloss 3.07591  last_update 2\n",
      "train: iter 130  trainloss 1.69799  validloss 3.10353±0.00000  bestvalidloss 3.07591  last_update 3\n",
      "train: iter 131  trainloss 1.71953  validloss 3.23865±0.00000  bestvalidloss 3.07591  last_update 4\n",
      "train: iter 132  trainloss 1.75837  validloss 3.18346±0.00000  bestvalidloss 3.07591  last_update 5\n",
      "train: iter 133  trainloss 1.75329  validloss 3.30409±0.00000  bestvalidloss 3.07591  last_update 6\n",
      "train: iter 134  trainloss 1.76902  validloss 3.51883±0.00000  bestvalidloss 3.07591  last_update 7\n",
      "train: iter 135  trainloss 1.72476  validloss 3.54728±0.00000  bestvalidloss 3.07591  last_update 8\n",
      "train: iter 136  trainloss 1.73101  validloss 3.17994±0.00000  bestvalidloss 3.07591  last_update 9\n",
      "train: iter 137  trainloss 1.71441  validloss 3.35248±0.00000  bestvalidloss 3.07591  last_update 10\n",
      "train: iter 138  trainloss 1.73913  validloss 3.20045±0.00000  bestvalidloss 3.07591  last_update 11\n",
      "train: iter 139  trainloss 1.72888  validloss 3.31821±0.00000  bestvalidloss 3.07591  last_update 12\n",
      "train: iter 140  trainloss 1.73625  validloss 3.36931±0.00000  bestvalidloss 3.07591  last_update 13\n",
      "train: iter 141  trainloss 1.72149  validloss 3.17250±0.00000  bestvalidloss 3.07591  last_update 14\n",
      "train: iter 142  trainloss 1.71328  validloss 3.29814±0.00000  bestvalidloss 3.07591  last_update 15\n",
      "train: iter 143  trainloss 1.72876  validloss 3.17407±0.00000  bestvalidloss 3.07591  last_update 16\n",
      "train: iter 144  trainloss 1.71982  validloss 3.25211±0.00000  bestvalidloss 3.07591  last_update 17\n",
      "train: iter 145  trainloss 1.74187  validloss 3.03513±0.00000  bestvalidloss 3.03513  last_update 0\n",
      "train: iter 146  trainloss 1.71233  validloss 3.05616±0.00000  bestvalidloss 3.03513  last_update 1\n",
      "train: iter 147  trainloss 1.70705  validloss 3.23145±0.00000  bestvalidloss 3.03513  last_update 2\n",
      "train: iter 148  trainloss 1.75900  validloss 3.20634±0.00000  bestvalidloss 3.03513  last_update 3\n",
      "train: iter 149  trainloss 1.72235  validloss 3.50652±0.00000  bestvalidloss 3.03513  last_update 4\n",
      "train: iter 150  trainloss 1.71470  validloss 3.23016±0.00000  bestvalidloss 3.03513  last_update 5\n",
      "train: iter 151  trainloss 1.71967  validloss 3.59567±0.00000  bestvalidloss 3.03513  last_update 6\n",
      "train: iter 152  trainloss 1.70996  validloss 3.22915±0.00000  bestvalidloss 3.03513  last_update 7\n",
      "train: iter 153  trainloss 1.71097  validloss 3.22076±0.00000  bestvalidloss 3.03513  last_update 8\n",
      "train: iter 154  trainloss 1.73379  validloss 3.20074±0.00000  bestvalidloss 3.03513  last_update 9\n",
      "train: iter 155  trainloss 1.72263  validloss 3.26995±0.00000  bestvalidloss 3.03513  last_update 10\n",
      "train: iter 156  trainloss 1.76727  validloss 3.45484±0.00000  bestvalidloss 3.03513  last_update 11\n",
      "train: iter 157  trainloss 1.73429  validloss 3.41362±0.00000  bestvalidloss 3.03513  last_update 12\n",
      "train: iter 158  trainloss 1.69127  validloss 3.30816±0.00000  bestvalidloss 3.03513  last_update 13\n",
      "train: iter 159  trainloss 1.75405  validloss 3.51601±0.00000  bestvalidloss 3.03513  last_update 14\n",
      "train: iter 160  trainloss 1.72527  validloss 3.39569±0.00000  bestvalidloss 3.03513  last_update 15\n",
      "train: iter 161  trainloss 1.77515  validloss 3.14108±0.00000  bestvalidloss 3.03513  last_update 16\n",
      "train: iter 162  trainloss 1.73988  validloss 3.43438±0.00000  bestvalidloss 3.03513  last_update 17\n",
      "train: iter 163  trainloss 1.76102  validloss 3.38129±0.00000  bestvalidloss 3.03513  last_update 18\n",
      "train: iter 164  trainloss 1.73409  validloss 3.42500±0.00000  bestvalidloss 3.03513  last_update 19\n",
      "train: iter 165  trainloss 1.73862  validloss 3.21300±0.00000  bestvalidloss 3.03513  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 166  trainloss 1.71083  validloss 3.38444±0.00000  bestvalidloss 3.03513  last_update 21\n",
      "train: iter 167  trainloss 1.74694  validloss 3.50611±0.00000  bestvalidloss 3.03513  last_update 22\n",
      "train: iter 168  trainloss 1.74397  validloss 3.50712±0.00000  bestvalidloss 3.03513  last_update 23\n",
      "train: iter 169  trainloss 1.73333  validloss 3.29350±0.00000  bestvalidloss 3.03513  last_update 24\n",
      "train: iter 170  trainloss 1.71515  validloss 3.17848±0.00000  bestvalidloss 3.03513  last_update 25\n",
      "train: iter 171  trainloss 1.72059  validloss 3.60106±0.00000  bestvalidloss 3.03513  last_update 26\n",
      "train: iter 172  trainloss 1.73276  validloss 3.30557±0.00000  bestvalidloss 3.03513  last_update 27\n",
      "train: iter 173  trainloss 1.75734  validloss 3.17268±0.00000  bestvalidloss 3.03513  last_update 28\n",
      "train: iter 174  trainloss 1.72862  validloss 3.33411±0.00000  bestvalidloss 3.03513  last_update 29\n",
      "train: iter 175  trainloss 1.73509  validloss 3.15598±0.00000  bestvalidloss 3.03513  last_update 30\n",
      "train: iter 176  trainloss 1.74357  validloss 3.10484±0.00000  bestvalidloss 3.03513  last_update 31\n",
      "train: iter 177  trainloss 1.71604  validloss 3.20367±0.00000  bestvalidloss 3.03513  last_update 32\n",
      "train: iter 178  trainloss 1.71696  validloss 3.07212±0.00000  bestvalidloss 3.03513  last_update 33\n",
      "train: iter 179  trainloss 1.70868  validloss 3.35530±0.00000  bestvalidloss 3.03513  last_update 34\n",
      "train: iter 180  trainloss 1.72833  validloss 3.15022±0.00000  bestvalidloss 3.03513  last_update 35\n",
      "train: iter 181  trainloss 1.72423  validloss 3.34639±0.00000  bestvalidloss 3.03513  last_update 36\n",
      "train: iter 182  trainloss 1.71244  validloss 3.35555±0.00000  bestvalidloss 3.03513  last_update 37\n",
      "train: iter 183  trainloss 1.71560  validloss 3.18121±0.00000  bestvalidloss 3.03513  last_update 38\n",
      "train: iter 184  trainloss 1.72240  validloss 3.16559±0.00000  bestvalidloss 3.03513  last_update 39\n",
      "train: iter 185  trainloss 1.72154  validloss 3.26548±0.00000  bestvalidloss 3.03513  last_update 40\n",
      "train: iter 186  trainloss 1.71995  validloss 3.23071±0.00000  bestvalidloss 3.03513  last_update 41\n",
      "train: iter 187  trainloss 1.69876  validloss 3.32532±0.00000  bestvalidloss 3.03513  last_update 42\n",
      "train: iter 188  trainloss 1.72414  validloss 3.16687±0.00000  bestvalidloss 3.03513  last_update 43\n",
      "train: iter 189  trainloss 1.70979  validloss 3.36858±0.00000  bestvalidloss 3.03513  last_update 44\n",
      "train: iter 190  trainloss 1.73299  validloss 3.24359±0.00000  bestvalidloss 3.03513  last_update 45\n",
      "train: iter 191  trainloss 1.72099  validloss 3.47799±0.00000  bestvalidloss 3.03513  last_update 46\n",
      "train: iter 192  trainloss 1.73229  validloss 3.43110±0.00000  bestvalidloss 3.03513  last_update 47\n",
      "train: iter 193  trainloss 1.72008  validloss 3.24381±0.00000  bestvalidloss 3.03513  last_update 48\n",
      "train: iter 194  trainloss 1.72749  validloss 3.15981±0.00000  bestvalidloss 3.03513  last_update 49\n",
      "train: iter 195  trainloss 1.74088  validloss 3.32875±0.00000  bestvalidloss 3.03513  last_update 50\n",
      "train: iter 196  trainloss 1.74239  validloss 3.29386±0.00000  bestvalidloss 3.03513  last_update 51\n",
      "train: iter 197  trainloss 1.69102  validloss 3.26618±0.00000  bestvalidloss 3.03513  last_update 52\n",
      "train: iter 198  trainloss 1.72333  validloss 3.23112±0.00000  bestvalidloss 3.03513  last_update 53\n",
      "train: iter 199  trainloss 1.72486  validloss 3.41198±0.00000  bestvalidloss 3.03513  last_update 54\n",
      "train: iter 200  trainloss 1.71308  validloss 3.13006±0.00000  bestvalidloss 3.03513  last_update 55\n",
      "train: iter 201  trainloss 1.71418  validloss 3.19127±0.00000  bestvalidloss 3.03513  last_update 56\n",
      "train: iter 202  trainloss 1.68821  validloss 3.23406±0.00000  bestvalidloss 3.03513  last_update 57\n",
      "train: iter 203  trainloss 1.71411  validloss 3.23650±0.00000  bestvalidloss 3.03513  last_update 58\n",
      "train: iter 204  trainloss 1.71910  validloss 3.19906±0.00000  bestvalidloss 3.03513  last_update 59\n",
      "train: iter 205  trainloss 1.69074  validloss 3.46357±0.00000  bestvalidloss 3.03513  last_update 60\n",
      "train: iter 206  trainloss 1.72981  validloss 3.19765±0.00000  bestvalidloss 3.03513  last_update 61\n",
      "train: iter 207  trainloss 1.69262  validloss 3.24406±0.00000  bestvalidloss 3.03513  last_update 62\n",
      "train: iter 208  trainloss 1.70089  validloss 3.40830±0.00000  bestvalidloss 3.03513  last_update 63\n",
      "train: iter 209  trainloss 1.74549  validloss 3.56468±0.00000  bestvalidloss 3.03513  last_update 64\n",
      "train: iter 210  trainloss 1.75446  validloss 3.35340±0.00000  bestvalidloss 3.03513  last_update 65\n",
      "train: iter 211  trainloss 1.69749  validloss 3.44853±0.00000  bestvalidloss 3.03513  last_update 66\n",
      "train: iter 212  trainloss 1.68926  validloss 3.21978±0.00000  bestvalidloss 3.03513  last_update 67\n",
      "train: iter 213  trainloss 1.72640  validloss 3.17389±0.00000  bestvalidloss 3.03513  last_update 68\n",
      "train: iter 214  trainloss 1.71732  validloss 3.20671±0.00000  bestvalidloss 3.03513  last_update 69\n",
      "train: iter 215  trainloss 1.74628  validloss 3.13853±0.00000  bestvalidloss 3.03513  last_update 70\n",
      "train: iter 216  trainloss 1.71247  validloss 3.33737±0.00000  bestvalidloss 3.03513  last_update 71\n",
      "train: iter 217  trainloss 1.72148  validloss 3.14085±0.00000  bestvalidloss 3.03513  last_update 72\n",
      "train: iter 218  trainloss 1.69031  validloss 3.26660±0.00000  bestvalidloss 3.03513  last_update 73\n",
      "train: iter 219  trainloss 1.71569  validloss 3.27926±0.00000  bestvalidloss 3.03513  last_update 74\n",
      "train: iter 220  trainloss 1.70828  validloss 3.19261±0.00000  bestvalidloss 3.03513  last_update 75\n",
      "train: iter 221  trainloss 1.72401  validloss 3.18114±0.00000  bestvalidloss 3.03513  last_update 76\n",
      "train: iter 222  trainloss 1.74525  validloss 3.10366±0.00000  bestvalidloss 3.03513  last_update 77\n",
      "train: iter 223  trainloss 1.68228  validloss 3.30353±0.00000  bestvalidloss 3.03513  last_update 78\n",
      "train: iter 224  trainloss 1.72572  validloss 3.30919±0.00000  bestvalidloss 3.03513  last_update 79\n",
      "train: iter 225  trainloss 1.71727  validloss 3.22154±0.00000  bestvalidloss 3.03513  last_update 80\n",
      "train: iter 226  trainloss 1.69624  validloss 3.28646±0.00000  bestvalidloss 3.03513  last_update 81\n",
      "train: iter 227  trainloss 1.67998  validloss 3.29467±0.00000  bestvalidloss 3.03513  last_update 82\n",
      "train: iter 228  trainloss 1.73856  validloss 3.18419±0.00000  bestvalidloss 3.03513  last_update 83\n",
      "train: iter 229  trainloss 1.69315  validloss 3.13501±0.00000  bestvalidloss 3.03513  last_update 84\n",
      "train: iter 230  trainloss 1.71444  validloss 3.32896±0.00000  bestvalidloss 3.03513  last_update 85\n",
      "train: iter 231  trainloss 1.71731  validloss 3.07737±0.00000  bestvalidloss 3.03513  last_update 86\n",
      "train: iter 232  trainloss 1.76448  validloss 3.28361±0.00000  bestvalidloss 3.03513  last_update 87\n",
      "train: iter 233  trainloss 1.70198  validloss 3.33306±0.00000  bestvalidloss 3.03513  last_update 88\n",
      "train: iter 234  trainloss 1.72611  validloss 3.43614±0.00000  bestvalidloss 3.03513  last_update 89\n",
      "train: iter 235  trainloss 1.67759  validloss 3.11463±0.00000  bestvalidloss 3.03513  last_update 90\n",
      "train: iter 236  trainloss 1.69822  validloss 3.39841±0.00000  bestvalidloss 3.03513  last_update 91\n",
      "train: iter 237  trainloss 1.71138  validloss 3.38484±0.00000  bestvalidloss 3.03513  last_update 92\n",
      "train: iter 238  trainloss 1.68474  validloss 3.26488±0.00000  bestvalidloss 3.03513  last_update 93\n",
      "train: iter 239  trainloss 1.74347  validloss 3.14732±0.00000  bestvalidloss 3.03513  last_update 94\n",
      "train: iter 240  trainloss 1.70617  validloss 3.25259±0.00000  bestvalidloss 3.03513  last_update 95\n",
      "train: iter 241  trainloss 1.68353  validloss 3.21967±0.00000  bestvalidloss 3.03513  last_update 96\n",
      "train: iter 242  trainloss 1.70290  validloss 3.42043±0.00000  bestvalidloss 3.03513  last_update 97\n",
      "train: iter 243  trainloss 1.67464  validloss 3.18634±0.00000  bestvalidloss 3.03513  last_update 98\n",
      "train: iter 244  trainloss 1.68207  validloss 3.41543±0.00000  bestvalidloss 3.03513  last_update 99\n",
      "train: iter 245  trainloss 1.68864  validloss 3.13807±0.00000  bestvalidloss 3.03513  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-11.2071)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(5.7558)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4708520232769516\n",
      "tensor([2.6833])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
