{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(10962.1631)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 20920.99403  validloss 1140951.52238±0.00000  bestvalidloss 1140951.52238  last_update 0\n",
      "train: iter 1  trainloss 2552.76593  validloss 50381.58835±0.00000  bestvalidloss 50381.58835  last_update 0\n",
      "train: iter 2  trainloss 1134.61370  validloss 6784.05489±0.00000  bestvalidloss 6784.05489  last_update 0\n",
      "train: iter 3  trainloss 947.76243  validloss 2629.29753±0.00000  bestvalidloss 2629.29753  last_update 0\n",
      "train: iter 4  trainloss 896.56624  validloss 1633.27301±0.00000  bestvalidloss 1633.27301  last_update 0\n",
      "train: iter 5  trainloss 842.98642  validloss 1749.65312±0.00000  bestvalidloss 1633.27301  last_update 1\n",
      "train: iter 6  trainloss 749.24182  validloss 1290.32150±0.00000  bestvalidloss 1290.32150  last_update 0\n",
      "train: iter 7  trainloss 710.29848  validloss 1398.07934±0.00000  bestvalidloss 1290.32150  last_update 1\n",
      "train: iter 8  trainloss 792.40910  validloss 1478.71331±0.00000  bestvalidloss 1290.32150  last_update 2\n",
      "train: iter 9  trainloss 696.82575  validloss 2797.82186±0.00000  bestvalidloss 1290.32150  last_update 3\n",
      "train: iter 10  trainloss 755.26345  validloss 1436.12073±0.00000  bestvalidloss 1290.32150  last_update 4\n",
      "train: iter 11  trainloss 740.10355  validloss 1896.72051±0.00000  bestvalidloss 1290.32150  last_update 5\n",
      "train: iter 12  trainloss 682.09141  validloss 1493.03099±0.00000  bestvalidloss 1290.32150  last_update 6\n",
      "train: iter 13  trainloss 600.12529  validloss 1028.36788±0.00000  bestvalidloss 1028.36788  last_update 0\n",
      "train: iter 14  trainloss 518.45709  validloss 1338.16369±0.00000  bestvalidloss 1028.36788  last_update 1\n",
      "train: iter 15  trainloss 515.39357  validloss 2150.94414±0.00000  bestvalidloss 1028.36788  last_update 2\n",
      "train: iter 16  trainloss 604.48447  validloss 1330.24314±0.00000  bestvalidloss 1028.36788  last_update 3\n",
      "train: iter 17  trainloss 543.50486  validloss 1237.59198±0.00000  bestvalidloss 1028.36788  last_update 4\n",
      "train: iter 18  trainloss 685.21411  validloss 3998.12589±0.00000  bestvalidloss 1028.36788  last_update 5\n",
      "train: iter 19  trainloss 598.75133  validloss 1527.91193±0.00000  bestvalidloss 1028.36788  last_update 6\n",
      "train: iter 20  trainloss 488.87637  validloss 1105.63070±0.00000  bestvalidloss 1028.36788  last_update 7\n",
      "train: iter 21  trainloss 360.36641  validloss 927.69501±0.00000  bestvalidloss 927.69501  last_update 0\n",
      "train: iter 22  trainloss 364.13158  validloss 1311.33066±0.00000  bestvalidloss 927.69501  last_update 1\n",
      "train: iter 23  trainloss 284.76205  validloss 1811.25600±0.00000  bestvalidloss 927.69501  last_update 2\n",
      "train: iter 24  trainloss 321.82550  validloss 1038.99120±0.00000  bestvalidloss 927.69501  last_update 3\n",
      "train: iter 25  trainloss 269.70688  validloss 1559.19775±0.00000  bestvalidloss 927.69501  last_update 4\n",
      "train: iter 26  trainloss 306.47330  validloss 1578.14412±0.00000  bestvalidloss 927.69501  last_update 5\n",
      "train: iter 27  trainloss 313.32795  validloss 1445.99113±0.00000  bestvalidloss 927.69501  last_update 6\n",
      "train: iter 28  trainloss 291.77084  validloss 1162.89583±0.00000  bestvalidloss 927.69501  last_update 7\n",
      "train: iter 29  trainloss 322.11308  validloss 1051.74321±0.00000  bestvalidloss 927.69501  last_update 8\n",
      "train: iter 30  trainloss 164.67958  validloss 915.99396±0.00000  bestvalidloss 915.99396  last_update 0\n",
      "train: iter 31  trainloss 223.11114  validloss 913.96802±0.00000  bestvalidloss 913.96802  last_update 0\n",
      "train: iter 32  trainloss 147.97437  validloss 1266.76947±0.00000  bestvalidloss 913.96802  last_update 1\n",
      "train: iter 33  trainloss 202.95449  validloss 999.21515±0.00000  bestvalidloss 913.96802  last_update 2\n",
      "train: iter 34  trainloss 117.33931  validloss 1636.78286±0.00000  bestvalidloss 913.96802  last_update 3\n",
      "train: iter 35  trainloss 76.39500  validloss 1068.95411±0.00000  bestvalidloss 913.96802  last_update 4\n",
      "train: iter 36  trainloss 41.60433  validloss 706.16645±0.00000  bestvalidloss 706.16645  last_update 0\n",
      "train: iter 37  trainloss 45.03722  validloss 647.62898±0.00000  bestvalidloss 647.62898  last_update 0\n",
      "train: iter 38  trainloss -5.07803  validloss 630.97555±0.00000  bestvalidloss 630.97555  last_update 0\n",
      "train: iter 39  trainloss 108.38122  validloss 694.55233±0.00000  bestvalidloss 630.97555  last_update 1\n",
      "train: iter 40  trainloss -59.40393  validloss 471.64514±0.00000  bestvalidloss 471.64514  last_update 0\n",
      "train: iter 41  trainloss -33.92165  validloss 605.03637±0.00000  bestvalidloss 471.64514  last_update 1\n",
      "train: iter 42  trainloss -78.75897  validloss 651.91493±0.00000  bestvalidloss 471.64514  last_update 2\n",
      "train: iter 43  trainloss -52.29708  validloss 396.32478±0.00000  bestvalidloss 396.32478  last_update 0\n",
      "train: iter 44  trainloss -114.40949  validloss 393.54289±0.00000  bestvalidloss 393.54289  last_update 0\n",
      "train: iter 45  trainloss -35.15903  validloss 236.95239±0.00000  bestvalidloss 236.95239  last_update 0\n",
      "train: iter 46  trainloss -98.71871  validloss 667.33883±0.00000  bestvalidloss 236.95239  last_update 1\n",
      "train: iter 47  trainloss -159.34511  validloss 241.71601±0.00000  bestvalidloss 236.95239  last_update 2\n",
      "train: iter 48  trainloss -199.63006  validloss 276.65069±0.00000  bestvalidloss 236.95239  last_update 3\n",
      "train: iter 49  trainloss -215.91704  validloss 360.98527±0.00000  bestvalidloss 236.95239  last_update 4\n",
      "train: iter 50  trainloss -214.47328  validloss 234.40612±0.00000  bestvalidloss 234.40612  last_update 0\n",
      "train: iter 51  trainloss -177.97828  validloss 181.62059±0.00000  bestvalidloss 181.62059  last_update 0\n",
      "train: iter 52  trainloss -172.41060  validloss 114.59336±0.00000  bestvalidloss 114.59336  last_update 0\n",
      "train: iter 53  trainloss -99.17200  validloss 675.06397±0.00000  bestvalidloss 114.59336  last_update 1\n",
      "train: iter 54  trainloss -182.11761  validloss 214.63872±0.00000  bestvalidloss 114.59336  last_update 2\n",
      "train: iter 55  trainloss -236.53934  validloss 58.88283±0.00000  bestvalidloss 58.88283  last_update 0\n",
      "train: iter 56  trainloss -231.33456  validloss 204.76416±0.00000  bestvalidloss 58.88283  last_update 1\n",
      "train: iter 57  trainloss -286.38633  validloss 145.16738±0.00000  bestvalidloss 58.88283  last_update 2\n",
      "train: iter 58  trainloss -341.95350  validloss 162.12047±0.00000  bestvalidloss 58.88283  last_update 3\n",
      "train: iter 59  trainloss -360.01721  validloss 136.59894±0.00000  bestvalidloss 58.88283  last_update 4\n",
      "train: iter 60  trainloss -302.93041  validloss 62.83230±0.00000  bestvalidloss 58.88283  last_update 5\n",
      "train: iter 61  trainloss -387.28354  validloss 18.88434±0.00000  bestvalidloss 18.88434  last_update 0\n",
      "train: iter 62  trainloss -415.63309  validloss 133.87466±0.00000  bestvalidloss 18.88434  last_update 1\n",
      "train: iter 63  trainloss -404.57922  validloss 117.26064±0.00000  bestvalidloss 18.88434  last_update 2\n",
      "train: iter 64  trainloss -452.15990  validloss -81.76768±0.00000  bestvalidloss -81.76768  last_update 0\n",
      "train: iter 65  trainloss -329.28542  validloss 206.33570±0.00000  bestvalidloss -81.76768  last_update 1\n",
      "train: iter 66  trainloss -340.43141  validloss 124.63353±0.00000  bestvalidloss -81.76768  last_update 2\n",
      "train: iter 67  trainloss -466.62707  validloss -95.68462±0.00000  bestvalidloss -95.68462  last_update 0\n",
      "train: iter 68  trainloss -545.38705  validloss -109.77121±0.00000  bestvalidloss -109.77121  last_update 0\n",
      "train: iter 69  trainloss -419.37510  validloss -137.05850±0.00000  bestvalidloss -137.05850  last_update 0\n",
      "train: iter 70  trainloss -451.85669  validloss 177.21549±0.00000  bestvalidloss -137.05850  last_update 1\n",
      "train: iter 71  trainloss -529.36212  validloss -126.99312±0.00000  bestvalidloss -137.05850  last_update 2\n",
      "train: iter 72  trainloss -379.20655  validloss -203.83507±0.00000  bestvalidloss -203.83507  last_update 0\n",
      "train: iter 73  trainloss -578.17877  validloss -256.57645±0.00000  bestvalidloss -256.57645  last_update 0\n",
      "train: iter 74  trainloss -563.96616  validloss -249.25048±0.00000  bestvalidloss -256.57645  last_update 1\n",
      "train: iter 75  trainloss -449.23565  validloss -29.33152±0.00000  bestvalidloss -256.57645  last_update 2\n",
      "train: iter 76  trainloss -536.13091  validloss -62.29179±0.00000  bestvalidloss -256.57645  last_update 3\n",
      "train: iter 77  trainloss -594.85227  validloss -290.46818±0.00000  bestvalidloss -290.46818  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 78  trainloss -541.17441  validloss 770.81138±0.00000  bestvalidloss -290.46818  last_update 1\n",
      "train: iter 79  trainloss -568.62484  validloss -216.49109±0.00000  bestvalidloss -290.46818  last_update 2\n",
      "train: iter 80  trainloss -608.42260  validloss -176.38120±0.00000  bestvalidloss -290.46818  last_update 3\n",
      "train: iter 81  trainloss -549.44566  validloss -101.78729±0.00000  bestvalidloss -290.46818  last_update 4\n",
      "train: iter 82  trainloss -626.69697  validloss -272.91722±0.00000  bestvalidloss -290.46818  last_update 5\n",
      "train: iter 83  trainloss -646.17617  validloss -314.20075±0.00000  bestvalidloss -314.20075  last_update 0\n",
      "train: iter 84  trainloss -592.34353  validloss -215.71769±0.00000  bestvalidloss -314.20075  last_update 1\n",
      "train: iter 85  trainloss -499.74436  validloss -240.10994±0.00000  bestvalidloss -314.20075  last_update 2\n",
      "train: iter 86  trainloss -574.83226  validloss -342.32661±0.00000  bestvalidloss -342.32661  last_update 0\n",
      "train: iter 87  trainloss -677.03531  validloss -457.93873±0.00000  bestvalidloss -457.93873  last_update 0\n",
      "train: iter 88  trainloss -661.12763  validloss -526.65033±0.00000  bestvalidloss -526.65033  last_update 0\n",
      "train: iter 89  trainloss -657.28790  validloss -373.60239±0.00000  bestvalidloss -526.65033  last_update 1\n",
      "train: iter 90  trainloss -508.25749  validloss -273.35662±0.00000  bestvalidloss -526.65033  last_update 2\n",
      "train: iter 91  trainloss -714.70113  validloss -371.50371±0.00000  bestvalidloss -526.65033  last_update 3\n",
      "train: iter 92  trainloss -602.63851  validloss -435.98729±0.00000  bestvalidloss -526.65033  last_update 4\n",
      "train: iter 93  trainloss -690.51686  validloss -319.26508±0.00000  bestvalidloss -526.65033  last_update 5\n",
      "train: iter 94  trainloss -701.27267  validloss -531.57009±0.00000  bestvalidloss -531.57009  last_update 0\n",
      "train: iter 95  trainloss -722.83051  validloss -511.38027±0.00000  bestvalidloss -531.57009  last_update 1\n",
      "train: iter 96  trainloss -579.97647  validloss -268.75400±0.00000  bestvalidloss -531.57009  last_update 2\n",
      "train: iter 97  trainloss -634.76247  validloss 184.10027±0.00000  bestvalidloss -531.57009  last_update 3\n",
      "train: iter 98  trainloss -757.17575  validloss -306.24414±0.00000  bestvalidloss -531.57009  last_update 4\n",
      "train: iter 99  trainloss -756.76200  validloss -636.47410±0.00000  bestvalidloss -636.47410  last_update 0\n",
      "train: iter 100  trainloss -565.87947  validloss -230.37256±0.00000  bestvalidloss -636.47410  last_update 1\n",
      "train: iter 101  trainloss -692.50673  validloss -365.85359±0.00000  bestvalidloss -636.47410  last_update 2\n",
      "train: iter 102  trainloss -746.79388  validloss -538.94504±0.00000  bestvalidloss -636.47410  last_update 3\n",
      "train: iter 103  trainloss -771.96672  validloss -498.40013±0.00000  bestvalidloss -636.47410  last_update 4\n",
      "train: iter 104  trainloss -761.67150  validloss -488.23725±0.00000  bestvalidloss -636.47410  last_update 5\n",
      "train: iter 105  trainloss -734.58201  validloss -559.32514±0.00000  bestvalidloss -636.47410  last_update 6\n",
      "train: iter 106  trainloss -588.12503  validloss -592.25318±0.00000  bestvalidloss -636.47410  last_update 7\n",
      "train: iter 107  trainloss -387.34520  validloss -239.97798±0.00000  bestvalidloss -636.47410  last_update 8\n",
      "train: iter 108  trainloss -653.84560  validloss -262.57600±0.00000  bestvalidloss -636.47410  last_update 9\n",
      "train: iter 109  trainloss -735.13843  validloss -434.34744±0.00000  bestvalidloss -636.47410  last_update 10\n",
      "train: iter 110  trainloss -777.34217  validloss -587.53558±0.00000  bestvalidloss -636.47410  last_update 11\n",
      "train: iter 111  trainloss -757.71105  validloss -544.38853±0.00000  bestvalidloss -636.47410  last_update 12\n",
      "train: iter 112  trainloss -771.56998  validloss -352.48427±0.00000  bestvalidloss -636.47410  last_update 13\n",
      "train: iter 113  trainloss -825.51093  validloss -586.57881±0.00000  bestvalidloss -636.47410  last_update 14\n",
      "train: iter 114  trainloss -822.90100  validloss -570.10262±0.00000  bestvalidloss -636.47410  last_update 15\n",
      "train: iter 115  trainloss -820.41364  validloss -741.41089±0.00000  bestvalidloss -741.41089  last_update 0\n",
      "train: iter 116  trainloss -829.08775  validloss -474.06856±0.00000  bestvalidloss -741.41089  last_update 1\n",
      "train: iter 117  trainloss -645.12095  validloss -563.26058±0.00000  bestvalidloss -741.41089  last_update 2\n",
      "train: iter 118  trainloss -756.41576  validloss -760.18783±0.00000  bestvalidloss -760.18783  last_update 0\n",
      "train: iter 119  trainloss -831.27196  validloss -595.87771±0.00000  bestvalidloss -760.18783  last_update 1\n",
      "train: iter 120  trainloss -879.31834  validloss -515.66711±0.00000  bestvalidloss -760.18783  last_update 2\n",
      "train: iter 121  trainloss -804.52672  validloss -695.86477±0.00000  bestvalidloss -760.18783  last_update 3\n",
      "train: iter 122  trainloss -753.33193  validloss -533.56543±0.00000  bestvalidloss -760.18783  last_update 4\n",
      "train: iter 123  trainloss -767.85516  validloss -760.25555±0.00000  bestvalidloss -760.25555  last_update 0\n",
      "train: iter 124  trainloss -832.17265  validloss -549.30078±0.00000  bestvalidloss -760.25555  last_update 1\n",
      "train: iter 125  trainloss -787.88140  validloss -637.35784±0.00000  bestvalidloss -760.25555  last_update 2\n",
      "train: iter 126  trainloss -771.42322  validloss -672.39806±0.00000  bestvalidloss -760.25555  last_update 3\n",
      "train: iter 127  trainloss -889.05210  validloss -622.98826±0.00000  bestvalidloss -760.25555  last_update 4\n",
      "train: iter 128  trainloss -856.80437  validloss -648.74489±0.00000  bestvalidloss -760.25555  last_update 5\n",
      "train: iter 129  trainloss -887.26866  validloss -776.71711±0.00000  bestvalidloss -776.71711  last_update 0\n",
      "train: iter 130  trainloss -884.63572  validloss -763.54068±0.00000  bestvalidloss -776.71711  last_update 1\n",
      "train: iter 131  trainloss -763.88480  validloss -728.07441±0.00000  bestvalidloss -776.71711  last_update 2\n",
      "train: iter 132  trainloss -790.95707  validloss -551.65987±0.00000  bestvalidloss -776.71711  last_update 3\n",
      "train: iter 133  trainloss -717.16356  validloss -751.61249±0.00000  bestvalidloss -776.71711  last_update 4\n",
      "train: iter 134  trainloss -875.16076  validloss -636.36970±0.00000  bestvalidloss -776.71711  last_update 5\n",
      "train: iter 135  trainloss -842.16738  validloss -719.18037±0.00000  bestvalidloss -776.71711  last_update 6\n",
      "train: iter 136  trainloss -863.61987  validloss -741.54199±0.00000  bestvalidloss -776.71711  last_update 7\n",
      "train: iter 137  trainloss -863.60995  validloss -756.82280±0.00000  bestvalidloss -776.71711  last_update 8\n",
      "train: iter 138  trainloss -925.11627  validloss -863.62124±0.00000  bestvalidloss -863.62124  last_update 0\n",
      "train: iter 139  trainloss -766.80966  validloss -644.37183±0.00000  bestvalidloss -863.62124  last_update 1\n",
      "train: iter 140  trainloss -937.38341  validloss -635.94290±0.00000  bestvalidloss -863.62124  last_update 2\n",
      "train: iter 141  trainloss -842.81708  validloss -633.61304±0.00000  bestvalidloss -863.62124  last_update 3\n",
      "train: iter 142  trainloss -859.51506  validloss -513.39762±0.00000  bestvalidloss -863.62124  last_update 4\n",
      "train: iter 143  trainloss -816.82594  validloss -555.45066±0.00000  bestvalidloss -863.62124  last_update 5\n",
      "train: iter 144  trainloss -616.34603  validloss -271.67650±0.00000  bestvalidloss -863.62124  last_update 6\n",
      "train: iter 145  trainloss -836.73195  validloss -389.68419±0.00000  bestvalidloss -863.62124  last_update 7\n",
      "train: iter 146  trainloss -927.32650  validloss -747.08534±0.00000  bestvalidloss -863.62124  last_update 8\n",
      "train: iter 147  trainloss -777.62245  validloss -902.27105±0.00000  bestvalidloss -902.27105  last_update 0\n",
      "train: iter 148  trainloss -884.00031  validloss -509.28180±0.00000  bestvalidloss -902.27105  last_update 1\n",
      "train: iter 149  trainloss -976.01862  validloss -745.99238±0.00000  bestvalidloss -902.27105  last_update 2\n",
      "train: iter 150  trainloss -799.22613  validloss -828.39849±0.00000  bestvalidloss -902.27105  last_update 3\n",
      "train: iter 151  trainloss -923.52994  validloss -684.23668±0.00000  bestvalidloss -902.27105  last_update 4\n",
      "train: iter 152  trainloss -887.17861  validloss -503.03488±0.00000  bestvalidloss -902.27105  last_update 5\n",
      "train: iter 153  trainloss -955.16814  validloss -852.79329±0.00000  bestvalidloss -902.27105  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 154  trainloss -908.97945  validloss -685.73828±0.00000  bestvalidloss -902.27105  last_update 7\n",
      "train: iter 155  trainloss -810.36590  validloss -652.18297±0.00000  bestvalidloss -902.27105  last_update 8\n",
      "train: iter 156  trainloss -746.99555  validloss -820.04938±0.00000  bestvalidloss -902.27105  last_update 9\n",
      "train: iter 157  trainloss -887.56834  validloss -275.36502±0.00000  bestvalidloss -902.27105  last_update 10\n",
      "train: iter 158  trainloss -901.67549  validloss -843.62966±0.00000  bestvalidloss -902.27105  last_update 11\n",
      "train: iter 159  trainloss -974.84525  validloss -760.37063±0.00000  bestvalidloss -902.27105  last_update 12\n",
      "train: iter 160  trainloss -901.85720  validloss -677.60833±0.00000  bestvalidloss -902.27105  last_update 13\n",
      "train: iter 161  trainloss -749.93221  validloss -736.27115±0.00000  bestvalidloss -902.27105  last_update 14\n",
      "train: iter 162  trainloss -806.78932  validloss -556.60537±0.00000  bestvalidloss -902.27105  last_update 15\n",
      "train: iter 163  trainloss -850.50318  validloss -968.94332±0.00000  bestvalidloss -968.94332  last_update 0\n",
      "train: iter 164  trainloss -1021.27665  validloss -837.37195±0.00000  bestvalidloss -968.94332  last_update 1\n",
      "train: iter 165  trainloss -775.13401  validloss -915.83139±0.00000  bestvalidloss -968.94332  last_update 2\n",
      "train: iter 166  trainloss -712.90278  validloss -769.91418±0.00000  bestvalidloss -968.94332  last_update 3\n",
      "train: iter 167  trainloss -910.60454  validloss -365.36509±0.00000  bestvalidloss -968.94332  last_update 4\n",
      "train: iter 168  trainloss -930.83830  validloss -730.68249±0.00000  bestvalidloss -968.94332  last_update 5\n",
      "train: iter 169  trainloss -873.52539  validloss -868.77086±0.00000  bestvalidloss -968.94332  last_update 6\n",
      "train: iter 170  trainloss -902.22115  validloss -815.00218±0.00000  bestvalidloss -968.94332  last_update 7\n",
      "train: iter 171  trainloss -1034.46270  validloss -856.16972±0.00000  bestvalidloss -968.94332  last_update 8\n",
      "train: iter 172  trainloss -969.70178  validloss -685.84483±0.00000  bestvalidloss -968.94332  last_update 9\n",
      "train: iter 173  trainloss -926.48800  validloss -888.47850±0.00000  bestvalidloss -968.94332  last_update 10\n",
      "train: iter 174  trainloss -1000.18160  validloss -934.88671±0.00000  bestvalidloss -968.94332  last_update 11\n",
      "train: iter 175  trainloss -1065.65318  validloss -875.47600±0.00000  bestvalidloss -968.94332  last_update 12\n",
      "train: iter 176  trainloss -994.43701  validloss -1044.24541±0.00000  bestvalidloss -1044.24541  last_update 0\n",
      "train: iter 177  trainloss -1126.38999  validloss -977.48666±0.00000  bestvalidloss -1044.24541  last_update 1\n",
      "train: iter 178  trainloss -790.71876  validloss -947.35418±0.00000  bestvalidloss -1044.24541  last_update 2\n",
      "train: iter 179  trainloss -851.44824  validloss -623.63409±0.00000  bestvalidloss -1044.24541  last_update 3\n",
      "train: iter 180  trainloss -1025.82338  validloss -793.49841±0.00000  bestvalidloss -1044.24541  last_update 4\n",
      "train: iter 181  trainloss -973.93376  validloss -932.72936±0.00000  bestvalidloss -1044.24541  last_update 5\n",
      "train: iter 182  trainloss -1021.64724  validloss -953.89820±0.00000  bestvalidloss -1044.24541  last_update 6\n",
      "train: iter 183  trainloss -1045.66023  validloss -777.29358±0.00000  bestvalidloss -1044.24541  last_update 7\n",
      "train: iter 184  trainloss -815.23659  validloss -693.00013±0.00000  bestvalidloss -1044.24541  last_update 8\n",
      "train: iter 185  trainloss -1028.87761  validloss -809.51173±0.00000  bestvalidloss -1044.24541  last_update 9\n",
      "train: iter 186  trainloss -835.45337  validloss -896.46571±0.00000  bestvalidloss -1044.24541  last_update 10\n",
      "train: iter 187  trainloss -716.38380  validloss -589.14086±0.00000  bestvalidloss -1044.24541  last_update 11\n",
      "train: iter 188  trainloss -974.10076  validloss -576.82770±0.00000  bestvalidloss -1044.24541  last_update 12\n",
      "train: iter 189  trainloss -1135.73946  validloss -1022.70363±0.00000  bestvalidloss -1044.24541  last_update 13\n",
      "train: iter 190  trainloss -986.97562  validloss -1022.31955±0.00000  bestvalidloss -1044.24541  last_update 14\n",
      "train: iter 191  trainloss -1067.69322  validloss -1013.06624±0.00000  bestvalidloss -1044.24541  last_update 15\n",
      "train: iter 192  trainloss -1139.60690  validloss -961.97462±0.00000  bestvalidloss -1044.24541  last_update 16\n",
      "train: iter 193  trainloss -1005.88412  validloss -1047.58997±0.00000  bestvalidloss -1047.58997  last_update 0\n",
      "train: iter 194  trainloss -1020.09434  validloss -877.24081±0.00000  bestvalidloss -1047.58997  last_update 1\n",
      "train: iter 195  trainloss -1091.49568  validloss -989.55083±0.00000  bestvalidloss -1047.58997  last_update 2\n",
      "train: iter 196  trainloss -1120.81016  validloss -1059.63239±0.00000  bestvalidloss -1059.63239  last_update 0\n",
      "train: iter 197  trainloss -1026.04777  validloss -1043.21555±0.00000  bestvalidloss -1059.63239  last_update 1\n",
      "train: iter 198  trainloss -846.22420  validloss -793.44407±0.00000  bestvalidloss -1059.63239  last_update 2\n",
      "train: iter 199  trainloss -1025.09835  validloss -557.28206±0.00000  bestvalidloss -1059.63239  last_update 3\n",
      "train: iter 200  trainloss -1089.90425  validloss -1017.42684±0.00000  bestvalidloss -1059.63239  last_update 4\n",
      "train: iter 201  trainloss -874.22638  validloss -139.11869±0.00000  bestvalidloss -1059.63239  last_update 5\n",
      "train: iter 202  trainloss -1085.36960  validloss -854.66418±0.00000  bestvalidloss -1059.63239  last_update 6\n",
      "train: iter 203  trainloss -939.84381  validloss -1050.93470±0.00000  bestvalidloss -1059.63239  last_update 7\n",
      "train: iter 204  trainloss -1106.46491  validloss -785.31575±0.00000  bestvalidloss -1059.63239  last_update 8\n",
      "train: iter 205  trainloss -1123.27382  validloss -1087.87004±0.00000  bestvalidloss -1087.87004  last_update 0\n",
      "train: iter 206  trainloss -908.73961  validloss -1061.91794±0.00000  bestvalidloss -1087.87004  last_update 1\n",
      "train: iter 207  trainloss -870.74278  validloss -983.09245±0.00000  bestvalidloss -1087.87004  last_update 2\n",
      "train: iter 208  trainloss -1039.71474  validloss -873.86481±0.00000  bestvalidloss -1087.87004  last_update 3\n",
      "train: iter 209  trainloss -1080.65690  validloss -758.44593±0.00000  bestvalidloss -1087.87004  last_update 4\n",
      "train: iter 210  trainloss -1113.01794  validloss -1034.23359±0.00000  bestvalidloss -1087.87004  last_update 5\n",
      "train: iter 211  trainloss -1075.29002  validloss -1127.50311±0.00000  bestvalidloss -1127.50311  last_update 0\n",
      "train: iter 212  trainloss -1096.15814  validloss -1073.17224±0.00000  bestvalidloss -1127.50311  last_update 1\n",
      "train: iter 213  trainloss -1180.70808  validloss -1006.53813±0.00000  bestvalidloss -1127.50311  last_update 2\n",
      "train: iter 214  trainloss -1040.69786  validloss -1085.51198±0.00000  bestvalidloss -1127.50311  last_update 3\n",
      "train: iter 215  trainloss -1149.21244  validloss -862.65166±0.00000  bestvalidloss -1127.50311  last_update 4\n",
      "train: iter 216  trainloss -893.79918  validloss -948.88621±0.00000  bestvalidloss -1127.50311  last_update 5\n",
      "train: iter 217  trainloss -1069.53222  validloss -924.30701±0.00000  bestvalidloss -1127.50311  last_update 6\n",
      "train: iter 218  trainloss -1169.58998  validloss -1107.09980±0.00000  bestvalidloss -1127.50311  last_update 7\n",
      "train: iter 219  trainloss -1137.90696  validloss -1047.73968±0.00000  bestvalidloss -1127.50311  last_update 8\n",
      "train: iter 220  trainloss -1103.08722  validloss -663.84663±0.00000  bestvalidloss -1127.50311  last_update 9\n",
      "train: iter 221  trainloss -1159.83543  validloss -1120.37435±0.00000  bestvalidloss -1127.50311  last_update 10\n",
      "train: iter 222  trainloss -1098.89881  validloss -1004.95969±0.00000  bestvalidloss -1127.50311  last_update 11\n",
      "train: iter 223  trainloss -1109.52736  validloss -867.79499±0.00000  bestvalidloss -1127.50311  last_update 12\n",
      "train: iter 224  trainloss -1160.82901  validloss -825.02871±0.00000  bestvalidloss -1127.50311  last_update 13\n",
      "train: iter 225  trainloss -1153.06133  validloss -1121.91866±0.00000  bestvalidloss -1127.50311  last_update 14\n",
      "train: iter 226  trainloss -1044.30195  validloss -697.80099±0.00000  bestvalidloss -1127.50311  last_update 15\n",
      "train: iter 227  trainloss -1063.30618  validloss -1021.74782±0.00000  bestvalidloss -1127.50311  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1091.36606  validloss -991.59268±0.00000  bestvalidloss -1127.50311  last_update 17\n",
      "train: iter 229  trainloss -740.17296  validloss -1081.02162±0.00000  bestvalidloss -1127.50311  last_update 18\n",
      "train: iter 230  trainloss -1004.99409  validloss -634.93265±0.00000  bestvalidloss -1127.50311  last_update 19\n",
      "train: iter 231  trainloss -1151.30928  validloss -1084.11474±0.00000  bestvalidloss -1127.50311  last_update 20\n",
      "train: iter 232  trainloss -1051.12450  validloss -917.79513±0.00000  bestvalidloss -1127.50311  last_update 21\n",
      "train: iter 233  trainloss -1191.26550  validloss -869.42864±0.00000  bestvalidloss -1127.50311  last_update 22\n",
      "train: iter 234  trainloss -1174.15236  validloss -966.05131±0.00000  bestvalidloss -1127.50311  last_update 23\n",
      "train: iter 235  trainloss -991.88390  validloss -1126.89884±0.00000  bestvalidloss -1127.50311  last_update 24\n",
      "train: iter 236  trainloss -1073.66301  validloss -937.12241±0.00000  bestvalidloss -1127.50311  last_update 25\n",
      "train: iter 237  trainloss -1128.39771  validloss -768.63889±0.00000  bestvalidloss -1127.50311  last_update 26\n",
      "train: iter 238  trainloss -1235.30782  validloss -1153.00827±0.00000  bestvalidloss -1153.00827  last_update 0\n",
      "train: iter 239  trainloss -999.08885  validloss -939.96891±0.00000  bestvalidloss -1153.00827  last_update 1\n",
      "train: iter 240  trainloss -1138.82473  validloss -1033.13191±0.00000  bestvalidloss -1153.00827  last_update 2\n",
      "train: iter 241  trainloss -1118.58542  validloss -1120.47328±0.00000  bestvalidloss -1153.00827  last_update 3\n",
      "train: iter 242  trainloss -1142.90013  validloss -990.29656±0.00000  bestvalidloss -1153.00827  last_update 4\n",
      "train: iter 243  trainloss -1061.48200  validloss -1089.69300±0.00000  bestvalidloss -1153.00827  last_update 5\n",
      "train: iter 244  trainloss -1105.17434  validloss -1210.23701±0.00000  bestvalidloss -1210.23701  last_update 0\n",
      "train: iter 245  trainloss -1215.67814  validloss -1056.23649±0.00000  bestvalidloss -1210.23701  last_update 1\n",
      "train: iter 246  trainloss -1128.70136  validloss -1085.38362±0.00000  bestvalidloss -1210.23701  last_update 2\n",
      "train: iter 247  trainloss -939.87992  validloss -889.14392±0.00000  bestvalidloss -1210.23701  last_update 3\n",
      "train: iter 248  trainloss -1214.62331  validloss -999.79125±0.00000  bestvalidloss -1210.23701  last_update 4\n",
      "train: iter 249  trainloss -1241.74749  validloss -1127.47474±0.00000  bestvalidloss -1210.23701  last_update 5\n",
      "train: iter 250  trainloss -1086.99033  validloss -1122.08930±0.00000  bestvalidloss -1210.23701  last_update 6\n",
      "train: iter 251  trainloss -1189.63500  validloss -1080.27729±0.00000  bestvalidloss -1210.23701  last_update 7\n",
      "train: iter 252  trainloss -1144.66602  validloss -1084.45807±0.00000  bestvalidloss -1210.23701  last_update 8\n",
      "train: iter 253  trainloss -1090.04069  validloss -1062.75555±0.00000  bestvalidloss -1210.23701  last_update 9\n",
      "train: iter 254  trainloss -1091.53516  validloss -790.26625±0.00000  bestvalidloss -1210.23701  last_update 10\n",
      "train: iter 255  trainloss -1255.95841  validloss -1136.49344±0.00000  bestvalidloss -1210.23701  last_update 11\n",
      "train: iter 256  trainloss -1119.97533  validloss -1196.75089±0.00000  bestvalidloss -1210.23701  last_update 12\n",
      "train: iter 257  trainloss -1153.68039  validloss -1088.27933±0.00000  bestvalidloss -1210.23701  last_update 13\n",
      "train: iter 258  trainloss -1227.83958  validloss -1109.22799±0.00000  bestvalidloss -1210.23701  last_update 14\n",
      "train: iter 259  trainloss -1240.82762  validloss -1166.14203±0.00000  bestvalidloss -1210.23701  last_update 15\n",
      "train: iter 260  trainloss -1178.00464  validloss -1118.95678±0.00000  bestvalidloss -1210.23701  last_update 16\n",
      "train: iter 261  trainloss -1116.96077  validloss -1189.45546±0.00000  bestvalidloss -1210.23701  last_update 17\n",
      "train: iter 262  trainloss -1076.88232  validloss -1013.30226±0.00000  bestvalidloss -1210.23701  last_update 18\n",
      "train: iter 263  trainloss -1042.80555  validloss -809.47807±0.00000  bestvalidloss -1210.23701  last_update 19\n",
      "train: iter 264  trainloss -1257.68370  validloss -1059.19307±0.00000  bestvalidloss -1210.23701  last_update 20\n",
      "train: iter 265  trainloss -1221.58919  validloss -1245.05650±0.00000  bestvalidloss -1245.05650  last_update 0\n",
      "train: iter 266  trainloss -1176.34686  validloss -610.96477±0.00000  bestvalidloss -1245.05650  last_update 1\n",
      "train: iter 267  trainloss -1314.38689  validloss -1193.73546±0.00000  bestvalidloss -1245.05650  last_update 2\n",
      "train: iter 268  trainloss -900.52726  validloss -893.36714±0.00000  bestvalidloss -1245.05650  last_update 3\n",
      "train: iter 269  trainloss -1203.41644  validloss -1188.51925±0.00000  bestvalidloss -1245.05650  last_update 4\n",
      "train: iter 270  trainloss -1033.70990  validloss -1168.64186±0.00000  bestvalidloss -1245.05650  last_update 5\n",
      "train: iter 271  trainloss -1231.33306  validloss -729.10073±0.00000  bestvalidloss -1245.05650  last_update 6\n",
      "train: iter 272  trainloss -1242.85708  validloss -1196.14958±0.00000  bestvalidloss -1245.05650  last_update 7\n",
      "train: iter 273  trainloss -1215.99300  validloss -983.24878±0.00000  bestvalidloss -1245.05650  last_update 8\n",
      "train: iter 274  trainloss -1280.48042  validloss -1094.66790±0.00000  bestvalidloss -1245.05650  last_update 9\n",
      "train: iter 275  trainloss -952.59271  validloss -587.27476±0.00000  bestvalidloss -1245.05650  last_update 10\n",
      "train: iter 276  trainloss -1283.94997  validloss -1212.52127±0.00000  bestvalidloss -1245.05650  last_update 11\n",
      "train: iter 277  trainloss -1220.19089  validloss -1255.47217±0.00000  bestvalidloss -1255.47217  last_update 0\n",
      "train: iter 278  trainloss -1271.13539  validloss -1246.39065±0.00000  bestvalidloss -1255.47217  last_update 1\n",
      "train: iter 279  trainloss -1170.22945  validloss -932.33344±0.00000  bestvalidloss -1255.47217  last_update 2\n",
      "train: iter 280  trainloss -1118.30512  validloss -966.80436±0.00000  bestvalidloss -1255.47217  last_update 3\n",
      "train: iter 281  trainloss -1221.27552  validloss -1102.23991±0.00000  bestvalidloss -1255.47217  last_update 4\n",
      "train: iter 282  trainloss -1313.25344  validloss -1216.57970±0.00000  bestvalidloss -1255.47217  last_update 5\n",
      "train: iter 283  trainloss -1051.51052  validloss -1155.90199±0.00000  bestvalidloss -1255.47217  last_update 6\n",
      "train: iter 284  trainloss -1294.69855  validloss -1075.94410±0.00000  bestvalidloss -1255.47217  last_update 7\n",
      "train: iter 285  trainloss -1259.31956  validloss -1143.17049±0.00000  bestvalidloss -1255.47217  last_update 8\n",
      "train: iter 286  trainloss -1096.51101  validloss -996.34254±0.00000  bestvalidloss -1255.47217  last_update 9\n",
      "train: iter 287  trainloss -1237.51760  validloss -797.90383±0.00000  bestvalidloss -1255.47217  last_update 10\n",
      "train: iter 288  trainloss -1303.92873  validloss -1230.56473±0.00000  bestvalidloss -1255.47217  last_update 11\n",
      "train: iter 289  trainloss -1196.36986  validloss -967.76738±0.00000  bestvalidloss -1255.47217  last_update 12\n",
      "train: iter 290  trainloss -1166.42383  validloss -1175.43671±0.00000  bestvalidloss -1255.47217  last_update 13\n",
      "train: iter 291  trainloss -1196.15071  validloss -1206.34204±0.00000  bestvalidloss -1255.47217  last_update 14\n",
      "train: iter 292  trainloss -1102.60106  validloss -1120.48513±0.00000  bestvalidloss -1255.47217  last_update 15\n",
      "train: iter 293  trainloss -1235.63342  validloss -1021.42466±0.00000  bestvalidloss -1255.47217  last_update 16\n",
      "train: iter 294  trainloss -1279.71616  validloss -1257.75968±0.00000  bestvalidloss -1257.75968  last_update 0\n",
      "train: iter 295  trainloss -1329.70414  validloss -1132.04542±0.00000  bestvalidloss -1257.75968  last_update 1\n",
      "train: iter 296  trainloss -1251.54536  validloss -1231.32898±0.00000  bestvalidloss -1257.75968  last_update 2\n",
      "train: iter 297  trainloss -1152.54044  validloss -876.43085±0.00000  bestvalidloss -1257.75968  last_update 3\n",
      "train: iter 298  trainloss -1213.42259  validloss -1126.55930±0.00000  bestvalidloss -1257.75968  last_update 4\n",
      "train: iter 299  trainloss -1259.98814  validloss -1092.70356±0.00000  bestvalidloss -1257.75968  last_update 5\n",
      "train: iter 300  trainloss -1337.57399  validloss -1091.86918±0.00000  bestvalidloss -1257.75968  last_update 6\n",
      "train: iter 301  trainloss -941.13358  validloss -1289.10168±0.00000  bestvalidloss -1289.10168  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 302  trainloss -1167.83391  validloss -1061.29291±0.00000  bestvalidloss -1289.10168  last_update 1\n",
      "train: iter 303  trainloss -1281.45825  validloss -457.82002±0.00000  bestvalidloss -1289.10168  last_update 2\n",
      "train: iter 304  trainloss -1173.88302  validloss -1056.33468±0.00000  bestvalidloss -1289.10168  last_update 3\n",
      "train: iter 305  trainloss -1226.46376  validloss -1071.72164±0.00000  bestvalidloss -1289.10168  last_update 4\n",
      "train: iter 306  trainloss -1306.62477  validloss -1188.57374±0.00000  bestvalidloss -1289.10168  last_update 5\n",
      "train: iter 307  trainloss -1206.41203  validloss -1184.83426±0.00000  bestvalidloss -1289.10168  last_update 6\n",
      "train: iter 308  trainloss -1295.53308  validloss -1179.28001±0.00000  bestvalidloss -1289.10168  last_update 7\n",
      "train: iter 309  trainloss -1345.50529  validloss -1269.81459±0.00000  bestvalidloss -1289.10168  last_update 8\n",
      "train: iter 310  trainloss -1276.04585  validloss -1175.76660±0.00000  bestvalidloss -1289.10168  last_update 9\n",
      "train: iter 311  trainloss -1294.71192  validloss -1111.43957±0.00000  bestvalidloss -1289.10168  last_update 10\n",
      "train: iter 312  trainloss -1311.82176  validloss -787.99432±0.00000  bestvalidloss -1289.10168  last_update 11\n",
      "train: iter 313  trainloss -1224.46508  validloss -1178.06510±0.00000  bestvalidloss -1289.10168  last_update 12\n",
      "train: iter 314  trainloss -1297.41239  validloss -1185.88105±0.00000  bestvalidloss -1289.10168  last_update 13\n",
      "train: iter 315  trainloss -929.20857  validloss -552.31773±0.00000  bestvalidloss -1289.10168  last_update 14\n",
      "train: iter 316  trainloss -1249.70465  validloss -1002.45565±0.00000  bestvalidloss -1289.10168  last_update 15\n",
      "train: iter 317  trainloss -1356.80987  validloss -1265.99892±0.00000  bestvalidloss -1289.10168  last_update 16\n",
      "train: iter 318  trainloss -1278.82649  validloss -1044.85087±0.00000  bestvalidloss -1289.10168  last_update 17\n",
      "train: iter 319  trainloss -1315.14279  validloss -1291.24984±0.00000  bestvalidloss -1291.24984  last_update 0\n",
      "train: iter 320  trainloss -1280.04627  validloss -1187.17669±0.00000  bestvalidloss -1291.24984  last_update 1\n",
      "train: iter 321  trainloss -1275.85488  validloss -1107.30452±0.00000  bestvalidloss -1291.24984  last_update 2\n",
      "train: iter 322  trainloss -1308.49543  validloss -1305.64477±0.00000  bestvalidloss -1305.64477  last_update 0\n",
      "train: iter 323  trainloss -1310.33634  validloss -1306.86644±0.00000  bestvalidloss -1306.86644  last_update 0\n",
      "train: iter 324  trainloss -1337.54826  validloss -1232.07970±0.00000  bestvalidloss -1306.86644  last_update 1\n",
      "train: iter 325  trainloss -1301.73414  validloss -1193.08692±0.00000  bestvalidloss -1306.86644  last_update 2\n",
      "train: iter 326  trainloss -1273.37095  validloss -1190.66881±0.00000  bestvalidloss -1306.86644  last_update 3\n",
      "train: iter 327  trainloss -1315.18143  validloss -1265.46122±0.00000  bestvalidloss -1306.86644  last_update 4\n",
      "train: iter 328  trainloss -1133.66565  validloss -1135.69164±0.00000  bestvalidloss -1306.86644  last_update 5\n",
      "train: iter 329  trainloss -1330.70859  validloss -1054.25270±0.00000  bestvalidloss -1306.86644  last_update 6\n",
      "train: iter 330  trainloss -1367.53871  validloss -1266.13417±0.00000  bestvalidloss -1306.86644  last_update 7\n",
      "train: iter 331  trainloss -1311.14887  validloss -1103.80249±0.00000  bestvalidloss -1306.86644  last_update 8\n",
      "train: iter 332  trainloss -1343.19263  validloss -1335.22850±0.00000  bestvalidloss -1335.22850  last_update 0\n",
      "train: iter 333  trainloss -1300.73566  validloss -1258.91258±0.00000  bestvalidloss -1335.22850  last_update 1\n",
      "train: iter 334  trainloss -1156.61526  validloss -1164.83755±0.00000  bestvalidloss -1335.22850  last_update 2\n",
      "train: iter 335  trainloss -1310.66583  validloss -1182.62037±0.00000  bestvalidloss -1335.22850  last_update 3\n",
      "train: iter 336  trainloss -1111.15533  validloss -804.62150±0.00000  bestvalidloss -1335.22850  last_update 4\n",
      "train: iter 337  trainloss -1390.47213  validloss -1218.31497±0.00000  bestvalidloss -1335.22850  last_update 5\n",
      "train: iter 338  trainloss -1390.66248  validloss -1218.72972±0.00000  bestvalidloss -1335.22850  last_update 6\n",
      "train: iter 339  trainloss -1237.50952  validloss -1243.39490±0.00000  bestvalidloss -1335.22850  last_update 7\n",
      "train: iter 340  trainloss -1291.21062  validloss -1214.59123±0.00000  bestvalidloss -1335.22850  last_update 8\n",
      "train: iter 341  trainloss -1301.60358  validloss -1282.89088±0.00000  bestvalidloss -1335.22850  last_update 9\n",
      "train: iter 342  trainloss -1294.08931  validloss -993.74400±0.00000  bestvalidloss -1335.22850  last_update 10\n",
      "train: iter 343  trainloss -1323.01564  validloss -1160.53834±0.00000  bestvalidloss -1335.22850  last_update 11\n",
      "train: iter 344  trainloss -1267.92946  validloss -1134.20018±0.00000  bestvalidloss -1335.22850  last_update 12\n",
      "train: iter 345  trainloss -1365.43113  validloss -1192.15215±0.00000  bestvalidloss -1335.22850  last_update 13\n",
      "train: iter 346  trainloss -1088.55673  validloss -985.42062±0.00000  bestvalidloss -1335.22850  last_update 14\n",
      "train: iter 347  trainloss -1297.92320  validloss -1133.60974±0.00000  bestvalidloss -1335.22850  last_update 15\n",
      "train: iter 348  trainloss -1345.65805  validloss -1011.94273±0.00000  bestvalidloss -1335.22850  last_update 16\n",
      "train: iter 349  trainloss -1359.48379  validloss -1294.26486±0.00000  bestvalidloss -1335.22850  last_update 17\n",
      "train: iter 350  trainloss -1079.70765  validloss -1188.15129±0.00000  bestvalidloss -1335.22850  last_update 18\n",
      "train: iter 351  trainloss -1300.46080  validloss -1109.33751±0.00000  bestvalidloss -1335.22850  last_update 19\n",
      "train: iter 352  trainloss -1181.08141  validloss -1269.43137±0.00000  bestvalidloss -1335.22850  last_update 20\n",
      "train: iter 353  trainloss -1362.84316  validloss -1223.35289±0.00000  bestvalidloss -1335.22850  last_update 21\n",
      "train: iter 354  trainloss -1326.28969  validloss -669.58429±0.00000  bestvalidloss -1335.22850  last_update 22\n",
      "train: iter 355  trainloss -1240.68278  validloss -1295.61956±0.00000  bestvalidloss -1335.22850  last_update 23\n",
      "train: iter 356  trainloss -1294.29554  validloss -961.29044±0.00000  bestvalidloss -1335.22850  last_update 24\n",
      "train: iter 357  trainloss -1198.95002  validloss -1197.30991±0.00000  bestvalidloss -1335.22850  last_update 25\n",
      "train: iter 358  trainloss -1393.96883  validloss -1238.27720±0.00000  bestvalidloss -1335.22850  last_update 26\n",
      "train: iter 359  trainloss -1439.53388  validloss -1360.64757±0.00000  bestvalidloss -1360.64757  last_update 0\n",
      "train: iter 360  trainloss -1326.05745  validloss -1187.49799±0.00000  bestvalidloss -1360.64757  last_update 1\n",
      "train: iter 361  trainloss -1273.33596  validloss -1244.45840±0.00000  bestvalidloss -1360.64757  last_update 2\n",
      "train: iter 362  trainloss -1305.94577  validloss -1218.17129±0.00000  bestvalidloss -1360.64757  last_update 3\n",
      "train: iter 363  trainloss -1309.90698  validloss -1175.12112±0.00000  bestvalidloss -1360.64757  last_update 4\n",
      "train: iter 364  trainloss -1442.36953  validloss -1259.02361±0.00000  bestvalidloss -1360.64757  last_update 5\n",
      "train: iter 365  trainloss -1367.87076  validloss -1274.25726±0.00000  bestvalidloss -1360.64757  last_update 6\n",
      "train: iter 366  trainloss -1362.49025  validloss -1303.02060±0.00000  bestvalidloss -1360.64757  last_update 7\n",
      "train: iter 367  trainloss -1288.54384  validloss -956.59146±0.00000  bestvalidloss -1360.64757  last_update 8\n",
      "train: iter 368  trainloss -1389.66730  validloss -1026.81784±0.00000  bestvalidloss -1360.64757  last_update 9\n",
      "train: iter 369  trainloss -1406.72733  validloss -1277.71625±0.00000  bestvalidloss -1360.64757  last_update 10\n",
      "train: iter 370  trainloss -1172.32925  validloss -904.03865±0.00000  bestvalidloss -1360.64757  last_update 11\n",
      "train: iter 371  trainloss -1396.04962  validloss -1250.79580±0.00000  bestvalidloss -1360.64757  last_update 12\n",
      "train: iter 372  trainloss -1368.65687  validloss -1161.41397±0.00000  bestvalidloss -1360.64757  last_update 13\n",
      "train: iter 373  trainloss -1373.35588  validloss -990.11578±0.00000  bestvalidloss -1360.64757  last_update 14\n",
      "train: iter 374  trainloss -1313.80718  validloss -1245.28138±0.00000  bestvalidloss -1360.64757  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 375  trainloss -1476.74403  validloss -1331.28219±0.00000  bestvalidloss -1360.64757  last_update 16\n",
      "train: iter 376  trainloss -1331.72789  validloss -1331.49122±0.00000  bestvalidloss -1360.64757  last_update 17\n",
      "train: iter 377  trainloss -1311.02685  validloss -1141.37528±0.00000  bestvalidloss -1360.64757  last_update 18\n",
      "train: iter 378  trainloss -1279.14846  validloss -1214.10603±0.00000  bestvalidloss -1360.64757  last_update 19\n",
      "train: iter 379  trainloss -1311.35439  validloss -1198.90065±0.00000  bestvalidloss -1360.64757  last_update 20\n",
      "train: iter 380  trainloss -1421.58094  validloss -1317.40782±0.00000  bestvalidloss -1360.64757  last_update 21\n",
      "train: iter 381  trainloss -1353.33704  validloss -1291.47634±0.00000  bestvalidloss -1360.64757  last_update 22\n",
      "train: iter 382  trainloss -1284.81516  validloss -1265.55796±0.00000  bestvalidloss -1360.64757  last_update 23\n",
      "train: iter 383  trainloss -1433.16067  validloss -1220.44355±0.00000  bestvalidloss -1360.64757  last_update 24\n",
      "train: iter 384  trainloss -1405.04580  validloss -1381.57364±0.00000  bestvalidloss -1381.57364  last_update 0\n",
      "train: iter 385  trainloss -1284.36641  validloss -1106.31919±0.00000  bestvalidloss -1381.57364  last_update 1\n",
      "train: iter 386  trainloss -1152.35639  validloss -1156.66320±0.00000  bestvalidloss -1381.57364  last_update 2\n",
      "train: iter 387  trainloss -1308.91778  validloss -1123.75995±0.00000  bestvalidloss -1381.57364  last_update 3\n",
      "train: iter 388  trainloss -1388.88928  validloss -1048.69107±0.00000  bestvalidloss -1381.57364  last_update 4\n",
      "train: iter 389  trainloss -1363.33941  validloss -1303.48253±0.00000  bestvalidloss -1381.57364  last_update 5\n",
      "train: iter 390  trainloss -1411.62401  validloss -1180.59917±0.00000  bestvalidloss -1381.57364  last_update 6\n",
      "train: iter 391  trainloss -1481.00341  validloss -1361.32817±0.00000  bestvalidloss -1381.57364  last_update 7\n",
      "train: iter 392  trainloss -1240.91275  validloss -1291.78974±0.00000  bestvalidloss -1381.57364  last_update 8\n",
      "train: iter 393  trainloss -1203.03289  validloss -1040.76948±0.00000  bestvalidloss -1381.57364  last_update 9\n",
      "train: iter 394  trainloss -1378.83851  validloss -1186.30326±0.00000  bestvalidloss -1381.57364  last_update 10\n",
      "train: iter 395  trainloss -1442.07486  validloss -1254.87800±0.00000  bestvalidloss -1381.57364  last_update 11\n",
      "train: iter 396  trainloss -1421.00718  validloss -1358.43522±0.00000  bestvalidloss -1381.57364  last_update 12\n",
      "train: iter 397  trainloss -1418.56249  validloss -1303.09186±0.00000  bestvalidloss -1381.57364  last_update 13\n",
      "train: iter 398  trainloss -1334.63177  validloss -1256.71465±0.00000  bestvalidloss -1381.57364  last_update 14\n",
      "train: iter 399  trainloss -1274.18308  validloss -1206.07259±0.00000  bestvalidloss -1381.57364  last_update 15\n",
      "train: iter 400  trainloss -1426.59283  validloss -1146.15424±0.00000  bestvalidloss -1381.57364  last_update 16\n",
      "train: iter 401  trainloss -1355.17263  validloss -1218.10311±0.00000  bestvalidloss -1381.57364  last_update 17\n",
      "train: iter 402  trainloss -1381.39742  validloss -1182.19887±0.00000  bestvalidloss -1381.57364  last_update 18\n",
      "train: iter 403  trainloss -1445.25363  validloss -1277.74248±0.00000  bestvalidloss -1381.57364  last_update 19\n",
      "train: iter 404  trainloss -1263.13185  validloss -1123.67530±0.00000  bestvalidloss -1381.57364  last_update 20\n",
      "train: iter 405  trainloss -1436.33672  validloss -1325.38588±0.00000  bestvalidloss -1381.57364  last_update 21\n",
      "train: iter 406  trainloss -1430.94508  validloss -1226.33106±0.00000  bestvalidloss -1381.57364  last_update 22\n",
      "train: iter 407  trainloss -1339.65638  validloss -1181.77883±0.00000  bestvalidloss -1381.57364  last_update 23\n",
      "train: iter 408  trainloss -1381.67386  validloss -1258.93428±0.00000  bestvalidloss -1381.57364  last_update 24\n",
      "train: iter 409  trainloss -1362.67744  validloss -1057.66796±0.00000  bestvalidloss -1381.57364  last_update 25\n",
      "train: iter 410  trainloss -1438.42532  validloss -1303.65867±0.00000  bestvalidloss -1381.57364  last_update 26\n",
      "train: iter 411  trainloss -1489.11682  validloss -1358.69840±0.00000  bestvalidloss -1381.57364  last_update 27\n",
      "train: iter 412  trainloss -1209.65608  validloss -1373.44633±0.00000  bestvalidloss -1381.57364  last_update 28\n",
      "train: iter 413  trainloss -1421.21024  validloss -1193.25620±0.00000  bestvalidloss -1381.57364  last_update 29\n",
      "train: iter 414  trainloss -1317.52667  validloss -1282.15484±0.00000  bestvalidloss -1381.57364  last_update 30\n",
      "train: iter 415  trainloss -1385.51142  validloss -1364.59534±0.00000  bestvalidloss -1381.57364  last_update 31\n",
      "train: iter 416  trainloss -1394.51858  validloss -1119.28560±0.00000  bestvalidloss -1381.57364  last_update 32\n",
      "train: iter 417  trainloss -1366.23615  validloss -1385.27986±0.00000  bestvalidloss -1385.27986  last_update 0\n",
      "train: iter 418  trainloss -1487.63925  validloss -1331.61896±0.00000  bestvalidloss -1385.27986  last_update 1\n",
      "train: iter 419  trainloss -1098.36574  validloss -1166.71743±0.00000  bestvalidloss -1385.27986  last_update 2\n",
      "train: iter 420  trainloss -1314.69926  validloss -1264.92685±0.00000  bestvalidloss -1385.27986  last_update 3\n",
      "train: iter 421  trainloss -1290.77278  validloss -694.95025±0.00000  bestvalidloss -1385.27986  last_update 4\n",
      "train: iter 422  trainloss -1400.03561  validloss -1273.45031±0.00000  bestvalidloss -1385.27986  last_update 5\n",
      "train: iter 423  trainloss -1415.83296  validloss -1266.11179±0.00000  bestvalidloss -1385.27986  last_update 6\n",
      "train: iter 424  trainloss -1467.35516  validloss -1358.72415±0.00000  bestvalidloss -1385.27986  last_update 7\n",
      "train: iter 425  trainloss -1437.07447  validloss -1401.24667±0.00000  bestvalidloss -1401.24667  last_update 0\n",
      "train: iter 426  trainloss -1433.90464  validloss -1298.57775±0.00000  bestvalidloss -1401.24667  last_update 1\n",
      "train: iter 427  trainloss -1181.55769  validloss -1181.49623±0.00000  bestvalidloss -1401.24667  last_update 2\n",
      "train: iter 428  trainloss -1390.34037  validloss -1231.36216±0.00000  bestvalidloss -1401.24667  last_update 3\n",
      "train: iter 429  trainloss -1420.59707  validloss -1230.82093±0.00000  bestvalidloss -1401.24667  last_update 4\n",
      "train: iter 430  trainloss -1282.39138  validloss -1247.96499±0.00000  bestvalidloss -1401.24667  last_update 5\n",
      "train: iter 431  trainloss -1448.13039  validloss -1312.04430±0.00000  bestvalidloss -1401.24667  last_update 6\n",
      "train: iter 432  trainloss -1399.25869  validloss -1232.15400±0.00000  bestvalidloss -1401.24667  last_update 7\n",
      "train: iter 433  trainloss -1496.51430  validloss -1351.16718±0.00000  bestvalidloss -1401.24667  last_update 8\n",
      "train: iter 434  trainloss -1345.54727  validloss -1329.93516±0.00000  bestvalidloss -1401.24667  last_update 9\n",
      "train: iter 435  trainloss -1477.08638  validloss -1358.69632±0.00000  bestvalidloss -1401.24667  last_update 10\n",
      "train: iter 436  trainloss -1378.81165  validloss -996.08627±0.00000  bestvalidloss -1401.24667  last_update 11\n",
      "train: iter 437  trainloss -1294.32357  validloss -1220.92513±0.00000  bestvalidloss -1401.24667  last_update 12\n",
      "train: iter 438  trainloss -1416.26882  validloss -1010.56768±0.00000  bestvalidloss -1401.24667  last_update 13\n",
      "train: iter 439  trainloss -1433.46948  validloss -1196.63068±0.00000  bestvalidloss -1401.24667  last_update 14\n",
      "train: iter 440  trainloss -1444.40705  validloss -1370.14712±0.00000  bestvalidloss -1401.24667  last_update 15\n",
      "train: iter 441  trainloss -1459.82546  validloss -1337.51687±0.00000  bestvalidloss -1401.24667  last_update 16\n",
      "train: iter 442  trainloss -1383.27271  validloss -1225.60663±0.00000  bestvalidloss -1401.24667  last_update 17\n",
      "train: iter 443  trainloss -1465.32385  validloss -1350.59010±0.00000  bestvalidloss -1401.24667  last_update 18\n",
      "train: iter 444  trainloss -1518.68569  validloss -1412.49954±0.00000  bestvalidloss -1412.49954  last_update 0\n",
      "train: iter 445  trainloss -1330.07806  validloss -1394.15966±0.00000  bestvalidloss -1412.49954  last_update 1\n",
      "train: iter 446  trainloss -1367.26809  validloss -1156.09406±0.00000  bestvalidloss -1412.49954  last_update 2\n",
      "train: iter 447  trainloss -1461.14857  validloss -1352.22371±0.00000  bestvalidloss -1412.49954  last_update 3\n",
      "train: iter 448  trainloss -1366.51213  validloss -1313.99550±0.00000  bestvalidloss -1412.49954  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 449  trainloss -1200.80308  validloss -1031.51739±0.00000  bestvalidloss -1412.49954  last_update 5\n",
      "train: iter 450  trainloss -1299.91036  validloss -1221.49391±0.00000  bestvalidloss -1412.49954  last_update 6\n",
      "train: iter 451  trainloss -1450.37761  validloss -1274.33103±0.00000  bestvalidloss -1412.49954  last_update 7\n",
      "train: iter 452  trainloss -1459.17857  validloss -1383.90751±0.00000  bestvalidloss -1412.49954  last_update 8\n",
      "train: iter 453  trainloss -1452.19780  validloss -1308.22242±0.00000  bestvalidloss -1412.49954  last_update 9\n",
      "train: iter 454  trainloss -1372.77608  validloss -1238.35479±0.00000  bestvalidloss -1412.49954  last_update 10\n",
      "train: iter 455  trainloss -1471.86784  validloss -1148.27476±0.00000  bestvalidloss -1412.49954  last_update 11\n",
      "train: iter 456  trainloss -1345.97966  validloss -1321.28352±0.00000  bestvalidloss -1412.49954  last_update 12\n",
      "train: iter 457  trainloss -1316.35915  validloss -1022.62296±0.00000  bestvalidloss -1412.49954  last_update 13\n",
      "train: iter 458  trainloss -1438.21434  validloss -1183.30370±0.00000  bestvalidloss -1412.49954  last_update 14\n",
      "train: iter 459  trainloss -1451.46906  validloss -1290.15982±0.00000  bestvalidloss -1412.49954  last_update 15\n",
      "train: iter 460  trainloss -1411.66237  validloss -1323.95502±0.00000  bestvalidloss -1412.49954  last_update 16\n",
      "train: iter 461  trainloss -1391.17532  validloss -1200.15467±0.00000  bestvalidloss -1412.49954  last_update 17\n",
      "train: iter 462  trainloss -1475.78664  validloss -1276.32328±0.00000  bestvalidloss -1412.49954  last_update 18\n",
      "train: iter 463  trainloss -1418.33227  validloss -1430.14460±0.00000  bestvalidloss -1430.14460  last_update 0\n",
      "train: iter 464  trainloss -1324.68343  validloss -1254.17079±0.00000  bestvalidloss -1430.14460  last_update 1\n",
      "train: iter 465  trainloss -1371.02197  validloss -1123.63225±0.00000  bestvalidloss -1430.14460  last_update 2\n",
      "train: iter 466  trainloss -1404.51233  validloss -1253.04732±0.00000  bestvalidloss -1430.14460  last_update 3\n",
      "train: iter 467  trainloss -1374.80667  validloss -1323.05670±0.00000  bestvalidloss -1430.14460  last_update 4\n",
      "train: iter 468  trainloss -1497.62606  validloss -1335.68525±0.00000  bestvalidloss -1430.14460  last_update 5\n",
      "train: iter 469  trainloss -1443.59712  validloss -1314.01337±0.00000  bestvalidloss -1430.14460  last_update 6\n",
      "train: iter 470  trainloss -1339.64008  validloss -1220.53636±0.00000  bestvalidloss -1430.14460  last_update 7\n",
      "train: iter 471  trainloss -1486.28189  validloss -1219.24280±0.00000  bestvalidloss -1430.14460  last_update 8\n",
      "train: iter 472  trainloss -1188.52422  validloss -1339.19019±0.00000  bestvalidloss -1430.14460  last_update 9\n",
      "train: iter 473  trainloss -1373.95932  validloss -925.99113±0.00000  bestvalidloss -1430.14460  last_update 10\n",
      "train: iter 474  trainloss -1379.79337  validloss -1239.30575±0.00000  bestvalidloss -1430.14460  last_update 11\n",
      "train: iter 475  trainloss -1532.78304  validloss -1392.77893±0.00000  bestvalidloss -1430.14460  last_update 12\n",
      "train: iter 476  trainloss -1247.32641  validloss -1389.71565±0.00000  bestvalidloss -1430.14460  last_update 13\n",
      "train: iter 477  trainloss -1474.13950  validloss -1284.26707±0.00000  bestvalidloss -1430.14460  last_update 14\n",
      "train: iter 478  trainloss -1455.90979  validloss -1012.76162±0.00000  bestvalidloss -1430.14460  last_update 15\n",
      "train: iter 479  trainloss -1569.13202  validloss -1457.96305±0.00000  bestvalidloss -1457.96305  last_update 0\n",
      "train: iter 480  trainloss -1381.16544  validloss -1466.18345±0.00000  bestvalidloss -1466.18345  last_update 0\n",
      "train: iter 481  trainloss -1433.24609  validloss -1274.76737±0.00000  bestvalidloss -1466.18345  last_update 1\n",
      "train: iter 482  trainloss -1411.06490  validloss -1371.05706±0.00000  bestvalidloss -1466.18345  last_update 2\n",
      "train: iter 483  trainloss -1348.99002  validloss -857.79774±0.00000  bestvalidloss -1466.18345  last_update 3\n",
      "train: iter 484  trainloss -1466.70742  validloss -1187.21891±0.00000  bestvalidloss -1466.18345  last_update 4\n",
      "train: iter 485  trainloss -1422.15981  validloss -1078.50499±0.00000  bestvalidloss -1466.18345  last_update 5\n",
      "train: iter 486  trainloss -1472.20612  validloss -1208.56126±0.00000  bestvalidloss -1466.18345  last_update 6\n",
      "train: iter 487  trainloss -1542.98377  validloss -1395.64112±0.00000  bestvalidloss -1466.18345  last_update 7\n",
      "train: iter 488  trainloss -1375.13822  validloss -1434.33437±0.00000  bestvalidloss -1466.18345  last_update 8\n",
      "train: iter 489  trainloss -1395.72813  validloss -762.87937±0.00000  bestvalidloss -1466.18345  last_update 9\n",
      "train: iter 490  trainloss -1527.57977  validloss -1364.42112±0.00000  bestvalidloss -1466.18345  last_update 10\n",
      "train: iter 491  trainloss -1471.89856  validloss -1286.12846±0.00000  bestvalidloss -1466.18345  last_update 11\n",
      "train: iter 492  trainloss -1503.21409  validloss -1339.48732±0.00000  bestvalidloss -1466.18345  last_update 12\n",
      "train: iter 493  trainloss -1443.91793  validloss -1285.37109±0.00000  bestvalidloss -1466.18345  last_update 13\n",
      "train: iter 494  trainloss -1295.67803  validloss -1316.47685±0.00000  bestvalidloss -1466.18345  last_update 14\n",
      "train: iter 495  trainloss -1475.94554  validloss -1340.43683±0.00000  bestvalidloss -1466.18345  last_update 15\n",
      "train: iter 496  trainloss -1508.95173  validloss -1259.21505±0.00000  bestvalidloss -1466.18345  last_update 16\n",
      "train: iter 497  trainloss -1487.24622  validloss -1420.11882±0.00000  bestvalidloss -1466.18345  last_update 17\n",
      "train: iter 498  trainloss -1386.74351  validloss -1324.09586±0.00000  bestvalidloss -1466.18345  last_update 18\n",
      "train: iter 499  trainloss -1449.03402  validloss -1335.20399±0.00000  bestvalidloss -1466.18345  last_update 19\n",
      "train: iter 500  trainloss -1499.62562  validloss -1401.72398±0.00000  bestvalidloss -1466.18345  last_update 20\n",
      "train: iter 501  trainloss -1404.11580  validloss -1265.06294±0.00000  bestvalidloss -1466.18345  last_update 21\n",
      "train: iter 502  trainloss -1316.92054  validloss -1352.91906±0.00000  bestvalidloss -1466.18345  last_update 22\n",
      "train: iter 503  trainloss -1492.40220  validloss -1288.25888±0.00000  bestvalidloss -1466.18345  last_update 23\n",
      "train: iter 504  trainloss -1477.48327  validloss -1316.53295±0.00000  bestvalidloss -1466.18345  last_update 24\n",
      "train: iter 505  trainloss -1544.58843  validloss -1390.04907±0.00000  bestvalidloss -1466.18345  last_update 25\n",
      "train: iter 506  trainloss -1235.47492  validloss -1428.59446±0.00000  bestvalidloss -1466.18345  last_update 26\n",
      "train: iter 507  trainloss -1447.14554  validloss -1235.50058±0.00000  bestvalidloss -1466.18345  last_update 27\n",
      "train: iter 508  trainloss -1068.00547  validloss -1307.77697±0.00000  bestvalidloss -1466.18345  last_update 28\n",
      "train: iter 509  trainloss -1410.33877  validloss -1162.30082±0.00000  bestvalidloss -1466.18345  last_update 29\n",
      "train: iter 510  trainloss -1494.30343  validloss -1107.40695±0.00000  bestvalidloss -1466.18345  last_update 30\n",
      "train: iter 511  trainloss -1394.91792  validloss -1390.03216±0.00000  bestvalidloss -1466.18345  last_update 31\n",
      "train: iter 512  trainloss -1350.13803  validloss -1025.24848±0.00000  bestvalidloss -1466.18345  last_update 32\n",
      "train: iter 513  trainloss -1494.46783  validloss -1416.62453±0.00000  bestvalidloss -1466.18345  last_update 33\n",
      "train: iter 514  trainloss -1559.65769  validloss -1383.34135±0.00000  bestvalidloss -1466.18345  last_update 34\n",
      "train: iter 515  trainloss -1487.78078  validloss -1475.18678±0.00000  bestvalidloss -1475.18678  last_update 0\n",
      "train: iter 516  trainloss -1344.37101  validloss -1254.00880±0.00000  bestvalidloss -1475.18678  last_update 1\n",
      "train: iter 517  trainloss -1489.81423  validloss -1359.35092±0.00000  bestvalidloss -1475.18678  last_update 2\n",
      "train: iter 518  trainloss -1438.15694  validloss -1241.18697±0.00000  bestvalidloss -1475.18678  last_update 3\n",
      "train: iter 519  trainloss -1535.60294  validloss -1379.00937±0.00000  bestvalidloss -1475.18678  last_update 4\n",
      "train: iter 520  trainloss -1540.20112  validloss -1425.09095±0.00000  bestvalidloss -1475.18678  last_update 5\n",
      "train: iter 521  trainloss -1133.17323  validloss -1259.24194±0.00000  bestvalidloss -1475.18678  last_update 6\n",
      "train: iter 522  trainloss -1313.51872  validloss -566.22489±0.00000  bestvalidloss -1475.18678  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 523  trainloss -1342.91533  validloss -1340.69877±0.00000  bestvalidloss -1475.18678  last_update 8\n",
      "train: iter 524  trainloss -1448.91053  validloss -1415.19507±0.00000  bestvalidloss -1475.18678  last_update 9\n",
      "train: iter 525  trainloss -1444.16728  validloss -970.79517±0.00000  bestvalidloss -1475.18678  last_update 10\n",
      "train: iter 526  trainloss -1552.84461  validloss -1458.38947±0.00000  bestvalidloss -1475.18678  last_update 11\n",
      "train: iter 527  trainloss -1447.71923  validloss -1477.43760±0.00000  bestvalidloss -1477.43760  last_update 0\n",
      "train: iter 528  trainloss -1365.40670  validloss -1412.02271±0.00000  bestvalidloss -1477.43760  last_update 1\n",
      "train: iter 529  trainloss -1528.72078  validloss -1344.66738±0.00000  bestvalidloss -1477.43760  last_update 2\n",
      "train: iter 530  trainloss -1467.53090  validloss -1288.41394±0.00000  bestvalidloss -1477.43760  last_update 3\n",
      "train: iter 531  trainloss -1542.82001  validloss -1441.52522±0.00000  bestvalidloss -1477.43760  last_update 4\n",
      "train: iter 532  trainloss -1490.73926  validloss -1455.68230±0.00000  bestvalidloss -1477.43760  last_update 5\n",
      "train: iter 533  trainloss -1463.84220  validloss -1442.45956±0.00000  bestvalidloss -1477.43760  last_update 6\n",
      "train: iter 534  trainloss -1251.35726  validloss -1258.80703±0.00000  bestvalidloss -1477.43760  last_update 7\n",
      "train: iter 535  trainloss -1178.66667  validloss -1364.00516±0.00000  bestvalidloss -1477.43760  last_update 8\n",
      "train: iter 536  trainloss -1381.26048  validloss -961.01198±0.00000  bestvalidloss -1477.43760  last_update 9\n",
      "train: iter 537  trainloss -1460.48331  validloss -1365.25168±0.00000  bestvalidloss -1477.43760  last_update 10\n",
      "train: iter 538  trainloss -1451.30892  validloss -1114.81090±0.00000  bestvalidloss -1477.43760  last_update 11\n",
      "train: iter 539  trainloss -1521.49441  validloss -1341.88089±0.00000  bestvalidloss -1477.43760  last_update 12\n",
      "train: iter 540  trainloss -1563.30687  validloss -1397.22162±0.00000  bestvalidloss -1477.43760  last_update 13\n",
      "train: iter 541  trainloss -1508.52446  validloss -1457.47066±0.00000  bestvalidloss -1477.43760  last_update 14\n",
      "train: iter 542  trainloss -1409.27157  validloss -1390.01129±0.00000  bestvalidloss -1477.43760  last_update 15\n",
      "train: iter 543  trainloss -1490.17778  validloss -1444.95103±0.00000  bestvalidloss -1477.43760  last_update 16\n",
      "train: iter 544  trainloss -1542.10307  validloss -1256.98945±0.00000  bestvalidloss -1477.43760  last_update 17\n",
      "train: iter 545  trainloss -1497.83604  validloss -1436.24389±0.00000  bestvalidloss -1477.43760  last_update 18\n",
      "train: iter 546  trainloss -1425.14086  validloss -1134.71312±0.00000  bestvalidloss -1477.43760  last_update 19\n",
      "train: iter 547  trainloss -1545.53597  validloss -1425.86612±0.00000  bestvalidloss -1477.43760  last_update 20\n",
      "train: iter 548  trainloss -1430.94674  validloss -1393.31384±0.00000  bestvalidloss -1477.43760  last_update 21\n",
      "train: iter 549  trainloss -1429.64787  validloss -748.23139±0.00000  bestvalidloss -1477.43760  last_update 22\n",
      "train: iter 550  trainloss -1540.40069  validloss -1413.64704±0.00000  bestvalidloss -1477.43760  last_update 23\n",
      "train: iter 551  trainloss -1402.39622  validloss -1448.15424±0.00000  bestvalidloss -1477.43760  last_update 24\n",
      "train: iter 552  trainloss -1561.29044  validloss -1467.56205±0.00000  bestvalidloss -1477.43760  last_update 25\n",
      "train: iter 553  trainloss -1469.27622  validloss -1386.27568±0.00000  bestvalidloss -1477.43760  last_update 26\n",
      "train: iter 554  trainloss -1494.43591  validloss -1417.36601±0.00000  bestvalidloss -1477.43760  last_update 27\n",
      "train: iter 555  trainloss -1563.52998  validloss -1448.98816±0.00000  bestvalidloss -1477.43760  last_update 28\n",
      "train: iter 556  trainloss -1536.69823  validloss -1461.65577±0.00000  bestvalidloss -1477.43760  last_update 29\n",
      "train: iter 557  trainloss -1442.74365  validloss -1040.26130±0.00000  bestvalidloss -1477.43760  last_update 30\n",
      "train: iter 558  trainloss -1495.36368  validloss -1354.89521±0.00000  bestvalidloss -1477.43760  last_update 31\n",
      "train: iter 559  trainloss -1493.65769  validloss -1366.79031±0.00000  bestvalidloss -1477.43760  last_update 32\n",
      "train: iter 560  trainloss -1487.35013  validloss -1326.96836±0.00000  bestvalidloss -1477.43760  last_update 33\n",
      "train: iter 561  trainloss -1523.54814  validloss -1368.67296±0.00000  bestvalidloss -1477.43760  last_update 34\n",
      "train: iter 562  trainloss -1420.03629  validloss -1093.97970±0.00000  bestvalidloss -1477.43760  last_update 35\n",
      "train: iter 563  trainloss -1451.55575  validloss -1417.54669±0.00000  bestvalidloss -1477.43760  last_update 36\n",
      "train: iter 564  trainloss -1449.04817  validloss -1115.75800±0.00000  bestvalidloss -1477.43760  last_update 37\n",
      "train: iter 565  trainloss -1549.42963  validloss -1463.26038±0.00000  bestvalidloss -1477.43760  last_update 38\n",
      "train: iter 566  trainloss -1382.75963  validloss -880.79761±0.00000  bestvalidloss -1477.43760  last_update 39\n",
      "train: iter 567  trainloss -1468.60425  validloss -1184.23831±0.00000  bestvalidloss -1477.43760  last_update 40\n",
      "train: iter 568  trainloss -1572.99385  validloss -1472.69980±0.00000  bestvalidloss -1477.43760  last_update 41\n",
      "train: iter 569  trainloss -1471.74000  validloss -1492.23619±0.00000  bestvalidloss -1492.23619  last_update 0\n",
      "train: iter 570  trainloss -1494.06032  validloss -1394.23358±0.00000  bestvalidloss -1492.23619  last_update 1\n",
      "train: iter 571  trainloss -1560.09147  validloss -1479.40949±0.00000  bestvalidloss -1492.23619  last_update 2\n",
      "train: iter 572  trainloss -1405.75366  validloss -1384.79594±0.00000  bestvalidloss -1492.23619  last_update 3\n",
      "train: iter 573  trainloss -1304.10532  validloss -1203.13585±0.00000  bestvalidloss -1492.23619  last_update 4\n",
      "train: iter 574  trainloss -1499.77738  validloss -1366.44499±0.00000  bestvalidloss -1492.23619  last_update 5\n",
      "train: iter 575  trainloss -1538.89528  validloss -1347.34319±0.00000  bestvalidloss -1492.23619  last_update 6\n",
      "train: iter 576  trainloss -1495.93190  validloss -1478.57361±0.00000  bestvalidloss -1492.23619  last_update 7\n",
      "train: iter 577  trainloss -1391.19613  validloss -1198.59728±0.00000  bestvalidloss -1492.23619  last_update 8\n",
      "train: iter 578  trainloss -1460.18846  validloss -1134.26209±0.00000  bestvalidloss -1492.23619  last_update 9\n",
      "train: iter 579  trainloss -1489.77003  validloss -1407.68817±0.00000  bestvalidloss -1492.23619  last_update 10\n",
      "train: iter 580  trainloss -1528.32705  validloss -1227.92487±0.00000  bestvalidloss -1492.23619  last_update 11\n",
      "train: iter 581  trainloss -1524.06726  validloss -1442.85483±0.00000  bestvalidloss -1492.23619  last_update 12\n",
      "train: iter 582  trainloss -1471.61623  validloss -1520.51005±0.00000  bestvalidloss -1520.51005  last_update 0\n",
      "train: iter 583  trainloss -1495.96502  validloss -1192.22837±0.00000  bestvalidloss -1520.51005  last_update 1\n",
      "train: iter 584  trainloss -1553.65165  validloss -1368.13253±0.00000  bestvalidloss -1520.51005  last_update 2\n",
      "train: iter 585  trainloss -1492.28932  validloss -1336.17386±0.00000  bestvalidloss -1520.51005  last_update 3\n",
      "train: iter 586  trainloss -1531.81198  validloss -1447.51413±0.00000  bestvalidloss -1520.51005  last_update 4\n",
      "train: iter 587  trainloss -1436.24076  validloss -1350.18402±0.00000  bestvalidloss -1520.51005  last_update 5\n",
      "train: iter 588  trainloss -1253.66889  validloss -1461.92077±0.00000  bestvalidloss -1520.51005  last_update 6\n",
      "train: iter 589  trainloss -1554.73750  validloss -1285.25110±0.00000  bestvalidloss -1520.51005  last_update 7\n",
      "train: iter 590  trainloss -1405.72695  validloss -1304.40770±0.00000  bestvalidloss -1520.51005  last_update 8\n",
      "train: iter 591  trainloss -1505.77765  validloss -1340.99596±0.00000  bestvalidloss -1520.51005  last_update 9\n",
      "train: iter 592  trainloss -1528.91877  validloss -1461.90113±0.00000  bestvalidloss -1520.51005  last_update 10\n",
      "train: iter 593  trainloss -1485.67983  validloss -1484.20927±0.00000  bestvalidloss -1520.51005  last_update 11\n",
      "train: iter 594  trainloss -1471.29531  validloss -1179.33884±0.00000  bestvalidloss -1520.51005  last_update 12\n",
      "train: iter 595  trainloss -1565.68445  validloss -1468.68242±0.00000  bestvalidloss -1520.51005  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 596  trainloss -1521.49338  validloss -1406.37862±0.00000  bestvalidloss -1520.51005  last_update 14\n",
      "train: iter 597  trainloss -1475.20960  validloss -1439.61123±0.00000  bestvalidloss -1520.51005  last_update 15\n",
      "train: iter 598  trainloss -1580.70636  validloss -1498.58655±0.00000  bestvalidloss -1520.51005  last_update 16\n",
      "train: iter 599  trainloss -1400.08892  validloss -1400.58143±0.00000  bestvalidloss -1520.51005  last_update 17\n",
      "train: iter 600  trainloss -1448.74846  validloss -1306.10825±0.00000  bestvalidloss -1520.51005  last_update 18\n",
      "train: iter 601  trainloss -1481.08029  validloss -1302.38144±0.00000  bestvalidloss -1520.51005  last_update 19\n",
      "train: iter 602  trainloss -1515.94660  validloss -1320.04750±0.00000  bestvalidloss -1520.51005  last_update 20\n",
      "train: iter 603  trainloss -1580.37499  validloss -1441.71689±0.00000  bestvalidloss -1520.51005  last_update 21\n",
      "train: iter 604  trainloss -1437.00631  validloss -1419.19897±0.00000  bestvalidloss -1520.51005  last_update 22\n",
      "train: iter 605  trainloss -1518.56233  validloss -1403.22529±0.00000  bestvalidloss -1520.51005  last_update 23\n",
      "train: iter 606  trainloss -1500.45370  validloss -1247.91126±0.00000  bestvalidloss -1520.51005  last_update 24\n",
      "train: iter 607  trainloss -1562.55068  validloss -1434.22162±0.00000  bestvalidloss -1520.51005  last_update 25\n",
      "train: iter 608  trainloss -1535.73580  validloss -1501.92567±0.00000  bestvalidloss -1520.51005  last_update 26\n",
      "train: iter 609  trainloss -1508.23599  validloss -1461.46095±0.00000  bestvalidloss -1520.51005  last_update 27\n",
      "train: iter 610  trainloss -1451.60527  validloss -1450.51121±0.00000  bestvalidloss -1520.51005  last_update 28\n",
      "train: iter 611  trainloss -1590.25295  validloss -1466.96875±0.00000  bestvalidloss -1520.51005  last_update 29\n",
      "train: iter 612  trainloss -1559.25255  validloss -1455.84417±0.00000  bestvalidloss -1520.51005  last_update 30\n",
      "train: iter 613  trainloss -921.06215  validloss -1518.94067±0.00000  bestvalidloss -1520.51005  last_update 31\n",
      "train: iter 614  trainloss -1215.78574  validloss -1090.85684±0.00000  bestvalidloss -1520.51005  last_update 32\n",
      "train: iter 615  trainloss -1399.88678  validloss -1043.03836±0.00000  bestvalidloss -1520.51005  last_update 33\n",
      "train: iter 616  trainloss -1503.24706  validloss -1246.62246±0.00000  bestvalidloss -1520.51005  last_update 34\n",
      "train: iter 617  trainloss -1561.88850  validloss -1402.75402±0.00000  bestvalidloss -1520.51005  last_update 35\n",
      "train: iter 618  trainloss -1532.30650  validloss -1433.91060±0.00000  bestvalidloss -1520.51005  last_update 36\n",
      "train: iter 619  trainloss -1520.84519  validloss -1425.11830±0.00000  bestvalidloss -1520.51005  last_update 37\n",
      "train: iter 620  trainloss -1580.72860  validloss -1467.14133±0.00000  bestvalidloss -1520.51005  last_update 38\n",
      "train: iter 621  trainloss -1361.59844  validloss -1402.92520±0.00000  bestvalidloss -1520.51005  last_update 39\n",
      "train: iter 622  trainloss -1577.69650  validloss -1396.74829±0.00000  bestvalidloss -1520.51005  last_update 40\n",
      "train: iter 623  trainloss -1583.42544  validloss -1492.14462±0.00000  bestvalidloss -1520.51005  last_update 41\n",
      "train: iter 624  trainloss -1515.96870  validloss -1474.96618±0.00000  bestvalidloss -1520.51005  last_update 42\n",
      "train: iter 625  trainloss -1532.33292  validloss -1459.85553±0.00000  bestvalidloss -1520.51005  last_update 43\n",
      "train: iter 626  trainloss -1567.14332  validloss -1500.09878±0.00000  bestvalidloss -1520.51005  last_update 44\n",
      "train: iter 627  trainloss -1564.05204  validloss -1487.38666±0.00000  bestvalidloss -1520.51005  last_update 45\n",
      "train: iter 628  trainloss -1438.47468  validloss -1476.55779±0.00000  bestvalidloss -1520.51005  last_update 46\n",
      "train: iter 629  trainloss -1522.25215  validloss -1166.19851±0.00000  bestvalidloss -1520.51005  last_update 47\n",
      "train: iter 630  trainloss -1526.84140  validloss -1466.13971±0.00000  bestvalidloss -1520.51005  last_update 48\n",
      "train: iter 631  trainloss -1585.88243  validloss -1336.56456±0.00000  bestvalidloss -1520.51005  last_update 49\n",
      "train: iter 632  trainloss -1559.62054  validloss -1469.16567±0.00000  bestvalidloss -1520.51005  last_update 50\n",
      "train: iter 633  trainloss -1558.80295  validloss -1465.57889±0.00000  bestvalidloss -1520.51005  last_update 51\n",
      "train: iter 634  trainloss -1507.85106  validloss -1483.21809±0.00000  bestvalidloss -1520.51005  last_update 52\n",
      "train: iter 635  trainloss -1475.35741  validloss -1455.41260±0.00000  bestvalidloss -1520.51005  last_update 53\n",
      "train: iter 636  trainloss -1548.12071  validloss -1327.82554±0.00000  bestvalidloss -1520.51005  last_update 54\n",
      "train: iter 637  trainloss -1473.64912  validloss -1123.63668±0.00000  bestvalidloss -1520.51005  last_update 55\n",
      "train: iter 638  trainloss -1575.17503  validloss -1453.66214±0.00000  bestvalidloss -1520.51005  last_update 56\n",
      "train: iter 639  trainloss -1502.29460  validloss -1492.15782±0.00000  bestvalidloss -1520.51005  last_update 57\n",
      "train: iter 640  trainloss -1591.86101  validloss -1466.04348±0.00000  bestvalidloss -1520.51005  last_update 58\n",
      "train: iter 641  trainloss -769.34599  validloss -1134.23711±0.00000  bestvalidloss -1520.51005  last_update 59\n",
      "train: iter 642  trainloss -753.59323  validloss -679.06504±0.00000  bestvalidloss -1520.51005  last_update 60\n",
      "train: iter 643  trainloss -1339.88552  validloss -1042.74492±0.00000  bestvalidloss -1520.51005  last_update 61\n",
      "train: iter 644  trainloss -1396.98567  validloss -988.06995±0.00000  bestvalidloss -1520.51005  last_update 62\n",
      "train: iter 645  trainloss -1411.00027  validloss -1386.69567±0.00000  bestvalidloss -1520.51005  last_update 63\n",
      "train: iter 646  trainloss -1546.01570  validloss -1180.90777±0.00000  bestvalidloss -1520.51005  last_update 64\n",
      "train: iter 647  trainloss -1548.65100  validloss -1521.12076±0.00000  bestvalidloss -1521.12076  last_update 0\n",
      "train: iter 648  trainloss -1537.34972  validloss -1278.76718±0.00000  bestvalidloss -1521.12076  last_update 1\n",
      "train: iter 649  trainloss -1465.80900  validloss -1349.03886±0.00000  bestvalidloss -1521.12076  last_update 2\n",
      "train: iter 650  trainloss -1564.17595  validloss -1323.81441±0.00000  bestvalidloss -1521.12076  last_update 3\n",
      "train: iter 651  trainloss -1552.97205  validloss -1517.96478±0.00000  bestvalidloss -1521.12076  last_update 4\n",
      "train: iter 652  trainloss -1497.94034  validloss -1534.76257±0.00000  bestvalidloss -1534.76257  last_update 0\n",
      "train: iter 653  trainloss -1473.26921  validloss -1518.79630±0.00000  bestvalidloss -1534.76257  last_update 1\n",
      "train: iter 654  trainloss -1548.91314  validloss -1256.69023±0.00000  bestvalidloss -1534.76257  last_update 2\n",
      "train: iter 655  trainloss -1586.21930  validloss -1483.09362±0.00000  bestvalidloss -1534.76257  last_update 3\n",
      "train: iter 656  trainloss -1602.24891  validloss -1517.60767±0.00000  bestvalidloss -1534.76257  last_update 4\n",
      "train: iter 657  trainloss -1579.49786  validloss -1537.47057±0.00000  bestvalidloss -1537.47057  last_update 0\n",
      "train: iter 658  trainloss -1499.95554  validloss -1394.29393±0.00000  bestvalidloss -1537.47057  last_update 1\n",
      "train: iter 659  trainloss -1583.05404  validloss -1414.21323±0.00000  bestvalidloss -1537.47057  last_update 2\n",
      "train: iter 660  trainloss -1568.41983  validloss -1521.03781±0.00000  bestvalidloss -1537.47057  last_update 3\n",
      "train: iter 661  trainloss -1555.04163  validloss -1510.61648±0.00000  bestvalidloss -1537.47057  last_update 4\n",
      "train: iter 662  trainloss -1524.48400  validloss -1498.43628±0.00000  bestvalidloss -1537.47057  last_update 5\n",
      "train: iter 663  trainloss -1520.22403  validloss -1342.99993±0.00000  bestvalidloss -1537.47057  last_update 6\n",
      "train: iter 664  trainloss -1549.27143  validloss -1513.05056±0.00000  bestvalidloss -1537.47057  last_update 7\n",
      "train: iter 665  trainloss -1567.27595  validloss -1456.73932±0.00000  bestvalidloss -1537.47057  last_update 8\n",
      "train: iter 666  trainloss -1597.59457  validloss -1491.40186±0.00000  bestvalidloss -1537.47057  last_update 9\n",
      "train: iter 667  trainloss -1604.47533  validloss -1540.04841±0.00000  bestvalidloss -1540.04841  last_update 0\n",
      "train: iter 668  trainloss -1404.65531  validloss -1468.44029±0.00000  bestvalidloss -1540.04841  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 669  trainloss -1463.78058  validloss -908.38473±0.00000  bestvalidloss -1540.04841  last_update 2\n",
      "train: iter 670  trainloss -1468.54698  validloss -1354.62723±0.00000  bestvalidloss -1540.04841  last_update 3\n",
      "train: iter 671  trainloss -1605.34858  validloss -1489.50717±0.00000  bestvalidloss -1540.04841  last_update 4\n",
      "train: iter 672  trainloss -1604.26212  validloss -1528.87924±0.00000  bestvalidloss -1540.04841  last_update 5\n",
      "train: iter 673  trainloss -1567.43935  validloss -1512.33241±0.00000  bestvalidloss -1540.04841  last_update 6\n",
      "train: iter 674  trainloss -1484.18387  validloss -1508.63079±0.00000  bestvalidloss -1540.04841  last_update 7\n",
      "train: iter 675  trainloss -1552.56854  validloss -1059.84952±0.00000  bestvalidloss -1540.04841  last_update 8\n",
      "train: iter 676  trainloss -1578.08506  validloss -1521.28814±0.00000  bestvalidloss -1540.04841  last_update 9\n",
      "train: iter 677  trainloss -1482.00988  validloss -1475.17916±0.00000  bestvalidloss -1540.04841  last_update 10\n",
      "train: iter 678  trainloss -1514.01886  validloss -1371.84099±0.00000  bestvalidloss -1540.04841  last_update 11\n",
      "train: iter 679  trainloss -1595.25734  validloss -1469.50853±0.00000  bestvalidloss -1540.04841  last_update 12\n",
      "train: iter 680  trainloss -1282.56816  validloss -1423.94218±0.00000  bestvalidloss -1540.04841  last_update 13\n",
      "train: iter 681  trainloss -1523.51951  validloss -1190.01536±0.00000  bestvalidloss -1540.04841  last_update 14\n",
      "train: iter 682  trainloss -1556.51681  validloss -1348.59233±0.00000  bestvalidloss -1540.04841  last_update 15\n",
      "train: iter 683  trainloss -1597.06890  validloss -1511.44521±0.00000  bestvalidloss -1540.04841  last_update 16\n",
      "train: iter 684  trainloss -1521.57675  validloss -1504.24875±0.00000  bestvalidloss -1540.04841  last_update 17\n",
      "train: iter 685  trainloss -1472.04044  validloss -1017.42177±0.00000  bestvalidloss -1540.04841  last_update 18\n",
      "train: iter 686  trainloss -1541.26207  validloss -1497.37562±0.00000  bestvalidloss -1540.04841  last_update 19\n",
      "train: iter 687  trainloss -1607.65623  validloss -1461.82556±0.00000  bestvalidloss -1540.04841  last_update 20\n",
      "train: iter 688  trainloss -1590.38787  validloss -1535.53680±0.00000  bestvalidloss -1540.04841  last_update 21\n",
      "train: iter 689  trainloss -1590.99579  validloss -1503.43119±0.00000  bestvalidloss -1540.04841  last_update 22\n",
      "train: iter 690  trainloss -1492.65648  validloss -1508.02233±0.00000  bestvalidloss -1540.04841  last_update 23\n",
      "train: iter 691  trainloss -1320.58821  validloss -812.86575±0.00000  bestvalidloss -1540.04841  last_update 24\n",
      "train: iter 692  trainloss -1566.64752  validloss -1416.71264±0.00000  bestvalidloss -1540.04841  last_update 25\n",
      "train: iter 693  trainloss -1596.58811  validloss -1364.45194±0.00000  bestvalidloss -1540.04841  last_update 26\n",
      "train: iter 694  trainloss -1567.86851  validloss -1503.55278±0.00000  bestvalidloss -1540.04841  last_update 27\n",
      "train: iter 695  trainloss -1535.51875  validloss -1427.00395±0.00000  bestvalidloss -1540.04841  last_update 28\n",
      "train: iter 696  trainloss -1552.53941  validloss -1502.33308±0.00000  bestvalidloss -1540.04841  last_update 29\n",
      "train: iter 697  trainloss -1602.23988  validloss -1506.56689±0.00000  bestvalidloss -1540.04841  last_update 30\n",
      "train: iter 698  trainloss -1621.16950  validloss -1561.18785±0.00000  bestvalidloss -1561.18785  last_update 0\n",
      "train: iter 699  trainloss -1575.54198  validloss -1546.47554±0.00000  bestvalidloss -1561.18785  last_update 1\n",
      "train: iter 700  trainloss -1504.72136  validloss -1364.12300±0.00000  bestvalidloss -1561.18785  last_update 2\n",
      "train: iter 701  trainloss -1575.39294  validloss -1485.37776±0.00000  bestvalidloss -1561.18785  last_update 3\n",
      "train: iter 702  trainloss -1422.79617  validloss -1072.14287±0.00000  bestvalidloss -1561.18785  last_update 4\n",
      "train: iter 703  trainloss -1629.71266  validloss -1496.40407±0.00000  bestvalidloss -1561.18785  last_update 5\n",
      "train: iter 704  trainloss -1585.81214  validloss -1546.75872±0.00000  bestvalidloss -1561.18785  last_update 6\n",
      "train: iter 705  trainloss -1535.32602  validloss -1530.42818±0.00000  bestvalidloss -1561.18785  last_update 7\n",
      "train: iter 706  trainloss -1543.26959  validloss -1237.79826±0.00000  bestvalidloss -1561.18785  last_update 8\n",
      "train: iter 707  trainloss -1555.22747  validloss -1525.85938±0.00000  bestvalidloss -1561.18785  last_update 9\n",
      "train: iter 708  trainloss -1555.83491  validloss -1461.50988±0.00000  bestvalidloss -1561.18785  last_update 10\n",
      "train: iter 709  trainloss -1468.64629  validloss -1089.63592±0.00000  bestvalidloss -1561.18785  last_update 11\n",
      "train: iter 710  trainloss -1601.70276  validloss -1479.93254±0.00000  bestvalidloss -1561.18785  last_update 12\n",
      "train: iter 711  trainloss -1609.42623  validloss -1523.59981±0.00000  bestvalidloss -1561.18785  last_update 13\n",
      "train: iter 712  trainloss -1608.41322  validloss -1515.31061±0.00000  bestvalidloss -1561.18785  last_update 14\n",
      "train: iter 713  trainloss -1615.24208  validloss -1537.99733±0.00000  bestvalidloss -1561.18785  last_update 15\n",
      "train: iter 714  trainloss -1596.89836  validloss -1563.03688±0.00000  bestvalidloss -1563.03688  last_update 0\n",
      "train: iter 715  trainloss -1470.80357  validloss -1421.21837±0.00000  bestvalidloss -1563.03688  last_update 1\n",
      "train: iter 716  trainloss -1555.59671  validloss -1317.43553±0.00000  bestvalidloss -1563.03688  last_update 2\n",
      "train: iter 717  trainloss -1616.95749  validloss -1542.91506±0.00000  bestvalidloss -1563.03688  last_update 3\n",
      "train: iter 718  trainloss -1503.27768  validloss -1482.47031±0.00000  bestvalidloss -1563.03688  last_update 4\n",
      "train: iter 719  trainloss -1612.11928  validloss -1511.75971±0.00000  bestvalidloss -1563.03688  last_update 5\n",
      "train: iter 720  trainloss -1468.62938  validloss -1363.51665±0.00000  bestvalidloss -1563.03688  last_update 6\n",
      "train: iter 721  trainloss -1581.63175  validloss -1322.81725±0.00000  bestvalidloss -1563.03688  last_update 7\n",
      "train: iter 722  trainloss -1543.48474  validloss -1532.16241±0.00000  bestvalidloss -1563.03688  last_update 8\n",
      "train: iter 723  trainloss -1528.97293  validloss -1361.59547±0.00000  bestvalidloss -1563.03688  last_update 9\n",
      "train: iter 724  trainloss -1525.36691  validloss -1406.79901±0.00000  bestvalidloss -1563.03688  last_update 10\n",
      "train: iter 725  trainloss -1623.45785  validloss -1480.89183±0.00000  bestvalidloss -1563.03688  last_update 11\n",
      "train: iter 726  trainloss -1606.79814  validloss -1509.45769±0.00000  bestvalidloss -1563.03688  last_update 12\n",
      "train: iter 727  trainloss -1340.39875  validloss -1407.44352±0.00000  bestvalidloss -1563.03688  last_update 13\n",
      "train: iter 728  trainloss -1256.42008  validloss -952.56547±0.00000  bestvalidloss -1563.03688  last_update 14\n",
      "train: iter 729  trainloss -1526.61282  validloss -1389.96674±0.00000  bestvalidloss -1563.03688  last_update 15\n",
      "train: iter 730  trainloss -1596.86613  validloss -1367.81249±0.00000  bestvalidloss -1563.03688  last_update 16\n",
      "train: iter 731  trainloss -1561.33448  validloss -1508.88213±0.00000  bestvalidloss -1563.03688  last_update 17\n",
      "train: iter 732  trainloss -1601.24954  validloss -1502.53172±0.00000  bestvalidloss -1563.03688  last_update 18\n",
      "train: iter 733  trainloss -1640.32975  validloss -1550.90923±0.00000  bestvalidloss -1563.03688  last_update 19\n",
      "train: iter 734  trainloss -1597.61629  validloss -1571.74067±0.00000  bestvalidloss -1571.74067  last_update 0\n",
      "train: iter 735  trainloss -1598.63191  validloss -1405.87273±0.00000  bestvalidloss -1571.74067  last_update 1\n",
      "train: iter 736  trainloss -1528.60189  validloss -1415.71076±0.00000  bestvalidloss -1571.74067  last_update 2\n",
      "train: iter 737  trainloss -1573.20504  validloss -1440.99811±0.00000  bestvalidloss -1571.74067  last_update 3\n",
      "train: iter 738  trainloss -1608.13435  validloss -1459.92380±0.00000  bestvalidloss -1571.74067  last_update 4\n",
      "train: iter 739  trainloss -1543.55548  validloss -1514.37517±0.00000  bestvalidloss -1571.74067  last_update 5\n",
      "train: iter 740  trainloss -1586.02055  validloss -1497.85565±0.00000  bestvalidloss -1571.74067  last_update 6\n",
      "train: iter 741  trainloss -1554.91613  validloss -1543.27937±0.00000  bestvalidloss -1571.74067  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 742  trainloss -1465.30500  validloss -1467.65440±0.00000  bestvalidloss -1571.74067  last_update 8\n",
      "train: iter 743  trainloss -1596.72085  validloss -1313.37358±0.00000  bestvalidloss -1571.74067  last_update 9\n",
      "train: iter 744  trainloss -1633.67046  validloss -1568.38096±0.00000  bestvalidloss -1571.74067  last_update 10\n",
      "train: iter 745  trainloss -1573.53338  validloss -1436.25709±0.00000  bestvalidloss -1571.74067  last_update 11\n",
      "train: iter 746  trainloss -1531.14834  validloss -1443.63170±0.00000  bestvalidloss -1571.74067  last_update 12\n",
      "train: iter 747  trainloss -1157.17204  validloss -734.06173±0.00000  bestvalidloss -1571.74067  last_update 13\n",
      "train: iter 748  trainloss -1467.18626  validloss -1187.95956±0.00000  bestvalidloss -1571.74067  last_update 14\n",
      "train: iter 749  trainloss -1523.37618  validloss -1382.25173±0.00000  bestvalidloss -1571.74067  last_update 15\n",
      "train: iter 750  trainloss -1597.24852  validloss -1419.27157±0.00000  bestvalidloss -1571.74067  last_update 16\n",
      "train: iter 751  trainloss -1573.37901  validloss -1520.31818±0.00000  bestvalidloss -1571.74067  last_update 17\n",
      "train: iter 752  trainloss -1578.12945  validloss -1469.26826±0.00000  bestvalidloss -1571.74067  last_update 18\n",
      "train: iter 753  trainloss -1565.65855  validloss -1482.33481±0.00000  bestvalidloss -1571.74067  last_update 19\n",
      "train: iter 754  trainloss -1517.04476  validloss -781.04028±0.00000  bestvalidloss -1571.74067  last_update 20\n",
      "train: iter 755  trainloss -1460.64990  validloss -1416.73655±0.00000  bestvalidloss -1571.74067  last_update 21\n",
      "train: iter 756  trainloss -1611.88994  validloss -1444.48360±0.00000  bestvalidloss -1571.74067  last_update 22\n",
      "train: iter 757  trainloss -1612.33363  validloss -1493.42373±0.00000  bestvalidloss -1571.74067  last_update 23\n",
      "train: iter 758  trainloss -1628.87814  validloss -1496.58637±0.00000  bestvalidloss -1571.74067  last_update 24\n",
      "train: iter 759  trainloss -1590.34944  validloss -1533.29951±0.00000  bestvalidloss -1571.74067  last_update 25\n",
      "train: iter 760  trainloss -1570.18952  validloss -1370.53851±0.00000  bestvalidloss -1571.74067  last_update 26\n",
      "train: iter 761  trainloss -1475.72882  validloss -1451.32660±0.00000  bestvalidloss -1571.74067  last_update 27\n",
      "train: iter 762  trainloss -1556.00462  validloss -1478.60084±0.00000  bestvalidloss -1571.74067  last_update 28\n",
      "train: iter 763  trainloss -1603.10590  validloss -1262.62671±0.00000  bestvalidloss -1571.74067  last_update 29\n",
      "train: iter 764  trainloss -1573.00381  validloss -1508.30385±0.00000  bestvalidloss -1571.74067  last_update 30\n",
      "train: iter 765  trainloss -1612.64926  validloss -1506.97265±0.00000  bestvalidloss -1571.74067  last_update 31\n",
      "train: iter 766  trainloss -1573.90567  validloss -1496.19738±0.00000  bestvalidloss -1571.74067  last_update 32\n",
      "train: iter 767  trainloss -1591.61246  validloss -1501.40736±0.00000  bestvalidloss -1571.74067  last_update 33\n",
      "train: iter 768  trainloss -1640.08469  validloss -1449.21474±0.00000  bestvalidloss -1571.74067  last_update 34\n",
      "train: iter 769  trainloss -1384.16516  validloss -1402.41317±0.00000  bestvalidloss -1571.74067  last_update 35\n",
      "train: iter 770  trainloss -1515.75930  validloss -1139.23232±0.00000  bestvalidloss -1571.74067  last_update 36\n",
      "train: iter 771  trainloss -1591.20843  validloss -1465.74759±0.00000  bestvalidloss -1571.74067  last_update 37\n",
      "train: iter 772  trainloss -1606.27302  validloss -1519.72461±0.00000  bestvalidloss -1571.74067  last_update 38\n",
      "train: iter 773  trainloss -1625.01777  validloss -1487.41116±0.00000  bestvalidloss -1571.74067  last_update 39\n",
      "train: iter 774  trainloss -1617.77693  validloss -1555.54794±0.00000  bestvalidloss -1571.74067  last_update 40\n",
      "train: iter 775  trainloss -1612.35225  validloss -1495.00408±0.00000  bestvalidloss -1571.74067  last_update 41\n",
      "train: iter 776  trainloss -1576.91557  validloss -1512.70385±0.00000  bestvalidloss -1571.74067  last_update 42\n",
      "train: iter 777  trainloss -1571.31969  validloss -1468.68947±0.00000  bestvalidloss -1571.74067  last_update 43\n",
      "train: iter 778  trainloss -1654.52826  validloss -1508.18390±0.00000  bestvalidloss -1571.74067  last_update 44\n",
      "train: iter 779  trainloss -1419.04521  validloss -1451.22362±0.00000  bestvalidloss -1571.74067  last_update 45\n",
      "train: iter 780  trainloss -1520.38454  validloss -1056.76701±0.00000  bestvalidloss -1571.74067  last_update 46\n",
      "train: iter 781  trainloss -1624.72729  validloss -1502.17125±0.00000  bestvalidloss -1571.74067  last_update 47\n",
      "train: iter 782  trainloss -1637.28624  validloss -1542.24477±0.00000  bestvalidloss -1571.74067  last_update 48\n",
      "train: iter 783  trainloss -1448.35406  validloss -1552.68550±0.00000  bestvalidloss -1571.74067  last_update 49\n",
      "train: iter 784  trainloss -1595.35525  validloss -1465.94243±0.00000  bestvalidloss -1571.74067  last_update 50\n",
      "train: iter 785  trainloss -1639.58997  validloss -1520.22752±0.00000  bestvalidloss -1571.74067  last_update 51\n",
      "train: iter 786  trainloss -1617.16124  validloss -1418.25481±0.00000  bestvalidloss -1571.74067  last_update 52\n",
      "train: iter 787  trainloss -1614.97869  validloss -1500.21606±0.00000  bestvalidloss -1571.74067  last_update 53\n",
      "train: iter 788  trainloss -1602.86240  validloss -1512.55077±0.00000  bestvalidloss -1571.74067  last_update 54\n",
      "train: iter 789  trainloss -1628.83955  validloss -1497.43055±0.00000  bestvalidloss -1571.74067  last_update 55\n",
      "train: iter 790  trainloss -1622.93842  validloss -1573.18641±0.00000  bestvalidloss -1573.18641  last_update 0\n",
      "train: iter 791  trainloss -1644.97274  validloss -1482.79284±0.00000  bestvalidloss -1573.18641  last_update 1\n",
      "train: iter 792  trainloss -1642.56285  validloss -1569.48618±0.00000  bestvalidloss -1573.18641  last_update 2\n",
      "train: iter 793  trainloss -1393.14550  validloss -1215.69836±0.00000  bestvalidloss -1573.18641  last_update 3\n",
      "train: iter 794  trainloss -1621.77314  validloss -1464.96348±0.00000  bestvalidloss -1573.18641  last_update 4\n",
      "train: iter 795  trainloss -1638.86699  validloss -1490.07363±0.00000  bestvalidloss -1573.18641  last_update 5\n",
      "train: iter 796  trainloss -1640.59054  validloss -1526.73475±0.00000  bestvalidloss -1573.18641  last_update 6\n",
      "train: iter 797  trainloss -1659.09384  validloss -1538.58664±0.00000  bestvalidloss -1573.18641  last_update 7\n",
      "train: iter 798  trainloss -1411.66797  validloss -1597.83619±0.00000  bestvalidloss -1597.83619  last_update 0\n",
      "train: iter 799  trainloss -1472.49593  validloss -1366.99777±0.00000  bestvalidloss -1597.83619  last_update 1\n",
      "train: iter 800  trainloss -1610.89445  validloss -1426.66053±0.00000  bestvalidloss -1597.83619  last_update 2\n",
      "train: iter 801  trainloss -1565.82328  validloss -1521.33825±0.00000  bestvalidloss -1597.83619  last_update 3\n",
      "train: iter 802  trainloss -1642.57735  validloss -1422.33993±0.00000  bestvalidloss -1597.83619  last_update 4\n",
      "train: iter 803  trainloss -1623.86756  validloss -1552.46780±0.00000  bestvalidloss -1597.83619  last_update 5\n",
      "train: iter 804  trainloss -1642.92250  validloss -1482.44687±0.00000  bestvalidloss -1597.83619  last_update 6\n",
      "train: iter 805  trainloss -1606.01319  validloss -1550.09362±0.00000  bestvalidloss -1597.83619  last_update 7\n",
      "train: iter 806  trainloss -1609.85465  validloss -1492.83123±0.00000  bestvalidloss -1597.83619  last_update 8\n",
      "train: iter 807  trainloss -1512.29636  validloss -1522.75102±0.00000  bestvalidloss -1597.83619  last_update 9\n",
      "train: iter 808  trainloss -1628.07431  validloss -1373.29359±0.00000  bestvalidloss -1597.83619  last_update 10\n",
      "train: iter 809  trainloss -1643.96330  validloss -1466.52505±0.00000  bestvalidloss -1597.83619  last_update 11\n",
      "train: iter 810  trainloss -1493.48365  validloss -1556.16388±0.00000  bestvalidloss -1597.83619  last_update 12\n",
      "train: iter 811  trainloss -1407.48586  validloss 235.31057±0.00000  bestvalidloss -1597.83619  last_update 13\n",
      "train: iter 812  trainloss -1631.97789  validloss -1492.55907±0.00000  bestvalidloss -1597.83619  last_update 14\n",
      "train: iter 813  trainloss -1597.38898  validloss -1549.42545±0.00000  bestvalidloss -1597.83619  last_update 15\n",
      "train: iter 814  trainloss -1582.21968  validloss -1130.23829±0.00000  bestvalidloss -1597.83619  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 815  trainloss -1609.56259  validloss -1470.07310±0.00000  bestvalidloss -1597.83619  last_update 17\n",
      "train: iter 816  trainloss -1606.03743  validloss -1538.21648±0.00000  bestvalidloss -1597.83619  last_update 18\n",
      "train: iter 817  trainloss -1536.27304  validloss -1429.89264±0.00000  bestvalidloss -1597.83619  last_update 19\n",
      "train: iter 818  trainloss -1627.77669  validloss -1450.86417±0.00000  bestvalidloss -1597.83619  last_update 20\n",
      "train: iter 819  trainloss -1657.51322  validloss -1551.70655±0.00000  bestvalidloss -1597.83619  last_update 21\n",
      "train: iter 820  trainloss -1674.40149  validloss -1557.82600±0.00000  bestvalidloss -1597.83619  last_update 22\n",
      "train: iter 821  trainloss -1527.25594  validloss -1554.51194±0.00000  bestvalidloss -1597.83619  last_update 23\n",
      "train: iter 822  trainloss -1517.85128  validloss -1220.23063±0.00000  bestvalidloss -1597.83619  last_update 24\n",
      "train: iter 823  trainloss -1638.22470  validloss -1490.42378±0.00000  bestvalidloss -1597.83619  last_update 25\n",
      "train: iter 824  trainloss -1641.27314  validloss -1508.20582±0.00000  bestvalidloss -1597.83619  last_update 26\n",
      "train: iter 825  trainloss -1552.51803  validloss -1424.32051±0.00000  bestvalidloss -1597.83619  last_update 27\n",
      "train: iter 826  trainloss -1631.18138  validloss -1496.27684±0.00000  bestvalidloss -1597.83619  last_update 28\n",
      "train: iter 827  trainloss -1566.64324  validloss -1515.64093±0.00000  bestvalidloss -1597.83619  last_update 29\n",
      "train: iter 828  trainloss -1296.62059  validloss 146.92028±0.00000  bestvalidloss -1597.83619  last_update 30\n",
      "train: iter 829  trainloss -1567.93428  validloss -1386.85293±0.00000  bestvalidloss -1597.83619  last_update 31\n",
      "train: iter 830  trainloss -1619.14931  validloss -1544.04123±0.00000  bestvalidloss -1597.83619  last_update 32\n",
      "train: iter 831  trainloss -1643.77461  validloss -1526.77164±0.00000  bestvalidloss -1597.83619  last_update 33\n",
      "train: iter 832  trainloss -1649.53579  validloss -1549.57886±0.00000  bestvalidloss -1597.83619  last_update 34\n",
      "train: iter 833  trainloss -1600.67752  validloss -1474.98881±0.00000  bestvalidloss -1597.83619  last_update 35\n",
      "train: iter 834  trainloss -1499.87147  validloss -1218.10683±0.00000  bestvalidloss -1597.83619  last_update 36\n",
      "train: iter 835  trainloss -1631.21442  validloss -1559.17478±0.00000  bestvalidloss -1597.83619  last_update 37\n",
      "train: iter 836  trainloss -1617.61718  validloss -1424.06106±0.00000  bestvalidloss -1597.83619  last_update 38\n",
      "train: iter 837  trainloss -1657.68967  validloss -1510.34844±0.00000  bestvalidloss -1597.83619  last_update 39\n",
      "train: iter 838  trainloss -1519.79953  validloss -1468.77785±0.00000  bestvalidloss -1597.83619  last_update 40\n",
      "train: iter 839  trainloss -1628.27616  validloss -1455.73212±0.00000  bestvalidloss -1597.83619  last_update 41\n",
      "train: iter 840  trainloss -1627.74525  validloss -1549.02707±0.00000  bestvalidloss -1597.83619  last_update 42\n",
      "train: iter 841  trainloss -1592.54492  validloss -1486.39903±0.00000  bestvalidloss -1597.83619  last_update 43\n",
      "train: iter 842  trainloss -1574.46987  validloss -1131.34625±0.00000  bestvalidloss -1597.83619  last_update 44\n",
      "train: iter 843  trainloss -1665.44729  validloss -1530.31417±0.00000  bestvalidloss -1597.83619  last_update 45\n",
      "train: iter 844  trainloss -1632.07360  validloss -1581.02059±0.00000  bestvalidloss -1597.83619  last_update 46\n",
      "train: iter 845  trainloss -1604.18751  validloss -1517.62155±0.00000  bestvalidloss -1597.83619  last_update 47\n",
      "train: iter 846  trainloss -1647.24091  validloss -1485.56613±0.00000  bestvalidloss -1597.83619  last_update 48\n",
      "train: iter 847  trainloss -1646.88524  validloss -1600.64031±0.00000  bestvalidloss -1600.64031  last_update 0\n",
      "train: iter 848  trainloss -1609.03356  validloss -1575.99403±0.00000  bestvalidloss -1600.64031  last_update 1\n",
      "train: iter 849  trainloss -1655.89454  validloss -1533.44977±0.00000  bestvalidloss -1600.64031  last_update 2\n",
      "train: iter 850  trainloss -1612.39743  validloss -1565.21949±0.00000  bestvalidloss -1600.64031  last_update 3\n",
      "train: iter 851  trainloss -1535.03702  validloss -1345.39846±0.00000  bestvalidloss -1600.64031  last_update 4\n",
      "train: iter 852  trainloss -1574.82430  validloss -1501.13537±0.00000  bestvalidloss -1600.64031  last_update 5\n",
      "train: iter 853  trainloss -1334.07601  validloss -1292.71610±0.00000  bestvalidloss -1600.64031  last_update 6\n",
      "train: iter 854  trainloss -1589.72529  validloss -1302.97662±0.00000  bestvalidloss -1600.64031  last_update 7\n",
      "train: iter 855  trainloss -1603.73574  validloss -1545.85512±0.00000  bestvalidloss -1600.64031  last_update 8\n",
      "train: iter 856  trainloss -1632.65982  validloss -1479.82111±0.00000  bestvalidloss -1600.64031  last_update 9\n",
      "train: iter 857  trainloss -1592.75074  validloss -1421.24678±0.00000  bestvalidloss -1600.64031  last_update 10\n",
      "train: iter 858  trainloss -1656.37101  validloss -1582.90172±0.00000  bestvalidloss -1600.64031  last_update 11\n",
      "train: iter 859  trainloss -1651.90432  validloss -1591.70012±0.00000  bestvalidloss -1600.64031  last_update 12\n",
      "train: iter 860  trainloss -1637.10893  validloss -1544.31664±0.00000  bestvalidloss -1600.64031  last_update 13\n",
      "train: iter 861  trainloss -1653.39557  validloss -1559.00579±0.00000  bestvalidloss -1600.64031  last_update 14\n",
      "train: iter 862  trainloss -1595.82879  validloss -1459.49463±0.00000  bestvalidloss -1600.64031  last_update 15\n",
      "train: iter 863  trainloss -1659.61619  validloss -1515.98512±0.00000  bestvalidloss -1600.64031  last_update 16\n",
      "train: iter 864  trainloss -1567.40570  validloss -1595.40190±0.00000  bestvalidloss -1600.64031  last_update 17\n",
      "train: iter 865  trainloss -1604.22881  validloss -1522.67081±0.00000  bestvalidloss -1600.64031  last_update 18\n",
      "train: iter 866  trainloss -1583.27351  validloss -1337.14022±0.00000  bestvalidloss -1600.64031  last_update 19\n",
      "train: iter 867  trainloss -1645.28873  validloss -1511.04346±0.00000  bestvalidloss -1600.64031  last_update 20\n",
      "train: iter 868  trainloss -1506.24975  validloss -1540.98497±0.00000  bestvalidloss -1600.64031  last_update 21\n",
      "train: iter 869  trainloss -1604.80079  validloss -1350.87250±0.00000  bestvalidloss -1600.64031  last_update 22\n",
      "train: iter 870  trainloss -1654.26288  validloss -1519.58520±0.00000  bestvalidloss -1600.64031  last_update 23\n",
      "train: iter 871  trainloss -1593.27217  validloss -1501.89614±0.00000  bestvalidloss -1600.64031  last_update 24\n",
      "train: iter 872  trainloss -1657.82629  validloss -1496.71517±0.00000  bestvalidloss -1600.64031  last_update 25\n",
      "train: iter 873  trainloss -1669.16873  validloss -1583.89912±0.00000  bestvalidloss -1600.64031  last_update 26\n",
      "train: iter 874  trainloss -1594.83490  validloss -1573.76621±0.00000  bestvalidloss -1600.64031  last_update 27\n",
      "train: iter 875  trainloss -1631.94907  validloss -1417.13263±0.00000  bestvalidloss -1600.64031  last_update 28\n",
      "train: iter 876  trainloss -1616.49160  validloss -1486.22990±0.00000  bestvalidloss -1600.64031  last_update 29\n",
      "train: iter 877  trainloss -1610.91166  validloss -1526.89193±0.00000  bestvalidloss -1600.64031  last_update 30\n",
      "train: iter 878  trainloss -1529.10973  validloss -1498.50663±0.00000  bestvalidloss -1600.64031  last_update 31\n",
      "train: iter 879  trainloss -1654.12409  validloss -1517.13544±0.00000  bestvalidloss -1600.64031  last_update 32\n",
      "train: iter 880  trainloss -1677.94645  validloss -1583.23456±0.00000  bestvalidloss -1600.64031  last_update 33\n",
      "train: iter 881  trainloss -1614.27646  validloss -1583.68143±0.00000  bestvalidloss -1600.64031  last_update 34\n",
      "train: iter 882  trainloss -1430.10931  validloss -948.49391±0.00000  bestvalidloss -1600.64031  last_update 35\n",
      "train: iter 883  trainloss -1651.15640  validloss -1504.49345±0.00000  bestvalidloss -1600.64031  last_update 36\n",
      "train: iter 884  trainloss -1668.99920  validloss -1580.35006±0.00000  bestvalidloss -1600.64031  last_update 37\n",
      "train: iter 885  trainloss -1616.08592  validloss -1560.90381±0.00000  bestvalidloss -1600.64031  last_update 38\n",
      "train: iter 886  trainloss -1591.79400  validloss -1463.20663±0.00000  bestvalidloss -1600.64031  last_update 39\n",
      "train: iter 887  trainloss -1577.99320  validloss -1508.34580±0.00000  bestvalidloss -1600.64031  last_update 40\n",
      "train: iter 888  trainloss -1663.10501  validloss -1579.63362±0.00000  bestvalidloss -1600.64031  last_update 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 889  trainloss -1607.34952  validloss -1499.40661±0.00000  bestvalidloss -1600.64031  last_update 42\n",
      "train: iter 890  trainloss -1676.18766  validloss -1515.51402±0.00000  bestvalidloss -1600.64031  last_update 43\n",
      "train: iter 891  trainloss -1537.10923  validloss -1392.90794±0.00000  bestvalidloss -1600.64031  last_update 44\n",
      "train: iter 892  trainloss -1630.46935  validloss -1507.75667±0.00000  bestvalidloss -1600.64031  last_update 45\n",
      "train: iter 893  trainloss -1642.37918  validloss -1538.80390±0.00000  bestvalidloss -1600.64031  last_update 46\n",
      "train: iter 894  trainloss -1675.05644  validloss -1508.76505±0.00000  bestvalidloss -1600.64031  last_update 47\n",
      "train: iter 895  trainloss -1678.15867  validloss -1599.18747±0.00000  bestvalidloss -1600.64031  last_update 48\n",
      "train: iter 896  trainloss -1561.84812  validloss -1552.54015±0.00000  bestvalidloss -1600.64031  last_update 49\n",
      "train: iter 897  trainloss -1557.72708  validloss -1349.60877±0.00000  bestvalidloss -1600.64031  last_update 50\n",
      "train: iter 898  trainloss -1668.41488  validloss -1501.49983±0.00000  bestvalidloss -1600.64031  last_update 51\n",
      "train: iter 899  trainloss -1608.46246  validloss -1425.25883±0.00000  bestvalidloss -1600.64031  last_update 52\n",
      "train: iter 900  trainloss -1609.40287  validloss -1392.12366±0.00000  bestvalidloss -1600.64031  last_update 53\n",
      "train: iter 901  trainloss -1604.61287  validloss -1378.86106±0.00000  bestvalidloss -1600.64031  last_update 54\n",
      "train: iter 902  trainloss -1645.14971  validloss -1467.52379±0.00000  bestvalidloss -1600.64031  last_update 55\n",
      "train: iter 903  trainloss -1292.48616  validloss -1454.96739±0.00000  bestvalidloss -1600.64031  last_update 56\n",
      "train: iter 904  trainloss -1606.36366  validloss -1359.36851±0.00000  bestvalidloss -1600.64031  last_update 57\n",
      "train: iter 905  trainloss -1671.77452  validloss -1561.28780±0.00000  bestvalidloss -1600.64031  last_update 58\n",
      "train: iter 906  trainloss -1534.88873  validloss -1551.89835±0.00000  bestvalidloss -1600.64031  last_update 59\n",
      "train: iter 907  trainloss -1606.29284  validloss -1363.39303±0.00000  bestvalidloss -1600.64031  last_update 60\n",
      "train: iter 908  trainloss -1651.72396  validloss -1544.29278±0.00000  bestvalidloss -1600.64031  last_update 61\n",
      "train: iter 909  trainloss -1649.78309  validloss -1548.64064±0.00000  bestvalidloss -1600.64031  last_update 62\n",
      "train: iter 910  trainloss -1674.97349  validloss -1514.79388±0.00000  bestvalidloss -1600.64031  last_update 63\n",
      "train: iter 911  trainloss -1681.12975  validloss -1600.02037±0.00000  bestvalidloss -1600.64031  last_update 64\n",
      "train: iter 912  trainloss -1613.39914  validloss -1588.18430±0.00000  bestvalidloss -1600.64031  last_update 65\n",
      "train: iter 913  trainloss -1438.70586  validloss -853.62831±0.00000  bestvalidloss -1600.64031  last_update 66\n",
      "train: iter 914  trainloss -1609.64945  validloss -1404.02727±0.00000  bestvalidloss -1600.64031  last_update 67\n",
      "train: iter 915  trainloss -1655.82657  validloss -1552.01403±0.00000  bestvalidloss -1600.64031  last_update 68\n",
      "train: iter 916  trainloss -1524.01287  validloss -1503.99791±0.00000  bestvalidloss -1600.64031  last_update 69\n",
      "train: iter 917  trainloss -1635.79077  validloss -1424.14495±0.00000  bestvalidloss -1600.64031  last_update 70\n",
      "train: iter 918  trainloss -1686.40683  validloss -1568.16976±0.00000  bestvalidloss -1600.64031  last_update 71\n",
      "train: iter 919  trainloss -1685.86281  validloss -1558.58973±0.00000  bestvalidloss -1600.64031  last_update 72\n",
      "train: iter 920  trainloss -1663.58427  validloss -1516.25371±0.00000  bestvalidloss -1600.64031  last_update 73\n",
      "train: iter 921  trainloss -1675.39646  validloss -1526.80396±0.00000  bestvalidloss -1600.64031  last_update 74\n",
      "train: iter 922  trainloss -1400.34553  validloss -1483.44129±0.00000  bestvalidloss -1600.64031  last_update 75\n",
      "train: iter 923  trainloss -1457.92040  validloss -1468.21242±0.00000  bestvalidloss -1600.64031  last_update 76\n",
      "train: iter 924  trainloss -1627.00081  validloss -1509.92724±0.00000  bestvalidloss -1600.64031  last_update 77\n",
      "train: iter 925  trainloss -1663.35879  validloss -1558.92164±0.00000  bestvalidloss -1600.64031  last_update 78\n",
      "train: iter 926  trainloss -1571.52537  validloss -1577.46692±0.00000  bestvalidloss -1600.64031  last_update 79\n",
      "train: iter 927  trainloss -1616.12947  validloss -1542.57541±0.00000  bestvalidloss -1600.64031  last_update 80\n",
      "train: iter 928  trainloss -1635.31439  validloss -1437.14492±0.00000  bestvalidloss -1600.64031  last_update 81\n",
      "train: iter 929  trainloss -1644.80845  validloss -1542.74960±0.00000  bestvalidloss -1600.64031  last_update 82\n",
      "train: iter 930  trainloss -1681.40545  validloss -1555.93039±0.00000  bestvalidloss -1600.64031  last_update 83\n",
      "train: iter 931  trainloss -1612.20726  validloss -1595.49776±0.00000  bestvalidloss -1600.64031  last_update 84\n",
      "train: iter 932  trainloss -1674.15836  validloss -1507.58882±0.00000  bestvalidloss -1600.64031  last_update 85\n",
      "train: iter 933  trainloss -1617.32500  validloss -1539.85703±0.00000  bestvalidloss -1600.64031  last_update 86\n",
      "train: iter 934  trainloss -1427.95468  validloss -572.11778±0.00000  bestvalidloss -1600.64031  last_update 87\n",
      "train: iter 935  trainloss -1647.45893  validloss -1498.38634±0.00000  bestvalidloss -1600.64031  last_update 88\n",
      "train: iter 936  trainloss -1676.13311  validloss -1563.47093±0.00000  bestvalidloss -1600.64031  last_update 89\n",
      "train: iter 937  trainloss -1661.70322  validloss -1528.33814±0.00000  bestvalidloss -1600.64031  last_update 90\n",
      "train: iter 938  trainloss -1670.92464  validloss -1575.55074±0.00000  bestvalidloss -1600.64031  last_update 91\n",
      "train: iter 939  trainloss -1682.19548  validloss -1595.22133±0.00000  bestvalidloss -1600.64031  last_update 92\n",
      "train: iter 940  trainloss -1662.21063  validloss -1387.71649±0.00000  bestvalidloss -1600.64031  last_update 93\n",
      "train: iter 941  trainloss -1454.61407  validloss -1380.35103±0.00000  bestvalidloss -1600.64031  last_update 94\n",
      "train: iter 942  trainloss -1671.08911  validloss -1484.80518±0.00000  bestvalidloss -1600.64031  last_update 95\n",
      "train: iter 943  trainloss -1675.31266  validloss -1524.49391±0.00000  bestvalidloss -1600.64031  last_update 96\n",
      "train: iter 944  trainloss -1640.55370  validloss -1432.85076±0.00000  bestvalidloss -1600.64031  last_update 97\n",
      "train: iter 945  trainloss -1692.94981  validloss -1607.15117±0.00000  bestvalidloss -1607.15117  last_update 0\n",
      "train: iter 946  trainloss -1686.39400  validloss -1572.61426±0.00000  bestvalidloss -1607.15117  last_update 1\n",
      "train: iter 947  trainloss -1560.32109  validloss -1376.98886±0.00000  bestvalidloss -1607.15117  last_update 2\n",
      "train: iter 948  trainloss -1533.93099  validloss -967.63587±0.00000  bestvalidloss -1607.15117  last_update 3\n",
      "train: iter 949  trainloss -1654.71508  validloss -1540.98694±0.00000  bestvalidloss -1607.15117  last_update 4\n",
      "train: iter 950  trainloss -1664.91357  validloss -1565.28145±0.00000  bestvalidloss -1607.15117  last_update 5\n",
      "train: iter 951  trainloss -1669.50488  validloss -1542.43371±0.00000  bestvalidloss -1607.15117  last_update 6\n",
      "train: iter 952  trainloss -1684.75592  validloss -1589.13691±0.00000  bestvalidloss -1607.15117  last_update 7\n",
      "train: iter 953  trainloss -1673.24348  validloss -1504.47053±0.00000  bestvalidloss -1607.15117  last_update 8\n",
      "train: iter 954  trainloss -1689.68485  validloss -1587.91574±0.00000  bestvalidloss -1607.15117  last_update 9\n",
      "train: iter 955  trainloss -1661.45519  validloss -1563.44807±0.00000  bestvalidloss -1607.15117  last_update 10\n",
      "train: iter 956  trainloss -1396.38763  validloss -1435.03570±0.00000  bestvalidloss -1607.15117  last_update 11\n",
      "train: iter 957  trainloss -1612.04556  validloss -1478.13643±0.00000  bestvalidloss -1607.15117  last_update 12\n",
      "train: iter 958  trainloss -1622.56926  validloss -1485.18267±0.00000  bestvalidloss -1607.15117  last_update 13\n",
      "train: iter 959  trainloss -1687.08802  validloss -1528.73957±0.00000  bestvalidloss -1607.15117  last_update 14\n",
      "train: iter 960  trainloss -1680.80569  validloss -1596.43268±0.00000  bestvalidloss -1607.15117  last_update 15\n",
      "train: iter 961  trainloss -1694.64314  validloss -1572.58851±0.00000  bestvalidloss -1607.15117  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 962  trainloss -1589.26547  validloss -1524.03141±0.00000  bestvalidloss -1607.15117  last_update 17\n",
      "train: iter 963  trainloss -1401.60263  validloss -825.47581±0.00000  bestvalidloss -1607.15117  last_update 18\n",
      "train: iter 964  trainloss -1649.78081  validloss -1484.17258±0.00000  bestvalidloss -1607.15117  last_update 19\n",
      "train: iter 965  trainloss -1456.89028  validloss -1562.57992±0.00000  bestvalidloss -1607.15117  last_update 20\n",
      "train: iter 966  trainloss -1612.84868  validloss -1263.41895±0.00000  bestvalidloss -1607.15117  last_update 21\n",
      "train: iter 967  trainloss -1657.44645  validloss -1542.06103±0.00000  bestvalidloss -1607.15117  last_update 22\n",
      "train: iter 968  trainloss -1683.41562  validloss -1550.03715±0.00000  bestvalidloss -1607.15117  last_update 23\n",
      "train: iter 969  trainloss -1682.78482  validloss -1530.89238±0.00000  bestvalidloss -1607.15117  last_update 24\n",
      "train: iter 970  trainloss -1663.80092  validloss -1501.18121±0.00000  bestvalidloss -1607.15117  last_update 25\n",
      "train: iter 971  trainloss -1693.51807  validloss -1537.41541±0.00000  bestvalidloss -1607.15117  last_update 26\n",
      "train: iter 972  trainloss -1671.83024  validloss -1604.39450±0.00000  bestvalidloss -1607.15117  last_update 27\n",
      "train: iter 973  trainloss -1598.82613  validloss -1552.82389±0.00000  bestvalidloss -1607.15117  last_update 28\n",
      "train: iter 974  trainloss -1691.67664  validloss -1537.76142±0.00000  bestvalidloss -1607.15117  last_update 29\n",
      "train: iter 975  trainloss -1673.84403  validloss -1581.95613±0.00000  bestvalidloss -1607.15117  last_update 30\n",
      "train: iter 976  trainloss -1637.72958  validloss -1568.17164±0.00000  bestvalidloss -1607.15117  last_update 31\n",
      "train: iter 977  trainloss -1699.40245  validloss -1559.29805±0.00000  bestvalidloss -1607.15117  last_update 32\n",
      "train: iter 978  trainloss -1691.05636  validloss -1581.16794±0.00000  bestvalidloss -1607.15117  last_update 33\n",
      "train: iter 979  trainloss -1665.98663  validloss -1580.72486±0.00000  bestvalidloss -1607.15117  last_update 34\n",
      "train: iter 980  trainloss -1464.10939  validloss -1444.78773±0.00000  bestvalidloss -1607.15117  last_update 35\n",
      "train: iter 981  trainloss -1519.31431  validloss -1142.48142±0.00000  bestvalidloss -1607.15117  last_update 36\n",
      "train: iter 982  trainloss -1618.32101  validloss -1513.21477±0.00000  bestvalidloss -1607.15117  last_update 37\n",
      "train: iter 983  trainloss -1667.36981  validloss -1512.43181±0.00000  bestvalidloss -1607.15117  last_update 38\n",
      "train: iter 984  trainloss -1669.96897  validloss -1467.57840±0.00000  bestvalidloss -1607.15117  last_update 39\n",
      "train: iter 985  trainloss -1605.50171  validloss -1568.54323±0.00000  bestvalidloss -1607.15117  last_update 40\n",
      "train: iter 986  trainloss -1660.82954  validloss -1430.82083±0.00000  bestvalidloss -1607.15117  last_update 41\n",
      "train: iter 987  trainloss -1681.45572  validloss -1552.18041±0.00000  bestvalidloss -1607.15117  last_update 42\n",
      "train: iter 988  trainloss -1708.67741  validloss -1599.03833±0.00000  bestvalidloss -1607.15117  last_update 43\n",
      "train: iter 989  trainloss -1672.98099  validloss -1588.52214±0.00000  bestvalidloss -1607.15117  last_update 44\n",
      "train: iter 990  trainloss -1671.76360  validloss -1551.20378±0.00000  bestvalidloss -1607.15117  last_update 45\n",
      "train: iter 991  trainloss -1647.36544  validloss -1498.07766±0.00000  bestvalidloss -1607.15117  last_update 46\n",
      "train: iter 992  trainloss -1621.43946  validloss -1585.89289±0.00000  bestvalidloss -1607.15117  last_update 47\n",
      "train: iter 993  trainloss -1475.99418  validloss -1349.51653±0.00000  bestvalidloss -1607.15117  last_update 48\n",
      "train: iter 994  trainloss -1644.42808  validloss -1455.11705±0.00000  bestvalidloss -1607.15117  last_update 49\n",
      "train: iter 995  trainloss -1692.85190  validloss -1548.37429±0.00000  bestvalidloss -1607.15117  last_update 50\n",
      "train: iter 996  trainloss -1677.94014  validloss -1551.97020±0.00000  bestvalidloss -1607.15117  last_update 51\n",
      "train: iter 997  trainloss -1547.78979  validloss -1560.27937±0.00000  bestvalidloss -1607.15117  last_update 52\n",
      "train: iter 998  trainloss -1667.20424  validloss -1554.63866±0.00000  bestvalidloss -1607.15117  last_update 53\n",
      "train: iter 999  trainloss -1644.27916  validloss -1561.22523±0.00000  bestvalidloss -1607.15117  last_update 54\n",
      "train: iter 1000  trainloss -1700.14824  validloss -1596.34570±0.00000  bestvalidloss -1607.15117  last_update 55\n",
      "train: iter 1001  trainloss -1624.58791  validloss -1584.80551±0.00000  bestvalidloss -1607.15117  last_update 56\n",
      "train: iter 1002  trainloss -1623.43793  validloss -1389.24658±0.00000  bestvalidloss -1607.15117  last_update 57\n",
      "train: iter 1003  trainloss -1704.23162  validloss -1555.55332±0.00000  bestvalidloss -1607.15117  last_update 58\n",
      "train: iter 1004  trainloss -1673.32461  validloss -1584.92932±0.00000  bestvalidloss -1607.15117  last_update 59\n",
      "train: iter 1005  trainloss -1604.22169  validloss -1544.64485±0.00000  bestvalidloss -1607.15117  last_update 60\n",
      "train: iter 1006  trainloss -1298.94641  validloss -1194.24299±0.00000  bestvalidloss -1607.15117  last_update 61\n",
      "train: iter 1007  trainloss -1623.29492  validloss -1420.14688±0.00000  bestvalidloss -1607.15117  last_update 62\n",
      "train: iter 1008  trainloss -1666.60309  validloss -1494.57993±0.00000  bestvalidloss -1607.15117  last_update 63\n",
      "train: iter 1009  trainloss -1686.49899  validloss -1566.98790±0.00000  bestvalidloss -1607.15117  last_update 64\n",
      "train: iter 1010  trainloss -1624.61665  validloss -1532.36303±0.00000  bestvalidloss -1607.15117  last_update 65\n",
      "train: iter 1011  trainloss -1641.48576  validloss -1481.39055±0.00000  bestvalidloss -1607.15117  last_update 66\n",
      "train: iter 1012  trainloss -1683.51330  validloss -1527.38155±0.00000  bestvalidloss -1607.15117  last_update 67\n",
      "train: iter 1013  trainloss -1624.61081  validloss -1563.99885±0.00000  bestvalidloss -1607.15117  last_update 68\n",
      "train: iter 1014  trainloss -1673.30479  validloss -1349.16176±0.00000  bestvalidloss -1607.15117  last_update 69\n",
      "train: iter 1015  trainloss -1695.80788  validloss -1578.82171±0.00000  bestvalidloss -1607.15117  last_update 70\n",
      "train: iter 1016  trainloss -1672.53429  validloss -1449.88876±0.00000  bestvalidloss -1607.15117  last_update 71\n",
      "train: iter 1017  trainloss -1670.04650  validloss -1562.98857±0.00000  bestvalidloss -1607.15117  last_update 72\n",
      "train: iter 1018  trainloss -1666.75572  validloss -1571.76995±0.00000  bestvalidloss -1607.15117  last_update 73\n",
      "train: iter 1019  trainloss -1534.81536  validloss -1503.12154±0.00000  bestvalidloss -1607.15117  last_update 74\n",
      "train: iter 1020  trainloss -1655.92879  validloss -1355.78222±0.00000  bestvalidloss -1607.15117  last_update 75\n",
      "train: iter 1021  trainloss -1696.62907  validloss -1525.19467±0.00000  bestvalidloss -1607.15117  last_update 76\n",
      "train: iter 1022  trainloss -1654.12479  validloss -1553.71903±0.00000  bestvalidloss -1607.15117  last_update 77\n",
      "train: iter 1023  trainloss -1671.53695  validloss -1412.33633±0.00000  bestvalidloss -1607.15117  last_update 78\n",
      "train: iter 1024  trainloss -1632.98607  validloss -1451.29161±0.00000  bestvalidloss -1607.15117  last_update 79\n",
      "train: iter 1025  trainloss -1618.22298  validloss -1439.46223±0.00000  bestvalidloss -1607.15117  last_update 80\n",
      "train: iter 1026  trainloss -1618.56638  validloss -1529.53881±0.00000  bestvalidloss -1607.15117  last_update 81\n",
      "train: iter 1027  trainloss -1663.90881  validloss -1434.13969±0.00000  bestvalidloss -1607.15117  last_update 82\n",
      "train: iter 1028  trainloss -1712.33272  validloss -1592.26889±0.00000  bestvalidloss -1607.15117  last_update 83\n",
      "train: iter 1029  trainloss -1700.85911  validloss -1575.31122±0.00000  bestvalidloss -1607.15117  last_update 84\n",
      "train: iter 1030  trainloss -1627.25246  validloss -1500.52888±0.00000  bestvalidloss -1607.15117  last_update 85\n",
      "train: iter 1031  trainloss -1646.38549  validloss -1472.27122±0.00000  bestvalidloss -1607.15117  last_update 86\n",
      "train: iter 1032  trainloss -1624.23629  validloss -1566.61465±0.00000  bestvalidloss -1607.15117  last_update 87\n",
      "train: iter 1033  trainloss -1668.82909  validloss -1532.34332±0.00000  bestvalidloss -1607.15117  last_update 88\n",
      "train: iter 1034  trainloss -1678.66978  validloss -1552.20641±0.00000  bestvalidloss -1607.15117  last_update 89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 1035  trainloss -1646.77834  validloss -1553.45377±0.00000  bestvalidloss -1607.15117  last_update 90\n",
      "train: iter 1036  trainloss -1576.01763  validloss -1155.44619±0.00000  bestvalidloss -1607.15117  last_update 91\n",
      "train: iter 1037  trainloss -1610.04392  validloss -1503.17660±0.00000  bestvalidloss -1607.15117  last_update 92\n",
      "train: iter 1038  trainloss -1589.21689  validloss -1580.22473±0.00000  bestvalidloss -1607.15117  last_update 93\n",
      "train: iter 1039  trainloss -1683.80989  validloss -1523.87525±0.00000  bestvalidloss -1607.15117  last_update 94\n",
      "train: iter 1040  trainloss -1707.18829  validloss -1569.88811±0.00000  bestvalidloss -1607.15117  last_update 95\n",
      "train: iter 1041  trainloss -1641.14280  validloss -1558.65208±0.00000  bestvalidloss -1607.15117  last_update 96\n",
      "train: iter 1042  trainloss -1689.33472  validloss -1411.19779±0.00000  bestvalidloss -1607.15117  last_update 97\n",
      "train: iter 1043  trainloss -1697.44818  validloss -1587.93568±0.00000  bestvalidloss -1607.15117  last_update 98\n",
      "train: iter 1044  trainloss -1569.56989  validloss -1572.50760±0.00000  bestvalidloss -1607.15117  last_update 99\n",
      "train: iter 1045  trainloss -1553.11401  validloss -1483.34786±0.00000  bestvalidloss -1607.15117  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.8139) penalty_target_max tensor(13.0874)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.16020  validloss 4.30763±0.00000  bestvalidloss 4.30763  last_update 0\n",
      "train: iter 1  trainloss 3.87438  validloss 3.99484±0.00000  bestvalidloss 3.99484  last_update 0\n",
      "train: iter 2  trainloss 3.64103  validloss 3.72676±0.00000  bestvalidloss 3.72676  last_update 0\n",
      "train: iter 3  trainloss 3.45412  validloss 3.54625±0.00000  bestvalidloss 3.54625  last_update 0\n",
      "train: iter 4  trainloss 3.29190  validloss 3.35045±0.00000  bestvalidloss 3.35045  last_update 0\n",
      "train: iter 5  trainloss 3.13816  validloss 3.19628±0.00000  bestvalidloss 3.19628  last_update 0\n",
      "train: iter 6  trainloss 3.00884  validloss 3.06836±0.00000  bestvalidloss 3.06836  last_update 0\n",
      "train: iter 7  trainloss 2.88014  validloss 2.94116±0.00000  bestvalidloss 2.94116  last_update 0\n",
      "train: iter 8  trainloss 2.75669  validloss 2.81035±0.00000  bestvalidloss 2.81035  last_update 0\n",
      "train: iter 9  trainloss 2.63643  validloss 2.68751±0.00000  bestvalidloss 2.68751  last_update 0\n",
      "train: iter 10  trainloss 2.52862  validloss 2.57105±0.00000  bestvalidloss 2.57105  last_update 0\n",
      "train: iter 11  trainloss 2.40647  validloss 2.45380±0.00000  bestvalidloss 2.45380  last_update 0\n",
      "train: iter 12  trainloss 2.29498  validloss 2.33855±0.00000  bestvalidloss 2.33855  last_update 0\n",
      "train: iter 13  trainloss 2.18296  validloss 2.22018±0.00000  bestvalidloss 2.22018  last_update 0\n",
      "train: iter 14  trainloss 2.06970  validloss 2.10778±0.00000  bestvalidloss 2.10778  last_update 0\n",
      "train: iter 15  trainloss 1.96628  validloss 1.99874±0.00000  bestvalidloss 1.99874  last_update 0\n",
      "train: iter 16  trainloss 1.86611  validloss 1.89257±0.00000  bestvalidloss 1.89257  last_update 0\n",
      "train: iter 17  trainloss 1.76539  validloss 1.79648±0.00000  bestvalidloss 1.79648  last_update 0\n",
      "train: iter 18  trainloss 1.67171  validloss 1.69525±0.00000  bestvalidloss 1.69525  last_update 0\n",
      "train: iter 19  trainloss 1.57653  validloss 1.61001±0.00000  bestvalidloss 1.61001  last_update 0\n",
      "train: iter 20  trainloss 1.48098  validloss 1.50946±0.00000  bestvalidloss 1.50946  last_update 0\n",
      "train: iter 21  trainloss 1.38880  validloss 1.40566±0.00000  bestvalidloss 1.40566  last_update 0\n",
      "train: iter 22  trainloss 1.30207  validloss 1.30778±0.00000  bestvalidloss 1.30778  last_update 0\n",
      "train: iter 23  trainloss 1.21005  validloss 1.21407±0.00000  bestvalidloss 1.21407  last_update 0\n",
      "train: iter 24  trainloss 1.12241  validloss 1.12717±0.00000  bestvalidloss 1.12717  last_update 0\n",
      "train: iter 25  trainloss 1.03154  validloss 1.02712±0.00000  bestvalidloss 1.02712  last_update 0\n",
      "train: iter 26  trainloss 0.94755  validloss 0.92582±0.00000  bestvalidloss 0.92582  last_update 0\n",
      "train: iter 27  trainloss 0.86257  validloss 0.83535±0.00000  bestvalidloss 0.83535  last_update 0\n",
      "train: iter 28  trainloss 0.77028  validloss 0.74316±0.00000  bestvalidloss 0.74316  last_update 0\n",
      "train: iter 29  trainloss 0.70168  validloss 0.67145±0.00000  bestvalidloss 0.67145  last_update 0\n",
      "train: iter 30  trainloss 0.62920  validloss 0.57581±0.00000  bestvalidloss 0.57581  last_update 0\n",
      "train: iter 31  trainloss 0.55340  validloss 0.51799±0.00000  bestvalidloss 0.51799  last_update 0\n",
      "train: iter 32  trainloss 0.47848  validloss 0.44874±0.00000  bestvalidloss 0.44874  last_update 0\n",
      "train: iter 33  trainloss 0.43157  validloss 0.35579±0.00000  bestvalidloss 0.35579  last_update 0\n",
      "train: iter 34  trainloss 0.37836  validloss 0.30393±0.00000  bestvalidloss 0.30393  last_update 0\n",
      "train: iter 35  trainloss 0.32611  validloss 0.25113±0.00000  bestvalidloss 0.25113  last_update 0\n",
      "train: iter 36  trainloss 0.26446  validloss 0.18803±0.00000  bestvalidloss 0.18803  last_update 0\n",
      "train: iter 37  trainloss 0.22141  validloss 0.13403±0.00000  bestvalidloss 0.13403  last_update 0\n",
      "train: iter 38  trainloss 0.17370  validloss 0.06587±0.00000  bestvalidloss 0.06587  last_update 0\n",
      "train: iter 39  trainloss 0.10088  validloss 0.01442±0.00000  bestvalidloss 0.01442  last_update 0\n",
      "train: iter 40  trainloss 0.09031  validloss -0.02765±0.00000  bestvalidloss -0.02765  last_update 0\n",
      "train: iter 41  trainloss 0.04811  validloss -0.06026±0.00000  bestvalidloss -0.06026  last_update 0\n",
      "train: iter 42  trainloss 0.00957  validloss -0.12594±0.00000  bestvalidloss -0.12594  last_update 0\n",
      "train: iter 43  trainloss -0.00277  validloss -0.15616±0.00000  bestvalidloss -0.15616  last_update 0\n",
      "train: iter 44  trainloss -0.05200  validloss -0.20530±0.00000  bestvalidloss -0.20530  last_update 0\n",
      "train: iter 45  trainloss -0.07799  validloss -0.23819±0.00000  bestvalidloss -0.23819  last_update 0\n",
      "train: iter 46  trainloss -0.12147  validloss -0.29431±0.00000  bestvalidloss -0.29431  last_update 0\n",
      "train: iter 47  trainloss -0.13503  validloss -0.29591±0.00000  bestvalidloss -0.29591  last_update 0\n",
      "train: iter 48  trainloss -0.17941  validloss -0.29287±0.00000  bestvalidloss -0.29591  last_update 1\n",
      "train: iter 49  trainloss -0.19056  validloss -0.34138±0.00000  bestvalidloss -0.34138  last_update 0\n",
      "train: iter 50  trainloss -0.16488  validloss -0.40176±0.00000  bestvalidloss -0.40176  last_update 0\n",
      "train: iter 51  trainloss -0.22201  validloss -0.41705±0.00000  bestvalidloss -0.41705  last_update 0\n",
      "train: iter 52  trainloss -0.22201  validloss -0.46797±0.00000  bestvalidloss -0.46797  last_update 0\n",
      "train: iter 53  trainloss -0.25970  validloss -0.52672±0.00000  bestvalidloss -0.52672  last_update 0\n",
      "train: iter 54  trainloss -0.24116  validloss -0.52547±0.00000  bestvalidloss -0.52672  last_update 1\n",
      "train: iter 55  trainloss -0.27607  validloss -0.50898±0.00000  bestvalidloss -0.52672  last_update 2\n",
      "train: iter 56  trainloss -0.29783  validloss -0.51499±0.00000  bestvalidloss -0.52672  last_update 3\n",
      "train: iter 57  trainloss -0.31140  validloss -0.51358±0.00000  bestvalidloss -0.52672  last_update 4\n",
      "train: iter 58  trainloss -0.30498  validloss -0.54523±0.00000  bestvalidloss -0.54523  last_update 0\n",
      "train: iter 59  trainloss -0.35478  validloss -0.53920±0.00000  bestvalidloss -0.54523  last_update 1\n",
      "train: iter 60  trainloss -0.30658  validloss -0.60687±0.00000  bestvalidloss -0.60687  last_update 0\n",
      "train: iter 61  trainloss -0.33135  validloss -0.63404±0.00000  bestvalidloss -0.63404  last_update 0\n",
      "train: iter 62  trainloss -0.33756  validloss -0.60653±0.00000  bestvalidloss -0.63404  last_update 1\n",
      "train: iter 63  trainloss -0.35907  validloss -0.64233±0.00000  bestvalidloss -0.64233  last_update 0\n",
      "train: iter 64  trainloss -0.34310  validloss -0.63258±0.00000  bestvalidloss -0.64233  last_update 1\n",
      "train: iter 65  trainloss -0.35629  validloss -0.65029±0.00000  bestvalidloss -0.65029  last_update 0\n",
      "train: iter 66  trainloss -0.35101  validloss -0.63303±0.00000  bestvalidloss -0.65029  last_update 1\n",
      "train: iter 67  trainloss -0.35765  validloss -0.71050±0.00000  bestvalidloss -0.71050  last_update 0\n",
      "train: iter 68  trainloss -0.36578  validloss -0.67161±0.00000  bestvalidloss -0.71050  last_update 1\n",
      "train: iter 69  trainloss -0.31770  validloss -0.67025±0.00000  bestvalidloss -0.71050  last_update 2\n",
      "train: iter 70  trainloss -0.36946  validloss -0.71455±0.00000  bestvalidloss -0.71455  last_update 0\n",
      "train: iter 71  trainloss -0.37217  validloss -0.70372±0.00000  bestvalidloss -0.71455  last_update 1\n",
      "train: iter 72  trainloss -0.37212  validloss -0.64151±0.00000  bestvalidloss -0.71455  last_update 2\n",
      "train: iter 73  trainloss -0.39275  validloss -0.72106±0.00000  bestvalidloss -0.72106  last_update 0\n",
      "train: iter 74  trainloss -0.38448  validloss -0.65323±0.00000  bestvalidloss -0.72106  last_update 1\n",
      "train: iter 75  trainloss -0.38413  validloss -0.72446±0.00000  bestvalidloss -0.72446  last_update 0\n",
      "train: iter 76  trainloss -0.34442  validloss -0.67037±0.00000  bestvalidloss -0.72446  last_update 1\n",
      "train: iter 77  trainloss -0.36607  validloss -0.71563±0.00000  bestvalidloss -0.72446  last_update 2\n",
      "train: iter 78  trainloss -0.36499  validloss -0.67841±0.00000  bestvalidloss -0.72446  last_update 3\n",
      "train: iter 79  trainloss -0.38873  validloss -0.72862±0.00000  bestvalidloss -0.72862  last_update 0\n",
      "train: iter 80  trainloss -0.39029  validloss -0.66977±0.00000  bestvalidloss -0.72862  last_update 1\n",
      "train: iter 81  trainloss -0.36325  validloss -0.73182±0.00000  bestvalidloss -0.73182  last_update 0\n",
      "train: iter 82  trainloss -0.37532  validloss -0.73185±0.00000  bestvalidloss -0.73185  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss -0.36857  validloss -0.69390±0.00000  bestvalidloss -0.73185  last_update 1\n",
      "train: iter 84  trainloss -0.38178  validloss -0.71724±0.00000  bestvalidloss -0.73185  last_update 2\n",
      "train: iter 85  trainloss -0.38640  validloss -0.69764±0.00000  bestvalidloss -0.73185  last_update 3\n",
      "train: iter 86  trainloss -0.34109  validloss -0.73558±0.00000  bestvalidloss -0.73558  last_update 0\n",
      "train: iter 87  trainloss -0.37559  validloss -0.73713±0.00000  bestvalidloss -0.73713  last_update 0\n",
      "train: iter 88  trainloss -0.39651  validloss -0.74367±0.00000  bestvalidloss -0.74367  last_update 0\n",
      "train: iter 89  trainloss -0.38511  validloss -0.69808±0.00000  bestvalidloss -0.74367  last_update 1\n",
      "train: iter 90  trainloss -0.38789  validloss -0.72572±0.00000  bestvalidloss -0.74367  last_update 2\n",
      "train: iter 91  trainloss -0.39984  validloss -0.75747±0.00000  bestvalidloss -0.75747  last_update 0\n",
      "train: iter 92  trainloss -0.39313  validloss -0.75569±0.00000  bestvalidloss -0.75747  last_update 1\n",
      "train: iter 93  trainloss -0.40438  validloss -0.71815±0.00000  bestvalidloss -0.75747  last_update 2\n",
      "train: iter 94  trainloss -0.39522  validloss -0.74436±0.00000  bestvalidloss -0.75747  last_update 3\n",
      "train: iter 95  trainloss -0.36917  validloss -0.75865±0.00000  bestvalidloss -0.75865  last_update 0\n",
      "train: iter 96  trainloss -0.37375  validloss -0.77753±0.00000  bestvalidloss -0.77753  last_update 0\n",
      "train: iter 97  trainloss -0.34365  validloss -0.73202±0.00000  bestvalidloss -0.77753  last_update 1\n",
      "train: iter 98  trainloss -0.36912  validloss -0.74925±0.00000  bestvalidloss -0.77753  last_update 2\n",
      "train: iter 99  trainloss -0.35354  validloss -0.71905±0.00000  bestvalidloss -0.77753  last_update 3\n",
      "train: iter 100  trainloss -0.37328  validloss -0.70457±0.00000  bestvalidloss -0.77753  last_update 4\n",
      "train: iter 101  trainloss -0.36106  validloss -0.70149±0.00000  bestvalidloss -0.77753  last_update 5\n",
      "train: iter 102  trainloss -0.42305  validloss -0.71854±0.00000  bestvalidloss -0.77753  last_update 6\n",
      "train: iter 103  trainloss -0.36686  validloss -0.74183±0.00000  bestvalidloss -0.77753  last_update 7\n",
      "train: iter 104  trainloss -0.38240  validloss -0.74073±0.00000  bestvalidloss -0.77753  last_update 8\n",
      "train: iter 105  trainloss -0.38919  validloss -0.73806±0.00000  bestvalidloss -0.77753  last_update 9\n",
      "train: iter 106  trainloss -0.38115  validloss -0.73708±0.00000  bestvalidloss -0.77753  last_update 10\n",
      "train: iter 107  trainloss -0.37597  validloss -0.68859±0.00000  bestvalidloss -0.77753  last_update 11\n",
      "train: iter 108  trainloss -0.39720  validloss -0.72440±0.00000  bestvalidloss -0.77753  last_update 12\n",
      "train: iter 109  trainloss -0.39431  validloss -0.72613±0.00000  bestvalidloss -0.77753  last_update 13\n",
      "train: iter 110  trainloss -0.39254  validloss -0.70406±0.00000  bestvalidloss -0.77753  last_update 14\n",
      "train: iter 111  trainloss -0.39257  validloss -0.71349±0.00000  bestvalidloss -0.77753  last_update 15\n",
      "train: iter 112  trainloss -0.36886  validloss -0.73246±0.00000  bestvalidloss -0.77753  last_update 16\n",
      "train: iter 113  trainloss -0.35232  validloss -0.73802±0.00000  bestvalidloss -0.77753  last_update 17\n",
      "train: iter 114  trainloss -0.38989  validloss -0.71436±0.00000  bestvalidloss -0.77753  last_update 18\n",
      "train: iter 115  trainloss -0.38819  validloss -0.68141±0.00000  bestvalidloss -0.77753  last_update 19\n",
      "train: iter 116  trainloss -0.35732  validloss -0.74108±0.00000  bestvalidloss -0.77753  last_update 20\n",
      "train: iter 117  trainloss -0.39750  validloss -0.73652±0.00000  bestvalidloss -0.77753  last_update 21\n",
      "train: iter 118  trainloss -0.37793  validloss -0.73153±0.00000  bestvalidloss -0.77753  last_update 22\n",
      "train: iter 119  trainloss -0.37075  validloss -0.72734±0.00000  bestvalidloss -0.77753  last_update 23\n",
      "train: iter 120  trainloss -0.34901  validloss -0.72496±0.00000  bestvalidloss -0.77753  last_update 24\n",
      "train: iter 121  trainloss -0.38442  validloss -0.71501±0.00000  bestvalidloss -0.77753  last_update 25\n",
      "train: iter 122  trainloss -0.41682  validloss -0.74603±0.00000  bestvalidloss -0.77753  last_update 26\n",
      "train: iter 123  trainloss -0.37645  validloss -0.70536±0.00000  bestvalidloss -0.77753  last_update 27\n",
      "train: iter 124  trainloss -0.36662  validloss -0.73578±0.00000  bestvalidloss -0.77753  last_update 28\n",
      "train: iter 125  trainloss -0.38275  validloss -0.75276±0.00000  bestvalidloss -0.77753  last_update 29\n",
      "train: iter 126  trainloss -0.37155  validloss -0.75033±0.00000  bestvalidloss -0.77753  last_update 30\n",
      "train: iter 127  trainloss -0.39527  validloss -0.75523±0.00000  bestvalidloss -0.77753  last_update 31\n",
      "train: iter 128  trainloss -0.37278  validloss -0.77480±0.00000  bestvalidloss -0.77753  last_update 32\n",
      "train: iter 129  trainloss -0.35502  validloss -0.70472±0.00000  bestvalidloss -0.77753  last_update 33\n",
      "train: iter 130  trainloss -0.33427  validloss -0.73510±0.00000  bestvalidloss -0.77753  last_update 34\n",
      "train: iter 131  trainloss -0.38040  validloss -0.70265±0.00000  bestvalidloss -0.77753  last_update 35\n",
      "train: iter 132  trainloss -0.38351  validloss -0.78215±0.00000  bestvalidloss -0.78215  last_update 0\n",
      "train: iter 133  trainloss -0.38563  validloss -0.73030±0.00000  bestvalidloss -0.78215  last_update 1\n",
      "train: iter 134  trainloss -0.37126  validloss -0.74805±0.00000  bestvalidloss -0.78215  last_update 2\n",
      "train: iter 135  trainloss -0.41569  validloss -0.72192±0.00000  bestvalidloss -0.78215  last_update 3\n",
      "train: iter 136  trainloss -0.40702  validloss -0.72046±0.00000  bestvalidloss -0.78215  last_update 4\n",
      "train: iter 137  trainloss -0.37041  validloss -0.74593±0.00000  bestvalidloss -0.78215  last_update 5\n",
      "train: iter 138  trainloss -0.40188  validloss -0.77012±0.00000  bestvalidloss -0.78215  last_update 6\n",
      "train: iter 139  trainloss -0.37838  validloss -0.75464±0.00000  bestvalidloss -0.78215  last_update 7\n",
      "train: iter 140  trainloss -0.34616  validloss -0.78035±0.00000  bestvalidloss -0.78215  last_update 8\n",
      "train: iter 141  trainloss -0.38357  validloss -0.71513±0.00000  bestvalidloss -0.78215  last_update 9\n",
      "train: iter 142  trainloss -0.40081  validloss -0.72531±0.00000  bestvalidloss -0.78215  last_update 10\n",
      "train: iter 143  trainloss -0.39545  validloss -0.73680±0.00000  bestvalidloss -0.78215  last_update 11\n",
      "train: iter 144  trainloss -0.36296  validloss -0.75950±0.00000  bestvalidloss -0.78215  last_update 12\n",
      "train: iter 145  trainloss -0.38770  validloss -0.75123±0.00000  bestvalidloss -0.78215  last_update 13\n",
      "train: iter 146  trainloss -0.35399  validloss -0.72339±0.00000  bestvalidloss -0.78215  last_update 14\n",
      "train: iter 147  trainloss -0.38800  validloss -0.75598±0.00000  bestvalidloss -0.78215  last_update 15\n",
      "train: iter 148  trainloss -0.37280  validloss -0.70209±0.00000  bestvalidloss -0.78215  last_update 16\n",
      "train: iter 149  trainloss -0.37846  validloss -0.69299±0.00000  bestvalidloss -0.78215  last_update 17\n",
      "train: iter 150  trainloss -0.36005  validloss -0.70274±0.00000  bestvalidloss -0.78215  last_update 18\n",
      "train: iter 151  trainloss -0.38910  validloss -0.80740±0.00000  bestvalidloss -0.80740  last_update 0\n",
      "train: iter 152  trainloss -0.36226  validloss -0.71278±0.00000  bestvalidloss -0.80740  last_update 1\n",
      "train: iter 153  trainloss -0.39117  validloss -0.75759±0.00000  bestvalidloss -0.80740  last_update 2\n",
      "train: iter 154  trainloss -0.40685  validloss -0.73777±0.00000  bestvalidloss -0.80740  last_update 3\n",
      "train: iter 155  trainloss -0.40545  validloss -0.71259±0.00000  bestvalidloss -0.80740  last_update 4\n",
      "train: iter 156  trainloss -0.39172  validloss -0.76546±0.00000  bestvalidloss -0.80740  last_update 5\n",
      "train: iter 157  trainloss -0.35414  validloss -0.71758±0.00000  bestvalidloss -0.80740  last_update 6\n",
      "train: iter 158  trainloss -0.37925  validloss -0.71424±0.00000  bestvalidloss -0.80740  last_update 7\n",
      "train: iter 159  trainloss -0.35335  validloss -0.75006±0.00000  bestvalidloss -0.80740  last_update 8\n",
      "train: iter 160  trainloss -0.36855  validloss -0.68066±0.00000  bestvalidloss -0.80740  last_update 9\n",
      "train: iter 161  trainloss -0.37782  validloss -0.72407±0.00000  bestvalidloss -0.80740  last_update 10\n",
      "train: iter 162  trainloss -0.36730  validloss -0.77245±0.00000  bestvalidloss -0.80740  last_update 11\n",
      "train: iter 163  trainloss -0.38621  validloss -0.69116±0.00000  bestvalidloss -0.80740  last_update 12\n",
      "train: iter 164  trainloss -0.41600  validloss -0.71703±0.00000  bestvalidloss -0.80740  last_update 13\n",
      "train: iter 165  trainloss -0.39201  validloss -0.72361±0.00000  bestvalidloss -0.80740  last_update 14\n",
      "train: iter 166  trainloss -0.38149  validloss -0.71121±0.00000  bestvalidloss -0.80740  last_update 15\n",
      "train: iter 167  trainloss -0.35047  validloss -0.74458±0.00000  bestvalidloss -0.80740  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss -0.38919  validloss -0.71925±0.00000  bestvalidloss -0.80740  last_update 17\n",
      "train: iter 169  trainloss -0.37600  validloss -0.74844±0.00000  bestvalidloss -0.80740  last_update 18\n",
      "train: iter 170  trainloss -0.38112  validloss -0.73897±0.00000  bestvalidloss -0.80740  last_update 19\n",
      "train: iter 171  trainloss -0.39687  validloss -0.76452±0.00000  bestvalidloss -0.80740  last_update 20\n",
      "train: iter 172  trainloss -0.40360  validloss -0.71034±0.00000  bestvalidloss -0.80740  last_update 21\n",
      "train: iter 173  trainloss -0.35725  validloss -0.73384±0.00000  bestvalidloss -0.80740  last_update 22\n",
      "train: iter 174  trainloss -0.36428  validloss -0.72257±0.00000  bestvalidloss -0.80740  last_update 23\n",
      "train: iter 175  trainloss -0.40547  validloss -0.72056±0.00000  bestvalidloss -0.80740  last_update 24\n",
      "train: iter 176  trainloss -0.38797  validloss -0.71368±0.00000  bestvalidloss -0.80740  last_update 25\n",
      "train: iter 177  trainloss -0.34975  validloss -0.72041±0.00000  bestvalidloss -0.80740  last_update 26\n",
      "train: iter 178  trainloss -0.34823  validloss -0.74338±0.00000  bestvalidloss -0.80740  last_update 27\n",
      "train: iter 179  trainloss -0.37998  validloss -0.69665±0.00000  bestvalidloss -0.80740  last_update 28\n",
      "train: iter 180  trainloss -0.40631  validloss -0.76069±0.00000  bestvalidloss -0.80740  last_update 29\n",
      "train: iter 181  trainloss -0.36443  validloss -0.71644±0.00000  bestvalidloss -0.80740  last_update 30\n",
      "train: iter 182  trainloss -0.36623  validloss -0.76496±0.00000  bestvalidloss -0.80740  last_update 31\n",
      "train: iter 183  trainloss -0.39817  validloss -0.75409±0.00000  bestvalidloss -0.80740  last_update 32\n",
      "train: iter 184  trainloss -0.38896  validloss -0.72521±0.00000  bestvalidloss -0.80740  last_update 33\n",
      "train: iter 185  trainloss -0.37865  validloss -0.70773±0.00000  bestvalidloss -0.80740  last_update 34\n",
      "train: iter 186  trainloss -0.41340  validloss -0.75137±0.00000  bestvalidloss -0.80740  last_update 35\n",
      "train: iter 187  trainloss -0.41194  validloss -0.74471±0.00000  bestvalidloss -0.80740  last_update 36\n",
      "train: iter 188  trainloss -0.34887  validloss -0.69188±0.00000  bestvalidloss -0.80740  last_update 37\n",
      "train: iter 189  trainloss -0.36248  validloss -0.72366±0.00000  bestvalidloss -0.80740  last_update 38\n",
      "train: iter 190  trainloss -0.35237  validloss -0.73712±0.00000  bestvalidloss -0.80740  last_update 39\n",
      "train: iter 191  trainloss -0.39743  validloss -0.74827±0.00000  bestvalidloss -0.80740  last_update 40\n",
      "train: iter 192  trainloss -0.36919  validloss -0.71845±0.00000  bestvalidloss -0.80740  last_update 41\n",
      "train: iter 193  trainloss -0.39436  validloss -0.73303±0.00000  bestvalidloss -0.80740  last_update 42\n",
      "train: iter 194  trainloss -0.39455  validloss -0.71368±0.00000  bestvalidloss -0.80740  last_update 43\n",
      "train: iter 195  trainloss -0.37559  validloss -0.76287±0.00000  bestvalidloss -0.80740  last_update 44\n",
      "train: iter 196  trainloss -0.38146  validloss -0.73008±0.00000  bestvalidloss -0.80740  last_update 45\n",
      "train: iter 197  trainloss -0.38384  validloss -0.68138±0.00000  bestvalidloss -0.80740  last_update 46\n",
      "train: iter 198  trainloss -0.41628  validloss -0.73003±0.00000  bestvalidloss -0.80740  last_update 47\n",
      "train: iter 199  trainloss -0.35046  validloss -0.72961±0.00000  bestvalidloss -0.80740  last_update 48\n",
      "train: iter 200  trainloss -0.39470  validloss -0.76599±0.00000  bestvalidloss -0.80740  last_update 49\n",
      "train: iter 201  trainloss -0.36286  validloss -0.73356±0.00000  bestvalidloss -0.80740  last_update 50\n",
      "train: iter 202  trainloss -0.37937  validloss -0.69872±0.00000  bestvalidloss -0.80740  last_update 51\n",
      "train: iter 203  trainloss -0.39167  validloss -0.75419±0.00000  bestvalidloss -0.80740  last_update 52\n",
      "train: iter 204  trainloss -0.36894  validloss -0.77705±0.00000  bestvalidloss -0.80740  last_update 53\n",
      "train: iter 205  trainloss -0.34311  validloss -0.65423±0.00000  bestvalidloss -0.80740  last_update 54\n",
      "train: iter 206  trainloss -0.38139  validloss -0.75913±0.00000  bestvalidloss -0.80740  last_update 55\n",
      "train: iter 207  trainloss -0.40120  validloss -0.66779±0.00000  bestvalidloss -0.80740  last_update 56\n",
      "train: iter 208  trainloss -0.34527  validloss -0.67844±0.00000  bestvalidloss -0.80740  last_update 57\n",
      "train: iter 209  trainloss -0.41991  validloss -0.75736±0.00000  bestvalidloss -0.80740  last_update 58\n",
      "train: iter 210  trainloss -0.40690  validloss -0.70974±0.00000  bestvalidloss -0.80740  last_update 59\n",
      "train: iter 211  trainloss -0.39054  validloss -0.73573±0.00000  bestvalidloss -0.80740  last_update 60\n",
      "train: iter 212  trainloss -0.40359  validloss -0.71328±0.00000  bestvalidloss -0.80740  last_update 61\n",
      "train: iter 213  trainloss -0.35057  validloss -0.67965±0.00000  bestvalidloss -0.80740  last_update 62\n",
      "train: iter 214  trainloss -0.37365  validloss -0.76719±0.00000  bestvalidloss -0.80740  last_update 63\n",
      "train: iter 215  trainloss -0.33806  validloss -0.72858±0.00000  bestvalidloss -0.80740  last_update 64\n",
      "train: iter 216  trainloss -0.37744  validloss -0.72332±0.00000  bestvalidloss -0.80740  last_update 65\n",
      "train: iter 217  trainloss -0.38150  validloss -0.73258±0.00000  bestvalidloss -0.80740  last_update 66\n",
      "train: iter 218  trainloss -0.38731  validloss -0.74214±0.00000  bestvalidloss -0.80740  last_update 67\n",
      "train: iter 219  trainloss -0.34212  validloss -0.72549±0.00000  bestvalidloss -0.80740  last_update 68\n",
      "train: iter 220  trainloss -0.38710  validloss -0.67413±0.00000  bestvalidloss -0.80740  last_update 69\n",
      "train: iter 221  trainloss -0.35362  validloss -0.74520±0.00000  bestvalidloss -0.80740  last_update 70\n",
      "train: iter 222  trainloss -0.36446  validloss -0.73283±0.00000  bestvalidloss -0.80740  last_update 71\n",
      "train: iter 223  trainloss -0.39417  validloss -0.69074±0.00000  bestvalidloss -0.80740  last_update 72\n",
      "train: iter 224  trainloss -0.36864  validloss -0.68647±0.00000  bestvalidloss -0.80740  last_update 73\n",
      "train: iter 225  trainloss -0.35019  validloss -0.73726±0.00000  bestvalidloss -0.80740  last_update 74\n",
      "train: iter 226  trainloss -0.40387  validloss -0.71415±0.00000  bestvalidloss -0.80740  last_update 75\n",
      "train: iter 227  trainloss -0.35087  validloss -0.67427±0.00000  bestvalidloss -0.80740  last_update 76\n",
      "train: iter 228  trainloss -0.39526  validloss -0.69406±0.00000  bestvalidloss -0.80740  last_update 77\n",
      "train: iter 229  trainloss -0.38795  validloss -0.72920±0.00000  bestvalidloss -0.80740  last_update 78\n",
      "train: iter 230  trainloss -0.39046  validloss -0.77640±0.00000  bestvalidloss -0.80740  last_update 79\n",
      "train: iter 231  trainloss -0.38392  validloss -0.74379±0.00000  bestvalidloss -0.80740  last_update 80\n",
      "train: iter 232  trainloss -0.38131  validloss -0.69635±0.00000  bestvalidloss -0.80740  last_update 81\n",
      "train: iter 233  trainloss -0.36318  validloss -0.73930±0.00000  bestvalidloss -0.80740  last_update 82\n",
      "train: iter 234  trainloss -0.37007  validloss -0.74126±0.00000  bestvalidloss -0.80740  last_update 83\n",
      "train: iter 235  trainloss -0.39661  validloss -0.73719±0.00000  bestvalidloss -0.80740  last_update 84\n",
      "train: iter 236  trainloss -0.37161  validloss -0.69621±0.00000  bestvalidloss -0.80740  last_update 85\n",
      "train: iter 237  trainloss -0.37009  validloss -0.72576±0.00000  bestvalidloss -0.80740  last_update 86\n",
      "train: iter 238  trainloss -0.35802  validloss -0.73384±0.00000  bestvalidloss -0.80740  last_update 87\n",
      "train: iter 239  trainloss -0.41582  validloss -0.68099±0.00000  bestvalidloss -0.80740  last_update 88\n",
      "train: iter 240  trainloss -0.39727  validloss -0.75081±0.00000  bestvalidloss -0.80740  last_update 89\n",
      "train: iter 241  trainloss -0.38613  validloss -0.72445±0.00000  bestvalidloss -0.80740  last_update 90\n",
      "train: iter 242  trainloss -0.37325  validloss -0.71450±0.00000  bestvalidloss -0.80740  last_update 91\n",
      "train: iter 243  trainloss -0.39296  validloss -0.69487±0.00000  bestvalidloss -0.80740  last_update 92\n",
      "train: iter 244  trainloss -0.36461  validloss -0.72233±0.00000  bestvalidloss -0.80740  last_update 93\n",
      "train: iter 245  trainloss -0.37769  validloss -0.72574±0.00000  bestvalidloss -0.80740  last_update 94\n",
      "train: iter 246  trainloss -0.36269  validloss -0.71071±0.00000  bestvalidloss -0.80740  last_update 95\n",
      "train: iter 247  trainloss -0.37565  validloss -0.70291±0.00000  bestvalidloss -0.80740  last_update 96\n",
      "train: iter 248  trainloss -0.35775  validloss -0.72777±0.00000  bestvalidloss -0.80740  last_update 97\n",
      "train: iter 249  trainloss -0.40625  validloss -0.76255±0.00000  bestvalidloss -0.80740  last_update 98\n",
      "train: iter 250  trainloss -0.39501  validloss -0.70316±0.00000  bestvalidloss -0.80740  last_update 99\n",
      "train: iter 251  trainloss -0.40631  validloss -0.72542±0.00000  bestvalidloss -0.80740  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.1956, -1.8563, -3.1189, -3.3115], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 70.32105  validloss 70.16736±0.00000  bestvalidloss 70.16736  last_update 0\n",
      "train: iter 1  trainloss 54.56973  validloss 57.70331±0.00000  bestvalidloss 57.70331  last_update 0\n",
      "train: iter 2  trainloss 40.23480  validloss 42.66551±0.00000  bestvalidloss 42.66551  last_update 0\n",
      "train: iter 3  trainloss 30.95478  validloss 31.95234±0.00000  bestvalidloss 31.95234  last_update 0\n",
      "train: iter 4  trainloss 24.19101  validloss 25.07351±0.00000  bestvalidloss 25.07351  last_update 0\n",
      "train: iter 5  trainloss 19.20722  validloss 19.49711±0.00000  bestvalidloss 19.49711  last_update 0\n",
      "train: iter 6  trainloss 15.66250  validloss 16.07263±0.00000  bestvalidloss 16.07263  last_update 0\n",
      "train: iter 7  trainloss 13.05418  validloss 13.51363±0.00000  bestvalidloss 13.51363  last_update 0\n",
      "train: iter 8  trainloss 11.20066  validloss 11.72775±0.00000  bestvalidloss 11.72775  last_update 0\n",
      "train: iter 9  trainloss 9.86880  validloss 10.42014±0.00000  bestvalidloss 10.42014  last_update 0\n",
      "train: iter 10  trainloss 8.90120  validloss 9.58132±0.00000  bestvalidloss 9.58132  last_update 0\n",
      "train: iter 11  trainloss 8.20768  validloss 9.04424±0.00000  bestvalidloss 9.04424  last_update 0\n",
      "train: iter 12  trainloss 7.75138  validloss 8.63162±0.00000  bestvalidloss 8.63162  last_update 0\n",
      "train: iter 13  trainloss 7.35001  validloss 8.42450±0.00000  bestvalidloss 8.42450  last_update 0\n",
      "train: iter 14  trainloss 7.09551  validloss 8.30863±0.00000  bestvalidloss 8.30863  last_update 0\n",
      "train: iter 15  trainloss 6.95634  validloss 8.12411±0.00000  bestvalidloss 8.12411  last_update 0\n",
      "train: iter 16  trainloss 6.81492  validloss 8.03056±0.00000  bestvalidloss 8.03056  last_update 0\n",
      "train: iter 17  trainloss 6.67735  validloss 7.90150±0.00000  bestvalidloss 7.90150  last_update 0\n",
      "train: iter 18  trainloss 6.63372  validloss 7.80241±0.00000  bestvalidloss 7.80241  last_update 0\n",
      "train: iter 19  trainloss 6.47824  validloss 7.84252±0.00000  bestvalidloss 7.80241  last_update 1\n",
      "train: iter 20  trainloss 6.40513  validloss 7.63024±0.00000  bestvalidloss 7.63024  last_update 0\n",
      "train: iter 21  trainloss 6.26515  validloss 7.46633±0.00000  bestvalidloss 7.46633  last_update 0\n",
      "train: iter 22  trainloss 5.98353  validloss 7.20157±0.00000  bestvalidloss 7.20157  last_update 0\n",
      "train: iter 23  trainloss 5.52020  validloss 6.40718±0.00000  bestvalidloss 6.40718  last_update 0\n",
      "train: iter 24  trainloss 5.19599  validloss 5.86990±0.00000  bestvalidloss 5.86990  last_update 0\n",
      "train: iter 25  trainloss 4.94591  validloss 5.55105±0.00000  bestvalidloss 5.55105  last_update 0\n",
      "train: iter 26  trainloss 4.73023  validloss 5.35774±0.00000  bestvalidloss 5.35774  last_update 0\n",
      "train: iter 27  trainloss 4.54182  validloss 5.25430±0.00000  bestvalidloss 5.25430  last_update 0\n",
      "train: iter 28  trainloss 4.41366  validloss 5.07747±0.00000  bestvalidloss 5.07747  last_update 0\n",
      "train: iter 29  trainloss 4.21556  validloss 4.92103±0.00000  bestvalidloss 4.92103  last_update 0\n",
      "train: iter 30  trainloss 4.13584  validloss 4.85988±0.00000  bestvalidloss 4.85988  last_update 0\n",
      "train: iter 31  trainloss 4.02216  validloss 4.87246±0.00000  bestvalidloss 4.85988  last_update 1\n",
      "train: iter 32  trainloss 3.94047  validloss 4.73906±0.00000  bestvalidloss 4.73906  last_update 0\n",
      "train: iter 33  trainloss 3.89241  validloss 4.89744±0.00000  bestvalidloss 4.73906  last_update 1\n",
      "train: iter 34  trainloss 3.82107  validloss 4.74235±0.00000  bestvalidloss 4.73906  last_update 2\n",
      "train: iter 35  trainloss 3.70194  validloss 4.76218±0.00000  bestvalidloss 4.73906  last_update 3\n",
      "train: iter 36  trainloss 3.69384  validloss 4.67356±0.00000  bestvalidloss 4.67356  last_update 0\n",
      "train: iter 37  trainloss 3.62053  validloss 4.54874±0.00000  bestvalidloss 4.54874  last_update 0\n",
      "train: iter 38  trainloss 3.60682  validloss 4.42897±0.00000  bestvalidloss 4.42897  last_update 0\n",
      "train: iter 39  trainloss 3.54542  validloss 4.51486±0.00000  bestvalidloss 4.42897  last_update 1\n",
      "train: iter 40  trainloss 3.46313  validloss 4.59970±0.00000  bestvalidloss 4.42897  last_update 2\n",
      "train: iter 41  trainloss 3.41365  validloss 4.70993±0.00000  bestvalidloss 4.42897  last_update 3\n",
      "train: iter 42  trainloss 3.41982  validloss 4.30188±0.00000  bestvalidloss 4.30188  last_update 0\n",
      "train: iter 43  trainloss 3.38356  validloss 4.56956±0.00000  bestvalidloss 4.30188  last_update 1\n",
      "train: iter 44  trainloss 3.29181  validloss 4.40686±0.00000  bestvalidloss 4.30188  last_update 2\n",
      "train: iter 45  trainloss 3.28978  validloss 4.59152±0.00000  bestvalidloss 4.30188  last_update 3\n",
      "train: iter 46  trainloss 3.27881  validloss 4.76649±0.00000  bestvalidloss 4.30188  last_update 4\n",
      "train: iter 47  trainloss 3.24841  validloss 4.57040±0.00000  bestvalidloss 4.30188  last_update 5\n",
      "train: iter 48  trainloss 3.23941  validloss 4.49643±0.00000  bestvalidloss 4.30188  last_update 6\n",
      "train: iter 49  trainloss 3.25305  validloss 4.53644±0.00000  bestvalidloss 4.30188  last_update 7\n",
      "train: iter 50  trainloss 3.27041  validloss 4.57441±0.00000  bestvalidloss 4.30188  last_update 8\n",
      "train: iter 51  trainloss 3.28400  validloss 4.48281±0.00000  bestvalidloss 4.30188  last_update 9\n",
      "train: iter 52  trainloss 3.20455  validloss 4.69645±0.00000  bestvalidloss 4.30188  last_update 10\n",
      "train: iter 53  trainloss 3.17538  validloss 4.54503±0.00000  bestvalidloss 4.30188  last_update 11\n",
      "train: iter 54  trainloss 3.22946  validloss 4.50721±0.00000  bestvalidloss 4.30188  last_update 12\n",
      "train: iter 55  trainloss 3.19414  validloss 4.63492±0.00000  bestvalidloss 4.30188  last_update 13\n",
      "train: iter 56  trainloss 3.20036  validloss 4.53133±0.00000  bestvalidloss 4.30188  last_update 14\n",
      "train: iter 57  trainloss 3.24699  validloss 5.19798±0.00000  bestvalidloss 4.30188  last_update 15\n",
      "train: iter 58  trainloss 3.21464  validloss 4.90200±0.00000  bestvalidloss 4.30188  last_update 16\n",
      "train: iter 59  trainloss 3.20050  validloss 4.60472±0.00000  bestvalidloss 4.30188  last_update 17\n",
      "train: iter 60  trainloss 3.21314  validloss 4.53325±0.00000  bestvalidloss 4.30188  last_update 18\n",
      "train: iter 61  trainloss 3.20900  validloss 4.64775±0.00000  bestvalidloss 4.30188  last_update 19\n",
      "train: iter 62  trainloss 3.18141  validloss 4.50719±0.00000  bestvalidloss 4.30188  last_update 20\n",
      "train: iter 63  trainloss 3.20502  validloss 4.53183±0.00000  bestvalidloss 4.30188  last_update 21\n",
      "train: iter 64  trainloss 3.22782  validloss 4.45303±0.00000  bestvalidloss 4.30188  last_update 22\n",
      "train: iter 65  trainloss 3.16903  validloss 4.51788±0.00000  bestvalidloss 4.30188  last_update 23\n",
      "train: iter 66  trainloss 3.21859  validloss 4.52551±0.00000  bestvalidloss 4.30188  last_update 24\n",
      "train: iter 67  trainloss 3.18401  validloss 4.57894±0.00000  bestvalidloss 4.30188  last_update 25\n",
      "train: iter 68  trainloss 3.16911  validloss 4.60363±0.00000  bestvalidloss 4.30188  last_update 26\n",
      "train: iter 69  trainloss 3.18621  validloss 4.53743±0.00000  bestvalidloss 4.30188  last_update 27\n",
      "train: iter 70  trainloss 3.18027  validloss 4.60928±0.00000  bestvalidloss 4.30188  last_update 28\n",
      "train: iter 71  trainloss 3.20765  validloss 4.48522±0.00000  bestvalidloss 4.30188  last_update 29\n",
      "train: iter 72  trainloss 3.18122  validloss 4.78537±0.00000  bestvalidloss 4.30188  last_update 30\n",
      "train: iter 73  trainloss 3.16580  validloss 4.44492±0.00000  bestvalidloss 4.30188  last_update 31\n",
      "train: iter 74  trainloss 3.22698  validloss 4.63042±0.00000  bestvalidloss 4.30188  last_update 32\n",
      "train: iter 75  trainloss 3.15404  validloss 4.69896±0.00000  bestvalidloss 4.30188  last_update 33\n",
      "train: iter 76  trainloss 3.18911  validloss 4.57148±0.00000  bestvalidloss 4.30188  last_update 34\n",
      "train: iter 77  trainloss 3.17495  validloss 4.86558±0.00000  bestvalidloss 4.30188  last_update 35\n",
      "train: iter 78  trainloss 3.15682  validloss 4.69159±0.00000  bestvalidloss 4.30188  last_update 36\n",
      "train: iter 79  trainloss 3.13451  validloss 4.56440±0.00000  bestvalidloss 4.30188  last_update 37\n",
      "train: iter 80  trainloss 3.18883  validloss 4.49480±0.00000  bestvalidloss 4.30188  last_update 38\n",
      "train: iter 81  trainloss 3.19268  validloss 4.70429±0.00000  bestvalidloss 4.30188  last_update 39\n",
      "train: iter 82  trainloss 3.17510  validloss 4.73931±0.00000  bestvalidloss 4.30188  last_update 40\n",
      "train: iter 83  trainloss 3.14161  validloss 4.67049±0.00000  bestvalidloss 4.30188  last_update 41\n",
      "train: iter 84  trainloss 3.15870  validloss 4.51288±0.00000  bestvalidloss 4.30188  last_update 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 3.18558  validloss 4.53590±0.00000  bestvalidloss 4.30188  last_update 43\n",
      "train: iter 86  trainloss 3.14305  validloss 4.53365±0.00000  bestvalidloss 4.30188  last_update 44\n",
      "train: iter 87  trainloss 3.21894  validloss 4.48859±0.00000  bestvalidloss 4.30188  last_update 45\n",
      "train: iter 88  trainloss 3.18116  validloss 4.41216±0.00000  bestvalidloss 4.30188  last_update 46\n",
      "train: iter 89  trainloss 3.12908  validloss 4.69785±0.00000  bestvalidloss 4.30188  last_update 47\n",
      "train: iter 90  trainloss 3.16747  validloss 4.71356±0.00000  bestvalidloss 4.30188  last_update 48\n",
      "train: iter 91  trainloss 3.11603  validloss 4.65563±0.00000  bestvalidloss 4.30188  last_update 49\n",
      "train: iter 92  trainloss 3.18315  validloss 4.76369±0.00000  bestvalidloss 4.30188  last_update 50\n",
      "train: iter 93  trainloss 3.12166  validloss 4.73484±0.00000  bestvalidloss 4.30188  last_update 51\n",
      "train: iter 94  trainloss 3.17901  validloss 4.41170±0.00000  bestvalidloss 4.30188  last_update 52\n",
      "train: iter 95  trainloss 3.18565  validloss 4.53772±0.00000  bestvalidloss 4.30188  last_update 53\n",
      "train: iter 96  trainloss 3.17835  validloss 4.63400±0.00000  bestvalidloss 4.30188  last_update 54\n",
      "train: iter 97  trainloss 3.14665  validloss 4.60871±0.00000  bestvalidloss 4.30188  last_update 55\n",
      "train: iter 98  trainloss 3.13870  validloss 4.68078±0.00000  bestvalidloss 4.30188  last_update 56\n",
      "train: iter 99  trainloss 3.16241  validloss 4.66788±0.00000  bestvalidloss 4.30188  last_update 57\n",
      "train: iter 100  trainloss 3.19624  validloss 4.40603±0.00000  bestvalidloss 4.30188  last_update 58\n",
      "train: iter 101  trainloss 3.12752  validloss 4.70448±0.00000  bestvalidloss 4.30188  last_update 59\n",
      "train: iter 102  trainloss 3.18475  validloss 4.46524±0.00000  bestvalidloss 4.30188  last_update 60\n",
      "train: iter 103  trainloss 3.14599  validloss 4.57554±0.00000  bestvalidloss 4.30188  last_update 61\n",
      "train: iter 104  trainloss 3.14504  validloss 4.77799±0.00000  bestvalidloss 4.30188  last_update 62\n",
      "train: iter 105  trainloss 3.17450  validloss 4.45679±0.00000  bestvalidloss 4.30188  last_update 63\n",
      "train: iter 106  trainloss 3.14577  validloss 4.49584±0.00000  bestvalidloss 4.30188  last_update 64\n",
      "train: iter 107  trainloss 3.13924  validloss 4.50080±0.00000  bestvalidloss 4.30188  last_update 65\n",
      "train: iter 108  trainloss 3.13399  validloss 4.57236±0.00000  bestvalidloss 4.30188  last_update 66\n",
      "train: iter 109  trainloss 3.16392  validloss 4.82045±0.00000  bestvalidloss 4.30188  last_update 67\n",
      "train: iter 110  trainloss 3.13308  validloss 4.49194±0.00000  bestvalidloss 4.30188  last_update 68\n",
      "train: iter 111  trainloss 3.14738  validloss 4.61179±0.00000  bestvalidloss 4.30188  last_update 69\n",
      "train: iter 112  trainloss 3.13855  validloss 4.52765±0.00000  bestvalidloss 4.30188  last_update 70\n",
      "train: iter 113  trainloss 3.13518  validloss 4.95083±0.00000  bestvalidloss 4.30188  last_update 71\n",
      "train: iter 114  trainloss 3.16015  validloss 4.58384±0.00000  bestvalidloss 4.30188  last_update 72\n",
      "train: iter 115  trainloss 3.18355  validloss 4.62079±0.00000  bestvalidloss 4.30188  last_update 73\n",
      "train: iter 116  trainloss 3.17726  validloss 4.72805±0.00000  bestvalidloss 4.30188  last_update 74\n",
      "train: iter 117  trainloss 3.14078  validloss 4.65645±0.00000  bestvalidloss 4.30188  last_update 75\n",
      "train: iter 118  trainloss 3.12066  validloss 4.47851±0.00000  bestvalidloss 4.30188  last_update 76\n",
      "train: iter 119  trainloss 3.11068  validloss 4.69569±0.00000  bestvalidloss 4.30188  last_update 77\n",
      "train: iter 120  trainloss 3.16257  validloss 4.53845±0.00000  bestvalidloss 4.30188  last_update 78\n",
      "train: iter 121  trainloss 3.18091  validloss 4.60694±0.00000  bestvalidloss 4.30188  last_update 79\n",
      "train: iter 122  trainloss 3.19540  validloss 4.78961±0.00000  bestvalidloss 4.30188  last_update 80\n",
      "train: iter 123  trainloss 3.13653  validloss 4.99479±0.00000  bestvalidloss 4.30188  last_update 81\n",
      "train: iter 124  trainloss 3.10135  validloss 4.74258±0.00000  bestvalidloss 4.30188  last_update 82\n",
      "train: iter 125  trainloss 3.15821  validloss 4.47962±0.00000  bestvalidloss 4.30188  last_update 83\n",
      "train: iter 126  trainloss 3.16789  validloss 4.65162±0.00000  bestvalidloss 4.30188  last_update 84\n",
      "train: iter 127  trainloss 3.16008  validloss 4.54498±0.00000  bestvalidloss 4.30188  last_update 85\n",
      "train: iter 128  trainloss 3.12759  validloss 4.72053±0.00000  bestvalidloss 4.30188  last_update 86\n",
      "train: iter 129  trainloss 3.13598  validloss 4.60100±0.00000  bestvalidloss 4.30188  last_update 87\n",
      "train: iter 130  trainloss 3.09042  validloss 4.73864±0.00000  bestvalidloss 4.30188  last_update 88\n",
      "train: iter 131  trainloss 3.11472  validloss 4.66338±0.00000  bestvalidloss 4.30188  last_update 89\n",
      "train: iter 132  trainloss 3.13067  validloss 4.69530±0.00000  bestvalidloss 4.30188  last_update 90\n",
      "train: iter 133  trainloss 3.10909  validloss 4.53513±0.00000  bestvalidloss 4.30188  last_update 91\n",
      "train: iter 134  trainloss 3.11034  validloss 4.63886±0.00000  bestvalidloss 4.30188  last_update 92\n",
      "train: iter 135  trainloss 3.17397  validloss 4.71307±0.00000  bestvalidloss 4.30188  last_update 93\n",
      "train: iter 136  trainloss 3.15454  validloss 4.61072±0.00000  bestvalidloss 4.30188  last_update 94\n",
      "train: iter 137  trainloss 3.11273  validloss 4.84315±0.00000  bestvalidloss 4.30188  last_update 95\n",
      "train: iter 138  trainloss 3.13580  validloss 4.57320±0.00000  bestvalidloss 4.30188  last_update 96\n",
      "train: iter 139  trainloss 3.08388  validloss 4.57750±0.00000  bestvalidloss 4.30188  last_update 97\n",
      "train: iter 140  trainloss 3.12192  validloss 4.48576±0.00000  bestvalidloss 4.30188  last_update 98\n",
      "train: iter 141  trainloss 3.12286  validloss 4.63645±0.00000  bestvalidloss 4.30188  last_update 99\n",
      "train: iter 142  trainloss 3.10799  validloss 4.97309±0.00000  bestvalidloss 4.30188  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-7.0911)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(1.9157)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0704959981900204\n",
      "tensor([-0.2217])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1102522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291e259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b666edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839fe72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480f604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
