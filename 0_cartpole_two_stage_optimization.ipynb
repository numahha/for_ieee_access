{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-2737.2300)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 18335.90895  validloss 6098.82032±0.00000  bestvalidloss 6098.82032  last_update 0\n",
      "train: iter 1  trainloss 1117.91817  validloss 1145.16592±0.00000  bestvalidloss 1145.16592  last_update 0\n",
      "train: iter 2  trainloss 923.32555  validloss 930.32752±0.00000  bestvalidloss 930.32752  last_update 0\n",
      "train: iter 3  trainloss 894.40961  validloss 949.25763±0.00000  bestvalidloss 930.32752  last_update 1\n",
      "train: iter 4  trainloss 839.34675  validloss 986.85049±0.00000  bestvalidloss 930.32752  last_update 2\n",
      "train: iter 5  trainloss 804.05712  validloss 901.29377±0.00000  bestvalidloss 901.29377  last_update 0\n",
      "train: iter 6  trainloss 773.80511  validloss 843.16758±0.00000  bestvalidloss 843.16758  last_update 0\n",
      "train: iter 7  trainloss 728.81887  validloss 838.78502±0.00000  bestvalidloss 838.78502  last_update 0\n",
      "train: iter 8  trainloss 678.30039  validloss 772.33170±0.00000  bestvalidloss 772.33170  last_update 0\n",
      "train: iter 9  trainloss 607.65664  validloss 721.70384±0.00000  bestvalidloss 721.70384  last_update 0\n",
      "train: iter 10  trainloss 502.86583  validloss 634.75402±0.00000  bestvalidloss 634.75402  last_update 0\n",
      "train: iter 11  trainloss 355.67580  validloss 482.57917±0.00000  bestvalidloss 482.57917  last_update 0\n",
      "train: iter 12  trainloss 245.95956  validloss 376.63805±0.00000  bestvalidloss 376.63805  last_update 0\n",
      "train: iter 13  trainloss 212.19880  validloss 351.80475±0.00000  bestvalidloss 351.80475  last_update 0\n",
      "train: iter 14  trainloss 76.51401  validloss 275.47487±0.00000  bestvalidloss 275.47487  last_update 0\n",
      "train: iter 15  trainloss 33.23475  validloss 149.44239±0.00000  bestvalidloss 149.44239  last_update 0\n",
      "train: iter 16  trainloss 12.65605  validloss 346.22604±0.00000  bestvalidloss 149.44239  last_update 1\n",
      "train: iter 17  trainloss -108.22990  validloss 60.73299±0.00000  bestvalidloss 60.73299  last_update 0\n",
      "train: iter 18  trainloss -126.42961  validloss -14.27957±0.00000  bestvalidloss -14.27957  last_update 0\n",
      "train: iter 19  trainloss -182.74860  validloss -31.07272±0.00000  bestvalidloss -31.07272  last_update 0\n",
      "train: iter 20  trainloss -171.20960  validloss -24.59643±0.00000  bestvalidloss -31.07272  last_update 1\n",
      "train: iter 21  trainloss -182.46680  validloss -111.24339±0.00000  bestvalidloss -111.24339  last_update 0\n",
      "train: iter 22  trainloss -226.12882  validloss -76.31308±0.00000  bestvalidloss -111.24339  last_update 1\n",
      "train: iter 23  trainloss -275.27912  validloss -110.71248±0.00000  bestvalidloss -111.24339  last_update 2\n",
      "train: iter 24  trainloss -307.40263  validloss -163.89504±0.00000  bestvalidloss -163.89504  last_update 0\n",
      "train: iter 25  trainloss -341.69284  validloss -181.34495±0.00000  bestvalidloss -181.34495  last_update 0\n",
      "train: iter 26  trainloss -342.80367  validloss -227.50080±0.00000  bestvalidloss -227.50080  last_update 0\n",
      "train: iter 27  trainloss -363.86504  validloss -244.79753±0.00000  bestvalidloss -244.79753  last_update 0\n",
      "train: iter 28  trainloss -379.06478  validloss -236.63644±0.00000  bestvalidloss -244.79753  last_update 1\n",
      "train: iter 29  trainloss -395.73624  validloss -262.59700±0.00000  bestvalidloss -262.59700  last_update 0\n",
      "train: iter 30  trainloss -414.00444  validloss -267.39287±0.00000  bestvalidloss -267.39287  last_update 0\n",
      "train: iter 31  trainloss -428.56018  validloss -326.59930±0.00000  bestvalidloss -326.59930  last_update 0\n",
      "train: iter 32  trainloss -269.96040  validloss -248.54771±0.00000  bestvalidloss -326.59930  last_update 1\n",
      "train: iter 33  trainloss -315.15527  validloss -57.23376±0.00000  bestvalidloss -326.59930  last_update 2\n",
      "train: iter 34  trainloss -409.42107  validloss -285.94809±0.00000  bestvalidloss -326.59930  last_update 3\n",
      "train: iter 35  trainloss -453.39657  validloss -347.37682±0.00000  bestvalidloss -347.37682  last_update 0\n",
      "train: iter 36  trainloss -450.02531  validloss -328.64687±0.00000  bestvalidloss -347.37682  last_update 1\n",
      "train: iter 37  trainloss -517.84417  validloss -291.43594±0.00000  bestvalidloss -347.37682  last_update 2\n",
      "train: iter 38  trainloss -492.17543  validloss -415.21982±0.00000  bestvalidloss -415.21982  last_update 0\n",
      "train: iter 39  trainloss -537.60530  validloss -352.83526±0.00000  bestvalidloss -415.21982  last_update 1\n",
      "train: iter 40  trainloss -493.76690  validloss -392.11481±0.00000  bestvalidloss -415.21982  last_update 2\n",
      "train: iter 41  trainloss -567.56756  validloss -389.44043±0.00000  bestvalidloss -415.21982  last_update 3\n",
      "train: iter 42  trainloss -607.69157  validloss -440.64803±0.00000  bestvalidloss -440.64803  last_update 0\n",
      "train: iter 43  trainloss -391.90330  validloss -319.33054±0.00000  bestvalidloss -440.64803  last_update 1\n",
      "train: iter 44  trainloss -548.52887  validloss -216.28239±0.00000  bestvalidloss -440.64803  last_update 2\n",
      "train: iter 45  trainloss -420.01259  validloss -333.11987±0.00000  bestvalidloss -440.64803  last_update 3\n",
      "train: iter 46  trainloss -555.39833  validloss -259.80207±0.00000  bestvalidloss -440.64803  last_update 4\n",
      "train: iter 47  trainloss -596.99421  validloss -347.34070±0.00000  bestvalidloss -440.64803  last_update 5\n",
      "train: iter 48  trainloss -470.61585  validloss -385.41976±0.00000  bestvalidloss -440.64803  last_update 6\n",
      "train: iter 49  trainloss -525.82605  validloss -249.49419±0.00000  bestvalidloss -440.64803  last_update 7\n",
      "train: iter 50  trainloss -621.69544  validloss -455.14694±0.00000  bestvalidloss -455.14694  last_update 0\n",
      "train: iter 51  trainloss -592.42819  validloss -486.18939±0.00000  bestvalidloss -486.18939  last_update 0\n",
      "train: iter 52  trainloss -620.01358  validloss -452.97223±0.00000  bestvalidloss -486.18939  last_update 1\n",
      "train: iter 53  trainloss -645.30571  validloss -539.19582±0.00000  bestvalidloss -539.19582  last_update 0\n",
      "train: iter 54  trainloss -504.83067  validloss -546.28320±0.00000  bestvalidloss -546.28320  last_update 0\n",
      "train: iter 55  trainloss -673.51876  validloss -495.98982±0.00000  bestvalidloss -546.28320  last_update 1\n",
      "train: iter 56  trainloss -691.50015  validloss -537.81592±0.00000  bestvalidloss -546.28320  last_update 2\n",
      "train: iter 57  trainloss -632.81416  validloss -498.05413±0.00000  bestvalidloss -546.28320  last_update 3\n",
      "train: iter 58  trainloss -690.86763  validloss -487.87975±0.00000  bestvalidloss -546.28320  last_update 4\n",
      "train: iter 59  trainloss -665.69444  validloss -534.60504±0.00000  bestvalidloss -546.28320  last_update 5\n",
      "train: iter 60  trainloss -706.68296  validloss -461.15523±0.00000  bestvalidloss -546.28320  last_update 6\n",
      "train: iter 61  trainloss -681.62935  validloss -599.99986±0.00000  bestvalidloss -599.99986  last_update 0\n",
      "train: iter 62  trainloss -670.52527  validloss -386.97928±0.00000  bestvalidloss -599.99986  last_update 1\n",
      "train: iter 63  trainloss -746.89853  validloss -582.55968±0.00000  bestvalidloss -599.99986  last_update 2\n",
      "train: iter 64  trainloss -698.21345  validloss -571.04644±0.00000  bestvalidloss -599.99986  last_update 3\n",
      "train: iter 65  trainloss -699.35270  validloss -486.22033±0.00000  bestvalidloss -599.99986  last_update 4\n",
      "train: iter 66  trainloss -714.39142  validloss -525.66383±0.00000  bestvalidloss -599.99986  last_update 5\n",
      "train: iter 67  trainloss -752.16083  validloss -476.02236±0.00000  bestvalidloss -599.99986  last_update 6\n",
      "train: iter 68  trainloss -754.80029  validloss -591.94804±0.00000  bestvalidloss -599.99986  last_update 7\n",
      "train: iter 69  trainloss -603.32855  validloss -639.05440±0.00000  bestvalidloss -639.05440  last_update 0\n",
      "train: iter 70  trainloss -709.83025  validloss -378.59919±0.00000  bestvalidloss -639.05440  last_update 1\n",
      "train: iter 71  trainloss -736.80167  validloss -577.53016±0.00000  bestvalidloss -639.05440  last_update 2\n",
      "train: iter 72  trainloss -694.81845  validloss -589.00393±0.00000  bestvalidloss -639.05440  last_update 3\n",
      "train: iter 73  trainloss -769.24740  validloss -560.75761±0.00000  bestvalidloss -639.05440  last_update 4\n",
      "train: iter 74  trainloss -760.65063  validloss -623.11815±0.00000  bestvalidloss -639.05440  last_update 5\n",
      "train: iter 75  trainloss -699.31596  validloss -455.75089±0.00000  bestvalidloss -639.05440  last_update 6\n",
      "train: iter 76  trainloss -739.80850  validloss -591.74797±0.00000  bestvalidloss -639.05440  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -770.80036  validloss -585.41184±0.00000  bestvalidloss -639.05440  last_update 8\n",
      "train: iter 78  trainloss -738.80069  validloss -653.66158±0.00000  bestvalidloss -653.66158  last_update 0\n",
      "train: iter 79  trainloss -821.87520  validloss -601.99893±0.00000  bestvalidloss -653.66158  last_update 1\n",
      "train: iter 80  trainloss -786.82022  validloss -584.83533±0.00000  bestvalidloss -653.66158  last_update 2\n",
      "train: iter 81  trainloss -753.40032  validloss -644.91355±0.00000  bestvalidloss -653.66158  last_update 3\n",
      "train: iter 82  trainloss -822.58860  validloss -637.88735±0.00000  bestvalidloss -653.66158  last_update 4\n",
      "train: iter 83  trainloss -811.17284  validloss -701.46349±0.00000  bestvalidloss -701.46349  last_update 0\n",
      "train: iter 84  trainloss -751.47192  validloss -585.22149±0.00000  bestvalidloss -701.46349  last_update 1\n",
      "train: iter 85  trainloss -822.14623  validloss -592.72848±0.00000  bestvalidloss -701.46349  last_update 2\n",
      "train: iter 86  trainloss -751.82951  validloss -633.87573±0.00000  bestvalidloss -701.46349  last_update 3\n",
      "train: iter 87  trainloss -745.91639  validloss -525.28256±0.00000  bestvalidloss -701.46349  last_update 4\n",
      "train: iter 88  trainloss -647.77459  validloss -679.36165±0.00000  bestvalidloss -701.46349  last_update 5\n",
      "train: iter 89  trainloss -794.81411  validloss -581.58643±0.00000  bestvalidloss -701.46349  last_update 6\n",
      "train: iter 90  trainloss -857.77362  validloss -659.20956±0.00000  bestvalidloss -701.46349  last_update 7\n",
      "train: iter 91  trainloss -818.72809  validloss -697.78005±0.00000  bestvalidloss -701.46349  last_update 8\n",
      "train: iter 92  trainloss -831.52930  validloss -650.53954±0.00000  bestvalidloss -701.46349  last_update 9\n",
      "train: iter 93  trainloss -827.97065  validloss -711.29866±0.00000  bestvalidloss -711.29866  last_update 0\n",
      "train: iter 94  trainloss -831.30354  validloss -620.95653±0.00000  bestvalidloss -711.29866  last_update 1\n",
      "train: iter 95  trainloss -836.13900  validloss -712.53461±0.00000  bestvalidloss -712.53461  last_update 0\n",
      "train: iter 96  trainloss -860.26499  validloss -619.11486±0.00000  bestvalidloss -712.53461  last_update 1\n",
      "train: iter 97  trainloss -783.70606  validloss -536.85041±0.00000  bestvalidloss -712.53461  last_update 2\n",
      "train: iter 98  trainloss -778.28886  validloss -356.11818±0.00000  bestvalidloss -712.53461  last_update 3\n",
      "train: iter 99  trainloss -852.62172  validloss -645.50469±0.00000  bestvalidloss -712.53461  last_update 4\n",
      "train: iter 100  trainloss -802.87436  validloss -636.92366±0.00000  bestvalidloss -712.53461  last_update 5\n",
      "train: iter 101  trainloss -888.96605  validloss -733.60157±0.00000  bestvalidloss -733.60157  last_update 0\n",
      "train: iter 102  trainloss -817.63826  validloss -781.57049±0.00000  bestvalidloss -781.57049  last_update 0\n",
      "train: iter 103  trainloss -870.86194  validloss -682.19460±0.00000  bestvalidloss -781.57049  last_update 1\n",
      "train: iter 104  trainloss -914.46552  validloss -717.76212±0.00000  bestvalidloss -781.57049  last_update 2\n",
      "train: iter 105  trainloss -894.30096  validloss -720.40606±0.00000  bestvalidloss -781.57049  last_update 3\n",
      "train: iter 106  trainloss -912.30341  validloss -731.77133±0.00000  bestvalidloss -781.57049  last_update 4\n",
      "train: iter 107  trainloss -583.29588  validloss -778.62976±0.00000  bestvalidloss -781.57049  last_update 5\n",
      "train: iter 108  trainloss -726.44317  validloss -447.96674±0.00000  bestvalidloss -781.57049  last_update 6\n",
      "train: iter 109  trainloss -761.45854  validloss -645.70632±0.00000  bestvalidloss -781.57049  last_update 7\n",
      "train: iter 110  trainloss -894.78389  validloss -634.78743±0.00000  bestvalidloss -781.57049  last_update 8\n",
      "train: iter 111  trainloss -779.25702  validloss -620.31154±0.00000  bestvalidloss -781.57049  last_update 9\n",
      "train: iter 112  trainloss -924.24615  validloss -768.45779±0.00000  bestvalidloss -781.57049  last_update 10\n",
      "train: iter 113  trainloss -905.11092  validloss -735.10215±0.00000  bestvalidloss -781.57049  last_update 11\n",
      "train: iter 114  trainloss -930.80282  validloss -771.76787±0.00000  bestvalidloss -781.57049  last_update 12\n",
      "train: iter 115  trainloss -834.31371  validloss -796.27430±0.00000  bestvalidloss -796.27430  last_update 0\n",
      "train: iter 116  trainloss -907.63885  validloss -637.39111±0.00000  bestvalidloss -796.27430  last_update 1\n",
      "train: iter 117  trainloss -910.32470  validloss -718.46935±0.00000  bestvalidloss -796.27430  last_update 2\n",
      "train: iter 118  trainloss -973.49061  validloss -792.24460±0.00000  bestvalidloss -796.27430  last_update 3\n",
      "train: iter 119  trainloss -930.50093  validloss -825.39746±0.00000  bestvalidloss -825.39746  last_update 0\n",
      "train: iter 120  trainloss -869.43545  validloss -577.20683±0.00000  bestvalidloss -825.39746  last_update 1\n",
      "train: iter 121  trainloss -928.45047  validloss -709.20112±0.00000  bestvalidloss -825.39746  last_update 2\n",
      "train: iter 122  trainloss -845.81456  validloss -757.70889±0.00000  bestvalidloss -825.39746  last_update 3\n",
      "train: iter 123  trainloss -820.44565  validloss -798.79842±0.00000  bestvalidloss -825.39746  last_update 4\n",
      "train: iter 124  trainloss -899.06648  validloss -584.66941±0.00000  bestvalidloss -825.39746  last_update 5\n",
      "train: iter 125  trainloss -949.22130  validloss -786.14863±0.00000  bestvalidloss -825.39746  last_update 6\n",
      "train: iter 126  trainloss -992.19647  validloss -692.95931±0.00000  bestvalidloss -825.39746  last_update 7\n",
      "train: iter 127  trainloss -992.78398  validloss -837.13530±0.00000  bestvalidloss -837.13530  last_update 0\n",
      "train: iter 128  trainloss -987.80058  validloss -843.19459±0.00000  bestvalidloss -843.19459  last_update 0\n",
      "train: iter 129  trainloss -983.78141  validloss -893.34254±0.00000  bestvalidloss -893.34254  last_update 0\n",
      "train: iter 130  trainloss -973.06634  validloss -766.35448±0.00000  bestvalidloss -893.34254  last_update 1\n",
      "train: iter 131  trainloss -949.44791  validloss -912.88875±0.00000  bestvalidloss -912.88875  last_update 0\n",
      "train: iter 132  trainloss -863.02692  validloss -798.01077±0.00000  bestvalidloss -912.88875  last_update 1\n",
      "train: iter 133  trainloss -886.09564  validloss -793.39649±0.00000  bestvalidloss -912.88875  last_update 2\n",
      "train: iter 134  trainloss -960.70137  validloss -725.06090±0.00000  bestvalidloss -912.88875  last_update 3\n",
      "train: iter 135  trainloss -1023.75998  validloss -708.54753±0.00000  bestvalidloss -912.88875  last_update 4\n",
      "train: iter 136  trainloss -946.51423  validloss -720.02168±0.00000  bestvalidloss -912.88875  last_update 5\n",
      "train: iter 137  trainloss -947.32801  validloss -880.27848±0.00000  bestvalidloss -912.88875  last_update 6\n",
      "train: iter 138  trainloss -944.55890  validloss -816.93964±0.00000  bestvalidloss -912.88875  last_update 7\n",
      "train: iter 139  trainloss -1026.34319  validloss -870.62267±0.00000  bestvalidloss -912.88875  last_update 8\n",
      "train: iter 140  trainloss -996.71501  validloss -884.98065±0.00000  bestvalidloss -912.88875  last_update 9\n",
      "train: iter 141  trainloss -930.98655  validloss -801.60372±0.00000  bestvalidloss -912.88875  last_update 10\n",
      "train: iter 142  trainloss -958.48632  validloss -842.60780±0.00000  bestvalidloss -912.88875  last_update 11\n",
      "train: iter 143  trainloss -911.00830  validloss -516.73094±0.00000  bestvalidloss -912.88875  last_update 12\n",
      "train: iter 144  trainloss -971.97765  validloss -849.37175±0.00000  bestvalidloss -912.88875  last_update 13\n",
      "train: iter 145  trainloss -1008.07935  validloss -842.32465±0.00000  bestvalidloss -912.88875  last_update 14\n",
      "train: iter 146  trainloss -1071.89224  validloss -834.88755±0.00000  bestvalidloss -912.88875  last_update 15\n",
      "train: iter 147  trainloss -1082.27101  validloss -887.12032±0.00000  bestvalidloss -912.88875  last_update 16\n",
      "train: iter 148  trainloss -1031.17892  validloss -926.55239±0.00000  bestvalidloss -926.55239  last_update 0\n",
      "train: iter 149  trainloss -1005.36778  validloss -678.32776±0.00000  bestvalidloss -926.55239  last_update 1\n",
      "train: iter 150  trainloss -1032.16928  validloss -905.74225±0.00000  bestvalidloss -926.55239  last_update 2\n",
      "train: iter 151  trainloss -992.55657  validloss -757.93803±0.00000  bestvalidloss -926.55239  last_update 3\n",
      "train: iter 152  trainloss -1051.08315  validloss -880.05247±0.00000  bestvalidloss -926.55239  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -953.91687  validloss -742.22755±0.00000  bestvalidloss -926.55239  last_update 5\n",
      "train: iter 154  trainloss -977.07401  validloss -733.00653±0.00000  bestvalidloss -926.55239  last_update 6\n",
      "train: iter 155  trainloss -932.36313  validloss -825.90083±0.00000  bestvalidloss -926.55239  last_update 7\n",
      "train: iter 156  trainloss -1052.75604  validloss -838.71129±0.00000  bestvalidloss -926.55239  last_update 8\n",
      "train: iter 157  trainloss -1063.90838  validloss -863.19850±0.00000  bestvalidloss -926.55239  last_update 9\n",
      "train: iter 158  trainloss -713.80251  validloss -18.43032±0.00000  bestvalidloss -926.55239  last_update 10\n",
      "train: iter 159  trainloss -890.40109  validloss -676.63495±0.00000  bestvalidloss -926.55239  last_update 11\n",
      "train: iter 160  trainloss -838.51862  validloss -347.95625±0.00000  bestvalidloss -926.55239  last_update 12\n",
      "train: iter 161  trainloss -1107.80129  validloss -924.61989±0.00000  bestvalidloss -926.55239  last_update 13\n",
      "train: iter 162  trainloss -1135.38174  validloss -930.21398±0.00000  bestvalidloss -930.21398  last_update 0\n",
      "train: iter 163  trainloss -1154.52357  validloss -1001.95660±0.00000  bestvalidloss -1001.95660  last_update 0\n",
      "train: iter 164  trainloss -1104.78227  validloss -915.23030±0.00000  bestvalidloss -1001.95660  last_update 1\n",
      "train: iter 165  trainloss -1143.21728  validloss -933.56599±0.00000  bestvalidloss -1001.95660  last_update 2\n",
      "train: iter 166  trainloss -1089.44245  validloss -956.31298±0.00000  bestvalidloss -1001.95660  last_update 3\n",
      "train: iter 167  trainloss -1015.80942  validloss -537.58960±0.00000  bestvalidloss -1001.95660  last_update 4\n",
      "train: iter 168  trainloss -1188.00572  validloss -1002.39466±0.00000  bestvalidloss -1002.39466  last_update 0\n",
      "train: iter 169  trainloss -1087.45110  validloss -979.53227±0.00000  bestvalidloss -1002.39466  last_update 1\n",
      "train: iter 170  trainloss -1146.74249  validloss -962.36954±0.00000  bestvalidloss -1002.39466  last_update 2\n",
      "train: iter 171  trainloss -1175.85965  validloss -963.49770±0.00000  bestvalidloss -1002.39466  last_update 3\n",
      "train: iter 172  trainloss -1144.14901  validloss -934.55032±0.00000  bestvalidloss -1002.39466  last_update 4\n",
      "train: iter 173  trainloss -1040.75876  validloss -994.03786±0.00000  bestvalidloss -1002.39466  last_update 5\n",
      "train: iter 174  trainloss -1119.89692  validloss -895.17390±0.00000  bestvalidloss -1002.39466  last_update 6\n",
      "train: iter 175  trainloss -1176.42987  validloss -961.97876±0.00000  bestvalidloss -1002.39466  last_update 7\n",
      "train: iter 176  trainloss -1070.41334  validloss -953.88791±0.00000  bestvalidloss -1002.39466  last_update 8\n",
      "train: iter 177  trainloss -1112.88498  validloss -905.84502±0.00000  bestvalidloss -1002.39466  last_update 9\n",
      "train: iter 178  trainloss -1226.54221  validloss -970.01803±0.00000  bestvalidloss -1002.39466  last_update 10\n",
      "train: iter 179  trainloss -1090.99431  validloss -1006.46478±0.00000  bestvalidloss -1006.46478  last_update 0\n",
      "train: iter 180  trainloss -1208.47653  validloss -1015.35481±0.00000  bestvalidloss -1015.35481  last_update 0\n",
      "train: iter 181  trainloss -1097.22419  validloss -953.91717±0.00000  bestvalidloss -1015.35481  last_update 1\n",
      "train: iter 182  trainloss -670.93474  validloss -776.45950±0.00000  bestvalidloss -1015.35481  last_update 2\n",
      "train: iter 183  trainloss -952.28551  validloss -742.61978±0.00000  bestvalidloss -1015.35481  last_update 3\n",
      "train: iter 184  trainloss -1074.79836  validloss -803.08515±0.00000  bestvalidloss -1015.35481  last_update 4\n",
      "train: iter 185  trainloss -1067.67641  validloss -851.04633±0.00000  bestvalidloss -1015.35481  last_update 5\n",
      "train: iter 186  trainloss -1139.21580  validloss -804.00513±0.00000  bestvalidloss -1015.35481  last_update 6\n",
      "train: iter 187  trainloss -820.72645  validloss -901.76240±0.00000  bestvalidloss -1015.35481  last_update 7\n",
      "train: iter 188  trainloss -999.42314  validloss -684.15725±0.00000  bestvalidloss -1015.35481  last_update 8\n",
      "train: iter 189  trainloss -1109.19459  validloss -882.43874±0.00000  bestvalidloss -1015.35481  last_update 9\n",
      "train: iter 190  trainloss -1204.35321  validloss -922.98848±0.00000  bestvalidloss -1015.35481  last_update 10\n",
      "train: iter 191  trainloss -1257.21078  validloss -1022.84415±0.00000  bestvalidloss -1022.84415  last_update 0\n",
      "train: iter 192  trainloss -927.23792  validloss -1039.69447±0.00000  bestvalidloss -1039.69447  last_update 0\n",
      "train: iter 193  trainloss -1164.40990  validloss -924.96229±0.00000  bestvalidloss -1039.69447  last_update 1\n",
      "train: iter 194  trainloss -1086.99101  validloss -1001.89043±0.00000  bestvalidloss -1039.69447  last_update 2\n",
      "train: iter 195  trainloss -1157.77023  validloss -1015.17031±0.00000  bestvalidloss -1039.69447  last_update 3\n",
      "train: iter 196  trainloss -1274.29004  validloss -1061.56753±0.00000  bestvalidloss -1061.56753  last_update 0\n",
      "train: iter 197  trainloss -1210.00950  validloss -1104.20324±0.00000  bestvalidloss -1104.20324  last_update 0\n",
      "train: iter 198  trainloss -1219.68087  validloss -893.51558±0.00000  bestvalidloss -1104.20324  last_update 1\n",
      "train: iter 199  trainloss -1272.38485  validloss -1044.88055±0.00000  bestvalidloss -1104.20324  last_update 2\n",
      "train: iter 200  trainloss -1245.26639  validloss -1000.17669±0.00000  bestvalidloss -1104.20324  last_update 3\n",
      "train: iter 201  trainloss -1274.26544  validloss -1046.03253±0.00000  bestvalidloss -1104.20324  last_update 4\n",
      "train: iter 202  trainloss -1199.36974  validloss -1071.00414±0.00000  bestvalidloss -1104.20324  last_update 5\n",
      "train: iter 203  trainloss -1265.98228  validloss -1078.75757±0.00000  bestvalidloss -1104.20324  last_update 6\n",
      "train: iter 204  trainloss -1071.46070  validloss -892.80796±0.00000  bestvalidloss -1104.20324  last_update 7\n",
      "train: iter 205  trainloss -1267.58720  validloss -1016.22385±0.00000  bestvalidloss -1104.20324  last_update 8\n",
      "train: iter 206  trainloss -1191.99906  validloss -1057.46966±0.00000  bestvalidloss -1104.20324  last_update 9\n",
      "train: iter 207  trainloss -1040.28536  validloss -956.25844±0.00000  bestvalidloss -1104.20324  last_update 10\n",
      "train: iter 208  trainloss -1248.31285  validloss -980.53009±0.00000  bestvalidloss -1104.20324  last_update 11\n",
      "train: iter 209  trainloss -1215.45282  validloss -1122.08381±0.00000  bestvalidloss -1122.08381  last_update 0\n",
      "train: iter 210  trainloss -1221.46924  validloss -941.09676±0.00000  bestvalidloss -1122.08381  last_update 1\n",
      "train: iter 211  trainloss -1229.85472  validloss -1113.83768±0.00000  bestvalidloss -1122.08381  last_update 2\n",
      "train: iter 212  trainloss -1279.04745  validloss -1037.90512±0.00000  bestvalidloss -1122.08381  last_update 3\n",
      "train: iter 213  trainloss -1230.93224  validloss -1040.13711±0.00000  bestvalidloss -1122.08381  last_update 4\n",
      "train: iter 214  trainloss -1252.25948  validloss -1105.20958±0.00000  bestvalidloss -1122.08381  last_update 5\n",
      "train: iter 215  trainloss -1245.81611  validloss -1065.59981±0.00000  bestvalidloss -1122.08381  last_update 6\n",
      "train: iter 216  trainloss -1219.90875  validloss -1111.70278±0.00000  bestvalidloss -1122.08381  last_update 7\n",
      "train: iter 217  trainloss -1293.96557  validloss -961.52690±0.00000  bestvalidloss -1122.08381  last_update 8\n",
      "train: iter 218  trainloss -1042.14983  validloss -1100.75472±0.00000  bestvalidloss -1122.08381  last_update 9\n",
      "train: iter 219  trainloss -1201.38150  validloss -920.50483±0.00000  bestvalidloss -1122.08381  last_update 10\n",
      "train: iter 220  trainloss -1309.76004  validloss -1087.92721±0.00000  bestvalidloss -1122.08381  last_update 11\n",
      "train: iter 221  trainloss -1265.93393  validloss -1061.16773±0.00000  bestvalidloss -1122.08381  last_update 12\n",
      "train: iter 222  trainloss -1307.83728  validloss -1071.06824±0.00000  bestvalidloss -1122.08381  last_update 13\n",
      "train: iter 223  trainloss -1309.06261  validloss -1069.27098±0.00000  bestvalidloss -1122.08381  last_update 14\n",
      "train: iter 224  trainloss -1265.47899  validloss -1034.61245±0.00000  bestvalidloss -1122.08381  last_update 15\n",
      "train: iter 225  trainloss -1319.96808  validloss -1053.66123±0.00000  bestvalidloss -1122.08381  last_update 16\n",
      "train: iter 226  trainloss -1242.30736  validloss -1029.26588±0.00000  bestvalidloss -1122.08381  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 227  trainloss -1296.48112  validloss -1024.34429±0.00000  bestvalidloss -1122.08381  last_update 18\n",
      "train: iter 228  trainloss -1269.53736  validloss -947.70833±0.00000  bestvalidloss -1122.08381  last_update 19\n",
      "train: iter 229  trainloss -1316.95841  validloss -1078.35880±0.00000  bestvalidloss -1122.08381  last_update 20\n",
      "train: iter 230  trainloss -1250.74767  validloss -1030.08771±0.00000  bestvalidloss -1122.08381  last_update 21\n",
      "train: iter 231  trainloss -1277.27242  validloss -1100.69859±0.00000  bestvalidloss -1122.08381  last_update 22\n",
      "train: iter 232  trainloss -1298.77540  validloss -1069.36548±0.00000  bestvalidloss -1122.08381  last_update 23\n",
      "train: iter 233  trainloss -1361.07208  validloss -1136.05802±0.00000  bestvalidloss -1136.05802  last_update 0\n",
      "train: iter 234  trainloss -1267.44320  validloss -1142.78221±0.00000  bestvalidloss -1142.78221  last_update 0\n",
      "train: iter 235  trainloss -1334.30735  validloss -1124.49611±0.00000  bestvalidloss -1142.78221  last_update 1\n",
      "train: iter 236  trainloss -1275.10249  validloss -984.03820±0.00000  bestvalidloss -1142.78221  last_update 2\n",
      "train: iter 237  trainloss -1057.11239  validloss -1111.72614±0.00000  bestvalidloss -1142.78221  last_update 3\n",
      "train: iter 238  trainloss -1166.79185  validloss -853.28744±0.00000  bestvalidloss -1142.78221  last_update 4\n",
      "train: iter 239  trainloss -1360.37852  validloss -1093.95155±0.00000  bestvalidloss -1142.78221  last_update 5\n",
      "train: iter 240  trainloss -1278.75156  validloss -1150.09697±0.00000  bestvalidloss -1150.09697  last_update 0\n",
      "train: iter 241  trainloss -1355.46435  validloss -1098.20797±0.00000  bestvalidloss -1150.09697  last_update 1\n",
      "train: iter 242  trainloss -1307.82085  validloss -718.19686±0.00000  bestvalidloss -1150.09697  last_update 2\n",
      "train: iter 243  trainloss -1365.26903  validloss -1149.27694±0.00000  bestvalidloss -1150.09697  last_update 3\n",
      "train: iter 244  trainloss -1197.64388  validloss -914.25045±0.00000  bestvalidloss -1150.09697  last_update 4\n",
      "train: iter 245  trainloss -1200.64126  validloss -1032.46871±0.00000  bestvalidloss -1150.09697  last_update 5\n",
      "train: iter 246  trainloss -1326.79007  validloss -910.25443±0.00000  bestvalidloss -1150.09697  last_update 6\n",
      "train: iter 247  trainloss -1205.78678  validloss -1096.81327±0.00000  bestvalidloss -1150.09697  last_update 7\n",
      "train: iter 248  trainloss -1353.78909  validloss -1015.33262±0.00000  bestvalidloss -1150.09697  last_update 8\n",
      "train: iter 249  trainloss -1364.58735  validloss -1101.64817±0.00000  bestvalidloss -1150.09697  last_update 9\n",
      "train: iter 250  trainloss -1374.66296  validloss -1135.95267±0.00000  bestvalidloss -1150.09697  last_update 10\n",
      "train: iter 251  trainloss -1212.81436  validloss -1043.39153±0.00000  bestvalidloss -1150.09697  last_update 11\n",
      "train: iter 252  trainloss -1342.87558  validloss -1007.65860±0.00000  bestvalidloss -1150.09697  last_update 12\n",
      "train: iter 253  trainloss -1393.11363  validloss -1137.25125±0.00000  bestvalidloss -1150.09697  last_update 13\n",
      "train: iter 254  trainloss -1341.68892  validloss -1126.59022±0.00000  bestvalidloss -1150.09697  last_update 14\n",
      "train: iter 255  trainloss -1030.71824  validloss -1099.07517±0.00000  bestvalidloss -1150.09697  last_update 15\n",
      "train: iter 256  trainloss -1293.94153  validloss -1013.50491±0.00000  bestvalidloss -1150.09697  last_update 16\n",
      "train: iter 257  trainloss -1354.44716  validloss -1087.93018±0.00000  bestvalidloss -1150.09697  last_update 17\n",
      "train: iter 258  trainloss -1294.92441  validloss -1115.47698±0.00000  bestvalidloss -1150.09697  last_update 18\n",
      "train: iter 259  trainloss -1321.47718  validloss -1122.11760±0.00000  bestvalidloss -1150.09697  last_update 19\n",
      "train: iter 260  trainloss -1140.88033  validloss -1019.74674±0.00000  bestvalidloss -1150.09697  last_update 20\n",
      "train: iter 261  trainloss -1326.31512  validloss -1081.38583±0.00000  bestvalidloss -1150.09697  last_update 21\n",
      "train: iter 262  trainloss -1242.59755  validloss -1091.41435±0.00000  bestvalidloss -1150.09697  last_update 22\n",
      "train: iter 263  trainloss -1359.47734  validloss -1178.41010±0.00000  bestvalidloss -1178.41010  last_update 0\n",
      "train: iter 264  trainloss -1407.32456  validloss -1201.43431±0.00000  bestvalidloss -1201.43431  last_update 0\n",
      "train: iter 265  trainloss -1394.36029  validloss -1120.81215±0.00000  bestvalidloss -1201.43431  last_update 1\n",
      "train: iter 266  trainloss -1412.38061  validloss -1243.53117±0.00000  bestvalidloss -1243.53117  last_update 0\n",
      "train: iter 267  trainloss -1337.00414  validloss -1079.28794±0.00000  bestvalidloss -1243.53117  last_update 1\n",
      "train: iter 268  trainloss -1402.33175  validloss -1194.54217±0.00000  bestvalidloss -1243.53117  last_update 2\n",
      "train: iter 269  trainloss -1330.71754  validloss -1228.21890±0.00000  bestvalidloss -1243.53117  last_update 3\n",
      "train: iter 270  trainloss -1232.74500  validloss -1082.40733±0.00000  bestvalidloss -1243.53117  last_update 4\n",
      "train: iter 271  trainloss -1381.05558  validloss -1125.42766±0.00000  bestvalidloss -1243.53117  last_update 5\n",
      "train: iter 272  trainloss -1321.24981  validloss -1183.43066±0.00000  bestvalidloss -1243.53117  last_update 6\n",
      "train: iter 273  trainloss -1305.16543  validloss -1070.69539±0.00000  bestvalidloss -1243.53117  last_update 7\n",
      "train: iter 274  trainloss -1363.49260  validloss -1178.54059±0.00000  bestvalidloss -1243.53117  last_update 8\n",
      "train: iter 275  trainloss -1393.48572  validloss -1122.31444±0.00000  bestvalidloss -1243.53117  last_update 9\n",
      "train: iter 276  trainloss -1420.07132  validloss -1225.97930±0.00000  bestvalidloss -1243.53117  last_update 10\n",
      "train: iter 277  trainloss -1344.00513  validloss -1250.40674±0.00000  bestvalidloss -1250.40674  last_update 0\n",
      "train: iter 278  trainloss -1440.82970  validloss -1263.44049±0.00000  bestvalidloss -1263.44049  last_update 0\n",
      "train: iter 279  trainloss -1353.96065  validloss -1267.98413±0.00000  bestvalidloss -1267.98413  last_update 0\n",
      "train: iter 280  trainloss -1376.54600  validloss -1136.37299±0.00000  bestvalidloss -1267.98413  last_update 1\n",
      "train: iter 281  trainloss -1423.18097  validloss -1216.07353±0.00000  bestvalidloss -1267.98413  last_update 2\n",
      "train: iter 282  trainloss -1399.47934  validloss -1238.18578±0.00000  bestvalidloss -1267.98413  last_update 3\n",
      "train: iter 283  trainloss -1379.65286  validloss -1288.41770±0.00000  bestvalidloss -1288.41770  last_update 0\n",
      "train: iter 284  trainloss -1068.82658  validloss -1144.93797±0.00000  bestvalidloss -1288.41770  last_update 1\n",
      "train: iter 285  trainloss -1382.11562  validloss -1032.66768±0.00000  bestvalidloss -1288.41770  last_update 2\n",
      "train: iter 286  trainloss -1389.23993  validloss -1146.75413±0.00000  bestvalidloss -1288.41770  last_update 3\n",
      "train: iter 287  trainloss -1324.36428  validloss -1209.65912±0.00000  bestvalidloss -1288.41770  last_update 4\n",
      "train: iter 288  trainloss -1308.35090  validloss -1143.98566±0.00000  bestvalidloss -1288.41770  last_update 5\n",
      "train: iter 289  trainloss -1410.48347  validloss -1222.94434±0.00000  bestvalidloss -1288.41770  last_update 6\n",
      "train: iter 290  trainloss -1434.87780  validloss -1100.78089±0.00000  bestvalidloss -1288.41770  last_update 7\n",
      "train: iter 291  trainloss -1440.73698  validloss -1264.35268±0.00000  bestvalidloss -1288.41770  last_update 8\n",
      "train: iter 292  trainloss -1229.64626  validloss -1246.90223±0.00000  bestvalidloss -1288.41770  last_update 9\n",
      "train: iter 293  trainloss -1276.79911  validloss -846.49677±0.00000  bestvalidloss -1288.41770  last_update 10\n",
      "train: iter 294  trainloss -1370.32303  validloss -1131.83965±0.00000  bestvalidloss -1288.41770  last_update 11\n",
      "train: iter 295  trainloss -1345.83397  validloss -924.89304±0.00000  bestvalidloss -1288.41770  last_update 12\n",
      "train: iter 296  trainloss -1367.31409  validloss -1146.84116±0.00000  bestvalidloss -1288.41770  last_update 13\n",
      "train: iter 297  trainloss -1383.63313  validloss -1190.09695±0.00000  bestvalidloss -1288.41770  last_update 14\n",
      "train: iter 298  trainloss -1394.01451  validloss -1066.91132±0.00000  bestvalidloss -1288.41770  last_update 15\n",
      "train: iter 299  trainloss -1437.90161  validloss -1185.37280±0.00000  bestvalidloss -1288.41770  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 300  trainloss -1442.00912  validloss -1190.23796±0.00000  bestvalidloss -1288.41770  last_update 17\n",
      "train: iter 301  trainloss -1423.00014  validloss -1167.70982±0.00000  bestvalidloss -1288.41770  last_update 18\n",
      "train: iter 302  trainloss -1285.02872  validloss -1246.34969±0.00000  bestvalidloss -1288.41770  last_update 19\n",
      "train: iter 303  trainloss -1283.62564  validloss -851.38494±0.00000  bestvalidloss -1288.41770  last_update 20\n",
      "train: iter 304  trainloss -1355.01803  validloss -1051.30632±0.00000  bestvalidloss -1288.41770  last_update 21\n",
      "train: iter 305  trainloss -1463.10083  validloss -1195.77146±0.00000  bestvalidloss -1288.41770  last_update 22\n",
      "train: iter 306  trainloss -1424.01461  validloss -1221.46405±0.00000  bestvalidloss -1288.41770  last_update 23\n",
      "train: iter 307  trainloss -1409.26415  validloss -1122.87101±0.00000  bestvalidloss -1288.41770  last_update 24\n",
      "train: iter 308  trainloss -1459.95006  validloss -1230.96457±0.00000  bestvalidloss -1288.41770  last_update 25\n",
      "train: iter 309  trainloss -1410.82985  validloss -1242.10975±0.00000  bestvalidloss -1288.41770  last_update 26\n",
      "train: iter 310  trainloss -1249.40234  validloss -1083.09986±0.00000  bestvalidloss -1288.41770  last_update 27\n",
      "train: iter 311  trainloss -1462.84325  validloss -1175.67806±0.00000  bestvalidloss -1288.41770  last_update 28\n",
      "train: iter 312  trainloss -1477.04893  validloss -1249.01221±0.00000  bestvalidloss -1288.41770  last_update 29\n",
      "train: iter 313  trainloss -1450.10785  validloss -1282.61695±0.00000  bestvalidloss -1288.41770  last_update 30\n",
      "train: iter 314  trainloss -1348.74515  validloss -1087.03239±0.00000  bestvalidloss -1288.41770  last_update 31\n",
      "train: iter 315  trainloss -1430.99916  validloss -1228.04228±0.00000  bestvalidloss -1288.41770  last_update 32\n",
      "train: iter 316  trainloss -1433.47864  validloss -1179.20913±0.00000  bestvalidloss -1288.41770  last_update 33\n",
      "train: iter 317  trainloss -1474.28095  validloss -1273.91519±0.00000  bestvalidloss -1288.41770  last_update 34\n",
      "train: iter 318  trainloss -1458.38378  validloss -1181.27514±0.00000  bestvalidloss -1288.41770  last_update 35\n",
      "train: iter 319  trainloss -1367.61454  validloss -1143.38237±0.00000  bestvalidloss -1288.41770  last_update 36\n",
      "train: iter 320  trainloss -1422.53192  validloss -1295.15998±0.00000  bestvalidloss -1295.15998  last_update 0\n",
      "train: iter 321  trainloss -1466.49994  validloss -1231.24158±0.00000  bestvalidloss -1295.15998  last_update 1\n",
      "train: iter 322  trainloss -1372.34934  validloss -1230.83646±0.00000  bestvalidloss -1295.15998  last_update 2\n",
      "train: iter 323  trainloss -1462.07060  validloss -1238.08829±0.00000  bestvalidloss -1295.15998  last_update 3\n",
      "train: iter 324  trainloss -1341.54568  validloss -1079.74096±0.00000  bestvalidloss -1295.15998  last_update 4\n",
      "train: iter 325  trainloss -1466.72201  validloss -1207.57294±0.00000  bestvalidloss -1295.15998  last_update 5\n",
      "train: iter 326  trainloss -1448.03714  validloss -1248.36823±0.00000  bestvalidloss -1295.15998  last_update 6\n",
      "train: iter 327  trainloss -1504.89907  validloss -1298.90226±0.00000  bestvalidloss -1298.90226  last_update 0\n",
      "train: iter 328  trainloss -1452.90869  validloss -1250.74822±0.00000  bestvalidloss -1298.90226  last_update 1\n",
      "train: iter 329  trainloss -1494.40533  validloss -1239.45011±0.00000  bestvalidloss -1298.90226  last_update 2\n",
      "train: iter 330  trainloss -1499.06987  validloss -1242.79447±0.00000  bestvalidloss -1298.90226  last_update 3\n",
      "train: iter 331  trainloss -1498.44449  validloss -1256.61826±0.00000  bestvalidloss -1298.90226  last_update 4\n",
      "train: iter 332  trainloss -1472.71662  validloss -1278.18587±0.00000  bestvalidloss -1298.90226  last_update 5\n",
      "train: iter 333  trainloss -1408.49090  validloss -1256.30286±0.00000  bestvalidloss -1298.90226  last_update 6\n",
      "train: iter 334  trainloss -1226.93584  validloss -1212.95471±0.00000  bestvalidloss -1298.90226  last_update 7\n",
      "train: iter 335  trainloss -1248.74324  validloss -564.96271±0.00000  bestvalidloss -1298.90226  last_update 8\n",
      "train: iter 336  trainloss -1404.36890  validloss -1229.01985±0.00000  bestvalidloss -1298.90226  last_update 9\n",
      "train: iter 337  trainloss -1365.88207  validloss -1126.44059±0.00000  bestvalidloss -1298.90226  last_update 10\n",
      "train: iter 338  trainloss -1481.35138  validloss -1261.59865±0.00000  bestvalidloss -1298.90226  last_update 11\n",
      "train: iter 339  trainloss -1473.10774  validloss -1086.39695±0.00000  bestvalidloss -1298.90226  last_update 12\n",
      "train: iter 340  trainloss -1421.71754  validloss -1316.82442±0.00000  bestvalidloss -1316.82442  last_update 0\n",
      "train: iter 341  trainloss -1076.34554  validloss -1323.41371±0.00000  bestvalidloss -1323.41371  last_update 0\n",
      "train: iter 342  trainloss -1054.16868  validloss -467.65819±0.00000  bestvalidloss -1323.41371  last_update 1\n",
      "train: iter 343  trainloss -1360.48629  validloss -977.27968±0.00000  bestvalidloss -1323.41371  last_update 2\n",
      "train: iter 344  trainloss -1471.46361  validloss -1196.64096±0.00000  bestvalidloss -1323.41371  last_update 3\n",
      "train: iter 345  trainloss -1097.45130  validloss -1278.97228±0.00000  bestvalidloss -1323.41371  last_update 4\n",
      "train: iter 346  trainloss -1373.76331  validloss -1052.19126±0.00000  bestvalidloss -1323.41371  last_update 5\n",
      "train: iter 347  trainloss -1468.67138  validloss -1219.31791±0.00000  bestvalidloss -1323.41371  last_update 6\n",
      "train: iter 348  trainloss -1476.44375  validloss -1262.01256±0.00000  bestvalidloss -1323.41371  last_update 7\n",
      "train: iter 349  trainloss -1420.09799  validloss -1217.10959±0.00000  bestvalidloss -1323.41371  last_update 8\n",
      "train: iter 350  trainloss -1487.64701  validloss -1258.26313±0.00000  bestvalidloss -1323.41371  last_update 9\n",
      "train: iter 351  trainloss -1507.77953  validloss -1307.45873±0.00000  bestvalidloss -1323.41371  last_update 10\n",
      "train: iter 352  trainloss -1515.11104  validloss -1249.19892±0.00000  bestvalidloss -1323.41371  last_update 11\n",
      "train: iter 353  trainloss -1425.28859  validloss -1212.37005±0.00000  bestvalidloss -1323.41371  last_update 12\n",
      "train: iter 354  trainloss -1442.12743  validloss -1234.65267±0.00000  bestvalidloss -1323.41371  last_update 13\n",
      "train: iter 355  trainloss -1423.81474  validloss -1103.85588±0.00000  bestvalidloss -1323.41371  last_update 14\n",
      "train: iter 356  trainloss -1532.55182  validloss -1278.48139±0.00000  bestvalidloss -1323.41371  last_update 15\n",
      "train: iter 357  trainloss -1490.48370  validloss -1329.15236±0.00000  bestvalidloss -1329.15236  last_update 0\n",
      "train: iter 358  trainloss -1435.28738  validloss -1277.23575±0.00000  bestvalidloss -1329.15236  last_update 1\n",
      "train: iter 359  trainloss -1431.95532  validloss -1297.44138±0.00000  bestvalidloss -1329.15236  last_update 2\n",
      "train: iter 360  trainloss -1398.89876  validloss -1274.84064±0.00000  bestvalidloss -1329.15236  last_update 3\n",
      "train: iter 361  trainloss -1540.62422  validloss -1325.85256±0.00000  bestvalidloss -1329.15236  last_update 4\n",
      "train: iter 362  trainloss -1283.10816  validloss -1245.37962±0.00000  bestvalidloss -1329.15236  last_update 5\n",
      "train: iter 363  trainloss -1465.82003  validloss -1277.45441±0.00000  bestvalidloss -1329.15236  last_update 6\n",
      "train: iter 364  trainloss -1499.90461  validloss -1272.86612±0.00000  bestvalidloss -1329.15236  last_update 7\n",
      "train: iter 365  trainloss -1509.89586  validloss -1330.92355±0.00000  bestvalidloss -1330.92355  last_update 0\n",
      "train: iter 366  trainloss -1490.13474  validloss -1217.18641±0.00000  bestvalidloss -1330.92355  last_update 1\n",
      "train: iter 367  trainloss -1434.56607  validloss -817.77187±0.00000  bestvalidloss -1330.92355  last_update 2\n",
      "train: iter 368  trainloss -1542.40812  validloss -1324.86965±0.00000  bestvalidloss -1330.92355  last_update 3\n",
      "train: iter 369  trainloss -1513.95421  validloss -1314.92774±0.00000  bestvalidloss -1330.92355  last_update 4\n",
      "train: iter 370  trainloss -1381.96970  validloss -1333.75637±0.00000  bestvalidloss -1333.75637  last_update 0\n",
      "train: iter 371  trainloss -1455.59641  validloss -1058.09440±0.00000  bestvalidloss -1333.75637  last_update 1\n",
      "train: iter 372  trainloss -1508.61217  validloss -1320.16918±0.00000  bestvalidloss -1333.75637  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 373  trainloss -1269.47151  validloss -1073.38368±0.00000  bestvalidloss -1333.75637  last_update 3\n",
      "train: iter 374  trainloss -1489.84163  validloss -1140.53866±0.00000  bestvalidloss -1333.75637  last_update 4\n",
      "train: iter 375  trainloss -1542.18878  validloss -1306.04465±0.00000  bestvalidloss -1333.75637  last_update 5\n",
      "train: iter 376  trainloss -1446.53302  validloss -1210.23394±0.00000  bestvalidloss -1333.75637  last_update 6\n",
      "train: iter 377  trainloss -1543.44825  validloss -1359.89443±0.00000  bestvalidloss -1359.89443  last_update 0\n",
      "train: iter 378  trainloss -1537.63310  validloss -1247.72172±0.00000  bestvalidloss -1359.89443  last_update 1\n",
      "train: iter 379  trainloss -1558.78052  validloss -1335.27174±0.00000  bestvalidloss -1359.89443  last_update 2\n",
      "train: iter 380  trainloss -1401.86159  validloss -1327.84338±0.00000  bestvalidloss -1359.89443  last_update 3\n",
      "train: iter 381  trainloss -1508.41298  validloss -1159.87173±0.00000  bestvalidloss -1359.89443  last_update 4\n",
      "train: iter 382  trainloss -1489.57348  validloss -1239.35087±0.00000  bestvalidloss -1359.89443  last_update 5\n",
      "train: iter 383  trainloss -1505.06043  validloss -1345.05494±0.00000  bestvalidloss -1359.89443  last_update 6\n",
      "train: iter 384  trainloss -1542.86425  validloss -1276.31548±0.00000  bestvalidloss -1359.89443  last_update 7\n",
      "train: iter 385  trainloss -1534.97428  validloss -1336.93249±0.00000  bestvalidloss -1359.89443  last_update 8\n",
      "train: iter 386  trainloss -1351.29961  validloss -1164.07441±0.00000  bestvalidloss -1359.89443  last_update 9\n",
      "train: iter 387  trainloss -1449.18175  validloss -1287.98689±0.00000  bestvalidloss -1359.89443  last_update 10\n",
      "train: iter 388  trainloss -1110.64786  validloss -1274.86357±0.00000  bestvalidloss -1359.89443  last_update 11\n",
      "train: iter 389  trainloss -1478.30739  validloss -1172.08524±0.00000  bestvalidloss -1359.89443  last_update 12\n",
      "train: iter 390  trainloss -1442.98194  validloss -1219.10111±0.00000  bestvalidloss -1359.89443  last_update 13\n",
      "train: iter 391  trainloss -1477.20086  validloss -1295.29619±0.00000  bestvalidloss -1359.89443  last_update 14\n",
      "train: iter 392  trainloss -1529.45847  validloss -1314.67133±0.00000  bestvalidloss -1359.89443  last_update 15\n",
      "train: iter 393  trainloss -1553.09554  validloss -1377.20592±0.00000  bestvalidloss -1377.20592  last_update 0\n",
      "train: iter 394  trainloss -1372.46249  validloss -1361.23484±0.00000  bestvalidloss -1377.20592  last_update 1\n",
      "train: iter 395  trainloss -1530.81539  validloss -1329.59434±0.00000  bestvalidloss -1377.20592  last_update 2\n",
      "train: iter 396  trainloss -1524.76249  validloss -1336.84152±0.00000  bestvalidloss -1377.20592  last_update 3\n",
      "train: iter 397  trainloss -1505.76889  validloss -1277.35412±0.00000  bestvalidloss -1377.20592  last_update 4\n",
      "train: iter 398  trainloss -1554.44826  validloss -1390.75062±0.00000  bestvalidloss -1390.75062  last_update 0\n",
      "train: iter 399  trainloss -1545.86102  validloss -1387.91423±0.00000  bestvalidloss -1390.75062  last_update 1\n",
      "train: iter 400  trainloss -1538.54353  validloss -1391.03398±0.00000  bestvalidloss -1391.03398  last_update 0\n",
      "train: iter 401  trainloss -1553.09168  validloss -1398.91362±0.00000  bestvalidloss -1398.91362  last_update 0\n",
      "train: iter 402  trainloss -1466.72649  validloss -1347.17240±0.00000  bestvalidloss -1398.91362  last_update 1\n",
      "train: iter 403  trainloss -1485.13356  validloss -1294.51197±0.00000  bestvalidloss -1398.91362  last_update 2\n",
      "train: iter 404  trainloss -1490.40053  validloss -1367.81033±0.00000  bestvalidloss -1398.91362  last_update 3\n",
      "train: iter 405  trainloss -1534.16828  validloss -1351.54856±0.00000  bestvalidloss -1398.91362  last_update 4\n",
      "train: iter 406  trainloss -1565.96570  validloss -1343.03416±0.00000  bestvalidloss -1398.91362  last_update 5\n",
      "train: iter 407  trainloss -1537.64404  validloss -1404.58240±0.00000  bestvalidloss -1404.58240  last_update 0\n",
      "train: iter 408  trainloss -1338.25439  validloss -1121.83223±0.00000  bestvalidloss -1404.58240  last_update 1\n",
      "train: iter 409  trainloss -1539.03900  validloss -1337.92129±0.00000  bestvalidloss -1404.58240  last_update 2\n",
      "train: iter 410  trainloss -1302.68079  validloss -1302.23250±0.00000  bestvalidloss -1404.58240  last_update 3\n",
      "train: iter 411  trainloss -1451.80977  validloss -939.45284±0.00000  bestvalidloss -1404.58240  last_update 4\n",
      "train: iter 412  trainloss -1592.68678  validloss -1413.24774±0.00000  bestvalidloss -1413.24774  last_update 0\n",
      "train: iter 413  trainloss -1579.82461  validloss -1440.37751±0.00000  bestvalidloss -1440.37751  last_update 0\n",
      "train: iter 414  trainloss -1529.38856  validloss -1423.00005±0.00000  bestvalidloss -1440.37751  last_update 1\n",
      "train: iter 415  trainloss -1541.62204  validloss -1416.44413±0.00000  bestvalidloss -1440.37751  last_update 2\n",
      "train: iter 416  trainloss -1528.38122  validloss -1396.15579±0.00000  bestvalidloss -1440.37751  last_update 3\n",
      "train: iter 417  trainloss -1514.87879  validloss -1411.70970±0.00000  bestvalidloss -1440.37751  last_update 4\n",
      "train: iter 418  trainloss -1509.58028  validloss -1204.06566±0.00000  bestvalidloss -1440.37751  last_update 5\n",
      "train: iter 419  trainloss -1531.34184  validloss -1404.26063±0.00000  bestvalidloss -1440.37751  last_update 6\n",
      "train: iter 420  trainloss -1414.27378  validloss -1321.50211±0.00000  bestvalidloss -1440.37751  last_update 7\n",
      "train: iter 421  trainloss -1398.54499  validloss -1230.53527±0.00000  bestvalidloss -1440.37751  last_update 8\n",
      "train: iter 422  trainloss -1443.59807  validloss -1342.07888±0.00000  bestvalidloss -1440.37751  last_update 9\n",
      "train: iter 423  trainloss -1419.05974  validloss -994.09633±0.00000  bestvalidloss -1440.37751  last_update 10\n",
      "train: iter 424  trainloss -1253.63614  validloss -1327.31433±0.00000  bestvalidloss -1440.37751  last_update 11\n",
      "train: iter 425  trainloss -1503.81956  validloss -1230.47342±0.00000  bestvalidloss -1440.37751  last_update 12\n",
      "train: iter 426  trainloss -1486.81750  validloss -1341.71514±0.00000  bestvalidloss -1440.37751  last_update 13\n",
      "train: iter 427  trainloss -1552.15334  validloss -1349.25965±0.00000  bestvalidloss -1440.37751  last_update 14\n",
      "train: iter 428  trainloss -1545.54568  validloss -1389.81596±0.00000  bestvalidloss -1440.37751  last_update 15\n",
      "train: iter 429  trainloss -1573.46809  validloss -1403.66088±0.00000  bestvalidloss -1440.37751  last_update 16\n",
      "train: iter 430  trainloss -1573.85922  validloss -1355.34440±0.00000  bestvalidloss -1440.37751  last_update 17\n",
      "train: iter 431  trainloss -1556.32415  validloss -1420.14600±0.00000  bestvalidloss -1440.37751  last_update 18\n",
      "train: iter 432  trainloss -1586.84975  validloss -1395.15135±0.00000  bestvalidloss -1440.37751  last_update 19\n",
      "train: iter 433  trainloss -1518.17398  validloss -1412.80822±0.00000  bestvalidloss -1440.37751  last_update 20\n",
      "train: iter 434  trainloss -1497.18386  validloss -1411.11499±0.00000  bestvalidloss -1440.37751  last_update 21\n",
      "train: iter 435  trainloss -1520.95338  validloss -1277.62780±0.00000  bestvalidloss -1440.37751  last_update 22\n",
      "train: iter 436  trainloss -1534.30979  validloss -1394.74720±0.00000  bestvalidloss -1440.37751  last_update 23\n",
      "train: iter 437  trainloss -1589.78083  validloss -1292.85245±0.00000  bestvalidloss -1440.37751  last_update 24\n",
      "train: iter 438  trainloss -1551.69494  validloss -1409.96448±0.00000  bestvalidloss -1440.37751  last_update 25\n",
      "train: iter 439  trainloss -1499.68945  validloss -1324.48286±0.00000  bestvalidloss -1440.37751  last_update 26\n",
      "train: iter 440  trainloss -1537.96061  validloss -1310.06304±0.00000  bestvalidloss -1440.37751  last_update 27\n",
      "train: iter 441  trainloss -1583.98469  validloss -1413.77990±0.00000  bestvalidloss -1440.37751  last_update 28\n",
      "train: iter 442  trainloss -1434.97428  validloss -1305.92371±0.00000  bestvalidloss -1440.37751  last_update 29\n",
      "train: iter 443  trainloss -1443.89504  validloss -1371.58284±0.00000  bestvalidloss -1440.37751  last_update 30\n",
      "train: iter 444  trainloss -1509.57747  validloss -1233.19543±0.00000  bestvalidloss -1440.37751  last_update 31\n",
      "train: iter 445  trainloss -1605.99455  validloss -1434.82484±0.00000  bestvalidloss -1440.37751  last_update 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 446  trainloss -1592.11868  validloss -1410.13701±0.00000  bestvalidloss -1440.37751  last_update 33\n",
      "train: iter 447  trainloss -1597.26639  validloss -1409.24474±0.00000  bestvalidloss -1440.37751  last_update 34\n",
      "train: iter 448  trainloss -1605.94211  validloss -1431.85276±0.00000  bestvalidloss -1440.37751  last_update 35\n",
      "train: iter 449  trainloss -1551.72559  validloss -1391.96143±0.00000  bestvalidloss -1440.37751  last_update 36\n",
      "train: iter 450  trainloss -1551.12946  validloss -1415.23855±0.00000  bestvalidloss -1440.37751  last_update 37\n",
      "train: iter 451  trainloss -1538.07105  validloss -1270.25734±0.00000  bestvalidloss -1440.37751  last_update 38\n",
      "train: iter 452  trainloss -1569.70085  validloss -1454.53631±0.00000  bestvalidloss -1454.53631  last_update 0\n",
      "train: iter 453  trainloss -1465.97167  validloss -1228.07606±0.00000  bestvalidloss -1454.53631  last_update 1\n",
      "train: iter 454  trainloss -1574.81635  validloss -1399.58372±0.00000  bestvalidloss -1454.53631  last_update 2\n",
      "train: iter 455  trainloss -1499.55565  validloss -1426.77297±0.00000  bestvalidloss -1454.53631  last_update 3\n",
      "train: iter 456  trainloss -1435.12869  validloss -1305.78394±0.00000  bestvalidloss -1454.53631  last_update 4\n",
      "train: iter 457  trainloss -1425.98830  validloss -1237.88442±0.00000  bestvalidloss -1454.53631  last_update 5\n",
      "train: iter 458  trainloss -1512.98511  validloss -1205.77556±0.00000  bestvalidloss -1454.53631  last_update 6\n",
      "train: iter 459  trainloss -1570.87229  validloss -1425.66482±0.00000  bestvalidloss -1454.53631  last_update 7\n",
      "train: iter 460  trainloss -1585.29862  validloss -1431.15585±0.00000  bestvalidloss -1454.53631  last_update 8\n",
      "train: iter 461  trainloss -1513.73135  validloss -1410.23246±0.00000  bestvalidloss -1454.53631  last_update 9\n",
      "train: iter 462  trainloss -1452.95786  validloss -1290.72289±0.00000  bestvalidloss -1454.53631  last_update 10\n",
      "train: iter 463  trainloss -1551.50940  validloss -1248.30671±0.00000  bestvalidloss -1454.53631  last_update 11\n",
      "train: iter 464  trainloss -1604.76298  validloss -1441.10768±0.00000  bestvalidloss -1454.53631  last_update 12\n",
      "train: iter 465  trainloss -1555.72953  validloss -1417.56666±0.00000  bestvalidloss -1454.53631  last_update 13\n",
      "train: iter 466  trainloss -1614.05725  validloss -1410.44463±0.00000  bestvalidloss -1454.53631  last_update 14\n",
      "train: iter 467  trainloss -1623.71153  validloss -1414.19532±0.00000  bestvalidloss -1454.53631  last_update 15\n",
      "train: iter 468  trainloss -1509.58690  validloss -1260.51497±0.00000  bestvalidloss -1454.53631  last_update 16\n",
      "train: iter 469  trainloss -1483.91633  validloss -1282.76631±0.00000  bestvalidloss -1454.53631  last_update 17\n",
      "train: iter 470  trainloss -1583.67566  validloss -1393.96910±0.00000  bestvalidloss -1454.53631  last_update 18\n",
      "train: iter 471  trainloss -1579.87019  validloss -1443.12279±0.00000  bestvalidloss -1454.53631  last_update 19\n",
      "train: iter 472  trainloss -1542.42514  validloss -1385.41975±0.00000  bestvalidloss -1454.53631  last_update 20\n",
      "train: iter 473  trainloss -1526.75344  validloss -1361.41418±0.00000  bestvalidloss -1454.53631  last_update 21\n",
      "train: iter 474  trainloss -1493.16576  validloss -684.86823±0.00000  bestvalidloss -1454.53631  last_update 22\n",
      "train: iter 475  trainloss -1462.53377  validloss -1398.63728±0.00000  bestvalidloss -1454.53631  last_update 23\n",
      "train: iter 476  trainloss -1569.38497  validloss -1415.96619±0.00000  bestvalidloss -1454.53631  last_update 24\n",
      "train: iter 477  trainloss -1597.51047  validloss -1415.82528±0.00000  bestvalidloss -1454.53631  last_update 25\n",
      "train: iter 478  trainloss -1597.38188  validloss -1445.08541±0.00000  bestvalidloss -1454.53631  last_update 26\n",
      "train: iter 479  trainloss -1600.66749  validloss -1447.71911±0.00000  bestvalidloss -1454.53631  last_update 27\n",
      "train: iter 480  trainloss -1446.97248  validloss -1320.31639±0.00000  bestvalidloss -1454.53631  last_update 28\n",
      "train: iter 481  trainloss -1484.10461  validloss -1375.37825±0.00000  bestvalidloss -1454.53631  last_update 29\n",
      "train: iter 482  trainloss -1606.61824  validloss -1447.37108±0.00000  bestvalidloss -1454.53631  last_update 30\n",
      "train: iter 483  trainloss -1194.10761  validloss -1401.25791±0.00000  bestvalidloss -1454.53631  last_update 31\n",
      "train: iter 484  trainloss -1482.80044  validloss -1314.81907±0.00000  bestvalidloss -1454.53631  last_update 32\n",
      "train: iter 485  trainloss -1566.77337  validloss -1343.83449±0.00000  bestvalidloss -1454.53631  last_update 33\n",
      "train: iter 486  trainloss -1563.51696  validloss -1383.80168±0.00000  bestvalidloss -1454.53631  last_update 34\n",
      "train: iter 487  trainloss -1488.92722  validloss -1422.14795±0.00000  bestvalidloss -1454.53631  last_update 35\n",
      "train: iter 488  trainloss -1552.39613  validloss -1254.48551±0.00000  bestvalidloss -1454.53631  last_update 36\n",
      "train: iter 489  trainloss -1561.70026  validloss -1452.14830±0.00000  bestvalidloss -1454.53631  last_update 37\n",
      "train: iter 490  trainloss -1578.50176  validloss -1411.79369±0.00000  bestvalidloss -1454.53631  last_update 38\n",
      "train: iter 491  trainloss -1608.24593  validloss -1427.49895±0.00000  bestvalidloss -1454.53631  last_update 39\n",
      "train: iter 492  trainloss -1442.84205  validloss -1315.59202±0.00000  bestvalidloss -1454.53631  last_update 40\n",
      "train: iter 493  trainloss -1583.39549  validloss -1392.88954±0.00000  bestvalidloss -1454.53631  last_update 41\n",
      "train: iter 494  trainloss -1630.47957  validloss -1423.63235±0.00000  bestvalidloss -1454.53631  last_update 42\n",
      "train: iter 495  trainloss -1587.55964  validloss -1443.16411±0.00000  bestvalidloss -1454.53631  last_update 43\n",
      "train: iter 496  trainloss -1543.88782  validloss -1391.51846±0.00000  bestvalidloss -1454.53631  last_update 44\n",
      "train: iter 497  trainloss -1401.13739  validloss -1401.70616±0.00000  bestvalidloss -1454.53631  last_update 45\n",
      "train: iter 498  trainloss -1567.74458  validloss -1406.81348±0.00000  bestvalidloss -1454.53631  last_update 46\n",
      "train: iter 499  trainloss -1567.11578  validloss -1416.34779±0.00000  bestvalidloss -1454.53631  last_update 47\n",
      "train: iter 500  trainloss -1593.23701  validloss -1431.60096±0.00000  bestvalidloss -1454.53631  last_update 48\n",
      "train: iter 501  trainloss -1525.63124  validloss -1356.65290±0.00000  bestvalidloss -1454.53631  last_update 49\n",
      "train: iter 502  trainloss -1596.52452  validloss -1448.86748±0.00000  bestvalidloss -1454.53631  last_update 50\n",
      "train: iter 503  trainloss -1579.65196  validloss -1443.41011±0.00000  bestvalidloss -1454.53631  last_update 51\n",
      "train: iter 504  trainloss -1524.37399  validloss -1399.14594±0.00000  bestvalidloss -1454.53631  last_update 52\n",
      "train: iter 505  trainloss -1629.20431  validloss -1451.23004±0.00000  bestvalidloss -1454.53631  last_update 53\n",
      "train: iter 506  trainloss -1590.76110  validloss -1461.66230±0.00000  bestvalidloss -1461.66230  last_update 0\n",
      "train: iter 507  trainloss -1419.94837  validloss -1371.94076±0.00000  bestvalidloss -1461.66230  last_update 1\n",
      "train: iter 508  trainloss -1429.20531  validloss -1186.13927±0.00000  bestvalidloss -1461.66230  last_update 2\n",
      "train: iter 509  trainloss -1579.95963  validloss -1418.06679±0.00000  bestvalidloss -1461.66230  last_update 3\n",
      "train: iter 510  trainloss -1572.58419  validloss -1439.85330±0.00000  bestvalidloss -1461.66230  last_update 4\n",
      "train: iter 511  trainloss -1531.76130  validloss -1240.73220±0.00000  bestvalidloss -1461.66230  last_update 5\n",
      "train: iter 512  trainloss -1532.38458  validloss -1399.37601±0.00000  bestvalidloss -1461.66230  last_update 6\n",
      "train: iter 513  trainloss -1555.45863  validloss -1410.69119±0.00000  bestvalidloss -1461.66230  last_update 7\n",
      "train: iter 514  trainloss -1623.26315  validloss -1461.32555±0.00000  bestvalidloss -1461.66230  last_update 8\n",
      "train: iter 515  trainloss -1618.14439  validloss -1485.12727±0.00000  bestvalidloss -1485.12727  last_update 0\n",
      "train: iter 516  trainloss -1610.46301  validloss -1468.72128±0.00000  bestvalidloss -1485.12727  last_update 1\n",
      "train: iter 517  trainloss -1583.36870  validloss -1462.03509±0.00000  bestvalidloss -1485.12727  last_update 2\n",
      "train: iter 518  trainloss -1596.60402  validloss -1404.08377±0.00000  bestvalidloss -1485.12727  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 519  trainloss -1596.56709  validloss -1411.49977±0.00000  bestvalidloss -1485.12727  last_update 4\n",
      "train: iter 520  trainloss -1412.20833  validloss -1464.70718±0.00000  bestvalidloss -1485.12727  last_update 5\n",
      "train: iter 521  trainloss -1439.37812  validloss -1035.91108±0.00000  bestvalidloss -1485.12727  last_update 6\n",
      "train: iter 522  trainloss -1562.14732  validloss -1410.78038±0.00000  bestvalidloss -1485.12727  last_update 7\n",
      "train: iter 523  trainloss -1588.90753  validloss -1450.84888±0.00000  bestvalidloss -1485.12727  last_update 8\n",
      "train: iter 524  trainloss -1573.08417  validloss -1422.15283±0.00000  bestvalidloss -1485.12727  last_update 9\n",
      "train: iter 525  trainloss -1474.23957  validloss -1393.37055±0.00000  bestvalidloss -1485.12727  last_update 10\n",
      "train: iter 526  trainloss -1534.96278  validloss -1274.29145±0.00000  bestvalidloss -1485.12727  last_update 11\n",
      "train: iter 527  trainloss -1563.66910  validloss -1403.44544±0.00000  bestvalidloss -1485.12727  last_update 12\n",
      "train: iter 528  trainloss -1590.68184  validloss -1365.27838±0.00000  bestvalidloss -1485.12727  last_update 13\n",
      "train: iter 529  trainloss -1557.13268  validloss -1450.32906±0.00000  bestvalidloss -1485.12727  last_update 14\n",
      "train: iter 530  trainloss -1510.25153  validloss -802.13029±0.00000  bestvalidloss -1485.12727  last_update 15\n",
      "train: iter 531  trainloss -1567.15240  validloss -1397.96213±0.00000  bestvalidloss -1485.12727  last_update 16\n",
      "train: iter 532  trainloss -1601.27899  validloss -1458.10697±0.00000  bestvalidloss -1485.12727  last_update 17\n",
      "train: iter 533  trainloss -1610.04124  validloss -1456.25316±0.00000  bestvalidloss -1485.12727  last_update 18\n",
      "train: iter 534  trainloss -1625.61533  validloss -1446.52824±0.00000  bestvalidloss -1485.12727  last_update 19\n",
      "train: iter 535  trainloss -1593.88365  validloss -1476.69061±0.00000  bestvalidloss -1485.12727  last_update 20\n",
      "train: iter 536  trainloss -1541.66922  validloss -1272.41185±0.00000  bestvalidloss -1485.12727  last_update 21\n",
      "train: iter 537  trainloss -1598.76999  validloss -1415.70923±0.00000  bestvalidloss -1485.12727  last_update 22\n",
      "train: iter 538  trainloss -1606.25616  validloss -1492.40466±0.00000  bestvalidloss -1492.40466  last_update 0\n",
      "train: iter 539  trainloss -1581.11660  validloss -1466.54154±0.00000  bestvalidloss -1492.40466  last_update 1\n",
      "train: iter 540  trainloss -1546.06658  validloss -1385.52397±0.00000  bestvalidloss -1492.40466  last_update 2\n",
      "train: iter 541  trainloss -1509.37807  validloss -1376.48603±0.00000  bestvalidloss -1492.40466  last_update 3\n",
      "train: iter 542  trainloss -1622.31921  validloss -1428.74651±0.00000  bestvalidloss -1492.40466  last_update 4\n",
      "train: iter 543  trainloss -1589.18012  validloss -1473.12336±0.00000  bestvalidloss -1492.40466  last_update 5\n",
      "train: iter 544  trainloss -1441.97690  validloss -1434.94844±0.00000  bestvalidloss -1492.40466  last_update 6\n",
      "train: iter 545  trainloss -1571.58637  validloss -1368.97455±0.00000  bestvalidloss -1492.40466  last_update 7\n",
      "train: iter 546  trainloss -1611.44834  validloss -1445.11783±0.00000  bestvalidloss -1492.40466  last_update 8\n",
      "train: iter 547  trainloss -1612.89234  validloss -1463.34349±0.00000  bestvalidloss -1492.40466  last_update 9\n",
      "train: iter 548  trainloss -1557.95874  validloss -1317.31063±0.00000  bestvalidloss -1492.40466  last_update 10\n",
      "train: iter 549  trainloss -1587.35296  validloss -1449.45903±0.00000  bestvalidloss -1492.40466  last_update 11\n",
      "train: iter 550  trainloss -1589.29308  validloss -1227.36132±0.00000  bestvalidloss -1492.40466  last_update 12\n",
      "train: iter 551  trainloss -1498.38427  validloss -1481.05884±0.00000  bestvalidloss -1492.40466  last_update 13\n",
      "train: iter 552  trainloss -1603.85716  validloss -1172.28605±0.00000  bestvalidloss -1492.40466  last_update 14\n",
      "train: iter 553  trainloss -1556.59143  validloss -1478.88891±0.00000  bestvalidloss -1492.40466  last_update 15\n",
      "train: iter 554  trainloss -1610.82497  validloss -1447.64076±0.00000  bestvalidloss -1492.40466  last_update 16\n",
      "train: iter 555  trainloss -1506.73811  validloss -1447.04683±0.00000  bestvalidloss -1492.40466  last_update 17\n",
      "train: iter 556  trainloss -1520.69595  validloss -1312.20932±0.00000  bestvalidloss -1492.40466  last_update 18\n",
      "train: iter 557  trainloss -1463.69512  validloss -1411.58997±0.00000  bestvalidloss -1492.40466  last_update 19\n",
      "train: iter 558  trainloss -1581.98276  validloss -1393.86593±0.00000  bestvalidloss -1492.40466  last_update 20\n",
      "train: iter 559  trainloss -1613.49605  validloss -1460.24226±0.00000  bestvalidloss -1492.40466  last_update 21\n",
      "train: iter 560  trainloss -1583.60719  validloss -1475.50820±0.00000  bestvalidloss -1492.40466  last_update 22\n",
      "train: iter 561  trainloss -1609.27391  validloss -1448.11138±0.00000  bestvalidloss -1492.40466  last_update 23\n",
      "train: iter 562  trainloss -1598.63664  validloss -1495.73686±0.00000  bestvalidloss -1495.73686  last_update 0\n",
      "train: iter 563  trainloss -1588.16099  validloss -1478.97277±0.00000  bestvalidloss -1495.73686  last_update 1\n",
      "train: iter 564  trainloss -1593.37640  validloss -1500.50258±0.00000  bestvalidloss -1500.50258  last_update 0\n",
      "train: iter 565  trainloss -1548.60916  validloss -1403.16554±0.00000  bestvalidloss -1500.50258  last_update 1\n",
      "train: iter 566  trainloss -1513.03506  validloss -1433.45383±0.00000  bestvalidloss -1500.50258  last_update 2\n",
      "train: iter 567  trainloss -1625.02176  validloss -1453.03834±0.00000  bestvalidloss -1500.50258  last_update 3\n",
      "train: iter 568  trainloss -1616.66576  validloss -1494.14386±0.00000  bestvalidloss -1500.50258  last_update 4\n",
      "train: iter 569  trainloss -1589.02882  validloss -1475.78712±0.00000  bestvalidloss -1500.50258  last_update 5\n",
      "train: iter 570  trainloss -1624.25623  validloss -1482.66169±0.00000  bestvalidloss -1500.50258  last_update 6\n",
      "train: iter 571  trainloss -1447.07073  validloss -1389.40493±0.00000  bestvalidloss -1500.50258  last_update 7\n",
      "train: iter 572  trainloss -1577.09069  validloss -1395.69231±0.00000  bestvalidloss -1500.50258  last_update 8\n",
      "train: iter 573  trainloss -1617.30553  validloss -1467.22518±0.00000  bestvalidloss -1500.50258  last_update 9\n",
      "train: iter 574  trainloss -1488.38661  validloss -1420.11756±0.00000  bestvalidloss -1500.50258  last_update 10\n",
      "train: iter 575  trainloss -1596.13852  validloss -1366.87561±0.00000  bestvalidloss -1500.50258  last_update 11\n",
      "train: iter 576  trainloss -1495.35042  validloss -1438.11509±0.00000  bestvalidloss -1500.50258  last_update 12\n",
      "train: iter 577  trainloss -1599.21459  validloss -1426.35546±0.00000  bestvalidloss -1500.50258  last_update 13\n",
      "train: iter 578  trainloss -1640.28872  validloss -1465.81060±0.00000  bestvalidloss -1500.50258  last_update 14\n",
      "train: iter 579  trainloss -1635.97976  validloss -1490.43778±0.00000  bestvalidloss -1500.50258  last_update 15\n",
      "train: iter 580  trainloss -1647.32530  validloss -1493.31719±0.00000  bestvalidloss -1500.50258  last_update 16\n",
      "train: iter 581  trainloss -1446.05961  validloss -1454.20697±0.00000  bestvalidloss -1500.50258  last_update 17\n",
      "train: iter 582  trainloss -1485.17352  validloss -1152.23648±0.00000  bestvalidloss -1500.50258  last_update 18\n",
      "train: iter 583  trainloss -1542.42332  validloss -1376.81641±0.00000  bestvalidloss -1500.50258  last_update 19\n",
      "train: iter 584  trainloss -1576.44218  validloss -1363.52326±0.00000  bestvalidloss -1500.50258  last_update 20\n",
      "train: iter 585  trainloss -1625.62137  validloss -1447.77177±0.00000  bestvalidloss -1500.50258  last_update 21\n",
      "train: iter 586  trainloss -1623.49943  validloss -1486.12785±0.00000  bestvalidloss -1500.50258  last_update 22\n",
      "train: iter 587  trainloss -1585.10424  validloss -1475.67722±0.00000  bestvalidloss -1500.50258  last_update 23\n",
      "train: iter 588  trainloss -1598.41589  validloss -1381.57751±0.00000  bestvalidloss -1500.50258  last_update 24\n",
      "train: iter 589  trainloss -1631.86973  validloss -1457.91087±0.00000  bestvalidloss -1500.50258  last_update 25\n",
      "train: iter 590  trainloss -1631.55545  validloss -1494.30590±0.00000  bestvalidloss -1500.50258  last_update 26\n",
      "train: iter 591  trainloss -1565.68913  validloss -1339.32271±0.00000  bestvalidloss -1500.50258  last_update 27\n",
      "train: iter 592  trainloss -1570.42250  validloss -1282.49579±0.00000  bestvalidloss -1500.50258  last_update 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 593  trainloss -1578.08712  validloss -1443.10386±0.00000  bestvalidloss -1500.50258  last_update 29\n",
      "train: iter 594  trainloss -1609.16714  validloss -1389.41810±0.00000  bestvalidloss -1500.50258  last_update 30\n",
      "train: iter 595  trainloss -1528.18994  validloss -1454.38941±0.00000  bestvalidloss -1500.50258  last_update 31\n",
      "train: iter 596  trainloss -1589.86261  validloss -1370.80759±0.00000  bestvalidloss -1500.50258  last_update 32\n",
      "train: iter 597  trainloss -1594.34359  validloss -1464.27632±0.00000  bestvalidloss -1500.50258  last_update 33\n",
      "train: iter 598  trainloss -1569.30011  validloss -1378.45355±0.00000  bestvalidloss -1500.50258  last_update 34\n",
      "train: iter 599  trainloss -1432.74319  validloss -1173.71159±0.00000  bestvalidloss -1500.50258  last_update 35\n",
      "train: iter 600  trainloss -1484.92867  validloss -1339.62338±0.00000  bestvalidloss -1500.50258  last_update 36\n",
      "train: iter 601  trainloss -1609.07417  validloss -1390.84596±0.00000  bestvalidloss -1500.50258  last_update 37\n",
      "train: iter 602  trainloss -1624.34324  validloss -1455.95823±0.00000  bestvalidloss -1500.50258  last_update 38\n",
      "train: iter 603  trainloss -1595.36636  validloss -1515.09560±0.00000  bestvalidloss -1515.09560  last_update 0\n",
      "train: iter 604  trainloss -1482.18522  validloss -1430.73474±0.00000  bestvalidloss -1515.09560  last_update 1\n",
      "train: iter 605  trainloss -1601.62081  validloss -1441.07745±0.00000  bestvalidloss -1515.09560  last_update 2\n",
      "train: iter 606  trainloss -1566.74362  validloss -1313.24404±0.00000  bestvalidloss -1515.09560  last_update 3\n",
      "train: iter 607  trainloss -1582.97160  validloss -1419.29828±0.00000  bestvalidloss -1515.09560  last_update 4\n",
      "train: iter 608  trainloss -1621.32787  validloss -1473.15123±0.00000  bestvalidloss -1515.09560  last_update 5\n",
      "train: iter 609  trainloss -1623.04016  validloss -1498.05781±0.00000  bestvalidloss -1515.09560  last_update 6\n",
      "train: iter 610  trainloss -1582.27454  validloss -1419.98898±0.00000  bestvalidloss -1515.09560  last_update 7\n",
      "train: iter 611  trainloss -1639.27368  validloss -1423.21146±0.00000  bestvalidloss -1515.09560  last_update 8\n",
      "train: iter 612  trainloss -1622.54497  validloss -1512.90679±0.00000  bestvalidloss -1515.09560  last_update 9\n",
      "train: iter 613  trainloss -1547.85134  validloss -1489.46960±0.00000  bestvalidloss -1515.09560  last_update 10\n",
      "train: iter 614  trainloss -1574.92056  validloss -1219.70525±0.00000  bestvalidloss -1515.09560  last_update 11\n",
      "train: iter 615  trainloss -1546.89604  validloss -1418.07611±0.00000  bestvalidloss -1515.09560  last_update 12\n",
      "train: iter 616  trainloss -1586.41494  validloss -1306.09442±0.00000  bestvalidloss -1515.09560  last_update 13\n",
      "train: iter 617  trainloss -1605.23568  validloss -1465.82607±0.00000  bestvalidloss -1515.09560  last_update 14\n",
      "train: iter 618  trainloss -1610.00048  validloss -1463.51550±0.00000  bestvalidloss -1515.09560  last_update 15\n",
      "train: iter 619  trainloss -1654.55384  validloss -1470.40217±0.00000  bestvalidloss -1515.09560  last_update 16\n",
      "train: iter 620  trainloss -1490.88775  validloss -1499.79886±0.00000  bestvalidloss -1515.09560  last_update 17\n",
      "train: iter 621  trainloss -1605.24601  validloss -1382.32440±0.00000  bestvalidloss -1515.09560  last_update 18\n",
      "train: iter 622  trainloss -1638.55127  validloss -1467.55461±0.00000  bestvalidloss -1515.09560  last_update 19\n",
      "train: iter 623  trainloss -1533.80218  validloss -1336.76104±0.00000  bestvalidloss -1515.09560  last_update 20\n",
      "train: iter 624  trainloss -1598.37959  validloss -1449.42523±0.00000  bestvalidloss -1515.09560  last_update 21\n",
      "train: iter 625  trainloss -1550.51121  validloss -1383.24875±0.00000  bestvalidloss -1515.09560  last_update 22\n",
      "train: iter 626  trainloss -1604.63055  validloss -1468.60142±0.00000  bestvalidloss -1515.09560  last_update 23\n",
      "train: iter 627  trainloss -1647.49802  validloss -1467.27198±0.00000  bestvalidloss -1515.09560  last_update 24\n",
      "train: iter 628  trainloss -1561.77727  validloss -1487.83307±0.00000  bestvalidloss -1515.09560  last_update 25\n",
      "train: iter 629  trainloss -1571.88938  validloss -1264.78942±0.00000  bestvalidloss -1515.09560  last_update 26\n",
      "train: iter 630  trainloss -1610.81369  validloss -1442.86940±0.00000  bestvalidloss -1515.09560  last_update 27\n",
      "train: iter 631  trainloss -1630.11365  validloss -1447.80988±0.00000  bestvalidloss -1515.09560  last_update 28\n",
      "train: iter 632  trainloss -1619.63308  validloss -1446.44030±0.00000  bestvalidloss -1515.09560  last_update 29\n",
      "train: iter 633  trainloss -1510.21344  validloss -1332.67694±0.00000  bestvalidloss -1515.09560  last_update 30\n",
      "train: iter 634  trainloss -1615.38752  validloss -1455.29010±0.00000  bestvalidloss -1515.09560  last_update 31\n",
      "train: iter 635  trainloss -1334.08371  validloss -1488.68459±0.00000  bestvalidloss -1515.09560  last_update 32\n",
      "train: iter 636  trainloss -1441.77539  validloss -1090.83228±0.00000  bestvalidloss -1515.09560  last_update 33\n",
      "train: iter 637  trainloss -1551.95050  validloss -1399.00608±0.00000  bestvalidloss -1515.09560  last_update 34\n",
      "train: iter 638  trainloss -1593.36244  validloss -1250.76824±0.00000  bestvalidloss -1515.09560  last_update 35\n",
      "train: iter 639  trainloss -1386.02251  validloss -1422.96234±0.00000  bestvalidloss -1515.09560  last_update 36\n",
      "train: iter 640  trainloss -1524.78134  validloss -1254.07299±0.00000  bestvalidloss -1515.09560  last_update 37\n",
      "train: iter 641  trainloss -1571.04230  validloss -1410.38494±0.00000  bestvalidloss -1515.09560  last_update 38\n",
      "train: iter 642  trainloss -1500.61608  validloss -1384.51895±0.00000  bestvalidloss -1515.09560  last_update 39\n",
      "train: iter 643  trainloss -1622.80212  validloss -1382.92628±0.00000  bestvalidloss -1515.09560  last_update 40\n",
      "train: iter 644  trainloss -1633.75461  validloss -1459.15224±0.00000  bestvalidloss -1515.09560  last_update 41\n",
      "train: iter 645  trainloss -1551.42997  validloss -1463.49171±0.00000  bestvalidloss -1515.09560  last_update 42\n",
      "train: iter 646  trainloss -1478.56998  validloss -1366.54963±0.00000  bestvalidloss -1515.09560  last_update 43\n",
      "train: iter 647  trainloss -1599.54359  validloss -1385.77867±0.00000  bestvalidloss -1515.09560  last_update 44\n",
      "train: iter 648  trainloss -1615.14532  validloss -1486.59074±0.00000  bestvalidloss -1515.09560  last_update 45\n",
      "train: iter 649  trainloss -1602.68328  validloss -1494.97140±0.00000  bestvalidloss -1515.09560  last_update 46\n",
      "train: iter 650  trainloss -1520.63368  validloss -1367.05142±0.00000  bestvalidloss -1515.09560  last_update 47\n",
      "train: iter 651  trainloss -1632.38558  validloss -1439.26271±0.00000  bestvalidloss -1515.09560  last_update 48\n",
      "train: iter 652  trainloss -1595.00253  validloss -1444.69368±0.00000  bestvalidloss -1515.09560  last_update 49\n",
      "train: iter 653  trainloss -1633.00645  validloss -1481.56353±0.00000  bestvalidloss -1515.09560  last_update 50\n",
      "train: iter 654  trainloss -1642.19410  validloss -1470.22812±0.00000  bestvalidloss -1515.09560  last_update 51\n",
      "train: iter 655  trainloss -1603.02272  validloss -1483.42604±0.00000  bestvalidloss -1515.09560  last_update 52\n",
      "train: iter 656  trainloss -1602.79225  validloss -1483.70490±0.00000  bestvalidloss -1515.09560  last_update 53\n",
      "train: iter 657  trainloss -1584.51142  validloss -1456.80842±0.00000  bestvalidloss -1515.09560  last_update 54\n",
      "train: iter 658  trainloss -1614.84144  validloss -1496.00141±0.00000  bestvalidloss -1515.09560  last_update 55\n",
      "train: iter 659  trainloss -1652.73889  validloss -1441.42584±0.00000  bestvalidloss -1515.09560  last_update 56\n",
      "train: iter 660  trainloss -1618.71112  validloss -1507.45161±0.00000  bestvalidloss -1515.09560  last_update 57\n",
      "train: iter 661  trainloss -1626.90871  validloss -1480.07584±0.00000  bestvalidloss -1515.09560  last_update 58\n",
      "train: iter 662  trainloss -1433.33608  validloss -1447.01761±0.00000  bestvalidloss -1515.09560  last_update 59\n",
      "train: iter 663  trainloss -1633.36810  validloss -1444.93149±0.00000  bestvalidloss -1515.09560  last_update 60\n",
      "train: iter 664  trainloss -1645.43370  validloss -1506.76670±0.00000  bestvalidloss -1515.09560  last_update 61\n",
      "train: iter 665  trainloss -1502.36608  validloss -1481.44159±0.00000  bestvalidloss -1515.09560  last_update 62\n",
      "train: iter 666  trainloss -1632.62226  validloss -1450.16201±0.00000  bestvalidloss -1515.09560  last_update 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 667  trainloss -1639.66844  validloss -1504.06580±0.00000  bestvalidloss -1515.09560  last_update 64\n",
      "train: iter 668  trainloss -1598.58100  validloss -1473.63424±0.00000  bestvalidloss -1515.09560  last_update 65\n",
      "train: iter 669  trainloss -1482.23287  validloss -1472.22359±0.00000  bestvalidloss -1515.09560  last_update 66\n",
      "train: iter 670  trainloss -1588.43055  validloss -1292.84912±0.00000  bestvalidloss -1515.09560  last_update 67\n",
      "train: iter 671  trainloss -1591.40961  validloss -1490.90849±0.00000  bestvalidloss -1515.09560  last_update 68\n",
      "train: iter 672  trainloss -1624.15519  validloss -1449.25348±0.00000  bestvalidloss -1515.09560  last_update 69\n",
      "train: iter 673  trainloss -1618.40311  validloss -1486.99698±0.00000  bestvalidloss -1515.09560  last_update 70\n",
      "train: iter 674  trainloss -1125.30806  validloss -1328.28342±0.00000  bestvalidloss -1515.09560  last_update 71\n",
      "train: iter 675  trainloss -1461.12941  validloss -1140.60222±0.00000  bestvalidloss -1515.09560  last_update 72\n",
      "train: iter 676  trainloss -1497.58433  validloss -1265.53194±0.00000  bestvalidloss -1515.09560  last_update 73\n",
      "train: iter 677  trainloss -1594.41993  validloss -1412.81195±0.00000  bestvalidloss -1515.09560  last_update 74\n",
      "train: iter 678  trainloss -1594.48624  validloss -1431.67036±0.00000  bestvalidloss -1515.09560  last_update 75\n",
      "train: iter 679  trainloss -1570.38963  validloss -1442.12505±0.00000  bestvalidloss -1515.09560  last_update 76\n",
      "train: iter 680  trainloss -1624.14355  validloss -1476.62018±0.00000  bestvalidloss -1515.09560  last_update 77\n",
      "train: iter 681  trainloss -1642.07686  validloss -1486.89413±0.00000  bestvalidloss -1515.09560  last_update 78\n",
      "train: iter 682  trainloss -1629.14523  validloss -1480.28452±0.00000  bestvalidloss -1515.09560  last_update 79\n",
      "train: iter 683  trainloss -1576.93025  validloss -1436.95974±0.00000  bestvalidloss -1515.09560  last_update 80\n",
      "train: iter 684  trainloss -1602.98454  validloss -1424.34041±0.00000  bestvalidloss -1515.09560  last_update 81\n",
      "train: iter 685  trainloss -1634.40891  validloss -1452.69985±0.00000  bestvalidloss -1515.09560  last_update 82\n",
      "train: iter 686  trainloss -1553.24679  validloss -1464.83329±0.00000  bestvalidloss -1515.09560  last_update 83\n",
      "train: iter 687  trainloss -1586.30231  validloss -1477.52743±0.00000  bestvalidloss -1515.09560  last_update 84\n",
      "train: iter 688  trainloss -1639.39489  validloss -1464.35381±0.00000  bestvalidloss -1515.09560  last_update 85\n",
      "train: iter 689  trainloss -1584.30393  validloss -1473.77235±0.00000  bestvalidloss -1515.09560  last_update 86\n",
      "train: iter 690  trainloss -1616.88074  validloss -1425.52015±0.00000  bestvalidloss -1515.09560  last_update 87\n",
      "train: iter 691  trainloss -1626.03692  validloss -1465.20202±0.00000  bestvalidloss -1515.09560  last_update 88\n",
      "train: iter 692  trainloss -1481.38542  validloss -1461.19641±0.00000  bestvalidloss -1515.09560  last_update 89\n",
      "train: iter 693  trainloss -1580.02915  validloss -1437.80675±0.00000  bestvalidloss -1515.09560  last_update 90\n",
      "train: iter 694  trainloss -1614.97283  validloss -1442.22216±0.00000  bestvalidloss -1515.09560  last_update 91\n",
      "train: iter 695  trainloss -1640.31493  validloss -1448.10242±0.00000  bestvalidloss -1515.09560  last_update 92\n",
      "train: iter 696  trainloss -1627.94851  validloss -1459.97254±0.00000  bestvalidloss -1515.09560  last_update 93\n",
      "train: iter 697  trainloss -1606.58557  validloss -1460.94865±0.00000  bestvalidloss -1515.09560  last_update 94\n",
      "train: iter 698  trainloss -1636.61076  validloss -1430.31425±0.00000  bestvalidloss -1515.09560  last_update 95\n",
      "train: iter 699  trainloss -1652.83719  validloss -1458.54697±0.00000  bestvalidloss -1515.09560  last_update 96\n",
      "train: iter 700  trainloss -1643.27952  validloss -1508.84030±0.00000  bestvalidloss -1515.09560  last_update 97\n",
      "train: iter 701  trainloss -1573.94062  validloss -1459.08932±0.00000  bestvalidloss -1515.09560  last_update 98\n",
      "train: iter 702  trainloss -1617.95751  validloss -1471.38102±0.00000  bestvalidloss -1515.09560  last_update 99\n",
      "train: iter 703  trainloss -1574.19630  validloss -1275.00760±0.00000  bestvalidloss -1515.09560  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.3077) penalty_target_max tensor(9.5790)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGdCAYAAAAWp6lMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdDklEQVR4nO3deVxU5eIG8OewzADCsIhsLoj7vhdSapokGreiPbXUcsmu3iy9ZnZbNPuFV6917Zaat9LubTHtppWahuSSiZooKi4kioLKgBszgDAwM+/vjwMHRlCBPBwanu/ncz7OnPPOmfcdlHl8l3MkIYQAERERkRNz0boCRERERGpj4CEiIiKnx8BDRERETo+Bh4iIiJweAw8RERE5PQYeIiIicnoMPEREROT0GHiIiIjI6blpXYGGwG634/z58/Dx8YEkSVpXh4iIiGpACIH8/HyEhYXBxeXGfTgMPADOnz+Pli1bal0NIiIiqoOsrCy0aNHihmUYeAD4+PgAkD8wg8GgcW2IiIioJsxmM1q2bKl8j98IAw+gDGMZDAYGHiIioj+YmkxH4aRlIiIicnoMPEREROT0GHiIiIjI6THwEBERkdNj4CEiIiKnx8BDRERETo+Bh4iIiJweAw8RERE5PQYeIiIicnoMPEREROT0GHiIiIjI6THwEBERkdPjzUNVdCHfgg+2psPD3RUvj+ikdXWIiIgaLfbwqMhcXIqVu07jiz1ntK4KERFRo8bAUw+E1hUgIiJq5Bh4VCSVP2DiISIi0hQDj4okSbp5ISIiIlIdA089YAcPERGRthh4VMT+HSIiooaBgaceCME+HiIiIi0x8KiIU3iIiIgaBgaeesD+HSIiIm0x8KhI4iweIiKiBqHOgWfHjh247777EBYWBkmSsG7dOofjkiRVuy1cuFAp07p16yrH58+f73CeQ4cOYeDAgfDw8EDLli2xYMGCKnVZs2YNOnXqBA8PD3Tv3h0bN26sa7NuqfIhLU7hISIi0ladA09hYSF69uyJDz74oNrj2dnZDtsnn3wCSZLw8MMPO5R78803Hcr95S9/UY6ZzWYMGzYM4eHhSE5OxsKFCzFnzhwsX75cKbNr1y6MHDkS48ePx4EDBxAXF4e4uDikpqbWtWm3nOCgFhERkabqfPPQESNGYMSIEdc9HhIS4vD822+/xZAhQ9CmTRuH/T4+PlXKlvv8889RUlKCTz75BDqdDl27dkVKSgreeecdTJo0CQCwePFiDB8+HDNnzgQAzJs3DwkJCXj//fexbNmyujaPiIiInEi9zOHJycnBhg0bMH78+CrH5s+fj6ZNm6J3795YuHAhrFarciwpKQmDBg2CTqdT9sXExCAtLQ1XrlxRykRHRzucMyYmBklJSSq1pvY4pEVERKStOvfw1Mann34KHx8fPPTQQw77n3/+efTp0wcBAQHYtWsXZs+ejezsbLzzzjsAAKPRiIiICIfXBAcHK8f8/f1hNBqVfZXLGI3G69bHYrHAYrEoz81m8+9q3/VwWToREVHDUC+B55NPPsHo0aPh4eHhsH/69OnK4x49ekCn0+HZZ59FfHw89Hq9avWJj4/H3LlzVTv/tdjBQ0REpC3Vh7R+/vlnpKWlYcKECTctGxkZCavVitOnTwOQ5wHl5OQ4lCl/Xj7v53plrjcvCABmz54Nk8mkbFlZWbVpUo3x5qFEREQNg+qB5+OPP0bfvn3Rs2fPm5ZNSUmBi4sLgoKCAABRUVHYsWMHSktLlTIJCQno2LEj/P39lTKJiYkO50lISEBUVNR130ev18NgMDhsqmIXDxERkabqHHgKCgqQkpKClJQUAEBGRgZSUlKQmZmplDGbzVizZk21vTtJSUn45z//iYMHD+LUqVP4/PPP8eKLL+LJJ59UwsyoUaOg0+kwfvx4HDlyBF999RUWL17sMBQ2bdo0bNq0CYsWLcLx48cxZ84c7Nu3D1OnTq1r026Z8v4dLksnIiLSmKijrVu3Csh9Fw7b2LFjlTIffvih8PT0FHl5eVVen5ycLCIjI4Wvr6/w8PAQnTt3Fm+//bYoLi52KHfw4EExYMAAodfrRfPmzcX8+fOrnGv16tWiQ4cOQqfTia5du4oNGzbUqi0mk0kAECaTqVavu5nzeVdF+Kz1ot0rtasPERER3Vxtvr8lIbho2mw2w9fXFyaT6ZYOb2WbihAV/xPcXCSkv33vLTsvERER1e77m/fSUhHvpUVERNQwMPDUg0bfhUZERKQxBh4VcVU6ERFRw8DAUw84TYqIiEhbDDwqqliWTkRERFpi4FETh7SIiIgaBAaeesARLSIiIm0x8KiIy9KJiIgaBgYeIiIicnoMPCrisnQiIqKGgYGnnnBpOhERkXYYeFTEDh4iIqKGgYFHRVKlMS128BAREWmHgaeeMO8QERFph4FHRRzSIiIiahgYeOoJJy0TERFph4FHRVyWTkRE1DAw8NQT9u8QERFph4FHRby1BBERUcPAwKOmSnmHU3iIiIi0w8BTTwQHtYiIiDTDwKMiTlomIiJqGBh46gmHtIiIiLTDwKMidvAQERE1DAw8RERE5PQYeFQkcRIPERFRg8DAo6LKcYdzeIiIiLTDwENEREROj4FHRZVHtHgdHiIiIu0w8NQTDmkRERFph4FHRbyXFhERUcNQ58CzY8cO3HfffQgLC4MkSVi3bp3D8XHjxkGSJIdt+PDhDmUuX76M0aNHw2AwwM/PD+PHj0dBQYFDmUOHDmHgwIHw8PBAy5YtsWDBgip1WbNmDTp16gQPDw90794dGzdurGuzVMMOHiIiIu3UOfAUFhaiZ8+e+OCDD65bZvjw4cjOzla2L7/80uH46NGjceTIESQkJGD9+vXYsWMHJk2apBw3m80YNmwYwsPDkZycjIULF2LOnDlYvny5UmbXrl0YOXIkxo8fjwMHDiAuLg5xcXFITU2ta9NuGa5KJyIiahgkIX7/7BJJkrB27VrExcUp+8aNG4e8vLwqPT/ljh07hi5duuDXX39Fv379AACbNm3Cvffei7NnzyIsLAxLly7F3/72NxiNRuh0OgDAyy+/jHXr1uH48eMAgMcffxyFhYVYv369cu7+/fujV69eWLZsWY3qbzab4evrC5PJBIPBUIdPoHrFpTZ0em0TAODwnGHw8XC/ZecmIiJq7Grz/a3qHJ5t27YhKCgIHTt2xHPPPYdLly4px5KSkuDn56eEHQCIjo6Gi4sL9uzZo5QZNGiQEnYAICYmBmlpabhy5YpSJjo62uF9Y2JikJSUpGbTiIiI6A/ETa0TDx8+HA899BAiIiJw8uRJvPLKKxgxYgSSkpLg6uoKo9GIoKAgx8q4uSEgIABGoxEAYDQaERER4VAmODhYOebv7w+j0ajsq1ym/BzVsVgssFgsynOz2fy72no9jsvSiYiISCuqBZ4nnnhCedy9e3f06NEDbdu2xbZt2zB06FC13rZG4uPjMXfu3Hp9Ty5LJyIi0k69LUtv06YNAgMDkZ6eDgAICQlBbm6uQxmr1YrLly8jJCREKZOTk+NQpvz5zcqUH6/O7NmzYTKZlC0rK+v3Ne46uCydiIioYai3wHP27FlcunQJoaGhAICoqCjk5eUhOTlZKfPTTz/BbrcjMjJSKbNjxw6UlpYqZRISEtCxY0f4+/srZRITEx3eKyEhAVFRUdeti16vh8FgcNhUxx4eIiIizdQ58BQUFCAlJQUpKSkAgIyMDKSkpCAzMxMFBQWYOXMmdu/ejdOnTyMxMREPPPAA2rVrh5iYGABA586dMXz4cEycOBF79+7FL7/8gqlTp+KJJ55AWFgYAGDUqFHQ6XQYP348jhw5gq+++gqLFy/G9OnTlXpMmzYNmzZtwqJFi3D8+HHMmTMH+/btw9SpU3/Hx3JrcFk6ERFRAyHqaOvWrQJyv4XDNnbsWHH16lUxbNgw0axZM+Hu7i7Cw8PFxIkThdFodDjHpUuXxMiRI4W3t7cwGAzi6aefFvn5+Q5lDh48KAYMGCD0er1o3ry5mD9/fpW6rF69WnTo0EHodDrRtWtXsWHDhlq1xWQyCQDCZDLV/oO4gRKrTYTPWi/CZ60XVwott/TcREREjV1tvr9vyXV4/ujUug6P1WZHu7/9AABIef0e+HnpbvIKIiIiqqkGcx2exk6qNKbFWElERKQdBp56wrxDRESkHQYeFXHOMhERUcPAwFNPOFWKiIhIOww8KuKydCIiooaBgaeesH+HiIhIOww8KpLYxUNERNQgMPDUE07hISIi0g4DDxERETk9Bh6VlY9qCc7iISIi0gwDT31h3iEiItIMA4/KOG2ZiIhIeww89YQdPERERNph4FEZl6YTERFpj4FHZeVxh8vSiYiItMPAQ0RERE6PgUdlXJZORESkPQaeesIhLSIiIu0w8KhM4sJ0IiIizTHw1BN28BAREWmHgUdt7OAhIiLSHAOPyiqWpbOPh4iISCsMPEREROT0GHhUpixLZwcPERGRZhh4iIiIyOkx8KiMy9KJiIi0x8BTTzikRUREpB0GHpXxZulERETaY+BRmbIsnZceJCIi0gwDDxERETk9Bh6VSWVjWpzDQ0REpJ06B54dO3bgvvvuQ1hYGCRJwrp165RjpaWlmDVrFrp3744mTZogLCwMY8aMwfnz5x3O0bp1a0iS5LDNnz/focyhQ4cwcOBAeHh4oGXLlliwYEGVuqxZswadOnWCh4cHunfvjo0bN9a1WUREROSE6hx4CgsL0bNnT3zwwQdVjl29ehX79+/Ha6+9hv379+Obb75BWloa7r///ipl33zzTWRnZyvbX/7yF+WY2WzGsGHDEB4ejuTkZCxcuBBz5szB8uXLlTK7du3CyJEjMX78eBw4cABxcXGIi4tDampqXZt2S1XM4SEiIiKtuNX1hSNGjMCIESOqPebr64uEhASHfe+//z5uv/12ZGZmolWrVsp+Hx8fhISEVHuezz//HCUlJfjkk0+g0+nQtWtXpKSk4J133sGkSZMAAIsXL8bw4cMxc+ZMAMC8efOQkJCA999/H8uWLatr82453kuLiIhIO/U2h8dkMkGSJPj5+Tnsnz9/Ppo2bYrevXtj4cKFsFqtyrGkpCQMGjQIOp1O2RcTE4O0tDRcuXJFKRMdHe1wzpiYGCQlJanXmNrgsnQiIiLN1bmHpzaKi4sxa9YsjBw5EgaDQdn//PPPo0+fPggICMCuXbswe/ZsZGdn45133gEAGI1GREREOJwrODhYOebv7w+j0ajsq1zGaDRetz4WiwUWi0V5bjabf3cbb4b9O0RERNpRPfCUlpbisccegxACS5cudTg2ffp05XGPHj2g0+nw7LPPIj4+Hnq9XrU6xcfHY+7cuaqdvzJ28BAREWlP1SGt8rBz5swZJCQkOPTuVCcyMhJWqxWnT58GAISEhCAnJ8ehTPnz8nk/1ytzvXlBADB79myYTCZly8rKqm3TaozL0omIiLSnWuApDzsnTpzAli1b0LRp05u+JiUlBS4uLggKCgIAREVFYceOHSgtLVXKJCQkoGPHjvD391fKJCYmOpwnISEBUVFR130fvV4Pg8HgsBEREZHzqvOQVkFBAdLT05XnGRkZSElJQUBAAEJDQ/HII49g//79WL9+PWw2mzKnJiAgADqdDklJSdizZw+GDBkCHx8fJCUl4cUXX8STTz6phJlRo0Zh7ty5GD9+PGbNmoXU1FQsXrwY7777rvK+06ZNw1133YVFixYhNjYWq1atwr59+xyWrmup4l5a7OIhIiLSjKijrVu3Csjf4g7b2LFjRUZGRrXHAIitW7cKIYRITk4WkZGRwtfXV3h4eIjOnTuLt99+WxQXFzu8z8GDB8WAAQOEXq8XzZs3F/Pnz69Sl9WrV4sOHToInU4nunbtKjZs2FCrtphMJgFAmEymun4c19Vz7mYRPmu9+M1ovuXnJiIiasxq8/0tCcHZJWazGb6+vjCZTLd8eKv3mz/iytVSJLw4CO2DfW7puYmIiBqz2nx/815a9aTRp0oiIiINMfCoTJK4MJ2IiEhrDDwqU+6lxS4eIiIizTDwEBERkdNj4FFZ+YiW4CweIiIizTDw1BMOaREREWmHgUd1nLRMRESkNQaeesIeHiIiIu0w8KiMq9KJiIi0x8CjMmVZOictExERaYaBh4iIiJweA4/KlGXp7OAhIiLSDAMPEREROT0GHpVJXJZORESkOQaeesIhLSIiIu0w8KiMy9KJiIi0x8CjMi5LJyIi0h4DDxERETk9Bh6VSWVjWpzDQ0REpB0GHiIiInJ6DDz1hB08RERE2mHgqSeCY1pERESaYeBRGZelExERaY+BR2XKvbS0rQYREVGjxsBDRERETo+BR2Xl99LiFB4iIiLtMPAQERGR02PgUVnFpGV28RAREWmFgaeecEiLiIhIOww8KuOqdCIiIu0x8KhMuZeWxvUgIiJqzOoceHbs2IH77rsPYWFhkCQJ69atczguhMDrr7+O0NBQeHp6Ijo6GidOnHAoc/nyZYwePRoGgwF+fn4YP348CgoKHMocOnQIAwcOhIeHB1q2bIkFCxZUqcuaNWvQqVMneHh4oHv37ti4cWNdm0VEREROqM6Bp7CwED179sQHH3xQ7fEFCxbgvffew7Jly7Bnzx40adIEMTExKC4uVsqMHj0aR44cQUJCAtavX48dO3Zg0qRJynGz2Yxhw4YhPDwcycnJWLhwIebMmYPly5crZXbt2oWRI0di/PjxOHDgAOLi4hAXF4fU1NS6Nu2WKh/S4hweIiIiDYlbAIBYu3at8txut4uQkBCxcOFCZV9eXp7Q6/Xiyy+/FEIIcfToUQFA/Prrr0qZH374QUiSJM6dOyeEEGLJkiXC399fWCwWpcysWbNEx44dleePPfaYiI2NdahPZGSkePbZZ2tcf5PJJAAIk8lU49fU1JCFW0X4rPViz6lLt/zcREREjVltvr9VmcOTkZEBo9GI6OhoZZ+vry8iIyORlJQEAEhKSoKfnx/69eunlImOjoaLiwv27NmjlBk0aBB0Op1SJiYmBmlpabhy5YpSpvL7lJcpfx/Nld9agl08REREmnFT46RGoxEAEBwc7LA/ODhYOWY0GhEUFORYGTc3BAQEOJSJiIioco7yY/7+/jAajTd8n+pYLBZYLBbludlsrk3ziIiI6A+mUa7Sio+Ph6+vr7K1bNlStfdS5vCo9g5ERER0M6oEnpCQEABATk6Ow/6cnBzlWEhICHJzcx2OW61WXL582aFMdeeo/B7XK1N+vDqzZ8+GyWRStqysrNo2sdY4okVERKQdVQJPREQEQkJCkJiYqOwzm83Ys2cPoqKiAABRUVHIy8tDcnKyUuann36C3W5HZGSkUmbHjh0oLS1VyiQkJKBjx47w9/dXylR+n/Iy5e9THb1eD4PB4LCpRZJ46UEiIiKt1TnwFBQUICUlBSkpKQDkicopKSnIzMyEJEl44YUX8NZbb+G7777D4cOHMWbMGISFhSEuLg4A0LlzZwwfPhwTJ07E3r178csvv2Dq1Kl44oknEBYWBgAYNWoUdDodxo8fjyNHjuCrr77C4sWLMX36dKUe06ZNw6ZNm7Bo0SIcP34cc+bMwb59+zB16tS6fyq3UMWQFrt4iIiINFPXpWBbt24VkKemOGxjx44VQshL01977TURHBws9Hq9GDp0qEhLS3M4x6VLl8TIkSOFt7e3MBgM4umnnxb5+fkOZQ4ePCgGDBgg9Hq9aN68uZg/f36VuqxevVp06NBB6HQ60bVrV7Fhw4ZatUXNZenRi7aJ8FnrxS/pF275uYmIiBqz2nx/S0JwdonZbIavry9MJtMtH94a9u52/JZTgC8mROKOdoG39NxERESNWW2+vxvlKi0iIiJqXBh4VCaBNw8lIiLSGgNPPeHAIRERkXYYeFTGVelERETaY+CpJ1yWTkREpB0GHiIiInJ6DDwqK7/SMufwEBERaYeBh4iIiJweA4/KeLd0IiIi7THw1BNe0JqIiEg7DDwq47J0IiIi7THwqKw88LB/h4iISDsMPEREROT0GHhUVn4vLXbxEBERaYeBh4iIiJweA4/KKubwsIuHiIhIKww8RERE5PQYeFSmXHiQHTxERESaYeBRG++lRUREpDkGHiIiInJ6DDwq4720iIiItMfAQ0RERE6PgUdlyrJ0TuIhIiLSDAMPEREROT0GHpVxDg8REZH2GHhUJnFZOhERkeYYeIiIiMjpMfCoTFIesYuHiIhIKww8RERE5PQYeFRWsSxd23oQERE1Zgw8RERE5PRUDTytW7eGJElVtilTpgAABg8eXOXY5MmTHc6RmZmJ2NhYeHl5ISgoCDNnzoTVanUos23bNvTp0wd6vR7t2rXDypUr1WxWrUhls3jYwUNERKQdNzVP/uuvv8JmsynPU1NTcc899+DRRx9V9k2cOBFvvvmm8tzLy0t5bLPZEBsbi5CQEOzatQvZ2dkYM2YM3N3d8fbbbwMAMjIyEBsbi8mTJ+Pzzz9HYmIiJkyYgNDQUMTExKjZvJqRbl6EiIiI1KVq4GnWrJnD8/nz56Nt27a46667lH1eXl4ICQmp9vU//vgjjh49ii1btiA4OBi9evXCvHnzMGvWLMyZMwc6nQ7Lli1DREQEFi1aBADo3Lkzdu7ciXfffbdhBJ4ynMNDRESknXqbw1NSUoLPPvsMzzzzjHIxPgD4/PPPERgYiG7dumH27Nm4evWqciwpKQndu3dHcHCwsi8mJgZmsxlHjhxRykRHRzu8V0xMDJKSklRuUc1UXGmZiYeIiEgrqvbwVLZu3Trk5eVh3Lhxyr5Ro0YhPDwcYWFhOHToEGbNmoW0tDR88803AACj0egQdgAoz41G4w3LmM1mFBUVwdPTs0pdLBYLLBaL8txsNt+SNhIREVHDVG+B5+OPP8aIESMQFham7Js0aZLyuHv37ggNDcXQoUNx8uRJtG3bVrW6xMfHY+7cuaqdvzIuSyciItJevQxpnTlzBlu2bMGECRNuWC4yMhIAkJ6eDgAICQlBTk6OQ5ny5+Xzfq5XxmAwVNu7AwCzZ8+GyWRStqysrNo3ioiIiP4w6iXwrFixAkFBQYiNjb1huZSUFABAaGgoACAqKgqHDx9Gbm6uUiYhIQEGgwFdunRRyiQmJjqcJyEhAVFRUdd9H71eD4PB4LCphcvSiYiItKd64LHb7VixYgXGjh0LN7eKEbSTJ09i3rx5SE5OxunTp/Hdd99hzJgxGDRoEHr06AEAGDZsGLp06YKnnnoKBw8exObNm/Hqq69iypQp0Ov1AIDJkyfj1KlTeOmll3D8+HEsWbIEq1evxosvvqh204iIiOgPQvXAs2XLFmRmZuKZZ55x2K/T6bBlyxYMGzYMnTp1wowZM/Dwww/j+++/V8q4urpi/fr1cHV1RVRUFJ588kmMGTPG4bo9ERER2LBhAxISEtCzZ08sWrQIH330UYNZkl4xh4d9PERERFqRBL+JYTab4evrC5PJdMuHt0Z/tBu/pF/C4id64YFezW/puYmIiBqz2nx/815aRERE5PQYeFSmTFpu9P1oRERE2mHgISIiIqfHwKMyZdIyF6YTERFphoGHiIiInB4DTz3hHB4iIiLtMPCorPzO8Aw8RERE2mHgISIiIqfHwKOysjnLnLJMRESkIQYeIiIicnoMPCrjvbSIiIi0x8BDRERETo+BR2Wcw0NERKQ9Bh6VlS9LJyIiIu0w8NQXdvEQERFphoFHZRVDWkw8REREWnHTugJO7fIpLMgaiYs6PVLwg9a1ISIiarQYeNRkt6Op7QLcJC/eWoKIiEhDHNJSU9mEZYnDWURERJpi4FGTJH+8LpzBQ0REpCkGHjVVCjxERESkHQYeNSmBx845PERERBpi4FFTWeCRIDioRUREpCEGHjVxSIuIiKhBYOBRE4e0iIiIGgQGHjWVBR5XiWmHiIhISww8apIqPl7BLh4iIiLNMPCoqdKd0iXYNawIERFR48bAo6ZKPTyw27SrBxERUSPHwKOmyoGHK7WIiIg0w8CjpkqBRxIc0iIiItKKqoFnzpw5kCTJYevUqZNyvLi4GFOmTEHTpk3h7e2Nhx9+GDk5OQ7nyMzMRGxsLLy8vBAUFISZM2fCarU6lNm2bRv69OkDvV6Pdu3aYeXKlWo2q+YchrQYeIiIiLSieg9P165dkZ2drWw7d+5Ujr344ov4/vvvsWbNGmzfvh3nz5/HQw89pBy32WyIjY1FSUkJdu3ahU8//RQrV67E66+/rpTJyMhAbGwshgwZgpSUFLzwwguYMGECNm/erHbTbo5DWkRERA2Cm+pv4OaGkJCQKvtNJhM+/vhjfPHFF7j77rsBACtWrEDnzp2xe/du9O/fHz/++COOHj2KLVu2IDg4GL169cK8efMwa9YszJkzBzqdDsuWLUNERAQWLVoEAOjcuTN27tyJd999FzExMWo378Y4aZmIiKhBUL2H58SJEwgLC0ObNm0wevRoZGZmAgCSk5NRWlqK6OhopWynTp3QqlUrJCUlAQCSkpLQvXt3BAcHK2ViYmJgNptx5MgRpUzlc5SXKT+HpirP4WEPDxERkWZU7eGJjIzEypUr0bFjR2RnZ2Pu3LkYOHAgUlNTYTQaodPp4Ofn5/Ca4OBgGI1GAIDRaHQIO+XHy4/dqIzZbEZRURE8PT2r1MtiscBisSjPzWbz725rtSr38HDSMhERkWZUDTwjRoxQHvfo0QORkZEIDw/H6tWrqw0i9SU+Ph5z585V/40qXXgQvPAgERGRZup1Wbqfnx86dOiA9PR0hISEoKSkBHl5eQ5lcnJylDk/ISEhVVZtlT+/WRmDwXDdUDV79myYTCZly8rKuhXNq0qSYEdZ6LFzSIuIiEgr9Rp4CgoKcPLkSYSGhqJv375wd3dHYmKicjwtLQ2ZmZmIiooCAERFReHw4cPIzc1VyiQkJMBgMKBLly5KmcrnKC9Tfo7q6PV6GAwGh00tojzwsIeHiIhIM6oGnr/+9a/Yvn07Tp8+jV27duHBBx+Eq6srRo4cCV9fX4wfPx7Tp0/H1q1bkZycjKeffhpRUVHo378/AGDYsGHo0qULnnrqKRw8eBCbN2/Gq6++iilTpkCv1wMAJk+ejFOnTuGll17C8ePHsWTJEqxevRovvviimk2rMVH2EfPCg0RERNpRdQ7P2bNnMXLkSFy6dAnNmjXDgAEDsHv3bjRr1gwA8O6778LFxQUPP/wwLBYLYmJisGTJEuX1rq6uWL9+PZ577jlERUWhSZMmGDt2LN58802lTEREBDZs2IAXX3wRixcvRosWLfDRRx9pvyS9nCTJl+Bh4CEiItKMJIRo9JNLzGYzfH19YTKZbvnwVsncZtCJEqy6YwOeGDbglp6biIioMavN9zfvpaUyoXzEjT5XEhERaYaBR2WibGk65/AQERFph4FHZUoPD0cOiYiINMPAozIuSyciItIeA4/KRPntJTikRUREpBkGHpUpPTwc0iIiItIMA4/KeOFBIiIi7THwqExInMNDRESkNQYelVX08HBIi4iISCsMPCqrmMPDHh4iIiKtMPCojKu0iIiItMfAo7LyHh6Jc3iIiIg0w8CjMl5pmYiISHsMPCrjvbSIiIi0x8CjMmWVFoe0iIiINMPAo7KKScsc0iIiItIKA4/KlEnLwqZxTYiIiBovBh6VsYeHiIhIeww8Kqvo4eEcHiIiIq0w8KhMWZYO9vAQERFphYFHZVyWTkREpD0GHpVVXHiQgYeIiEgrDDwqU3p4OKRFRESkGQYelVX08HBZOhERkVYYeFRWviydPTxERETaYeBRWfmydM7hISIi0g4Dj8p4t3QiIiLtMfCorGLSMnt4iIiItMLAo7qyOTwc0iIiItIMA4/KeOFBIiIi7THwqEyZtMxVWkRERJpRNfDEx8fjtttug4+PD4KCghAXF4e0tDSHMoMHD4YkSQ7b5MmTHcpkZmYiNjYWXl5eCAoKwsyZM2G1Wh3KbNu2DX369IFer0e7du2wcuVKNZtWcxKHtIiIiLSmauDZvn07pkyZgt27dyMhIQGlpaUYNmwYCgsLHcpNnDgR2dnZyrZgwQLlmM1mQ2xsLEpKSrBr1y58+umnWLlyJV5//XWlTEZGBmJjYzFkyBCkpKTghRdewIQJE7B582Y1m1cjXKVFRESkPTc1T75p0yaH5ytXrkRQUBCSk5MxaNAgZb+XlxdCQkKqPcePP/6Io0ePYsuWLQgODkavXr0wb948zJo1C3PmzIFOp8OyZcsQERGBRYsWAQA6d+6MnTt34t1330VMTIx6DayBiiEtXmmZiIhIK/U6h8dkMgEAAgICHPZ//vnnCAwMRLdu3TB79mxcvXpVOZaUlITu3bsjODhY2RcTEwOz2YwjR44oZaKjox3OGRMTg6SkJLWaUmPKlZbZw0NERKQZVXt4KrPb7XjhhRdw5513olu3bsr+UaNGITw8HGFhYTh06BBmzZqFtLQ0fPPNNwAAo9HoEHYAKM+NRuMNy5jNZhQVFcHT09PhmMVigcViUZ6bzeZb19BrlPfwcA4PERGRduot8EyZMgWpqanYuXOnw/5JkyYpj7t3747Q0FAMHToUJ0+eRNu2bVWpS3x8PObOnavKua9V3sPDVVpERETaqZchralTp2L9+vXYunUrWrRoccOykZGRAID09HQAQEhICHJychzKlD8vn/dzvTIGg6FK7w4AzJ49GyaTSdmysrLq1rAa4KRlIiIi7akaeIQQmDp1KtauXYuffvoJERERN31NSkoKACA0NBQAEBUVhcOHDyM3N1cpk5CQAIPBgC5duihlEhMTHc6TkJCAqKioat9Dr9fDYDA4bKrhrSWIiIg0p2rgmTJlCj777DN88cUX8PHxgdFohNFoRFFREQDg5MmTmDdvHpKTk3H69Gl89913GDNmDAYNGoQePXoAAIYNG4YuXbrgqaeewsGDB7F582a8+uqrmDJlCvR6PQBg8uTJOHXqFF566SUcP34cS5YswerVq/Hiiy+q2bwaEeCkZSIiIq2pGniWLl0Kk8mEwYMHIzQ0VNm++uorAIBOp8OWLVswbNgwdOrUCTNmzMDDDz+M77//XjmHq6sr1q9fD1dXV0RFReHJJ5/EmDFj8OabbyplIiIisGHDBiQkJKBnz55YtGgRPvroI82XpAO8eSgREVFDoOqkZXGTXo2WLVti+/btNz1PeHg4Nm7ceMMygwcPxoEDB2pVv/pQMYeHgYeIiEgrvJeWynjzUCIiIu0x8KhMmcPDZelERESaYeBRm8QhLSIiIq0x8KisYtIye3iIiIi0wsCjsopl6ezhISIi0goDj8qUm4dyWToREZFmGHhUJw9p8dYSRERE2mHgUZnSw8MhLSIiIs0w8KisYlk6Aw8REZFWGHjUJnFIi4iISGsMPCpjDw8REZH2GHhUxltLEBERaY+BR20Sby1BRESkNQYelfFu6URERNpj4FGZYA8PERGR5hh4VCbAOTxERERaY+BRmd1FBwBwtxVpXBMiIqLGi4FHZbaAdgAA34J0jWtCRETUeDHwqKxZu94AgHYlxyEWdQZObdO2QkRERI0QA4/KIjr0UB5L+eeBH1/jVZeJiIjqGQOPyjz0emz3iqnYYTwEfP88UFqsXaWIiIgaGQaeetBz6mcY5vsdFlsfknfs/w+w9S1tK0VERNSIMPDUAz8vHZaM7osvPZ7ACqvc2yN2LwXOJmtcMyIiosaBgaeetAvyxhfP3onlTZ7FelskJLsVYuNfOZ+HiIioHjDw1KM2zbzx3/GRiMd4WIQ7pPP7gXPs5SEiIlIbA089axfkjUcG9caP9r7yjhM/alshIiKiRoCBRwNPRYUjSXQDABSd2K5xbYiIiJwfA48GAr31sLYaAADQZe8Diq5oXCMiIiLnxsCjkY5deuGYvSVchRXY8yFgtQCFl7SuFhERkVNi4NHIHW2b4mvbXfKTbfHAW0HAu12A/BxtK0ZEROSEGHg00inEBwnecdhou71ip7UYSN+iXaWIiIiclFMFng8++ACtW7eGh4cHIiMjsXfvXq2rdF2SJCG2d0vMLR3jeKCkQJsKEREROTGnCTxfffUVpk+fjjfeeAP79+9Hz549ERMTg9zcXK2rdl3PDmoDd//mjjuvnNakLkRERM7MaQLPO++8g4kTJ+Lpp59Gly5dsGzZMnh5eeGTTz7RumrX5eelw5P9wzGzdFLFTgYeIiKiW84pAk9JSQmSk5MRHR2t7HNxcUF0dDSSkpI0rNnN3d0pCGtsg/FiyXMAAHH+AGAt0bhWjYDdpnUNiIioHjlF4Ll48SJsNhuCg4Md9gcHB8NoNFYpb7FYYDabHTatdAj2wZ8Ht8UP9ttxQfhCys8G3moGbPv79b+UL6QB51PqtZ5O5YeXgYVtAfN5rWtCRET1xCkCT23Fx8fD19dX2Vq2bKlpfWbGdMSgLq0cJzBvexuYHw7kHncsbLMCH9wOLL8LKGi485MatD1L5Ys97npf65oQEVE9cYrAExgYCFdXV+TkOF7DJicnByEhIVXKz549GyaTSdmysrLqq6rVkiQJIyNbYb09Cn2KlyEfXvKBknzg80eBC79VFL5QKQDlHKnfijobe6nWNSAionriFIFHp9Ohb9++SExMVPbZ7XYkJiYiKiqqSnm9Xg+DweCwaW1wh2aYOqQdLsOABy1z8Il1OEpcPAFTJvDRUGDPcuBiOpCdUvGii79VPVHySiDhdXk4zGYFivLqqQV/QJzHQ0TUaLhpXYFbZfr06Rg7diz69euH22+/Hf/85z9RWFiIp59+Wuuq1YgkSZgxrANcXST8ku6PN8+0wH9s92B1048QVHAM+GFm1Red2w/s/y/QLhowhMq3pvh+mnzsl8VAWB85IE3YAjTvW6/t+UMQDDxERI2FJIQQWlfiVnn//fexcOFCGI1G9OrVC++99x4iIyNv+jqz2QxfX1+YTKYG0dsDAB/vzMC89UfhiwIsDvwO/e374HG16gRsAIBXIDD2eyBrD7D+harHO/0JeOLzmr+5EIAk1aneDjJ3AwFtAO+g33+uW8VmBeY1rXg+8yTQJFC7+hARUZ3V5vvbqQJPXTXEwAMA7yT8hvcSTyjPJwYcxF8LFyFFtEMwrqC1Sw3vu9VhODDqq6r7843ANxOB2ycBne+T9xVcAP49RH4+PL7ulf/tR+CLR4GgLsCfG9ClAYpNwPxWFc/bDgWe+ka7+hARUZ3V5vvbKebwOKvp93TAyqdvw1P9w+Glc8W/L/fEnZZ/YUzJyxhX+hLiS0dW+7oJJTPwtaHSiq/fNgGrx8hf9kLI83oy9wCLOgIZO4CvngTyMoGzycD2+YApC9i9RC67e5m81VbySvnP3KNVj/3yHvDlSKC0uPbn/b1KCh2fn0ysvhz98eQeB5I/Bex2rWtCRA2Q08zhcVaDOwZhcMcg/HVYR3y1LxPrD2VjaKdgbD5ixIfZoUgVrTHU5QCyRDPMcFuDPfbO2GLviy25wBKpBzbpX4YOVuDot/J2Pf/sXnXfmV3Aplny447DAf/WjsftNiB5BRAxGAhs53js6qWKx5YCQO9d8TzhNfnPQ6uAvuNq9kHURMEFeTl/n7FAWK/qy5Rcvf7rL52UQ961baE/hiVlw9cubkDv0drWhYgaHPbw/EH4erlj0qC2+G7qAEyLbo9Vz/ZHVJum+MXeHW9ax2CFbQT6WpZhfOlfldecEmGYVPJi3d905b0Vjz9/FEj9Btj3iTwP5tePgPd6AxtmAO/3BVL/V1G2tNhx+XzeGeWhyWyq2H/5VNX3FALY+S5wfIN8naHdy4DSoprVd9MsuX7LB1+/zLU3Z3Vxl/+0WoB/9ZHbUtP3I+0Um4AVscDef1c9duaX+q8PETV47OH5gzJ4uOPzCZH48agRGw4b8f3B87BAV6XcNntvtCv+D/7u/m8MdDkMCQK/BD6OwR4n4Hdua83f8OJvwNdlK97WVxOivn5GnhOUnlh1mGjjS8C49YAkYem3O/By+f5fFgPZB4FRq+UrR6dtBCIGAlvmyMeDuwM5h4ELx4D7Ft+8jll7yx7cYFpa6TU9PLom8p+VL+JYkAv4h1/3FBarDXo315vXh9STtAQ4s1Pebp/oeMxq0aZORNSgMfD8gbm4SBjeLRTDu4XipZiOeH7VAdzZNhDT7+mAfyaegLmoFInHc5B1uQgzSp+reOE5ABiMaa4BaO1iRLK9A7y6xqJLoCvidj0IAFhtvQuPuW2vXYU2v1L9/jM7gXc6A6E94XfS2/HYqW3y/8i/Hg8UXQaSKl39OOew/GfySqDLA0DbuyuOXT4FnNoOtOoPBHWu/n2Pb5DD1oPL5CAlRNU5PG4e8p+FlQLP1UvXDTz7Tl/GqH/vwYv3dMBzg9vK8542vwLELgJCulVfj/pScAEozgMC22tbj/pQnHf9Y1YN5oY5I7sd+N8z8lB29Byta0P0uzHwOImWAV5Y++c7lefT7+kAAJg1vBMkCVizLwvLfz6FrMsVwzWLbQ8D5ZeiOSTfsPQDaQGaSxexzd4LL1knoSnMuAwfvOD2DYJDwtBcV4SB5z8GAPyf/kVEXt2GaNcD1dbp0J/Wo8f6P8lP8rOB/GxMrq7gfx+seGy3Vt/A/z4IPJ8CnN0HBHeVL8ZYelWerzHtEODbXA405awWYNUo+fGnfwJ8W8p1aHpNGLCU3Uet4ELFvsrzj67x1vepmCqtQu+f0oCeXwGf3geUFspDfjOOXfd19eKdTvLnN/0YYAjTti5aYg/PrXEuGTiyVn489I1bc6kKIg0x8Dg5T5089PJUVGs82T8cB7LyoHdzwZlLV5FmzMfmI0YcN+ajU4gPjhvzcUK0wAnRouzVEi7BFwDwrvUR4Ky8t6cUjmDpCn4svg3/Rj/oS0vRFGa80j4T7Wyn0EQU4h/nuuLbr83oKb2Jb/WvV6nXOtsd2G7riXd1S2vemPd6Vd1ntwLL7gSipgDmsxX7961wLGcqu33IBTmUHLS3QU+XU3JospY49vAUXrxuFQaV/ozn3dbJTxb3qDiQr+GNSIWQP4fysHg+RbvAY8kH3L0Al2qG/Oy26vfXReVwa7cDotLKrLr28JxNlodVB80E3D1+X/2cQeXhX6tF+8+ktBj44jGg9UDgrmouxEp0Eww8jYgkSejTyh8A0DXMF/d2D8Xku9riXF4R2gV542BWHs5cvorozkEotQks2ZaOZt56hDdtgon/2aec56Bop0yT6d+mKY6cM+O8RYepJwIB9HF4z4OiHV4qnYgHXX7BPw0zUHz5HP7ithb/tsbiN9ES7azncI/+KNpYT+G0e1u0s8rXHfrAej/GuW5GE+n6/1sXHe+FlLZRvhHoT285HixfXXYdOcIfdiHBRRLy8EhBpWsalffw2KzyxRxb9ZcnyXoFoI/t0PVPai0B3CrNo8o9Buh9AN+yAJm1FwhoCzRpWv3r6yI9EVjzNDCw0ryq6/WSqS0/R5743XogMGqV47EfZgEHVwGTfwb8WlX/+roqKYDDvK269vB8VDZkqvcGBvyOyf7OonKItORrH3iOrAUytssbAw/VAQNPI+epc0W7IHleTc+WfujZ0k85NntExdyYw3OGYdXeLPRv0xQ/p19Am8AmOHulCKMiW2HHbxfx/KoD0Lu6YFDHZjiZW4Djxny0bdYEJy8UYrVtCFbbhgCXAKAdJpTORIjBA6XmYiy0PoGFVkCHUpRY3BHlcgTdpAx8ZLsXH1jjcBV6xHczYmT6DId632d5C0/YmmA0NlZpU6mLHu72ql96p4KHofTKOXQsOYKjIhyROAZfXAX+cc0w14Vj8iq0DY7vibhlaGORV5+ts92BONddDocPL58Aj+IctBv2LKSWkcCS/vIcob8Z5SX+K++VJ2I/tFy++vShr4CuD8m3BQHk5fup/wMO/Bd4+GPHeUS5x4ECI9BmsGOdvn4GsJgqJnoDwOqn5D+HvFq/XwzHvpPDx28/yLc4iX0XcClbCLqn7FpO2xcAD9yCu9TbKv18LWZAqtRzdO08rdqqr5vy5ucA+z8Fej9V8XegIan8OVrMgHcz7eoCyEPHRL8DAw/ViI+HOyYOagMA6N7C1+HY8G4hOPTGMHi4y186QgiYi6zw9XJHgcWK9xJPoNRmx3+SzsBmFxjWJRgvRHfAlC/2I+Oi/EusBPLy8CR7VyShKwAgLCgQ6bkFmJ0aim0t/oPHr3yIu22/YJutJw6LCBxOBZJdJqMQHugkZWGz/TYcF3Lvwea7TqPjHnkS9WldB3xceAe+PHM3rHBFSykXZ0UzDHQ5jL7SCVRx4DN5u9a6ySjvm/i/0ifxZfAMPJ0zH+2kc2jnch7dc8uuc/T1bmBgWViyFsu9G+XDAzmHgaWVbmib8iXw3E55iOaTGCAnVd6/YQbw5Nfy44ILFdeYmfxLxeTog6tuPHl361tAr5GAhy+QtgnoMAz2IhNcSgvlid6XTwG+rQDXW/RrwKXSeZJXymGuzV2Ow0+ms1VeVifFZsfHrpV61oou1/58letYfqkCtX39jDyh/+RPwDObqh4/kQCc3gkMff3WDQXWhqXSZ3zt5Rw0UWkOUWmx9j1O9IfDwEO3RHnYAeShM18v+UvDW++GV+6Ve4r+dm9nuLpISpmtfx2M83lFuFxYgiZ6N6QZzZjyxQFMGBCB6C7B6N3SD4sTT+BfP6Vj81k3bMYU6Nz+ghn3dAB+kHtavrEPAgBsxu0O9YnZ3hqtpUW4LAwwFzdxOJYlgtHMR4+x+bOQoJ+FUOn6k5QB4KqhLbzMJ5XnW209cQF+uHDWgj14EYDAriYvIcx2ruJFPy+qeLz3w+ufPOcw8G43edirPOwAQHoCsGm2fHPYkvyK/cvuBG5/Fhj8MrD22RvWGwDwblfALxzIO4OM8EfgfXoLmroWwuXuV4Etb8i3HXniS7knxpIvX4NI7wPYSgBztjxRtVnHKqc9eXQ/Wq4fCV3UpIpwd23QOPa9PJ+n8usrDx0WmwD3JnLgut7928znAa+mgJvecX/lL2OLGcJVr3wdinwjpITXgfA7gQ4xN/+MALnt5Vzd5Os/efoDoT2BoE41O0dtndkp/5l5nVuvfP6I/GdQZ6DnE+rU4UYqfyaVH9eH/02Uf/Zjvq0UyCuF0uI8wD2kfuvUENntFb2odFMMPFRv3Fyr/sMM8/NEmJ8nACAisAnS5gU7lJt+Twf0aOGHolIbmjbRoVtzX/h6uqNjiA/e2nAMbz7QFV/syURuvgXzH+qOFv5eePTDJBzMysNp4ThMMO6O1li56zQA4M62TfH9oRLcb3kTL4UewNzs/rDBBWNcE3DA3g4te9+Dcyk/Ikf4IyM3FAYUYLrb12guXcLrpeOuaYWEuUWPYbH7+/CQSpFhD0ZETe9zBsgTqssnVVe2e0n15fd+eOMQda2yCz9GnPla/k+yHXLYAeTbjvw3Duj9JLB2csUy/crDB9FzgDumARBA7jHYm3XBqS//irauRiDxTaDnSGDz34Aj19yT7Nd/y9vY9RX7Lp0EUr6Qe1HWPQd0fwTwDgb2Lgcm/iR/uV+9DHgFyCvyPr5HPn/cNZ9F5R6eT2Iq/98fEoR8jadfFgNv5FUEqStngI1/lefnhN/heL7KQSz9J2D/fyqeP/1D1fJlLFYb5q0/iqGdgjGkUw1vkmspAFJucjPfyj1Ol9Jrdt5brfJnXJ+Bx2oBDq+WHxsPAs37Vq1DsQnw0TDw3KobLP8eRVeApXfKl+u4FcPE1Th5oQAZWWcR3T0ccPdU5T3qEwMPNSjXhiJJknBPl+Aq5cpvuQEAd7R1vNv54sd74ZW1h1FitWPJ6D7w1Lli35kruKt9M8R0DcHuU5fwSN8WyLhYiINnBWZmV1zf50ObfBPVvfvPAuii7DfDG3Os4wAAejcXDO8YhE1HKu5ev9l+G/pa5HkqrrDjW883ESGygLhlEJ7+OPR1PNKLvbHONgDhUg7ecr9mFdk1bN6hcA3pJv9Sbz9Mvo7QV08Bp3++yScoK75tCjx+/aBGZZWJoED18yS2zJFDSUEOsGUOCu+YhV4ulYYC37nOdZDKffqnisc2ixx0yh38suLxkv5Apz8Bx9cD970n93IJuxwO7v0HoPOqKFu5h+dGLp2suFXI/8YDZ3+Vh5Bev6ZXr3LgMV8z7LbpZeDZHfLj5E+B1K+BB5cDhbnI+foVmLN7IXNfGjBzsXx5hJvZ+n/XD7O2sgnnldtnt1Vf9veoyZCQQy9axZCWEAJHzpsREdgETfR1/Ao5kSBfXqK61YSVV0k6hJxK9SnKq937/fIe4OkH9Blz06I39cMseTXfpO1yML+RY+vly2Fce3HMWyH1G8B8Tp7zp1LgGbVoLbboZyJvTy/4PVfNsOsfDAMPOZ3WgU3wxcT+DvuGlIWjqLZNEdVWXiW1+InemPn1Qfx6+goAwN1VQqntBldpLtOjhS+WPdUXy3ecxN6MK2jbrAk+3HEKhaj4H9DwonloLl1E4J7WuFJYghP5LynHfgZwSRjgKxXCENwaV5r2QUvXyzh06AAO2yNwGQa8/ac+eLRfS5RY7Ug4moMWFyV0HP0tUtKz0LfkV7j9vABnLU3w90sDYIYX3vP6GH7NWqDwwhn8p3gA/v7zHfBCX2weeBLnDybC5NsZnsZfsdY2AHvsnfGc/14kmZqip8tJTHLbcPMP9ed3gEtyyPHZ9Xf4qPWf2+NlvUHfP++4f9d78vCY1QJEDIT10uma/fJ6vy9w18vA1Yty2AHKlvCXDQXkHpN7lPKN1z9H9kFgUSfg3oUV9fruL8DF39Aq7wze05UNTX08DJiWArjeZA5Q6jfV77dZgQ/LLpBZ+eKRO98B+j1ds9VtpcXAz/8AOt8nD8eVu5Am93jd/Zq82inhdWDgdGDIK8CZJMAnGAhoU3avOSFfgfyaYcNyW9Ny8czKfbg9IgCrn40C8rLkn01NVx+mfiNftd0vXK5Du+iKlYyA4yUiKl8BvXJ9iivdouZGrl6Wl7KX/+x7PF51eLS2yifgJ6+oGM6tjq0U+Krsnm5hvYEW/aovV5Ar39y516ibBzKHIaxKv6sydgCeAbf84qfRrvvhIxUBOUmA6VzNAn117HZ5PmPl/7RogIGHGq3WgU2w+tkoFJfa4alzRaHFin/8mIZ7Ogcj68pVDO4YhFyzBWcuF+LN748iN98CFwmYe7/8S2XSoLaYNAg4l1eED3fI9wWL7hyMCwUWHMzKwykRhlMZ1U+g/cFeNgn5PIDzeZBva9dXOT7z60OY890RFJZU/d99y4CmyLo8x2Ffr4L3cF/bMHyfcQ7lkzuvwgMDf+4KoCtgBoB7lPKvXokFAGy194I/8vGo2w6H831mHYoubVqhRRM7go59qoSdyg7bWyPE2w3NrjoOucwPXYyXY9oDe5bKq6eOrgMA5Lv4ooneFS51mVS8Lb7i8dbr/+JSLjVQ2fb5VQu+6V+798/PBr56suJ5ekLVMuazwM5/yivjMn6W52ANe1Mecsg5AhxeA9z5QjW/9MvS48XfgNyj8uML11zE8ptngWd+qHhuLZFDw+VTQLeH5V5Ai1keljRlAbv+Bbxa1mv1/QvylzMgT3QXZX+nUr6Qe+42TJfDzl/2yxPnLxwH7n+/+jk8hZewZk8G3GHFpdOHgfwI+XpUAW2AKXvlNjTrdOPhnvJevbwz8mo+31bAi4crjle+CGh+ttyWg6sAD7+K/cUm4Mpp+YKktz8L9K/mkqa2UuB/EyrCDiCHs6LL8jBZXSaCV/5Mrl7z9/hCmnzV9aipQNshwMVK/2bO7ZcDjxBAdgoQ3K0iGO96T57HlZkEhPYCQnugWtsXyNuELfLNkSv1uuFTuWcaD38sDxP/HiVXgZ//AXu3R9FWqnR9sZOJde8hu3wK+OA2IKQHMGmbZsOBkhDi5v+ldXJmsxm+vr4wmUwwGAxaV4caoGxTESyldrQObFLt8S1Hc/DJLxmIf6g7zly6ijGf7IWnuyuKSh0Di6+nOyYNaoOzV66iuZ8nlmw7iaslNrQJbIJTF7Vbdrv0wVbwOfgJXs7ogXApB7vtXWCDK1xdJHx6dymCfl2AiJI05AbfBenqBYSZD+Jvpc/gc1s0PFGMv4Qex72XPsUuexe8bn0a/doE4dXYLujW3BeL1iWhyb73scZ2F6Ij+2L2AAO++O9yJF9wQQ+XkxjrloAzTXqghcENLpd+g1S2IuhS6F340nY3Hnb7GaHnt8iTl8PvhDi+HpftTTCz9Fn44CoW+qyCziJ/+fxguw0BUj76SCfwm2cvdC1OrmhklweAzD3y8v76EtAGGL8F+FfvG/dKvHJevhXKNzcY+vjTP4HCC0D7e+Ql7V8+fuP3fv2KvLpqfsvqj7u4yVv5hRrHfAv85wH5cZNmgH8EcLbs/nQD/yp/kX44CCd0nZFW4Ik/ue52PF+/Z+Sb994zD7izUg/duWT5GlS3T5JDxifDq07Ufv1yRQA58Bnw7RT58W0T5EtEXOvef8gX2EwpW035Rp4ctryD5N6mjJ+BjG1yWKqsXTSQvgUY9BJw99+u88GVEULe0hPkIOITLAfXpZXmc/3NCECSew3/Hi7/GdgBGLdBvk3OL2X3AOzyAPDYfyraFvkcMKIsiK+bUtEOAHg5S+5hO7VVHk4e9pZ8bas3y4bPgrrKKy8zHS+LoXgpQ+4JNR6WL2Nx9lf5EheVe9FuZP10YN/HEDof7CsOxW0uvzm2oS5S/yevSmzeV56rdwvV5vubgQcMPHTrXS2xwkvnhhKrHZIEuEiSskKtsryrJfDSuUHn5oLUcybkF1uxP/MKfjyag2beeuw7cxkhBg/c1joAv56+jGFdgvHxzgyl52fcHa3x5d5MWKx2h/PWdHiudgQACR6w4DaXNPxi7wY7brxCpE8rP6SeN6OkUv0e7N0caw+Ur2gTaC+dQ6YIQs9WgejR3Bu/7E5CmHQRiXa5x8sTxTj60BVI7e8B/MPx9bZ9eG3TGRTBQznHIvel6O9yDG+XjsYWex94woImfkF4/u62GJL/Pbzc7NjoFYcmRecw/MCfIeVlIkOEIkhcxP9ZR+NVnw3w8vaBRRcAz/PyF3meaIK3raPwtv5TuNlLlPoXN2kOj0K5/iftoXildAIOiHb4uesGBJ9cXbePtssDwNFv6/ba6/EKlIfybpXADnKoqAHh5oUrogksLaIQeuY7eWeTIHmYrbresTueB4bNkwPKj6/e/A0GvyIPNaaVDcdGDJKHdQwtYA9sD5dTNbgxcv8/AzFvy70NxzfKc7MG/hUI7gKsGSdfygGiIhBO+Ekebvuy0oq5vk/L9wKsyefy2H8rrpEFyKEoaw9waI1jj96T/5MnzVf++9D5PnnVY01ILhUXjdQb5J4/T39g2kE5KJW7ehl2vR9OnM9F+2A/uOjK/j29201ZRGER7tBLpRWvmfIr0KyDvILzZCLQdqh8DamSQvnehhED5WPezQCdD5C1Ww6LOxbI4a/fM8Cf3q1ZO2qIgaeWGHjoj+S3nHxsSjXiidtbopm3Hvsz87D71CW4uUg4l1eEEd1CEdW2KbYez8XaA+dQYLHiYoEF564U4dNnbseJ3Hz0aumPiMAmuFRgwX3/2onzporbMTTz0aNpEx3u7hSEvRmXse/MlevWRe/m4hC22gd5o12QN7JNxUjJylP2u0jypQuuVjNEV1OtArww+a62+HjnKZy8ULU3zEUC7NX8NgsxeMDPyx3HjfJwhAQ7xDVBbXD7ABRY7NiXmQcX2OGBElwtC1QusGOG7zZcadYXa9JdYYYXdjzRBA+sykE+vFBaNsDmBisWun8IbxThS9vd+LjTfkin5P/Nlkh6pAcNQ4TOBM+sHcgRfoi1xOML3Vvo4HIO1/rBdhsWWh9HpgiCD65iZYsN6Hmxhl94N5Flb4aL8ENvl6rDlLVhExJcrx0+/D0C2shDH/XN019e8VQDRU1awLOwdteSyhYBCJXqMIyrhs73Azpv4OAXyi6rcIGbZIfwCYNUzS1ySoQrzJIBgbhScY6TP8m9h3oD0PJ2udfsWq56xwuEAsB9i4G+425hgxh4ao2Bh5ydEAIWq93heknlcszF2H3qEkptAp1DfdDC3wu+nvL8glKbHV8nn8XqfVlwkSTE9W6OywUlGBMVDj8vd9gFcO5KEeZ8fwQnLxRg7v1dldVzqedMePmbQ7hSWIoXotvjYkEJ/r7p+C1pj6+nOza9MBDxG4/ju4PyL+lxd7RG3tUSrEvR8L5mDgTubeOOjHM5uGhxwQX4w91VQqjdCItwRw4C0Fs6gb/rV8DqHYoTru2w6UIAzoumOC5aQbh5OPSMzerngjGd7LiQuhU/njDjYFEw3DsMRRv7aaw5IdBNysAR0RpdpdN4qelORHTogavnjyJbF47w01/joGiLY/ZW+NHeDxahw0yfTTh8NQC77Z3xts//4NFlOFZneOB9Yxes8F4CvyaeuCfnz4hyOYrxhl8RVfILcm3eyBdecIMNT5S8ijaSEXPcP0Vnl0yYhBfiraNwm8txDHQ7hi9L74IrbBgZmIGmeY63ZPnIOgIdpSwE+/ugUNcMvS9+V+XTswsJNskV75XGYavbAKxqvhqu5/dDuLrDy1Z1mfxJl9YIsuXIk2xv4Ji9FQxSIZrf5Ppb5ar0cgCYVzoaz4WkIfDSPof9QuetDMkCwHF7SzxW8joOeDwLVzj2wl6rxKMpdMU3r5OQXCBVuu3HCyV/Rqh0GQXwwCVhwDseH8PDfuuGxzfabscH1gewPORbNL+y93edyz45CS4hXW5esBYYeGqJgYdIfVabHYfOmdCjuS+yTcUI9NZj7YFz8NS5IK5XcxzLzkdKVh5ie4QiPbcAnu6ucHOVsP5QNt5LlHsjwpt6wc9Lhzfu64I+rfxRXGrDkq3paOajxxO3y6uYEo7moG+4P348YsQxYz62Hc/FeVMxRkW2wt6My0jPLcDYqHAkHs/F2Svyl+O1PVXN/TxxLu/GX5zl5VZN6o81+7Lw2Z5MXC4suelrauKeLsH495h+2HniIp78eE+dznF76wDsPS33LOhRAitcYYMrApro6lRPF9ghgLLeMXl4s5wHLCjG9Vc/SbBDAuCNqwiXcnFYRCivl2DHs9478WjzK/gsrys+y2mN7tIppIh2cINNuQq73DMnwQdFmNrLFe5XTmBfVgH6uKTDw8WGBSWPoJmUh3bSefxo74tOUhayRDOES7mIc92JQnhgs+02HBPhcIEdsS67Mdl3D4JsRhRbivFu6cMIlvJwl1sqfrOFYqUtBq2kXOywy5OIZ/om4i7bbiQWd8S71kcQ4FaMJSEbkGP3RXBwKFx++wHTip/FOZsv/JCPYOkKLgg/XIYBMS6/Yon7P/GFbShesz6NOSFJiC75CZckf/Qs/AVfWO/G36zP4PnW51CclYJHXHdgk/02fGm9GwXwwAjXX3G7yzEkug+Ba7u7sf7QOYx2TUQnKRNvWMfBhor/yATjMtq4ZOOK8MFMt69ggTteK30an3RORnN9Ma7kZCLUfBDeNhMuCANWWIdjlNtP0KME3ijGdntPZIlmiHI5iovCF/HWkUgru4L9E94peDHsKA4X+GCFFAd79iHc5poOX4MPdlxpCgl27Ld3wAejeiO46AT0ei8Eb5mKq/l5mFE6GYYesVjwSA/o3W7dlcMZeGqJgYfIednsAkZzMUIMHjhzqRCp582I7R6KiwUWfLk3E+MHRMDD3RVuLhI+3pkBD3dXjLq9FQSAjIsFWLnrNK5abMi6chVtm3kj/qHu+CHViKSTl/Bgn+bKDXnP5xXh75uOo9Rmx+AOQdhx4gLO5xXB4OmOIB89XvtTF7y6LhXb0i7gsX4t0KppEyzZmo7ssuHESYPaYEjHIFwssODOdoEIaCLfLsN0tRR//fogth7PhbVszM7T3RWLHuuJV9YeRt7VUkiSPL/2znZNkXW5CJmXr1b7Wfh7uWPD8wPxj81p+ObAOejdXKB3c4G5uOoNZ710rphzf1dsPZ6LH1KrTvT29XSHqai0yv7a8PFwg80uqgx1XluvYIMeOeY63hT2Gu2DvHEi9/fdKqNzqAHHsmt4LagyATAjD95V5r3dLCyqp/yrX8K1AbayEd1CsDP9IvKr+TtyM64uEoTdVhZ3JXQJNWD15Ch41/X6TdVg4KklBh4iqi9CCEhly3KPG81IPWfGsK7BMHjc+Po9xaU2nMsrQnGpDXo3+aa/Z69cxakLhRjYPhAHz5oQHuCFtJx8fJ18Fu6u8pfMK/d2gs7NBUIAJTY7DB7usNsF9mdeQTMf+Yv2n1tOYM+pSygqteGdx3oBEtA11IAggwcsVhv+m3QGGRcLERHYBF46NxRarJgwMAJ2IX+p5ZqL8Y8f02C1CSQczUFkmwAsGd0XlwtLsP23XBRabCgqtWHptpPoGmbA0if74tyVIrQNaoL9Z/Iw5Yv98PdyR9tm8hyw2B6hCPLxwJ6MSxjcMQiSBCQey8FdHYKwLS0XX+zJxJHzZjzUpzksVjta+HuiS6gBr32birF3tEZxqR0/Hc9BtzBf9Gzph4yLhUg6eQmtA5sg/qHu2HI0B0u2pUMIoH+bpmju7wl/L3e8+f1RZUHAiG4hyLhYiL7h/sgxW7DlmLzMP8TggW0zB+PpFb9id8YleFVajTn/oR44mm2Gh7sr/Lzc0TfcH64uEqatOgC9myui2jSF3s0Fu05ewtGywKR3c8GCR3ogzM8TCzenYe81l7J4tG8LfJtyHiU2O/q08sP+zDwA8py2dx7rCUmScLHAgiEdg7Bs+0m8k/Abwpt64bF+LeVezux8lNgqei9bBXhdNxADQIdgbzzWryXW7DuLCwUWLHq0J3w83LDlWC6WbT953dcBQJivB8KbNkHSqapDcz1b+mH5U30RbLi190Bj4KklBh4iolujuNRW7VwxACix2uHuKimB7/eoHBxvtWvPLYTAgaw8XCooQbsgb0SUXZ7CZhdwdZGQd7UEdgGlV66m9T1zqRAGD3f4l71OCIGNh40I9NYhzM8Tvl7uMHi447jRjOJSO3q19CsLvC7XbXve1RLo3Vzhqat0M+diKwotVpy9UoTbWvsj32LFxkPZuKtjM/h76fDr6csID2iCi4UWdAz2ue4VtG12gUNn8xDm54lm3nq510cCrhSWILypFyRJghACJy8UwN9Lh+PGfJy8UIDhXUMQdIuDTjkGnlpi4CEiIvrjqc33N2+zSkRERE6PgYeIiIicHgMPEREROT0GHiIiInJ6DDxERETk9Bh4iIiIyOkx8BAREZHTY+AhIiIip6dK4Dl9+jTGjx+PiIgIeHp6om3btnjjjTdQUlLiUEaSpCrb7t27Hc61Zs0adOrUCR4eHujevTs2btzocFwIgddffx2hoaHw9PREdHQ0Tpw4oUaziIiI6A9KlcBz/Phx2O12fPjhhzhy5AjeffddLFu2DK+88kqVslu2bEF2dray9e3bVzm2a9cujBw5EuPHj8eBAwcQFxeHuLg4pKamKmUWLFiA9957D8uWLcOePXvQpEkTxMTEoLi4WI2mERER0R9Qvd1aYuHChVi6dClOnToFQO7hiYiIwIEDB9CrV69qX/P444+jsLAQ69evV/b1798fvXr1wrJlyyCEQFhYGGbMmIG//vWvAACTyYTg4GCsXLkSTzzxRI3qxltLEBER/fE0yFtLmEwmBAQEVNl///33IygoCAMGDMB3333ncCwpKQnR0dEO+2JiYpCUlAQAyMjIgNFodCjj6+uLyMhIpUx1LBYLzGazw0ZERETOq14CT3p6Ov71r3/h2WefVfZ5e3tj0aJFWLNmDTZs2IABAwYgLi7OIfQYjUYEBwc7nCs4OBhGo1E5Xr7vemWqEx8fD19fX2Vr2bLl724jERERNVzV3wP+Ol5++WX8/e9/v2GZY8eOoVOnTsrzc+fOYfjw4Xj00UcxceJEZX9gYCCmT5+uPL/ttttw/vx5LFy4EPfff39tqlVrs2fPdnhvk8mEVq1asaeHiIjoD6T8e7sms3NqFXhmzJiBcePG3bBMmzZtlMfnz5/HkCFDcMcdd2D58uU3PX9kZCQSEhKU5yEhIcjJyXEok5OTg5CQEOV4+b7Q0FCHMtebFwQAer0eer1eeV7+gbGnh4iI6I8nPz8fvr6+NyxTq8DTrFkzNGvWrEZlz507hyFDhqBv375YsWIFXFxuPnqWkpLiEFyioqKQmJiIF154QdmXkJCAqKgoAEBERARCQkKQmJioBByz2Yw9e/bgueeeq3G7wsLCkJWVBR8fH0iSVOPX1YTZbEbLli2RlZXVKCdEs/1sP9vfeNsP8DNg+9VtvxAC+fn5CAsLu2nZWgWemjp37hwGDx6M8PBw/OMf/8CFCxeUY+W9Mp9++il0Oh169+4NAPjmm2/wySef4KOPPlLKTps2DXfddRcWLVqE2NhYrFq1Cvv27VN6iyRJwgsvvIC33noL7du3R0REBF577TWEhYUhLi6uxvV1cXFBixYtbkHLr89gMDTKv+zl2H62n+1vvO0H+Bmw/eq1/2Y9O+VUCTwJCQlIT09Henp6lSBReZxt3rx5OHPmDNzc3NCpUyd89dVXeOSRR5Tjd9xxB7744gu8+uqreOWVV9C+fXusW7cO3bp1U8q89NJLKCwsxKRJk5CXl4cBAwZg06ZN8PDwUKNpRERE9AdUb9fhaawa+zV+2H62n+1vvO0H+Bmw/Q2n/byXlsr0ej3eeOMNh0nSjQnbz/az/Y23/QA/A7a/4bSfPTxERETk9NjDQ0RERE6PgYeIiIicHgMPEREROT0GHiIiInJ6DDwq+uCDD9C6dWt4eHggMjISe/fu1bpKt8SOHTtw3333ISwsDJIkYd26dQ7HhRB4/fXXERoaCk9PT0RHR+PEiRMOZS5fvozRo0fDYDDAz88P48ePR0FBQT22ou7i4+Nx2223wcfHB0FBQYiLi0NaWppDmeLiYkyZMgVNmzaFt7c3Hn744Sq3ScnMzERsbCy8vLwQFBSEmTNnwmq11mdT6mTp0qXo0aOHciGxqKgo/PDDD8pxZ257debPn69cBLWcs38Gc+bMgSRJDlvleyg6e/sB+QK7Tz75JJo2bQpPT090794d+/btU4478+/B1q1bV/n5S5KEKVOmAGjAP39Bqli1apXQ6XTik08+EUeOHBETJ04Ufn5+IicnR+uq/W4bN24Uf/vb38Q333wjAIi1a9c6HJ8/f77w9fUV69atEwcPHhT333+/iIiIEEVFRUqZ4cOHi549e4rdu3eLn3/+WbRr106MHDmynltSNzExMWLFihUiNTVVpKSkiHvvvVe0atVKFBQUKGUmT54sWrZsKRITE8W+fftE//79xR133KEct1qtolu3biI6OlocOHBAbNy4UQQGBorZs2dr0aRa+e6778SGDRvEb7/9JtLS0sQrr7wi3N3dRWpqqhDCudt+rb1794rWrVuLHj16iGnTpin7nf0zeOONN0TXrl1Fdna2sl24cEE57uztv3z5sggPDxfjxo0Te/bsEadOnRKbN28W6enpShln/j2Ym5vr8LNPSEgQAMTWrVuFEA3358/Ao5Lbb79dTJkyRXlus9lEWFiYiI+P17BWt961gcdut4uQkBCxcOFCZV9eXp7Q6/Xiyy+/FEIIcfToUQFA/Prrr0qZH374QUiSJM6dO1dvdb9VcnNzBQCxfft2IYTcXnd3d7FmzRqlzLFjxwQAkZSUJISQQ6OLi4swGo1KmaVLlwqDwSAsFkv9NuAW8Pf3Fx999FGjant+fr5o3769SEhIEHfddZcSeBrDZ/DGG2+Inj17VnusMbR/1qxZYsCAAdc93th+D06bNk20bdtW2O32Bv3z55CWCkpKSpCcnIzo6Ghln4uLC6Kjo5GUlKRhzdSXkZEBo9Ho0HZfX19ERkYqbU9KSoKfnx/69eunlImOjoaLiwv27NlT73X+vUwmEwAgICAAAJCcnIzS0lKHz6BTp05o1aqVw2fQvXt3BAcHK2ViYmJgNptx5MiReqz972Oz2bBq1SoUFhYiKiqqUbV9ypQpiI2NdWgr0Hh+/idOnEBYWBjatGmD0aNHIzMzE0DjaP93332Hfv364dFHH0VQUBB69+6Nf//738rxxvR7sKSkBJ999hmeeeYZSJLUoH/+DDwquHjxImw2m8MPEwCCg4NhNBo1qlX9KG/fjdpuNBoRFBTkcNzNzQ0BAQF/uM/HbrfjhRdewJ133qnc481oNEKn08HPz8+h7LWfQXWfUfmxhu7w4cPw9vaGXq/H5MmTsXbtWnTp0qVRtB0AVq1ahf379yM+Pr7KscbwGURGRmLlypXYtGkTli5dioyMDAwcOBD5+fmNov2nTp3C0qVL0b59e2zevBnPPfccnn/+eXz66acAGtfvwXXr1iEvLw/jxo0D0LD//qty81CixmLKlClITU3Fzp07ta5KverYsSNSUlJgMpnw9ddfY+zYsdi+fbvW1aoXWVlZmDZtGhISEhrtTYpHjBihPO7RowciIyMRHh6O1atXw9PTU8Oa1Q+73Y5+/frh7bffBgD07t0bqampWLZsGcaOHatx7erXxx9/jBEjRiAsLEzrqtwUe3hUEBgYCFdX1yqz0nNychASEqJRrepHeftu1PaQkBDk5uY6HLdarbh8+fIf6vOZOnUq1q9fj61bt6JFixbK/pCQEJSUlCAvL8+h/LWfQXWfUfmxhk6n06Fdu3bo27cv4uPj0bNnTyxevLhRtD05ORm5ubno06cP3Nzc4Obmhu3bt+O9996Dm5sbgoODnf4zuJafnx86dOiA9PT0RvF3IDQ0FF26dHHY17lzZ2VYr7H8Hjxz5gy2bNmCCRMmKPsa8s+fgUcFOp0Offv2RWJiorLPbrcjMTERUVFRGtZMfREREQgJCXFou9lsxp49e5S2R0VFIS8vD8nJyUqZn376CXa7HZGRkfVe59oSQmDq1KlYu3YtfvrpJ0RERDgc79u3L9zd3R0+g7S0NGRmZjp8BocPH3b4hZeQkACDwVDlF+kfgd1uh8ViaRRtHzp0KA4fPoyUlBRl69evH0aPHq08dvbP4FoFBQU4efIkQkNDG8XfgTvvvLPKpSh+++03hIeHA2gcvwcBYMWKFQgKCkJsbKyyr0H//FWbDt3IrVq1Suj1erFy5Upx9OhRMWnSJOHn5+cwK/2PKj8/Xxw4cEAcOHBAABDvvPOOOHDggDhz5owQQl6O6efnJ7799ltx6NAh8cADD1S7HLN3795iz549YufOnaJ9+/Z/iOWYQgjx3HPPCV9fX7Ft2zaHpZlXr15VykyePFm0atVK/PTTT2Lfvn0iKipKREVFKcfLl2UOGzZMpKSkiE2bNolmzZr9IZblvvzyy2L79u0iIyNDHDp0SLz88stCkiTx448/CiGcu+3XU3mVlhDO/xnMmDFDbNu2TWRkZIhffvlFREdHi8DAQJGbmyuEcP727927V7i5uYn/+7//EydOnBCff/658PLyEp999plSxtl/D9psNtGqVSsxa9asKsca6s+fgUdF//rXv0SrVq2ETqcTt99+u9i9e7fWVboltm7dKgBU2caOHSuEkJdkvvbaayI4OFjo9XoxdOhQkZaW5nCOS5cuiZEjRwpvb29hMBjE008/LfLz8zVoTe1V13YAYsWKFUqZoqIi8ec//1n4+/sLLy8v8eCDD4rs7GyH85w+fVqMGDFCeHp6isDAQDFjxgxRWlpaz62pvWeeeUaEh4cLnU4nmjVrJoYOHaqEHSGcu+3Xc23gcfbP4PHHHxehoaFCp9OJ5s2bi8cff9zhGjTO3n4hhPj+++9Ft27dhF6vF506dRLLly93OO7svwc3b94sAFRpkxAN9+cvCSGEev1HRERERNrjHB4iIiJyegw8RERE5PQYeIiIiMjpMfAQERGR02PgISIiIqfHwENEREROj4GHiIiInB4DDxERETk9Bh4iIiJyegw8RERE5PQYeIiIiMjpMfAQERGR0/t/hmYliJEDx/QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.97529  validloss 10.42593±0.00000  bestvalidloss 10.42593  last_update 0\n",
      "train: iter 1  trainloss 9.09046  validloss 9.47284±0.00000  bestvalidloss 9.47284  last_update 0\n",
      "train: iter 2  trainloss 8.35362  validloss 8.66775±0.00000  bestvalidloss 8.66775  last_update 0\n",
      "train: iter 3  trainloss 7.72152  validloss 8.01388±0.00000  bestvalidloss 8.01388  last_update 0\n",
      "train: iter 4  trainloss 7.20743  validloss 7.44040±0.00000  bestvalidloss 7.44040  last_update 0\n",
      "train: iter 5  trainloss 6.75935  validloss 6.95669±0.00000  bestvalidloss 6.95669  last_update 0\n",
      "train: iter 6  trainloss 6.36997  validloss 6.54823±0.00000  bestvalidloss 6.54823  last_update 0\n",
      "train: iter 7  trainloss 6.04092  validloss 6.19007±0.00000  bestvalidloss 6.19007  last_update 0\n",
      "train: iter 8  trainloss 5.74892  validloss 5.86319±0.00000  bestvalidloss 5.86319  last_update 0\n",
      "train: iter 9  trainloss 5.49032  validloss 5.59191±0.00000  bestvalidloss 5.59191  last_update 0\n",
      "train: iter 10  trainloss 5.27583  validloss 5.36172±0.00000  bestvalidloss 5.36172  last_update 0\n",
      "train: iter 11  trainloss 5.06106  validloss 5.14759±0.00000  bestvalidloss 5.14759  last_update 0\n",
      "train: iter 12  trainloss 4.86925  validloss 4.95448±0.00000  bestvalidloss 4.95448  last_update 0\n",
      "train: iter 13  trainloss 4.70842  validloss 4.76757±0.00000  bestvalidloss 4.76757  last_update 0\n",
      "train: iter 14  trainloss 4.55043  validloss 4.62334±0.00000  bestvalidloss 4.62334  last_update 0\n",
      "train: iter 15  trainloss 4.40932  validloss 4.45866±0.00000  bestvalidloss 4.45866  last_update 0\n",
      "train: iter 16  trainloss 4.27206  validloss 4.32940±0.00000  bestvalidloss 4.32940  last_update 0\n",
      "train: iter 17  trainloss 4.14654  validloss 4.19243±0.00000  bestvalidloss 4.19243  last_update 0\n",
      "train: iter 18  trainloss 4.02404  validloss 4.08201±0.00000  bestvalidloss 4.08201  last_update 0\n",
      "train: iter 19  trainloss 3.90817  validloss 3.95443±0.00000  bestvalidloss 3.95443  last_update 0\n",
      "train: iter 20  trainloss 3.79336  validloss 3.84633±0.00000  bestvalidloss 3.84633  last_update 0\n",
      "train: iter 21  trainloss 3.68639  validloss 3.72904±0.00000  bestvalidloss 3.72904  last_update 0\n",
      "train: iter 22  trainloss 3.57275  validloss 3.61890±0.00000  bestvalidloss 3.61890  last_update 0\n",
      "train: iter 23  trainloss 3.47289  validloss 3.51089±0.00000  bestvalidloss 3.51089  last_update 0\n",
      "train: iter 24  trainloss 3.36306  validloss 3.40795±0.00000  bestvalidloss 3.40795  last_update 0\n",
      "train: iter 25  trainloss 3.26655  validloss 3.30480±0.00000  bestvalidloss 3.30480  last_update 0\n",
      "train: iter 26  trainloss 3.16303  validloss 3.20352±0.00000  bestvalidloss 3.20352  last_update 0\n",
      "train: iter 27  trainloss 3.06070  validloss 3.10721±0.00000  bestvalidloss 3.10721  last_update 0\n",
      "train: iter 28  trainloss 2.96282  validloss 3.00374±0.00000  bestvalidloss 3.00374  last_update 0\n",
      "train: iter 29  trainloss 2.87075  validloss 2.90773±0.00000  bestvalidloss 2.90773  last_update 0\n",
      "train: iter 30  trainloss 2.77986  validloss 2.81881±0.00000  bestvalidloss 2.81881  last_update 0\n",
      "train: iter 31  trainloss 2.69620  validloss 2.73759±0.00000  bestvalidloss 2.73759  last_update 0\n",
      "train: iter 32  trainloss 2.61452  validloss 2.65213±0.00000  bestvalidloss 2.65213  last_update 0\n",
      "train: iter 33  trainloss 2.53708  validloss 2.57662±0.00000  bestvalidloss 2.57662  last_update 0\n",
      "train: iter 34  trainloss 2.46055  validloss 2.49415±0.00000  bestvalidloss 2.49415  last_update 0\n",
      "train: iter 35  trainloss 2.38449  validloss 2.42218±0.00000  bestvalidloss 2.42218  last_update 0\n",
      "train: iter 36  trainloss 2.31719  validloss 2.35996±0.00000  bestvalidloss 2.35996  last_update 0\n",
      "train: iter 37  trainloss 2.24796  validloss 2.28724±0.00000  bestvalidloss 2.28724  last_update 0\n",
      "train: iter 38  trainloss 2.18636  validloss 2.21486±0.00000  bestvalidloss 2.21486  last_update 0\n",
      "train: iter 39  trainloss 2.12114  validloss 2.14969±0.00000  bestvalidloss 2.14969  last_update 0\n",
      "train: iter 40  trainloss 2.05160  validloss 2.09314±0.00000  bestvalidloss 2.09314  last_update 0\n",
      "train: iter 41  trainloss 1.99448  validloss 2.02505±0.00000  bestvalidloss 2.02505  last_update 0\n",
      "train: iter 42  trainloss 1.93281  validloss 1.96033±0.00000  bestvalidloss 1.96033  last_update 0\n",
      "train: iter 43  trainloss 1.86645  validloss 1.89995±0.00000  bestvalidloss 1.89995  last_update 0\n",
      "train: iter 44  trainloss 1.80581  validloss 1.84762±0.00000  bestvalidloss 1.84762  last_update 0\n",
      "train: iter 45  trainloss 1.74516  validloss 1.77405±0.00000  bestvalidloss 1.77405  last_update 0\n",
      "train: iter 46  trainloss 1.68275  validloss 1.72717±0.00000  bestvalidloss 1.72717  last_update 0\n",
      "train: iter 47  trainloss 1.62283  validloss 1.64760±0.00000  bestvalidloss 1.64760  last_update 0\n",
      "train: iter 48  trainloss 1.56035  validloss 1.59298±0.00000  bestvalidloss 1.59298  last_update 0\n",
      "train: iter 49  trainloss 1.49681  validloss 1.52551±0.00000  bestvalidloss 1.52551  last_update 0\n",
      "train: iter 50  trainloss 1.43678  validloss 1.47657±0.00000  bestvalidloss 1.47657  last_update 0\n",
      "train: iter 51  trainloss 1.37908  validloss 1.40078±0.00000  bestvalidloss 1.40078  last_update 0\n",
      "train: iter 52  trainloss 1.31266  validloss 1.33124±0.00000  bestvalidloss 1.33124  last_update 0\n",
      "train: iter 53  trainloss 1.24033  validloss 1.27927±0.00000  bestvalidloss 1.27927  last_update 0\n",
      "train: iter 54  trainloss 1.18257  validloss 1.22008±0.00000  bestvalidloss 1.22008  last_update 0\n",
      "train: iter 55  trainloss 1.11150  validloss 1.17152±0.00000  bestvalidloss 1.17152  last_update 0\n",
      "train: iter 56  trainloss 1.06418  validloss 1.09507±0.00000  bestvalidloss 1.09507  last_update 0\n",
      "train: iter 57  trainloss 0.99058  validloss 1.03341±0.00000  bestvalidloss 1.03341  last_update 0\n",
      "train: iter 58  trainloss 0.92464  validloss 0.98409±0.00000  bestvalidloss 0.98409  last_update 0\n",
      "train: iter 59  trainloss 0.85406  validloss 0.90740±0.00000  bestvalidloss 0.90740  last_update 0\n",
      "train: iter 60  trainloss 0.80740  validloss 0.85722±0.00000  bestvalidloss 0.85722  last_update 0\n",
      "train: iter 61  trainloss 0.72033  validloss 0.75818±0.00000  bestvalidloss 0.75818  last_update 0\n",
      "train: iter 62  trainloss 0.65620  validloss 0.67687±0.00000  bestvalidloss 0.67687  last_update 0\n",
      "train: iter 63  trainloss 0.60016  validloss 0.62907±0.00000  bestvalidloss 0.62907  last_update 0\n",
      "train: iter 64  trainloss 0.51537  validloss 0.56039±0.00000  bestvalidloss 0.56039  last_update 0\n",
      "train: iter 65  trainloss 0.47279  validloss 0.50524±0.00000  bestvalidloss 0.50524  last_update 0\n",
      "train: iter 66  trainloss 0.39027  validloss 0.43912±0.00000  bestvalidloss 0.43912  last_update 0\n",
      "train: iter 67  trainloss 0.33522  validloss 0.41570±0.00000  bestvalidloss 0.41570  last_update 0\n",
      "train: iter 68  trainloss 0.28833  validloss 0.27509±0.00000  bestvalidloss 0.27509  last_update 0\n",
      "train: iter 69  trainloss 0.21319  validloss 0.25606±0.00000  bestvalidloss 0.25606  last_update 0\n",
      "train: iter 70  trainloss 0.18861  validloss 0.13441±0.00000  bestvalidloss 0.13441  last_update 0\n",
      "train: iter 71  trainloss 0.10009  validloss 0.22424±0.00000  bestvalidloss 0.13441  last_update 1\n",
      "train: iter 72  trainloss 0.05997  validloss 0.06741±0.00000  bestvalidloss 0.06741  last_update 0\n",
      "train: iter 73  trainloss -0.00144  validloss 0.07342±0.00000  bestvalidloss 0.06741  last_update 1\n",
      "train: iter 74  trainloss -0.05176  validloss 0.02994±0.00000  bestvalidloss 0.02994  last_update 0\n",
      "train: iter 75  trainloss -0.08170  validloss -0.03259±0.00000  bestvalidloss -0.03259  last_update 0\n",
      "train: iter 76  trainloss -0.13887  validloss -0.06471±0.00000  bestvalidloss -0.06471  last_update 0\n",
      "train: iter 77  trainloss -0.19232  validloss -0.08577±0.00000  bestvalidloss -0.08577  last_update 0\n",
      "train: iter 78  trainloss -0.23303  validloss -0.17478±0.00000  bestvalidloss -0.17478  last_update 0\n",
      "train: iter 79  trainloss -0.29900  validloss -0.22135±0.00000  bestvalidloss -0.22135  last_update 0\n",
      "train: iter 80  trainloss -0.30071  validloss -0.28221±0.00000  bestvalidloss -0.28221  last_update 0\n",
      "train: iter 81  trainloss -0.33828  validloss -0.27374±0.00000  bestvalidloss -0.28221  last_update 1\n",
      "train: iter 82  trainloss -0.38617  validloss -0.44165±0.00000  bestvalidloss -0.44165  last_update 0\n",
      "train: iter 83  trainloss -0.47640  validloss -0.40615±0.00000  bestvalidloss -0.44165  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss -0.50654  validloss -0.41439±0.00000  bestvalidloss -0.44165  last_update 2\n",
      "train: iter 85  trainloss -0.51581  validloss -0.44145±0.00000  bestvalidloss -0.44165  last_update 3\n",
      "train: iter 86  trainloss -0.58248  validloss -0.50046±0.00000  bestvalidloss -0.50046  last_update 0\n",
      "train: iter 87  trainloss -0.63191  validloss -0.57823±0.00000  bestvalidloss -0.57823  last_update 0\n",
      "train: iter 88  trainloss -0.68527  validloss -0.61127±0.00000  bestvalidloss -0.61127  last_update 0\n",
      "train: iter 89  trainloss -0.71272  validloss -0.59655±0.00000  bestvalidloss -0.61127  last_update 1\n",
      "train: iter 90  trainloss -0.75142  validloss -0.66610±0.00000  bestvalidloss -0.66610  last_update 0\n",
      "train: iter 91  trainloss -0.82262  validloss -0.69554±0.00000  bestvalidloss -0.69554  last_update 0\n",
      "train: iter 92  trainloss -0.81099  validloss -0.70889±0.00000  bestvalidloss -0.70889  last_update 0\n",
      "train: iter 93  trainloss -0.83801  validloss -0.81650±0.00000  bestvalidloss -0.81650  last_update 0\n",
      "train: iter 94  trainloss -0.90877  validloss -0.78557±0.00000  bestvalidloss -0.81650  last_update 1\n",
      "train: iter 95  trainloss -0.92297  validloss -0.92903±0.00000  bestvalidloss -0.92903  last_update 0\n",
      "train: iter 96  trainloss -0.97133  validloss -0.84010±0.00000  bestvalidloss -0.92903  last_update 1\n",
      "train: iter 97  trainloss -1.00031  validloss -0.88849±0.00000  bestvalidloss -0.92903  last_update 2\n",
      "train: iter 98  trainloss -1.04578  validloss -1.00851±0.00000  bestvalidloss -1.00851  last_update 0\n",
      "train: iter 99  trainloss -1.10487  validloss -0.94311±0.00000  bestvalidloss -1.00851  last_update 1\n",
      "train: iter 100  trainloss -1.12336  validloss -1.07899±0.00000  bestvalidloss -1.07899  last_update 0\n",
      "train: iter 101  trainloss -1.16314  validloss -1.17798±0.00000  bestvalidloss -1.17798  last_update 0\n",
      "train: iter 102  trainloss -1.19500  validloss -1.19596±0.00000  bestvalidloss -1.19596  last_update 0\n",
      "train: iter 103  trainloss -1.26118  validloss -1.20812±0.00000  bestvalidloss -1.20812  last_update 0\n",
      "train: iter 104  trainloss -1.27920  validloss -1.25350±0.00000  bestvalidloss -1.25350  last_update 0\n",
      "train: iter 105  trainloss -1.31390  validloss -1.25134±0.00000  bestvalidloss -1.25350  last_update 1\n",
      "train: iter 106  trainloss -1.33140  validloss -1.34972±0.00000  bestvalidloss -1.34972  last_update 0\n",
      "train: iter 107  trainloss -1.39732  validloss -1.39054±0.00000  bestvalidloss -1.39054  last_update 0\n",
      "train: iter 108  trainloss -1.44953  validloss -1.31407±0.00000  bestvalidloss -1.39054  last_update 1\n",
      "train: iter 109  trainloss -1.47321  validloss -1.40404±0.00000  bestvalidloss -1.40404  last_update 0\n",
      "train: iter 110  trainloss -1.50935  validloss -1.53496±0.00000  bestvalidloss -1.53496  last_update 0\n",
      "train: iter 111  trainloss -1.54672  validloss -1.50895±0.00000  bestvalidloss -1.53496  last_update 1\n",
      "train: iter 112  trainloss -1.61651  validloss -1.56348±0.00000  bestvalidloss -1.56348  last_update 0\n",
      "train: iter 113  trainloss -1.63442  validloss -1.56799±0.00000  bestvalidloss -1.56799  last_update 0\n",
      "train: iter 114  trainloss -1.68907  validloss -1.56106±0.00000  bestvalidloss -1.56799  last_update 1\n",
      "train: iter 115  trainloss -1.69224  validloss -1.57595±0.00000  bestvalidloss -1.57595  last_update 0\n",
      "train: iter 116  trainloss -1.73192  validloss -1.75677±0.00000  bestvalidloss -1.75677  last_update 0\n",
      "train: iter 117  trainloss -1.73916  validloss -1.74888±0.00000  bestvalidloss -1.75677  last_update 1\n",
      "train: iter 118  trainloss -1.74733  validloss -1.76182±0.00000  bestvalidloss -1.76182  last_update 0\n",
      "train: iter 119  trainloss -1.86156  validloss -1.86463±0.00000  bestvalidloss -1.86463  last_update 0\n",
      "train: iter 120  trainloss -1.83168  validloss -1.79423±0.00000  bestvalidloss -1.86463  last_update 1\n",
      "train: iter 121  trainloss -1.86663  validloss -1.80810±0.00000  bestvalidloss -1.86463  last_update 2\n",
      "train: iter 122  trainloss -1.92404  validloss -1.88983±0.00000  bestvalidloss -1.88983  last_update 0\n",
      "train: iter 123  trainloss -1.95332  validloss -1.95466±0.00000  bestvalidloss -1.95466  last_update 0\n",
      "train: iter 124  trainloss -1.99078  validloss -2.07657±0.00000  bestvalidloss -2.07657  last_update 0\n",
      "train: iter 125  trainloss -1.96525  validloss -2.02130±0.00000  bestvalidloss -2.07657  last_update 1\n",
      "train: iter 126  trainloss -2.05307  validloss -2.02377±0.00000  bestvalidloss -2.07657  last_update 2\n",
      "train: iter 127  trainloss -2.01972  validloss -2.10951±0.00000  bestvalidloss -2.10951  last_update 0\n",
      "train: iter 128  trainloss -2.11878  validloss -2.01158±0.00000  bestvalidloss -2.10951  last_update 1\n",
      "train: iter 129  trainloss -2.11129  validloss -2.15055±0.00000  bestvalidloss -2.15055  last_update 0\n",
      "train: iter 130  trainloss -2.13154  validloss -2.13655±0.00000  bestvalidloss -2.15055  last_update 1\n",
      "train: iter 131  trainloss -2.19088  validloss -2.15080±0.00000  bestvalidloss -2.15080  last_update 0\n",
      "train: iter 132  trainloss -2.23587  validloss -2.19159±0.00000  bestvalidloss -2.19159  last_update 0\n",
      "train: iter 133  trainloss -2.14192  validloss -2.15671±0.00000  bestvalidloss -2.19159  last_update 1\n",
      "train: iter 134  trainloss -2.23094  validloss -2.24258±0.00000  bestvalidloss -2.24258  last_update 0\n",
      "train: iter 135  trainloss -2.19396  validloss -2.24360±0.00000  bestvalidloss -2.24360  last_update 0\n",
      "train: iter 136  trainloss -2.23089  validloss -2.37477±0.00000  bestvalidloss -2.37477  last_update 0\n",
      "train: iter 137  trainloss -2.30553  validloss -2.39408±0.00000  bestvalidloss -2.39408  last_update 0\n",
      "train: iter 138  trainloss -2.29736  validloss -2.37348±0.00000  bestvalidloss -2.39408  last_update 1\n",
      "train: iter 139  trainloss -2.32718  validloss -2.30279±0.00000  bestvalidloss -2.39408  last_update 2\n",
      "train: iter 140  trainloss -2.31553  validloss -2.38549±0.00000  bestvalidloss -2.39408  last_update 3\n",
      "train: iter 141  trainloss -2.35937  validloss -2.35854±0.00000  bestvalidloss -2.39408  last_update 4\n",
      "train: iter 142  trainloss -2.30366  validloss -2.40860±0.00000  bestvalidloss -2.40860  last_update 0\n",
      "train: iter 143  trainloss -2.42964  validloss -2.55386±0.00000  bestvalidloss -2.55386  last_update 0\n",
      "train: iter 144  trainloss -2.31984  validloss -2.35913±0.00000  bestvalidloss -2.55386  last_update 1\n",
      "train: iter 145  trainloss -2.39661  validloss -2.48332±0.00000  bestvalidloss -2.55386  last_update 2\n",
      "train: iter 146  trainloss -2.35964  validloss -2.42615±0.00000  bestvalidloss -2.55386  last_update 3\n",
      "train: iter 147  trainloss -2.40585  validloss -2.29549±0.00000  bestvalidloss -2.55386  last_update 4\n",
      "train: iter 148  trainloss -2.40327  validloss -2.40820±0.00000  bestvalidloss -2.55386  last_update 5\n",
      "train: iter 149  trainloss -2.36996  validloss -2.38522±0.00000  bestvalidloss -2.55386  last_update 6\n",
      "train: iter 150  trainloss -2.47212  validloss -2.48862±0.00000  bestvalidloss -2.55386  last_update 7\n",
      "train: iter 151  trainloss -2.40181  validloss -2.48578±0.00000  bestvalidloss -2.55386  last_update 8\n",
      "train: iter 152  trainloss -2.41562  validloss -2.41047±0.00000  bestvalidloss -2.55386  last_update 9\n",
      "train: iter 153  trainloss -2.32999  validloss -2.64310±0.00000  bestvalidloss -2.64310  last_update 0\n",
      "train: iter 154  trainloss -2.46260  validloss -2.62870±0.00000  bestvalidloss -2.64310  last_update 1\n",
      "train: iter 155  trainloss -2.46703  validloss -2.61800±0.00000  bestvalidloss -2.64310  last_update 2\n",
      "train: iter 156  trainloss -2.43099  validloss -2.61060±0.00000  bestvalidloss -2.64310  last_update 3\n",
      "train: iter 157  trainloss -2.34963  validloss -2.56209±0.00000  bestvalidloss -2.64310  last_update 4\n",
      "train: iter 158  trainloss -2.39339  validloss -2.54712±0.00000  bestvalidloss -2.64310  last_update 5\n",
      "train: iter 159  trainloss -2.41646  validloss -2.61053±0.00000  bestvalidloss -2.64310  last_update 6\n",
      "train: iter 160  trainloss -2.41130  validloss -2.41506±0.00000  bestvalidloss -2.64310  last_update 7\n",
      "train: iter 161  trainloss -2.36708  validloss -2.37214±0.00000  bestvalidloss -2.64310  last_update 8\n",
      "train: iter 162  trainloss -2.46209  validloss -2.45724±0.00000  bestvalidloss -2.64310  last_update 9\n",
      "train: iter 163  trainloss -2.43598  validloss -2.60956±0.00000  bestvalidloss -2.64310  last_update 10\n",
      "train: iter 164  trainloss -2.45307  validloss -2.62034±0.00000  bestvalidloss -2.64310  last_update 11\n",
      "train: iter 165  trainloss -2.37912  validloss -2.60116±0.00000  bestvalidloss -2.64310  last_update 12\n",
      "train: iter 166  trainloss -2.33977  validloss -2.48670±0.00000  bestvalidloss -2.64310  last_update 13\n",
      "train: iter 167  trainloss -2.40492  validloss -2.58254±0.00000  bestvalidloss -2.64310  last_update 14\n",
      "train: iter 168  trainloss -2.44554  validloss -2.57226±0.00000  bestvalidloss -2.64310  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 169  trainloss -2.55291  validloss -2.59579±0.00000  bestvalidloss -2.64310  last_update 16\n",
      "train: iter 170  trainloss -2.38132  validloss -2.48341±0.00000  bestvalidloss -2.64310  last_update 17\n",
      "train: iter 171  trainloss -2.38702  validloss -2.44183±0.00000  bestvalidloss -2.64310  last_update 18\n",
      "train: iter 172  trainloss -2.46243  validloss -2.58174±0.00000  bestvalidloss -2.64310  last_update 19\n",
      "train: iter 173  trainloss -2.51119  validloss -2.56543±0.00000  bestvalidloss -2.64310  last_update 20\n",
      "train: iter 174  trainloss -2.45571  validloss -2.61042±0.00000  bestvalidloss -2.64310  last_update 21\n",
      "train: iter 175  trainloss -2.37173  validloss -2.48575±0.00000  bestvalidloss -2.64310  last_update 22\n",
      "train: iter 176  trainloss -2.46115  validloss -2.44987±0.00000  bestvalidloss -2.64310  last_update 23\n",
      "train: iter 177  trainloss -2.32503  validloss -2.56827±0.00000  bestvalidloss -2.64310  last_update 24\n",
      "train: iter 178  trainloss -2.36461  validloss -2.51339±0.00000  bestvalidloss -2.64310  last_update 25\n",
      "train: iter 179  trainloss -2.42170  validloss -2.45018±0.00000  bestvalidloss -2.64310  last_update 26\n",
      "train: iter 180  trainloss -2.40134  validloss -2.56037±0.00000  bestvalidloss -2.64310  last_update 27\n",
      "train: iter 181  trainloss -2.48031  validloss -2.57189±0.00000  bestvalidloss -2.64310  last_update 28\n",
      "train: iter 182  trainloss -2.39722  validloss -2.56078±0.00000  bestvalidloss -2.64310  last_update 29\n",
      "train: iter 183  trainloss -2.46324  validloss -2.70779±0.00000  bestvalidloss -2.70779  last_update 0\n",
      "train: iter 184  trainloss -2.48703  validloss -2.61424±0.00000  bestvalidloss -2.70779  last_update 1\n",
      "train: iter 185  trainloss -2.42549  validloss -2.62001±0.00000  bestvalidloss -2.70779  last_update 2\n",
      "train: iter 186  trainloss -2.38760  validloss -2.50313±0.00000  bestvalidloss -2.70779  last_update 3\n",
      "train: iter 187  trainloss -2.50487  validloss -2.53961±0.00000  bestvalidloss -2.70779  last_update 4\n",
      "train: iter 188  trainloss -2.42028  validloss -2.55284±0.00000  bestvalidloss -2.70779  last_update 5\n",
      "train: iter 189  trainloss -2.37522  validloss -2.46504±0.00000  bestvalidloss -2.70779  last_update 6\n",
      "train: iter 190  trainloss -2.38736  validloss -2.48380±0.00000  bestvalidloss -2.70779  last_update 7\n",
      "train: iter 191  trainloss -2.42155  validloss -2.59738±0.00000  bestvalidloss -2.70779  last_update 8\n",
      "train: iter 192  trainloss -2.41938  validloss -2.52783±0.00000  bestvalidloss -2.70779  last_update 9\n",
      "train: iter 193  trainloss -2.50959  validloss -2.54908±0.00000  bestvalidloss -2.70779  last_update 10\n",
      "train: iter 194  trainloss -2.39366  validloss -2.53338±0.00000  bestvalidloss -2.70779  last_update 11\n",
      "train: iter 195  trainloss -2.46664  validloss -2.56163±0.00000  bestvalidloss -2.70779  last_update 12\n",
      "train: iter 196  trainloss -2.42052  validloss -2.41835±0.00000  bestvalidloss -2.70779  last_update 13\n",
      "train: iter 197  trainloss -2.49516  validloss -2.54325±0.00000  bestvalidloss -2.70779  last_update 14\n",
      "train: iter 198  trainloss -2.38991  validloss -2.50864±0.00000  bestvalidloss -2.70779  last_update 15\n",
      "train: iter 199  trainloss -2.49859  validloss -2.41545±0.00000  bestvalidloss -2.70779  last_update 16\n",
      "train: iter 200  trainloss -2.42957  validloss -2.69456±0.00000  bestvalidloss -2.70779  last_update 17\n",
      "train: iter 201  trainloss -2.52939  validloss -2.64631±0.00000  bestvalidloss -2.70779  last_update 18\n",
      "train: iter 202  trainloss -2.43411  validloss -2.44915±0.00000  bestvalidloss -2.70779  last_update 19\n",
      "train: iter 203  trainloss -2.46381  validloss -2.35137±0.00000  bestvalidloss -2.70779  last_update 20\n",
      "train: iter 204  trainloss -2.40952  validloss -2.62358±0.00000  bestvalidloss -2.70779  last_update 21\n",
      "train: iter 205  trainloss -2.46575  validloss -2.63647±0.00000  bestvalidloss -2.70779  last_update 22\n",
      "train: iter 206  trainloss -2.41360  validloss -2.59417±0.00000  bestvalidloss -2.70779  last_update 23\n",
      "train: iter 207  trainloss -2.43457  validloss -2.43434±0.00000  bestvalidloss -2.70779  last_update 24\n",
      "train: iter 208  trainloss -2.41589  validloss -2.80628±0.00000  bestvalidloss -2.80628  last_update 0\n",
      "train: iter 209  trainloss -2.45432  validloss -2.58346±0.00000  bestvalidloss -2.80628  last_update 1\n",
      "train: iter 210  trainloss -2.44926  validloss -2.60172±0.00000  bestvalidloss -2.80628  last_update 2\n",
      "train: iter 211  trainloss -2.46874  validloss -2.63396±0.00000  bestvalidloss -2.80628  last_update 3\n",
      "train: iter 212  trainloss -2.34622  validloss -2.70132±0.00000  bestvalidloss -2.80628  last_update 4\n",
      "train: iter 213  trainloss -2.42812  validloss -2.56561±0.00000  bestvalidloss -2.80628  last_update 5\n",
      "train: iter 214  trainloss -2.46273  validloss -2.63077±0.00000  bestvalidloss -2.80628  last_update 6\n",
      "train: iter 215  trainloss -2.47716  validloss -2.64322±0.00000  bestvalidloss -2.80628  last_update 7\n",
      "train: iter 216  trainloss -2.48516  validloss -2.60199±0.00000  bestvalidloss -2.80628  last_update 8\n",
      "train: iter 217  trainloss -2.47063  validloss -2.56867±0.00000  bestvalidloss -2.80628  last_update 9\n",
      "train: iter 218  trainloss -2.40421  validloss -2.52714±0.00000  bestvalidloss -2.80628  last_update 10\n",
      "train: iter 219  trainloss -2.40295  validloss -2.31350±0.00000  bestvalidloss -2.80628  last_update 11\n",
      "train: iter 220  trainloss -2.44655  validloss -2.54149±0.00000  bestvalidloss -2.80628  last_update 12\n",
      "train: iter 221  trainloss -2.46543  validloss -2.62796±0.00000  bestvalidloss -2.80628  last_update 13\n",
      "train: iter 222  trainloss -2.38650  validloss -2.43483±0.00000  bestvalidloss -2.80628  last_update 14\n",
      "train: iter 223  trainloss -2.41944  validloss -2.38792±0.00000  bestvalidloss -2.80628  last_update 15\n",
      "train: iter 224  trainloss -2.43063  validloss -2.70358±0.00000  bestvalidloss -2.80628  last_update 16\n",
      "train: iter 225  trainloss -2.36837  validloss -2.50894±0.00000  bestvalidloss -2.80628  last_update 17\n",
      "train: iter 226  trainloss -2.47527  validloss -2.55623±0.00000  bestvalidloss -2.80628  last_update 18\n",
      "train: iter 227  trainloss -2.34621  validloss -2.61193±0.00000  bestvalidloss -2.80628  last_update 19\n",
      "train: iter 228  trainloss -2.39901  validloss -2.66062±0.00000  bestvalidloss -2.80628  last_update 20\n",
      "train: iter 229  trainloss -2.45134  validloss -2.57920±0.00000  bestvalidloss -2.80628  last_update 21\n",
      "train: iter 230  trainloss -2.42438  validloss -2.67528±0.00000  bestvalidloss -2.80628  last_update 22\n",
      "train: iter 231  trainloss -2.44213  validloss -2.66075±0.00000  bestvalidloss -2.80628  last_update 23\n",
      "train: iter 232  trainloss -2.47641  validloss -2.66693±0.00000  bestvalidloss -2.80628  last_update 24\n",
      "train: iter 233  trainloss -2.49301  validloss -2.59762±0.00000  bestvalidloss -2.80628  last_update 25\n",
      "train: iter 234  trainloss -2.38505  validloss -2.62551±0.00000  bestvalidloss -2.80628  last_update 26\n",
      "train: iter 235  trainloss -2.45105  validloss -2.47904±0.00000  bestvalidloss -2.80628  last_update 27\n",
      "train: iter 236  trainloss -2.58453  validloss -2.38673±0.00000  bestvalidloss -2.80628  last_update 28\n",
      "train: iter 237  trainloss -2.48989  validloss -2.42560±0.00000  bestvalidloss -2.80628  last_update 29\n",
      "train: iter 238  trainloss -2.50933  validloss -2.56288±0.00000  bestvalidloss -2.80628  last_update 30\n",
      "train: iter 239  trainloss -2.53398  validloss -2.43448±0.00000  bestvalidloss -2.80628  last_update 31\n",
      "train: iter 240  trainloss -2.46717  validloss -2.57676±0.00000  bestvalidloss -2.80628  last_update 32\n",
      "train: iter 241  trainloss -2.46111  validloss -2.56724±0.00000  bestvalidloss -2.80628  last_update 33\n",
      "train: iter 242  trainloss -2.37948  validloss -2.67775±0.00000  bestvalidloss -2.80628  last_update 34\n",
      "train: iter 243  trainloss -2.41357  validloss -2.56918±0.00000  bestvalidloss -2.80628  last_update 35\n",
      "train: iter 244  trainloss -2.41940  validloss -2.41319±0.00000  bestvalidloss -2.80628  last_update 36\n",
      "train: iter 245  trainloss -2.41405  validloss -2.63464±0.00000  bestvalidloss -2.80628  last_update 37\n",
      "train: iter 246  trainloss -2.38367  validloss -2.55249±0.00000  bestvalidloss -2.80628  last_update 38\n",
      "train: iter 247  trainloss -2.41339  validloss -2.64462±0.00000  bestvalidloss -2.80628  last_update 39\n",
      "train: iter 248  trainloss -2.37882  validloss -2.48526±0.00000  bestvalidloss -2.80628  last_update 40\n",
      "train: iter 249  trainloss -2.46934  validloss -2.56273±0.00000  bestvalidloss -2.80628  last_update 41\n",
      "train: iter 250  trainloss -2.32634  validloss -2.56233±0.00000  bestvalidloss -2.80628  last_update 42\n",
      "train: iter 251  trainloss -2.43892  validloss -2.55679±0.00000  bestvalidloss -2.80628  last_update 43\n",
      "train: iter 252  trainloss -2.44176  validloss -2.59627±0.00000  bestvalidloss -2.80628  last_update 44\n",
      "train: iter 253  trainloss -2.45231  validloss -2.53717±0.00000  bestvalidloss -2.80628  last_update 45\n",
      "train: iter 254  trainloss -2.46008  validloss -2.55105±0.00000  bestvalidloss -2.80628  last_update 46\n",
      "train: iter 255  trainloss -2.50231  validloss -2.56556±0.00000  bestvalidloss -2.80628  last_update 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 256  trainloss -2.48015  validloss -2.64859±0.00000  bestvalidloss -2.80628  last_update 48\n",
      "train: iter 257  trainloss -2.49608  validloss -2.59843±0.00000  bestvalidloss -2.80628  last_update 49\n",
      "train: iter 258  trainloss -2.44200  validloss -2.64005±0.00000  bestvalidloss -2.80628  last_update 50\n",
      "train: iter 259  trainloss -2.43024  validloss -2.47276±0.00000  bestvalidloss -2.80628  last_update 51\n",
      "train: iter 260  trainloss -2.56155  validloss -2.58301±0.00000  bestvalidloss -2.80628  last_update 52\n",
      "train: iter 261  trainloss -2.50564  validloss -2.76206±0.00000  bestvalidloss -2.80628  last_update 53\n",
      "train: iter 262  trainloss -2.46774  validloss -2.62837±0.00000  bestvalidloss -2.80628  last_update 54\n",
      "train: iter 263  trainloss -2.34740  validloss -2.52131±0.00000  bestvalidloss -2.80628  last_update 55\n",
      "train: iter 264  trainloss -2.42126  validloss -2.47820±0.00000  bestvalidloss -2.80628  last_update 56\n",
      "train: iter 265  trainloss -2.45821  validloss -2.47169±0.00000  bestvalidloss -2.80628  last_update 57\n",
      "train: iter 266  trainloss -2.53453  validloss -2.57329±0.00000  bestvalidloss -2.80628  last_update 58\n",
      "train: iter 267  trainloss -2.48962  validloss -2.58238±0.00000  bestvalidloss -2.80628  last_update 59\n",
      "train: iter 268  trainloss -2.45866  validloss -2.55500±0.00000  bestvalidloss -2.80628  last_update 60\n",
      "train: iter 269  trainloss -2.43464  validloss -2.54722±0.00000  bestvalidloss -2.80628  last_update 61\n",
      "train: iter 270  trainloss -2.37091  validloss -2.56644±0.00000  bestvalidloss -2.80628  last_update 62\n",
      "train: iter 271  trainloss -2.47438  validloss -2.52920±0.00000  bestvalidloss -2.80628  last_update 63\n",
      "train: iter 272  trainloss -2.43640  validloss -2.59262±0.00000  bestvalidloss -2.80628  last_update 64\n",
      "train: iter 273  trainloss -2.44287  validloss -2.58541±0.00000  bestvalidloss -2.80628  last_update 65\n",
      "train: iter 274  trainloss -2.53683  validloss -2.68294±0.00000  bestvalidloss -2.80628  last_update 66\n",
      "train: iter 275  trainloss -2.44812  validloss -2.62007±0.00000  bestvalidloss -2.80628  last_update 67\n",
      "train: iter 276  trainloss -2.48588  validloss -2.48805±0.00000  bestvalidloss -2.80628  last_update 68\n",
      "train: iter 277  trainloss -2.44896  validloss -2.61203±0.00000  bestvalidloss -2.80628  last_update 69\n",
      "train: iter 278  trainloss -2.52327  validloss -2.45885±0.00000  bestvalidloss -2.80628  last_update 70\n",
      "train: iter 279  trainloss -2.46283  validloss -2.50826±0.00000  bestvalidloss -2.80628  last_update 71\n",
      "train: iter 280  trainloss -2.37607  validloss -2.64101±0.00000  bestvalidloss -2.80628  last_update 72\n",
      "train: iter 281  trainloss -2.45779  validloss -2.54314±0.00000  bestvalidloss -2.80628  last_update 73\n",
      "train: iter 282  trainloss -2.39867  validloss -2.54709±0.00000  bestvalidloss -2.80628  last_update 74\n",
      "train: iter 283  trainloss -2.45608  validloss -2.65483±0.00000  bestvalidloss -2.80628  last_update 75\n",
      "train: iter 284  trainloss -2.43739  validloss -2.61789±0.00000  bestvalidloss -2.80628  last_update 76\n",
      "train: iter 285  trainloss -2.48087  validloss -2.68261±0.00000  bestvalidloss -2.80628  last_update 77\n",
      "train: iter 286  trainloss -2.45108  validloss -2.62183±0.00000  bestvalidloss -2.80628  last_update 78\n",
      "train: iter 287  trainloss -2.43890  validloss -2.60549±0.00000  bestvalidloss -2.80628  last_update 79\n",
      "train: iter 288  trainloss -2.43891  validloss -2.50321±0.00000  bestvalidloss -2.80628  last_update 80\n",
      "train: iter 289  trainloss -2.30389  validloss -2.58867±0.00000  bestvalidloss -2.80628  last_update 81\n",
      "train: iter 290  trainloss -2.43578  validloss -2.53360±0.00000  bestvalidloss -2.80628  last_update 82\n",
      "train: iter 291  trainloss -2.46354  validloss -2.63173±0.00000  bestvalidloss -2.80628  last_update 83\n",
      "train: iter 292  trainloss -2.38988  validloss -2.64917±0.00000  bestvalidloss -2.80628  last_update 84\n",
      "train: iter 293  trainloss -2.45712  validloss -2.49327±0.00000  bestvalidloss -2.80628  last_update 85\n",
      "train: iter 294  trainloss -2.51211  validloss -2.57357±0.00000  bestvalidloss -2.80628  last_update 86\n",
      "train: iter 295  trainloss -2.40179  validloss -2.38903±0.00000  bestvalidloss -2.80628  last_update 87\n",
      "train: iter 296  trainloss -2.45786  validloss -2.65514±0.00000  bestvalidloss -2.80628  last_update 88\n",
      "train: iter 297  trainloss -2.43869  validloss -2.64802±0.00000  bestvalidloss -2.80628  last_update 89\n",
      "train: iter 298  trainloss -2.35932  validloss -2.49744±0.00000  bestvalidloss -2.80628  last_update 90\n",
      "train: iter 299  trainloss -2.45267  validloss -2.51438±0.00000  bestvalidloss -2.80628  last_update 91\n",
      "train: iter 300  trainloss -2.44147  validloss -2.38187±0.00000  bestvalidloss -2.80628  last_update 92\n",
      "train: iter 301  trainloss -2.41611  validloss -2.44979±0.00000  bestvalidloss -2.80628  last_update 93\n",
      "train: iter 302  trainloss -2.45807  validloss -2.50866±0.00000  bestvalidloss -2.80628  last_update 94\n",
      "train: iter 303  trainloss -2.48320  validloss -2.57010±0.00000  bestvalidloss -2.80628  last_update 95\n",
      "train: iter 304  trainloss -2.45348  validloss -2.56720±0.00000  bestvalidloss -2.80628  last_update 96\n",
      "train: iter 305  trainloss -2.29132  validloss -2.56115±0.00000  bestvalidloss -2.80628  last_update 97\n",
      "train: iter 306  trainloss -2.50451  validloss -2.62664±0.00000  bestvalidloss -2.80628  last_update 98\n",
      "train: iter 307  trainloss -2.40127  validloss -2.60736±0.00000  bestvalidloss -2.80628  last_update 99\n",
      "train: iter 308  trainloss -2.39875  validloss -2.45637±0.00000  bestvalidloss -2.80628  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.9457, -3.6640, -4.2309, -6.2975], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 68.06580  validloss 67.36280±0.00000  bestvalidloss 67.36280  last_update 0\n",
      "train: iter 1  trainloss 49.16519  validloss 51.77969±0.00000  bestvalidloss 51.77969  last_update 0\n",
      "train: iter 2  trainloss 34.38987  validloss 35.31631±0.00000  bestvalidloss 35.31631  last_update 0\n",
      "train: iter 3  trainloss 26.02648  validloss 25.85530±0.00000  bestvalidloss 25.85530  last_update 0\n",
      "train: iter 4  trainloss 20.65360  validloss 20.43178±0.00000  bestvalidloss 20.43178  last_update 0\n",
      "train: iter 5  trainloss 16.93972  validloss 16.78669±0.00000  bestvalidloss 16.78669  last_update 0\n",
      "train: iter 6  trainloss 14.09970  validloss 14.43346±0.00000  bestvalidloss 14.43346  last_update 0\n",
      "train: iter 7  trainloss 12.09520  validloss 12.89241±0.00000  bestvalidloss 12.89241  last_update 0\n",
      "train: iter 8  trainloss 10.56228  validloss 11.43997±0.00000  bestvalidloss 11.43997  last_update 0\n",
      "train: iter 9  trainloss 9.30385  validloss 10.83094±0.00000  bestvalidloss 10.83094  last_update 0\n",
      "train: iter 10  trainloss 8.26621  validloss 10.06426±0.00000  bestvalidloss 10.06426  last_update 0\n",
      "train: iter 11  trainloss 7.41483  validloss 9.40716±0.00000  bestvalidloss 9.40716  last_update 0\n",
      "train: iter 12  trainloss 6.77102  validloss 9.36431±0.00000  bestvalidloss 9.36431  last_update 0\n",
      "train: iter 13  trainloss 6.24588  validloss 8.91686±0.00000  bestvalidloss 8.91686  last_update 0\n",
      "train: iter 14  trainloss 5.83033  validloss 8.74378±0.00000  bestvalidloss 8.74378  last_update 0\n",
      "train: iter 15  trainloss 5.50207  validloss 8.51884±0.00000  bestvalidloss 8.51884  last_update 0\n",
      "train: iter 16  trainloss 5.25124  validloss 8.57561±0.00000  bestvalidloss 8.51884  last_update 1\n",
      "train: iter 17  trainloss 4.92935  validloss 8.26517±0.00000  bestvalidloss 8.26517  last_update 0\n",
      "train: iter 18  trainloss 4.73329  validloss 8.01020±0.00000  bestvalidloss 8.01020  last_update 0\n",
      "train: iter 19  trainloss 4.57906  validloss 8.15275±0.00000  bestvalidloss 8.01020  last_update 1\n",
      "train: iter 20  trainloss 4.43070  validloss 8.08756±0.00000  bestvalidloss 8.01020  last_update 2\n",
      "train: iter 21  trainloss 4.34004  validloss 8.27002±0.00000  bestvalidloss 8.01020  last_update 3\n",
      "train: iter 22  trainloss 4.25816  validloss 7.96311±0.00000  bestvalidloss 7.96311  last_update 0\n",
      "train: iter 23  trainloss 4.16532  validloss 7.78588±0.00000  bestvalidloss 7.78588  last_update 0\n",
      "train: iter 24  trainloss 4.12311  validloss 7.73057±0.00000  bestvalidloss 7.73057  last_update 0\n",
      "train: iter 25  trainloss 4.09390  validloss 7.86703±0.00000  bestvalidloss 7.73057  last_update 1\n",
      "train: iter 26  trainloss 4.06291  validloss 7.71656±0.00000  bestvalidloss 7.71656  last_update 0\n",
      "train: iter 27  trainloss 4.02005  validloss 7.65611±0.00000  bestvalidloss 7.65611  last_update 0\n",
      "train: iter 28  trainloss 3.96994  validloss 7.62769±0.00000  bestvalidloss 7.62769  last_update 0\n",
      "train: iter 29  trainloss 3.93964  validloss 7.54364±0.00000  bestvalidloss 7.54364  last_update 0\n",
      "train: iter 30  trainloss 3.91967  validloss 7.45299±0.00000  bestvalidloss 7.45299  last_update 0\n",
      "train: iter 31  trainloss 3.93360  validloss 7.25874±0.00000  bestvalidloss 7.25874  last_update 0\n",
      "train: iter 32  trainloss 3.89592  validloss 7.33502±0.00000  bestvalidloss 7.25874  last_update 1\n",
      "train: iter 33  trainloss 3.90643  validloss 7.29997±0.00000  bestvalidloss 7.25874  last_update 2\n",
      "train: iter 34  trainloss 3.82693  validloss 7.05541±0.00000  bestvalidloss 7.05541  last_update 0\n",
      "train: iter 35  trainloss 3.82624  validloss 7.10402±0.00000  bestvalidloss 7.05541  last_update 1\n",
      "train: iter 36  trainloss 3.78158  validloss 7.22512±0.00000  bestvalidloss 7.05541  last_update 2\n",
      "train: iter 37  trainloss 3.80081  validloss 7.27325±0.00000  bestvalidloss 7.05541  last_update 3\n",
      "train: iter 38  trainloss 3.78805  validloss 6.83246±0.00000  bestvalidloss 6.83246  last_update 0\n",
      "train: iter 39  trainloss 3.75183  validloss 6.95530±0.00000  bestvalidloss 6.83246  last_update 1\n",
      "train: iter 40  trainloss 3.76767  validloss 7.26482±0.00000  bestvalidloss 6.83246  last_update 2\n",
      "train: iter 41  trainloss 3.73118  validloss 7.03262±0.00000  bestvalidloss 6.83246  last_update 3\n",
      "train: iter 42  trainloss 3.75995  validloss 6.98886±0.00000  bestvalidloss 6.83246  last_update 4\n",
      "train: iter 43  trainloss 3.73705  validloss 6.78901±0.00000  bestvalidloss 6.78901  last_update 0\n",
      "train: iter 44  trainloss 3.71841  validloss 7.03063±0.00000  bestvalidloss 6.78901  last_update 1\n",
      "train: iter 45  trainloss 3.72277  validloss 6.94561±0.00000  bestvalidloss 6.78901  last_update 2\n",
      "train: iter 46  trainloss 3.71975  validloss 6.73089±0.00000  bestvalidloss 6.73089  last_update 0\n",
      "train: iter 47  trainloss 3.75367  validloss 6.50658±0.00000  bestvalidloss 6.50658  last_update 0\n",
      "train: iter 48  trainloss 3.68288  validloss 6.74487±0.00000  bestvalidloss 6.50658  last_update 1\n",
      "train: iter 49  trainloss 3.70238  validloss 6.77617±0.00000  bestvalidloss 6.50658  last_update 2\n",
      "train: iter 50  trainloss 3.69254  validloss 6.58876±0.00000  bestvalidloss 6.50658  last_update 3\n",
      "train: iter 51  trainloss 3.68672  validloss 6.54088±0.00000  bestvalidloss 6.50658  last_update 4\n",
      "train: iter 52  trainloss 3.69039  validloss 6.62351±0.00000  bestvalidloss 6.50658  last_update 5\n",
      "train: iter 53  trainloss 3.66496  validloss 6.61471±0.00000  bestvalidloss 6.50658  last_update 6\n",
      "train: iter 54  trainloss 3.63542  validloss 6.47542±0.00000  bestvalidloss 6.47542  last_update 0\n",
      "train: iter 55  trainloss 3.66161  validloss 6.78907±0.00000  bestvalidloss 6.47542  last_update 1\n",
      "train: iter 56  trainloss 3.65670  validloss 6.51869±0.00000  bestvalidloss 6.47542  last_update 2\n",
      "train: iter 57  trainloss 3.65401  validloss 6.63039±0.00000  bestvalidloss 6.47542  last_update 3\n",
      "train: iter 58  trainloss 3.64724  validloss 6.67782±0.00000  bestvalidloss 6.47542  last_update 4\n",
      "train: iter 59  trainloss 3.58240  validloss 6.55462±0.00000  bestvalidloss 6.47542  last_update 5\n",
      "train: iter 60  trainloss 3.65662  validloss 7.00305±0.00000  bestvalidloss 6.47542  last_update 6\n",
      "train: iter 61  trainloss 3.61606  validloss 6.84393±0.00000  bestvalidloss 6.47542  last_update 7\n",
      "train: iter 62  trainloss 3.61268  validloss 6.74933±0.00000  bestvalidloss 6.47542  last_update 8\n",
      "train: iter 63  trainloss 3.65027  validloss 6.74395±0.00000  bestvalidloss 6.47542  last_update 9\n",
      "train: iter 64  trainloss 3.57163  validloss 6.59390±0.00000  bestvalidloss 6.47542  last_update 10\n",
      "train: iter 65  trainloss 3.57997  validloss 6.66461±0.00000  bestvalidloss 6.47542  last_update 11\n",
      "train: iter 66  trainloss 3.59277  validloss 6.42323±0.00000  bestvalidloss 6.42323  last_update 0\n",
      "train: iter 67  trainloss 3.57164  validloss 7.06807±0.00000  bestvalidloss 6.42323  last_update 1\n",
      "train: iter 68  trainloss 3.55153  validloss 6.41121±0.00000  bestvalidloss 6.41121  last_update 0\n",
      "train: iter 69  trainloss 3.57833  validloss 6.78750±0.00000  bestvalidloss 6.41121  last_update 1\n",
      "train: iter 70  trainloss 3.53642  validloss 6.59294±0.00000  bestvalidloss 6.41121  last_update 2\n",
      "train: iter 71  trainloss 3.54612  validloss 6.41866±0.00000  bestvalidloss 6.41121  last_update 3\n",
      "train: iter 72  trainloss 3.53701  validloss 6.50470±0.00000  bestvalidloss 6.41121  last_update 4\n",
      "train: iter 73  trainloss 3.50106  validloss 6.39298±0.00000  bestvalidloss 6.39298  last_update 0\n",
      "train: iter 74  trainloss 3.49860  validloss 6.62021±0.00000  bestvalidloss 6.39298  last_update 1\n",
      "train: iter 75  trainloss 3.47906  validloss 6.44492±0.00000  bestvalidloss 6.39298  last_update 2\n",
      "train: iter 76  trainloss 3.50525  validloss 6.31670±0.00000  bestvalidloss 6.31670  last_update 0\n",
      "train: iter 77  trainloss 3.51102  validloss 6.41666±0.00000  bestvalidloss 6.31670  last_update 1\n",
      "train: iter 78  trainloss 3.50768  validloss 6.41907±0.00000  bestvalidloss 6.31670  last_update 2\n",
      "train: iter 79  trainloss 3.49005  validloss 6.59509±0.00000  bestvalidloss 6.31670  last_update 3\n",
      "train: iter 80  trainloss 3.46892  validloss 6.53062±0.00000  bestvalidloss 6.31670  last_update 4\n",
      "train: iter 81  trainloss 3.44312  validloss 6.24364±0.00000  bestvalidloss 6.24364  last_update 0\n",
      "train: iter 82  trainloss 3.46442  validloss 6.50290±0.00000  bestvalidloss 6.24364  last_update 1\n",
      "train: iter 83  trainloss 3.43994  validloss 6.48939±0.00000  bestvalidloss 6.24364  last_update 2\n",
      "train: iter 84  trainloss 3.42539  validloss 6.57962±0.00000  bestvalidloss 6.24364  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 3.44353  validloss 6.14008±0.00000  bestvalidloss 6.14008  last_update 0\n",
      "train: iter 86  trainloss 3.44640  validloss 6.26797±0.00000  bestvalidloss 6.14008  last_update 1\n",
      "train: iter 87  trainloss 3.43927  validloss 6.45090±0.00000  bestvalidloss 6.14008  last_update 2\n",
      "train: iter 88  trainloss 3.50243  validloss 6.26738±0.00000  bestvalidloss 6.14008  last_update 3\n",
      "train: iter 89  trainloss 3.41625  validloss 6.25725±0.00000  bestvalidloss 6.14008  last_update 4\n",
      "train: iter 90  trainloss 3.41281  validloss 6.07153±0.00000  bestvalidloss 6.07153  last_update 0\n",
      "train: iter 91  trainloss 3.41116  validloss 6.04572±0.00000  bestvalidloss 6.04572  last_update 0\n",
      "train: iter 92  trainloss 3.41268  validloss 6.47409±0.00000  bestvalidloss 6.04572  last_update 1\n",
      "train: iter 93  trainloss 3.41940  validloss 6.42040±0.00000  bestvalidloss 6.04572  last_update 2\n",
      "train: iter 94  trainloss 3.42482  validloss 6.10260±0.00000  bestvalidloss 6.04572  last_update 3\n",
      "train: iter 95  trainloss 3.39974  validloss 6.54191±0.00000  bestvalidloss 6.04572  last_update 4\n",
      "train: iter 96  trainloss 3.41303  validloss 6.34746±0.00000  bestvalidloss 6.04572  last_update 5\n",
      "train: iter 97  trainloss 3.41730  validloss 6.22213±0.00000  bestvalidloss 6.04572  last_update 6\n",
      "train: iter 98  trainloss 3.39386  validloss 6.30097±0.00000  bestvalidloss 6.04572  last_update 7\n",
      "train: iter 99  trainloss 3.39758  validloss 6.44483±0.00000  bestvalidloss 6.04572  last_update 8\n",
      "train: iter 100  trainloss 3.42215  validloss 6.34422±0.00000  bestvalidloss 6.04572  last_update 9\n",
      "train: iter 101  trainloss 3.37215  validloss 6.18645±0.00000  bestvalidloss 6.04572  last_update 10\n",
      "train: iter 102  trainloss 3.39062  validloss 6.02106±0.00000  bestvalidloss 6.02106  last_update 0\n",
      "train: iter 103  trainloss 3.39698  validloss 6.36149±0.00000  bestvalidloss 6.02106  last_update 1\n",
      "train: iter 104  trainloss 3.35537  validloss 6.23989±0.00000  bestvalidloss 6.02106  last_update 2\n",
      "train: iter 105  trainloss 3.40042  validloss 6.24255±0.00000  bestvalidloss 6.02106  last_update 3\n",
      "train: iter 106  trainloss 3.39803  validloss 6.15820±0.00000  bestvalidloss 6.02106  last_update 4\n",
      "train: iter 107  trainloss 3.34881  validloss 6.30214±0.00000  bestvalidloss 6.02106  last_update 5\n",
      "train: iter 108  trainloss 3.39561  validloss 6.13750±0.00000  bestvalidloss 6.02106  last_update 6\n",
      "train: iter 109  trainloss 3.37641  validloss 6.12811±0.00000  bestvalidloss 6.02106  last_update 7\n",
      "train: iter 110  trainloss 3.44236  validloss 6.45376±0.00000  bestvalidloss 6.02106  last_update 8\n",
      "train: iter 111  trainloss 3.34947  validloss 6.41624±0.00000  bestvalidloss 6.02106  last_update 9\n",
      "train: iter 112  trainloss 3.41604  validloss 5.95368±0.00000  bestvalidloss 5.95368  last_update 0\n",
      "train: iter 113  trainloss 3.36255  validloss 6.30818±0.00000  bestvalidloss 5.95368  last_update 1\n",
      "train: iter 114  trainloss 3.38451  validloss 6.36768±0.00000  bestvalidloss 5.95368  last_update 2\n",
      "train: iter 115  trainloss 3.35709  validloss 6.30903±0.00000  bestvalidloss 5.95368  last_update 3\n",
      "train: iter 116  trainloss 3.40011  validloss 6.01454±0.00000  bestvalidloss 5.95368  last_update 4\n",
      "train: iter 117  trainloss 3.32544  validloss 6.26720±0.00000  bestvalidloss 5.95368  last_update 5\n",
      "train: iter 118  trainloss 3.40031  validloss 6.30437±0.00000  bestvalidloss 5.95368  last_update 6\n",
      "train: iter 119  trainloss 3.36268  validloss 6.05535±0.00000  bestvalidloss 5.95368  last_update 7\n",
      "train: iter 120  trainloss 3.36494  validloss 6.30790±0.00000  bestvalidloss 5.95368  last_update 8\n",
      "train: iter 121  trainloss 3.32586  validloss 6.21256±0.00000  bestvalidloss 5.95368  last_update 9\n",
      "train: iter 122  trainloss 3.34559  validloss 6.32187±0.00000  bestvalidloss 5.95368  last_update 10\n",
      "train: iter 123  trainloss 3.33295  validloss 6.28070±0.00000  bestvalidloss 5.95368  last_update 11\n",
      "train: iter 124  trainloss 3.34497  validloss 6.25477±0.00000  bestvalidloss 5.95368  last_update 12\n",
      "train: iter 125  trainloss 3.37462  validloss 6.29247±0.00000  bestvalidloss 5.95368  last_update 13\n",
      "train: iter 126  trainloss 3.34234  validloss 6.32256±0.00000  bestvalidloss 5.95368  last_update 14\n",
      "train: iter 127  trainloss 3.36171  validloss 6.13293±0.00000  bestvalidloss 5.95368  last_update 15\n",
      "train: iter 128  trainloss 3.34247  validloss 6.35614±0.00000  bestvalidloss 5.95368  last_update 16\n",
      "train: iter 129  trainloss 3.32370  validloss 6.16878±0.00000  bestvalidloss 5.95368  last_update 17\n",
      "train: iter 130  trainloss 3.34860  validloss 6.36020±0.00000  bestvalidloss 5.95368  last_update 18\n",
      "train: iter 131  trainloss 3.34190  validloss 6.55001±0.00000  bestvalidloss 5.95368  last_update 19\n",
      "train: iter 132  trainloss 3.33479  validloss 6.38060±0.00000  bestvalidloss 5.95368  last_update 20\n",
      "train: iter 133  trainloss 3.33436  validloss 6.15044±0.00000  bestvalidloss 5.95368  last_update 21\n",
      "train: iter 134  trainloss 3.29887  validloss 6.05089±0.00000  bestvalidloss 5.95368  last_update 22\n",
      "train: iter 135  trainloss 3.36131  validloss 6.37080±0.00000  bestvalidloss 5.95368  last_update 23\n",
      "train: iter 136  trainloss 3.34640  validloss 6.27036±0.00000  bestvalidloss 5.95368  last_update 24\n",
      "train: iter 137  trainloss 3.33878  validloss 6.49122±0.00000  bestvalidloss 5.95368  last_update 25\n",
      "train: iter 138  trainloss 3.32749  validloss 6.13279±0.00000  bestvalidloss 5.95368  last_update 26\n",
      "train: iter 139  trainloss 3.32381  validloss 6.16785±0.00000  bestvalidloss 5.95368  last_update 27\n",
      "train: iter 140  trainloss 3.34792  validloss 6.00762±0.00000  bestvalidloss 5.95368  last_update 28\n",
      "train: iter 141  trainloss 3.30142  validloss 6.14719±0.00000  bestvalidloss 5.95368  last_update 29\n",
      "train: iter 142  trainloss 3.28670  validloss 6.27080±0.00000  bestvalidloss 5.95368  last_update 30\n",
      "train: iter 143  trainloss 3.28972  validloss 6.15425±0.00000  bestvalidloss 5.95368  last_update 31\n",
      "train: iter 144  trainloss 3.29042  validloss 6.20412±0.00000  bestvalidloss 5.95368  last_update 32\n",
      "train: iter 145  trainloss 3.31610  validloss 6.21837±0.00000  bestvalidloss 5.95368  last_update 33\n",
      "train: iter 146  trainloss 3.33428  validloss 6.17731±0.00000  bestvalidloss 5.95368  last_update 34\n",
      "train: iter 147  trainloss 3.32910  validloss 6.05794±0.00000  bestvalidloss 5.95368  last_update 35\n",
      "train: iter 148  trainloss 3.31522  validloss 6.23189±0.00000  bestvalidloss 5.95368  last_update 36\n",
      "train: iter 149  trainloss 3.33128  validloss 6.17687±0.00000  bestvalidloss 5.95368  last_update 37\n",
      "train: iter 150  trainloss 3.35068  validloss 6.16418±0.00000  bestvalidloss 5.95368  last_update 38\n",
      "train: iter 151  trainloss 3.31090  validloss 6.06748±0.00000  bestvalidloss 5.95368  last_update 39\n",
      "train: iter 152  trainloss 3.33295  validloss 6.19023±0.00000  bestvalidloss 5.95368  last_update 40\n",
      "train: iter 153  trainloss 3.27450  validloss 6.44241±0.00000  bestvalidloss 5.95368  last_update 41\n",
      "train: iter 154  trainloss 3.29958  validloss 6.34499±0.00000  bestvalidloss 5.95368  last_update 42\n",
      "train: iter 155  trainloss 3.32369  validloss 6.07549±0.00000  bestvalidloss 5.95368  last_update 43\n",
      "train: iter 156  trainloss 3.31325  validloss 6.14915±0.00000  bestvalidloss 5.95368  last_update 44\n",
      "train: iter 157  trainloss 3.29688  validloss 6.17143±0.00000  bestvalidloss 5.95368  last_update 45\n",
      "train: iter 158  trainloss 3.31359  validloss 6.04526±0.00000  bestvalidloss 5.95368  last_update 46\n",
      "train: iter 159  trainloss 3.28334  validloss 6.16748±0.00000  bestvalidloss 5.95368  last_update 47\n",
      "train: iter 160  trainloss 3.28541  validloss 6.21953±0.00000  bestvalidloss 5.95368  last_update 48\n",
      "train: iter 161  trainloss 3.30206  validloss 6.10121±0.00000  bestvalidloss 5.95368  last_update 49\n",
      "train: iter 162  trainloss 3.32231  validloss 6.24698±0.00000  bestvalidloss 5.95368  last_update 50\n",
      "train: iter 163  trainloss 3.25613  validloss 6.10002±0.00000  bestvalidloss 5.95368  last_update 51\n",
      "train: iter 164  trainloss 3.27112  validloss 6.36191±0.00000  bestvalidloss 5.95368  last_update 52\n",
      "train: iter 165  trainloss 3.27111  validloss 6.38054±0.00000  bestvalidloss 5.95368  last_update 53\n",
      "train: iter 166  trainloss 3.30478  validloss 6.03048±0.00000  bestvalidloss 5.95368  last_update 54\n",
      "train: iter 167  trainloss 3.30496  validloss 6.44796±0.00000  bestvalidloss 5.95368  last_update 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 3.31362  validloss 6.20454±0.00000  bestvalidloss 5.95368  last_update 56\n",
      "train: iter 169  trainloss 3.27434  validloss 6.08960±0.00000  bestvalidloss 5.95368  last_update 57\n",
      "train: iter 170  trainloss 3.29102  validloss 6.29493±0.00000  bestvalidloss 5.95368  last_update 58\n",
      "train: iter 171  trainloss 3.29717  validloss 6.37238±0.00000  bestvalidloss 5.95368  last_update 59\n",
      "train: iter 172  trainloss 3.29090  validloss 6.13805±0.00000  bestvalidloss 5.95368  last_update 60\n",
      "train: iter 173  trainloss 3.31677  validloss 6.41497±0.00000  bestvalidloss 5.95368  last_update 61\n",
      "train: iter 174  trainloss 3.27935  validloss 6.25108±0.00000  bestvalidloss 5.95368  last_update 62\n",
      "train: iter 175  trainloss 3.33704  validloss 6.20564±0.00000  bestvalidloss 5.95368  last_update 63\n",
      "train: iter 176  trainloss 3.28256  validloss 6.02597±0.00000  bestvalidloss 5.95368  last_update 64\n",
      "train: iter 177  trainloss 3.28037  validloss 6.14675±0.00000  bestvalidloss 5.95368  last_update 65\n",
      "train: iter 178  trainloss 3.24750  validloss 6.07060±0.00000  bestvalidloss 5.95368  last_update 66\n",
      "train: iter 179  trainloss 3.29783  validloss 6.13304±0.00000  bestvalidloss 5.95368  last_update 67\n",
      "train: iter 180  trainloss 3.25280  validloss 6.31549±0.00000  bestvalidloss 5.95368  last_update 68\n",
      "train: iter 181  trainloss 3.29332  validloss 5.97831±0.00000  bestvalidloss 5.95368  last_update 69\n",
      "train: iter 182  trainloss 3.29609  validloss 6.06093±0.00000  bestvalidloss 5.95368  last_update 70\n",
      "train: iter 183  trainloss 3.25884  validloss 6.09129±0.00000  bestvalidloss 5.95368  last_update 71\n",
      "train: iter 184  trainloss 3.26810  validloss 6.09749±0.00000  bestvalidloss 5.95368  last_update 72\n",
      "train: iter 185  trainloss 3.31088  validloss 6.22297±0.00000  bestvalidloss 5.95368  last_update 73\n",
      "train: iter 186  trainloss 3.27394  validloss 6.25230±0.00000  bestvalidloss 5.95368  last_update 74\n",
      "train: iter 187  trainloss 3.27650  validloss 6.16065±0.00000  bestvalidloss 5.95368  last_update 75\n",
      "train: iter 188  trainloss 3.29385  validloss 6.14354±0.00000  bestvalidloss 5.95368  last_update 76\n",
      "train: iter 189  trainloss 3.26186  validloss 6.06331±0.00000  bestvalidloss 5.95368  last_update 77\n",
      "train: iter 190  trainloss 3.25319  validloss 6.45642±0.00000  bestvalidloss 5.95368  last_update 78\n",
      "train: iter 191  trainloss 3.29150  validloss 6.21430±0.00000  bestvalidloss 5.95368  last_update 79\n",
      "train: iter 192  trainloss 3.24625  validloss 5.99408±0.00000  bestvalidloss 5.95368  last_update 80\n",
      "train: iter 193  trainloss 3.28844  validloss 6.21251±0.00000  bestvalidloss 5.95368  last_update 81\n",
      "train: iter 194  trainloss 3.26323  validloss 5.93217±0.00000  bestvalidloss 5.93217  last_update 0\n",
      "train: iter 195  trainloss 3.25620  validloss 6.27550±0.00000  bestvalidloss 5.93217  last_update 1\n",
      "train: iter 196  trainloss 3.24797  validloss 6.09939±0.00000  bestvalidloss 5.93217  last_update 2\n",
      "train: iter 197  trainloss 3.23101  validloss 6.15123±0.00000  bestvalidloss 5.93217  last_update 3\n",
      "train: iter 198  trainloss 3.21693  validloss 6.16711±0.00000  bestvalidloss 5.93217  last_update 4\n",
      "train: iter 199  trainloss 3.28385  validloss 6.44171±0.00000  bestvalidloss 5.93217  last_update 5\n",
      "train: iter 200  trainloss 3.25877  validloss 6.23695±0.00000  bestvalidloss 5.93217  last_update 6\n",
      "train: iter 201  trainloss 3.27670  validloss 6.16725±0.00000  bestvalidloss 5.93217  last_update 7\n",
      "train: iter 202  trainloss 3.30661  validloss 6.08122±0.00000  bestvalidloss 5.93217  last_update 8\n",
      "train: iter 203  trainloss 3.24938  validloss 6.31100±0.00000  bestvalidloss 5.93217  last_update 9\n",
      "train: iter 204  trainloss 3.25329  validloss 6.05260±0.00000  bestvalidloss 5.93217  last_update 10\n",
      "train: iter 205  trainloss 3.25377  validloss 5.97613±0.00000  bestvalidloss 5.93217  last_update 11\n",
      "train: iter 206  trainloss 3.21901  validloss 6.07193±0.00000  bestvalidloss 5.93217  last_update 12\n",
      "train: iter 207  trainloss 3.22687  validloss 6.12169±0.00000  bestvalidloss 5.93217  last_update 13\n",
      "train: iter 208  trainloss 3.26080  validloss 6.03338±0.00000  bestvalidloss 5.93217  last_update 14\n",
      "train: iter 209  trainloss 3.24595  validloss 6.07993±0.00000  bestvalidloss 5.93217  last_update 15\n",
      "train: iter 210  trainloss 3.23252  validloss 6.24089±0.00000  bestvalidloss 5.93217  last_update 16\n",
      "train: iter 211  trainloss 3.21596  validloss 6.01041±0.00000  bestvalidloss 5.93217  last_update 17\n",
      "train: iter 212  trainloss 3.28398  validloss 6.09444±0.00000  bestvalidloss 5.93217  last_update 18\n",
      "train: iter 213  trainloss 3.30772  validloss 6.04929±0.00000  bestvalidloss 5.93217  last_update 19\n",
      "train: iter 214  trainloss 3.24594  validloss 6.04137±0.00000  bestvalidloss 5.93217  last_update 20\n",
      "train: iter 215  trainloss 3.22216  validloss 6.23446±0.00000  bestvalidloss 5.93217  last_update 21\n",
      "train: iter 216  trainloss 3.22564  validloss 6.20774±0.00000  bestvalidloss 5.93217  last_update 22\n",
      "train: iter 217  trainloss 3.24442  validloss 6.23898±0.00000  bestvalidloss 5.93217  last_update 23\n",
      "train: iter 218  trainloss 3.26301  validloss 5.98316±0.00000  bestvalidloss 5.93217  last_update 24\n",
      "train: iter 219  trainloss 3.23233  validloss 6.23472±0.00000  bestvalidloss 5.93217  last_update 25\n",
      "train: iter 220  trainloss 3.21663  validloss 6.00210±0.00000  bestvalidloss 5.93217  last_update 26\n",
      "train: iter 221  trainloss 3.25560  validloss 6.26429±0.00000  bestvalidloss 5.93217  last_update 27\n",
      "train: iter 222  trainloss 3.22747  validloss 6.18953±0.00000  bestvalidloss 5.93217  last_update 28\n",
      "train: iter 223  trainloss 3.24113  validloss 5.95500±0.00000  bestvalidloss 5.93217  last_update 29\n",
      "train: iter 224  trainloss 3.26049  validloss 6.33810±0.00000  bestvalidloss 5.93217  last_update 30\n",
      "train: iter 225  trainloss 3.23160  validloss 6.19525±0.00000  bestvalidloss 5.93217  last_update 31\n",
      "train: iter 226  trainloss 3.23887  validloss 6.08083±0.00000  bestvalidloss 5.93217  last_update 32\n",
      "train: iter 227  trainloss 3.23145  validloss 6.18469±0.00000  bestvalidloss 5.93217  last_update 33\n",
      "train: iter 228  trainloss 3.25300  validloss 6.72973±0.00000  bestvalidloss 5.93217  last_update 34\n",
      "train: iter 229  trainloss 3.20379  validloss 6.23362±0.00000  bestvalidloss 5.93217  last_update 35\n",
      "train: iter 230  trainloss 3.27737  validloss 6.00821±0.00000  bestvalidloss 5.93217  last_update 36\n",
      "train: iter 231  trainloss 3.21111  validloss 6.16041±0.00000  bestvalidloss 5.93217  last_update 37\n",
      "train: iter 232  trainloss 3.21519  validloss 6.02652±0.00000  bestvalidloss 5.93217  last_update 38\n",
      "train: iter 233  trainloss 3.22114  validloss 6.12652±0.00000  bestvalidloss 5.93217  last_update 39\n",
      "train: iter 234  trainloss 3.20894  validloss 6.28438±0.00000  bestvalidloss 5.93217  last_update 40\n",
      "train: iter 235  trainloss 3.25309  validloss 6.06296±0.00000  bestvalidloss 5.93217  last_update 41\n",
      "train: iter 236  trainloss 3.23237  validloss 6.15344±0.00000  bestvalidloss 5.93217  last_update 42\n",
      "train: iter 237  trainloss 3.19627  validloss 6.37507±0.00000  bestvalidloss 5.93217  last_update 43\n",
      "train: iter 238  trainloss 3.23107  validloss 5.91367±0.00000  bestvalidloss 5.91367  last_update 0\n",
      "train: iter 239  trainloss 3.27639  validloss 6.11163±0.00000  bestvalidloss 5.91367  last_update 1\n",
      "train: iter 240  trainloss 3.21345  validloss 6.13698±0.00000  bestvalidloss 5.91367  last_update 2\n",
      "train: iter 241  trainloss 3.21269  validloss 6.20441±0.00000  bestvalidloss 5.91367  last_update 3\n",
      "train: iter 242  trainloss 3.20221  validloss 6.14282±0.00000  bestvalidloss 5.91367  last_update 4\n",
      "train: iter 243  trainloss 3.19988  validloss 6.03867±0.00000  bestvalidloss 5.91367  last_update 5\n",
      "train: iter 244  trainloss 3.23057  validloss 6.17969±0.00000  bestvalidloss 5.91367  last_update 6\n",
      "train: iter 245  trainloss 3.24171  validloss 6.36860±0.00000  bestvalidloss 5.91367  last_update 7\n",
      "train: iter 246  trainloss 3.23764  validloss 6.35231±0.00000  bestvalidloss 5.91367  last_update 8\n",
      "train: iter 247  trainloss 3.18517  validloss 6.03364±0.00000  bestvalidloss 5.91367  last_update 9\n",
      "train: iter 248  trainloss 3.20365  validloss 6.31811±0.00000  bestvalidloss 5.91367  last_update 10\n",
      "train: iter 249  trainloss 3.19679  validloss 6.31101±0.00000  bestvalidloss 5.91367  last_update 11\n",
      "train: iter 250  trainloss 3.19774  validloss 6.02371±0.00000  bestvalidloss 5.91367  last_update 12\n",
      "train: iter 251  trainloss 3.20903  validloss 6.29458±0.00000  bestvalidloss 5.91367  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 252  trainloss 3.19348  validloss 6.20625±0.00000  bestvalidloss 5.91367  last_update 14\n",
      "train: iter 253  trainloss 3.19390  validloss 6.25748±0.00000  bestvalidloss 5.91367  last_update 15\n",
      "train: iter 254  trainloss 3.21084  validloss 6.48118±0.00000  bestvalidloss 5.91367  last_update 16\n",
      "train: iter 255  trainloss 3.17456  validloss 6.58752±0.00000  bestvalidloss 5.91367  last_update 17\n",
      "train: iter 256  trainloss 3.17941  validloss 5.96665±0.00000  bestvalidloss 5.91367  last_update 18\n",
      "train: iter 257  trainloss 3.20711  validloss 6.22700±0.00000  bestvalidloss 5.91367  last_update 19\n",
      "train: iter 258  trainloss 3.21279  validloss 6.02383±0.00000  bestvalidloss 5.91367  last_update 20\n",
      "train: iter 259  trainloss 3.19800  validloss 6.13830±0.00000  bestvalidloss 5.91367  last_update 21\n",
      "train: iter 260  trainloss 3.22828  validloss 5.91483±0.00000  bestvalidloss 5.91367  last_update 22\n",
      "train: iter 261  trainloss 3.17829  validloss 6.23545±0.00000  bestvalidloss 5.91367  last_update 23\n",
      "train: iter 262  trainloss 3.22388  validloss 6.35057±0.00000  bestvalidloss 5.91367  last_update 24\n",
      "train: iter 263  trainloss 3.16282  validloss 6.07345±0.00000  bestvalidloss 5.91367  last_update 25\n",
      "train: iter 264  trainloss 3.18040  validloss 6.08777±0.00000  bestvalidloss 5.91367  last_update 26\n",
      "train: iter 265  trainloss 3.21863  validloss 6.62865±0.00000  bestvalidloss 5.91367  last_update 27\n",
      "train: iter 266  trainloss 3.19001  validloss 6.29994±0.00000  bestvalidloss 5.91367  last_update 28\n",
      "train: iter 267  trainloss 3.19126  validloss 6.08246±0.00000  bestvalidloss 5.91367  last_update 29\n",
      "train: iter 268  trainloss 3.20467  validloss 6.10090±0.00000  bestvalidloss 5.91367  last_update 30\n",
      "train: iter 269  trainloss 3.16669  validloss 6.33509±0.00000  bestvalidloss 5.91367  last_update 31\n",
      "train: iter 270  trainloss 3.23306  validloss 6.26449±0.00000  bestvalidloss 5.91367  last_update 32\n",
      "train: iter 271  trainloss 3.19900  validloss 6.06815±0.00000  bestvalidloss 5.91367  last_update 33\n",
      "train: iter 272  trainloss 3.21864  validloss 6.30161±0.00000  bestvalidloss 5.91367  last_update 34\n",
      "train: iter 273  trainloss 3.18040  validloss 6.20833±0.00000  bestvalidloss 5.91367  last_update 35\n",
      "train: iter 274  trainloss 3.17656  validloss 5.92263±0.00000  bestvalidloss 5.91367  last_update 36\n",
      "train: iter 275  trainloss 3.19517  validloss 6.02241±0.00000  bestvalidloss 5.91367  last_update 37\n",
      "train: iter 276  trainloss 3.18116  validloss 6.02647±0.00000  bestvalidloss 5.91367  last_update 38\n",
      "train: iter 277  trainloss 3.18601  validloss 6.04174±0.00000  bestvalidloss 5.91367  last_update 39\n",
      "train: iter 278  trainloss 3.21811  validloss 6.07597±0.00000  bestvalidloss 5.91367  last_update 40\n",
      "train: iter 279  trainloss 3.17158  validloss 6.23876±0.00000  bestvalidloss 5.91367  last_update 41\n",
      "train: iter 280  trainloss 3.19004  validloss 6.12389±0.00000  bestvalidloss 5.91367  last_update 42\n",
      "train: iter 281  trainloss 3.16196  validloss 6.32613±0.00000  bestvalidloss 5.91367  last_update 43\n",
      "train: iter 282  trainloss 3.17433  validloss 6.13147±0.00000  bestvalidloss 5.91367  last_update 44\n",
      "train: iter 283  trainloss 3.21917  validloss 6.32916±0.00000  bestvalidloss 5.91367  last_update 45\n",
      "train: iter 284  trainloss 3.23384  validloss 6.25971±0.00000  bestvalidloss 5.91367  last_update 46\n",
      "train: iter 285  trainloss 3.16304  validloss 6.05366±0.00000  bestvalidloss 5.91367  last_update 47\n",
      "train: iter 286  trainloss 3.14601  validloss 6.07170±0.00000  bestvalidloss 5.91367  last_update 48\n",
      "train: iter 287  trainloss 3.21470  validloss 6.21887±0.00000  bestvalidloss 5.91367  last_update 49\n",
      "train: iter 288  trainloss 3.18755  validloss 6.13500±0.00000  bestvalidloss 5.91367  last_update 50\n",
      "train: iter 289  trainloss 3.22093  validloss 6.08539±0.00000  bestvalidloss 5.91367  last_update 51\n",
      "train: iter 290  trainloss 3.12515  validloss 6.19661±0.00000  bestvalidloss 5.91367  last_update 52\n",
      "train: iter 291  trainloss 3.17789  validloss 6.04078±0.00000  bestvalidloss 5.91367  last_update 53\n",
      "train: iter 292  trainloss 3.17314  validloss 6.13283±0.00000  bestvalidloss 5.91367  last_update 54\n",
      "train: iter 293  trainloss 3.13850  validloss 6.08161±0.00000  bestvalidloss 5.91367  last_update 55\n",
      "train: iter 294  trainloss 3.17806  validloss 6.03037±0.00000  bestvalidloss 5.91367  last_update 56\n",
      "train: iter 295  trainloss 3.14749  validloss 6.21658±0.00000  bestvalidloss 5.91367  last_update 57\n",
      "train: iter 296  trainloss 3.13117  validloss 6.25084±0.00000  bestvalidloss 5.91367  last_update 58\n",
      "train: iter 297  trainloss 3.16962  validloss 6.12043±0.00000  bestvalidloss 5.91367  last_update 59\n",
      "train: iter 298  trainloss 3.17259  validloss 5.99350±0.00000  bestvalidloss 5.91367  last_update 60\n",
      "train: iter 299  trainloss 3.16699  validloss 6.28218±0.00000  bestvalidloss 5.91367  last_update 61\n",
      "train: iter 300  trainloss 3.18031  validloss 6.07023±0.00000  bestvalidloss 5.91367  last_update 62\n",
      "train: iter 301  trainloss 3.18281  validloss 6.12732±0.00000  bestvalidloss 5.91367  last_update 63\n",
      "train: iter 302  trainloss 3.14911  validloss 6.15181±0.00000  bestvalidloss 5.91367  last_update 64\n",
      "train: iter 303  trainloss 3.15941  validloss 6.11017±0.00000  bestvalidloss 5.91367  last_update 65\n",
      "train: iter 304  trainloss 3.16458  validloss 6.21221±0.00000  bestvalidloss 5.91367  last_update 66\n",
      "train: iter 305  trainloss 3.14446  validloss 6.05260±0.00000  bestvalidloss 5.91367  last_update 67\n",
      "train: iter 306  trainloss 3.16814  validloss 6.35880±0.00000  bestvalidloss 5.91367  last_update 68\n",
      "train: iter 307  trainloss 3.17597  validloss 6.24505±0.00000  bestvalidloss 5.91367  last_update 69\n",
      "train: iter 308  trainloss 3.15075  validloss 5.98714±0.00000  bestvalidloss 5.91367  last_update 70\n",
      "train: iter 309  trainloss 3.10550  validloss 6.45601±0.00000  bestvalidloss 5.91367  last_update 71\n",
      "train: iter 310  trainloss 3.16311  validloss 6.34801±0.00000  bestvalidloss 5.91367  last_update 72\n",
      "train: iter 311  trainloss 3.16156  validloss 6.37045±0.00000  bestvalidloss 5.91367  last_update 73\n",
      "train: iter 312  trainloss 3.13479  validloss 6.06687±0.00000  bestvalidloss 5.91367  last_update 74\n",
      "train: iter 313  trainloss 3.13110  validloss 6.28612±0.00000  bestvalidloss 5.91367  last_update 75\n",
      "train: iter 314  trainloss 3.12961  validloss 6.27194±0.00000  bestvalidloss 5.91367  last_update 76\n",
      "train: iter 315  trainloss 3.19753  validloss 6.38003±0.00000  bestvalidloss 5.91367  last_update 77\n",
      "train: iter 316  trainloss 3.12319  validloss 6.00974±0.00000  bestvalidloss 5.91367  last_update 78\n",
      "train: iter 317  trainloss 3.15574  validloss 6.14992±0.00000  bestvalidloss 5.91367  last_update 79\n",
      "train: iter 318  trainloss 3.17218  validloss 6.23998±0.00000  bestvalidloss 5.91367  last_update 80\n",
      "train: iter 319  trainloss 3.13275  validloss 5.95074±0.00000  bestvalidloss 5.91367  last_update 81\n",
      "train: iter 320  trainloss 3.17326  validloss 6.20826±0.00000  bestvalidloss 5.91367  last_update 82\n",
      "train: iter 321  trainloss 3.14831  validloss 6.06925±0.00000  bestvalidloss 5.91367  last_update 83\n",
      "train: iter 322  trainloss 3.12308  validloss 6.23643±0.00000  bestvalidloss 5.91367  last_update 84\n",
      "train: iter 323  trainloss 3.15558  validloss 6.19776±0.00000  bestvalidloss 5.91367  last_update 85\n",
      "train: iter 324  trainloss 3.11114  validloss 6.07330±0.00000  bestvalidloss 5.91367  last_update 86\n",
      "train: iter 325  trainloss 3.12358  validloss 6.18302±0.00000  bestvalidloss 5.91367  last_update 87\n",
      "train: iter 326  trainloss 3.11614  validloss 6.16726±0.00000  bestvalidloss 5.91367  last_update 88\n",
      "train: iter 327  trainloss 3.12860  validloss 6.43069±0.00000  bestvalidloss 5.91367  last_update 89\n",
      "train: iter 328  trainloss 3.14411  validloss 6.14616±0.00000  bestvalidloss 5.91367  last_update 90\n",
      "train: iter 329  trainloss 3.09562  validloss 5.93601±0.00000  bestvalidloss 5.91367  last_update 91\n",
      "train: iter 330  trainloss 3.12786  validloss 6.28301±0.00000  bestvalidloss 5.91367  last_update 92\n",
      "train: iter 331  trainloss 3.14197  validloss 6.23373±0.00000  bestvalidloss 5.91367  last_update 93\n",
      "train: iter 332  trainloss 3.12653  validloss 6.24319±0.00000  bestvalidloss 5.91367  last_update 94\n",
      "train: iter 333  trainloss 3.13855  validloss 6.40235±0.00000  bestvalidloss 5.91367  last_update 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 334  trainloss 3.13823  validloss 6.22618±0.00000  bestvalidloss 5.91367  last_update 96\n",
      "train: iter 335  trainloss 3.15488  validloss 6.20005±0.00000  bestvalidloss 5.91367  last_update 97\n",
      "train: iter 336  trainloss 3.13003  validloss 6.09559±0.00000  bestvalidloss 5.91367  last_update 98\n",
      "train: iter 337  trainloss 3.09575  validloss 6.43559±0.00000  bestvalidloss 5.91367  last_update 99\n",
      "train: iter 338  trainloss 3.15402  validloss 6.14495±0.00000  bestvalidloss 5.91367  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-16.1381)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(6.1439)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3160754712957883\n",
      "tensor([2.6833])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9928837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e11dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7242a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e518ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dce011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
