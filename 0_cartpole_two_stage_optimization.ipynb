{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(461.4626)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 620.93013  validloss 891.15529±0.00000  bestvalidloss 891.15529  last_update 0\n",
      "train: iter 1  trainloss 315.94644  validloss 321.39160±0.00000  bestvalidloss 321.39160  last_update 0\n",
      "train: iter 2  trainloss 57.94719  validloss 174.41492±0.00000  bestvalidloss 174.41492  last_update 0\n",
      "train: iter 3  trainloss 170.15096  validloss -152.45597±0.00000  bestvalidloss -152.45597  last_update 0\n",
      "train: iter 4  trainloss -12.96336  validloss 35.38015±0.00000  bestvalidloss -152.45597  last_update 1\n",
      "train: iter 5  trainloss -237.65913  validloss -128.93737±0.00000  bestvalidloss -152.45597  last_update 2\n",
      "train: iter 6  trainloss -393.68857  validloss -316.74887±0.00000  bestvalidloss -316.74887  last_update 0\n",
      "train: iter 7  trainloss -499.31234  validloss -486.32368±0.00000  bestvalidloss -486.32368  last_update 0\n",
      "train: iter 8  trainloss -606.23721  validloss -635.00987±0.00000  bestvalidloss -635.00987  last_update 0\n",
      "train: iter 9  trainloss -740.72569  validloss -697.69625±0.00000  bestvalidloss -697.69625  last_update 0\n",
      "train: iter 10  trainloss -812.58316  validloss -839.75170±0.00000  bestvalidloss -839.75170  last_update 0\n",
      "train: iter 11  trainloss -852.52399  validloss -826.04814±0.00000  bestvalidloss -839.75170  last_update 1\n",
      "train: iter 12  trainloss -931.48222  validloss -890.11086±0.00000  bestvalidloss -890.11086  last_update 0\n",
      "train: iter 13  trainloss -955.46509  validloss -1062.58568±0.00000  bestvalidloss -1062.58568  last_update 0\n",
      "train: iter 14  trainloss -1035.15147  validloss -1093.08801±0.00000  bestvalidloss -1093.08801  last_update 0\n",
      "train: iter 15  trainloss -1085.53453  validloss -1202.78454±0.00000  bestvalidloss -1202.78454  last_update 0\n",
      "train: iter 16  trainloss -1072.67771  validloss -1043.54342±0.00000  bestvalidloss -1202.78454  last_update 1\n",
      "train: iter 17  trainloss -1037.54049  validloss -1161.12549±0.00000  bestvalidloss -1202.78454  last_update 2\n",
      "train: iter 18  trainloss -1083.44468  validloss -1193.89062±0.00000  bestvalidloss -1202.78454  last_update 3\n",
      "train: iter 19  trainloss -1159.28194  validloss -1307.83742±0.00000  bestvalidloss -1307.83742  last_update 0\n",
      "train: iter 20  trainloss -1229.87491  validloss -1288.37256±0.00000  bestvalidloss -1307.83742  last_update 1\n",
      "train: iter 21  trainloss -1255.36004  validloss -1345.76658±0.00000  bestvalidloss -1345.76658  last_update 0\n",
      "train: iter 22  trainloss -1279.35240  validloss -1376.68026±0.00000  bestvalidloss -1376.68026  last_update 0\n",
      "train: iter 23  trainloss -1277.25836  validloss -1393.61457±0.00000  bestvalidloss -1393.61457  last_update 0\n",
      "train: iter 24  trainloss -1287.09078  validloss -1138.44192±0.00000  bestvalidloss -1393.61457  last_update 1\n",
      "train: iter 25  trainloss -1303.39534  validloss -1339.27427±0.00000  bestvalidloss -1393.61457  last_update 2\n",
      "train: iter 26  trainloss -1369.14786  validloss -1432.52619±0.00000  bestvalidloss -1432.52619  last_update 0\n",
      "train: iter 27  trainloss -1332.68749  validloss -1422.53778±0.00000  bestvalidloss -1432.52619  last_update 1\n",
      "train: iter 28  trainloss -1358.11241  validloss -1377.18523±0.00000  bestvalidloss -1432.52619  last_update 2\n",
      "train: iter 29  trainloss -1362.34013  validloss -1443.14253±0.00000  bestvalidloss -1443.14253  last_update 0\n",
      "train: iter 30  trainloss -1331.17537  validloss -1486.32076±0.00000  bestvalidloss -1486.32076  last_update 0\n",
      "train: iter 31  trainloss -1127.09334  validloss -1304.59829±0.00000  bestvalidloss -1486.32076  last_update 1\n",
      "train: iter 32  trainloss -1376.60847  validloss -1360.71925±0.00000  bestvalidloss -1486.32076  last_update 2\n",
      "train: iter 33  trainloss -1414.78699  validloss -1504.78704±0.00000  bestvalidloss -1504.78704  last_update 0\n",
      "train: iter 34  trainloss -1432.99997  validloss -1469.02792±0.00000  bestvalidloss -1504.78704  last_update 1\n",
      "train: iter 35  trainloss -1431.18120  validloss -1420.30156±0.00000  bestvalidloss -1504.78704  last_update 2\n",
      "train: iter 36  trainloss -1248.52467  validloss -1429.74142±0.00000  bestvalidloss -1504.78704  last_update 3\n",
      "train: iter 37  trainloss -1425.88065  validloss -1237.11182±0.00000  bestvalidloss -1504.78704  last_update 4\n",
      "train: iter 38  trainloss -1426.42060  validloss -1498.30982±0.00000  bestvalidloss -1504.78704  last_update 5\n",
      "train: iter 39  trainloss -1466.35050  validloss -1541.23819±0.00000  bestvalidloss -1541.23819  last_update 0\n",
      "train: iter 40  trainloss -1468.69436  validloss -1542.17751±0.00000  bestvalidloss -1542.17751  last_update 0\n",
      "train: iter 41  trainloss -1455.31599  validloss -1510.22662±0.00000  bestvalidloss -1542.17751  last_update 1\n",
      "train: iter 42  trainloss -1451.57086  validloss -1574.05781±0.00000  bestvalidloss -1574.05781  last_update 0\n",
      "train: iter 43  trainloss -1439.31405  validloss -1527.71927±0.00000  bestvalidloss -1574.05781  last_update 1\n",
      "train: iter 44  trainloss -1453.38102  validloss -1482.34492±0.00000  bestvalidloss -1574.05781  last_update 2\n",
      "train: iter 45  trainloss -1532.14249  validloss -1565.55853±0.00000  bestvalidloss -1574.05781  last_update 3\n",
      "train: iter 46  trainloss -1504.14056  validloss -1599.35135±0.00000  bestvalidloss -1599.35135  last_update 0\n",
      "train: iter 47  trainloss -1530.38440  validloss -1523.08537±0.00000  bestvalidloss -1599.35135  last_update 1\n",
      "train: iter 48  trainloss -1527.88818  validloss -1574.07720±0.00000  bestvalidloss -1599.35135  last_update 2\n",
      "train: iter 49  trainloss -1521.67378  validloss -1565.52315±0.00000  bestvalidloss -1599.35135  last_update 3\n",
      "train: iter 50  trainloss -1320.18054  validloss -1623.81082±0.00000  bestvalidloss -1623.81082  last_update 0\n",
      "train: iter 51  trainloss -1554.55656  validloss -1603.30346±0.00000  bestvalidloss -1623.81082  last_update 1\n",
      "train: iter 52  trainloss -1535.97565  validloss -1649.71003±0.00000  bestvalidloss -1649.71003  last_update 0\n",
      "train: iter 53  trainloss -1546.58473  validloss -1588.78208±0.00000  bestvalidloss -1649.71003  last_update 1\n",
      "train: iter 54  trainloss -1575.20858  validloss -1687.85133±0.00000  bestvalidloss -1687.85133  last_update 0\n",
      "train: iter 55  trainloss -1567.88398  validloss -1423.05090±0.00000  bestvalidloss -1687.85133  last_update 1\n",
      "train: iter 56  trainloss -1515.67045  validloss -1655.14790±0.00000  bestvalidloss -1687.85133  last_update 2\n",
      "train: iter 57  trainloss -779.85713  validloss -1388.93313±0.00000  bestvalidloss -1687.85133  last_update 3\n",
      "train: iter 58  trainloss -1519.65764  validloss -1393.20695±0.00000  bestvalidloss -1687.85133  last_update 4\n",
      "train: iter 59  trainloss -1508.28835  validloss -1608.75895±0.00000  bestvalidloss -1687.85133  last_update 5\n",
      "train: iter 60  trainloss -1598.81630  validloss -1662.25920±0.00000  bestvalidloss -1687.85133  last_update 6\n",
      "train: iter 61  trainloss -1608.81064  validloss -1710.09052±0.00000  bestvalidloss -1710.09052  last_update 0\n",
      "train: iter 62  trainloss -1633.63395  validloss -1652.45499±0.00000  bestvalidloss -1710.09052  last_update 1\n",
      "train: iter 63  trainloss -1502.21316  validloss -1638.53427±0.00000  bestvalidloss -1710.09052  last_update 2\n",
      "train: iter 64  trainloss -1605.73783  validloss -1646.35544±0.00000  bestvalidloss -1710.09052  last_update 3\n",
      "train: iter 65  trainloss -1658.18106  validloss -1738.86266±0.00000  bestvalidloss -1738.86266  last_update 0\n",
      "train: iter 66  trainloss -1687.88525  validloss -1745.77107±0.00000  bestvalidloss -1745.77107  last_update 0\n",
      "train: iter 67  trainloss -1638.40179  validloss -1712.11776±0.00000  bestvalidloss -1745.77107  last_update 1\n",
      "train: iter 68  trainloss -1676.71602  validloss -1748.70093±0.00000  bestvalidloss -1748.70093  last_update 0\n",
      "train: iter 69  trainloss -1688.36865  validloss -1780.24200±0.00000  bestvalidloss -1780.24200  last_update 0\n",
      "train: iter 70  trainloss -1562.13856  validloss -1726.45010±0.00000  bestvalidloss -1780.24200  last_update 1\n",
      "train: iter 71  trainloss -1630.29453  validloss -1795.36078±0.00000  bestvalidloss -1795.36078  last_update 0\n",
      "train: iter 72  trainloss -1689.02994  validloss -1739.46219±0.00000  bestvalidloss -1795.36078  last_update 1\n",
      "train: iter 73  trainloss -1680.32696  validloss -1767.34167±0.00000  bestvalidloss -1795.36078  last_update 2\n",
      "train: iter 74  trainloss -1701.99083  validloss -1776.02368±0.00000  bestvalidloss -1795.36078  last_update 3\n",
      "train: iter 75  trainloss -1692.01098  validloss -1749.34576±0.00000  bestvalidloss -1795.36078  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 76  trainloss -1655.19805  validloss -1748.96099±0.00000  bestvalidloss -1795.36078  last_update 5\n",
      "train: iter 77  trainloss -1692.21599  validloss -1751.11776±0.00000  bestvalidloss -1795.36078  last_update 6\n",
      "train: iter 78  trainloss -1659.53275  validloss -1705.96212±0.00000  bestvalidloss -1795.36078  last_update 7\n",
      "train: iter 79  trainloss -1749.45957  validloss -1827.72565±0.00000  bestvalidloss -1827.72565  last_update 0\n",
      "train: iter 80  trainloss -1731.41129  validloss -1841.04886±0.00000  bestvalidloss -1841.04886  last_update 0\n",
      "train: iter 81  trainloss -1718.90997  validloss -1763.94837±0.00000  bestvalidloss -1841.04886  last_update 1\n",
      "train: iter 82  trainloss -1693.34551  validloss -1768.60418±0.00000  bestvalidloss -1841.04886  last_update 2\n",
      "train: iter 83  trainloss -1723.09277  validloss -1806.67796±0.00000  bestvalidloss -1841.04886  last_update 3\n",
      "train: iter 84  trainloss -1556.13604  validloss -1761.29420±0.00000  bestvalidloss -1841.04886  last_update 4\n",
      "train: iter 85  trainloss -1643.87511  validloss -1787.05582±0.00000  bestvalidloss -1841.04886  last_update 5\n",
      "train: iter 86  trainloss -1733.31033  validloss -1814.88381±0.00000  bestvalidloss -1841.04886  last_update 6\n",
      "train: iter 87  trainloss -1704.20602  validloss -1785.25008±0.00000  bestvalidloss -1841.04886  last_update 7\n",
      "train: iter 88  trainloss -1755.94875  validloss -1857.27401±0.00000  bestvalidloss -1857.27401  last_update 0\n",
      "train: iter 89  trainloss -1704.91583  validloss -1792.14066±0.00000  bestvalidloss -1857.27401  last_update 1\n",
      "train: iter 90  trainloss -1733.59227  validloss -1812.01560±0.00000  bestvalidloss -1857.27401  last_update 2\n",
      "train: iter 91  trainloss -1557.57382  validloss -1831.42236±0.00000  bestvalidloss -1857.27401  last_update 3\n",
      "train: iter 92  trainloss -1619.77697  validloss -1779.86671±0.00000  bestvalidloss -1857.27401  last_update 4\n",
      "train: iter 93  trainloss -1712.82657  validloss -1789.33749±0.00000  bestvalidloss -1857.27401  last_update 5\n",
      "train: iter 94  trainloss -1746.65245  validloss -1819.97221±0.00000  bestvalidloss -1857.27401  last_update 6\n",
      "train: iter 95  trainloss -1644.64490  validloss -1827.50620±0.00000  bestvalidloss -1857.27401  last_update 7\n",
      "train: iter 96  trainloss -1751.29472  validloss -1794.81595±0.00000  bestvalidloss -1857.27401  last_update 8\n",
      "train: iter 97  trainloss -1786.27623  validloss -1835.82094±0.00000  bestvalidloss -1857.27401  last_update 9\n",
      "train: iter 98  trainloss -1801.71096  validloss -1864.35309±0.00000  bestvalidloss -1864.35309  last_update 0\n",
      "train: iter 99  trainloss -1739.38301  validloss -1833.79985±0.00000  bestvalidloss -1864.35309  last_update 1\n",
      "train: iter 100  trainloss -1811.40594  validloss -1907.18309±0.00000  bestvalidloss -1907.18309  last_update 0\n",
      "train: iter 101  trainloss -1824.79059  validloss -1848.07914±0.00000  bestvalidloss -1907.18309  last_update 1\n",
      "train: iter 102  trainloss -1751.68238  validloss -1877.88328±0.00000  bestvalidloss -1907.18309  last_update 2\n",
      "train: iter 103  trainloss -1786.22069  validloss -1872.13079±0.00000  bestvalidloss -1907.18309  last_update 3\n",
      "train: iter 104  trainloss -1821.20322  validloss -1883.97349±0.00000  bestvalidloss -1907.18309  last_update 4\n",
      "train: iter 105  trainloss -1731.04768  validloss -1829.79489±0.00000  bestvalidloss -1907.18309  last_update 5\n",
      "train: iter 106  trainloss -1656.50280  validloss -1784.87991±0.00000  bestvalidloss -1907.18309  last_update 6\n",
      "train: iter 107  trainloss -1737.53476  validloss -1816.12235±0.00000  bestvalidloss -1907.18309  last_update 7\n",
      "train: iter 108  trainloss -1774.11191  validloss -1790.49426±0.00000  bestvalidloss -1907.18309  last_update 8\n",
      "train: iter 109  trainloss -1816.39350  validloss -1912.28712±0.00000  bestvalidloss -1912.28712  last_update 0\n",
      "train: iter 110  trainloss -1831.15719  validloss -1893.23064±0.00000  bestvalidloss -1912.28712  last_update 1\n",
      "train: iter 111  trainloss -1850.46610  validloss -1920.45340±0.00000  bestvalidloss -1920.45340  last_update 0\n",
      "train: iter 112  trainloss -1649.66278  validloss -1865.38574±0.00000  bestvalidloss -1920.45340  last_update 1\n",
      "train: iter 113  trainloss -1633.87621  validloss -1172.02190±0.00000  bestvalidloss -1920.45340  last_update 2\n",
      "train: iter 114  trainloss -1524.01864  validloss -1727.28846±0.00000  bestvalidloss -1920.45340  last_update 3\n",
      "train: iter 115  trainloss -1792.23285  validloss -1730.46181±0.00000  bestvalidloss -1920.45340  last_update 4\n",
      "train: iter 116  trainloss -1829.95955  validloss -1868.03174±0.00000  bestvalidloss -1920.45340  last_update 5\n",
      "train: iter 117  trainloss -1750.23682  validloss -1847.28127±0.00000  bestvalidloss -1920.45340  last_update 6\n",
      "train: iter 118  trainloss -1836.23980  validloss -1780.96597±0.00000  bestvalidloss -1920.45340  last_update 7\n",
      "train: iter 119  trainloss -1847.52712  validloss -1925.12617±0.00000  bestvalidloss -1925.12617  last_update 0\n",
      "train: iter 120  trainloss -1882.30875  validloss -1924.40784±0.00000  bestvalidloss -1925.12617  last_update 1\n",
      "train: iter 121  trainloss -1877.70776  validloss -1929.07246±0.00000  bestvalidloss -1929.07246  last_update 0\n",
      "train: iter 122  trainloss -1820.79678  validloss -1901.73952±0.00000  bestvalidloss -1929.07246  last_update 1\n",
      "train: iter 123  trainloss -1431.09218  validloss -1741.98089±0.00000  bestvalidloss -1929.07246  last_update 2\n",
      "train: iter 124  trainloss -1846.79264  validloss -1874.37110±0.00000  bestvalidloss -1929.07246  last_update 3\n",
      "train: iter 125  trainloss -1824.80372  validloss -1896.57281±0.00000  bestvalidloss -1929.07246  last_update 4\n",
      "train: iter 126  trainloss -1869.46583  validloss -1922.00594±0.00000  bestvalidloss -1929.07246  last_update 5\n",
      "train: iter 127  trainloss -1842.40013  validloss -1957.66131±0.00000  bestvalidloss -1957.66131  last_update 0\n",
      "train: iter 128  trainloss -1886.84153  validloss -1950.88274±0.00000  bestvalidloss -1957.66131  last_update 1\n",
      "train: iter 129  trainloss -1758.94616  validloss -1923.89813±0.00000  bestvalidloss -1957.66131  last_update 2\n",
      "train: iter 130  trainloss -1839.51986  validloss -1929.19453±0.00000  bestvalidloss -1957.66131  last_update 3\n",
      "train: iter 131  trainloss -1870.28944  validloss -1912.94243±0.00000  bestvalidloss -1957.66131  last_update 4\n",
      "train: iter 132  trainloss -1874.38651  validloss -1922.40148±0.00000  bestvalidloss -1957.66131  last_update 5\n",
      "train: iter 133  trainloss -1865.37725  validloss -1910.27850±0.00000  bestvalidloss -1957.66131  last_update 6\n",
      "train: iter 134  trainloss -1849.40232  validloss -1942.77205±0.00000  bestvalidloss -1957.66131  last_update 7\n",
      "train: iter 135  trainloss -1834.24411  validloss -1892.62477±0.00000  bestvalidloss -1957.66131  last_update 8\n",
      "train: iter 136  trainloss -1862.98253  validloss -1869.61671±0.00000  bestvalidloss -1957.66131  last_update 9\n",
      "train: iter 137  trainloss -1827.98849  validloss -1805.53039±0.00000  bestvalidloss -1957.66131  last_update 10\n",
      "train: iter 138  trainloss -1859.66581  validloss -1925.61366±0.00000  bestvalidloss -1957.66131  last_update 11\n",
      "train: iter 139  trainloss -1869.75871  validloss -1972.22477±0.00000  bestvalidloss -1972.22477  last_update 0\n",
      "train: iter 140  trainloss -1825.76725  validloss -1875.40175±0.00000  bestvalidloss -1972.22477  last_update 1\n",
      "train: iter 141  trainloss -1626.93513  validloss -1872.56359±0.00000  bestvalidloss -1972.22477  last_update 2\n",
      "train: iter 142  trainloss -1855.50380  validloss -1900.53124±0.00000  bestvalidloss -1972.22477  last_update 3\n",
      "train: iter 143  trainloss -1843.52256  validloss -1984.63318±0.00000  bestvalidloss -1984.63318  last_update 0\n",
      "train: iter 144  trainloss -1871.78136  validloss -1943.79212±0.00000  bestvalidloss -1984.63318  last_update 1\n",
      "train: iter 145  trainloss -1871.08639  validloss -1962.42012±0.00000  bestvalidloss -1984.63318  last_update 2\n",
      "train: iter 146  trainloss -1915.51628  validloss -1904.23434±0.00000  bestvalidloss -1984.63318  last_update 3\n",
      "train: iter 147  trainloss -1873.39544  validloss -1979.43513±0.00000  bestvalidloss -1984.63318  last_update 4\n",
      "train: iter 148  trainloss -1878.84502  validloss -1937.55849±0.00000  bestvalidloss -1984.63318  last_update 5\n",
      "train: iter 149  trainloss -1801.52242  validloss -1919.74266±0.00000  bestvalidloss -1984.63318  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 150  trainloss -1517.56639  validloss -1867.20308±0.00000  bestvalidloss -1984.63318  last_update 7\n",
      "train: iter 151  trainloss -1504.67358  validloss -1759.64028±0.00000  bestvalidloss -1984.63318  last_update 8\n",
      "train: iter 152  trainloss -1901.05466  validloss -1977.68381±0.00000  bestvalidloss -1984.63318  last_update 9\n",
      "train: iter 153  trainloss -1917.06073  validloss -1964.72028±0.00000  bestvalidloss -1984.63318  last_update 10\n",
      "train: iter 154  trainloss -1906.13729  validloss -1960.18792±0.00000  bestvalidloss -1984.63318  last_update 11\n",
      "train: iter 155  trainloss -1897.27245  validloss -1911.87846±0.00000  bestvalidloss -1984.63318  last_update 12\n",
      "train: iter 156  trainloss -1890.72168  validloss -1971.99378±0.00000  bestvalidloss -1984.63318  last_update 13\n",
      "train: iter 157  trainloss -1894.96298  validloss -1991.63471±0.00000  bestvalidloss -1991.63471  last_update 0\n",
      "train: iter 158  trainloss -1859.05847  validloss -1952.02333±0.00000  bestvalidloss -1991.63471  last_update 1\n",
      "train: iter 159  trainloss -1905.51292  validloss -2006.88427±0.00000  bestvalidloss -2006.88427  last_update 0\n",
      "train: iter 160  trainloss -1890.56567  validloss -1971.87328±0.00000  bestvalidloss -2006.88427  last_update 1\n",
      "train: iter 161  trainloss -1919.84835  validloss -1995.46678±0.00000  bestvalidloss -2006.88427  last_update 2\n",
      "train: iter 162  trainloss -1876.60368  validloss -1964.03172±0.00000  bestvalidloss -2006.88427  last_update 3\n",
      "train: iter 163  trainloss -1901.31518  validloss -1847.87765±0.00000  bestvalidloss -2006.88427  last_update 4\n",
      "train: iter 164  trainloss -1859.26298  validloss -1950.63536±0.00000  bestvalidloss -2006.88427  last_update 5\n",
      "train: iter 165  trainloss -1855.05272  validloss -1851.50422±0.00000  bestvalidloss -2006.88427  last_update 6\n",
      "train: iter 166  trainloss -1901.21130  validloss -1950.32504±0.00000  bestvalidloss -2006.88427  last_update 7\n",
      "train: iter 167  trainloss -1914.27483  validloss -1860.83032±0.00000  bestvalidloss -2006.88427  last_update 8\n",
      "train: iter 168  trainloss -1929.28362  validloss -2003.82891±0.00000  bestvalidloss -2006.88427  last_update 9\n",
      "train: iter 169  trainloss -1876.70221  validloss -1925.23362±0.00000  bestvalidloss -2006.88427  last_update 10\n",
      "train: iter 170  trainloss -1843.74143  validloss -1937.82294±0.00000  bestvalidloss -2006.88427  last_update 11\n",
      "train: iter 171  trainloss -1888.16757  validloss -1902.42498±0.00000  bestvalidloss -2006.88427  last_update 12\n",
      "train: iter 172  trainloss -1926.45788  validloss -2012.10310±0.00000  bestvalidloss -2012.10310  last_update 0\n",
      "train: iter 173  trainloss -1904.71024  validloss -1996.05669±0.00000  bestvalidloss -2012.10310  last_update 1\n",
      "train: iter 174  trainloss -1687.72026  validloss -1961.03839±0.00000  bestvalidloss -2012.10310  last_update 2\n",
      "train: iter 175  trainloss -1831.24368  validloss -1800.06435±0.00000  bestvalidloss -2012.10310  last_update 3\n",
      "train: iter 176  trainloss -1898.31677  validloss -1996.49847±0.00000  bestvalidloss -2012.10310  last_update 4\n",
      "train: iter 177  trainloss -1931.31154  validloss -2022.41390±0.00000  bestvalidloss -2022.41390  last_update 0\n",
      "train: iter 178  trainloss -1943.62273  validloss -2018.59951±0.00000  bestvalidloss -2022.41390  last_update 1\n",
      "train: iter 179  trainloss -1922.44423  validloss -1986.60065±0.00000  bestvalidloss -2022.41390  last_update 2\n",
      "train: iter 180  trainloss -1910.69854  validloss -1968.09837±0.00000  bestvalidloss -2022.41390  last_update 3\n",
      "train: iter 181  trainloss -1791.40949  validloss -1810.63269±0.00000  bestvalidloss -2022.41390  last_update 4\n",
      "train: iter 182  trainloss -1912.38490  validloss -1997.38040±0.00000  bestvalidloss -2022.41390  last_update 5\n",
      "train: iter 183  trainloss -1899.30658  validloss -1951.34174±0.00000  bestvalidloss -2022.41390  last_update 6\n",
      "train: iter 184  trainloss -1925.05928  validloss -1967.89370±0.00000  bestvalidloss -2022.41390  last_update 7\n",
      "train: iter 185  trainloss -1936.26241  validloss -2009.53563±0.00000  bestvalidloss -2022.41390  last_update 8\n",
      "train: iter 186  trainloss -1911.81891  validloss -2012.79857±0.00000  bestvalidloss -2022.41390  last_update 9\n",
      "train: iter 187  trainloss -1909.00094  validloss -1986.51146±0.00000  bestvalidloss -2022.41390  last_update 10\n",
      "train: iter 188  trainloss -1893.46035  validloss -1927.30028±0.00000  bestvalidloss -2022.41390  last_update 11\n",
      "train: iter 189  trainloss -1952.95962  validloss -1982.32585±0.00000  bestvalidloss -2022.41390  last_update 12\n",
      "train: iter 190  trainloss -1887.22715  validloss -1999.34370±0.00000  bestvalidloss -2022.41390  last_update 13\n",
      "train: iter 191  trainloss -1914.38815  validloss -1957.60874±0.00000  bestvalidloss -2022.41390  last_update 14\n",
      "train: iter 192  trainloss -1849.09040  validloss -1913.41268±0.00000  bestvalidloss -2022.41390  last_update 15\n",
      "train: iter 193  trainloss -1919.67394  validloss -2010.47208±0.00000  bestvalidloss -2022.41390  last_update 16\n",
      "train: iter 194  trainloss -1935.41309  validloss -1990.73361±0.00000  bestvalidloss -2022.41390  last_update 17\n",
      "train: iter 195  trainloss -1916.82153  validloss -2009.84592±0.00000  bestvalidloss -2022.41390  last_update 18\n",
      "train: iter 196  trainloss -1876.02373  validloss -1918.45780±0.00000  bestvalidloss -2022.41390  last_update 19\n",
      "train: iter 197  trainloss -1873.35333  validloss -1854.56559±0.00000  bestvalidloss -2022.41390  last_update 20\n",
      "train: iter 198  trainloss -1953.38560  validloss -2023.88913±0.00000  bestvalidloss -2023.88913  last_update 0\n",
      "train: iter 199  trainloss -1965.75668  validloss -2025.52682±0.00000  bestvalidloss -2025.52682  last_update 0\n",
      "train: iter 200  trainloss -1683.86701  validloss -1979.15106±0.00000  bestvalidloss -2025.52682  last_update 1\n",
      "train: iter 201  trainloss -1918.79402  validloss -1974.13348±0.00000  bestvalidloss -2025.52682  last_update 2\n",
      "train: iter 202  trainloss -1929.02570  validloss -1998.28253±0.00000  bestvalidloss -2025.52682  last_update 3\n",
      "train: iter 203  trainloss -1826.97731  validloss -1941.87067±0.00000  bestvalidloss -2025.52682  last_update 4\n",
      "train: iter 204  trainloss -1901.75814  validloss -1884.16302±0.00000  bestvalidloss -2025.52682  last_update 5\n",
      "train: iter 205  trainloss -1953.60137  validloss -2003.06830±0.00000  bestvalidloss -2025.52682  last_update 6\n",
      "train: iter 206  trainloss -1966.94299  validloss -2035.26342±0.00000  bestvalidloss -2035.26342  last_update 0\n",
      "train: iter 207  trainloss -1945.88143  validloss -2035.12790±0.00000  bestvalidloss -2035.26342  last_update 1\n",
      "train: iter 208  trainloss -1937.86930  validloss -2009.75366±0.00000  bestvalidloss -2035.26342  last_update 2\n",
      "train: iter 209  trainloss -1974.44252  validloss -2003.79992±0.00000  bestvalidloss -2035.26342  last_update 3\n",
      "train: iter 210  trainloss -1733.45364  validloss -2009.46013±0.00000  bestvalidloss -2035.26342  last_update 4\n",
      "train: iter 211  trainloss -1922.28847  validloss -1841.61951±0.00000  bestvalidloss -2035.26342  last_update 5\n",
      "train: iter 212  trainloss -1952.75615  validloss -2021.55674±0.00000  bestvalidloss -2035.26342  last_update 6\n",
      "train: iter 213  trainloss -1968.90290  validloss -2035.83344±0.00000  bestvalidloss -2035.83344  last_update 0\n",
      "train: iter 214  trainloss -1932.36817  validloss -2036.16961±0.00000  bestvalidloss -2036.16961  last_update 0\n",
      "train: iter 215  trainloss -1906.52706  validloss -1992.48665±0.00000  bestvalidloss -2036.16961  last_update 1\n",
      "train: iter 216  trainloss -1963.52835  validloss -1959.82236±0.00000  bestvalidloss -2036.16961  last_update 2\n",
      "train: iter 217  trainloss -1962.88495  validloss -2038.38027±0.00000  bestvalidloss -2038.38027  last_update 0\n",
      "train: iter 218  trainloss -1884.88699  validloss -2012.91765±0.00000  bestvalidloss -2038.38027  last_update 1\n",
      "train: iter 219  trainloss -1908.22933  validloss -1989.01935±0.00000  bestvalidloss -2038.38027  last_update 2\n",
      "train: iter 220  trainloss -1881.05721  validloss -1941.08293±0.00000  bestvalidloss -2038.38027  last_update 3\n",
      "train: iter 221  trainloss -1949.73636  validloss -2008.66290±0.00000  bestvalidloss -2038.38027  last_update 4\n",
      "train: iter 222  trainloss -1844.77726  validloss -2031.87755±0.00000  bestvalidloss -2038.38027  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1949.60307  validloss -1977.12345±0.00000  bestvalidloss -2038.38027  last_update 6\n",
      "train: iter 224  trainloss -1915.43114  validloss -2010.92658±0.00000  bestvalidloss -2038.38027  last_update 7\n",
      "train: iter 225  trainloss -1950.47409  validloss -2029.15928±0.00000  bestvalidloss -2038.38027  last_update 8\n",
      "train: iter 226  trainloss -1841.27735  validloss -2026.24365±0.00000  bestvalidloss -2038.38027  last_update 9\n",
      "train: iter 227  trainloss -1967.02360  validloss -2023.90725±0.00000  bestvalidloss -2038.38027  last_update 10\n",
      "train: iter 228  trainloss -1809.18220  validloss -2022.93741±0.00000  bestvalidloss -2038.38027  last_update 11\n",
      "train: iter 229  trainloss -1867.51933  validloss -1952.03064±0.00000  bestvalidloss -2038.38027  last_update 12\n",
      "train: iter 230  trainloss -1962.57716  validloss -1943.35278±0.00000  bestvalidloss -2038.38027  last_update 13\n",
      "train: iter 231  trainloss -1961.67901  validloss -2037.38256±0.00000  bestvalidloss -2038.38027  last_update 14\n",
      "train: iter 232  trainloss -1955.53629  validloss -2037.58612±0.00000  bestvalidloss -2038.38027  last_update 15\n",
      "train: iter 233  trainloss -1925.83921  validloss -1988.10269±0.00000  bestvalidloss -2038.38027  last_update 16\n",
      "train: iter 234  trainloss -1976.77348  validloss -2024.58303±0.00000  bestvalidloss -2038.38027  last_update 17\n",
      "train: iter 235  trainloss -1932.97863  validloss -1952.95408±0.00000  bestvalidloss -2038.38027  last_update 18\n",
      "train: iter 236  trainloss -1901.24761  validloss -2009.72331±0.00000  bestvalidloss -2038.38027  last_update 19\n",
      "train: iter 237  trainloss -1965.43853  validloss -1990.64411±0.00000  bestvalidloss -2038.38027  last_update 20\n",
      "train: iter 238  trainloss -1933.07418  validloss -1991.28320±0.00000  bestvalidloss -2038.38027  last_update 21\n",
      "train: iter 239  trainloss -1508.54184  validloss -1692.69490±0.00000  bestvalidloss -2038.38027  last_update 22\n",
      "train: iter 240  trainloss -1966.92932  validloss -2036.29841±0.00000  bestvalidloss -2038.38027  last_update 23\n",
      "train: iter 241  trainloss -1986.80630  validloss -2028.64664±0.00000  bestvalidloss -2038.38027  last_update 24\n",
      "train: iter 242  trainloss -1966.50170  validloss -1986.42933±0.00000  bestvalidloss -2038.38027  last_update 25\n",
      "train: iter 243  trainloss -1938.58762  validloss -2040.09255±0.00000  bestvalidloss -2040.09255  last_update 0\n",
      "train: iter 244  trainloss -1902.72017  validloss -2026.34625±0.00000  bestvalidloss -2040.09255  last_update 1\n",
      "train: iter 245  trainloss -1968.44670  validloss -2009.23950±0.00000  bestvalidloss -2040.09255  last_update 2\n",
      "train: iter 246  trainloss -1916.29286  validloss -2039.73306±0.00000  bestvalidloss -2040.09255  last_update 3\n",
      "train: iter 247  trainloss -1983.50624  validloss -2048.39604±0.00000  bestvalidloss -2048.39604  last_update 0\n",
      "train: iter 248  trainloss -1959.58792  validloss -2042.15429±0.00000  bestvalidloss -2048.39604  last_update 1\n",
      "train: iter 249  trainloss -1903.34592  validloss -1799.17495±0.00000  bestvalidloss -2048.39604  last_update 2\n",
      "train: iter 250  trainloss -1957.89217  validloss -1978.13336±0.00000  bestvalidloss -2048.39604  last_update 3\n",
      "train: iter 251  trainloss -1975.19866  validloss -2028.18515±0.00000  bestvalidloss -2048.39604  last_update 4\n",
      "train: iter 252  trainloss -1917.62592  validloss -2053.94924±0.00000  bestvalidloss -2053.94924  last_update 0\n",
      "train: iter 253  trainloss -1954.72774  validloss -2017.97329±0.00000  bestvalidloss -2053.94924  last_update 1\n",
      "train: iter 254  trainloss -1937.45749  validloss -1979.37377±0.00000  bestvalidloss -2053.94924  last_update 2\n",
      "train: iter 255  trainloss -1870.07854  validloss -1824.04262±0.00000  bestvalidloss -2053.94924  last_update 3\n",
      "train: iter 256  trainloss -1909.28461  validloss -2017.04555±0.00000  bestvalidloss -2053.94924  last_update 4\n",
      "train: iter 257  trainloss -1970.96014  validloss -1931.16376±0.00000  bestvalidloss -2053.94924  last_update 5\n",
      "train: iter 258  trainloss -1997.17749  validloss -2047.61753±0.00000  bestvalidloss -2053.94924  last_update 6\n",
      "train: iter 259  trainloss -1999.51513  validloss -2037.73445±0.00000  bestvalidloss -2053.94924  last_update 7\n",
      "train: iter 260  trainloss -1933.78755  validloss -2042.56198±0.00000  bestvalidloss -2053.94924  last_update 8\n",
      "train: iter 261  trainloss -1781.01426  validloss -2026.62786±0.00000  bestvalidloss -2053.94924  last_update 9\n",
      "train: iter 262  trainloss -1846.41474  validloss -1850.43848±0.00000  bestvalidloss -2053.94924  last_update 10\n",
      "train: iter 263  trainloss -1923.20556  validloss -2010.82333±0.00000  bestvalidloss -2053.94924  last_update 11\n",
      "train: iter 264  trainloss -1757.05946  validloss -1899.50799±0.00000  bestvalidloss -2053.94924  last_update 12\n",
      "train: iter 265  trainloss -1356.72196  validloss -1459.69692±0.00000  bestvalidloss -2053.94924  last_update 13\n",
      "train: iter 266  trainloss -1959.43093  validloss -2008.38304±0.00000  bestvalidloss -2053.94924  last_update 14\n",
      "train: iter 267  trainloss -1941.82886  validloss -1941.69560±0.00000  bestvalidloss -2053.94924  last_update 15\n",
      "train: iter 268  trainloss -1951.41161  validloss -2039.59761±0.00000  bestvalidloss -2053.94924  last_update 16\n",
      "train: iter 269  trainloss -1975.23827  validloss -2015.59512±0.00000  bestvalidloss -2053.94924  last_update 17\n",
      "train: iter 270  trainloss -1950.18378  validloss -2052.62344±0.00000  bestvalidloss -2053.94924  last_update 18\n",
      "train: iter 271  trainloss -1954.29623  validloss -1964.81337±0.00000  bestvalidloss -2053.94924  last_update 19\n",
      "train: iter 272  trainloss -1993.31483  validloss -2039.02913±0.00000  bestvalidloss -2053.94924  last_update 20\n",
      "train: iter 273  trainloss -1913.85254  validloss -2048.99747±0.00000  bestvalidloss -2053.94924  last_update 21\n",
      "train: iter 274  trainloss -1957.74326  validloss -2011.03413±0.00000  bestvalidloss -2053.94924  last_update 22\n",
      "train: iter 275  trainloss -1976.84574  validloss -2004.48184±0.00000  bestvalidloss -2053.94924  last_update 23\n",
      "train: iter 276  trainloss -2004.76092  validloss -2041.66108±0.00000  bestvalidloss -2053.94924  last_update 24\n",
      "train: iter 277  trainloss -1996.25196  validloss -2051.53712±0.00000  bestvalidloss -2053.94924  last_update 25\n",
      "train: iter 278  trainloss -2003.18073  validloss -2000.06327±0.00000  bestvalidloss -2053.94924  last_update 26\n",
      "train: iter 279  trainloss -1921.32505  validloss -2067.78302±0.00000  bestvalidloss -2067.78302  last_update 0\n",
      "train: iter 280  trainloss -1670.81701  validloss -1746.32806±0.00000  bestvalidloss -2067.78302  last_update 1\n",
      "train: iter 281  trainloss -1949.39649  validloss -2003.61710±0.00000  bestvalidloss -2067.78302  last_update 2\n",
      "train: iter 282  trainloss -1944.82184  validloss -2021.93832±0.00000  bestvalidloss -2067.78302  last_update 3\n",
      "train: iter 283  trainloss -1986.71096  validloss -2047.54526±0.00000  bestvalidloss -2067.78302  last_update 4\n",
      "train: iter 284  trainloss -1952.00463  validloss -2044.91677±0.00000  bestvalidloss -2067.78302  last_update 5\n",
      "train: iter 285  trainloss -1922.56268  validloss -1951.94289±0.00000  bestvalidloss -2067.78302  last_update 6\n",
      "train: iter 286  trainloss -1973.75022  validloss -2046.49464±0.00000  bestvalidloss -2067.78302  last_update 7\n",
      "train: iter 287  trainloss -1999.56998  validloss -2037.15683±0.00000  bestvalidloss -2067.78302  last_update 8\n",
      "train: iter 288  trainloss -1993.97192  validloss -2060.51208±0.00000  bestvalidloss -2067.78302  last_update 9\n",
      "train: iter 289  trainloss -2000.26849  validloss -2022.03302±0.00000  bestvalidloss -2067.78302  last_update 10\n",
      "train: iter 290  trainloss -1978.01524  validloss -2037.82548±0.00000  bestvalidloss -2067.78302  last_update 11\n",
      "train: iter 291  trainloss -1995.06896  validloss -2037.28561±0.00000  bestvalidloss -2067.78302  last_update 12\n",
      "train: iter 292  trainloss -1962.46608  validloss -2065.70715±0.00000  bestvalidloss -2067.78302  last_update 13\n",
      "train: iter 293  trainloss -1995.53597  validloss -2022.81063±0.00000  bestvalidloss -2067.78302  last_update 14\n",
      "train: iter 294  trainloss -2005.44290  validloss -2051.04883±0.00000  bestvalidloss -2067.78302  last_update 15\n",
      "train: iter 295  trainloss -1992.71228  validloss -2034.59460±0.00000  bestvalidloss -2067.78302  last_update 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -1866.88600  validloss -2014.11044±0.00000  bestvalidloss -2067.78302  last_update 17\n",
      "train: iter 297  trainloss -1987.87833  validloss -2031.61054±0.00000  bestvalidloss -2067.78302  last_update 18\n",
      "train: iter 298  trainloss -1959.73317  validloss -2036.12396±0.00000  bestvalidloss -2067.78302  last_update 19\n",
      "train: iter 299  trainloss -1988.35941  validloss -2051.67338±0.00000  bestvalidloss -2067.78302  last_update 20\n",
      "train: iter 300  trainloss -1959.63590  validloss -2002.12250±0.00000  bestvalidloss -2067.78302  last_update 21\n",
      "train: iter 301  trainloss -1978.43756  validloss -2038.55043±0.00000  bestvalidloss -2067.78302  last_update 22\n",
      "train: iter 302  trainloss -1858.14618  validloss -2030.15551±0.00000  bestvalidloss -2067.78302  last_update 23\n",
      "train: iter 303  trainloss -2002.50984  validloss -2060.76373±0.00000  bestvalidloss -2067.78302  last_update 24\n",
      "train: iter 304  trainloss -2008.90878  validloss -2010.31691±0.00000  bestvalidloss -2067.78302  last_update 25\n",
      "train: iter 305  trainloss -1853.65107  validloss -2069.83755±0.00000  bestvalidloss -2069.83755  last_update 0\n",
      "train: iter 306  trainloss -1800.53973  validloss -1514.58569±0.00000  bestvalidloss -2069.83755  last_update 1\n",
      "train: iter 307  trainloss -1971.11610  validloss -2011.86788±0.00000  bestvalidloss -2069.83755  last_update 2\n",
      "train: iter 308  trainloss -1978.61524  validloss -2045.66440±0.00000  bestvalidloss -2069.83755  last_update 3\n",
      "train: iter 309  trainloss -2003.52841  validloss -2007.79579±0.00000  bestvalidloss -2069.83755  last_update 4\n",
      "train: iter 310  trainloss -1976.39061  validloss -2039.23210±0.00000  bestvalidloss -2069.83755  last_update 5\n",
      "train: iter 311  trainloss -1967.74604  validloss -2059.32695±0.00000  bestvalidloss -2069.83755  last_update 6\n",
      "train: iter 312  trainloss -1982.81741  validloss -1970.84026±0.00000  bestvalidloss -2069.83755  last_update 7\n",
      "train: iter 313  trainloss -1998.31081  validloss -2055.22080±0.00000  bestvalidloss -2069.83755  last_update 8\n",
      "train: iter 314  trainloss -1940.89090  validloss -2013.23625±0.00000  bestvalidloss -2069.83755  last_update 9\n",
      "train: iter 315  trainloss -1974.98116  validloss -1936.02414±0.00000  bestvalidloss -2069.83755  last_update 10\n",
      "train: iter 316  trainloss -1983.87837  validloss -2027.61426±0.00000  bestvalidloss -2069.83755  last_update 11\n",
      "train: iter 317  trainloss -2014.75160  validloss -2019.25901±0.00000  bestvalidloss -2069.83755  last_update 12\n",
      "train: iter 318  trainloss -1999.85565  validloss -2060.67857±0.00000  bestvalidloss -2069.83755  last_update 13\n",
      "train: iter 319  trainloss -1979.91972  validloss -2039.21730±0.00000  bestvalidloss -2069.83755  last_update 14\n",
      "train: iter 320  trainloss -1786.63949  validloss -1918.70948±0.00000  bestvalidloss -2069.83755  last_update 15\n",
      "train: iter 321  trainloss -1981.93489  validloss -2012.87875±0.00000  bestvalidloss -2069.83755  last_update 16\n",
      "train: iter 322  trainloss -2000.53683  validloss -2063.46177±0.00000  bestvalidloss -2069.83755  last_update 17\n",
      "train: iter 323  trainloss -2010.70667  validloss -2029.14521±0.00000  bestvalidloss -2069.83755  last_update 18\n",
      "train: iter 324  trainloss -1892.15423  validloss -2048.69907±0.00000  bestvalidloss -2069.83755  last_update 19\n",
      "train: iter 325  trainloss -1835.54250  validloss -1868.15465±0.00000  bestvalidloss -2069.83755  last_update 20\n",
      "train: iter 326  trainloss -1959.93398  validloss -2053.76965±0.00000  bestvalidloss -2069.83755  last_update 21\n",
      "train: iter 327  trainloss -2017.07365  validloss -2021.45004±0.00000  bestvalidloss -2069.83755  last_update 22\n",
      "train: iter 328  trainloss -1952.03959  validloss -2045.45767±0.00000  bestvalidloss -2069.83755  last_update 23\n",
      "train: iter 329  trainloss -1958.69257  validloss -1969.08655±0.00000  bestvalidloss -2069.83755  last_update 24\n",
      "train: iter 330  trainloss -1923.93153  validloss -2003.69594±0.00000  bestvalidloss -2069.83755  last_update 25\n",
      "train: iter 331  trainloss -2020.49459  validloss -2046.32765±0.00000  bestvalidloss -2069.83755  last_update 26\n",
      "train: iter 332  trainloss -1997.42994  validloss -2054.98511±0.00000  bestvalidloss -2069.83755  last_update 27\n",
      "train: iter 333  trainloss -2000.40815  validloss -2070.16788±0.00000  bestvalidloss -2070.16788  last_update 0\n",
      "train: iter 334  trainloss -2008.88876  validloss -2032.82888±0.00000  bestvalidloss -2070.16788  last_update 1\n",
      "train: iter 335  trainloss -2016.80812  validloss -1923.05303±0.00000  bestvalidloss -2070.16788  last_update 2\n",
      "train: iter 336  trainloss -2023.14796  validloss -2043.92728±0.00000  bestvalidloss -2070.16788  last_update 3\n",
      "train: iter 337  trainloss -1937.78941  validloss -1903.48702±0.00000  bestvalidloss -2070.16788  last_update 4\n",
      "train: iter 338  trainloss -1733.49777  validloss -1800.78138±0.00000  bestvalidloss -2070.16788  last_update 5\n",
      "train: iter 339  trainloss -1936.81218  validloss -2020.81873±0.00000  bestvalidloss -2070.16788  last_update 6\n",
      "train: iter 340  trainloss -1988.82883  validloss -2010.43090±0.00000  bestvalidloss -2070.16788  last_update 7\n",
      "train: iter 341  trainloss -1978.76345  validloss -1876.60290±0.00000  bestvalidloss -2070.16788  last_update 8\n",
      "train: iter 342  trainloss -2013.53616  validloss -2060.86665±0.00000  bestvalidloss -2070.16788  last_update 9\n",
      "train: iter 343  trainloss -1996.47795  validloss -2048.59611±0.00000  bestvalidloss -2070.16788  last_update 10\n",
      "train: iter 344  trainloss -1978.97757  validloss -2048.44058±0.00000  bestvalidloss -2070.16788  last_update 11\n",
      "train: iter 345  trainloss -2022.17305  validloss -2000.89102±0.00000  bestvalidloss -2070.16788  last_update 12\n",
      "train: iter 346  trainloss -1977.09801  validloss -2026.37428±0.00000  bestvalidloss -2070.16788  last_update 13\n",
      "train: iter 347  trainloss -2020.15533  validloss -2021.86838±0.00000  bestvalidloss -2070.16788  last_update 14\n",
      "train: iter 348  trainloss -2035.18458  validloss -2012.55951±0.00000  bestvalidloss -2070.16788  last_update 15\n",
      "train: iter 349  trainloss -1996.81961  validloss -2071.54368±0.00000  bestvalidloss -2071.54368  last_update 0\n",
      "train: iter 350  trainloss -2006.04053  validloss -2033.37584±0.00000  bestvalidloss -2071.54368  last_update 1\n",
      "train: iter 351  trainloss -1739.88552  validloss -2050.86875±0.00000  bestvalidloss -2071.54368  last_update 2\n",
      "train: iter 352  trainloss -1985.69017  validloss -1963.76703±0.00000  bestvalidloss -2071.54368  last_update 3\n",
      "train: iter 353  trainloss -2000.25514  validloss -2050.99095±0.00000  bestvalidloss -2071.54368  last_update 4\n",
      "train: iter 354  trainloss -2014.30953  validloss -2012.85632±0.00000  bestvalidloss -2071.54368  last_update 5\n",
      "train: iter 355  trainloss -2010.14365  validloss -2039.47864±0.00000  bestvalidloss -2071.54368  last_update 6\n",
      "train: iter 356  trainloss -2006.61331  validloss -2013.97126±0.00000  bestvalidloss -2071.54368  last_update 7\n",
      "train: iter 357  trainloss -2030.53903  validloss -2048.21342±0.00000  bestvalidloss -2071.54368  last_update 8\n",
      "train: iter 358  trainloss -2018.24434  validloss -2029.37094±0.00000  bestvalidloss -2071.54368  last_update 9\n",
      "train: iter 359  trainloss -1817.38172  validloss -2010.53337±0.00000  bestvalidloss -2071.54368  last_update 10\n",
      "train: iter 360  trainloss -2003.16749  validloss -1980.17654±0.00000  bestvalidloss -2071.54368  last_update 11\n",
      "train: iter 361  trainloss -1983.68896  validloss -2030.19389±0.00000  bestvalidloss -2071.54368  last_update 12\n",
      "train: iter 362  trainloss -2041.33907  validloss -2067.71324±0.00000  bestvalidloss -2071.54368  last_update 13\n",
      "train: iter 363  trainloss -2038.79944  validloss -2073.59838±0.00000  bestvalidloss -2073.59838  last_update 0\n",
      "train: iter 364  trainloss -2038.46899  validloss -2077.12347±0.00000  bestvalidloss -2077.12347  last_update 0\n",
      "train: iter 365  trainloss -2003.33662  validloss -2073.95267±0.00000  bestvalidloss -2077.12347  last_update 1\n",
      "train: iter 366  trainloss -1943.82313  validloss -2025.46316±0.00000  bestvalidloss -2077.12347  last_update 2\n",
      "train: iter 367  trainloss -2012.46026  validloss -1935.66055±0.00000  bestvalidloss -2077.12347  last_update 3\n",
      "train: iter 368  trainloss -1999.06726  validloss -2025.98466±0.00000  bestvalidloss -2077.12347  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -1999.89306  validloss -2070.69756±0.00000  bestvalidloss -2077.12347  last_update 5\n",
      "train: iter 370  trainloss -2004.19011  validloss -2046.36265±0.00000  bestvalidloss -2077.12347  last_update 6\n",
      "train: iter 371  trainloss -1946.16742  validloss -2068.54434±0.00000  bestvalidloss -2077.12347  last_update 7\n",
      "train: iter 372  trainloss -1976.85500  validloss -1946.87269±0.00000  bestvalidloss -2077.12347  last_update 8\n",
      "train: iter 373  trainloss -2006.09865  validloss -2037.00803±0.00000  bestvalidloss -2077.12347  last_update 9\n",
      "train: iter 374  trainloss -2041.41824  validloss -2040.66169±0.00000  bestvalidloss -2077.12347  last_update 10\n",
      "train: iter 375  trainloss -2034.33043  validloss -2081.46097±0.00000  bestvalidloss -2081.46097  last_update 0\n",
      "train: iter 376  trainloss -1882.43757  validloss -2032.33961±0.00000  bestvalidloss -2081.46097  last_update 1\n",
      "train: iter 377  trainloss -1945.09197  validloss -1723.08101±0.00000  bestvalidloss -2081.46097  last_update 2\n",
      "train: iter 378  trainloss -2004.47314  validloss -2022.65405±0.00000  bestvalidloss -2081.46097  last_update 3\n",
      "train: iter 379  trainloss -2033.00952  validloss -2058.37087±0.00000  bestvalidloss -2081.46097  last_update 4\n",
      "train: iter 380  trainloss -2007.63006  validloss -2079.08218±0.00000  bestvalidloss -2081.46097  last_update 5\n",
      "train: iter 381  trainloss -2032.12410  validloss -2033.35691±0.00000  bestvalidloss -2081.46097  last_update 6\n",
      "train: iter 382  trainloss -2014.56798  validloss -2058.04013±0.00000  bestvalidloss -2081.46097  last_update 7\n",
      "train: iter 383  trainloss -2021.81681  validloss -2051.53553±0.00000  bestvalidloss -2081.46097  last_update 8\n",
      "train: iter 384  trainloss -1978.48955  validloss -2025.53495±0.00000  bestvalidloss -2081.46097  last_update 9\n",
      "train: iter 385  trainloss -1944.15032  validloss -1957.39241±0.00000  bestvalidloss -2081.46097  last_update 10\n",
      "train: iter 386  trainloss -1726.02209  validloss -1937.95418±0.00000  bestvalidloss -2081.46097  last_update 11\n",
      "train: iter 387  trainloss -2013.62384  validloss -2058.72126±0.00000  bestvalidloss -2081.46097  last_update 12\n",
      "train: iter 388  trainloss -2032.75860  validloss -2058.36438±0.00000  bestvalidloss -2081.46097  last_update 13\n",
      "train: iter 389  trainloss -2024.24580  validloss -2079.31640±0.00000  bestvalidloss -2081.46097  last_update 14\n",
      "train: iter 390  trainloss -2020.36090  validloss -2020.29148±0.00000  bestvalidloss -2081.46097  last_update 15\n",
      "train: iter 391  trainloss -1976.96823  validloss -2041.35270±0.00000  bestvalidloss -2081.46097  last_update 16\n",
      "train: iter 392  trainloss -1988.23302  validloss -1983.32985±0.00000  bestvalidloss -2081.46097  last_update 17\n",
      "train: iter 393  trainloss -2028.78967  validloss -2059.65991±0.00000  bestvalidloss -2081.46097  last_update 18\n",
      "train: iter 394  trainloss -2036.29213  validloss -2061.91307±0.00000  bestvalidloss -2081.46097  last_update 19\n",
      "train: iter 395  trainloss -2035.65174  validloss -2070.66752±0.00000  bestvalidloss -2081.46097  last_update 20\n",
      "train: iter 396  trainloss -2005.45770  validloss -2069.83804±0.00000  bestvalidloss -2081.46097  last_update 21\n",
      "train: iter 397  trainloss -2031.55201  validloss -2043.98392±0.00000  bestvalidloss -2081.46097  last_update 22\n",
      "train: iter 398  trainloss -2029.93761  validloss -1997.48138±0.00000  bestvalidloss -2081.46097  last_update 23\n",
      "train: iter 399  trainloss -1988.19722  validloss -2049.62656±0.00000  bestvalidloss -2081.46097  last_update 24\n",
      "train: iter 400  trainloss -2020.16736  validloss -1991.36494±0.00000  bestvalidloss -2081.46097  last_update 25\n",
      "train: iter 401  trainloss -2032.57430  validloss -2056.73500±0.00000  bestvalidloss -2081.46097  last_update 26\n",
      "train: iter 402  trainloss -2035.55796  validloss -2039.48091±0.00000  bestvalidloss -2081.46097  last_update 27\n",
      "train: iter 403  trainloss -2004.74279  validloss -2027.24983±0.00000  bestvalidloss -2081.46097  last_update 28\n",
      "train: iter 404  trainloss -2031.43671  validloss -2076.73777±0.00000  bestvalidloss -2081.46097  last_update 29\n",
      "train: iter 405  trainloss -2044.40906  validloss -2067.94384±0.00000  bestvalidloss -2081.46097  last_update 30\n",
      "train: iter 406  trainloss -2036.48122  validloss -2074.25984±0.00000  bestvalidloss -2081.46097  last_update 31\n",
      "train: iter 407  trainloss -1387.89835  validloss -2076.10456±0.00000  bestvalidloss -2081.46097  last_update 32\n",
      "train: iter 408  trainloss -1828.56811  validloss -1743.91773±0.00000  bestvalidloss -2081.46097  last_update 33\n",
      "train: iter 409  trainloss -1985.12591  validloss -2010.44443±0.00000  bestvalidloss -2081.46097  last_update 34\n",
      "train: iter 410  trainloss -1995.17210  validloss -2070.79630±0.00000  bestvalidloss -2081.46097  last_update 35\n",
      "train: iter 411  trainloss -2019.92166  validloss -2039.06147±0.00000  bestvalidloss -2081.46097  last_update 36\n",
      "train: iter 412  trainloss -1989.76838  validloss -2037.61420±0.00000  bestvalidloss -2081.46097  last_update 37\n",
      "train: iter 413  trainloss -2000.44057  validloss -2038.66092±0.00000  bestvalidloss -2081.46097  last_update 38\n",
      "train: iter 414  trainloss -2029.41501  validloss -2079.49019±0.00000  bestvalidloss -2081.46097  last_update 39\n",
      "train: iter 415  trainloss -2040.19578  validloss -2078.55780±0.00000  bestvalidloss -2081.46097  last_update 40\n",
      "train: iter 416  trainloss -1894.73341  validloss -2078.61620±0.00000  bestvalidloss -2081.46097  last_update 41\n",
      "train: iter 417  trainloss -2027.44896  validloss -2062.80706±0.00000  bestvalidloss -2081.46097  last_update 42\n",
      "train: iter 418  trainloss -2032.72039  validloss -2073.45563±0.00000  bestvalidloss -2081.46097  last_update 43\n",
      "train: iter 419  trainloss -2046.24705  validloss -2073.52088±0.00000  bestvalidloss -2081.46097  last_update 44\n",
      "train: iter 420  trainloss -2013.75338  validloss -2082.59026±0.00000  bestvalidloss -2082.59026  last_update 0\n",
      "train: iter 421  trainloss -2033.49637  validloss -2062.30085±0.00000  bestvalidloss -2082.59026  last_update 1\n",
      "train: iter 422  trainloss -2029.51124  validloss -2065.56497±0.00000  bestvalidloss -2082.59026  last_update 2\n",
      "train: iter 423  trainloss -2024.27729  validloss -2027.56108±0.00000  bestvalidloss -2082.59026  last_update 3\n",
      "train: iter 424  trainloss -2030.61870  validloss -2061.59125±0.00000  bestvalidloss -2082.59026  last_update 4\n",
      "train: iter 425  trainloss -2039.45407  validloss -2052.75351±0.00000  bestvalidloss -2082.59026  last_update 5\n",
      "train: iter 426  trainloss -2061.67379  validloss -2056.71202±0.00000  bestvalidloss -2082.59026  last_update 6\n",
      "train: iter 427  trainloss -1945.00253  validloss -2093.65156±0.00000  bestvalidloss -2093.65156  last_update 0\n",
      "train: iter 428  trainloss -2008.86808  validloss -2018.19108±0.00000  bestvalidloss -2093.65156  last_update 1\n",
      "train: iter 429  trainloss -2045.97721  validloss -2079.27904±0.00000  bestvalidloss -2093.65156  last_update 2\n",
      "train: iter 430  trainloss -1968.60156  validloss -2052.28117±0.00000  bestvalidloss -2093.65156  last_update 3\n",
      "train: iter 431  trainloss -2032.94514  validloss -2095.59241±0.00000  bestvalidloss -2095.59241  last_update 0\n",
      "train: iter 432  trainloss -2003.20343  validloss -2017.69373±0.00000  bestvalidloss -2095.59241  last_update 1\n",
      "train: iter 433  trainloss -2021.04387  validloss -2071.82545±0.00000  bestvalidloss -2095.59241  last_update 2\n",
      "train: iter 434  trainloss -2034.74964  validloss -2089.71979±0.00000  bestvalidloss -2095.59241  last_update 3\n",
      "train: iter 435  trainloss -1996.83289  validloss -2050.29634±0.00000  bestvalidloss -2095.59241  last_update 4\n",
      "train: iter 436  trainloss -1986.57398  validloss -2080.06208±0.00000  bestvalidloss -2095.59241  last_update 5\n",
      "train: iter 437  trainloss -2007.82917  validloss -2040.23513±0.00000  bestvalidloss -2095.59241  last_update 6\n",
      "train: iter 438  trainloss -1954.70614  validloss -1980.16136±0.00000  bestvalidloss -2095.59241  last_update 7\n",
      "train: iter 439  trainloss -1938.53947  validloss -1950.76368±0.00000  bestvalidloss -2095.59241  last_update 8\n",
      "train: iter 440  trainloss -2025.70203  validloss -2075.62993±0.00000  bestvalidloss -2095.59241  last_update 9\n",
      "train: iter 441  trainloss -2037.76362  validloss -2069.85681±0.00000  bestvalidloss -2095.59241  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 442  trainloss -2045.02856  validloss -2090.45513±0.00000  bestvalidloss -2095.59241  last_update 11\n",
      "train: iter 443  trainloss -2058.17676  validloss -2081.36866±0.00000  bestvalidloss -2095.59241  last_update 12\n",
      "train: iter 444  trainloss -2059.14861  validloss -2072.39702±0.00000  bestvalidloss -2095.59241  last_update 13\n",
      "train: iter 445  trainloss -2060.93864  validloss -2069.31141±0.00000  bestvalidloss -2095.59241  last_update 14\n",
      "train: iter 446  trainloss -2037.34765  validloss -2082.66949±0.00000  bestvalidloss -2095.59241  last_update 15\n",
      "train: iter 447  trainloss -2041.68016  validloss -2070.46690±0.00000  bestvalidloss -2095.59241  last_update 16\n",
      "train: iter 448  trainloss -1977.63928  validloss -2010.03268±0.00000  bestvalidloss -2095.59241  last_update 17\n",
      "train: iter 449  trainloss -2019.74066  validloss -2021.70428±0.00000  bestvalidloss -2095.59241  last_update 18\n",
      "train: iter 450  trainloss -2032.31177  validloss -2035.72972±0.00000  bestvalidloss -2095.59241  last_update 19\n",
      "train: iter 451  trainloss -1960.09591  validloss -1961.25344±0.00000  bestvalidloss -2095.59241  last_update 20\n",
      "train: iter 452  trainloss -2009.45973  validloss -2043.90069±0.00000  bestvalidloss -2095.59241  last_update 21\n",
      "train: iter 453  trainloss -2010.78382  validloss -2079.56453±0.00000  bestvalidloss -2095.59241  last_update 22\n",
      "train: iter 454  trainloss -2060.39647  validloss -2058.42744±0.00000  bestvalidloss -2095.59241  last_update 23\n",
      "train: iter 455  trainloss -2011.94192  validloss -2094.29999±0.00000  bestvalidloss -2095.59241  last_update 24\n",
      "train: iter 456  trainloss -2015.62389  validloss -2068.81201±0.00000  bestvalidloss -2095.59241  last_update 25\n",
      "train: iter 457  trainloss -2048.72899  validloss -2093.27910±0.00000  bestvalidloss -2095.59241  last_update 26\n",
      "train: iter 458  trainloss -2053.65033  validloss -2081.70386±0.00000  bestvalidloss -2095.59241  last_update 27\n",
      "train: iter 459  trainloss -1986.99169  validloss -2069.68454±0.00000  bestvalidloss -2095.59241  last_update 28\n",
      "train: iter 460  trainloss -2043.40382  validloss -2065.96509±0.00000  bestvalidloss -2095.59241  last_update 29\n",
      "train: iter 461  trainloss -2038.94427  validloss -2086.50807±0.00000  bestvalidloss -2095.59241  last_update 30\n",
      "train: iter 462  trainloss -2018.79096  validloss -2065.40837±0.00000  bestvalidloss -2095.59241  last_update 31\n",
      "train: iter 463  trainloss -2036.02935  validloss -2037.88056±0.00000  bestvalidloss -2095.59241  last_update 32\n",
      "train: iter 464  trainloss -2061.19654  validloss -2101.86120±0.00000  bestvalidloss -2101.86120  last_update 0\n",
      "train: iter 465  trainloss -1909.14498  validloss -2074.56650±0.00000  bestvalidloss -2101.86120  last_update 1\n",
      "train: iter 466  trainloss -1924.95458  validloss -1944.72982±0.00000  bestvalidloss -2101.86120  last_update 2\n",
      "train: iter 467  trainloss -2007.98708  validloss -2054.50491±0.00000  bestvalidloss -2101.86120  last_update 3\n",
      "train: iter 468  trainloss -2040.04397  validloss -2061.01583±0.00000  bestvalidloss -2101.86120  last_update 4\n",
      "train: iter 469  trainloss -2044.24933  validloss -2095.87184±0.00000  bestvalidloss -2101.86120  last_update 5\n",
      "train: iter 470  trainloss -1923.02862  validloss -2031.73842±0.00000  bestvalidloss -2101.86120  last_update 6\n",
      "train: iter 471  trainloss -2018.96170  validloss -2046.15002±0.00000  bestvalidloss -2101.86120  last_update 7\n",
      "train: iter 472  trainloss -2052.41620  validloss -2094.81970±0.00000  bestvalidloss -2101.86120  last_update 8\n",
      "train: iter 473  trainloss -2041.70240  validloss -2066.38582±0.00000  bestvalidloss -2101.86120  last_update 9\n",
      "train: iter 474  trainloss -2029.07002  validloss -2084.00759±0.00000  bestvalidloss -2101.86120  last_update 10\n",
      "train: iter 475  trainloss -2041.28113  validloss -2070.77064±0.00000  bestvalidloss -2101.86120  last_update 11\n",
      "train: iter 476  trainloss -2012.83900  validloss -2095.09655±0.00000  bestvalidloss -2101.86120  last_update 12\n",
      "train: iter 477  trainloss -2059.23096  validloss -2079.59416±0.00000  bestvalidloss -2101.86120  last_update 13\n",
      "train: iter 478  trainloss -2059.73952  validloss -2089.94080±0.00000  bestvalidloss -2101.86120  last_update 14\n",
      "train: iter 479  trainloss -1958.01302  validloss -1955.96005±0.00000  bestvalidloss -2101.86120  last_update 15\n",
      "train: iter 480  trainloss -2061.65265  validloss -2062.89423±0.00000  bestvalidloss -2101.86120  last_update 16\n",
      "train: iter 481  trainloss -2010.94279  validloss -2043.67303±0.00000  bestvalidloss -2101.86120  last_update 17\n",
      "train: iter 482  trainloss -2056.46844  validloss -2048.23673±0.00000  bestvalidloss -2101.86120  last_update 18\n",
      "train: iter 483  trainloss -2076.66698  validloss -2099.40242±0.00000  bestvalidloss -2101.86120  last_update 19\n",
      "train: iter 484  trainloss -2075.01910  validloss -2101.42337±0.00000  bestvalidloss -2101.86120  last_update 20\n",
      "train: iter 485  trainloss -2001.67058  validloss -2069.77426±0.00000  bestvalidloss -2101.86120  last_update 21\n",
      "train: iter 486  trainloss -2055.53379  validloss -2066.13627±0.00000  bestvalidloss -2101.86120  last_update 22\n",
      "train: iter 487  trainloss -2068.67684  validloss -2087.89838±0.00000  bestvalidloss -2101.86120  last_update 23\n",
      "train: iter 488  trainloss -1924.05717  validloss -1997.09316±0.00000  bestvalidloss -2101.86120  last_update 24\n",
      "train: iter 489  trainloss -1918.09626  validloss -1615.34448±0.00000  bestvalidloss -2101.86120  last_update 25\n",
      "train: iter 490  trainloss -2051.48271  validloss -2074.71532±0.00000  bestvalidloss -2101.86120  last_update 26\n",
      "train: iter 491  trainloss -2068.49837  validloss -2082.34511±0.00000  bestvalidloss -2101.86120  last_update 27\n",
      "train: iter 492  trainloss -2058.19481  validloss -2056.37625±0.00000  bestvalidloss -2101.86120  last_update 28\n",
      "train: iter 493  trainloss -2065.95861  validloss -2090.90353±0.00000  bestvalidloss -2101.86120  last_update 29\n",
      "train: iter 494  trainloss -2068.96958  validloss -2071.45756±0.00000  bestvalidloss -2101.86120  last_update 30\n",
      "train: iter 495  trainloss -2065.23033  validloss -2103.29470±0.00000  bestvalidloss -2103.29470  last_update 0\n",
      "train: iter 496  trainloss -2072.49311  validloss -2099.96503±0.00000  bestvalidloss -2103.29470  last_update 1\n",
      "train: iter 497  trainloss -1875.35997  validloss -2089.15338±0.00000  bestvalidloss -2103.29470  last_update 2\n",
      "train: iter 498  trainloss -1711.03265  validloss -1928.78577±0.00000  bestvalidloss -2103.29470  last_update 3\n",
      "train: iter 499  trainloss -2028.20769  validloss -2039.20356±0.00000  bestvalidloss -2103.29470  last_update 4\n",
      "train: iter 500  trainloss -2045.73202  validloss -2088.98781±0.00000  bestvalidloss -2103.29470  last_update 5\n",
      "train: iter 501  trainloss -2069.25450  validloss -2086.83358±0.00000  bestvalidloss -2103.29470  last_update 6\n",
      "train: iter 502  trainloss -2057.90113  validloss -2098.97263±0.00000  bestvalidloss -2103.29470  last_update 7\n",
      "train: iter 503  trainloss -2076.39260  validloss -2086.01160±0.00000  bestvalidloss -2103.29470  last_update 8\n",
      "train: iter 504  trainloss -2071.33807  validloss -2096.00806±0.00000  bestvalidloss -2103.29470  last_update 9\n",
      "train: iter 505  trainloss -2062.69260  validloss -2105.66525±0.00000  bestvalidloss -2105.66525  last_update 0\n",
      "train: iter 506  trainloss -2057.17896  validloss -2045.51506±0.00000  bestvalidloss -2105.66525  last_update 1\n",
      "train: iter 507  trainloss -2040.90580  validloss -2081.22650±0.00000  bestvalidloss -2105.66525  last_update 2\n",
      "train: iter 508  trainloss -1853.88967  validloss -2094.80479±0.00000  bestvalidloss -2105.66525  last_update 3\n",
      "train: iter 509  trainloss -1979.16332  validloss -1976.79164±0.00000  bestvalidloss -2105.66525  last_update 4\n",
      "train: iter 510  trainloss -2026.69242  validloss -2049.06370±0.00000  bestvalidloss -2105.66525  last_update 5\n",
      "train: iter 511  trainloss -2055.76018  validloss -2078.93930±0.00000  bestvalidloss -2105.66525  last_update 6\n",
      "train: iter 512  trainloss -2057.57198  validloss -2075.79680±0.00000  bestvalidloss -2105.66525  last_update 7\n",
      "train: iter 513  trainloss -2051.94669  validloss -2093.18680±0.00000  bestvalidloss -2105.66525  last_update 8\n",
      "train: iter 514  trainloss -2034.11640  validloss -2044.47288±0.00000  bestvalidloss -2105.66525  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 515  trainloss -2054.05681  validloss -2078.61642±0.00000  bestvalidloss -2105.66525  last_update 10\n",
      "train: iter 516  trainloss -2075.06033  validloss -2102.27964±0.00000  bestvalidloss -2105.66525  last_update 11\n",
      "train: iter 517  trainloss -1974.67318  validloss -2081.48633±0.00000  bestvalidloss -2105.66525  last_update 12\n",
      "train: iter 518  trainloss -2008.38617  validloss -2075.60179±0.00000  bestvalidloss -2105.66525  last_update 13\n",
      "train: iter 519  trainloss -2059.10508  validloss -2069.82126±0.00000  bestvalidloss -2105.66525  last_update 14\n",
      "train: iter 520  trainloss -2076.36759  validloss -2098.42325±0.00000  bestvalidloss -2105.66525  last_update 15\n",
      "train: iter 521  trainloss -2049.67649  validloss -2095.12773±0.00000  bestvalidloss -2105.66525  last_update 16\n",
      "train: iter 522  trainloss -2069.94314  validloss -2051.36115±0.00000  bestvalidloss -2105.66525  last_update 17\n",
      "train: iter 523  trainloss -1978.43494  validloss -2097.33707±0.00000  bestvalidloss -2105.66525  last_update 18\n",
      "train: iter 524  trainloss -2045.18472  validloss -2064.66836±0.00000  bestvalidloss -2105.66525  last_update 19\n",
      "train: iter 525  trainloss -2063.77268  validloss -2097.05072±0.00000  bestvalidloss -2105.66525  last_update 20\n",
      "train: iter 526  trainloss -2067.53183  validloss -2021.24454±0.00000  bestvalidloss -2105.66525  last_update 21\n",
      "train: iter 527  trainloss -2031.76374  validloss -2061.89894±0.00000  bestvalidloss -2105.66525  last_update 22\n",
      "train: iter 528  trainloss -2033.45630  validloss -2038.60388±0.00000  bestvalidloss -2105.66525  last_update 23\n",
      "train: iter 529  trainloss -2044.69878  validloss -2079.71056±0.00000  bestvalidloss -2105.66525  last_update 24\n",
      "train: iter 530  trainloss -2018.92732  validloss -2099.30909±0.00000  bestvalidloss -2105.66525  last_update 25\n",
      "train: iter 531  trainloss -2077.42998  validloss -2078.61759±0.00000  bestvalidloss -2105.66525  last_update 26\n",
      "train: iter 532  trainloss -2063.54955  validloss -2064.11746±0.00000  bestvalidloss -2105.66525  last_update 27\n",
      "train: iter 533  trainloss -2024.31608  validloss -2099.13745±0.00000  bestvalidloss -2105.66525  last_update 28\n",
      "train: iter 534  trainloss -2054.11268  validloss -2065.45911±0.00000  bestvalidloss -2105.66525  last_update 29\n",
      "train: iter 535  trainloss -2047.02274  validloss -2039.38424±0.00000  bestvalidloss -2105.66525  last_update 30\n",
      "train: iter 536  trainloss -2060.22144  validloss -2095.27184±0.00000  bestvalidloss -2105.66525  last_update 31\n",
      "train: iter 537  trainloss -2038.92717  validloss -2094.20809±0.00000  bestvalidloss -2105.66525  last_update 32\n",
      "train: iter 538  trainloss -2047.15193  validloss -2041.55400±0.00000  bestvalidloss -2105.66525  last_update 33\n",
      "train: iter 539  trainloss -2081.44818  validloss -2098.07521±0.00000  bestvalidloss -2105.66525  last_update 34\n",
      "train: iter 540  trainloss -2080.72692  validloss -2106.11286±0.00000  bestvalidloss -2106.11286  last_update 0\n",
      "train: iter 541  trainloss -2063.71409  validloss -2098.18362±0.00000  bestvalidloss -2106.11286  last_update 1\n",
      "train: iter 542  trainloss -1950.84865  validloss -2065.69373±0.00000  bestvalidloss -2106.11286  last_update 2\n",
      "train: iter 543  trainloss -2052.62824  validloss -2064.96318±0.00000  bestvalidloss -2106.11286  last_update 3\n",
      "train: iter 544  trainloss -2047.67592  validloss -2060.37183±0.00000  bestvalidloss -2106.11286  last_update 4\n",
      "train: iter 545  trainloss -2068.38134  validloss -2054.59237±0.00000  bestvalidloss -2106.11286  last_update 5\n",
      "train: iter 546  trainloss -2049.22635  validloss -2088.27740±0.00000  bestvalidloss -2106.11286  last_update 6\n",
      "train: iter 547  trainloss -1972.88912  validloss -2090.06659±0.00000  bestvalidloss -2106.11286  last_update 7\n",
      "train: iter 548  trainloss -2001.30077  validloss -1979.06301±0.00000  bestvalidloss -2106.11286  last_update 8\n",
      "train: iter 549  trainloss -2065.93443  validloss -2067.46573±0.00000  bestvalidloss -2106.11286  last_update 9\n",
      "train: iter 550  trainloss -2069.55200  validloss -2088.10421±0.00000  bestvalidloss -2106.11286  last_update 10\n",
      "train: iter 551  trainloss -2059.96625  validloss -2091.20441±0.00000  bestvalidloss -2106.11286  last_update 11\n",
      "train: iter 552  trainloss -2010.56326  validloss -2032.74297±0.00000  bestvalidloss -2106.11286  last_update 12\n",
      "train: iter 553  trainloss -2024.40745  validloss -2059.34053±0.00000  bestvalidloss -2106.11286  last_update 13\n",
      "train: iter 554  trainloss -2081.86901  validloss -2082.33241±0.00000  bestvalidloss -2106.11286  last_update 14\n",
      "train: iter 555  trainloss -2069.17959  validloss -2026.44409±0.00000  bestvalidloss -2106.11286  last_update 15\n",
      "train: iter 556  trainloss -2054.54889  validloss -2102.66162±0.00000  bestvalidloss -2106.11286  last_update 16\n",
      "train: iter 557  trainloss -2024.93607  validloss -1894.38676±0.00000  bestvalidloss -2106.11286  last_update 17\n",
      "train: iter 558  trainloss -2079.27818  validloss -2073.45800±0.00000  bestvalidloss -2106.11286  last_update 18\n",
      "train: iter 559  trainloss -2067.85742  validloss -2084.87247±0.00000  bestvalidloss -2106.11286  last_update 19\n",
      "train: iter 560  trainloss -1925.87231  validloss -2056.94926±0.00000  bestvalidloss -2106.11286  last_update 20\n",
      "train: iter 561  trainloss -1925.29384  validloss -1991.15387±0.00000  bestvalidloss -2106.11286  last_update 21\n",
      "train: iter 562  trainloss -2062.41099  validloss -2108.50208±0.00000  bestvalidloss -2108.50208  last_update 0\n",
      "train: iter 563  trainloss -2065.31925  validloss -2026.78575±0.00000  bestvalidloss -2108.50208  last_update 1\n",
      "train: iter 564  trainloss -2079.99491  validloss -2019.53209±0.00000  bestvalidloss -2108.50208  last_update 2\n",
      "train: iter 565  trainloss -2014.00809  validloss -2100.88391±0.00000  bestvalidloss -2108.50208  last_update 3\n",
      "train: iter 566  trainloss -2014.47813  validloss -2092.66318±0.00000  bestvalidloss -2108.50208  last_update 4\n",
      "train: iter 567  trainloss -2065.84153  validloss -2094.40380±0.00000  bestvalidloss -2108.50208  last_update 5\n",
      "train: iter 568  trainloss -2077.30596  validloss -2103.39463±0.00000  bestvalidloss -2108.50208  last_update 6\n",
      "train: iter 569  trainloss -2075.03520  validloss -2082.57790±0.00000  bestvalidloss -2108.50208  last_update 7\n",
      "train: iter 570  trainloss -2090.47302  validloss -2077.73415±0.00000  bestvalidloss -2108.50208  last_update 8\n",
      "train: iter 571  trainloss -2091.50260  validloss -2105.21091±0.00000  bestvalidloss -2108.50208  last_update 9\n",
      "train: iter 572  trainloss -1994.79967  validloss -2110.82211±0.00000  bestvalidloss -2110.82211  last_update 0\n",
      "train: iter 573  trainloss -1781.65938  validloss -2042.13383±0.00000  bestvalidloss -2110.82211  last_update 1\n",
      "train: iter 574  trainloss -2079.60911  validloss -2081.67389±0.00000  bestvalidloss -2110.82211  last_update 2\n",
      "train: iter 575  trainloss -2072.24169  validloss -2068.59683±0.00000  bestvalidloss -2110.82211  last_update 3\n",
      "train: iter 576  trainloss -2031.18990  validloss -2086.63325±0.00000  bestvalidloss -2110.82211  last_update 4\n",
      "train: iter 577  trainloss -2074.11611  validloss -2081.35872±0.00000  bestvalidloss -2110.82211  last_update 5\n",
      "train: iter 578  trainloss -2082.77066  validloss -2104.03445±0.00000  bestvalidloss -2110.82211  last_update 6\n",
      "train: iter 579  trainloss -2069.93282  validloss -2089.06531±0.00000  bestvalidloss -2110.82211  last_update 7\n",
      "train: iter 580  trainloss -2078.71238  validloss -2097.15956±0.00000  bestvalidloss -2110.82211  last_update 8\n",
      "train: iter 581  trainloss -2084.02340  validloss -2107.13764±0.00000  bestvalidloss -2110.82211  last_update 9\n",
      "train: iter 582  trainloss -2076.31915  validloss -2085.80139±0.00000  bestvalidloss -2110.82211  last_update 10\n",
      "train: iter 583  trainloss -2031.10061  validloss -2089.52640±0.00000  bestvalidloss -2110.82211  last_update 11\n",
      "train: iter 584  trainloss -2046.35781  validloss -2000.10272±0.00000  bestvalidloss -2110.82211  last_update 12\n",
      "train: iter 585  trainloss -2072.18040  validloss -2069.68757±0.00000  bestvalidloss -2110.82211  last_update 13\n",
      "train: iter 586  trainloss -2085.82141  validloss -2101.85128±0.00000  bestvalidloss -2110.82211  last_update 14\n",
      "train: iter 587  trainloss -1993.16505  validloss -2080.11309±0.00000  bestvalidloss -2110.82211  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 588  trainloss -2015.04977  validloss -1985.10687±0.00000  bestvalidloss -2110.82211  last_update 16\n",
      "train: iter 589  trainloss -2072.34436  validloss -2057.02337±0.00000  bestvalidloss -2110.82211  last_update 17\n",
      "train: iter 590  trainloss -2073.57883  validloss -2091.95955±0.00000  bestvalidloss -2110.82211  last_update 18\n",
      "train: iter 591  trainloss -2056.47641  validloss -2086.16995±0.00000  bestvalidloss -2110.82211  last_update 19\n",
      "train: iter 592  trainloss -2076.17109  validloss -2098.96245±0.00000  bestvalidloss -2110.82211  last_update 20\n",
      "train: iter 593  trainloss -2081.41093  validloss -2095.43577±0.00000  bestvalidloss -2110.82211  last_update 21\n",
      "train: iter 594  trainloss -2034.58056  validloss -2073.05308±0.00000  bestvalidloss -2110.82211  last_update 22\n",
      "train: iter 595  trainloss -2014.67827  validloss -2037.28626±0.00000  bestvalidloss -2110.82211  last_update 23\n",
      "train: iter 596  trainloss -2074.09043  validloss -2094.00157±0.00000  bestvalidloss -2110.82211  last_update 24\n",
      "train: iter 597  trainloss -2078.29927  validloss -2107.87147±0.00000  bestvalidloss -2110.82211  last_update 25\n",
      "train: iter 598  trainloss -2084.07842  validloss -2069.67812±0.00000  bestvalidloss -2110.82211  last_update 26\n",
      "train: iter 599  trainloss -2077.45408  validloss -2101.26470±0.00000  bestvalidloss -2110.82211  last_update 27\n",
      "train: iter 600  trainloss -2075.84933  validloss -2060.77094±0.00000  bestvalidloss -2110.82211  last_update 28\n",
      "train: iter 601  trainloss -2100.78478  validloss -2110.73043±0.00000  bestvalidloss -2110.82211  last_update 29\n",
      "train: iter 602  trainloss -2085.29112  validloss -2092.43054±0.00000  bestvalidloss -2110.82211  last_update 30\n",
      "train: iter 603  trainloss -1849.86423  validloss -2099.60412±0.00000  bestvalidloss -2110.82211  last_update 31\n",
      "train: iter 604  trainloss -2058.65645  validloss -2071.86732±0.00000  bestvalidloss -2110.82211  last_update 32\n",
      "train: iter 605  trainloss -2078.24032  validloss -2098.75826±0.00000  bestvalidloss -2110.82211  last_update 33\n",
      "train: iter 606  trainloss -2082.38369  validloss -2085.86401±0.00000  bestvalidloss -2110.82211  last_update 34\n",
      "train: iter 607  trainloss -2076.24420  validloss -2101.30054±0.00000  bestvalidloss -2110.82211  last_update 35\n",
      "train: iter 608  trainloss -2063.97869  validloss -2027.69040±0.00000  bestvalidloss -2110.82211  last_update 36\n",
      "train: iter 609  trainloss -2073.51873  validloss -2109.30088±0.00000  bestvalidloss -2110.82211  last_update 37\n",
      "train: iter 610  trainloss -2075.87774  validloss -2112.90820±0.00000  bestvalidloss -2112.90820  last_update 0\n",
      "train: iter 611  trainloss -2061.09073  validloss -1995.29271±0.00000  bestvalidloss -2112.90820  last_update 1\n",
      "train: iter 612  trainloss -2068.30145  validloss -2097.58812±0.00000  bestvalidloss -2112.90820  last_update 2\n",
      "train: iter 613  trainloss -1885.97409  validloss -2043.99220±0.00000  bestvalidloss -2112.90820  last_update 3\n",
      "train: iter 614  trainloss -2050.53099  validloss -2074.99037±0.00000  bestvalidloss -2112.90820  last_update 4\n",
      "train: iter 615  trainloss -2081.16134  validloss -2032.50662±0.00000  bestvalidloss -2112.90820  last_update 5\n",
      "train: iter 616  trainloss -2085.73022  validloss -2098.27870±0.00000  bestvalidloss -2112.90820  last_update 6\n",
      "train: iter 617  trainloss -2098.69595  validloss -2110.08811±0.00000  bestvalidloss -2112.90820  last_update 7\n",
      "train: iter 618  trainloss -2082.60467  validloss -2120.12123±0.00000  bestvalidloss -2120.12123  last_update 0\n",
      "train: iter 619  trainloss -2026.60956  validloss -2082.88757±0.00000  bestvalidloss -2120.12123  last_update 1\n",
      "train: iter 620  trainloss -2060.82264  validloss -2088.98565±0.00000  bestvalidloss -2120.12123  last_update 2\n",
      "train: iter 621  trainloss -2038.98245  validloss -2095.48251±0.00000  bestvalidloss -2120.12123  last_update 3\n",
      "train: iter 622  trainloss -2073.95041  validloss -2069.92621±0.00000  bestvalidloss -2120.12123  last_update 4\n",
      "train: iter 623  trainloss -2078.49029  validloss -2092.75486±0.00000  bestvalidloss -2120.12123  last_update 5\n",
      "train: iter 624  trainloss -2077.48071  validloss -2065.84200±0.00000  bestvalidloss -2120.12123  last_update 6\n",
      "train: iter 625  trainloss -2075.62441  validloss -2087.36288±0.00000  bestvalidloss -2120.12123  last_update 7\n",
      "train: iter 626  trainloss -2070.51084  validloss -2101.98729±0.00000  bestvalidloss -2120.12123  last_update 8\n",
      "train: iter 627  trainloss -2070.21573  validloss -2111.79888±0.00000  bestvalidloss -2120.12123  last_update 9\n",
      "train: iter 628  trainloss -2049.56824  validloss -2099.18892±0.00000  bestvalidloss -2120.12123  last_update 10\n",
      "train: iter 629  trainloss -2042.07670  validloss -2058.25096±0.00000  bestvalidloss -2120.12123  last_update 11\n",
      "train: iter 630  trainloss -2072.32499  validloss -2041.91372±0.00000  bestvalidloss -2120.12123  last_update 12\n",
      "train: iter 631  trainloss -2106.55069  validloss -2104.54583±0.00000  bestvalidloss -2120.12123  last_update 13\n",
      "train: iter 632  trainloss -2069.43802  validloss -2086.36907±0.00000  bestvalidloss -2120.12123  last_update 14\n",
      "train: iter 633  trainloss -2072.49962  validloss -2105.11057±0.00000  bestvalidloss -2120.12123  last_update 15\n",
      "train: iter 634  trainloss -2077.91862  validloss -2095.07428±0.00000  bestvalidloss -2120.12123  last_update 16\n",
      "train: iter 635  trainloss -2092.54481  validloss -2063.70604±0.00000  bestvalidloss -2120.12123  last_update 17\n",
      "train: iter 636  trainloss -2001.60117  validloss -2067.13891±0.00000  bestvalidloss -2120.12123  last_update 18\n",
      "train: iter 637  trainloss -2050.70748  validloss -2039.80736±0.00000  bestvalidloss -2120.12123  last_update 19\n",
      "train: iter 638  trainloss -2072.32149  validloss -2093.49121±0.00000  bestvalidloss -2120.12123  last_update 20\n",
      "train: iter 639  trainloss -1952.85884  validloss -2097.07024±0.00000  bestvalidloss -2120.12123  last_update 21\n",
      "train: iter 640  trainloss -2027.12132  validloss -2032.96752±0.00000  bestvalidloss -2120.12123  last_update 22\n",
      "train: iter 641  trainloss -2100.08770  validloss -2121.68607±0.00000  bestvalidloss -2121.68607  last_update 0\n",
      "train: iter 642  trainloss -2093.71163  validloss -2105.37977±0.00000  bestvalidloss -2121.68607  last_update 1\n",
      "train: iter 643  trainloss -2099.01313  validloss -2123.40038±0.00000  bestvalidloss -2123.40038  last_update 0\n",
      "train: iter 644  trainloss -2089.21256  validloss -2093.63359±0.00000  bestvalidloss -2123.40038  last_update 1\n",
      "train: iter 645  trainloss -2055.12923  validloss -2046.84042±0.00000  bestvalidloss -2123.40038  last_update 2\n",
      "train: iter 646  trainloss -2090.90316  validloss -2056.61791±0.00000  bestvalidloss -2123.40038  last_update 3\n",
      "train: iter 647  trainloss -2095.96240  validloss -2112.08605±0.00000  bestvalidloss -2123.40038  last_update 4\n",
      "train: iter 648  trainloss -2085.74154  validloss -2116.46754±0.00000  bestvalidloss -2123.40038  last_update 5\n",
      "train: iter 649  trainloss -2078.88382  validloss -2056.33500±0.00000  bestvalidloss -2123.40038  last_update 6\n",
      "train: iter 650  trainloss -2056.29035  validloss -2093.07496±0.00000  bestvalidloss -2123.40038  last_update 7\n",
      "train: iter 651  trainloss -2011.38352  validloss -2060.10444±0.00000  bestvalidloss -2123.40038  last_update 8\n",
      "train: iter 652  trainloss -2087.55055  validloss -2069.39742±0.00000  bestvalidloss -2123.40038  last_update 9\n",
      "train: iter 653  trainloss -2059.71709  validloss -2010.53181±0.00000  bestvalidloss -2123.40038  last_update 10\n",
      "train: iter 654  trainloss -2031.62129  validloss -2105.93989±0.00000  bestvalidloss -2123.40038  last_update 11\n",
      "train: iter 655  trainloss -2037.39714  validloss -1966.30655±0.00000  bestvalidloss -2123.40038  last_update 12\n",
      "train: iter 656  trainloss -2102.26162  validloss -2112.81457±0.00000  bestvalidloss -2123.40038  last_update 13\n",
      "train: iter 657  trainloss -2098.74402  validloss -2091.41345±0.00000  bestvalidloss -2123.40038  last_update 14\n",
      "train: iter 658  trainloss -2084.03316  validloss -2125.30532±0.00000  bestvalidloss -2125.30532  last_update 0\n",
      "train: iter 659  trainloss -2073.34137  validloss -2061.89766±0.00000  bestvalidloss -2125.30532  last_update 1\n",
      "train: iter 660  trainloss -2101.94434  validloss -2110.77793±0.00000  bestvalidloss -2125.30532  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 661  trainloss -2021.18657  validloss -2062.94470±0.00000  bestvalidloss -2125.30532  last_update 3\n",
      "train: iter 662  trainloss -1866.39100  validloss -2031.40843±0.00000  bestvalidloss -2125.30532  last_update 4\n",
      "train: iter 663  trainloss -2072.88052  validloss -2096.07428±0.00000  bestvalidloss -2125.30532  last_update 5\n",
      "train: iter 664  trainloss -2086.77501  validloss -2110.29614±0.00000  bestvalidloss -2125.30532  last_update 6\n",
      "train: iter 665  trainloss -2093.30462  validloss -2078.86414±0.00000  bestvalidloss -2125.30532  last_update 7\n",
      "train: iter 666  trainloss -2084.12652  validloss -2098.17617±0.00000  bestvalidloss -2125.30532  last_update 8\n",
      "train: iter 667  trainloss -2090.14101  validloss -2093.33058±0.00000  bestvalidloss -2125.30532  last_update 9\n",
      "train: iter 668  trainloss -2091.59654  validloss -2092.59772±0.00000  bestvalidloss -2125.30532  last_update 10\n",
      "train: iter 669  trainloss -2050.48010  validloss -2063.83721±0.00000  bestvalidloss -2125.30532  last_update 11\n",
      "train: iter 670  trainloss -2078.03279  validloss -2068.66726±0.00000  bestvalidloss -2125.30532  last_update 12\n",
      "train: iter 671  trainloss -2105.17052  validloss -2109.37383±0.00000  bestvalidloss -2125.30532  last_update 13\n",
      "train: iter 672  trainloss -2095.62396  validloss -2125.48281±0.00000  bestvalidloss -2125.48281  last_update 0\n",
      "train: iter 673  trainloss -2085.87277  validloss -2098.27747±0.00000  bestvalidloss -2125.48281  last_update 1\n",
      "train: iter 674  trainloss -2043.70465  validloss -2091.02294±0.00000  bestvalidloss -2125.48281  last_update 2\n",
      "train: iter 675  trainloss -2098.24727  validloss -2117.67209±0.00000  bestvalidloss -2125.48281  last_update 3\n",
      "train: iter 676  trainloss -2097.60851  validloss -2111.99832±0.00000  bestvalidloss -2125.48281  last_update 4\n",
      "train: iter 677  trainloss -2062.38086  validloss -2104.59883±0.00000  bestvalidloss -2125.48281  last_update 5\n",
      "train: iter 678  trainloss -2073.33430  validloss -2043.39624±0.00000  bestvalidloss -2125.48281  last_update 6\n",
      "train: iter 679  trainloss -2096.90125  validloss -2111.34891±0.00000  bestvalidloss -2125.48281  last_update 7\n",
      "train: iter 680  trainloss -2086.34899  validloss -2105.96013±0.00000  bestvalidloss -2125.48281  last_update 8\n",
      "train: iter 681  trainloss -2054.99267  validloss -2075.27103±0.00000  bestvalidloss -2125.48281  last_update 9\n",
      "train: iter 682  trainloss -2088.73534  validloss -2055.02727±0.00000  bestvalidloss -2125.48281  last_update 10\n",
      "train: iter 683  trainloss -2087.01686  validloss -2103.01936±0.00000  bestvalidloss -2125.48281  last_update 11\n",
      "train: iter 684  trainloss -2062.46534  validloss -2100.43987±0.00000  bestvalidloss -2125.48281  last_update 12\n",
      "train: iter 685  trainloss -2074.99438  validloss -2108.73489±0.00000  bestvalidloss -2125.48281  last_update 13\n",
      "train: iter 686  trainloss -2026.53239  validloss -2013.52861±0.00000  bestvalidloss -2125.48281  last_update 14\n",
      "train: iter 687  trainloss -2068.71321  validloss -2107.00656±0.00000  bestvalidloss -2125.48281  last_update 15\n",
      "train: iter 688  trainloss -2104.25677  validloss -2108.61976±0.00000  bestvalidloss -2125.48281  last_update 16\n",
      "train: iter 689  trainloss -2034.44199  validloss -2089.76002±0.00000  bestvalidloss -2125.48281  last_update 17\n",
      "train: iter 690  trainloss -2066.36990  validloss -2076.57344±0.00000  bestvalidloss -2125.48281  last_update 18\n",
      "train: iter 691  trainloss -2080.39725  validloss -2087.89962±0.00000  bestvalidloss -2125.48281  last_update 19\n",
      "train: iter 692  trainloss -2088.80441  validloss -2110.40813±0.00000  bestvalidloss -2125.48281  last_update 20\n",
      "train: iter 693  trainloss -2058.02870  validloss -2099.47599±0.00000  bestvalidloss -2125.48281  last_update 21\n",
      "train: iter 694  trainloss -2081.90900  validloss -2103.88614±0.00000  bestvalidloss -2125.48281  last_update 22\n",
      "train: iter 695  trainloss -2050.62996  validloss -1980.43560±0.00000  bestvalidloss -2125.48281  last_update 23\n",
      "train: iter 696  trainloss -2090.95296  validloss -2096.91490±0.00000  bestvalidloss -2125.48281  last_update 24\n",
      "train: iter 697  trainloss -2107.31052  validloss -2078.89415±0.00000  bestvalidloss -2125.48281  last_update 25\n",
      "train: iter 698  trainloss -2085.15515  validloss -2067.87027±0.00000  bestvalidloss -2125.48281  last_update 26\n",
      "train: iter 699  trainloss -2091.82216  validloss -2068.14563±0.00000  bestvalidloss -2125.48281  last_update 27\n",
      "train: iter 700  trainloss -1924.57397  validloss -2113.23929±0.00000  bestvalidloss -2125.48281  last_update 28\n",
      "train: iter 701  trainloss -2057.79322  validloss -2038.01808±0.00000  bestvalidloss -2125.48281  last_update 29\n",
      "train: iter 702  trainloss -2052.48317  validloss -2079.34268±0.00000  bestvalidloss -2125.48281  last_update 30\n",
      "train: iter 703  trainloss -2077.01086  validloss -2103.65303±0.00000  bestvalidloss -2125.48281  last_update 31\n",
      "train: iter 704  trainloss -2073.87397  validloss -2125.00961±0.00000  bestvalidloss -2125.48281  last_update 32\n",
      "train: iter 705  trainloss -2098.58245  validloss -2119.96324±0.00000  bestvalidloss -2125.48281  last_update 33\n",
      "train: iter 706  trainloss -2083.28610  validloss -2107.81965±0.00000  bestvalidloss -2125.48281  last_update 34\n",
      "train: iter 707  trainloss -2097.73860  validloss -2117.88262±0.00000  bestvalidloss -2125.48281  last_update 35\n",
      "train: iter 708  trainloss -2100.12013  validloss -2097.69863±0.00000  bestvalidloss -2125.48281  last_update 36\n",
      "train: iter 709  trainloss -2087.56017  validloss -2107.43951±0.00000  bestvalidloss -2125.48281  last_update 37\n",
      "train: iter 710  trainloss -2108.54911  validloss -2090.31964±0.00000  bestvalidloss -2125.48281  last_update 38\n",
      "train: iter 711  trainloss -2057.60196  validloss -2117.07814±0.00000  bestvalidloss -2125.48281  last_update 39\n",
      "train: iter 712  trainloss -2054.44470  validloss -2071.69313±0.00000  bestvalidloss -2125.48281  last_update 40\n",
      "train: iter 713  trainloss -2106.62080  validloss -2132.99467±0.00000  bestvalidloss -2132.99467  last_update 0\n",
      "train: iter 714  trainloss -2082.67931  validloss -2115.84885±0.00000  bestvalidloss -2132.99467  last_update 1\n",
      "train: iter 715  trainloss -2093.74928  validloss -2113.11004±0.00000  bestvalidloss -2132.99467  last_update 2\n",
      "train: iter 716  trainloss -2115.47865  validloss -2128.47066±0.00000  bestvalidloss -2132.99467  last_update 3\n",
      "train: iter 717  trainloss -2094.65171  validloss -2120.29321±0.00000  bestvalidloss -2132.99467  last_update 4\n",
      "train: iter 718  trainloss -2075.93159  validloss -2079.16666±0.00000  bestvalidloss -2132.99467  last_update 5\n",
      "train: iter 719  trainloss -2074.08308  validloss -2097.23615±0.00000  bestvalidloss -2132.99467  last_update 6\n",
      "train: iter 720  trainloss -2108.85363  validloss -2065.62662±0.00000  bestvalidloss -2132.99467  last_update 7\n",
      "train: iter 721  trainloss -2076.33967  validloss -2089.73550±0.00000  bestvalidloss -2132.99467  last_update 8\n",
      "train: iter 722  trainloss -1969.09004  validloss -2065.29537±0.00000  bestvalidloss -2132.99467  last_update 9\n",
      "train: iter 723  trainloss -2104.28004  validloss -2110.12938±0.00000  bestvalidloss -2132.99467  last_update 10\n",
      "train: iter 724  trainloss -2112.26329  validloss -2104.84432±0.00000  bestvalidloss -2132.99467  last_update 11\n",
      "train: iter 725  trainloss -2090.22146  validloss -2121.75770±0.00000  bestvalidloss -2132.99467  last_update 12\n",
      "train: iter 726  trainloss -2051.89988  validloss -1968.57784±0.00000  bestvalidloss -2132.99467  last_update 13\n",
      "train: iter 727  trainloss -2104.10985  validloss -2127.78166±0.00000  bestvalidloss -2132.99467  last_update 14\n",
      "train: iter 728  trainloss -2052.42506  validloss -2038.26257±0.00000  bestvalidloss -2132.99467  last_update 15\n",
      "train: iter 729  trainloss -2083.88676  validloss -2123.15369±0.00000  bestvalidloss -2132.99467  last_update 16\n",
      "train: iter 730  trainloss -2091.91370  validloss -2120.02478±0.00000  bestvalidloss -2132.99467  last_update 17\n",
      "train: iter 731  trainloss -2112.57947  validloss -2118.37726±0.00000  bestvalidloss -2132.99467  last_update 18\n",
      "train: iter 732  trainloss -2117.06858  validloss -2127.40660±0.00000  bestvalidloss -2132.99467  last_update 19\n",
      "train: iter 733  trainloss -2018.89366  validloss -2103.59701±0.00000  bestvalidloss -2132.99467  last_update 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 734  trainloss -2088.38103  validloss -2128.96044±0.00000  bestvalidloss -2132.99467  last_update 21\n",
      "train: iter 735  trainloss -2107.11901  validloss -2102.87092±0.00000  bestvalidloss -2132.99467  last_update 22\n",
      "train: iter 736  trainloss -2079.11391  validloss -2119.13950±0.00000  bestvalidloss -2132.99467  last_update 23\n",
      "train: iter 737  trainloss -2052.64121  validloss -2076.64653±0.00000  bestvalidloss -2132.99467  last_update 24\n",
      "train: iter 738  trainloss -2096.02213  validloss -2096.89724±0.00000  bestvalidloss -2132.99467  last_update 25\n",
      "train: iter 739  trainloss -2107.48978  validloss -2124.73954±0.00000  bestvalidloss -2132.99467  last_update 26\n",
      "train: iter 740  trainloss -2096.81205  validloss -2088.84770±0.00000  bestvalidloss -2132.99467  last_update 27\n",
      "train: iter 741  trainloss -2073.35342  validloss -2051.40549±0.00000  bestvalidloss -2132.99467  last_update 28\n",
      "train: iter 742  trainloss -2125.11786  validloss -2123.24144±0.00000  bestvalidloss -2132.99467  last_update 29\n",
      "train: iter 743  trainloss -2102.65056  validloss -2117.93614±0.00000  bestvalidloss -2132.99467  last_update 30\n",
      "train: iter 744  trainloss -2088.98819  validloss -2080.27873±0.00000  bestvalidloss -2132.99467  last_update 31\n",
      "train: iter 745  trainloss -2091.78791  validloss -2103.10870±0.00000  bestvalidloss -2132.99467  last_update 32\n",
      "train: iter 746  trainloss -2084.96517  validloss -2034.81714±0.00000  bestvalidloss -2132.99467  last_update 33\n",
      "train: iter 747  trainloss -1988.87893  validloss -2108.07527±0.00000  bestvalidloss -2132.99467  last_update 34\n",
      "train: iter 748  trainloss -2086.97495  validloss -2095.37745±0.00000  bestvalidloss -2132.99467  last_update 35\n",
      "train: iter 749  trainloss -2114.10359  validloss -2119.84115±0.00000  bestvalidloss -2132.99467  last_update 36\n",
      "train: iter 750  trainloss -2073.01413  validloss -2082.37364±0.00000  bestvalidloss -2132.99467  last_update 37\n",
      "train: iter 751  trainloss -2108.42465  validloss -2092.10915±0.00000  bestvalidloss -2132.99467  last_update 38\n",
      "train: iter 752  trainloss -2075.23555  validloss -2100.64780±0.00000  bestvalidloss -2132.99467  last_update 39\n",
      "train: iter 753  trainloss -2087.92541  validloss -2125.69233±0.00000  bestvalidloss -2132.99467  last_update 40\n",
      "train: iter 754  trainloss -2110.06518  validloss -2128.78479±0.00000  bestvalidloss -2132.99467  last_update 41\n",
      "train: iter 755  trainloss -2110.89249  validloss -2095.21000±0.00000  bestvalidloss -2132.99467  last_update 42\n",
      "train: iter 756  trainloss -2053.56702  validloss -2110.72338±0.00000  bestvalidloss -2132.99467  last_update 43\n",
      "train: iter 757  trainloss -2093.83468  validloss -2089.80349±0.00000  bestvalidloss -2132.99467  last_update 44\n",
      "train: iter 758  trainloss -2117.10243  validloss -2109.33732±0.00000  bestvalidloss -2132.99467  last_update 45\n",
      "train: iter 759  trainloss -2101.24770  validloss -2098.29169±0.00000  bestvalidloss -2132.99467  last_update 46\n",
      "train: iter 760  trainloss -2082.26134  validloss -2045.61259±0.00000  bestvalidloss -2132.99467  last_update 47\n",
      "train: iter 761  trainloss -2103.35822  validloss -2129.78104±0.00000  bestvalidloss -2132.99467  last_update 48\n",
      "train: iter 762  trainloss -2057.75655  validloss -2120.80647±0.00000  bestvalidloss -2132.99467  last_update 49\n",
      "train: iter 763  trainloss -2094.80197  validloss -2082.47701±0.00000  bestvalidloss -2132.99467  last_update 50\n",
      "train: iter 764  trainloss -2062.43155  validloss -2090.66712±0.00000  bestvalidloss -2132.99467  last_update 51\n",
      "train: iter 765  trainloss -1779.06587  validloss -2026.75429±0.00000  bestvalidloss -2132.99467  last_update 52\n",
      "train: iter 766  trainloss -2008.69400  validloss -2045.30409±0.00000  bestvalidloss -2132.99467  last_update 53\n",
      "train: iter 767  trainloss -2092.73829  validloss -2117.76700±0.00000  bestvalidloss -2132.99467  last_update 54\n",
      "train: iter 768  trainloss -2105.66421  validloss -2111.56700±0.00000  bestvalidloss -2132.99467  last_update 55\n",
      "train: iter 769  trainloss -2116.70490  validloss -2094.88892±0.00000  bestvalidloss -2132.99467  last_update 56\n",
      "train: iter 770  trainloss -2100.32938  validloss -2101.60796±0.00000  bestvalidloss -2132.99467  last_update 57\n",
      "train: iter 771  trainloss -2006.77842  validloss -2118.97990±0.00000  bestvalidloss -2132.99467  last_update 58\n",
      "train: iter 772  trainloss -2051.85842  validloss -1898.66589±0.00000  bestvalidloss -2132.99467  last_update 59\n",
      "train: iter 773  trainloss -2105.28492  validloss -2113.14014±0.00000  bestvalidloss -2132.99467  last_update 60\n",
      "train: iter 774  trainloss -2069.90492  validloss -2113.22327±0.00000  bestvalidloss -2132.99467  last_update 61\n",
      "train: iter 775  trainloss -2085.52926  validloss -2075.46243±0.00000  bestvalidloss -2132.99467  last_update 62\n",
      "train: iter 776  trainloss -2109.23158  validloss -2112.80641±0.00000  bestvalidloss -2132.99467  last_update 63\n",
      "train: iter 777  trainloss -2106.69634  validloss -2070.31753±0.00000  bestvalidloss -2132.99467  last_update 64\n",
      "train: iter 778  trainloss -2104.93328  validloss -2060.10420±0.00000  bestvalidloss -2132.99467  last_update 65\n",
      "train: iter 779  trainloss -2125.35469  validloss -2110.57126±0.00000  bestvalidloss -2132.99467  last_update 66\n",
      "train: iter 780  trainloss -2112.86876  validloss -2114.25832±0.00000  bestvalidloss -2132.99467  last_update 67\n",
      "train: iter 781  trainloss -2110.80610  validloss -2103.76402±0.00000  bestvalidloss -2132.99467  last_update 68\n",
      "train: iter 782  trainloss -2093.91589  validloss -2127.33861±0.00000  bestvalidloss -2132.99467  last_update 69\n",
      "train: iter 783  trainloss -2080.51887  validloss -1931.97090±0.00000  bestvalidloss -2132.99467  last_update 70\n",
      "train: iter 784  trainloss -2129.99009  validloss -2109.80228±0.00000  bestvalidloss -2132.99467  last_update 71\n",
      "train: iter 785  trainloss -2107.44417  validloss -2112.26992±0.00000  bestvalidloss -2132.99467  last_update 72\n",
      "train: iter 786  trainloss -2109.14834  validloss -2117.46238±0.00000  bestvalidloss -2132.99467  last_update 73\n",
      "train: iter 787  trainloss -2099.98559  validloss -2129.07007±0.00000  bestvalidloss -2132.99467  last_update 74\n",
      "train: iter 788  trainloss -2115.61361  validloss -2093.00013±0.00000  bestvalidloss -2132.99467  last_update 75\n",
      "train: iter 789  trainloss -2106.79936  validloss -2114.25418±0.00000  bestvalidloss -2132.99467  last_update 76\n",
      "train: iter 790  trainloss -1814.08324  validloss -1964.66052±0.00000  bestvalidloss -2132.99467  last_update 77\n",
      "train: iter 791  trainloss -2091.94055  validloss -2096.23151±0.00000  bestvalidloss -2132.99467  last_update 78\n",
      "train: iter 792  trainloss -2107.39952  validloss -2131.01898±0.00000  bestvalidloss -2132.99467  last_update 79\n",
      "train: iter 793  trainloss -2107.93628  validloss -1976.61788±0.00000  bestvalidloss -2132.99467  last_update 80\n",
      "train: iter 794  trainloss -2114.71317  validloss -2123.82594±0.00000  bestvalidloss -2132.99467  last_update 81\n",
      "train: iter 795  trainloss -2110.86345  validloss -2107.85380±0.00000  bestvalidloss -2132.99467  last_update 82\n",
      "train: iter 796  trainloss -2106.92205  validloss -2108.59286±0.00000  bestvalidloss -2132.99467  last_update 83\n",
      "train: iter 797  trainloss -2042.11390  validloss -2118.17482±0.00000  bestvalidloss -2132.99467  last_update 84\n",
      "train: iter 798  trainloss -1992.71892  validloss -1935.65305±0.00000  bestvalidloss -2132.99467  last_update 85\n",
      "train: iter 799  trainloss -2105.13646  validloss -2074.66123±0.00000  bestvalidloss -2132.99467  last_update 86\n",
      "train: iter 800  trainloss -2106.43868  validloss -2047.04235±0.00000  bestvalidloss -2132.99467  last_update 87\n",
      "train: iter 801  trainloss -2116.23779  validloss -2113.77864±0.00000  bestvalidloss -2132.99467  last_update 88\n",
      "train: iter 802  trainloss -2118.98259  validloss -2120.78551±0.00000  bestvalidloss -2132.99467  last_update 89\n",
      "train: iter 803  trainloss -2096.63585  validloss -2128.51152±0.00000  bestvalidloss -2132.99467  last_update 90\n",
      "train: iter 804  trainloss -2101.27434  validloss -2099.52484±0.00000  bestvalidloss -2132.99467  last_update 91\n",
      "train: iter 805  trainloss -2120.31140  validloss -2052.87516±0.00000  bestvalidloss -2132.99467  last_update 92\n",
      "train: iter 806  trainloss -2134.20820  validloss -2115.85168±0.00000  bestvalidloss -2132.99467  last_update 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 807  trainloss -2114.72409  validloss -2119.18718±0.00000  bestvalidloss -2132.99467  last_update 94\n",
      "train: iter 808  trainloss -2053.73381  validloss -2089.37264±0.00000  bestvalidloss -2132.99467  last_update 95\n",
      "train: iter 809  trainloss -2111.52381  validloss -2119.54041±0.00000  bestvalidloss -2132.99467  last_update 96\n",
      "train: iter 810  trainloss -2122.51480  validloss -2094.82776±0.00000  bestvalidloss -2132.99467  last_update 97\n",
      "train: iter 811  trainloss -2117.35735  validloss -2116.65587±0.00000  bestvalidloss -2132.99467  last_update 98\n",
      "train: iter 812  trainloss -2070.44439  validloss -2082.62279±0.00000  bestvalidloss -2132.99467  last_update 99\n",
      "train: iter 813  trainloss -2076.43306  validloss -2081.37127±0.00000  bestvalidloss -2132.99467  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3174) penalty_target_max tensor(2.6220)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 5.02309  validloss 5.32781±0.00000  bestvalidloss 5.32781  last_update 0\n",
      "train: iter 1  trainloss 4.63493  validloss 4.91421±0.00000  bestvalidloss 4.91421  last_update 0\n",
      "train: iter 2  trainloss 4.30938  validloss 4.55835±0.00000  bestvalidloss 4.55835  last_update 0\n",
      "train: iter 3  trainloss 4.02650  validloss 4.23827±0.00000  bestvalidloss 4.23827  last_update 0\n",
      "train: iter 4  trainloss 3.77665  validloss 3.95867±0.00000  bestvalidloss 3.95867  last_update 0\n",
      "train: iter 5  trainloss 3.55135  validloss 3.72956±0.00000  bestvalidloss 3.72956  last_update 0\n",
      "train: iter 6  trainloss 3.34970  validloss 3.49363±0.00000  bestvalidloss 3.49363  last_update 0\n",
      "train: iter 7  trainloss 3.16499  validloss 3.29924±0.00000  bestvalidloss 3.29924  last_update 0\n",
      "train: iter 8  trainloss 2.98888  validloss 3.10064±0.00000  bestvalidloss 3.10064  last_update 0\n",
      "train: iter 9  trainloss 2.83184  validloss 2.94465±0.00000  bestvalidloss 2.94465  last_update 0\n",
      "train: iter 10  trainloss 2.68863  validloss 2.78297±0.00000  bestvalidloss 2.78297  last_update 0\n",
      "train: iter 11  trainloss 2.55221  validloss 2.64386±0.00000  bestvalidloss 2.64386  last_update 0\n",
      "train: iter 12  trainloss 2.42981  validloss 2.50910±0.00000  bestvalidloss 2.50910  last_update 0\n",
      "train: iter 13  trainloss 2.32382  validloss 2.38428±0.00000  bestvalidloss 2.38428  last_update 0\n",
      "train: iter 14  trainloss 2.22066  validloss 2.27456±0.00000  bestvalidloss 2.27456  last_update 0\n",
      "train: iter 15  trainloss 2.13284  validloss 2.17663±0.00000  bestvalidloss 2.17663  last_update 0\n",
      "train: iter 16  trainloss 2.05023  validloss 2.07641±0.00000  bestvalidloss 2.07641  last_update 0\n",
      "train: iter 17  trainloss 1.97036  validloss 2.00316±0.00000  bestvalidloss 2.00316  last_update 0\n",
      "train: iter 18  trainloss 1.89654  validloss 1.91666±0.00000  bestvalidloss 1.91666  last_update 0\n",
      "train: iter 19  trainloss 1.82300  validloss 1.83852±0.00000  bestvalidloss 1.83852  last_update 0\n",
      "train: iter 20  trainloss 1.75884  validloss 1.76644±0.00000  bestvalidloss 1.76644  last_update 0\n",
      "train: iter 21  trainloss 1.68885  validloss 1.69694±0.00000  bestvalidloss 1.69694  last_update 0\n",
      "train: iter 22  trainloss 1.62496  validloss 1.62338±0.00000  bestvalidloss 1.62338  last_update 0\n",
      "train: iter 23  trainloss 1.56025  validloss 1.55262±0.00000  bestvalidloss 1.55262  last_update 0\n",
      "train: iter 24  trainloss 1.50004  validloss 1.47803±0.00000  bestvalidloss 1.47803  last_update 0\n",
      "train: iter 25  trainloss 1.43528  validloss 1.41294±0.00000  bestvalidloss 1.41294  last_update 0\n",
      "train: iter 26  trainloss 1.37876  validloss 1.34058±0.00000  bestvalidloss 1.34058  last_update 0\n",
      "train: iter 27  trainloss 1.30863  validloss 1.28482±0.00000  bestvalidloss 1.28482  last_update 0\n",
      "train: iter 28  trainloss 1.25188  validloss 1.19911±0.00000  bestvalidloss 1.19911  last_update 0\n",
      "train: iter 29  trainloss 1.19717  validloss 1.13763±0.00000  bestvalidloss 1.13763  last_update 0\n",
      "train: iter 30  trainloss 1.13374  validloss 1.07038±0.00000  bestvalidloss 1.07038  last_update 0\n",
      "train: iter 31  trainloss 1.06341  validloss 0.99916±0.00000  bestvalidloss 0.99916  last_update 0\n",
      "train: iter 32  trainloss 1.00293  validloss 0.92556±0.00000  bestvalidloss 0.92556  last_update 0\n",
      "train: iter 33  trainloss 0.93427  validloss 0.86448±0.00000  bestvalidloss 0.86448  last_update 0\n",
      "train: iter 34  trainloss 0.87746  validloss 0.78558±0.00000  bestvalidloss 0.78558  last_update 0\n",
      "train: iter 35  trainloss 0.79676  validloss 0.70792±0.00000  bestvalidloss 0.70792  last_update 0\n",
      "train: iter 36  trainloss 0.72933  validloss 0.64488±0.00000  bestvalidloss 0.64488  last_update 0\n",
      "train: iter 37  trainloss 0.67026  validloss 0.55969±0.00000  bestvalidloss 0.55969  last_update 0\n",
      "train: iter 38  trainloss 0.61549  validloss 0.50870±0.00000  bestvalidloss 0.50870  last_update 0\n",
      "train: iter 39  trainloss 0.55650  validloss 0.42199±0.00000  bestvalidloss 0.42199  last_update 0\n",
      "train: iter 40  trainloss 0.49124  validloss 0.35179±0.00000  bestvalidloss 0.35179  last_update 0\n",
      "train: iter 41  trainloss 0.42882  validloss 0.29060±0.00000  bestvalidloss 0.29060  last_update 0\n",
      "train: iter 42  trainloss 0.36968  validloss 0.22596±0.00000  bestvalidloss 0.22596  last_update 0\n",
      "train: iter 43  trainloss 0.30885  validloss 0.16708±0.00000  bestvalidloss 0.16708  last_update 0\n",
      "train: iter 44  trainloss 0.27451  validloss 0.11032±0.00000  bestvalidloss 0.11032  last_update 0\n",
      "train: iter 45  trainloss 0.22943  validloss 0.05667±0.00000  bestvalidloss 0.05667  last_update 0\n",
      "train: iter 46  trainloss 0.17603  validloss -0.00451±0.00000  bestvalidloss -0.00451  last_update 0\n",
      "train: iter 47  trainloss 0.12550  validloss -0.05641±0.00000  bestvalidloss -0.05641  last_update 0\n",
      "train: iter 48  trainloss 0.08074  validloss -0.12455±0.00000  bestvalidloss -0.12455  last_update 0\n",
      "train: iter 49  trainloss 0.04550  validloss -0.13792±0.00000  bestvalidloss -0.13792  last_update 0\n",
      "train: iter 50  trainloss 0.00608  validloss -0.19912±0.00000  bestvalidloss -0.19912  last_update 0\n",
      "train: iter 51  trainloss -0.04288  validloss -0.24622±0.00000  bestvalidloss -0.24622  last_update 0\n",
      "train: iter 52  trainloss -0.07612  validloss -0.29365±0.00000  bestvalidloss -0.29365  last_update 0\n",
      "train: iter 53  trainloss -0.11899  validloss -0.32330±0.00000  bestvalidloss -0.32330  last_update 0\n",
      "train: iter 54  trainloss -0.16441  validloss -0.36085±0.00000  bestvalidloss -0.36085  last_update 0\n",
      "train: iter 55  trainloss -0.20873  validloss -0.41830±0.00000  bestvalidloss -0.41830  last_update 0\n",
      "train: iter 56  trainloss -0.24797  validloss -0.48249±0.00000  bestvalidloss -0.48249  last_update 0\n",
      "train: iter 57  trainloss -0.27907  validloss -0.52252±0.00000  bestvalidloss -0.52252  last_update 0\n",
      "train: iter 58  trainloss -0.32605  validloss -0.56140±0.00000  bestvalidloss -0.56140  last_update 0\n",
      "train: iter 59  trainloss -0.34777  validloss -0.58497±0.00000  bestvalidloss -0.58497  last_update 0\n",
      "train: iter 60  trainloss -0.37575  validloss -0.63490±0.00000  bestvalidloss -0.63490  last_update 0\n",
      "train: iter 61  trainloss -0.42498  validloss -0.64470±0.00000  bestvalidloss -0.64470  last_update 0\n",
      "train: iter 62  trainloss -0.45108  validloss -0.70471±0.00000  bestvalidloss -0.70471  last_update 0\n",
      "train: iter 63  trainloss -0.48769  validloss -0.74284±0.00000  bestvalidloss -0.74284  last_update 0\n",
      "train: iter 64  trainloss -0.49897  validloss -0.76071±0.00000  bestvalidloss -0.76071  last_update 0\n",
      "train: iter 65  trainloss -0.57359  validloss -0.79889±0.00000  bestvalidloss -0.79889  last_update 0\n",
      "train: iter 66  trainloss -0.58783  validloss -0.81381±0.00000  bestvalidloss -0.81381  last_update 0\n",
      "train: iter 67  trainloss -0.59942  validloss -0.87749±0.00000  bestvalidloss -0.87749  last_update 0\n",
      "train: iter 68  trainloss -0.63253  validloss -0.88380±0.00000  bestvalidloss -0.88380  last_update 0\n",
      "train: iter 69  trainloss -0.67267  validloss -0.92082±0.00000  bestvalidloss -0.92082  last_update 0\n",
      "train: iter 70  trainloss -0.67970  validloss -0.94223±0.00000  bestvalidloss -0.94223  last_update 0\n",
      "train: iter 71  trainloss -0.72601  validloss -0.97878±0.00000  bestvalidloss -0.97878  last_update 0\n",
      "train: iter 72  trainloss -0.75570  validloss -0.99204±0.00000  bestvalidloss -0.99204  last_update 0\n",
      "train: iter 73  trainloss -0.76823  validloss -0.99900±0.00000  bestvalidloss -0.99900  last_update 0\n",
      "train: iter 74  trainloss -0.79169  validloss -1.06926±0.00000  bestvalidloss -1.06926  last_update 0\n",
      "train: iter 75  trainloss -0.78888  validloss -1.06934±0.00000  bestvalidloss -1.06934  last_update 0\n",
      "train: iter 76  trainloss -0.81920  validloss -1.12629±0.00000  bestvalidloss -1.12629  last_update 0\n",
      "train: iter 77  trainloss -0.85712  validloss -1.13177±0.00000  bestvalidloss -1.13177  last_update 0\n",
      "train: iter 78  trainloss -0.86719  validloss -1.10842±0.00000  bestvalidloss -1.13177  last_update 1\n",
      "train: iter 79  trainloss -0.89226  validloss -1.16791±0.00000  bestvalidloss -1.16791  last_update 0\n",
      "train: iter 80  trainloss -0.89086  validloss -1.16870±0.00000  bestvalidloss -1.16870  last_update 0\n",
      "train: iter 81  trainloss -0.88517  validloss -1.18309±0.00000  bestvalidloss -1.18309  last_update 0\n",
      "train: iter 82  trainloss -0.89894  validloss -1.20938±0.00000  bestvalidloss -1.20938  last_update 0\n",
      "train: iter 83  trainloss -0.93319  validloss -1.21024±0.00000  bestvalidloss -1.21024  last_update 0\n",
      "train: iter 84  trainloss -0.92832  validloss -1.21154±0.00000  bestvalidloss -1.21154  last_update 0\n",
      "train: iter 85  trainloss -0.93072  validloss -1.24877±0.00000  bestvalidloss -1.24877  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 86  trainloss -0.95594  validloss -1.22594±0.00000  bestvalidloss -1.24877  last_update 1\n",
      "train: iter 87  trainloss -0.94888  validloss -1.24563±0.00000  bestvalidloss -1.24877  last_update 2\n",
      "train: iter 88  trainloss -0.94105  validloss -1.22560±0.00000  bestvalidloss -1.24877  last_update 3\n",
      "train: iter 89  trainloss -0.96697  validloss -1.24832±0.00000  bestvalidloss -1.24877  last_update 4\n",
      "train: iter 90  trainloss -0.99786  validloss -1.26547±0.00000  bestvalidloss -1.26547  last_update 0\n",
      "train: iter 91  trainloss -0.98678  validloss -1.25706±0.00000  bestvalidloss -1.26547  last_update 1\n",
      "train: iter 92  trainloss -0.97437  validloss -1.31574±0.00000  bestvalidloss -1.31574  last_update 0\n",
      "train: iter 93  trainloss -0.99314  validloss -1.32101±0.00000  bestvalidloss -1.32101  last_update 0\n",
      "train: iter 94  trainloss -0.98210  validloss -1.24604±0.00000  bestvalidloss -1.32101  last_update 1\n",
      "train: iter 95  trainloss -1.00895  validloss -1.30140±0.00000  bestvalidloss -1.32101  last_update 2\n",
      "train: iter 96  trainloss -1.00749  validloss -1.29811±0.00000  bestvalidloss -1.32101  last_update 3\n",
      "train: iter 97  trainloss -0.97475  validloss -1.22445±0.00000  bestvalidloss -1.32101  last_update 4\n",
      "train: iter 98  trainloss -1.00542  validloss -1.23453±0.00000  bestvalidloss -1.32101  last_update 5\n",
      "train: iter 99  trainloss -1.00867  validloss -1.30752±0.00000  bestvalidloss -1.32101  last_update 6\n",
      "train: iter 100  trainloss -1.01216  validloss -1.27547±0.00000  bestvalidloss -1.32101  last_update 7\n",
      "train: iter 101  trainloss -0.99284  validloss -1.27918±0.00000  bestvalidloss -1.32101  last_update 8\n",
      "train: iter 102  trainloss -0.99946  validloss -1.26316±0.00000  bestvalidloss -1.32101  last_update 9\n",
      "train: iter 103  trainloss -0.97801  validloss -1.26636±0.00000  bestvalidloss -1.32101  last_update 10\n",
      "train: iter 104  trainloss -1.01853  validloss -1.29106±0.00000  bestvalidloss -1.32101  last_update 11\n",
      "train: iter 105  trainloss -0.98906  validloss -1.26949±0.00000  bestvalidloss -1.32101  last_update 12\n",
      "train: iter 106  trainloss -1.01036  validloss -1.28014±0.00000  bestvalidloss -1.32101  last_update 13\n",
      "train: iter 107  trainloss -0.95223  validloss -1.34370±0.00000  bestvalidloss -1.34370  last_update 0\n",
      "train: iter 108  trainloss -0.97820  validloss -1.30535±0.00000  bestvalidloss -1.34370  last_update 1\n",
      "train: iter 109  trainloss -1.01423  validloss -1.27605±0.00000  bestvalidloss -1.34370  last_update 2\n",
      "train: iter 110  trainloss -1.01565  validloss -1.31886±0.00000  bestvalidloss -1.34370  last_update 3\n",
      "train: iter 111  trainloss -0.97957  validloss -1.34717±0.00000  bestvalidloss -1.34717  last_update 0\n",
      "train: iter 112  trainloss -0.98326  validloss -1.29633±0.00000  bestvalidloss -1.34717  last_update 1\n",
      "train: iter 113  trainloss -1.01940  validloss -1.27576±0.00000  bestvalidloss -1.34717  last_update 2\n",
      "train: iter 114  trainloss -1.00683  validloss -1.28615±0.00000  bestvalidloss -1.34717  last_update 3\n",
      "train: iter 115  trainloss -1.03575  validloss -1.30331±0.00000  bestvalidloss -1.34717  last_update 4\n",
      "train: iter 116  trainloss -0.97640  validloss -1.24764±0.00000  bestvalidloss -1.34717  last_update 5\n",
      "train: iter 117  trainloss -1.01157  validloss -1.26936±0.00000  bestvalidloss -1.34717  last_update 6\n",
      "train: iter 118  trainloss -1.01425  validloss -1.24198±0.00000  bestvalidloss -1.34717  last_update 7\n",
      "train: iter 119  trainloss -0.99620  validloss -1.35505±0.00000  bestvalidloss -1.35505  last_update 0\n",
      "train: iter 120  trainloss -0.97171  validloss -1.25625±0.00000  bestvalidloss -1.35505  last_update 1\n",
      "train: iter 121  trainloss -1.02518  validloss -1.29224±0.00000  bestvalidloss -1.35505  last_update 2\n",
      "train: iter 122  trainloss -0.98816  validloss -1.35391±0.00000  bestvalidloss -1.35505  last_update 3\n",
      "train: iter 123  trainloss -0.99171  validloss -1.33385±0.00000  bestvalidloss -1.35505  last_update 4\n",
      "train: iter 124  trainloss -0.98372  validloss -1.38209±0.00000  bestvalidloss -1.38209  last_update 0\n",
      "train: iter 125  trainloss -0.99206  validloss -1.30222±0.00000  bestvalidloss -1.38209  last_update 1\n",
      "train: iter 126  trainloss -0.98154  validloss -1.27906±0.00000  bestvalidloss -1.38209  last_update 2\n",
      "train: iter 127  trainloss -0.99559  validloss -1.32972±0.00000  bestvalidloss -1.38209  last_update 3\n",
      "train: iter 128  trainloss -0.99648  validloss -1.30007±0.00000  bestvalidloss -1.38209  last_update 4\n",
      "train: iter 129  trainloss -1.02187  validloss -1.39742±0.00000  bestvalidloss -1.39742  last_update 0\n",
      "train: iter 130  trainloss -1.00084  validloss -1.33483±0.00000  bestvalidloss -1.39742  last_update 1\n",
      "train: iter 131  trainloss -0.95912  validloss -1.28091±0.00000  bestvalidloss -1.39742  last_update 2\n",
      "train: iter 132  trainloss -1.00636  validloss -1.21995±0.00000  bestvalidloss -1.39742  last_update 3\n",
      "train: iter 133  trainloss -1.01660  validloss -1.29787±0.00000  bestvalidloss -1.39742  last_update 4\n",
      "train: iter 134  trainloss -1.01865  validloss -1.33050±0.00000  bestvalidloss -1.39742  last_update 5\n",
      "train: iter 135  trainloss -0.95442  validloss -1.33695±0.00000  bestvalidloss -1.39742  last_update 6\n",
      "train: iter 136  trainloss -0.99609  validloss -1.30724±0.00000  bestvalidloss -1.39742  last_update 7\n",
      "train: iter 137  trainloss -0.98681  validloss -1.33706±0.00000  bestvalidloss -1.39742  last_update 8\n",
      "train: iter 138  trainloss -1.00061  validloss -1.34095±0.00000  bestvalidloss -1.39742  last_update 9\n",
      "train: iter 139  trainloss -0.98616  validloss -1.26605±0.00000  bestvalidloss -1.39742  last_update 10\n",
      "train: iter 140  trainloss -0.98394  validloss -1.28534±0.00000  bestvalidloss -1.39742  last_update 11\n",
      "train: iter 141  trainloss -0.96021  validloss -1.31291±0.00000  bestvalidloss -1.39742  last_update 12\n",
      "train: iter 142  trainloss -1.02850  validloss -1.32631±0.00000  bestvalidloss -1.39742  last_update 13\n",
      "train: iter 143  trainloss -1.02974  validloss -1.27371±0.00000  bestvalidloss -1.39742  last_update 14\n",
      "train: iter 144  trainloss -0.98124  validloss -1.33364±0.00000  bestvalidloss -1.39742  last_update 15\n",
      "train: iter 145  trainloss -0.98059  validloss -1.24405±0.00000  bestvalidloss -1.39742  last_update 16\n",
      "train: iter 146  trainloss -1.02787  validloss -1.34325±0.00000  bestvalidloss -1.39742  last_update 17\n",
      "train: iter 147  trainloss -0.98388  validloss -1.31695±0.00000  bestvalidloss -1.39742  last_update 18\n",
      "train: iter 148  trainloss -0.99209  validloss -1.26779±0.00000  bestvalidloss -1.39742  last_update 19\n",
      "train: iter 149  trainloss -1.01419  validloss -1.37828±0.00000  bestvalidloss -1.39742  last_update 20\n",
      "train: iter 150  trainloss -1.04771  validloss -1.32354±0.00000  bestvalidloss -1.39742  last_update 21\n",
      "train: iter 151  trainloss -0.99058  validloss -1.30924±0.00000  bestvalidloss -1.39742  last_update 22\n",
      "train: iter 152  trainloss -0.99491  validloss -1.31661±0.00000  bestvalidloss -1.39742  last_update 23\n",
      "train: iter 153  trainloss -1.01503  validloss -1.31096±0.00000  bestvalidloss -1.39742  last_update 24\n",
      "train: iter 154  trainloss -0.99392  validloss -1.33010±0.00000  bestvalidloss -1.39742  last_update 25\n",
      "train: iter 155  trainloss -0.95099  validloss -1.31733±0.00000  bestvalidloss -1.39742  last_update 26\n",
      "train: iter 156  trainloss -1.00984  validloss -1.32250±0.00000  bestvalidloss -1.39742  last_update 27\n",
      "train: iter 157  trainloss -0.99376  validloss -1.31143±0.00000  bestvalidloss -1.39742  last_update 28\n",
      "train: iter 158  trainloss -0.99201  validloss -1.35203±0.00000  bestvalidloss -1.39742  last_update 29\n",
      "train: iter 159  trainloss -0.98141  validloss -1.32382±0.00000  bestvalidloss -1.39742  last_update 30\n",
      "train: iter 160  trainloss -0.98026  validloss -1.27769±0.00000  bestvalidloss -1.39742  last_update 31\n",
      "train: iter 161  trainloss -0.98996  validloss -1.33600±0.00000  bestvalidloss -1.39742  last_update 32\n",
      "train: iter 162  trainloss -1.00992  validloss -1.32787±0.00000  bestvalidloss -1.39742  last_update 33\n",
      "train: iter 163  trainloss -0.99931  validloss -1.23616±0.00000  bestvalidloss -1.39742  last_update 34\n",
      "train: iter 164  trainloss -1.02290  validloss -1.28121±0.00000  bestvalidloss -1.39742  last_update 35\n",
      "train: iter 165  trainloss -1.01109  validloss -1.34713±0.00000  bestvalidloss -1.39742  last_update 36\n",
      "train: iter 166  trainloss -1.00982  validloss -1.28896±0.00000  bestvalidloss -1.39742  last_update 37\n",
      "train: iter 167  trainloss -0.96741  validloss -1.30012±0.00000  bestvalidloss -1.39742  last_update 38\n",
      "train: iter 168  trainloss -0.99759  validloss -1.30332±0.00000  bestvalidloss -1.39742  last_update 39\n",
      "train: iter 169  trainloss -1.02539  validloss -1.34834±0.00000  bestvalidloss -1.39742  last_update 40\n",
      "train: iter 170  trainloss -0.98358  validloss -1.36669±0.00000  bestvalidloss -1.39742  last_update 41\n",
      "train: iter 171  trainloss -0.96749  validloss -1.26970±0.00000  bestvalidloss -1.39742  last_update 42\n",
      "train: iter 172  trainloss -0.99985  validloss -1.28872±0.00000  bestvalidloss -1.39742  last_update 43\n",
      "train: iter 173  trainloss -1.01061  validloss -1.29890±0.00000  bestvalidloss -1.39742  last_update 44\n",
      "train: iter 174  trainloss -0.97423  validloss -1.30237±0.00000  bestvalidloss -1.39742  last_update 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 175  trainloss -1.00103  validloss -1.34449±0.00000  bestvalidloss -1.39742  last_update 46\n",
      "train: iter 176  trainloss -1.03150  validloss -1.30401±0.00000  bestvalidloss -1.39742  last_update 47\n",
      "train: iter 177  trainloss -1.00471  validloss -1.29830±0.00000  bestvalidloss -1.39742  last_update 48\n",
      "train: iter 178  trainloss -0.99825  validloss -1.35997±0.00000  bestvalidloss -1.39742  last_update 49\n",
      "train: iter 179  trainloss -0.95936  validloss -1.33647±0.00000  bestvalidloss -1.39742  last_update 50\n",
      "train: iter 180  trainloss -0.99436  validloss -1.26947±0.00000  bestvalidloss -1.39742  last_update 51\n",
      "train: iter 181  trainloss -1.00023  validloss -1.30193±0.00000  bestvalidloss -1.39742  last_update 52\n",
      "train: iter 182  trainloss -0.98222  validloss -1.30490±0.00000  bestvalidloss -1.39742  last_update 53\n",
      "train: iter 183  trainloss -0.99830  validloss -1.28957±0.00000  bestvalidloss -1.39742  last_update 54\n",
      "train: iter 184  trainloss -1.00847  validloss -1.32168±0.00000  bestvalidloss -1.39742  last_update 55\n",
      "train: iter 185  trainloss -0.97571  validloss -1.29131±0.00000  bestvalidloss -1.39742  last_update 56\n",
      "train: iter 186  trainloss -0.98628  validloss -1.33813±0.00000  bestvalidloss -1.39742  last_update 57\n",
      "train: iter 187  trainloss -0.99114  validloss -1.30704±0.00000  bestvalidloss -1.39742  last_update 58\n",
      "train: iter 188  trainloss -0.99827  validloss -1.34639±0.00000  bestvalidloss -1.39742  last_update 59\n",
      "train: iter 189  trainloss -0.99008  validloss -1.35959±0.00000  bestvalidloss -1.39742  last_update 60\n",
      "train: iter 190  trainloss -0.98876  validloss -1.35738±0.00000  bestvalidloss -1.39742  last_update 61\n",
      "train: iter 191  trainloss -0.98748  validloss -1.32245±0.00000  bestvalidloss -1.39742  last_update 62\n",
      "train: iter 192  trainloss -1.04346  validloss -1.24328±0.00000  bestvalidloss -1.39742  last_update 63\n",
      "train: iter 193  trainloss -1.04299  validloss -1.36188±0.00000  bestvalidloss -1.39742  last_update 64\n",
      "train: iter 194  trainloss -0.94527  validloss -1.29842±0.00000  bestvalidloss -1.39742  last_update 65\n",
      "train: iter 195  trainloss -0.96976  validloss -1.32260±0.00000  bestvalidloss -1.39742  last_update 66\n",
      "train: iter 196  trainloss -1.02823  validloss -1.28972±0.00000  bestvalidloss -1.39742  last_update 67\n",
      "train: iter 197  trainloss -0.98408  validloss -1.29333±0.00000  bestvalidloss -1.39742  last_update 68\n",
      "train: iter 198  trainloss -1.02672  validloss -1.30067±0.00000  bestvalidloss -1.39742  last_update 69\n",
      "train: iter 199  trainloss -0.98350  validloss -1.37998±0.00000  bestvalidloss -1.39742  last_update 70\n",
      "train: iter 200  trainloss -0.98804  validloss -1.32856±0.00000  bestvalidloss -1.39742  last_update 71\n",
      "train: iter 201  trainloss -0.96599  validloss -1.35741±0.00000  bestvalidloss -1.39742  last_update 72\n",
      "train: iter 202  trainloss -0.98732  validloss -1.29961±0.00000  bestvalidloss -1.39742  last_update 73\n",
      "train: iter 203  trainloss -1.02991  validloss -1.33915±0.00000  bestvalidloss -1.39742  last_update 74\n",
      "train: iter 204  trainloss -0.95637  validloss -1.32254±0.00000  bestvalidloss -1.39742  last_update 75\n",
      "train: iter 205  trainloss -0.97588  validloss -1.31425±0.00000  bestvalidloss -1.39742  last_update 76\n",
      "train: iter 206  trainloss -1.05528  validloss -1.32195±0.00000  bestvalidloss -1.39742  last_update 77\n",
      "train: iter 207  trainloss -0.98255  validloss -1.31100±0.00000  bestvalidloss -1.39742  last_update 78\n",
      "train: iter 208  trainloss -0.99777  validloss -1.28333±0.00000  bestvalidloss -1.39742  last_update 79\n",
      "train: iter 209  trainloss -0.99080  validloss -1.34301±0.00000  bestvalidloss -1.39742  last_update 80\n",
      "train: iter 210  trainloss -0.98013  validloss -1.31523±0.00000  bestvalidloss -1.39742  last_update 81\n",
      "train: iter 211  trainloss -0.98750  validloss -1.31009±0.00000  bestvalidloss -1.39742  last_update 82\n",
      "train: iter 212  trainloss -1.00857  validloss -1.29199±0.00000  bestvalidloss -1.39742  last_update 83\n",
      "train: iter 213  trainloss -0.98343  validloss -1.35526±0.00000  bestvalidloss -1.39742  last_update 84\n",
      "train: iter 214  trainloss -0.95642  validloss -1.32289±0.00000  bestvalidloss -1.39742  last_update 85\n",
      "train: iter 215  trainloss -0.98712  validloss -1.25470±0.00000  bestvalidloss -1.39742  last_update 86\n",
      "train: iter 216  trainloss -1.00797  validloss -1.36844±0.00000  bestvalidloss -1.39742  last_update 87\n",
      "train: iter 217  trainloss -1.00549  validloss -1.35266±0.00000  bestvalidloss -1.39742  last_update 88\n",
      "train: iter 218  trainloss -0.97689  validloss -1.21436±0.00000  bestvalidloss -1.39742  last_update 89\n",
      "train: iter 219  trainloss -1.02810  validloss -1.27673±0.00000  bestvalidloss -1.39742  last_update 90\n",
      "train: iter 220  trainloss -0.97823  validloss -1.36117±0.00000  bestvalidloss -1.39742  last_update 91\n",
      "train: iter 221  trainloss -1.04301  validloss -1.29521±0.00000  bestvalidloss -1.39742  last_update 92\n",
      "train: iter 222  trainloss -0.98458  validloss -1.34881±0.00000  bestvalidloss -1.39742  last_update 93\n",
      "train: iter 223  trainloss -1.03531  validloss -1.33912±0.00000  bestvalidloss -1.39742  last_update 94\n",
      "train: iter 224  trainloss -1.01626  validloss -1.29363±0.00000  bestvalidloss -1.39742  last_update 95\n",
      "train: iter 225  trainloss -1.02063  validloss -1.27327±0.00000  bestvalidloss -1.39742  last_update 96\n",
      "train: iter 226  trainloss -1.00774  validloss -1.33627±0.00000  bestvalidloss -1.39742  last_update 97\n",
      "train: iter 227  trainloss -1.01477  validloss -1.30734±0.00000  bestvalidloss -1.39742  last_update 98\n",
      "train: iter 228  trainloss -1.02662  validloss -1.27837±0.00000  bestvalidloss -1.39742  last_update 99\n",
      "train: iter 229  trainloss -0.95231  validloss -1.30181±0.00000  bestvalidloss -1.39742  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.3905, -1.0161, -4.1795, -3.4576], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 100.21775  validloss 115.90938±0.00000  bestvalidloss 115.90938  last_update 0\n",
      "train: iter 1  trainloss 71.53796  validloss 86.80603±0.00000  bestvalidloss 86.80603  last_update 0\n",
      "train: iter 2  trainloss 51.19078  validloss 61.15407±0.00000  bestvalidloss 61.15407  last_update 0\n",
      "train: iter 3  trainloss 38.60254  validloss 45.22568±0.00000  bestvalidloss 45.22568  last_update 0\n",
      "train: iter 4  trainloss 29.86695  validloss 34.66639±0.00000  bestvalidloss 34.66639  last_update 0\n",
      "train: iter 5  trainloss 23.57024  validloss 27.18978±0.00000  bestvalidloss 27.18978  last_update 0\n",
      "train: iter 6  trainloss 18.57471  validloss 21.55093±0.00000  bestvalidloss 21.55093  last_update 0\n",
      "train: iter 7  trainloss 14.91172  validloss 16.99392±0.00000  bestvalidloss 16.99392  last_update 0\n",
      "train: iter 8  trainloss 11.89380  validloss 13.54056±0.00000  bestvalidloss 13.54056  last_update 0\n",
      "train: iter 9  trainloss 9.58335  validloss 10.71907±0.00000  bestvalidloss 10.71907  last_update 0\n",
      "train: iter 10  trainloss 7.79890  validloss 8.60813±0.00000  bestvalidloss 8.60813  last_update 0\n",
      "train: iter 11  trainloss 6.51365  validloss 7.06166±0.00000  bestvalidloss 7.06166  last_update 0\n",
      "train: iter 12  trainloss 5.44618  validloss 5.70107±0.00000  bestvalidloss 5.70107  last_update 0\n",
      "train: iter 13  trainloss 4.71393  validloss 4.83729±0.00000  bestvalidloss 4.83729  last_update 0\n",
      "train: iter 14  trainloss 4.17429  validloss 4.12680±0.00000  bestvalidloss 4.12680  last_update 0\n",
      "train: iter 15  trainloss 3.80566  validloss 3.55402±0.00000  bestvalidloss 3.55402  last_update 0\n",
      "train: iter 16  trainloss 3.51811  validloss 3.23060±0.00000  bestvalidloss 3.23060  last_update 0\n",
      "train: iter 17  trainloss 3.31840  validloss 2.97858±0.00000  bestvalidloss 2.97858  last_update 0\n",
      "train: iter 18  trainloss 3.17405  validloss 2.83866±0.00000  bestvalidloss 2.83866  last_update 0\n",
      "train: iter 19  trainloss 3.06497  validloss 2.74689±0.00000  bestvalidloss 2.74689  last_update 0\n",
      "train: iter 20  trainloss 2.99870  validloss 2.55065±0.00000  bestvalidloss 2.55065  last_update 0\n",
      "train: iter 21  trainloss 2.90950  validloss 2.57653±0.00000  bestvalidloss 2.55065  last_update 1\n",
      "train: iter 22  trainloss 2.83284  validloss 2.47476±0.00000  bestvalidloss 2.47476  last_update 0\n",
      "train: iter 23  trainloss 2.79516  validloss 2.51788±0.00000  bestvalidloss 2.47476  last_update 1\n",
      "train: iter 24  trainloss 2.73737  validloss 2.49837±0.00000  bestvalidloss 2.47476  last_update 2\n",
      "train: iter 25  trainloss 2.73898  validloss 2.33852±0.00000  bestvalidloss 2.33852  last_update 0\n",
      "train: iter 26  trainloss 2.72752  validloss 2.41572±0.00000  bestvalidloss 2.33852  last_update 1\n",
      "train: iter 27  trainloss 2.67184  validloss 2.43283±0.00000  bestvalidloss 2.33852  last_update 2\n",
      "train: iter 28  trainloss 2.65076  validloss 2.49101±0.00000  bestvalidloss 2.33852  last_update 3\n",
      "train: iter 29  trainloss 2.60475  validloss 2.30281±0.00000  bestvalidloss 2.30281  last_update 0\n",
      "train: iter 30  trainloss 2.46824  validloss 2.32813±0.00000  bestvalidloss 2.30281  last_update 1\n",
      "train: iter 31  trainloss 2.36984  validloss 2.17730±0.00000  bestvalidloss 2.17730  last_update 0\n",
      "train: iter 32  trainloss 2.27994  validloss 2.23289±0.00000  bestvalidloss 2.17730  last_update 1\n",
      "train: iter 33  trainloss 2.23050  validloss 2.23079±0.00000  bestvalidloss 2.17730  last_update 2\n",
      "train: iter 34  trainloss 2.20717  validloss 2.29590±0.00000  bestvalidloss 2.17730  last_update 3\n",
      "train: iter 35  trainloss 2.14644  validloss 2.26503±0.00000  bestvalidloss 2.17730  last_update 4\n",
      "train: iter 36  trainloss 2.14420  validloss 2.31683±0.00000  bestvalidloss 2.17730  last_update 5\n",
      "train: iter 37  trainloss 2.10113  validloss 2.14361±0.00000  bestvalidloss 2.14361  last_update 0\n",
      "train: iter 38  trainloss 2.09130  validloss 2.29652±0.00000  bestvalidloss 2.14361  last_update 1\n",
      "train: iter 39  trainloss 2.08650  validloss 2.14450±0.00000  bestvalidloss 2.14361  last_update 2\n",
      "train: iter 40  trainloss 2.06957  validloss 2.21984±0.00000  bestvalidloss 2.14361  last_update 3\n",
      "train: iter 41  trainloss 2.06513  validloss 2.09694±0.00000  bestvalidloss 2.09694  last_update 0\n",
      "train: iter 42  trainloss 2.04107  validloss 2.24710±0.00000  bestvalidloss 2.09694  last_update 1\n",
      "train: iter 43  trainloss 2.03504  validloss 2.24630±0.00000  bestvalidloss 2.09694  last_update 2\n",
      "train: iter 44  trainloss 2.03169  validloss 2.22889±0.00000  bestvalidloss 2.09694  last_update 3\n",
      "train: iter 45  trainloss 2.01543  validloss 2.19501±0.00000  bestvalidloss 2.09694  last_update 4\n",
      "train: iter 46  trainloss 1.99164  validloss 2.13485±0.00000  bestvalidloss 2.09694  last_update 5\n",
      "train: iter 47  trainloss 2.01005  validloss 2.21158±0.00000  bestvalidloss 2.09694  last_update 6\n",
      "train: iter 48  trainloss 2.02091  validloss 2.14887±0.00000  bestvalidloss 2.09694  last_update 7\n",
      "train: iter 49  trainloss 1.98872  validloss 2.19665±0.00000  bestvalidloss 2.09694  last_update 8\n",
      "train: iter 50  trainloss 1.98353  validloss 2.12565±0.00000  bestvalidloss 2.09694  last_update 9\n",
      "train: iter 51  trainloss 1.96406  validloss 2.14850±0.00000  bestvalidloss 2.09694  last_update 10\n",
      "train: iter 52  trainloss 1.97875  validloss 2.16307±0.00000  bestvalidloss 2.09694  last_update 11\n",
      "train: iter 53  trainloss 1.98010  validloss 2.10527±0.00000  bestvalidloss 2.09694  last_update 12\n",
      "train: iter 54  trainloss 1.96457  validloss 2.17034±0.00000  bestvalidloss 2.09694  last_update 13\n",
      "train: iter 55  trainloss 1.96699  validloss 2.17469±0.00000  bestvalidloss 2.09694  last_update 14\n",
      "train: iter 56  trainloss 1.92721  validloss 2.26606±0.00000  bestvalidloss 2.09694  last_update 15\n",
      "train: iter 57  trainloss 1.94754  validloss 2.12255±0.00000  bestvalidloss 2.09694  last_update 16\n",
      "train: iter 58  trainloss 1.95415  validloss 2.11265±0.00000  bestvalidloss 2.09694  last_update 17\n",
      "train: iter 59  trainloss 1.93065  validloss 2.19300±0.00000  bestvalidloss 2.09694  last_update 18\n",
      "train: iter 60  trainloss 1.91745  validloss 2.09971±0.00000  bestvalidloss 2.09694  last_update 19\n",
      "train: iter 61  trainloss 1.91940  validloss 2.11647±0.00000  bestvalidloss 2.09694  last_update 20\n",
      "train: iter 62  trainloss 1.92268  validloss 2.27544±0.00000  bestvalidloss 2.09694  last_update 21\n",
      "train: iter 63  trainloss 1.89781  validloss 2.18169±0.00000  bestvalidloss 2.09694  last_update 22\n",
      "train: iter 64  trainloss 1.94895  validloss 2.34402±0.00000  bestvalidloss 2.09694  last_update 23\n",
      "train: iter 65  trainloss 1.90962  validloss 2.07237±0.00000  bestvalidloss 2.07237  last_update 0\n",
      "train: iter 66  trainloss 1.89759  validloss 2.15321±0.00000  bestvalidloss 2.07237  last_update 1\n",
      "train: iter 67  trainloss 1.89638  validloss 2.26014±0.00000  bestvalidloss 2.07237  last_update 2\n",
      "train: iter 68  trainloss 1.87536  validloss 2.06593±0.00000  bestvalidloss 2.06593  last_update 0\n",
      "train: iter 69  trainloss 1.87324  validloss 2.12672±0.00000  bestvalidloss 2.06593  last_update 1\n",
      "train: iter 70  trainloss 1.86176  validloss 2.13110±0.00000  bestvalidloss 2.06593  last_update 2\n",
      "train: iter 71  trainloss 1.87872  validloss 2.15046±0.00000  bestvalidloss 2.06593  last_update 3\n",
      "train: iter 72  trainloss 1.84088  validloss 2.08686±0.00000  bestvalidloss 2.06593  last_update 4\n",
      "train: iter 73  trainloss 1.82862  validloss 2.05075±0.00000  bestvalidloss 2.05075  last_update 0\n",
      "train: iter 74  trainloss 1.81786  validloss 2.15112±0.00000  bestvalidloss 2.05075  last_update 1\n",
      "train: iter 75  trainloss 1.80141  validloss 2.09913±0.00000  bestvalidloss 2.05075  last_update 2\n",
      "train: iter 76  trainloss 1.82762  validloss 2.15964±0.00000  bestvalidloss 2.05075  last_update 3\n",
      "train: iter 77  trainloss 1.83032  validloss 2.14130±0.00000  bestvalidloss 2.05075  last_update 4\n",
      "train: iter 78  trainloss 1.81233  validloss 2.15207±0.00000  bestvalidloss 2.05075  last_update 5\n",
      "train: iter 79  trainloss 1.82119  validloss 2.16020±0.00000  bestvalidloss 2.05075  last_update 6\n",
      "train: iter 80  trainloss 1.79917  validloss 2.11520±0.00000  bestvalidloss 2.05075  last_update 7\n",
      "train: iter 81  trainloss 1.80977  validloss 2.06325±0.00000  bestvalidloss 2.05075  last_update 8\n",
      "train: iter 82  trainloss 1.81606  validloss 2.11867±0.00000  bestvalidloss 2.05075  last_update 9\n",
      "train: iter 83  trainloss 1.79304  validloss 2.28509±0.00000  bestvalidloss 2.05075  last_update 10\n",
      "train: iter 84  trainloss 1.79795  validloss 2.17262±0.00000  bestvalidloss 2.05075  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 1.78209  validloss 2.05771±0.00000  bestvalidloss 2.05075  last_update 12\n",
      "train: iter 86  trainloss 1.81440  validloss 2.02554±0.00000  bestvalidloss 2.02554  last_update 0\n",
      "train: iter 87  trainloss 1.78426  validloss 2.23160±0.00000  bestvalidloss 2.02554  last_update 1\n",
      "train: iter 88  trainloss 1.80893  validloss 2.05275±0.00000  bestvalidloss 2.02554  last_update 2\n",
      "train: iter 89  trainloss 1.79753  validloss 2.14792±0.00000  bestvalidloss 2.02554  last_update 3\n",
      "train: iter 90  trainloss 1.81221  validloss 2.05022±0.00000  bestvalidloss 2.02554  last_update 4\n",
      "train: iter 91  trainloss 1.79949  validloss 2.22514±0.00000  bestvalidloss 2.02554  last_update 5\n",
      "train: iter 92  trainloss 1.80157  validloss 2.11770±0.00000  bestvalidloss 2.02554  last_update 6\n",
      "train: iter 93  trainloss 1.78120  validloss 2.13314±0.00000  bestvalidloss 2.02554  last_update 7\n",
      "train: iter 94  trainloss 1.79834  validloss 2.05186±0.00000  bestvalidloss 2.02554  last_update 8\n",
      "train: iter 95  trainloss 1.78306  validloss 2.27108±0.00000  bestvalidloss 2.02554  last_update 9\n",
      "train: iter 96  trainloss 1.77276  validloss 2.10590±0.00000  bestvalidloss 2.02554  last_update 10\n",
      "train: iter 97  trainloss 1.78176  validloss 1.97372±0.00000  bestvalidloss 1.97372  last_update 0\n",
      "train: iter 98  trainloss 1.75831  validloss 2.07749±0.00000  bestvalidloss 1.97372  last_update 1\n",
      "train: iter 99  trainloss 1.76171  validloss 2.21116±0.00000  bestvalidloss 1.97372  last_update 2\n",
      "train: iter 100  trainloss 1.78659  validloss 2.15928±0.00000  bestvalidloss 1.97372  last_update 3\n",
      "train: iter 101  trainloss 1.76666  validloss 2.11080±0.00000  bestvalidloss 1.97372  last_update 4\n",
      "train: iter 102  trainloss 1.78417  validloss 2.11539±0.00000  bestvalidloss 1.97372  last_update 5\n",
      "train: iter 103  trainloss 1.80137  validloss 2.15737±0.00000  bestvalidloss 1.97372  last_update 6\n",
      "train: iter 104  trainloss 1.78244  validloss 2.01505±0.00000  bestvalidloss 1.97372  last_update 7\n",
      "train: iter 105  trainloss 1.78400  validloss 2.28784±0.00000  bestvalidloss 1.97372  last_update 8\n",
      "train: iter 106  trainloss 1.77747  validloss 2.02793±0.00000  bestvalidloss 1.97372  last_update 9\n",
      "train: iter 107  trainloss 1.78060  validloss 2.14737±0.00000  bestvalidloss 1.97372  last_update 10\n",
      "train: iter 108  trainloss 1.75319  validloss 2.10025±0.00000  bestvalidloss 1.97372  last_update 11\n",
      "train: iter 109  trainloss 1.77471  validloss 2.11772±0.00000  bestvalidloss 1.97372  last_update 12\n",
      "train: iter 110  trainloss 1.72584  validloss 2.18439±0.00000  bestvalidloss 1.97372  last_update 13\n",
      "train: iter 111  trainloss 1.78265  validloss 2.09580±0.00000  bestvalidloss 1.97372  last_update 14\n",
      "train: iter 112  trainloss 1.79220  validloss 2.06978±0.00000  bestvalidloss 1.97372  last_update 15\n",
      "train: iter 113  trainloss 1.76608  validloss 2.08268±0.00000  bestvalidloss 1.97372  last_update 16\n",
      "train: iter 114  trainloss 1.75776  validloss 2.07785±0.00000  bestvalidloss 1.97372  last_update 17\n",
      "train: iter 115  trainloss 1.79814  validloss 2.19355±0.00000  bestvalidloss 1.97372  last_update 18\n",
      "train: iter 116  trainloss 1.75949  validloss 2.03924±0.00000  bestvalidloss 1.97372  last_update 19\n",
      "train: iter 117  trainloss 1.77120  validloss 2.05995±0.00000  bestvalidloss 1.97372  last_update 20\n",
      "train: iter 118  trainloss 1.78058  validloss 2.00647±0.00000  bestvalidloss 1.97372  last_update 21\n",
      "train: iter 119  trainloss 1.75793  validloss 2.00517±0.00000  bestvalidloss 1.97372  last_update 22\n",
      "train: iter 120  trainloss 1.76161  validloss 2.09630±0.00000  bestvalidloss 1.97372  last_update 23\n",
      "train: iter 121  trainloss 1.77369  validloss 1.98998±0.00000  bestvalidloss 1.97372  last_update 24\n",
      "train: iter 122  trainloss 1.75180  validloss 2.16464±0.00000  bestvalidloss 1.97372  last_update 25\n",
      "train: iter 123  trainloss 1.80336  validloss 2.14419±0.00000  bestvalidloss 1.97372  last_update 26\n",
      "train: iter 124  trainloss 1.76291  validloss 2.05551±0.00000  bestvalidloss 1.97372  last_update 27\n",
      "train: iter 125  trainloss 1.77068  validloss 2.13214±0.00000  bestvalidloss 1.97372  last_update 28\n",
      "train: iter 126  trainloss 1.77056  validloss 2.03879±0.00000  bestvalidloss 1.97372  last_update 29\n",
      "train: iter 127  trainloss 1.76182  validloss 2.13160±0.00000  bestvalidloss 1.97372  last_update 30\n",
      "train: iter 128  trainloss 1.76329  validloss 2.03524±0.00000  bestvalidloss 1.97372  last_update 31\n",
      "train: iter 129  trainloss 1.75536  validloss 2.12925±0.00000  bestvalidloss 1.97372  last_update 32\n",
      "train: iter 130  trainloss 1.72562  validloss 2.07570±0.00000  bestvalidloss 1.97372  last_update 33\n",
      "train: iter 131  trainloss 1.74933  validloss 2.10309±0.00000  bestvalidloss 1.97372  last_update 34\n",
      "train: iter 132  trainloss 1.80036  validloss 2.13273±0.00000  bestvalidloss 1.97372  last_update 35\n",
      "train: iter 133  trainloss 1.76748  validloss 2.00801±0.00000  bestvalidloss 1.97372  last_update 36\n",
      "train: iter 134  trainloss 1.73765  validloss 2.05111±0.00000  bestvalidloss 1.97372  last_update 37\n",
      "train: iter 135  trainloss 1.75765  validloss 2.07177±0.00000  bestvalidloss 1.97372  last_update 38\n",
      "train: iter 136  trainloss 1.78614  validloss 2.18428±0.00000  bestvalidloss 1.97372  last_update 39\n",
      "train: iter 137  trainloss 1.75606  validloss 2.16362±0.00000  bestvalidloss 1.97372  last_update 40\n",
      "train: iter 138  trainloss 1.72554  validloss 2.00267±0.00000  bestvalidloss 1.97372  last_update 41\n",
      "train: iter 139  trainloss 1.80485  validloss 2.11959±0.00000  bestvalidloss 1.97372  last_update 42\n",
      "train: iter 140  trainloss 1.76321  validloss 1.97972±0.00000  bestvalidloss 1.97372  last_update 43\n",
      "train: iter 141  trainloss 1.76601  validloss 2.10905±0.00000  bestvalidloss 1.97372  last_update 44\n",
      "train: iter 142  trainloss 1.75972  validloss 2.04916±0.00000  bestvalidloss 1.97372  last_update 45\n",
      "train: iter 143  trainloss 1.80059  validloss 2.13225±0.00000  bestvalidloss 1.97372  last_update 46\n",
      "train: iter 144  trainloss 1.75357  validloss 2.11662±0.00000  bestvalidloss 1.97372  last_update 47\n",
      "train: iter 145  trainloss 1.76496  validloss 2.09805±0.00000  bestvalidloss 1.97372  last_update 48\n",
      "train: iter 146  trainloss 1.75286  validloss 2.14104±0.00000  bestvalidloss 1.97372  last_update 49\n",
      "train: iter 147  trainloss 1.75726  validloss 2.13896±0.00000  bestvalidloss 1.97372  last_update 50\n",
      "train: iter 148  trainloss 1.76329  validloss 2.28217±0.00000  bestvalidloss 1.97372  last_update 51\n",
      "train: iter 149  trainloss 1.78875  validloss 2.12184±0.00000  bestvalidloss 1.97372  last_update 52\n",
      "train: iter 150  trainloss 1.75832  validloss 1.99938±0.00000  bestvalidloss 1.97372  last_update 53\n",
      "train: iter 151  trainloss 1.79969  validloss 2.02929±0.00000  bestvalidloss 1.97372  last_update 54\n",
      "train: iter 152  trainloss 1.76136  validloss 2.24311±0.00000  bestvalidloss 1.97372  last_update 55\n",
      "train: iter 153  trainloss 1.73092  validloss 2.11009±0.00000  bestvalidloss 1.97372  last_update 56\n",
      "train: iter 154  trainloss 1.79461  validloss 2.12461±0.00000  bestvalidloss 1.97372  last_update 57\n",
      "train: iter 155  trainloss 1.78659  validloss 2.06998±0.00000  bestvalidloss 1.97372  last_update 58\n",
      "train: iter 156  trainloss 1.73230  validloss 2.02634±0.00000  bestvalidloss 1.97372  last_update 59\n",
      "train: iter 157  trainloss 1.77786  validloss 2.19436±0.00000  bestvalidloss 1.97372  last_update 60\n",
      "train: iter 158  trainloss 1.77848  validloss 2.24218±0.00000  bestvalidloss 1.97372  last_update 61\n",
      "train: iter 159  trainloss 1.77301  validloss 2.07380±0.00000  bestvalidloss 1.97372  last_update 62\n",
      "train: iter 160  trainloss 1.76149  validloss 1.93900±0.00000  bestvalidloss 1.93900  last_update 0\n",
      "train: iter 161  trainloss 1.78774  validloss 2.00777±0.00000  bestvalidloss 1.93900  last_update 1\n",
      "train: iter 162  trainloss 1.74927  validloss 2.02772±0.00000  bestvalidloss 1.93900  last_update 2\n",
      "train: iter 163  trainloss 1.75651  validloss 2.12587±0.00000  bestvalidloss 1.93900  last_update 3\n",
      "train: iter 164  trainloss 1.75894  validloss 2.12042±0.00000  bestvalidloss 1.93900  last_update 4\n",
      "train: iter 165  trainloss 1.74203  validloss 2.08019±0.00000  bestvalidloss 1.93900  last_update 5\n",
      "train: iter 166  trainloss 1.74633  validloss 2.12521±0.00000  bestvalidloss 1.93900  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 1.74834  validloss 2.15064±0.00000  bestvalidloss 1.93900  last_update 7\n",
      "train: iter 168  trainloss 1.74318  validloss 2.18820±0.00000  bestvalidloss 1.93900  last_update 8\n",
      "train: iter 169  trainloss 1.74415  validloss 2.17236±0.00000  bestvalidloss 1.93900  last_update 9\n",
      "train: iter 170  trainloss 1.76347  validloss 2.04771±0.00000  bestvalidloss 1.93900  last_update 10\n",
      "train: iter 171  trainloss 1.72464  validloss 2.16910±0.00000  bestvalidloss 1.93900  last_update 11\n",
      "train: iter 172  trainloss 1.76288  validloss 2.09486±0.00000  bestvalidloss 1.93900  last_update 12\n",
      "train: iter 173  trainloss 1.75711  validloss 2.15898±0.00000  bestvalidloss 1.93900  last_update 13\n",
      "train: iter 174  trainloss 1.73747  validloss 2.13605±0.00000  bestvalidloss 1.93900  last_update 14\n",
      "train: iter 175  trainloss 1.75897  validloss 1.98962±0.00000  bestvalidloss 1.93900  last_update 15\n",
      "train: iter 176  trainloss 1.74017  validloss 2.05693±0.00000  bestvalidloss 1.93900  last_update 16\n",
      "train: iter 177  trainloss 1.76629  validloss 2.18758±0.00000  bestvalidloss 1.93900  last_update 17\n",
      "train: iter 178  trainloss 1.74471  validloss 2.15983±0.00000  bestvalidloss 1.93900  last_update 18\n",
      "train: iter 179  trainloss 1.73981  validloss 1.95283±0.00000  bestvalidloss 1.93900  last_update 19\n",
      "train: iter 180  trainloss 1.74966  validloss 2.22173±0.00000  bestvalidloss 1.93900  last_update 20\n",
      "train: iter 181  trainloss 1.74303  validloss 1.97995±0.00000  bestvalidloss 1.93900  last_update 21\n",
      "train: iter 182  trainloss 1.76650  validloss 2.14843±0.00000  bestvalidloss 1.93900  last_update 22\n",
      "train: iter 183  trainloss 1.75820  validloss 2.16863±0.00000  bestvalidloss 1.93900  last_update 23\n",
      "train: iter 184  trainloss 1.76851  validloss 2.15582±0.00000  bestvalidloss 1.93900  last_update 24\n",
      "train: iter 185  trainloss 1.76812  validloss 2.06190±0.00000  bestvalidloss 1.93900  last_update 25\n",
      "train: iter 186  trainloss 1.73563  validloss 2.00975±0.00000  bestvalidloss 1.93900  last_update 26\n",
      "train: iter 187  trainloss 1.73989  validloss 2.11493±0.00000  bestvalidloss 1.93900  last_update 27\n",
      "train: iter 188  trainloss 1.71653  validloss 2.10933±0.00000  bestvalidloss 1.93900  last_update 28\n",
      "train: iter 189  trainloss 1.73986  validloss 1.91298±0.00000  bestvalidloss 1.91298  last_update 0\n",
      "train: iter 190  trainloss 1.74309  validloss 2.06265±0.00000  bestvalidloss 1.91298  last_update 1\n",
      "train: iter 191  trainloss 1.73036  validloss 2.22257±0.00000  bestvalidloss 1.91298  last_update 2\n",
      "train: iter 192  trainloss 1.74823  validloss 2.09904±0.00000  bestvalidloss 1.91298  last_update 3\n",
      "train: iter 193  trainloss 1.73351  validloss 2.21531±0.00000  bestvalidloss 1.91298  last_update 4\n",
      "train: iter 194  trainloss 1.75691  validloss 2.15756±0.00000  bestvalidloss 1.91298  last_update 5\n",
      "train: iter 195  trainloss 1.75268  validloss 2.04962±0.00000  bestvalidloss 1.91298  last_update 6\n",
      "train: iter 196  trainloss 1.73208  validloss 2.10889±0.00000  bestvalidloss 1.91298  last_update 7\n",
      "train: iter 197  trainloss 1.74746  validloss 2.20085±0.00000  bestvalidloss 1.91298  last_update 8\n",
      "train: iter 198  trainloss 1.73995  validloss 2.10353±0.00000  bestvalidloss 1.91298  last_update 9\n",
      "train: iter 199  trainloss 1.73568  validloss 2.15382±0.00000  bestvalidloss 1.91298  last_update 10\n",
      "train: iter 200  trainloss 1.74865  validloss 1.99854±0.00000  bestvalidloss 1.91298  last_update 11\n",
      "train: iter 201  trainloss 1.78540  validloss 2.15113±0.00000  bestvalidloss 1.91298  last_update 12\n",
      "train: iter 202  trainloss 1.73782  validloss 2.24428±0.00000  bestvalidloss 1.91298  last_update 13\n",
      "train: iter 203  trainloss 1.74028  validloss 2.24965±0.00000  bestvalidloss 1.91298  last_update 14\n",
      "train: iter 204  trainloss 1.74234  validloss 2.13671±0.00000  bestvalidloss 1.91298  last_update 15\n",
      "train: iter 205  trainloss 1.77388  validloss 2.17710±0.00000  bestvalidloss 1.91298  last_update 16\n",
      "train: iter 206  trainloss 1.72660  validloss 2.15139±0.00000  bestvalidloss 1.91298  last_update 17\n",
      "train: iter 207  trainloss 1.72519  validloss 2.02638±0.00000  bestvalidloss 1.91298  last_update 18\n",
      "train: iter 208  trainloss 1.74325  validloss 2.09829±0.00000  bestvalidloss 1.91298  last_update 19\n",
      "train: iter 209  trainloss 1.77279  validloss 2.14132±0.00000  bestvalidloss 1.91298  last_update 20\n",
      "train: iter 210  trainloss 1.74606  validloss 2.14605±0.00000  bestvalidloss 1.91298  last_update 21\n",
      "train: iter 211  trainloss 1.71766  validloss 2.01575±0.00000  bestvalidloss 1.91298  last_update 22\n",
      "train: iter 212  trainloss 1.74657  validloss 2.01973±0.00000  bestvalidloss 1.91298  last_update 23\n",
      "train: iter 213  trainloss 1.74916  validloss 2.12707±0.00000  bestvalidloss 1.91298  last_update 24\n",
      "train: iter 214  trainloss 1.72403  validloss 2.06630±0.00000  bestvalidloss 1.91298  last_update 25\n",
      "train: iter 215  trainloss 1.71771  validloss 2.05700±0.00000  bestvalidloss 1.91298  last_update 26\n",
      "train: iter 216  trainloss 1.75169  validloss 2.08606±0.00000  bestvalidloss 1.91298  last_update 27\n",
      "train: iter 217  trainloss 1.73404  validloss 2.08421±0.00000  bestvalidloss 1.91298  last_update 28\n",
      "train: iter 218  trainloss 1.75315  validloss 2.13587±0.00000  bestvalidloss 1.91298  last_update 29\n",
      "train: iter 219  trainloss 1.75730  validloss 2.20632±0.00000  bestvalidloss 1.91298  last_update 30\n",
      "train: iter 220  trainloss 1.74636  validloss 2.03398±0.00000  bestvalidloss 1.91298  last_update 31\n",
      "train: iter 221  trainloss 1.76785  validloss 2.17922±0.00000  bestvalidloss 1.91298  last_update 32\n",
      "train: iter 222  trainloss 1.74777  validloss 2.11563±0.00000  bestvalidloss 1.91298  last_update 33\n",
      "train: iter 223  trainloss 1.73513  validloss 2.01657±0.00000  bestvalidloss 1.91298  last_update 34\n",
      "train: iter 224  trainloss 1.75114  validloss 2.10111±0.00000  bestvalidloss 1.91298  last_update 35\n",
      "train: iter 225  trainloss 1.73140  validloss 1.99668±0.00000  bestvalidloss 1.91298  last_update 36\n",
      "train: iter 226  trainloss 1.72228  validloss 1.96406±0.00000  bestvalidloss 1.91298  last_update 37\n",
      "train: iter 227  trainloss 1.73155  validloss 2.02794±0.00000  bestvalidloss 1.91298  last_update 38\n",
      "train: iter 228  trainloss 1.73196  validloss 2.00858±0.00000  bestvalidloss 1.91298  last_update 39\n",
      "train: iter 229  trainloss 1.73662  validloss 2.08339±0.00000  bestvalidloss 1.91298  last_update 40\n",
      "train: iter 230  trainloss 1.73972  validloss 2.09356±0.00000  bestvalidloss 1.91298  last_update 41\n",
      "train: iter 231  trainloss 1.73001  validloss 2.09722±0.00000  bestvalidloss 1.91298  last_update 42\n",
      "train: iter 232  trainloss 1.74129  validloss 2.12949±0.00000  bestvalidloss 1.91298  last_update 43\n",
      "train: iter 233  trainloss 1.72987  validloss 2.10452±0.00000  bestvalidloss 1.91298  last_update 44\n",
      "train: iter 234  trainloss 1.73263  validloss 1.97266±0.00000  bestvalidloss 1.91298  last_update 45\n",
      "train: iter 235  trainloss 1.73120  validloss 2.24045±0.00000  bestvalidloss 1.91298  last_update 46\n",
      "train: iter 236  trainloss 1.72465  validloss 2.07254±0.00000  bestvalidloss 1.91298  last_update 47\n",
      "train: iter 237  trainloss 1.72267  validloss 2.09491±0.00000  bestvalidloss 1.91298  last_update 48\n",
      "train: iter 238  trainloss 1.73433  validloss 2.10821±0.00000  bestvalidloss 1.91298  last_update 49\n",
      "train: iter 239  trainloss 1.72525  validloss 2.17483±0.00000  bestvalidloss 1.91298  last_update 50\n",
      "train: iter 240  trainloss 1.73151  validloss 2.13907±0.00000  bestvalidloss 1.91298  last_update 51\n",
      "train: iter 241  trainloss 1.74516  validloss 2.22075±0.00000  bestvalidloss 1.91298  last_update 52\n",
      "train: iter 242  trainloss 1.73343  validloss 2.14330±0.00000  bestvalidloss 1.91298  last_update 53\n",
      "train: iter 243  trainloss 1.72004  validloss 2.18660±0.00000  bestvalidloss 1.91298  last_update 54\n",
      "train: iter 244  trainloss 1.72653  validloss 2.13889±0.00000  bestvalidloss 1.91298  last_update 55\n",
      "train: iter 245  trainloss 1.75197  validloss 2.13938±0.00000  bestvalidloss 1.91298  last_update 56\n",
      "train: iter 246  trainloss 1.72886  validloss 2.05967±0.00000  bestvalidloss 1.91298  last_update 57\n",
      "train: iter 247  trainloss 1.72296  validloss 2.15241±0.00000  bestvalidloss 1.91298  last_update 58\n",
      "train: iter 248  trainloss 1.72598  validloss 2.03525±0.00000  bestvalidloss 1.91298  last_update 59\n",
      "train: iter 249  trainloss 1.75039  validloss 2.11748±0.00000  bestvalidloss 1.91298  last_update 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 250  trainloss 1.72985  validloss 2.09672±0.00000  bestvalidloss 1.91298  last_update 61\n",
      "train: iter 251  trainloss 1.71586  validloss 2.05149±0.00000  bestvalidloss 1.91298  last_update 62\n",
      "train: iter 252  trainloss 1.73459  validloss 2.10184±0.00000  bestvalidloss 1.91298  last_update 63\n",
      "train: iter 253  trainloss 1.75225  validloss 2.26311±0.00000  bestvalidloss 1.91298  last_update 64\n",
      "train: iter 254  trainloss 1.70369  validloss 2.18565±0.00000  bestvalidloss 1.91298  last_update 65\n",
      "train: iter 255  trainloss 1.74193  validloss 2.04342±0.00000  bestvalidloss 1.91298  last_update 66\n",
      "train: iter 256  trainloss 1.72574  validloss 2.03590±0.00000  bestvalidloss 1.91298  last_update 67\n",
      "train: iter 257  trainloss 1.73751  validloss 2.00254±0.00000  bestvalidloss 1.91298  last_update 68\n",
      "train: iter 258  trainloss 1.73445  validloss 2.01974±0.00000  bestvalidloss 1.91298  last_update 69\n",
      "train: iter 259  trainloss 1.76063  validloss 2.26300±0.00000  bestvalidloss 1.91298  last_update 70\n",
      "train: iter 260  trainloss 1.72216  validloss 2.06953±0.00000  bestvalidloss 1.91298  last_update 71\n",
      "train: iter 261  trainloss 1.74592  validloss 2.06101±0.00000  bestvalidloss 1.91298  last_update 72\n",
      "train: iter 262  trainloss 1.70999  validloss 2.23596±0.00000  bestvalidloss 1.91298  last_update 73\n",
      "train: iter 263  trainloss 1.73284  validloss 2.09961±0.00000  bestvalidloss 1.91298  last_update 74\n",
      "train: iter 264  trainloss 1.71554  validloss 2.32636±0.00000  bestvalidloss 1.91298  last_update 75\n",
      "train: iter 265  trainloss 1.72301  validloss 2.06864±0.00000  bestvalidloss 1.91298  last_update 76\n",
      "train: iter 266  trainloss 1.73277  validloss 2.17024±0.00000  bestvalidloss 1.91298  last_update 77\n",
      "train: iter 267  trainloss 1.71021  validloss 2.21945±0.00000  bestvalidloss 1.91298  last_update 78\n",
      "train: iter 268  trainloss 1.72038  validloss 2.06791±0.00000  bestvalidloss 1.91298  last_update 79\n",
      "train: iter 269  trainloss 1.72950  validloss 1.96877±0.00000  bestvalidloss 1.91298  last_update 80\n",
      "train: iter 270  trainloss 1.72188  validloss 2.10003±0.00000  bestvalidloss 1.91298  last_update 81\n",
      "train: iter 271  trainloss 1.71235  validloss 2.19352±0.00000  bestvalidloss 1.91298  last_update 82\n",
      "train: iter 272  trainloss 1.72545  validloss 1.98171±0.00000  bestvalidloss 1.91298  last_update 83\n",
      "train: iter 273  trainloss 1.73756  validloss 2.26172±0.00000  bestvalidloss 1.91298  last_update 84\n",
      "train: iter 274  trainloss 1.72121  validloss 2.39547±0.00000  bestvalidloss 1.91298  last_update 85\n",
      "train: iter 275  trainloss 1.71672  validloss 2.20936±0.00000  bestvalidloss 1.91298  last_update 86\n",
      "train: iter 276  trainloss 1.73201  validloss 2.23821±0.00000  bestvalidloss 1.91298  last_update 87\n",
      "train: iter 277  trainloss 1.72858  validloss 2.07850±0.00000  bestvalidloss 1.91298  last_update 88\n",
      "train: iter 278  trainloss 1.74529  validloss 2.13000±0.00000  bestvalidloss 1.91298  last_update 89\n",
      "train: iter 279  trainloss 1.72157  validloss 2.12464±0.00000  bestvalidloss 1.91298  last_update 90\n",
      "train: iter 280  trainloss 1.73534  validloss 2.01175±0.00000  bestvalidloss 1.91298  last_update 91\n",
      "train: iter 281  trainloss 1.70016  validloss 2.07974±0.00000  bestvalidloss 1.91298  last_update 92\n",
      "train: iter 282  trainloss 1.73231  validloss 2.05896±0.00000  bestvalidloss 1.91298  last_update 93\n",
      "train: iter 283  trainloss 1.74222  validloss 2.07615±0.00000  bestvalidloss 1.91298  last_update 94\n",
      "train: iter 284  trainloss 1.76223  validloss 2.15277±0.00000  bestvalidloss 1.91298  last_update 95\n",
      "train: iter 285  trainloss 1.74459  validloss 2.23317±0.00000  bestvalidloss 1.91298  last_update 96\n",
      "train: iter 286  trainloss 1.69776  validloss 2.20726±0.00000  bestvalidloss 1.91298  last_update 97\n",
      "train: iter 287  trainloss 1.73115  validloss 1.97009±0.00000  bestvalidloss 1.91298  last_update 98\n",
      "train: iter 288  trainloss 1.74046  validloss 2.12665±0.00000  bestvalidloss 1.91298  last_update 99\n",
      "train: iter 289  trainloss 1.71499  validloss 2.25209±0.00000  bestvalidloss 1.91298  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-11.0437)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(4.3481)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8594555714535662\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
