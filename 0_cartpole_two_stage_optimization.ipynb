{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-20625.3926)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 19051.46793  validloss 20869.94328±0.00000  bestvalidloss 20869.94328  last_update 0\n",
      "train: iter 1  trainloss 2170.79988  validloss 1318.04865±0.00000  bestvalidloss 1318.04865  last_update 0\n",
      "train: iter 2  trainloss 1511.67232  validloss 1207.23717±0.00000  bestvalidloss 1207.23717  last_update 0\n",
      "train: iter 3  trainloss 1233.11430  validloss 1268.54904±0.00000  bestvalidloss 1207.23717  last_update 1\n",
      "train: iter 4  trainloss 1103.43021  validloss 1092.06158±0.00000  bestvalidloss 1092.06158  last_update 0\n",
      "train: iter 5  trainloss 979.53467  validloss 1016.78927±0.00000  bestvalidloss 1016.78927  last_update 0\n",
      "train: iter 6  trainloss 900.03035  validloss 996.97883±0.00000  bestvalidloss 996.97883  last_update 0\n",
      "train: iter 7  trainloss 874.28969  validloss 1019.47540±0.00000  bestvalidloss 996.97883  last_update 1\n",
      "train: iter 8  trainloss 818.35685  validloss 1152.27263±0.00000  bestvalidloss 996.97883  last_update 2\n",
      "train: iter 9  trainloss 765.89515  validloss 1161.53709±0.00000  bestvalidloss 996.97883  last_update 3\n",
      "train: iter 10  trainloss 730.02595  validloss 1026.85540±0.00000  bestvalidloss 996.97883  last_update 4\n",
      "train: iter 11  trainloss 712.98243  validloss 3188.71958±0.00000  bestvalidloss 996.97883  last_update 5\n",
      "train: iter 12  trainloss 732.36727  validloss 1088.00213±0.00000  bestvalidloss 996.97883  last_update 6\n",
      "train: iter 13  trainloss 717.75453  validloss 727.00446±0.00000  bestvalidloss 727.00446  last_update 0\n",
      "train: iter 14  trainloss 643.44176  validloss 694.22586±0.00000  bestvalidloss 694.22586  last_update 0\n",
      "train: iter 15  trainloss 561.75004  validloss 630.15265±0.00000  bestvalidloss 630.15265  last_update 0\n",
      "train: iter 16  trainloss 502.71950  validloss 663.78886±0.00000  bestvalidloss 630.15265  last_update 1\n",
      "train: iter 17  trainloss 458.27211  validloss 635.44803±0.00000  bestvalidloss 630.15265  last_update 2\n",
      "train: iter 18  trainloss 419.66566  validloss 570.84841±0.00000  bestvalidloss 570.84841  last_update 0\n",
      "train: iter 19  trainloss 380.74134  validloss 652.92701±0.00000  bestvalidloss 570.84841  last_update 1\n",
      "train: iter 20  trainloss 336.79504  validloss 470.48919±0.00000  bestvalidloss 470.48919  last_update 0\n",
      "train: iter 21  trainloss 285.88157  validloss 470.33673±0.00000  bestvalidloss 470.33673  last_update 0\n",
      "train: iter 22  trainloss 248.76135  validloss 398.53267±0.00000  bestvalidloss 398.53267  last_update 0\n",
      "train: iter 23  trainloss 197.14684  validloss 362.64413±0.00000  bestvalidloss 362.64413  last_update 0\n",
      "train: iter 24  trainloss 162.85117  validloss 312.57720±0.00000  bestvalidloss 312.57720  last_update 0\n",
      "train: iter 25  trainloss 118.74376  validloss 255.19794±0.00000  bestvalidloss 255.19794  last_update 0\n",
      "train: iter 26  trainloss 88.29831  validloss 169.18625±0.00000  bestvalidloss 169.18625  last_update 0\n",
      "train: iter 27  trainloss 45.33219  validloss 201.47853±0.00000  bestvalidloss 169.18625  last_update 1\n",
      "train: iter 28  trainloss 40.10742  validloss 284.28830±0.00000  bestvalidloss 169.18625  last_update 2\n",
      "train: iter 29  trainloss -10.30072  validloss 39.66332±0.00000  bestvalidloss 39.66332  last_update 0\n",
      "train: iter 30  trainloss -50.36511  validloss 91.60257±0.00000  bestvalidloss 39.66332  last_update 1\n",
      "train: iter 31  trainloss -50.73162  validloss -19.59106±0.00000  bestvalidloss -19.59106  last_update 0\n",
      "train: iter 32  trainloss -59.57918  validloss 71.29052±0.00000  bestvalidloss -19.59106  last_update 1\n",
      "train: iter 33  trainloss -119.28648  validloss -59.99474±0.00000  bestvalidloss -59.99474  last_update 0\n",
      "train: iter 34  trainloss -153.07347  validloss -76.42882±0.00000  bestvalidloss -76.42882  last_update 0\n",
      "train: iter 35  trainloss -136.23359  validloss 66.33181±0.00000  bestvalidloss -76.42882  last_update 1\n",
      "train: iter 36  trainloss -182.99007  validloss -2.40472±0.00000  bestvalidloss -76.42882  last_update 2\n",
      "train: iter 37  trainloss -190.82269  validloss -91.10000±0.00000  bestvalidloss -91.10000  last_update 0\n",
      "train: iter 38  trainloss -239.00698  validloss -202.50920±0.00000  bestvalidloss -202.50920  last_update 0\n",
      "train: iter 39  trainloss -239.16152  validloss -189.51516±0.00000  bestvalidloss -202.50920  last_update 1\n",
      "train: iter 40  trainloss -255.04034  validloss -224.02776±0.00000  bestvalidloss -224.02776  last_update 0\n",
      "train: iter 41  trainloss -274.82939  validloss -201.17706±0.00000  bestvalidloss -224.02776  last_update 1\n",
      "train: iter 42  trainloss -311.54544  validloss -240.26883±0.00000  bestvalidloss -240.26883  last_update 0\n",
      "train: iter 43  trainloss -325.36165  validloss -287.32144±0.00000  bestvalidloss -287.32144  last_update 0\n",
      "train: iter 44  trainloss -318.19577  validloss -217.15006±0.00000  bestvalidloss -287.32144  last_update 1\n",
      "train: iter 45  trainloss -349.21262  validloss -280.24971±0.00000  bestvalidloss -287.32144  last_update 2\n",
      "train: iter 46  trainloss -355.20506  validloss -308.63096±0.00000  bestvalidloss -308.63096  last_update 0\n",
      "train: iter 47  trainloss -401.10312  validloss -323.91594±0.00000  bestvalidloss -323.91594  last_update 0\n",
      "train: iter 48  trainloss -407.52062  validloss -331.85825±0.00000  bestvalidloss -331.85825  last_update 0\n",
      "train: iter 49  trainloss -313.61604  validloss -265.98002±0.00000  bestvalidloss -331.85825  last_update 1\n",
      "train: iter 50  trainloss -408.98898  validloss -143.92970±0.00000  bestvalidloss -331.85825  last_update 2\n",
      "train: iter 51  trainloss -403.60508  validloss -377.34098±0.00000  bestvalidloss -377.34098  last_update 0\n",
      "train: iter 52  trainloss -437.20674  validloss -347.69961±0.00000  bestvalidloss -377.34098  last_update 1\n",
      "train: iter 53  trainloss -469.46146  validloss -332.33079±0.00000  bestvalidloss -377.34098  last_update 2\n",
      "train: iter 54  trainloss -480.16153  validloss -413.34652±0.00000  bestvalidloss -413.34652  last_update 0\n",
      "train: iter 55  trainloss -484.70655  validloss -421.96710±0.00000  bestvalidloss -421.96710  last_update 0\n",
      "train: iter 56  trainloss -470.92622  validloss -420.33236±0.00000  bestvalidloss -421.96710  last_update 1\n",
      "train: iter 57  trainloss -487.48937  validloss -417.73627±0.00000  bestvalidloss -421.96710  last_update 2\n",
      "train: iter 58  trainloss -438.26804  validloss -265.46913±0.00000  bestvalidloss -421.96710  last_update 3\n",
      "train: iter 59  trainloss -503.23614  validloss -377.27174±0.00000  bestvalidloss -421.96710  last_update 4\n",
      "train: iter 60  trainloss -485.40344  validloss -465.53034±0.00000  bestvalidloss -465.53034  last_update 0\n",
      "train: iter 61  trainloss -540.82381  validloss -451.78770±0.00000  bestvalidloss -465.53034  last_update 1\n",
      "train: iter 62  trainloss -488.16204  validloss -456.94760±0.00000  bestvalidloss -465.53034  last_update 2\n",
      "train: iter 63  trainloss -535.54702  validloss -414.04060±0.00000  bestvalidloss -465.53034  last_update 3\n",
      "train: iter 64  trainloss -509.00529  validloss -439.12809±0.00000  bestvalidloss -465.53034  last_update 4\n",
      "train: iter 65  trainloss -532.41462  validloss -455.78934±0.00000  bestvalidloss -465.53034  last_update 5\n",
      "train: iter 66  trainloss -577.15866  validloss -443.29813±0.00000  bestvalidloss -465.53034  last_update 6\n",
      "train: iter 67  trainloss -433.83185  validloss -540.47156±0.00000  bestvalidloss -540.47156  last_update 0\n",
      "train: iter 68  trainloss -491.23876  validloss -346.49677±0.00000  bestvalidloss -540.47156  last_update 1\n",
      "train: iter 69  trainloss -560.73711  validloss -468.53980±0.00000  bestvalidloss -540.47156  last_update 2\n",
      "train: iter 70  trainloss -595.75359  validloss -532.71417±0.00000  bestvalidloss -540.47156  last_update 3\n",
      "train: iter 71  trainloss -568.02550  validloss -528.56024±0.00000  bestvalidloss -540.47156  last_update 4\n",
      "train: iter 72  trainloss -609.97203  validloss -551.56871±0.00000  bestvalidloss -551.56871  last_update 0\n",
      "train: iter 73  trainloss -566.70248  validloss -480.72522±0.00000  bestvalidloss -551.56871  last_update 1\n",
      "train: iter 74  trainloss -603.53045  validloss -562.10523±0.00000  bestvalidloss -562.10523  last_update 0\n",
      "train: iter 75  trainloss -618.07131  validloss -386.67357±0.00000  bestvalidloss -562.10523  last_update 1\n",
      "train: iter 76  trainloss -589.49737  validloss -577.12133±0.00000  bestvalidloss -577.12133  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -665.31143  validloss -518.79138±0.00000  bestvalidloss -577.12133  last_update 1\n",
      "train: iter 78  trainloss -668.87007  validloss -559.85938±0.00000  bestvalidloss -577.12133  last_update 2\n",
      "train: iter 79  trainloss -569.13606  validloss -496.16539±0.00000  bestvalidloss -577.12133  last_update 3\n",
      "train: iter 80  trainloss -548.35174  validloss -397.80622±0.00000  bestvalidloss -577.12133  last_update 4\n",
      "train: iter 81  trainloss -579.36594  validloss -506.74560±0.00000  bestvalidloss -577.12133  last_update 5\n",
      "train: iter 82  trainloss -581.23370  validloss -480.39468±0.00000  bestvalidloss -577.12133  last_update 6\n",
      "train: iter 83  trainloss -625.04902  validloss -560.36255±0.00000  bestvalidloss -577.12133  last_update 7\n",
      "train: iter 84  trainloss -581.67070  validloss -634.02512±0.00000  bestvalidloss -634.02512  last_update 0\n",
      "train: iter 85  trainloss -647.99009  validloss -507.29285±0.00000  bestvalidloss -634.02512  last_update 1\n",
      "train: iter 86  trainloss -650.03646  validloss -441.33872±0.00000  bestvalidloss -634.02512  last_update 2\n",
      "train: iter 87  trainloss -718.29705  validloss -656.49318±0.00000  bestvalidloss -656.49318  last_update 0\n",
      "train: iter 88  trainloss -723.87150  validloss -591.32993±0.00000  bestvalidloss -656.49318  last_update 1\n",
      "train: iter 89  trainloss -640.01419  validloss -556.32103±0.00000  bestvalidloss -656.49318  last_update 2\n",
      "train: iter 90  trainloss -704.18875  validloss -609.75936±0.00000  bestvalidloss -656.49318  last_update 3\n",
      "train: iter 91  trainloss -613.64183  validloss -327.65390±0.00000  bestvalidloss -656.49318  last_update 4\n",
      "train: iter 92  trainloss -704.27496  validloss -604.98090±0.00000  bestvalidloss -656.49318  last_update 5\n",
      "train: iter 93  trainloss -608.30267  validloss -623.73516±0.00000  bestvalidloss -656.49318  last_update 6\n",
      "train: iter 94  trainloss -658.99949  validloss -396.17451±0.00000  bestvalidloss -656.49318  last_update 7\n",
      "train: iter 95  trainloss -732.42589  validloss -628.74921±0.00000  bestvalidloss -656.49318  last_update 8\n",
      "train: iter 96  trainloss -726.78058  validloss -727.66550±0.00000  bestvalidloss -727.66550  last_update 0\n",
      "train: iter 97  trainloss -587.77125  validloss -479.11374±0.00000  bestvalidloss -727.66550  last_update 1\n",
      "train: iter 98  trainloss -775.67083  validloss -671.73006±0.00000  bestvalidloss -727.66550  last_update 2\n",
      "train: iter 99  trainloss -611.45099  validloss -721.94232±0.00000  bestvalidloss -727.66550  last_update 3\n",
      "train: iter 100  trainloss -592.95750  validloss -416.22911±0.00000  bestvalidloss -727.66550  last_update 4\n",
      "train: iter 101  trainloss -727.39611  validloss -548.76672±0.00000  bestvalidloss -727.66550  last_update 5\n",
      "train: iter 102  trainloss -697.63198  validloss -701.97004±0.00000  bestvalidloss -727.66550  last_update 6\n",
      "train: iter 103  trainloss -760.65017  validloss -698.20095±0.00000  bestvalidloss -727.66550  last_update 7\n",
      "train: iter 104  trainloss -638.45043  validloss -662.41137±0.00000  bestvalidloss -727.66550  last_update 8\n",
      "train: iter 105  trainloss -695.24751  validloss -501.01974±0.00000  bestvalidloss -727.66550  last_update 9\n",
      "train: iter 106  trainloss -751.84820  validloss -697.11496±0.00000  bestvalidloss -727.66550  last_update 10\n",
      "train: iter 107  trainloss -534.46471  validloss -682.00977±0.00000  bestvalidloss -727.66550  last_update 11\n",
      "train: iter 108  trainloss -743.83308  validloss -575.32472±0.00000  bestvalidloss -727.66550  last_update 12\n",
      "train: iter 109  trainloss -775.35539  validloss -714.43450±0.00000  bestvalidloss -727.66550  last_update 13\n",
      "train: iter 110  trainloss -809.83849  validloss -713.73006±0.00000  bestvalidloss -727.66550  last_update 14\n",
      "train: iter 111  trainloss -735.71154  validloss -661.34291±0.00000  bestvalidloss -727.66550  last_update 15\n",
      "train: iter 112  trainloss -657.37499  validloss -619.53100±0.00000  bestvalidloss -727.66550  last_update 16\n",
      "train: iter 113  trainloss -780.57627  validloss -720.07623±0.00000  bestvalidloss -727.66550  last_update 17\n",
      "train: iter 114  trainloss -739.16783  validloss -746.94975±0.00000  bestvalidloss -746.94975  last_update 0\n",
      "train: iter 115  trainloss -691.33236  validloss -573.33089±0.00000  bestvalidloss -746.94975  last_update 1\n",
      "train: iter 116  trainloss -709.42528  validloss -811.20557±0.00000  bestvalidloss -811.20557  last_update 0\n",
      "train: iter 117  trainloss -825.58969  validloss -668.44572±0.00000  bestvalidloss -811.20557  last_update 1\n",
      "train: iter 118  trainloss -731.25159  validloss -760.73759±0.00000  bestvalidloss -811.20557  last_update 2\n",
      "train: iter 119  trainloss -771.26780  validloss -596.40987±0.00000  bestvalidloss -811.20557  last_update 3\n",
      "train: iter 120  trainloss -865.06284  validloss -787.73953±0.00000  bestvalidloss -811.20557  last_update 4\n",
      "train: iter 121  trainloss -737.03264  validloss -727.49651±0.00000  bestvalidloss -811.20557  last_update 5\n",
      "train: iter 122  trainloss -879.20977  validloss -759.00693±0.00000  bestvalidloss -811.20557  last_update 6\n",
      "train: iter 123  trainloss -781.51286  validloss -864.53514±0.00000  bestvalidloss -864.53514  last_update 0\n",
      "train: iter 124  trainloss -810.66176  validloss -466.00448±0.00000  bestvalidloss -864.53514  last_update 1\n",
      "train: iter 125  trainloss -817.71868  validloss -486.67879±0.00000  bestvalidloss -864.53514  last_update 2\n",
      "train: iter 126  trainloss -781.80837  validloss -158.62766±0.00000  bestvalidloss -864.53514  last_update 3\n",
      "train: iter 127  trainloss -832.79593  validloss -605.25306±0.00000  bestvalidloss -864.53514  last_update 4\n",
      "train: iter 128  trainloss -785.36545  validloss -614.80142±0.00000  bestvalidloss -864.53514  last_update 5\n",
      "train: iter 129  trainloss -721.50668  validloss -350.25535±0.00000  bestvalidloss -864.53514  last_update 6\n",
      "train: iter 130  trainloss -849.92663  validloss -786.38503±0.00000  bestvalidloss -864.53514  last_update 7\n",
      "train: iter 131  trainloss -902.14060  validloss -762.75583±0.00000  bestvalidloss -864.53514  last_update 8\n",
      "train: iter 132  trainloss -817.25829  validloss -866.48035±0.00000  bestvalidloss -866.48035  last_update 0\n",
      "train: iter 133  trainloss -928.80682  validloss -776.79869±0.00000  bestvalidloss -866.48035  last_update 1\n",
      "train: iter 134  trainloss -753.44227  validloss -636.25941±0.00000  bestvalidloss -866.48035  last_update 2\n",
      "train: iter 135  trainloss -801.95348  validloss -873.36316±0.00000  bestvalidloss -873.36316  last_update 0\n",
      "train: iter 136  trainloss -801.88865  validloss -795.20810±0.00000  bestvalidloss -873.36316  last_update 1\n",
      "train: iter 137  trainloss -898.91407  validloss -798.36869±0.00000  bestvalidloss -873.36316  last_update 2\n",
      "train: iter 138  trainloss -794.75705  validloss -865.26746±0.00000  bestvalidloss -873.36316  last_update 3\n",
      "train: iter 139  trainloss -791.22748  validloss -672.60126±0.00000  bestvalidloss -873.36316  last_update 4\n",
      "train: iter 140  trainloss -892.08250  validloss -782.60115±0.00000  bestvalidloss -873.36316  last_update 5\n",
      "train: iter 141  trainloss -801.22173  validloss -937.39986±0.00000  bestvalidloss -937.39986  last_update 0\n",
      "train: iter 142  trainloss -925.82194  validloss -578.06883±0.00000  bestvalidloss -937.39986  last_update 1\n",
      "train: iter 143  trainloss -943.97078  validloss -911.75754±0.00000  bestvalidloss -937.39986  last_update 2\n",
      "train: iter 144  trainloss -912.76889  validloss -791.45273±0.00000  bestvalidloss -937.39986  last_update 3\n",
      "train: iter 145  trainloss -912.40867  validloss -817.73034±0.00000  bestvalidloss -937.39986  last_update 4\n",
      "train: iter 146  trainloss -455.07962  validloss -705.74825±0.00000  bestvalidloss -937.39986  last_update 5\n",
      "train: iter 147  trainloss -548.18678  validloss -476.29155±0.00000  bestvalidloss -937.39986  last_update 6\n",
      "train: iter 148  trainloss -817.59590  validloss -643.79096±0.00000  bestvalidloss -937.39986  last_update 7\n",
      "train: iter 149  trainloss -805.32253  validloss -603.08301±0.00000  bestvalidloss -937.39986  last_update 8\n",
      "train: iter 150  trainloss -904.38824  validloss -599.66089±0.00000  bestvalidloss -937.39986  last_update 9\n",
      "train: iter 151  trainloss -896.32609  validloss -942.93669±0.00000  bestvalidloss -942.93669  last_update 0\n",
      "train: iter 152  trainloss -918.43758  validloss -786.45995±0.00000  bestvalidloss -942.93669  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -877.18827  validloss -859.41870±0.00000  bestvalidloss -942.93669  last_update 2\n",
      "train: iter 154  trainloss -1002.36432  validloss -725.06163±0.00000  bestvalidloss -942.93669  last_update 3\n",
      "train: iter 155  trainloss -933.56057  validloss -956.26198±0.00000  bestvalidloss -956.26198  last_update 0\n",
      "train: iter 156  trainloss -905.50056  validloss -943.16220±0.00000  bestvalidloss -956.26198  last_update 1\n",
      "train: iter 157  trainloss -917.14723  validloss -838.17372±0.00000  bestvalidloss -956.26198  last_update 2\n",
      "train: iter 158  trainloss -430.42976  validloss -264.48766±0.00000  bestvalidloss -956.26198  last_update 3\n",
      "train: iter 159  trainloss -323.67264  validloss -234.00377±0.00000  bestvalidloss -956.26198  last_update 4\n",
      "train: iter 160  trainloss -545.28695  validloss -398.16158±0.00000  bestvalidloss -956.26198  last_update 5\n",
      "train: iter 161  trainloss -443.01045  validloss -634.32335±0.00000  bestvalidloss -956.26198  last_update 6\n",
      "train: iter 162  trainloss -936.46531  validloss -795.95234±0.00000  bestvalidloss -956.26198  last_update 7\n",
      "train: iter 163  trainloss -940.96669  validloss -904.27354±0.00000  bestvalidloss -956.26198  last_update 8\n",
      "train: iter 164  trainloss -927.71992  validloss -995.97908±0.00000  bestvalidloss -995.97908  last_update 0\n",
      "train: iter 165  trainloss -831.18340  validloss -638.58804±0.00000  bestvalidloss -995.97908  last_update 1\n",
      "train: iter 166  trainloss -1022.45667  validloss -918.32640±0.00000  bestvalidloss -995.97908  last_update 2\n",
      "train: iter 167  trainloss -804.21562  validloss -901.24152±0.00000  bestvalidloss -995.97908  last_update 3\n",
      "train: iter 168  trainloss -948.61088  validloss -864.22067±0.00000  bestvalidloss -995.97908  last_update 4\n",
      "train: iter 169  trainloss -954.42543  validloss -773.96665±0.00000  bestvalidloss -995.97908  last_update 5\n",
      "train: iter 170  trainloss -996.94592  validloss -1003.96850±0.00000  bestvalidloss -1003.96850  last_update 0\n",
      "train: iter 171  trainloss -986.92911  validloss -880.01267±0.00000  bestvalidloss -1003.96850  last_update 1\n",
      "train: iter 172  trainloss -1006.09235  validloss -917.12925±0.00000  bestvalidloss -1003.96850  last_update 2\n",
      "train: iter 173  trainloss -950.85743  validloss -969.18751±0.00000  bestvalidloss -1003.96850  last_update 3\n",
      "train: iter 174  trainloss -593.35329  validloss -887.83061±0.00000  bestvalidloss -1003.96850  last_update 4\n",
      "train: iter 175  trainloss -213.47108  validloss -115.73094±0.00000  bestvalidloss -1003.96850  last_update 5\n",
      "train: iter 176  trainloss -520.97225  validloss -364.06282±0.00000  bestvalidloss -1003.96850  last_update 6\n",
      "train: iter 177  trainloss -893.69364  validloss -687.24425±0.00000  bestvalidloss -1003.96850  last_update 7\n",
      "train: iter 178  trainloss -917.67113  validloss -957.97592±0.00000  bestvalidloss -1003.96850  last_update 8\n",
      "train: iter 179  trainloss -994.68800  validloss -748.99931±0.00000  bestvalidloss -1003.96850  last_update 9\n",
      "train: iter 180  trainloss -417.58224  validloss -998.39825±0.00000  bestvalidloss -1003.96850  last_update 10\n",
      "train: iter 181  trainloss -854.17139  validloss -540.10331±0.00000  bestvalidloss -1003.96850  last_update 11\n",
      "train: iter 182  trainloss -1048.95310  validloss -904.99363±0.00000  bestvalidloss -1003.96850  last_update 12\n",
      "train: iter 183  trainloss -1036.65184  validloss -1039.60481±0.00000  bestvalidloss -1039.60481  last_update 0\n",
      "train: iter 184  trainloss -1078.89361  validloss -1042.25892±0.00000  bestvalidloss -1042.25892  last_update 0\n",
      "train: iter 185  trainloss -1057.11769  validloss -909.32364±0.00000  bestvalidloss -1042.25892  last_update 1\n",
      "train: iter 186  trainloss -1021.67196  validloss -1035.66003±0.00000  bestvalidloss -1042.25892  last_update 2\n",
      "train: iter 187  trainloss -1038.41662  validloss -908.31027±0.00000  bestvalidloss -1042.25892  last_update 3\n",
      "train: iter 188  trainloss -980.71136  validloss -813.63545±0.00000  bestvalidloss -1042.25892  last_update 4\n",
      "train: iter 189  trainloss -980.14683  validloss -1024.95804±0.00000  bestvalidloss -1042.25892  last_update 5\n",
      "train: iter 190  trainloss -1104.47136  validloss -1030.53478±0.00000  bestvalidloss -1042.25892  last_update 6\n",
      "train: iter 191  trainloss -1084.91187  validloss -1005.46387±0.00000  bestvalidloss -1042.25892  last_update 7\n",
      "train: iter 192  trainloss -986.19766  validloss -971.39274±0.00000  bestvalidloss -1042.25892  last_update 8\n",
      "train: iter 193  trainloss -808.73717  validloss -850.62298±0.00000  bestvalidloss -1042.25892  last_update 9\n",
      "train: iter 194  trainloss -946.57019  validloss -708.22491±0.00000  bestvalidloss -1042.25892  last_update 10\n",
      "train: iter 195  trainloss -949.82792  validloss -809.71468±0.00000  bestvalidloss -1042.25892  last_update 11\n",
      "train: iter 196  trainloss -1008.36830  validloss -968.70701±0.00000  bestvalidloss -1042.25892  last_update 12\n",
      "train: iter 197  trainloss -1096.77311  validloss -945.58879±0.00000  bestvalidloss -1042.25892  last_update 13\n",
      "train: iter 198  trainloss -1011.75511  validloss -1081.76156±0.00000  bestvalidloss -1081.76156  last_update 0\n",
      "train: iter 199  trainloss -1017.25813  validloss -864.60558±0.00000  bestvalidloss -1081.76156  last_update 1\n",
      "train: iter 200  trainloss -1047.49522  validloss -894.55206±0.00000  bestvalidloss -1081.76156  last_update 2\n",
      "train: iter 201  trainloss -1059.96851  validloss -1037.77889±0.00000  bestvalidloss -1081.76156  last_update 3\n",
      "train: iter 202  trainloss -969.44117  validloss -1010.55391±0.00000  bestvalidloss -1081.76156  last_update 4\n",
      "train: iter 203  trainloss -1047.47002  validloss -942.30345±0.00000  bestvalidloss -1081.76156  last_update 5\n",
      "train: iter 204  trainloss -967.62667  validloss -1015.91086±0.00000  bestvalidloss -1081.76156  last_update 6\n",
      "train: iter 205  trainloss -974.51492  validloss -1009.79175±0.00000  bestvalidloss -1081.76156  last_update 7\n",
      "train: iter 206  trainloss -1016.06424  validloss -975.11433±0.00000  bestvalidloss -1081.76156  last_update 8\n",
      "train: iter 207  trainloss -1053.77295  validloss -950.04259±0.00000  bestvalidloss -1081.76156  last_update 9\n",
      "train: iter 208  trainloss -1057.28895  validloss -1024.70459±0.00000  bestvalidloss -1081.76156  last_update 10\n",
      "train: iter 209  trainloss -788.77436  validloss -1067.50525±0.00000  bestvalidloss -1081.76156  last_update 11\n",
      "train: iter 210  trainloss -768.42574  validloss -737.67230±0.00000  bestvalidloss -1081.76156  last_update 12\n",
      "train: iter 211  trainloss -614.30924  validloss -992.85170±0.00000  bestvalidloss -1081.76156  last_update 13\n",
      "train: iter 212  trainloss -664.50134  validloss -881.20656±0.00000  bestvalidloss -1081.76156  last_update 14\n",
      "train: iter 213  trainloss -880.52596  validloss -839.46358±0.00000  bestvalidloss -1081.76156  last_update 15\n",
      "train: iter 214  trainloss -978.33803  validloss -971.03112±0.00000  bestvalidloss -1081.76156  last_update 16\n",
      "train: iter 215  trainloss -1016.48001  validloss -799.29189±0.00000  bestvalidloss -1081.76156  last_update 17\n",
      "train: iter 216  trainloss -1075.57355  validloss -973.96144±0.00000  bestvalidloss -1081.76156  last_update 18\n",
      "train: iter 217  trainloss -1057.21956  validloss -987.24245±0.00000  bestvalidloss -1081.76156  last_update 19\n",
      "train: iter 218  trainloss -1069.26207  validloss -1057.16501±0.00000  bestvalidloss -1081.76156  last_update 20\n",
      "train: iter 219  trainloss -1117.18632  validloss -1090.32710±0.00000  bestvalidloss -1090.32710  last_update 0\n",
      "train: iter 220  trainloss -1117.00231  validloss -797.31219±0.00000  bestvalidloss -1090.32710  last_update 1\n",
      "train: iter 221  trainloss -960.89203  validloss -1113.74291±0.00000  bestvalidloss -1113.74291  last_update 0\n",
      "train: iter 222  trainloss -874.15569  validloss -892.23965±0.00000  bestvalidloss -1113.74291  last_update 1\n",
      "train: iter 223  trainloss -1104.82972  validloss -1035.67861±0.00000  bestvalidloss -1113.74291  last_update 2\n",
      "train: iter 224  trainloss -1004.73390  validloss -771.05870±0.00000  bestvalidloss -1113.74291  last_update 3\n",
      "train: iter 225  trainloss -1018.39304  validloss -929.51952±0.00000  bestvalidloss -1113.74291  last_update 4\n",
      "train: iter 226  trainloss -1111.07387  validloss -1063.35122±0.00000  bestvalidloss -1113.74291  last_update 5\n",
      "train: iter 227  trainloss -985.31310  validloss -1063.75277±0.00000  bestvalidloss -1113.74291  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1134.03569  validloss -1050.90223±0.00000  bestvalidloss -1113.74291  last_update 7\n",
      "train: iter 229  trainloss -1034.00858  validloss -1092.70904±0.00000  bestvalidloss -1113.74291  last_update 8\n",
      "train: iter 230  trainloss -1054.31550  validloss -860.96334±0.00000  bestvalidloss -1113.74291  last_update 9\n",
      "train: iter 231  trainloss -1078.40790  validloss -1110.39591±0.00000  bestvalidloss -1113.74291  last_update 10\n",
      "train: iter 232  trainloss -1157.31203  validloss -1067.70600±0.00000  bestvalidloss -1113.74291  last_update 11\n",
      "train: iter 233  trainloss -861.94938  validloss -1049.64593±0.00000  bestvalidloss -1113.74291  last_update 12\n",
      "train: iter 234  trainloss -960.95518  validloss -840.36923±0.00000  bestvalidloss -1113.74291  last_update 13\n",
      "train: iter 235  trainloss -1129.16029  validloss -999.73260±0.00000  bestvalidloss -1113.74291  last_update 14\n",
      "train: iter 236  trainloss -1078.94675  validloss -1107.94112±0.00000  bestvalidloss -1113.74291  last_update 15\n",
      "train: iter 237  trainloss -933.87210  validloss -1052.34066±0.00000  bestvalidloss -1113.74291  last_update 16\n",
      "train: iter 238  trainloss -900.52868  validloss -422.11820±0.00000  bestvalidloss -1113.74291  last_update 17\n",
      "train: iter 239  trainloss -1014.38049  validloss -969.23424±0.00000  bestvalidloss -1113.74291  last_update 18\n",
      "train: iter 240  trainloss -1094.49402  validloss -1022.07698±0.00000  bestvalidloss -1113.74291  last_update 19\n",
      "train: iter 241  trainloss -835.80202  validloss -1118.18873±0.00000  bestvalidloss -1118.18873  last_update 0\n",
      "train: iter 242  trainloss -920.21380  validloss -930.36804±0.00000  bestvalidloss -1118.18873  last_update 1\n",
      "train: iter 243  trainloss -1062.75391  validloss -635.19120±0.00000  bestvalidloss -1118.18873  last_update 2\n",
      "train: iter 244  trainloss -1177.91735  validloss -1072.81470±0.00000  bestvalidloss -1118.18873  last_update 3\n",
      "train: iter 245  trainloss -1002.99153  validloss -1143.34536±0.00000  bestvalidloss -1143.34536  last_update 0\n",
      "train: iter 246  trainloss -950.32668  validloss -673.75985±0.00000  bestvalidloss -1143.34536  last_update 1\n",
      "train: iter 247  trainloss -1072.93213  validloss -1068.04756±0.00000  bestvalidloss -1143.34536  last_update 2\n",
      "train: iter 248  trainloss -962.58165  validloss -844.62282±0.00000  bestvalidloss -1143.34536  last_update 3\n",
      "train: iter 249  trainloss -1078.77454  validloss -971.26793±0.00000  bestvalidloss -1143.34536  last_update 4\n",
      "train: iter 250  trainloss -1018.30407  validloss -873.82334±0.00000  bestvalidloss -1143.34536  last_update 5\n",
      "train: iter 251  trainloss -1072.71548  validloss -955.01815±0.00000  bestvalidloss -1143.34536  last_update 6\n",
      "train: iter 252  trainloss -1063.19041  validloss -1019.34147±0.00000  bestvalidloss -1143.34536  last_update 7\n",
      "train: iter 253  trainloss -336.19296  validloss -1078.67382±0.00000  bestvalidloss -1143.34536  last_update 8\n",
      "train: iter 254  trainloss -466.37157  validloss -146.27031±0.00000  bestvalidloss -1143.34536  last_update 9\n",
      "train: iter 255  trainloss -822.95960  validloss -688.52675±0.00000  bestvalidloss -1143.34536  last_update 10\n",
      "train: iter 256  trainloss -926.99164  validloss -954.14275±0.00000  bestvalidloss -1143.34536  last_update 11\n",
      "train: iter 257  trainloss -1134.62965  validloss -1068.51711±0.00000  bestvalidloss -1143.34536  last_update 12\n",
      "train: iter 258  trainloss -1017.16516  validloss -1114.12070±0.00000  bestvalidloss -1143.34536  last_update 13\n",
      "train: iter 259  trainloss -1092.74886  validloss -989.62637±0.00000  bestvalidloss -1143.34536  last_update 14\n",
      "train: iter 260  trainloss -1155.66696  validloss -1073.14606±0.00000  bestvalidloss -1143.34536  last_update 15\n",
      "train: iter 261  trainloss -1120.97722  validloss -1063.90705±0.00000  bestvalidloss -1143.34536  last_update 16\n",
      "train: iter 262  trainloss -1011.66971  validloss -1106.04472±0.00000  bestvalidloss -1143.34536  last_update 17\n",
      "train: iter 263  trainloss -713.19708  validloss -806.06560±0.00000  bestvalidloss -1143.34536  last_update 18\n",
      "train: iter 264  trainloss -1007.56330  validloss -735.63542±0.00000  bestvalidloss -1143.34536  last_update 19\n",
      "train: iter 265  trainloss -1158.29803  validloss -1067.11601±0.00000  bestvalidloss -1143.34536  last_update 20\n",
      "train: iter 266  trainloss -1023.10078  validloss -1097.60330±0.00000  bestvalidloss -1143.34536  last_update 21\n",
      "train: iter 267  trainloss -1165.95087  validloss -1012.34827±0.00000  bestvalidloss -1143.34536  last_update 22\n",
      "train: iter 268  trainloss -1170.97527  validloss -1125.04528±0.00000  bestvalidloss -1143.34536  last_update 23\n",
      "train: iter 269  trainloss -1104.38180  validloss -1162.99157±0.00000  bestvalidloss -1162.99157  last_update 0\n",
      "train: iter 270  trainloss -1182.94465  validloss -1114.41219±0.00000  bestvalidloss -1162.99157  last_update 1\n",
      "train: iter 271  trainloss -981.27139  validloss -895.25082±0.00000  bestvalidloss -1162.99157  last_update 2\n",
      "train: iter 272  trainloss -1168.89029  validloss -946.70683±0.00000  bestvalidloss -1162.99157  last_update 3\n",
      "train: iter 273  trainloss -1092.05067  validloss -1142.34288±0.00000  bestvalidloss -1162.99157  last_update 4\n",
      "train: iter 274  trainloss -956.60863  validloss -611.60425±0.00000  bestvalidloss -1162.99157  last_update 5\n",
      "train: iter 275  trainloss -1128.91432  validloss -1093.54227±0.00000  bestvalidloss -1162.99157  last_update 6\n",
      "train: iter 276  trainloss -930.56026  validloss -960.42028±0.00000  bestvalidloss -1162.99157  last_update 7\n",
      "train: iter 277  trainloss -1099.85897  validloss -1114.58470±0.00000  bestvalidloss -1162.99157  last_update 8\n",
      "train: iter 278  trainloss -1036.46603  validloss -1123.51089±0.00000  bestvalidloss -1162.99157  last_update 9\n",
      "train: iter 279  trainloss -1092.64144  validloss -1042.35707±0.00000  bestvalidloss -1162.99157  last_update 10\n",
      "train: iter 280  trainloss -946.66194  validloss -857.14063±0.00000  bestvalidloss -1162.99157  last_update 11\n",
      "train: iter 281  trainloss -1186.73756  validloss -988.23130±0.00000  bestvalidloss -1162.99157  last_update 12\n",
      "train: iter 282  trainloss -1074.04343  validloss -1010.73358±0.00000  bestvalidloss -1162.99157  last_update 13\n",
      "train: iter 283  trainloss -1095.71130  validloss -1084.55940±0.00000  bestvalidloss -1162.99157  last_update 14\n",
      "train: iter 284  trainloss -1209.36074  validloss -1107.40230±0.00000  bestvalidloss -1162.99157  last_update 15\n",
      "train: iter 285  trainloss -855.92691  validloss -1103.21221±0.00000  bestvalidloss -1162.99157  last_update 16\n",
      "train: iter 286  trainloss -986.66102  validloss -988.43214±0.00000  bestvalidloss -1162.99157  last_update 17\n",
      "train: iter 287  trainloss -1054.07474  validloss -757.42073±0.00000  bestvalidloss -1162.99157  last_update 18\n",
      "train: iter 288  trainloss -1195.48287  validloss -1138.81712±0.00000  bestvalidloss -1162.99157  last_update 19\n",
      "train: iter 289  trainloss -1120.94579  validloss -1150.58501±0.00000  bestvalidloss -1162.99157  last_update 20\n",
      "train: iter 290  trainloss -1133.94052  validloss -1056.75822±0.00000  bestvalidloss -1162.99157  last_update 21\n",
      "train: iter 291  trainloss -1140.83421  validloss -1090.22916±0.00000  bestvalidloss -1162.99157  last_update 22\n",
      "train: iter 292  trainloss -1234.18423  validloss -1152.89873±0.00000  bestvalidloss -1162.99157  last_update 23\n",
      "train: iter 293  trainloss -990.91994  validloss -779.58913±0.00000  bestvalidloss -1162.99157  last_update 24\n",
      "train: iter 294  trainloss -1108.99697  validloss -1020.62793±0.00000  bestvalidloss -1162.99157  last_update 25\n",
      "train: iter 295  trainloss -1164.53834  validloss -975.86293±0.00000  bestvalidloss -1162.99157  last_update 26\n",
      "train: iter 296  trainloss -1165.93665  validloss -1141.68604±0.00000  bestvalidloss -1162.99157  last_update 27\n",
      "train: iter 297  trainloss -1167.10360  validloss -1118.93374±0.00000  bestvalidloss -1162.99157  last_update 28\n",
      "train: iter 298  trainloss -1090.71603  validloss -1198.41346±0.00000  bestvalidloss -1198.41346  last_update 0\n",
      "train: iter 299  trainloss -1132.99301  validloss -1090.45941±0.00000  bestvalidloss -1198.41346  last_update 1\n",
      "train: iter 300  trainloss -1148.83965  validloss -1162.50973±0.00000  bestvalidloss -1198.41346  last_update 2\n",
      "train: iter 301  trainloss -1164.40513  validloss -1085.32731±0.00000  bestvalidloss -1198.41346  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 302  trainloss -1142.54653  validloss -939.55977±0.00000  bestvalidloss -1198.41346  last_update 4\n",
      "train: iter 303  trainloss -1088.94950  validloss -1089.23735±0.00000  bestvalidloss -1198.41346  last_update 5\n",
      "train: iter 304  trainloss -1166.01507  validloss -1024.50706±0.00000  bestvalidloss -1198.41346  last_update 6\n",
      "train: iter 305  trainloss -1169.41665  validloss -708.24817±0.00000  bestvalidloss -1198.41346  last_update 7\n",
      "train: iter 306  trainloss -1104.73692  validloss -1173.10681±0.00000  bestvalidloss -1198.41346  last_update 8\n",
      "train: iter 307  trainloss -1087.36490  validloss -1013.85107±0.00000  bestvalidloss -1198.41346  last_update 9\n",
      "train: iter 308  trainloss -1013.04187  validloss -1158.98261±0.00000  bestvalidloss -1198.41346  last_update 10\n",
      "train: iter 309  trainloss -1004.27816  validloss -705.82992±0.00000  bestvalidloss -1198.41346  last_update 11\n",
      "train: iter 310  trainloss -1181.05608  validloss -1077.48868±0.00000  bestvalidloss -1198.41346  last_update 12\n",
      "train: iter 311  trainloss -1075.18676  validloss -841.65745±0.00000  bestvalidloss -1198.41346  last_update 13\n",
      "train: iter 312  trainloss -1200.14303  validloss -1146.38509±0.00000  bestvalidloss -1198.41346  last_update 14\n",
      "train: iter 313  trainloss -974.79254  validloss -1011.09957±0.00000  bestvalidloss -1198.41346  last_update 15\n",
      "train: iter 314  trainloss -1209.16483  validloss -1109.08182±0.00000  bestvalidloss -1198.41346  last_update 16\n",
      "train: iter 315  trainloss -863.61151  validloss -945.04753±0.00000  bestvalidloss -1198.41346  last_update 17\n",
      "train: iter 316  trainloss -1040.32237  validloss -1026.38515±0.00000  bestvalidloss -1198.41346  last_update 18\n",
      "train: iter 317  trainloss -1150.03432  validloss -1068.72532±0.00000  bestvalidloss -1198.41346  last_update 19\n",
      "train: iter 318  trainloss -1252.73547  validloss -987.68089±0.00000  bestvalidloss -1198.41346  last_update 20\n",
      "train: iter 319  trainloss -1137.02702  validloss -1198.10059±0.00000  bestvalidloss -1198.41346  last_update 21\n",
      "train: iter 320  trainloss -1221.38477  validloss -862.97219±0.00000  bestvalidloss -1198.41346  last_update 22\n",
      "train: iter 321  trainloss -1166.78904  validloss -1134.16422±0.00000  bestvalidloss -1198.41346  last_update 23\n",
      "train: iter 322  trainloss -1104.00343  validloss -994.92080±0.00000  bestvalidloss -1198.41346  last_update 24\n",
      "train: iter 323  trainloss -1228.86641  validloss -1126.41745±0.00000  bestvalidloss -1198.41346  last_update 25\n",
      "train: iter 324  trainloss -1185.69936  validloss -1143.24754±0.00000  bestvalidloss -1198.41346  last_update 26\n",
      "train: iter 325  trainloss -1285.84292  validloss -1219.08638±0.00000  bestvalidloss -1219.08638  last_update 0\n",
      "train: iter 326  trainloss -1151.31471  validloss -1195.66739±0.00000  bestvalidloss -1219.08638  last_update 1\n",
      "train: iter 327  trainloss -1183.89586  validloss -1045.51107±0.00000  bestvalidloss -1219.08638  last_update 2\n",
      "train: iter 328  trainloss -1250.13001  validloss -1221.07676±0.00000  bestvalidloss -1221.07676  last_update 0\n",
      "train: iter 329  trainloss -1094.71682  validloss -1149.45791±0.00000  bestvalidloss -1221.07676  last_update 1\n",
      "train: iter 330  trainloss -1215.76675  validloss -916.60468±0.00000  bestvalidloss -1221.07676  last_update 2\n",
      "train: iter 331  trainloss -1063.68737  validloss -1230.37252±0.00000  bestvalidloss -1230.37252  last_update 0\n",
      "train: iter 332  trainloss -1167.46247  validloss -887.53806±0.00000  bestvalidloss -1230.37252  last_update 1\n",
      "train: iter 333  trainloss -947.82294  validloss -877.08463±0.00000  bestvalidloss -1230.37252  last_update 2\n",
      "train: iter 334  trainloss -1071.78003  validloss -894.43820±0.00000  bestvalidloss -1230.37252  last_update 3\n",
      "train: iter 335  trainloss -1217.42884  validloss -1143.88065±0.00000  bestvalidloss -1230.37252  last_update 4\n",
      "train: iter 336  trainloss -1159.80168  validloss -938.23014±0.00000  bestvalidloss -1230.37252  last_update 5\n",
      "train: iter 337  trainloss -1202.68277  validloss -1189.27198±0.00000  bestvalidloss -1230.37252  last_update 6\n",
      "train: iter 338  trainloss -1292.47216  validloss -1160.86489±0.00000  bestvalidloss -1230.37252  last_update 7\n",
      "train: iter 339  trainloss -1159.74618  validloss -1260.97098±0.00000  bestvalidloss -1260.97098  last_update 0\n",
      "train: iter 340  trainloss -1199.18370  validloss -1029.35361±0.00000  bestvalidloss -1260.97098  last_update 1\n",
      "train: iter 341  trainloss -1178.22313  validloss -1203.52458±0.00000  bestvalidloss -1260.97098  last_update 2\n",
      "train: iter 342  trainloss -1117.76120  validloss -1027.77634±0.00000  bestvalidloss -1260.97098  last_update 3\n",
      "train: iter 343  trainloss -1201.45001  validloss -855.88802±0.00000  bestvalidloss -1260.97098  last_update 4\n",
      "train: iter 344  trainloss -886.54863  validloss -1114.86336±0.00000  bestvalidloss -1260.97098  last_update 5\n",
      "train: iter 345  trainloss -1049.93528  validloss -1049.67807±0.00000  bestvalidloss -1260.97098  last_update 6\n",
      "train: iter 346  trainloss -1210.81378  validloss -950.85352±0.00000  bestvalidloss -1260.97098  last_update 7\n",
      "train: iter 347  trainloss -1269.75700  validloss -1244.41312±0.00000  bestvalidloss -1260.97098  last_update 8\n",
      "train: iter 348  trainloss -1063.43055  validloss -1149.53337±0.00000  bestvalidloss -1260.97098  last_update 9\n",
      "train: iter 349  trainloss -1232.31979  validloss -1170.47941±0.00000  bestvalidloss -1260.97098  last_update 10\n",
      "train: iter 350  trainloss -1227.13706  validloss -953.48913±0.00000  bestvalidloss -1260.97098  last_update 11\n",
      "train: iter 351  trainloss -1128.33097  validloss -1202.32586±0.00000  bestvalidloss -1260.97098  last_update 12\n",
      "train: iter 352  trainloss -1266.40235  validloss -1199.45919±0.00000  bestvalidloss -1260.97098  last_update 13\n",
      "train: iter 353  trainloss -1249.65200  validloss -1141.32430±0.00000  bestvalidloss -1260.97098  last_update 14\n",
      "train: iter 354  trainloss -1106.55681  validloss -382.17414±0.00000  bestvalidloss -1260.97098  last_update 15\n",
      "train: iter 355  trainloss -1160.98788  validloss -1192.59386±0.00000  bestvalidloss -1260.97098  last_update 16\n",
      "train: iter 356  trainloss -1255.80833  validloss -961.79855±0.00000  bestvalidloss -1260.97098  last_update 17\n",
      "train: iter 357  trainloss -1237.33650  validloss -1234.15963±0.00000  bestvalidloss -1260.97098  last_update 18\n",
      "train: iter 358  trainloss -1216.89084  validloss -1177.68660±0.00000  bestvalidloss -1260.97098  last_update 19\n",
      "train: iter 359  trainloss -1350.04052  validloss -1259.94972±0.00000  bestvalidloss -1260.97098  last_update 20\n",
      "train: iter 360  trainloss -1301.22290  validloss -1269.78625±0.00000  bestvalidloss -1269.78625  last_update 0\n",
      "train: iter 361  trainloss -1327.51732  validloss -1240.55999±0.00000  bestvalidloss -1269.78625  last_update 1\n",
      "train: iter 362  trainloss -1155.04965  validloss -1302.56580±0.00000  bestvalidloss -1302.56580  last_update 0\n",
      "train: iter 363  trainloss -1313.67870  validloss -1073.40387±0.00000  bestvalidloss -1302.56580  last_update 1\n",
      "train: iter 364  trainloss -1294.49015  validloss -1168.04173±0.00000  bestvalidloss -1302.56580  last_update 2\n",
      "train: iter 365  trainloss -1186.07070  validloss -1236.22360±0.00000  bestvalidloss -1302.56580  last_update 3\n",
      "train: iter 366  trainloss -917.80367  validloss -1024.65271±0.00000  bestvalidloss -1302.56580  last_update 4\n",
      "train: iter 367  trainloss -1212.56776  validloss -1040.24298±0.00000  bestvalidloss -1302.56580  last_update 5\n",
      "train: iter 368  trainloss -1266.87535  validloss -1131.22923±0.00000  bestvalidloss -1302.56580  last_update 6\n",
      "train: iter 369  trainloss -688.54166  validloss -1208.24810±0.00000  bestvalidloss -1302.56580  last_update 7\n",
      "train: iter 370  trainloss -1065.86302  validloss -929.66573±0.00000  bestvalidloss -1302.56580  last_update 8\n",
      "train: iter 371  trainloss -1143.67974  validloss -554.78923±0.00000  bestvalidloss -1302.56580  last_update 9\n",
      "train: iter 372  trainloss -1347.47966  validloss -1194.77747±0.00000  bestvalidloss -1302.56580  last_update 10\n",
      "train: iter 373  trainloss -1211.74173  validloss -1274.90370±0.00000  bestvalidloss -1302.56580  last_update 11\n",
      "train: iter 374  trainloss -1203.00970  validloss -1079.08837±0.00000  bestvalidloss -1302.56580  last_update 12\n",
      "train: iter 375  trainloss -1334.88593  validloss -1213.47149±0.00000  bestvalidloss -1302.56580  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 376  trainloss -1408.68877  validloss -1283.18788±0.00000  bestvalidloss -1302.56580  last_update 14\n",
      "train: iter 377  trainloss -1211.11232  validloss -1270.05412±0.00000  bestvalidloss -1302.56580  last_update 15\n",
      "train: iter 378  trainloss -1308.10352  validloss -1190.97033±0.00000  bestvalidloss -1302.56580  last_update 16\n",
      "train: iter 379  trainloss -1136.82443  validloss -986.04239±0.00000  bestvalidloss -1302.56580  last_update 17\n",
      "train: iter 380  trainloss -1332.05985  validloss -1162.93960±0.00000  bestvalidloss -1302.56580  last_update 18\n",
      "train: iter 381  trainloss -1333.98477  validloss -1058.34519±0.00000  bestvalidloss -1302.56580  last_update 19\n",
      "train: iter 382  trainloss -1337.38777  validloss -1255.60278±0.00000  bestvalidloss -1302.56580  last_update 20\n",
      "train: iter 383  trainloss -1341.64946  validloss -1299.95299±0.00000  bestvalidloss -1302.56580  last_update 21\n",
      "train: iter 384  trainloss -1373.64599  validloss -1147.73214±0.00000  bestvalidloss -1302.56580  last_update 22\n",
      "train: iter 385  trainloss -1341.96752  validloss -1264.25894±0.00000  bestvalidloss -1302.56580  last_update 23\n",
      "train: iter 386  trainloss -1307.43112  validloss -1233.80524±0.00000  bestvalidloss -1302.56580  last_update 24\n",
      "train: iter 387  trainloss -1265.48225  validloss -1155.16771±0.00000  bestvalidloss -1302.56580  last_update 25\n",
      "train: iter 388  trainloss -1335.83790  validloss -1255.91211±0.00000  bestvalidloss -1302.56580  last_update 26\n",
      "train: iter 389  trainloss -1302.17182  validloss -1273.21177±0.00000  bestvalidloss -1302.56580  last_update 27\n",
      "train: iter 390  trainloss -1301.54955  validloss -1206.50319±0.00000  bestvalidloss -1302.56580  last_update 28\n",
      "train: iter 391  trainloss -1304.19127  validloss -1284.92010±0.00000  bestvalidloss -1302.56580  last_update 29\n",
      "train: iter 392  trainloss -1320.34840  validloss -1321.38589±0.00000  bestvalidloss -1321.38589  last_update 0\n",
      "train: iter 393  trainloss -1285.85681  validloss -1191.73550±0.00000  bestvalidloss -1321.38589  last_update 1\n",
      "train: iter 394  trainloss -1360.63943  validloss -1258.44028±0.00000  bestvalidloss -1321.38589  last_update 2\n",
      "train: iter 395  trainloss -1174.69014  validloss -1275.84808±0.00000  bestvalidloss -1321.38589  last_update 3\n",
      "train: iter 396  trainloss -1245.97339  validloss -1192.39396±0.00000  bestvalidloss -1321.38589  last_update 4\n",
      "train: iter 397  trainloss -1303.32436  validloss -1235.50461±0.00000  bestvalidloss -1321.38589  last_update 5\n",
      "train: iter 398  trainloss -1262.40703  validloss -1178.67670±0.00000  bestvalidloss -1321.38589  last_update 6\n",
      "train: iter 399  trainloss -1073.87314  validloss -808.48848±0.00000  bestvalidloss -1321.38589  last_update 7\n",
      "train: iter 400  trainloss -1299.41480  validloss -845.25071±0.00000  bestvalidloss -1321.38589  last_update 8\n",
      "train: iter 401  trainloss -1207.85396  validloss -1243.62775±0.00000  bestvalidloss -1321.38589  last_update 9\n",
      "train: iter 402  trainloss -1248.99508  validloss -963.66869±0.00000  bestvalidloss -1321.38589  last_update 10\n",
      "train: iter 403  trainloss -1353.33331  validloss -1239.16586±0.00000  bestvalidloss -1321.38589  last_update 11\n",
      "train: iter 404  trainloss -1373.08515  validloss -1284.83218±0.00000  bestvalidloss -1321.38589  last_update 12\n",
      "train: iter 405  trainloss -1311.76058  validloss -1257.28104±0.00000  bestvalidloss -1321.38589  last_update 13\n",
      "train: iter 406  trainloss -1301.33042  validloss -847.80860±0.00000  bestvalidloss -1321.38589  last_update 14\n",
      "train: iter 407  trainloss -1409.60032  validloss -1128.83066±0.00000  bestvalidloss -1321.38589  last_update 15\n",
      "train: iter 408  trainloss -1258.74086  validloss -1293.97822±0.00000  bestvalidloss -1321.38589  last_update 16\n",
      "train: iter 409  trainloss -1224.90506  validloss -973.55373±0.00000  bestvalidloss -1321.38589  last_update 17\n",
      "train: iter 410  trainloss -1323.34920  validloss -1082.07977±0.00000  bestvalidloss -1321.38589  last_update 18\n",
      "train: iter 411  trainloss -1394.38919  validloss -723.98652±0.00000  bestvalidloss -1321.38589  last_update 19\n",
      "train: iter 412  trainloss -1246.06409  validloss -1266.26849±0.00000  bestvalidloss -1321.38589  last_update 20\n",
      "train: iter 413  trainloss -1394.72980  validloss -1252.21139±0.00000  bestvalidloss -1321.38589  last_update 21\n",
      "train: iter 414  trainloss -1449.93433  validloss -1327.87125±0.00000  bestvalidloss -1327.87125  last_update 0\n",
      "train: iter 415  trainloss -882.36582  validloss -1202.87456±0.00000  bestvalidloss -1327.87125  last_update 1\n",
      "train: iter 416  trainloss -1247.23814  validloss -799.81028±0.00000  bestvalidloss -1327.87125  last_update 2\n",
      "train: iter 417  trainloss -1339.77151  validloss -1281.45125±0.00000  bestvalidloss -1327.87125  last_update 3\n",
      "train: iter 418  trainloss -1431.77646  validloss -1328.44191±0.00000  bestvalidloss -1328.44191  last_update 0\n",
      "train: iter 419  trainloss -1374.74790  validloss -1191.39223±0.00000  bestvalidloss -1328.44191  last_update 1\n",
      "train: iter 420  trainloss -1416.67442  validloss -1340.05087±0.00000  bestvalidloss -1340.05087  last_update 0\n",
      "train: iter 421  trainloss -1169.43472  validloss -1206.96623±0.00000  bestvalidloss -1340.05087  last_update 1\n",
      "train: iter 422  trainloss -1409.15498  validloss -1275.08894±0.00000  bestvalidloss -1340.05087  last_update 2\n",
      "train: iter 423  trainloss -1392.09719  validloss -1357.47620±0.00000  bestvalidloss -1357.47620  last_update 0\n",
      "train: iter 424  trainloss -1173.39482  validloss -1328.50020±0.00000  bestvalidloss -1357.47620  last_update 1\n",
      "train: iter 425  trainloss -1355.60854  validloss -1196.57760±0.00000  bestvalidloss -1357.47620  last_update 2\n",
      "train: iter 426  trainloss -1408.61536  validloss -1321.96017±0.00000  bestvalidloss -1357.47620  last_update 3\n",
      "train: iter 427  trainloss -1117.32215  validloss -1124.38465±0.00000  bestvalidloss -1357.47620  last_update 4\n",
      "train: iter 428  trainloss -1228.61327  validloss -341.75310±0.00000  bestvalidloss -1357.47620  last_update 5\n",
      "train: iter 429  trainloss -1399.78121  validloss -1272.41871±0.00000  bestvalidloss -1357.47620  last_update 6\n",
      "train: iter 430  trainloss -1284.43004  validloss -1213.17935±0.00000  bestvalidloss -1357.47620  last_update 7\n",
      "train: iter 431  trainloss -1348.93186  validloss -1212.55886±0.00000  bestvalidloss -1357.47620  last_update 8\n",
      "train: iter 432  trainloss -1422.86752  validloss -1068.96312±0.00000  bestvalidloss -1357.47620  last_update 9\n",
      "train: iter 433  trainloss -1467.19703  validloss -1326.62806±0.00000  bestvalidloss -1357.47620  last_update 10\n",
      "train: iter 434  trainloss -1221.05997  validloss -1129.95390±0.00000  bestvalidloss -1357.47620  last_update 11\n",
      "train: iter 435  trainloss -1350.72520  validloss -1278.24619±0.00000  bestvalidloss -1357.47620  last_update 12\n",
      "train: iter 436  trainloss -1371.71434  validloss -1260.75382±0.00000  bestvalidloss -1357.47620  last_update 13\n",
      "train: iter 437  trainloss -1362.36750  validloss -1300.61441±0.00000  bestvalidloss -1357.47620  last_update 14\n",
      "train: iter 438  trainloss -1277.40514  validloss -1085.42815±0.00000  bestvalidloss -1357.47620  last_update 15\n",
      "train: iter 439  trainloss -1440.24312  validloss -1272.00440±0.00000  bestvalidloss -1357.47620  last_update 16\n",
      "train: iter 440  trainloss -1453.40729  validloss -1357.19566±0.00000  bestvalidloss -1357.47620  last_update 17\n",
      "train: iter 441  trainloss -1346.55214  validloss -1379.09911±0.00000  bestvalidloss -1379.09911  last_update 0\n",
      "train: iter 442  trainloss -845.28782  validloss -1291.76159±0.00000  bestvalidloss -1379.09911  last_update 1\n",
      "train: iter 443  trainloss -1179.38115  validloss -1236.96691±0.00000  bestvalidloss -1379.09911  last_update 2\n",
      "train: iter 444  trainloss -1391.90829  validloss -1212.96099±0.00000  bestvalidloss -1379.09911  last_update 3\n",
      "train: iter 445  trainloss -909.80753  validloss -1270.91661±0.00000  bestvalidloss -1379.09911  last_update 4\n",
      "train: iter 446  trainloss -1296.07479  validloss -1089.14567±0.00000  bestvalidloss -1379.09911  last_update 5\n",
      "train: iter 447  trainloss -1225.98932  validloss -1086.36680±0.00000  bestvalidloss -1379.09911  last_update 6\n",
      "train: iter 448  trainloss -1383.53348  validloss -1239.27793±0.00000  bestvalidloss -1379.09911  last_update 7\n",
      "train: iter 449  trainloss -1462.19712  validloss -1312.93632±0.00000  bestvalidloss -1379.09911  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 450  trainloss -1414.81809  validloss -1328.54948±0.00000  bestvalidloss -1379.09911  last_update 9\n",
      "train: iter 451  trainloss -1368.15752  validloss -1364.62549±0.00000  bestvalidloss -1379.09911  last_update 10\n",
      "train: iter 452  trainloss -1176.57112  validloss -1263.97022±0.00000  bestvalidloss -1379.09911  last_update 11\n",
      "train: iter 453  trainloss -1325.63845  validloss -1277.15471±0.00000  bestvalidloss -1379.09911  last_update 12\n",
      "train: iter 454  trainloss -1380.34443  validloss -1210.66479±0.00000  bestvalidloss -1379.09911  last_update 13\n",
      "train: iter 455  trainloss -1475.66150  validloss -1338.74859±0.00000  bestvalidloss -1379.09911  last_update 14\n",
      "train: iter 456  trainloss -1348.48129  validloss -1385.88194±0.00000  bestvalidloss -1385.88194  last_update 0\n",
      "train: iter 457  trainloss -1257.57549  validloss -1318.16056±0.00000  bestvalidloss -1385.88194  last_update 1\n",
      "train: iter 458  trainloss -1441.15427  validloss -1319.76049±0.00000  bestvalidloss -1385.88194  last_update 2\n",
      "train: iter 459  trainloss -1416.75110  validloss -1386.95403±0.00000  bestvalidloss -1386.95403  last_update 0\n",
      "train: iter 460  trainloss -1411.14311  validloss -1111.76342±0.00000  bestvalidloss -1386.95403  last_update 1\n",
      "train: iter 461  trainloss -1181.36661  validloss -1309.73660±0.00000  bestvalidloss -1386.95403  last_update 2\n",
      "train: iter 462  trainloss -1444.41455  validloss -1091.80398±0.00000  bestvalidloss -1386.95403  last_update 3\n",
      "train: iter 463  trainloss -1253.36522  validloss -1408.83827±0.00000  bestvalidloss -1408.83827  last_update 0\n",
      "train: iter 464  trainloss -1440.97556  validloss -1339.18367±0.00000  bestvalidloss -1408.83827  last_update 1\n",
      "train: iter 465  trainloss -1250.94552  validloss -1222.46252±0.00000  bestvalidloss -1408.83827  last_update 2\n",
      "train: iter 466  trainloss -1322.44849  validloss -1290.43508±0.00000  bestvalidloss -1408.83827  last_update 3\n",
      "train: iter 467  trainloss -1433.88589  validloss -1292.87620±0.00000  bestvalidloss -1408.83827  last_update 4\n",
      "train: iter 468  trainloss -1468.53007  validloss -1339.08640±0.00000  bestvalidloss -1408.83827  last_update 5\n",
      "train: iter 469  trainloss -1294.34005  validloss -1307.22605±0.00000  bestvalidloss -1408.83827  last_update 6\n",
      "train: iter 470  trainloss -1202.40059  validloss -1173.53623±0.00000  bestvalidloss -1408.83827  last_update 7\n",
      "train: iter 471  trainloss -1353.39701  validloss -811.96231±0.00000  bestvalidloss -1408.83827  last_update 8\n",
      "train: iter 472  trainloss -1409.30860  validloss -1309.24409±0.00000  bestvalidloss -1408.83827  last_update 9\n",
      "train: iter 473  trainloss -1468.33944  validloss -1354.64270±0.00000  bestvalidloss -1408.83827  last_update 10\n",
      "train: iter 474  trainloss -1346.06041  validloss -1375.72033±0.00000  bestvalidloss -1408.83827  last_update 11\n",
      "train: iter 475  trainloss -1444.07589  validloss -1334.41167±0.00000  bestvalidloss -1408.83827  last_update 12\n",
      "train: iter 476  trainloss -1262.86354  validloss -1375.95337±0.00000  bestvalidloss -1408.83827  last_update 13\n",
      "train: iter 477  trainloss -1373.74201  validloss -1292.73495±0.00000  bestvalidloss -1408.83827  last_update 14\n",
      "train: iter 478  trainloss -1389.16950  validloss -1362.70133±0.00000  bestvalidloss -1408.83827  last_update 15\n",
      "train: iter 479  trainloss -1503.78151  validloss -1380.52795±0.00000  bestvalidloss -1408.83827  last_update 16\n",
      "train: iter 480  trainloss -1161.62679  validloss -1257.87727±0.00000  bestvalidloss -1408.83827  last_update 17\n",
      "train: iter 481  trainloss -1293.43953  validloss -937.68705±0.00000  bestvalidloss -1408.83827  last_update 18\n",
      "train: iter 482  trainloss -1360.85859  validloss -1284.66296±0.00000  bestvalidloss -1408.83827  last_update 19\n",
      "train: iter 483  trainloss -1447.40131  validloss -1351.02384±0.00000  bestvalidloss -1408.83827  last_update 20\n",
      "train: iter 484  trainloss -1475.51983  validloss -1348.73301±0.00000  bestvalidloss -1408.83827  last_update 21\n",
      "train: iter 485  trainloss -1391.31412  validloss -1360.25242±0.00000  bestvalidloss -1408.83827  last_update 22\n",
      "train: iter 486  trainloss -1343.43946  validloss -1394.76224±0.00000  bestvalidloss -1408.83827  last_update 23\n",
      "train: iter 487  trainloss -1277.65657  validloss -1230.16169±0.00000  bestvalidloss -1408.83827  last_update 24\n",
      "train: iter 488  trainloss -1475.17744  validloss -1280.06118±0.00000  bestvalidloss -1408.83827  last_update 25\n",
      "train: iter 489  trainloss -1376.11870  validloss -1318.44665±0.00000  bestvalidloss -1408.83827  last_update 26\n",
      "train: iter 490  trainloss -1325.12042  validloss -1266.36178±0.00000  bestvalidloss -1408.83827  last_update 27\n",
      "train: iter 491  trainloss -1434.62943  validloss -1397.28759±0.00000  bestvalidloss -1408.83827  last_update 28\n",
      "train: iter 492  trainloss -1445.71484  validloss -1335.15067±0.00000  bestvalidloss -1408.83827  last_update 29\n",
      "train: iter 493  trainloss -1439.99799  validloss -1401.96717±0.00000  bestvalidloss -1408.83827  last_update 30\n",
      "train: iter 494  trainloss -1337.08535  validloss -1322.46712±0.00000  bestvalidloss -1408.83827  last_update 31\n",
      "train: iter 495  trainloss -1365.23759  validloss -1082.58385±0.00000  bestvalidloss -1408.83827  last_update 32\n",
      "train: iter 496  trainloss -1263.53765  validloss -1317.93636±0.00000  bestvalidloss -1408.83827  last_update 33\n",
      "train: iter 497  trainloss -1507.83087  validloss -1387.73782±0.00000  bestvalidloss -1408.83827  last_update 34\n",
      "train: iter 498  trainloss -1242.59392  validloss -1244.67372±0.00000  bestvalidloss -1408.83827  last_update 35\n",
      "train: iter 499  trainloss -1432.72636  validloss -1354.25171±0.00000  bestvalidloss -1408.83827  last_update 36\n",
      "train: iter 500  trainloss -1392.97215  validloss -1341.55630±0.00000  bestvalidloss -1408.83827  last_update 37\n",
      "train: iter 501  trainloss -1459.69879  validloss -1191.77218±0.00000  bestvalidloss -1408.83827  last_update 38\n",
      "train: iter 502  trainloss -1455.74691  validloss -1407.33208±0.00000  bestvalidloss -1408.83827  last_update 39\n",
      "train: iter 503  trainloss -1221.64362  validloss -1311.91467±0.00000  bestvalidloss -1408.83827  last_update 40\n",
      "train: iter 504  trainloss -1426.12830  validloss -1212.19230±0.00000  bestvalidloss -1408.83827  last_update 41\n",
      "train: iter 505  trainloss -1494.99978  validloss -1387.84521±0.00000  bestvalidloss -1408.83827  last_update 42\n",
      "train: iter 506  trainloss -1374.78289  validloss -1431.20338±0.00000  bestvalidloss -1431.20338  last_update 0\n",
      "train: iter 507  trainloss -1375.64056  validloss -1371.73889±0.00000  bestvalidloss -1431.20338  last_update 1\n",
      "train: iter 508  trainloss -1381.35560  validloss -1171.81100±0.00000  bestvalidloss -1431.20338  last_update 2\n",
      "train: iter 509  trainloss -1451.86030  validloss -1220.88256±0.00000  bestvalidloss -1431.20338  last_update 3\n",
      "train: iter 510  trainloss -1507.10191  validloss -1309.71963±0.00000  bestvalidloss -1431.20338  last_update 4\n",
      "train: iter 511  trainloss -1065.37109  validloss -1370.72510±0.00000  bestvalidloss -1431.20338  last_update 5\n",
      "train: iter 512  trainloss -1360.45955  validloss -1310.73698±0.00000  bestvalidloss -1431.20338  last_update 6\n",
      "train: iter 513  trainloss -1491.81763  validloss -1373.58269±0.00000  bestvalidloss -1431.20338  last_update 7\n",
      "train: iter 514  trainloss -1518.88933  validloss -1420.48617±0.00000  bestvalidloss -1431.20338  last_update 8\n",
      "train: iter 515  trainloss -1310.50683  validloss -1365.57083±0.00000  bestvalidloss -1431.20338  last_update 9\n",
      "train: iter 516  trainloss -1463.07864  validloss -1230.85896±0.00000  bestvalidloss -1431.20338  last_update 10\n",
      "train: iter 517  trainloss -1375.55257  validloss -1249.55403±0.00000  bestvalidloss -1431.20338  last_update 11\n",
      "train: iter 518  trainloss -1262.74496  validloss -1303.61798±0.00000  bestvalidloss -1431.20338  last_update 12\n",
      "train: iter 519  trainloss -1426.90361  validloss -1279.89627±0.00000  bestvalidloss -1431.20338  last_update 13\n",
      "train: iter 520  trainloss -1443.35267  validloss -1253.34053±0.00000  bestvalidloss -1431.20338  last_update 14\n",
      "train: iter 521  trainloss -1221.62612  validloss -1364.60279±0.00000  bestvalidloss -1431.20338  last_update 15\n",
      "train: iter 522  trainloss -1367.62252  validloss -1230.93358±0.00000  bestvalidloss -1431.20338  last_update 16\n",
      "train: iter 523  trainloss -1446.59536  validloss -1377.87223±0.00000  bestvalidloss -1431.20338  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 524  trainloss -1419.69538  validloss -1382.64006±0.00000  bestvalidloss -1431.20338  last_update 18\n",
      "train: iter 525  trainloss -1276.06353  validloss -898.08007±0.00000  bestvalidloss -1431.20338  last_update 19\n",
      "train: iter 526  trainloss -1429.54304  validloss -1350.21277±0.00000  bestvalidloss -1431.20338  last_update 20\n",
      "train: iter 527  trainloss -1456.76238  validloss -1394.10492±0.00000  bestvalidloss -1431.20338  last_update 21\n",
      "train: iter 528  trainloss -1467.65791  validloss -1254.05077±0.00000  bestvalidloss -1431.20338  last_update 22\n",
      "train: iter 529  trainloss -1484.08736  validloss -1404.25675±0.00000  bestvalidloss -1431.20338  last_update 23\n",
      "train: iter 530  trainloss -1473.42842  validloss -1326.18518±0.00000  bestvalidloss -1431.20338  last_update 24\n",
      "train: iter 531  trainloss -1475.81087  validloss -1415.49784±0.00000  bestvalidloss -1431.20338  last_update 25\n",
      "train: iter 532  trainloss -1372.12214  validloss -998.96211±0.00000  bestvalidloss -1431.20338  last_update 26\n",
      "train: iter 533  trainloss -1398.48184  validloss -1388.07017±0.00000  bestvalidloss -1431.20338  last_update 27\n",
      "train: iter 534  trainloss -1373.64485  validloss -1312.90428±0.00000  bestvalidloss -1431.20338  last_update 28\n",
      "train: iter 535  trainloss -544.78152  validloss -727.53310±0.00000  bestvalidloss -1431.20338  last_update 29\n",
      "train: iter 536  trainloss -614.35178  validloss -1105.78303±0.00000  bestvalidloss -1431.20338  last_update 30\n",
      "train: iter 537  trainloss -1038.46019  validloss -546.35100±0.00000  bestvalidloss -1431.20338  last_update 31\n",
      "train: iter 538  trainloss -1327.89171  validloss -1161.05464±0.00000  bestvalidloss -1431.20338  last_update 32\n",
      "train: iter 539  trainloss -1407.94744  validloss -1324.41916±0.00000  bestvalidloss -1431.20338  last_update 33\n",
      "train: iter 540  trainloss -1393.31916  validloss -1352.29712±0.00000  bestvalidloss -1431.20338  last_update 34\n",
      "train: iter 541  trainloss -1449.29738  validloss -1372.29345±0.00000  bestvalidloss -1431.20338  last_update 35\n",
      "train: iter 542  trainloss -1434.51784  validloss -1262.58416±0.00000  bestvalidloss -1431.20338  last_update 36\n",
      "train: iter 543  trainloss -1504.48395  validloss -1317.54442±0.00000  bestvalidloss -1431.20338  last_update 37\n",
      "train: iter 544  trainloss -1463.97965  validloss -1401.47737±0.00000  bestvalidloss -1431.20338  last_update 38\n",
      "train: iter 545  trainloss -1501.83224  validloss -1387.94712±0.00000  bestvalidloss -1431.20338  last_update 39\n",
      "train: iter 546  trainloss -1495.27212  validloss -1412.83199±0.00000  bestvalidloss -1431.20338  last_update 40\n",
      "train: iter 547  trainloss -1409.87507  validloss -1422.23298±0.00000  bestvalidloss -1431.20338  last_update 41\n",
      "train: iter 548  trainloss -1445.50176  validloss -1268.93857±0.00000  bestvalidloss -1431.20338  last_update 42\n",
      "train: iter 549  trainloss -1534.66591  validloss -1387.45222±0.00000  bestvalidloss -1431.20338  last_update 43\n",
      "train: iter 550  trainloss -1219.96070  validloss -1345.46569±0.00000  bestvalidloss -1431.20338  last_update 44\n",
      "train: iter 551  trainloss -1396.03098  validloss -1102.04279±0.00000  bestvalidloss -1431.20338  last_update 45\n",
      "train: iter 552  trainloss -1533.82799  validloss -1372.90879±0.00000  bestvalidloss -1431.20338  last_update 46\n",
      "train: iter 553  trainloss -1369.39258  validloss -1400.67507±0.00000  bestvalidloss -1431.20338  last_update 47\n",
      "train: iter 554  trainloss -1387.88718  validloss -1429.99063±0.00000  bestvalidloss -1431.20338  last_update 48\n",
      "train: iter 555  trainloss -1417.88959  validloss -1350.20005±0.00000  bestvalidloss -1431.20338  last_update 49\n",
      "train: iter 556  trainloss -1467.17581  validloss -1350.34768±0.00000  bestvalidloss -1431.20338  last_update 50\n",
      "train: iter 557  trainloss -1443.72657  validloss -1361.14190±0.00000  bestvalidloss -1431.20338  last_update 51\n",
      "train: iter 558  trainloss -1526.51230  validloss -1262.39366±0.00000  bestvalidloss -1431.20338  last_update 52\n",
      "train: iter 559  trainloss -1453.38203  validloss -1414.25272±0.00000  bestvalidloss -1431.20338  last_update 53\n",
      "train: iter 560  trainloss -1450.95619  validloss -1390.45967±0.00000  bestvalidloss -1431.20338  last_update 54\n",
      "train: iter 561  trainloss -1438.95745  validloss -1441.92402±0.00000  bestvalidloss -1441.92402  last_update 0\n",
      "train: iter 562  trainloss -1457.38449  validloss -1314.84986±0.00000  bestvalidloss -1441.92402  last_update 1\n",
      "train: iter 563  trainloss -1475.17191  validloss -1332.25989±0.00000  bestvalidloss -1441.92402  last_update 2\n",
      "train: iter 564  trainloss -1487.24394  validloss -1384.99008±0.00000  bestvalidloss -1441.92402  last_update 3\n",
      "train: iter 565  trainloss -1356.09846  validloss -1393.00977±0.00000  bestvalidloss -1441.92402  last_update 4\n",
      "train: iter 566  trainloss -1466.31614  validloss -1400.05826±0.00000  bestvalidloss -1441.92402  last_update 5\n",
      "train: iter 567  trainloss -1517.87743  validloss -1393.49065±0.00000  bestvalidloss -1441.92402  last_update 6\n",
      "train: iter 568  trainloss -1519.34425  validloss -1461.25883±0.00000  bestvalidloss -1461.25883  last_update 0\n",
      "train: iter 569  trainloss -1231.04787  validloss -1224.17210±0.00000  bestvalidloss -1461.25883  last_update 1\n",
      "train: iter 570  trainloss -1222.09696  validloss -601.91364±0.00000  bestvalidloss -1461.25883  last_update 2\n",
      "train: iter 571  trainloss -1272.20743  validloss -1233.35060±0.00000  bestvalidloss -1461.25883  last_update 3\n",
      "train: iter 572  trainloss -1433.36286  validloss -1253.23687±0.00000  bestvalidloss -1461.25883  last_update 4\n",
      "train: iter 573  trainloss -1489.19987  validloss -1430.07868±0.00000  bestvalidloss -1461.25883  last_update 5\n",
      "train: iter 574  trainloss -1457.52425  validloss -1325.35412±0.00000  bestvalidloss -1461.25883  last_update 6\n",
      "train: iter 575  trainloss -1539.25453  validloss -1404.52040±0.00000  bestvalidloss -1461.25883  last_update 7\n",
      "train: iter 576  trainloss -1512.36267  validloss -1450.65165±0.00000  bestvalidloss -1461.25883  last_update 8\n",
      "train: iter 577  trainloss -1503.16870  validloss -1372.41793±0.00000  bestvalidloss -1461.25883  last_update 9\n",
      "train: iter 578  trainloss -1488.33179  validloss -1352.50286±0.00000  bestvalidloss -1461.25883  last_update 10\n",
      "train: iter 579  trainloss -1312.82515  validloss -985.84575±0.00000  bestvalidloss -1461.25883  last_update 11\n",
      "train: iter 580  trainloss -1481.76488  validloss -1384.73200±0.00000  bestvalidloss -1461.25883  last_update 12\n",
      "train: iter 581  trainloss -1521.98981  validloss -1418.17852±0.00000  bestvalidloss -1461.25883  last_update 13\n",
      "train: iter 582  trainloss -1218.65016  validloss -1331.52632±0.00000  bestvalidloss -1461.25883  last_update 14\n",
      "train: iter 583  trainloss -1398.48670  validloss -1271.39726±0.00000  bestvalidloss -1461.25883  last_update 15\n",
      "train: iter 584  trainloss -1469.48694  validloss -1154.11369±0.00000  bestvalidloss -1461.25883  last_update 16\n",
      "train: iter 585  trainloss -1498.22277  validloss -1420.65927±0.00000  bestvalidloss -1461.25883  last_update 17\n",
      "train: iter 586  trainloss -1549.57748  validloss -1422.54761±0.00000  bestvalidloss -1461.25883  last_update 18\n",
      "train: iter 587  trainloss -1468.90389  validloss -1427.11306±0.00000  bestvalidloss -1461.25883  last_update 19\n",
      "train: iter 588  trainloss -1571.69861  validloss -1459.64213±0.00000  bestvalidloss -1461.25883  last_update 20\n",
      "train: iter 589  trainloss -1456.62486  validloss -1467.07679±0.00000  bestvalidloss -1467.07679  last_update 0\n",
      "train: iter 590  trainloss -1497.64621  validloss -1394.93036±0.00000  bestvalidloss -1467.07679  last_update 1\n",
      "train: iter 591  trainloss -1431.12912  validloss -1299.00656±0.00000  bestvalidloss -1467.07679  last_update 2\n",
      "train: iter 592  trainloss -1511.31142  validloss -1427.11612±0.00000  bestvalidloss -1467.07679  last_update 3\n",
      "train: iter 593  trainloss -1464.81421  validloss -1455.52481±0.00000  bestvalidloss -1467.07679  last_update 4\n",
      "train: iter 594  trainloss -1429.50895  validloss -1477.34774±0.00000  bestvalidloss -1477.34774  last_update 0\n",
      "train: iter 595  trainloss -1521.35128  validloss -1424.45144±0.00000  bestvalidloss -1477.34774  last_update 1\n",
      "train: iter 596  trainloss -1539.56922  validloss -1388.78851±0.00000  bestvalidloss -1477.34774  last_update 2\n",
      "train: iter 597  trainloss -1498.00300  validloss -1355.60597±0.00000  bestvalidloss -1477.34774  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 598  trainloss -1390.90664  validloss -1455.55924±0.00000  bestvalidloss -1477.34774  last_update 4\n",
      "train: iter 599  trainloss -1495.92789  validloss -1343.18330±0.00000  bestvalidloss -1477.34774  last_update 5\n",
      "train: iter 600  trainloss -1504.75745  validloss -1462.08475±0.00000  bestvalidloss -1477.34774  last_update 6\n",
      "train: iter 601  trainloss -1413.26904  validloss -1331.35352±0.00000  bestvalidloss -1477.34774  last_update 7\n",
      "train: iter 602  trainloss -1368.35705  validloss -1298.95597±0.00000  bestvalidloss -1477.34774  last_update 8\n",
      "train: iter 603  trainloss -1568.03218  validloss -1404.22286±0.00000  bestvalidloss -1477.34774  last_update 9\n",
      "train: iter 604  trainloss -1473.42069  validloss -1455.37630±0.00000  bestvalidloss -1477.34774  last_update 10\n",
      "train: iter 605  trainloss -1256.52359  validloss -1216.56076±0.00000  bestvalidloss -1477.34774  last_update 11\n",
      "train: iter 606  trainloss -1528.03094  validloss -1382.31678±0.00000  bestvalidloss -1477.34774  last_update 12\n",
      "train: iter 607  trainloss -1497.82113  validloss -1470.19163±0.00000  bestvalidloss -1477.34774  last_update 13\n",
      "train: iter 608  trainloss -1577.49702  validloss -1444.54959±0.00000  bestvalidloss -1477.34774  last_update 14\n",
      "train: iter 609  trainloss -1510.13835  validloss -1489.46134±0.00000  bestvalidloss -1489.46134  last_update 0\n",
      "train: iter 610  trainloss -1390.67098  validloss -1341.55339±0.00000  bestvalidloss -1489.46134  last_update 1\n",
      "train: iter 611  trainloss -1483.24802  validloss -1309.92540±0.00000  bestvalidloss -1489.46134  last_update 2\n",
      "train: iter 612  trainloss -1558.60260  validloss -1400.62725±0.00000  bestvalidloss -1489.46134  last_update 3\n",
      "train: iter 613  trainloss -1412.65510  validloss -1433.03843±0.00000  bestvalidloss -1489.46134  last_update 4\n",
      "train: iter 614  trainloss -1442.10989  validloss -1293.08379±0.00000  bestvalidloss -1489.46134  last_update 5\n",
      "train: iter 615  trainloss -1531.05698  validloss -1387.62285±0.00000  bestvalidloss -1489.46134  last_update 6\n",
      "train: iter 616  trainloss -1567.30157  validloss -1503.42792±0.00000  bestvalidloss -1503.42792  last_update 0\n",
      "train: iter 617  trainloss -1285.80899  validloss -1412.95637±0.00000  bestvalidloss -1503.42792  last_update 1\n",
      "train: iter 618  trainloss -1529.80117  validloss -1318.32407±0.00000  bestvalidloss -1503.42792  last_update 2\n",
      "train: iter 619  trainloss -1516.60070  validloss -1461.18747±0.00000  bestvalidloss -1503.42792  last_update 3\n",
      "train: iter 620  trainloss -1526.53553  validloss -1364.82638±0.00000  bestvalidloss -1503.42792  last_update 4\n",
      "train: iter 621  trainloss -1478.31872  validloss -1466.05809±0.00000  bestvalidloss -1503.42792  last_update 5\n",
      "train: iter 622  trainloss -1515.50940  validloss -1251.56910±0.00000  bestvalidloss -1503.42792  last_update 6\n",
      "train: iter 623  trainloss -1458.77913  validloss -1402.30069±0.00000  bestvalidloss -1503.42792  last_update 7\n",
      "train: iter 624  trainloss -1520.66571  validloss -1441.30255±0.00000  bestvalidloss -1503.42792  last_update 8\n",
      "train: iter 625  trainloss -1554.49519  validloss -1334.33283±0.00000  bestvalidloss -1503.42792  last_update 9\n",
      "train: iter 626  trainloss -1054.43171  validloss -1457.91800±0.00000  bestvalidloss -1503.42792  last_update 10\n",
      "train: iter 627  trainloss -1260.35673  validloss -1003.19876±0.00000  bestvalidloss -1503.42792  last_update 11\n",
      "train: iter 628  trainloss -1480.20085  validloss -1225.08471±0.00000  bestvalidloss -1503.42792  last_update 12\n",
      "train: iter 629  trainloss -1533.05848  validloss -1372.62924±0.00000  bestvalidloss -1503.42792  last_update 13\n",
      "train: iter 630  trainloss -1584.64218  validloss -1431.85883±0.00000  bestvalidloss -1503.42792  last_update 14\n",
      "train: iter 631  trainloss -1551.76787  validloss -1302.09711±0.00000  bestvalidloss -1503.42792  last_update 15\n",
      "train: iter 632  trainloss -1598.33311  validloss -1478.65947±0.00000  bestvalidloss -1503.42792  last_update 16\n",
      "train: iter 633  trainloss -1562.47941  validloss -1471.48916±0.00000  bestvalidloss -1503.42792  last_update 17\n",
      "train: iter 634  trainloss -1350.44772  validloss -1438.15467±0.00000  bestvalidloss -1503.42792  last_update 18\n",
      "train: iter 635  trainloss -1502.53289  validloss -1175.78485±0.00000  bestvalidloss -1503.42792  last_update 19\n",
      "train: iter 636  trainloss -1467.84465  validloss -1503.11079±0.00000  bestvalidloss -1503.42792  last_update 20\n",
      "train: iter 637  trainloss -1466.95813  validloss -1332.55240±0.00000  bestvalidloss -1503.42792  last_update 21\n",
      "train: iter 638  trainloss -1601.57348  validloss -1416.59245±0.00000  bestvalidloss -1503.42792  last_update 22\n",
      "train: iter 639  trainloss -1567.80098  validloss -1484.09852±0.00000  bestvalidloss -1503.42792  last_update 23\n",
      "train: iter 640  trainloss -1516.51669  validloss -1336.23063±0.00000  bestvalidloss -1503.42792  last_update 24\n",
      "train: iter 641  trainloss -1514.80904  validloss -1485.04225±0.00000  bestvalidloss -1503.42792  last_update 25\n",
      "train: iter 642  trainloss -1406.15885  validloss -1228.74025±0.00000  bestvalidloss -1503.42792  last_update 26\n",
      "train: iter 643  trainloss -1467.50017  validloss -1394.05738±0.00000  bestvalidloss -1503.42792  last_update 27\n",
      "train: iter 644  trainloss -1388.88057  validloss -1428.35006±0.00000  bestvalidloss -1503.42792  last_update 28\n",
      "train: iter 645  trainloss -1566.36087  validloss -1395.89504±0.00000  bestvalidloss -1503.42792  last_update 29\n",
      "train: iter 646  trainloss -1367.50109  validloss -1463.31918±0.00000  bestvalidloss -1503.42792  last_update 30\n",
      "train: iter 647  trainloss -1386.85723  validloss -1121.47572±0.00000  bestvalidloss -1503.42792  last_update 31\n",
      "train: iter 648  trainloss -1526.49869  validloss -1415.55181±0.00000  bestvalidloss -1503.42792  last_update 32\n",
      "train: iter 649  trainloss -1531.76540  validloss -1411.38387±0.00000  bestvalidloss -1503.42792  last_update 33\n",
      "train: iter 650  trainloss -1561.52029  validloss -1500.55336±0.00000  bestvalidloss -1503.42792  last_update 34\n",
      "train: iter 651  trainloss -1414.83328  validloss -1197.46589±0.00000  bestvalidloss -1503.42792  last_update 35\n",
      "train: iter 652  trainloss -1551.82543  validloss -1380.47821±0.00000  bestvalidloss -1503.42792  last_update 36\n",
      "train: iter 653  trainloss -1509.72180  validloss -1435.10444±0.00000  bestvalidloss -1503.42792  last_update 37\n",
      "train: iter 654  trainloss -1591.89852  validloss -1448.17513±0.00000  bestvalidloss -1503.42792  last_update 38\n",
      "train: iter 655  trainloss -1414.28287  validloss -1463.66073±0.00000  bestvalidloss -1503.42792  last_update 39\n",
      "train: iter 656  trainloss -1578.72422  validloss -1357.46079±0.00000  bestvalidloss -1503.42792  last_update 40\n",
      "train: iter 657  trainloss -1620.50257  validloss -1511.32547±0.00000  bestvalidloss -1511.32547  last_update 0\n",
      "train: iter 658  trainloss -1446.97579  validloss -1361.66512±0.00000  bestvalidloss -1511.32547  last_update 1\n",
      "train: iter 659  trainloss -1571.91759  validloss -1424.82007±0.00000  bestvalidloss -1511.32547  last_update 2\n",
      "train: iter 660  trainloss -1419.48455  validloss -1412.59602±0.00000  bestvalidloss -1511.32547  last_update 3\n",
      "train: iter 661  trainloss -1460.48825  validloss -1258.23050±0.00000  bestvalidloss -1511.32547  last_update 4\n",
      "train: iter 662  trainloss -1513.43018  validloss -1387.78353±0.00000  bestvalidloss -1511.32547  last_update 5\n",
      "train: iter 663  trainloss -1587.39989  validloss -1477.61725±0.00000  bestvalidloss -1511.32547  last_update 6\n",
      "train: iter 664  trainloss -1557.52233  validloss -1274.89639±0.00000  bestvalidloss -1511.32547  last_update 7\n",
      "train: iter 665  trainloss -1563.71256  validloss -1504.32114±0.00000  bestvalidloss -1511.32547  last_update 8\n",
      "train: iter 666  trainloss -1555.61970  validloss -1404.61271±0.00000  bestvalidloss -1511.32547  last_update 9\n",
      "train: iter 667  trainloss -1379.75661  validloss -1367.72329±0.00000  bestvalidloss -1511.32547  last_update 10\n",
      "train: iter 668  trainloss -1537.14674  validloss -1431.86890±0.00000  bestvalidloss -1511.32547  last_update 11\n",
      "train: iter 669  trainloss -1453.06646  validloss -1310.57410±0.00000  bestvalidloss -1511.32547  last_update 12\n",
      "train: iter 670  trainloss -1575.97908  validloss -1451.45265±0.00000  bestvalidloss -1511.32547  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 671  trainloss -1497.39138  validloss -1443.80029±0.00000  bestvalidloss -1511.32547  last_update 14\n",
      "train: iter 672  trainloss -1482.80707  validloss -1170.04080±0.00000  bestvalidloss -1511.32547  last_update 15\n",
      "train: iter 673  trainloss -1390.63745  validloss -1430.40922±0.00000  bestvalidloss -1511.32547  last_update 16\n",
      "train: iter 674  trainloss -1483.39736  validloss -1298.63796±0.00000  bestvalidloss -1511.32547  last_update 17\n",
      "train: iter 675  trainloss -1578.21021  validloss -1357.05255±0.00000  bestvalidloss -1511.32547  last_update 18\n",
      "train: iter 676  trainloss -1606.67966  validloss -1485.09853±0.00000  bestvalidloss -1511.32547  last_update 19\n",
      "train: iter 677  trainloss -1601.35290  validloss -1511.71631±0.00000  bestvalidloss -1511.71631  last_update 0\n",
      "train: iter 678  trainloss -1479.70980  validloss -1177.53616±0.00000  bestvalidloss -1511.71631  last_update 1\n",
      "train: iter 679  trainloss -1500.30581  validloss -1426.31943±0.00000  bestvalidloss -1511.71631  last_update 2\n",
      "train: iter 680  trainloss -1574.55063  validloss -1405.46406±0.00000  bestvalidloss -1511.71631  last_update 3\n",
      "train: iter 681  trainloss -1473.93657  validloss -1476.27721±0.00000  bestvalidloss -1511.71631  last_update 4\n",
      "train: iter 682  trainloss -1595.91263  validloss -1472.43591±0.00000  bestvalidloss -1511.71631  last_update 5\n",
      "train: iter 683  trainloss -1531.12445  validloss -1485.84111±0.00000  bestvalidloss -1511.71631  last_update 6\n",
      "train: iter 684  trainloss -1560.02296  validloss -1445.01124±0.00000  bestvalidloss -1511.71631  last_update 7\n",
      "train: iter 685  trainloss -1550.57878  validloss -1425.15463±0.00000  bestvalidloss -1511.71631  last_update 8\n",
      "train: iter 686  trainloss -1500.10251  validloss -1327.20285±0.00000  bestvalidloss -1511.71631  last_update 9\n",
      "train: iter 687  trainloss -1586.53795  validloss -1490.28608±0.00000  bestvalidloss -1511.71631  last_update 10\n",
      "train: iter 688  trainloss -1544.96602  validloss -1543.79199±0.00000  bestvalidloss -1543.79199  last_update 0\n",
      "train: iter 689  trainloss -1399.46490  validloss -1300.65860±0.00000  bestvalidloss -1543.79199  last_update 1\n",
      "train: iter 690  trainloss -1573.18308  validloss -1472.16005±0.00000  bestvalidloss -1543.79199  last_update 2\n",
      "train: iter 691  trainloss -1517.89524  validloss -1488.58087±0.00000  bestvalidloss -1543.79199  last_update 3\n",
      "train: iter 692  trainloss -1589.06536  validloss -1479.49951±0.00000  bestvalidloss -1543.79199  last_update 4\n",
      "train: iter 693  trainloss -1619.67747  validloss -1501.99774±0.00000  bestvalidloss -1543.79199  last_update 5\n",
      "train: iter 694  trainloss -1603.57671  validloss -1513.04244±0.00000  bestvalidloss -1543.79199  last_update 6\n",
      "train: iter 695  trainloss -1384.67200  validloss -1393.19582±0.00000  bestvalidloss -1543.79199  last_update 7\n",
      "train: iter 696  trainloss -1518.96966  validloss -1406.65473±0.00000  bestvalidloss -1543.79199  last_update 8\n",
      "train: iter 697  trainloss -1545.73302  validloss -1460.56896±0.00000  bestvalidloss -1543.79199  last_update 9\n",
      "train: iter 698  trainloss -1558.66731  validloss -1436.78739±0.00000  bestvalidloss -1543.79199  last_update 10\n",
      "train: iter 699  trainloss -1600.35312  validloss -1448.27768±0.00000  bestvalidloss -1543.79199  last_update 11\n",
      "train: iter 700  trainloss -1575.27485  validloss -1519.24325±0.00000  bestvalidloss -1543.79199  last_update 12\n",
      "train: iter 701  trainloss -1453.83169  validloss -1420.53432±0.00000  bestvalidloss -1543.79199  last_update 13\n",
      "train: iter 702  trainloss -1483.49793  validloss -1355.66904±0.00000  bestvalidloss -1543.79199  last_update 14\n",
      "train: iter 703  trainloss -1599.52623  validloss -1434.23738±0.00000  bestvalidloss -1543.79199  last_update 15\n",
      "train: iter 704  trainloss -1609.72751  validloss -1446.02037±0.00000  bestvalidloss -1543.79199  last_update 16\n",
      "train: iter 705  trainloss -1323.89119  validloss -1538.08659±0.00000  bestvalidloss -1543.79199  last_update 17\n",
      "train: iter 706  trainloss -1325.93604  validloss -1295.72922±0.00000  bestvalidloss -1543.79199  last_update 18\n",
      "train: iter 707  trainloss -1538.70855  validloss -1325.74745±0.00000  bestvalidloss -1543.79199  last_update 19\n",
      "train: iter 708  trainloss -1535.40597  validloss -1354.03534±0.00000  bestvalidloss -1543.79199  last_update 20\n",
      "train: iter 709  trainloss -1577.70597  validloss -1466.04452±0.00000  bestvalidloss -1543.79199  last_update 21\n",
      "train: iter 710  trainloss -1623.13033  validloss -1471.92964±0.00000  bestvalidloss -1543.79199  last_update 22\n",
      "train: iter 711  trainloss -1527.34321  validloss -1522.65783±0.00000  bestvalidloss -1543.79199  last_update 23\n",
      "train: iter 712  trainloss -1408.07868  validloss -1237.27510±0.00000  bestvalidloss -1543.79199  last_update 24\n",
      "train: iter 713  trainloss -1598.58768  validloss -1450.65365±0.00000  bestvalidloss -1543.79199  last_update 25\n",
      "train: iter 714  trainloss -1550.51177  validloss -1471.16678±0.00000  bestvalidloss -1543.79199  last_update 26\n",
      "train: iter 715  trainloss -1534.05964  validloss -1367.61324±0.00000  bestvalidloss -1543.79199  last_update 27\n",
      "train: iter 716  trainloss -1628.33521  validloss -1410.82261±0.00000  bestvalidloss -1543.79199  last_update 28\n",
      "train: iter 717  trainloss -1650.86234  validloss -1495.66621±0.00000  bestvalidloss -1543.79199  last_update 29\n",
      "train: iter 718  trainloss -1598.70163  validloss -1507.52155±0.00000  bestvalidloss -1543.79199  last_update 30\n",
      "train: iter 719  trainloss -1544.30234  validloss -1424.72503±0.00000  bestvalidloss -1543.79199  last_update 31\n",
      "train: iter 720  trainloss -1609.33241  validloss -1433.38665±0.00000  bestvalidloss -1543.79199  last_update 32\n",
      "train: iter 721  trainloss -1547.94041  validloss -1413.93940±0.00000  bestvalidloss -1543.79199  last_update 33\n",
      "train: iter 722  trainloss -1573.06932  validloss -1378.44073±0.00000  bestvalidloss -1543.79199  last_update 34\n",
      "train: iter 723  trainloss -1506.18144  validloss -1131.33310±0.00000  bestvalidloss -1543.79199  last_update 35\n",
      "train: iter 724  trainloss -1553.72923  validloss -1481.45404±0.00000  bestvalidloss -1543.79199  last_update 36\n",
      "train: iter 725  trainloss -1413.88955  validloss -1300.98658±0.00000  bestvalidloss -1543.79199  last_update 37\n",
      "train: iter 726  trainloss -1577.81541  validloss -1389.12773±0.00000  bestvalidloss -1543.79199  last_update 38\n",
      "train: iter 727  trainloss -1609.91441  validloss -1452.50861±0.00000  bestvalidloss -1543.79199  last_update 39\n",
      "train: iter 728  trainloss -1615.17047  validloss -1275.16922±0.00000  bestvalidloss -1543.79199  last_update 40\n",
      "train: iter 729  trainloss -1568.85923  validloss -1528.09435±0.00000  bestvalidloss -1543.79199  last_update 41\n",
      "train: iter 730  trainloss -1577.18997  validloss -1433.58861±0.00000  bestvalidloss -1543.79199  last_update 42\n",
      "train: iter 731  trainloss -1582.49738  validloss -1518.83977±0.00000  bestvalidloss -1543.79199  last_update 43\n",
      "train: iter 732  trainloss -1259.93375  validloss -1424.91699±0.00000  bestvalidloss -1543.79199  last_update 44\n",
      "train: iter 733  trainloss -1423.60269  validloss -942.99192±0.00000  bestvalidloss -1543.79199  last_update 45\n",
      "train: iter 734  trainloss -1596.49665  validloss -1454.07894±0.00000  bestvalidloss -1543.79199  last_update 46\n",
      "train: iter 735  trainloss -1635.45278  validloss -1490.53339±0.00000  bestvalidloss -1543.79199  last_update 47\n",
      "train: iter 736  trainloss -1613.22657  validloss -1513.41013±0.00000  bestvalidloss -1543.79199  last_update 48\n",
      "train: iter 737  trainloss -1462.23124  validloss -1454.69696±0.00000  bestvalidloss -1543.79199  last_update 49\n",
      "train: iter 738  trainloss -1614.82331  validloss -1458.78058±0.00000  bestvalidloss -1543.79199  last_update 50\n",
      "train: iter 739  trainloss -1482.44591  validloss -1443.82516±0.00000  bestvalidloss -1543.79199  last_update 51\n",
      "train: iter 740  trainloss -1451.32724  validloss -1339.38444±0.00000  bestvalidloss -1543.79199  last_update 52\n",
      "train: iter 741  trainloss -1633.57236  validloss -1425.98702±0.00000  bestvalidloss -1543.79199  last_update 53\n",
      "train: iter 742  trainloss -1567.86385  validloss -1208.14489±0.00000  bestvalidloss -1543.79199  last_update 54\n",
      "train: iter 743  trainloss -1608.06916  validloss -1467.74183±0.00000  bestvalidloss -1543.79199  last_update 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 744  trainloss -1455.12481  validloss -1446.71014±0.00000  bestvalidloss -1543.79199  last_update 56\n",
      "train: iter 745  trainloss -1579.42091  validloss -1420.20763±0.00000  bestvalidloss -1543.79199  last_update 57\n",
      "train: iter 746  trainloss -1631.14473  validloss -1461.29078±0.00000  bestvalidloss -1543.79199  last_update 58\n",
      "train: iter 747  trainloss -1508.61916  validloss -1468.21527±0.00000  bestvalidloss -1543.79199  last_update 59\n",
      "train: iter 748  trainloss -1593.25155  validloss -1508.29013±0.00000  bestvalidloss -1543.79199  last_update 60\n",
      "train: iter 749  trainloss -1599.97404  validloss -1470.22588±0.00000  bestvalidloss -1543.79199  last_update 61\n",
      "train: iter 750  trainloss -1613.27545  validloss -1394.01191±0.00000  bestvalidloss -1543.79199  last_update 62\n",
      "train: iter 751  trainloss -1413.24755  validloss -1391.42672±0.00000  bestvalidloss -1543.79199  last_update 63\n",
      "train: iter 752  trainloss -1620.97273  validloss -1413.03346±0.00000  bestvalidloss -1543.79199  last_update 64\n",
      "train: iter 753  trainloss -1563.41107  validloss -1461.44957±0.00000  bestvalidloss -1543.79199  last_update 65\n",
      "train: iter 754  trainloss -1574.75349  validloss -1445.02878±0.00000  bestvalidloss -1543.79199  last_update 66\n",
      "train: iter 755  trainloss -1232.75670  validloss -1476.86945±0.00000  bestvalidloss -1543.79199  last_update 67\n",
      "train: iter 756  trainloss -1566.20502  validloss -1431.39939±0.00000  bestvalidloss -1543.79199  last_update 68\n",
      "train: iter 757  trainloss -1610.79438  validloss -1465.38399±0.00000  bestvalidloss -1543.79199  last_update 69\n",
      "train: iter 758  trainloss -1613.30035  validloss -1505.50556±0.00000  bestvalidloss -1543.79199  last_update 70\n",
      "train: iter 759  trainloss -1518.08288  validloss -1249.35824±0.00000  bestvalidloss -1543.79199  last_update 71\n",
      "train: iter 760  trainloss -1592.65666  validloss -1485.07568±0.00000  bestvalidloss -1543.79199  last_update 72\n",
      "train: iter 761  trainloss -1623.33661  validloss -1349.79708±0.00000  bestvalidloss -1543.79199  last_update 73\n",
      "train: iter 762  trainloss -1616.89997  validloss -1511.05862±0.00000  bestvalidloss -1543.79199  last_update 74\n",
      "train: iter 763  trainloss -1630.06827  validloss -1534.87008±0.00000  bestvalidloss -1543.79199  last_update 75\n",
      "train: iter 764  trainloss -1647.03117  validloss -1292.95109±0.00000  bestvalidloss -1543.79199  last_update 76\n",
      "train: iter 765  trainloss -1496.60310  validloss -1483.53833±0.00000  bestvalidloss -1543.79199  last_update 77\n",
      "train: iter 766  trainloss -1541.67739  validloss -1269.04672±0.00000  bestvalidloss -1543.79199  last_update 78\n",
      "train: iter 767  trainloss -1638.50261  validloss -1501.21164±0.00000  bestvalidloss -1543.79199  last_update 79\n",
      "train: iter 768  trainloss -1565.06186  validloss -1445.06351±0.00000  bestvalidloss -1543.79199  last_update 80\n",
      "train: iter 769  trainloss -1484.41440  validloss -1388.25453±0.00000  bestvalidloss -1543.79199  last_update 81\n",
      "train: iter 770  trainloss -1613.69889  validloss -1425.27288±0.00000  bestvalidloss -1543.79199  last_update 82\n",
      "train: iter 771  trainloss -1667.03668  validloss -1439.13936±0.00000  bestvalidloss -1543.79199  last_update 83\n",
      "train: iter 772  trainloss -1653.62745  validloss -1517.69282±0.00000  bestvalidloss -1543.79199  last_update 84\n",
      "train: iter 773  trainloss -1497.59982  validloss -1289.74422±0.00000  bestvalidloss -1543.79199  last_update 85\n",
      "train: iter 774  trainloss -1493.20290  validloss -1511.59397±0.00000  bestvalidloss -1543.79199  last_update 86\n",
      "train: iter 775  trainloss -1562.13074  validloss -1464.69540±0.00000  bestvalidloss -1543.79199  last_update 87\n",
      "train: iter 776  trainloss -1594.81844  validloss -1490.14924±0.00000  bestvalidloss -1543.79199  last_update 88\n",
      "train: iter 777  trainloss -1557.96675  validloss -1449.56826±0.00000  bestvalidloss -1543.79199  last_update 89\n",
      "train: iter 778  trainloss -1599.32865  validloss -1532.27468±0.00000  bestvalidloss -1543.79199  last_update 90\n",
      "train: iter 779  trainloss -1486.19557  validloss -1343.32016±0.00000  bestvalidloss -1543.79199  last_update 91\n",
      "train: iter 780  trainloss -1521.31214  validloss -1392.31013±0.00000  bestvalidloss -1543.79199  last_update 92\n",
      "train: iter 781  trainloss -1593.71432  validloss -1338.67967±0.00000  bestvalidloss -1543.79199  last_update 93\n",
      "train: iter 782  trainloss -1560.93542  validloss -1437.37200±0.00000  bestvalidloss -1543.79199  last_update 94\n",
      "train: iter 783  trainloss -1535.48820  validloss -1508.14707±0.00000  bestvalidloss -1543.79199  last_update 95\n",
      "train: iter 784  trainloss -1604.71081  validloss -1475.96165±0.00000  bestvalidloss -1543.79199  last_update 96\n",
      "train: iter 785  trainloss -1620.64627  validloss -1506.51026±0.00000  bestvalidloss -1543.79199  last_update 97\n",
      "train: iter 786  trainloss -1594.68976  validloss -1422.06553±0.00000  bestvalidloss -1543.79199  last_update 98\n",
      "train: iter 787  trainloss -1600.30023  validloss -1388.60554±0.00000  bestvalidloss -1543.79199  last_update 99\n",
      "train: iter 788  trainloss -1550.10956  validloss -1492.39957±0.00000  bestvalidloss -1543.79199  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.3066) penalty_target_max tensor(8.3031)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 5.82997  validloss 6.11904±0.00000  bestvalidloss 6.11904  last_update 0\n",
      "train: iter 1  trainloss 5.37213  validloss 5.59965±0.00000  bestvalidloss 5.59965  last_update 0\n",
      "train: iter 2  trainloss 4.99091  validloss 5.18558±0.00000  bestvalidloss 5.18558  last_update 0\n",
      "train: iter 3  trainloss 4.67417  validloss 4.84149±0.00000  bestvalidloss 4.84149  last_update 0\n",
      "train: iter 4  trainloss 4.42913  validloss 4.54976±0.00000  bestvalidloss 4.54976  last_update 0\n",
      "train: iter 5  trainloss 4.19990  validloss 4.31969±0.00000  bestvalidloss 4.31969  last_update 0\n",
      "train: iter 6  trainloss 4.00458  validloss 4.10862±0.00000  bestvalidloss 4.10862  last_update 0\n",
      "train: iter 7  trainloss 3.83848  validloss 3.91816±0.00000  bestvalidloss 3.91816  last_update 0\n",
      "train: iter 8  trainloss 3.67869  validloss 3.77259±0.00000  bestvalidloss 3.77259  last_update 0\n",
      "train: iter 9  trainloss 3.52392  validloss 3.60283±0.00000  bestvalidloss 3.60283  last_update 0\n",
      "train: iter 10  trainloss 3.38727  validloss 3.45661±0.00000  bestvalidloss 3.45661  last_update 0\n",
      "train: iter 11  trainloss 3.24596  validloss 3.33671±0.00000  bestvalidloss 3.33671  last_update 0\n",
      "train: iter 12  trainloss 3.11212  validloss 3.19417±0.00000  bestvalidloss 3.19417  last_update 0\n",
      "train: iter 13  trainloss 2.98627  validloss 3.04476±0.00000  bestvalidloss 3.04476  last_update 0\n",
      "train: iter 14  trainloss 2.85341  validloss 2.92784±0.00000  bestvalidloss 2.92784  last_update 0\n",
      "train: iter 15  trainloss 2.72804  validloss 2.79345±0.00000  bestvalidloss 2.79345  last_update 0\n",
      "train: iter 16  trainloss 2.59982  validloss 2.66625±0.00000  bestvalidloss 2.66625  last_update 0\n",
      "train: iter 17  trainloss 2.47238  validloss 2.54519±0.00000  bestvalidloss 2.54519  last_update 0\n",
      "train: iter 18  trainloss 2.36027  validloss 2.41858±0.00000  bestvalidloss 2.41858  last_update 0\n",
      "train: iter 19  trainloss 2.24429  validloss 2.30381±0.00000  bestvalidloss 2.30381  last_update 0\n",
      "train: iter 20  trainloss 2.13714  validloss 2.19448±0.00000  bestvalidloss 2.19448  last_update 0\n",
      "train: iter 21  trainloss 2.03455  validloss 2.09900±0.00000  bestvalidloss 2.09900  last_update 0\n",
      "train: iter 22  trainloss 1.94500  validloss 2.00649±0.00000  bestvalidloss 2.00649  last_update 0\n",
      "train: iter 23  trainloss 1.85585  validloss 1.90643±0.00000  bestvalidloss 1.90643  last_update 0\n",
      "train: iter 24  trainloss 1.77128  validloss 1.82629±0.00000  bestvalidloss 1.82629  last_update 0\n",
      "train: iter 25  trainloss 1.68730  validloss 1.74052±0.00000  bestvalidloss 1.74052  last_update 0\n",
      "train: iter 26  trainloss 1.60645  validloss 1.66315±0.00000  bestvalidloss 1.66315  last_update 0\n",
      "train: iter 27  trainloss 1.52850  validloss 1.58115±0.00000  bestvalidloss 1.58115  last_update 0\n",
      "train: iter 28  trainloss 1.45314  validloss 1.50601±0.00000  bestvalidloss 1.50601  last_update 0\n",
      "train: iter 29  trainloss 1.36824  validloss 1.41293±0.00000  bestvalidloss 1.41293  last_update 0\n",
      "train: iter 30  trainloss 1.28596  validloss 1.33814±0.00000  bestvalidloss 1.33814  last_update 0\n",
      "train: iter 31  trainloss 1.20349  validloss 1.26346±0.00000  bestvalidloss 1.26346  last_update 0\n",
      "train: iter 32  trainloss 1.12017  validloss 1.18237±0.00000  bestvalidloss 1.18237  last_update 0\n",
      "train: iter 33  trainloss 1.03515  validloss 1.10068±0.00000  bestvalidloss 1.10068  last_update 0\n",
      "train: iter 34  trainloss 0.95323  validloss 1.02350±0.00000  bestvalidloss 1.02350  last_update 0\n",
      "train: iter 35  trainloss 0.86706  validloss 0.93056±0.00000  bestvalidloss 0.93056  last_update 0\n",
      "train: iter 36  trainloss 0.78643  validloss 0.84342±0.00000  bestvalidloss 0.84342  last_update 0\n",
      "train: iter 37  trainloss 0.69770  validloss 0.77028±0.00000  bestvalidloss 0.77028  last_update 0\n",
      "train: iter 38  trainloss 0.60922  validloss 0.68465±0.00000  bestvalidloss 0.68465  last_update 0\n",
      "train: iter 39  trainloss 0.52661  validloss 0.59235±0.00000  bestvalidloss 0.59235  last_update 0\n",
      "train: iter 40  trainloss 0.43451  validloss 0.51336±0.00000  bestvalidloss 0.51336  last_update 0\n",
      "train: iter 41  trainloss 0.35403  validloss 0.43259±0.00000  bestvalidloss 0.43259  last_update 0\n",
      "train: iter 42  trainloss 0.26757  validloss 0.34633±0.00000  bestvalidloss 0.34633  last_update 0\n",
      "train: iter 43  trainloss 0.18214  validloss 0.24926±0.00000  bestvalidloss 0.24926  last_update 0\n",
      "train: iter 44  trainloss 0.09963  validloss 0.17954±0.00000  bestvalidloss 0.17954  last_update 0\n",
      "train: iter 45  trainloss 0.02296  validloss 0.10156±0.00000  bestvalidloss 0.10156  last_update 0\n",
      "train: iter 46  trainloss -0.04888  validloss 0.00539±0.00000  bestvalidloss 0.00539  last_update 0\n",
      "train: iter 47  trainloss -0.13448  validloss -0.04869±0.00000  bestvalidloss -0.04869  last_update 0\n",
      "train: iter 48  trainloss -0.20405  validloss -0.10534±0.00000  bestvalidloss -0.10534  last_update 0\n",
      "train: iter 49  trainloss -0.27474  validloss -0.17513±0.00000  bestvalidloss -0.17513  last_update 0\n",
      "train: iter 50  trainloss -0.34698  validloss -0.27535±0.00000  bestvalidloss -0.27535  last_update 0\n",
      "train: iter 51  trainloss -0.41535  validloss -0.27000±0.00000  bestvalidloss -0.27535  last_update 1\n",
      "train: iter 52  trainloss -0.47860  validloss -0.34139±0.00000  bestvalidloss -0.34139  last_update 0\n",
      "train: iter 53  trainloss -0.54014  validloss -0.42724±0.00000  bestvalidloss -0.42724  last_update 0\n",
      "train: iter 54  trainloss -0.58888  validloss -0.46585±0.00000  bestvalidloss -0.46585  last_update 0\n",
      "train: iter 55  trainloss -0.65458  validloss -0.53505±0.00000  bestvalidloss -0.53505  last_update 0\n",
      "train: iter 56  trainloss -0.71702  validloss -0.60640±0.00000  bestvalidloss -0.60640  last_update 0\n",
      "train: iter 57  trainloss -0.77470  validloss -0.69415±0.00000  bestvalidloss -0.69415  last_update 0\n",
      "train: iter 58  trainloss -0.84083  validloss -0.64983±0.00000  bestvalidloss -0.69415  last_update 1\n",
      "train: iter 59  trainloss -0.87838  validloss -0.67314±0.00000  bestvalidloss -0.69415  last_update 2\n",
      "train: iter 60  trainloss -0.90182  validloss -0.79319±0.00000  bestvalidloss -0.79319  last_update 0\n",
      "train: iter 61  trainloss -0.95426  validloss -0.78941±0.00000  bestvalidloss -0.79319  last_update 1\n",
      "train: iter 62  trainloss -1.02705  validloss -0.82527±0.00000  bestvalidloss -0.82527  last_update 0\n",
      "train: iter 63  trainloss -1.06938  validloss -0.93881±0.00000  bestvalidloss -0.93881  last_update 0\n",
      "train: iter 64  trainloss -1.09079  validloss -0.91382±0.00000  bestvalidloss -0.93881  last_update 1\n",
      "train: iter 65  trainloss -1.12883  validloss -0.92601±0.00000  bestvalidloss -0.93881  last_update 2\n",
      "train: iter 66  trainloss -1.15561  validloss -0.99384±0.00000  bestvalidloss -0.99384  last_update 0\n",
      "train: iter 67  trainloss -1.21513  validloss -1.07638±0.00000  bestvalidloss -1.07638  last_update 0\n",
      "train: iter 68  trainloss -1.23896  validloss -1.00124±0.00000  bestvalidloss -1.07638  last_update 1\n",
      "train: iter 69  trainloss -1.26355  validloss -1.06003±0.00000  bestvalidloss -1.07638  last_update 2\n",
      "train: iter 70  trainloss -1.28589  validloss -1.08483±0.00000  bestvalidloss -1.08483  last_update 0\n",
      "train: iter 71  trainloss -1.31617  validloss -1.19161±0.00000  bestvalidloss -1.19161  last_update 0\n",
      "train: iter 72  trainloss -1.34136  validloss -1.15034±0.00000  bestvalidloss -1.19161  last_update 1\n",
      "train: iter 73  trainloss -1.33460  validloss -1.16472±0.00000  bestvalidloss -1.19161  last_update 2\n",
      "train: iter 74  trainloss -1.41551  validloss -1.20894±0.00000  bestvalidloss -1.20894  last_update 0\n",
      "train: iter 75  trainloss -1.40227  validloss -1.18017±0.00000  bestvalidloss -1.20894  last_update 1\n",
      "train: iter 76  trainloss -1.36684  validloss -1.11967±0.00000  bestvalidloss -1.20894  last_update 2\n",
      "train: iter 77  trainloss -1.38983  validloss -1.14842±0.00000  bestvalidloss -1.20894  last_update 3\n",
      "train: iter 78  trainloss -1.47277  validloss -1.15549±0.00000  bestvalidloss -1.20894  last_update 4\n",
      "train: iter 79  trainloss -1.48222  validloss -1.22825±0.00000  bestvalidloss -1.22825  last_update 0\n",
      "train: iter 80  trainloss -1.48476  validloss -1.25663±0.00000  bestvalidloss -1.25663  last_update 0\n",
      "train: iter 81  trainloss -1.52443  validloss -1.18360±0.00000  bestvalidloss -1.25663  last_update 1\n",
      "train: iter 82  trainloss -1.48885  validloss -1.24209±0.00000  bestvalidloss -1.25663  last_update 2\n",
      "train: iter 83  trainloss -1.49056  validloss -1.22873±0.00000  bestvalidloss -1.25663  last_update 3\n",
      "train: iter 84  trainloss -1.51279  validloss -1.27258±0.00000  bestvalidloss -1.27258  last_update 0\n",
      "train: iter 85  trainloss -1.55534  validloss -1.27883±0.00000  bestvalidloss -1.27883  last_update 0\n",
      "train: iter 86  trainloss -1.48583  validloss -1.10300±0.00000  bestvalidloss -1.27883  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 87  trainloss -1.55040  validloss -1.39655±0.00000  bestvalidloss -1.39655  last_update 0\n",
      "train: iter 88  trainloss -1.50532  validloss -1.04251±0.00000  bestvalidloss -1.39655  last_update 1\n",
      "train: iter 89  trainloss -1.51445  validloss -1.34743±0.00000  bestvalidloss -1.39655  last_update 2\n",
      "train: iter 90  trainloss -1.52136  validloss -1.13846±0.00000  bestvalidloss -1.39655  last_update 3\n",
      "train: iter 91  trainloss -1.53150  validloss -1.33884±0.00000  bestvalidloss -1.39655  last_update 4\n",
      "train: iter 92  trainloss -1.53099  validloss -1.14175±0.00000  bestvalidloss -1.39655  last_update 5\n",
      "train: iter 93  trainloss -1.54264  validloss -1.21768±0.00000  bestvalidloss -1.39655  last_update 6\n",
      "train: iter 94  trainloss -1.54103  validloss -1.27978±0.00000  bestvalidloss -1.39655  last_update 7\n",
      "train: iter 95  trainloss -1.56857  validloss -1.23281±0.00000  bestvalidloss -1.39655  last_update 8\n",
      "train: iter 96  trainloss -1.57260  validloss -1.15322±0.00000  bestvalidloss -1.39655  last_update 9\n",
      "train: iter 97  trainloss -1.54099  validloss -1.35481±0.00000  bestvalidloss -1.39655  last_update 10\n",
      "train: iter 98  trainloss -1.59474  validloss -1.23065±0.00000  bestvalidloss -1.39655  last_update 11\n",
      "train: iter 99  trainloss -1.50227  validloss -1.39408±0.00000  bestvalidloss -1.39655  last_update 12\n",
      "train: iter 100  trainloss -1.52436  validloss -1.26210±0.00000  bestvalidloss -1.39655  last_update 13\n",
      "train: iter 101  trainloss -1.50243  validloss -1.13353±0.00000  bestvalidloss -1.39655  last_update 14\n",
      "train: iter 102  trainloss -1.51550  validloss -1.30438±0.00000  bestvalidloss -1.39655  last_update 15\n",
      "train: iter 103  trainloss -1.51166  validloss -1.21103±0.00000  bestvalidloss -1.39655  last_update 16\n",
      "train: iter 104  trainloss -1.51111  validloss -1.28313±0.00000  bestvalidloss -1.39655  last_update 17\n",
      "train: iter 105  trainloss -1.50306  validloss -1.20162±0.00000  bestvalidloss -1.39655  last_update 18\n",
      "train: iter 106  trainloss -1.57958  validloss -1.25638±0.00000  bestvalidloss -1.39655  last_update 19\n",
      "train: iter 107  trainloss -1.54318  validloss -1.33884±0.00000  bestvalidloss -1.39655  last_update 20\n",
      "train: iter 108  trainloss -1.52466  validloss -1.04140±0.00000  bestvalidloss -1.39655  last_update 21\n",
      "train: iter 109  trainloss -1.49679  validloss -1.25536±0.00000  bestvalidloss -1.39655  last_update 22\n",
      "train: iter 110  trainloss -1.56773  validloss -1.45181±0.00000  bestvalidloss -1.45181  last_update 0\n",
      "train: iter 111  trainloss -1.49763  validloss -1.29076±0.00000  bestvalidloss -1.45181  last_update 1\n",
      "train: iter 112  trainloss -1.47205  validloss -1.07723±0.00000  bestvalidloss -1.45181  last_update 2\n",
      "train: iter 113  trainloss -1.45287  validloss -1.42569±0.00000  bestvalidloss -1.45181  last_update 3\n",
      "train: iter 114  trainloss -1.49573  validloss -1.25086±0.00000  bestvalidloss -1.45181  last_update 4\n",
      "train: iter 115  trainloss -1.56870  validloss -1.12122±0.00000  bestvalidloss -1.45181  last_update 5\n",
      "train: iter 116  trainloss -1.50913  validloss -1.31792±0.00000  bestvalidloss -1.45181  last_update 6\n",
      "train: iter 117  trainloss -1.54487  validloss -1.26153±0.00000  bestvalidloss -1.45181  last_update 7\n",
      "train: iter 118  trainloss -1.55102  validloss -1.34636±0.00000  bestvalidloss -1.45181  last_update 8\n",
      "train: iter 119  trainloss -1.50252  validloss -1.22978±0.00000  bestvalidloss -1.45181  last_update 9\n",
      "train: iter 120  trainloss -1.51783  validloss -1.16262±0.00000  bestvalidloss -1.45181  last_update 10\n",
      "train: iter 121  trainloss -1.56327  validloss -1.23358±0.00000  bestvalidloss -1.45181  last_update 11\n",
      "train: iter 122  trainloss -1.57929  validloss -1.21566±0.00000  bestvalidloss -1.45181  last_update 12\n",
      "train: iter 123  trainloss -1.50943  validloss -1.21292±0.00000  bestvalidloss -1.45181  last_update 13\n",
      "train: iter 124  trainloss -1.55696  validloss -1.22526±0.00000  bestvalidloss -1.45181  last_update 14\n",
      "train: iter 125  trainloss -1.55827  validloss -1.24728±0.00000  bestvalidloss -1.45181  last_update 15\n",
      "train: iter 126  trainloss -1.52075  validloss -1.23241±0.00000  bestvalidloss -1.45181  last_update 16\n",
      "train: iter 127  trainloss -1.53763  validloss -1.04527±0.00000  bestvalidloss -1.45181  last_update 17\n",
      "train: iter 128  trainloss -1.48880  validloss -1.33795±0.00000  bestvalidloss -1.45181  last_update 18\n",
      "train: iter 129  trainloss -1.48857  validloss -1.18772±0.00000  bestvalidloss -1.45181  last_update 19\n",
      "train: iter 130  trainloss -1.48761  validloss -1.30077±0.00000  bestvalidloss -1.45181  last_update 20\n",
      "train: iter 131  trainloss -1.51616  validloss -1.33036±0.00000  bestvalidloss -1.45181  last_update 21\n",
      "train: iter 132  trainloss -1.53466  validloss -1.22226±0.00000  bestvalidloss -1.45181  last_update 22\n",
      "train: iter 133  trainloss -1.51607  validloss -1.46234±0.00000  bestvalidloss -1.46234  last_update 0\n",
      "train: iter 134  trainloss -1.56791  validloss -1.17140±0.00000  bestvalidloss -1.46234  last_update 1\n",
      "train: iter 135  trainloss -1.50336  validloss -1.33628±0.00000  bestvalidloss -1.46234  last_update 2\n",
      "train: iter 136  trainloss -1.51063  validloss -1.26110±0.00000  bestvalidloss -1.46234  last_update 3\n",
      "train: iter 137  trainloss -1.56634  validloss -1.32239±0.00000  bestvalidloss -1.46234  last_update 4\n",
      "train: iter 138  trainloss -1.49511  validloss -1.25336±0.00000  bestvalidloss -1.46234  last_update 5\n",
      "train: iter 139  trainloss -1.55315  validloss -1.36258±0.00000  bestvalidloss -1.46234  last_update 6\n",
      "train: iter 140  trainloss -1.58789  validloss -1.12729±0.00000  bestvalidloss -1.46234  last_update 7\n",
      "train: iter 141  trainloss -1.47380  validloss -1.20497±0.00000  bestvalidloss -1.46234  last_update 8\n",
      "train: iter 142  trainloss -1.47125  validloss -1.32567±0.00000  bestvalidloss -1.46234  last_update 9\n",
      "train: iter 143  trainloss -1.51369  validloss -1.26405±0.00000  bestvalidloss -1.46234  last_update 10\n",
      "train: iter 144  trainloss -1.58224  validloss -1.43448±0.00000  bestvalidloss -1.46234  last_update 11\n",
      "train: iter 145  trainloss -1.53723  validloss -1.22451±0.00000  bestvalidloss -1.46234  last_update 12\n",
      "train: iter 146  trainloss -1.56278  validloss -1.28013±0.00000  bestvalidloss -1.46234  last_update 13\n",
      "train: iter 147  trainloss -1.53176  validloss -1.25458±0.00000  bestvalidloss -1.46234  last_update 14\n",
      "train: iter 148  trainloss -1.55585  validloss -1.21745±0.00000  bestvalidloss -1.46234  last_update 15\n",
      "train: iter 149  trainloss -1.57635  validloss -1.32121±0.00000  bestvalidloss -1.46234  last_update 16\n",
      "train: iter 150  trainloss -1.53748  validloss -1.25123±0.00000  bestvalidloss -1.46234  last_update 17\n",
      "train: iter 151  trainloss -1.53235  validloss -1.39376±0.00000  bestvalidloss -1.46234  last_update 18\n",
      "train: iter 152  trainloss -1.58080  validloss -1.39702±0.00000  bestvalidloss -1.46234  last_update 19\n",
      "train: iter 153  trainloss -1.59847  validloss -1.07617±0.00000  bestvalidloss -1.46234  last_update 20\n",
      "train: iter 154  trainloss -1.53448  validloss -1.26420±0.00000  bestvalidloss -1.46234  last_update 21\n",
      "train: iter 155  trainloss -1.54556  validloss -1.25130±0.00000  bestvalidloss -1.46234  last_update 22\n",
      "train: iter 156  trainloss -1.48533  validloss -1.23154±0.00000  bestvalidloss -1.46234  last_update 23\n",
      "train: iter 157  trainloss -1.56551  validloss -1.28829±0.00000  bestvalidloss -1.46234  last_update 24\n",
      "train: iter 158  trainloss -1.51511  validloss -1.22840±0.00000  bestvalidloss -1.46234  last_update 25\n",
      "train: iter 159  trainloss -1.56937  validloss -1.22159±0.00000  bestvalidloss -1.46234  last_update 26\n",
      "train: iter 160  trainloss -1.46376  validloss -1.29062±0.00000  bestvalidloss -1.46234  last_update 27\n",
      "train: iter 161  trainloss -1.51126  validloss -1.36465±0.00000  bestvalidloss -1.46234  last_update 28\n",
      "train: iter 162  trainloss -1.58464  validloss -1.29264±0.00000  bestvalidloss -1.46234  last_update 29\n",
      "train: iter 163  trainloss -1.59532  validloss -1.23916±0.00000  bestvalidloss -1.46234  last_update 30\n",
      "train: iter 164  trainloss -1.50055  validloss -1.32196±0.00000  bestvalidloss -1.46234  last_update 31\n",
      "train: iter 165  trainloss -1.55119  validloss -1.15051±0.00000  bestvalidloss -1.46234  last_update 32\n",
      "train: iter 166  trainloss -1.53818  validloss -1.20913±0.00000  bestvalidloss -1.46234  last_update 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss -1.51470  validloss -1.19496±0.00000  bestvalidloss -1.46234  last_update 34\n",
      "train: iter 168  trainloss -1.51104  validloss -1.23680±0.00000  bestvalidloss -1.46234  last_update 35\n",
      "train: iter 169  trainloss -1.54362  validloss -1.32714±0.00000  bestvalidloss -1.46234  last_update 36\n",
      "train: iter 170  trainloss -1.48868  validloss -1.24575±0.00000  bestvalidloss -1.46234  last_update 37\n",
      "train: iter 171  trainloss -1.61418  validloss -1.37090±0.00000  bestvalidloss -1.46234  last_update 38\n",
      "train: iter 172  trainloss -1.58022  validloss -1.26149±0.00000  bestvalidloss -1.46234  last_update 39\n",
      "train: iter 173  trainloss -1.52151  validloss -1.27389±0.00000  bestvalidloss -1.46234  last_update 40\n",
      "train: iter 174  trainloss -1.54038  validloss -1.27758±0.00000  bestvalidloss -1.46234  last_update 41\n",
      "train: iter 175  trainloss -1.55579  validloss -1.22936±0.00000  bestvalidloss -1.46234  last_update 42\n",
      "train: iter 176  trainloss -1.53526  validloss -1.36794±0.00000  bestvalidloss -1.46234  last_update 43\n",
      "train: iter 177  trainloss -1.43776  validloss -1.25896±0.00000  bestvalidloss -1.46234  last_update 44\n",
      "train: iter 178  trainloss -1.54860  validloss -1.25727±0.00000  bestvalidloss -1.46234  last_update 45\n",
      "train: iter 179  trainloss -1.56375  validloss -1.33910±0.00000  bestvalidloss -1.46234  last_update 46\n",
      "train: iter 180  trainloss -1.59188  validloss -1.38090±0.00000  bestvalidloss -1.46234  last_update 47\n",
      "train: iter 181  trainloss -1.52502  validloss -1.24441±0.00000  bestvalidloss -1.46234  last_update 48\n",
      "train: iter 182  trainloss -1.55128  validloss -1.12461±0.00000  bestvalidloss -1.46234  last_update 49\n",
      "train: iter 183  trainloss -1.54767  validloss -1.20784±0.00000  bestvalidloss -1.46234  last_update 50\n",
      "train: iter 184  trainloss -1.46555  validloss -0.94235±0.00000  bestvalidloss -1.46234  last_update 51\n",
      "train: iter 185  trainloss -1.60227  validloss -1.25570±0.00000  bestvalidloss -1.46234  last_update 52\n",
      "train: iter 186  trainloss -1.49261  validloss -1.27694±0.00000  bestvalidloss -1.46234  last_update 53\n",
      "train: iter 187  trainloss -1.58801  validloss -1.15964±0.00000  bestvalidloss -1.46234  last_update 54\n",
      "train: iter 188  trainloss -1.57915  validloss -1.28123±0.00000  bestvalidloss -1.46234  last_update 55\n",
      "train: iter 189  trainloss -1.49715  validloss -1.17820±0.00000  bestvalidloss -1.46234  last_update 56\n",
      "train: iter 190  trainloss -1.57366  validloss -1.22302±0.00000  bestvalidloss -1.46234  last_update 57\n",
      "train: iter 191  trainloss -1.56912  validloss -1.14542±0.00000  bestvalidloss -1.46234  last_update 58\n",
      "train: iter 192  trainloss -1.50980  validloss -1.28619±0.00000  bestvalidloss -1.46234  last_update 59\n",
      "train: iter 193  trainloss -1.59556  validloss -1.22334±0.00000  bestvalidloss -1.46234  last_update 60\n",
      "train: iter 194  trainloss -1.48118  validloss -1.07502±0.00000  bestvalidloss -1.46234  last_update 61\n",
      "train: iter 195  trainloss -1.47088  validloss -0.98277±0.00000  bestvalidloss -1.46234  last_update 62\n",
      "train: iter 196  trainloss -1.52056  validloss -1.05594±0.00000  bestvalidloss -1.46234  last_update 63\n",
      "train: iter 197  trainloss -1.55407  validloss -1.22390±0.00000  bestvalidloss -1.46234  last_update 64\n",
      "train: iter 198  trainloss -1.56435  validloss -1.18221±0.00000  bestvalidloss -1.46234  last_update 65\n",
      "train: iter 199  trainloss -1.58661  validloss -1.13548±0.00000  bestvalidloss -1.46234  last_update 66\n",
      "train: iter 200  trainloss -1.53830  validloss -1.43071±0.00000  bestvalidloss -1.46234  last_update 67\n",
      "train: iter 201  trainloss -1.55785  validloss -1.32121±0.00000  bestvalidloss -1.46234  last_update 68\n",
      "train: iter 202  trainloss -1.55223  validloss -1.31230±0.00000  bestvalidloss -1.46234  last_update 69\n",
      "train: iter 203  trainloss -1.49897  validloss -1.16203±0.00000  bestvalidloss -1.46234  last_update 70\n",
      "train: iter 204  trainloss -1.52545  validloss -1.14086±0.00000  bestvalidloss -1.46234  last_update 71\n",
      "train: iter 205  trainloss -1.57976  validloss -1.16176±0.00000  bestvalidloss -1.46234  last_update 72\n",
      "train: iter 206  trainloss -1.56339  validloss -1.27861±0.00000  bestvalidloss -1.46234  last_update 73\n",
      "train: iter 207  trainloss -1.54255  validloss -1.34494±0.00000  bestvalidloss -1.46234  last_update 74\n",
      "train: iter 208  trainloss -1.53217  validloss -1.27727±0.00000  bestvalidloss -1.46234  last_update 75\n",
      "train: iter 209  trainloss -1.50285  validloss -1.37475±0.00000  bestvalidloss -1.46234  last_update 76\n",
      "train: iter 210  trainloss -1.51838  validloss -1.24577±0.00000  bestvalidloss -1.46234  last_update 77\n",
      "train: iter 211  trainloss -1.49973  validloss -1.25438±0.00000  bestvalidloss -1.46234  last_update 78\n",
      "train: iter 212  trainloss -1.60250  validloss -1.19352±0.00000  bestvalidloss -1.46234  last_update 79\n",
      "train: iter 213  trainloss -1.49645  validloss -1.16765±0.00000  bestvalidloss -1.46234  last_update 80\n",
      "train: iter 214  trainloss -1.54622  validloss -1.05841±0.00000  bestvalidloss -1.46234  last_update 81\n",
      "train: iter 215  trainloss -1.49030  validloss -1.26291±0.00000  bestvalidloss -1.46234  last_update 82\n",
      "train: iter 216  trainloss -1.56526  validloss -1.23947±0.00000  bestvalidloss -1.46234  last_update 83\n",
      "train: iter 217  trainloss -1.58766  validloss -1.26515±0.00000  bestvalidloss -1.46234  last_update 84\n",
      "train: iter 218  trainloss -1.53672  validloss -1.01984±0.00000  bestvalidloss -1.46234  last_update 85\n",
      "train: iter 219  trainloss -1.51346  validloss -1.39036±0.00000  bestvalidloss -1.46234  last_update 86\n",
      "train: iter 220  trainloss -1.54980  validloss -1.32039±0.00000  bestvalidloss -1.46234  last_update 87\n",
      "train: iter 221  trainloss -1.59162  validloss -1.36692±0.00000  bestvalidloss -1.46234  last_update 88\n",
      "train: iter 222  trainloss -1.47065  validloss -1.12262±0.00000  bestvalidloss -1.46234  last_update 89\n",
      "train: iter 223  trainloss -1.50507  validloss -1.31474±0.00000  bestvalidloss -1.46234  last_update 90\n",
      "train: iter 224  trainloss -1.54386  validloss -1.21274±0.00000  bestvalidloss -1.46234  last_update 91\n",
      "train: iter 225  trainloss -1.51830  validloss -1.23251±0.00000  bestvalidloss -1.46234  last_update 92\n",
      "train: iter 226  trainloss -1.55680  validloss -1.28979±0.00000  bestvalidloss -1.46234  last_update 93\n",
      "train: iter 227  trainloss -1.58694  validloss -1.23977±0.00000  bestvalidloss -1.46234  last_update 94\n",
      "train: iter 228  trainloss -1.51625  validloss -1.19874±0.00000  bestvalidloss -1.46234  last_update 95\n",
      "train: iter 229  trainloss -1.48918  validloss -1.31977±0.00000  bestvalidloss -1.46234  last_update 96\n",
      "train: iter 230  trainloss -1.52184  validloss -1.19640±0.00000  bestvalidloss -1.46234  last_update 97\n",
      "train: iter 231  trainloss -1.44189  validloss -1.22930±0.00000  bestvalidloss -1.46234  last_update 98\n",
      "train: iter 232  trainloss -1.47623  validloss -1.17044±0.00000  bestvalidloss -1.46234  last_update 99\n",
      "train: iter 233  trainloss -1.53432  validloss -1.22005±0.00000  bestvalidloss -1.46234  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 2.5174,  1.4688, -3.3910, -5.3142], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 66.98410  validloss 69.57251±0.00000  bestvalidloss 69.57251  last_update 0\n",
      "train: iter 1  trainloss 50.62194  validloss 55.28785±0.00000  bestvalidloss 55.28785  last_update 0\n",
      "train: iter 2  trainloss 36.81756  validloss 40.63443±0.00000  bestvalidloss 40.63443  last_update 0\n",
      "train: iter 3  trainloss 27.60614  validloss 30.18450±0.00000  bestvalidloss 30.18450  last_update 0\n",
      "train: iter 4  trainloss 21.60081  validloss 23.91598±0.00000  bestvalidloss 23.91598  last_update 0\n",
      "train: iter 5  trainloss 17.54349  validloss 19.57892±0.00000  bestvalidloss 19.57892  last_update 0\n",
      "train: iter 6  trainloss 14.60917  validloss 16.60128±0.00000  bestvalidloss 16.60128  last_update 0\n",
      "train: iter 7  trainloss 12.39676  validloss 14.58467±0.00000  bestvalidloss 14.58467  last_update 0\n",
      "train: iter 8  trainloss 10.80987  validloss 13.20180±0.00000  bestvalidloss 13.20180  last_update 0\n",
      "train: iter 9  trainloss 9.69271  validloss 12.09242±0.00000  bestvalidloss 12.09242  last_update 0\n",
      "train: iter 10  trainloss 8.75890  validloss 11.65874±0.00000  bestvalidloss 11.65874  last_update 0\n",
      "train: iter 11  trainloss 7.95553  validloss 10.98751±0.00000  bestvalidloss 10.98751  last_update 0\n",
      "train: iter 12  trainloss 7.29192  validloss 10.94707±0.00000  bestvalidloss 10.94707  last_update 0\n",
      "train: iter 13  trainloss 6.81192  validloss 10.84338±0.00000  bestvalidloss 10.84338  last_update 0\n",
      "train: iter 14  trainloss 6.40164  validloss 10.56056±0.00000  bestvalidloss 10.56056  last_update 0\n",
      "train: iter 15  trainloss 5.98374  validloss 10.43181±0.00000  bestvalidloss 10.43181  last_update 0\n",
      "train: iter 16  trainloss 5.65345  validloss 10.08554±0.00000  bestvalidloss 10.08554  last_update 0\n",
      "train: iter 17  trainloss 5.37916  validloss 9.53169±0.00000  bestvalidloss 9.53169  last_update 0\n",
      "train: iter 18  trainloss 5.07003  validloss 9.24782±0.00000  bestvalidloss 9.24782  last_update 0\n",
      "train: iter 19  trainloss 4.92942  validloss 8.92677±0.00000  bestvalidloss 8.92677  last_update 0\n",
      "train: iter 20  trainloss 4.70205  validloss 8.36154±0.00000  bestvalidloss 8.36154  last_update 0\n",
      "train: iter 21  trainloss 4.55283  validloss 8.42300±0.00000  bestvalidloss 8.36154  last_update 1\n",
      "train: iter 22  trainloss 4.45099  validloss 7.95527±0.00000  bestvalidloss 7.95527  last_update 0\n",
      "train: iter 23  trainloss 4.33135  validloss 7.73212±0.00000  bestvalidloss 7.73212  last_update 0\n",
      "train: iter 24  trainloss 4.29396  validloss 7.34156±0.00000  bestvalidloss 7.34156  last_update 0\n",
      "train: iter 25  trainloss 4.23064  validloss 7.89143±0.00000  bestvalidloss 7.34156  last_update 1\n",
      "train: iter 26  trainloss 4.11393  validloss 7.61435±0.00000  bestvalidloss 7.34156  last_update 2\n",
      "train: iter 27  trainloss 4.07722  validloss 7.53744±0.00000  bestvalidloss 7.34156  last_update 3\n",
      "train: iter 28  trainloss 4.00856  validloss 7.50376±0.00000  bestvalidloss 7.34156  last_update 4\n",
      "train: iter 29  trainloss 3.96402  validloss 7.36584±0.00000  bestvalidloss 7.34156  last_update 5\n",
      "train: iter 30  trainloss 3.90334  validloss 7.12675±0.00000  bestvalidloss 7.12675  last_update 0\n",
      "train: iter 31  trainloss 3.91087  validloss 7.16602±0.00000  bestvalidloss 7.12675  last_update 1\n",
      "train: iter 32  trainloss 3.86545  validloss 6.99136±0.00000  bestvalidloss 6.99136  last_update 0\n",
      "train: iter 33  trainloss 3.84378  validloss 6.93948±0.00000  bestvalidloss 6.93948  last_update 0\n",
      "train: iter 34  trainloss 3.81491  validloss 7.05191±0.00000  bestvalidloss 6.93948  last_update 1\n",
      "train: iter 35  trainloss 3.79429  validloss 7.12959±0.00000  bestvalidloss 6.93948  last_update 2\n",
      "train: iter 36  trainloss 3.75667  validloss 7.32823±0.00000  bestvalidloss 6.93948  last_update 3\n",
      "train: iter 37  trainloss 3.75292  validloss 6.88864±0.00000  bestvalidloss 6.88864  last_update 0\n",
      "train: iter 38  trainloss 3.71346  validloss 6.87072±0.00000  bestvalidloss 6.87072  last_update 0\n",
      "train: iter 39  trainloss 3.71288  validloss 6.84284±0.00000  bestvalidloss 6.84284  last_update 0\n",
      "train: iter 40  trainloss 3.63499  validloss 6.82337±0.00000  bestvalidloss 6.82337  last_update 0\n",
      "train: iter 41  trainloss 3.65176  validloss 6.82774±0.00000  bestvalidloss 6.82337  last_update 1\n",
      "train: iter 42  trainloss 3.65613  validloss 6.43610±0.00000  bestvalidloss 6.43610  last_update 0\n",
      "train: iter 43  trainloss 3.66148  validloss 6.77024±0.00000  bestvalidloss 6.43610  last_update 1\n",
      "train: iter 44  trainloss 3.63430  validloss 6.70956±0.00000  bestvalidloss 6.43610  last_update 2\n",
      "train: iter 45  trainloss 3.62652  validloss 7.01958±0.00000  bestvalidloss 6.43610  last_update 3\n",
      "train: iter 46  trainloss 3.63421  validloss 6.83422±0.00000  bestvalidloss 6.43610  last_update 4\n",
      "train: iter 47  trainloss 3.59494  validloss 6.99470±0.00000  bestvalidloss 6.43610  last_update 5\n",
      "train: iter 48  trainloss 3.62859  validloss 6.92879±0.00000  bestvalidloss 6.43610  last_update 6\n",
      "train: iter 49  trainloss 3.57976  validloss 6.92768±0.00000  bestvalidloss 6.43610  last_update 7\n",
      "train: iter 50  trainloss 3.53964  validloss 6.79102±0.00000  bestvalidloss 6.43610  last_update 8\n",
      "train: iter 51  trainloss 3.51930  validloss 6.36851±0.00000  bestvalidloss 6.36851  last_update 0\n",
      "train: iter 52  trainloss 3.50248  validloss 6.88254±0.00000  bestvalidloss 6.36851  last_update 1\n",
      "train: iter 53  trainloss 3.52663  validloss 6.59722±0.00000  bestvalidloss 6.36851  last_update 2\n",
      "train: iter 54  trainloss 3.55948  validloss 6.67222±0.00000  bestvalidloss 6.36851  last_update 3\n",
      "train: iter 55  trainloss 3.48810  validloss 6.49408±0.00000  bestvalidloss 6.36851  last_update 4\n",
      "train: iter 56  trainloss 3.44816  validloss 6.49002±0.00000  bestvalidloss 6.36851  last_update 5\n",
      "train: iter 57  trainloss 3.45706  validloss 6.26849±0.00000  bestvalidloss 6.26849  last_update 0\n",
      "train: iter 58  trainloss 3.41699  validloss 6.79964±0.00000  bestvalidloss 6.26849  last_update 1\n",
      "train: iter 59  trainloss 3.34711  validloss 7.04172±0.00000  bestvalidloss 6.26849  last_update 2\n",
      "train: iter 60  trainloss 3.34470  validloss 6.62804±0.00000  bestvalidloss 6.26849  last_update 3\n",
      "train: iter 61  trainloss 3.38121  validloss 6.48204±0.00000  bestvalidloss 6.26849  last_update 4\n",
      "train: iter 62  trainloss 3.31671  validloss 6.09620±0.00000  bestvalidloss 6.09620  last_update 0\n",
      "train: iter 63  trainloss 3.30705  validloss 6.49129±0.00000  bestvalidloss 6.09620  last_update 1\n",
      "train: iter 64  trainloss 3.27548  validloss 6.46290±0.00000  bestvalidloss 6.09620  last_update 2\n",
      "train: iter 65  trainloss 3.40670  validloss 6.53088±0.00000  bestvalidloss 6.09620  last_update 3\n",
      "train: iter 66  trainloss 3.27132  validloss 6.57007±0.00000  bestvalidloss 6.09620  last_update 4\n",
      "train: iter 67  trainloss 3.31347  validloss 6.59251±0.00000  bestvalidloss 6.09620  last_update 5\n",
      "train: iter 68  trainloss 3.28715  validloss 6.31383±0.00000  bestvalidloss 6.09620  last_update 6\n",
      "train: iter 69  trainloss 3.30225  validloss 6.17562±0.00000  bestvalidloss 6.09620  last_update 7\n",
      "train: iter 70  trainloss 3.35774  validloss 6.54836±0.00000  bestvalidloss 6.09620  last_update 8\n",
      "train: iter 71  trainloss 3.27402  validloss 6.70952±0.00000  bestvalidloss 6.09620  last_update 9\n",
      "train: iter 72  trainloss 3.25274  validloss 6.16408±0.00000  bestvalidloss 6.09620  last_update 10\n",
      "train: iter 73  trainloss 3.30183  validloss 6.60459±0.00000  bestvalidloss 6.09620  last_update 11\n",
      "train: iter 74  trainloss 3.32129  validloss 6.19853±0.00000  bestvalidloss 6.09620  last_update 12\n",
      "train: iter 75  trainloss 3.29332  validloss 6.55002±0.00000  bestvalidloss 6.09620  last_update 13\n",
      "train: iter 76  trainloss 3.27128  validloss 6.54799±0.00000  bestvalidloss 6.09620  last_update 14\n",
      "train: iter 77  trainloss 3.31978  validloss 6.63978±0.00000  bestvalidloss 6.09620  last_update 15\n",
      "train: iter 78  trainloss 3.27869  validloss 6.08858±0.00000  bestvalidloss 6.08858  last_update 0\n",
      "train: iter 79  trainloss 3.26049  validloss 6.50218±0.00000  bestvalidloss 6.08858  last_update 1\n",
      "train: iter 80  trainloss 3.26139  validloss 6.62819±0.00000  bestvalidloss 6.08858  last_update 2\n",
      "train: iter 81  trainloss 3.22021  validloss 6.18320±0.00000  bestvalidloss 6.08858  last_update 3\n",
      "train: iter 82  trainloss 3.26414  validloss 6.43273±0.00000  bestvalidloss 6.08858  last_update 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 3.25398  validloss 6.42012±0.00000  bestvalidloss 6.08858  last_update 5\n",
      "train: iter 84  trainloss 3.29773  validloss 6.23125±0.00000  bestvalidloss 6.08858  last_update 6\n",
      "train: iter 85  trainloss 3.23740  validloss 6.47500±0.00000  bestvalidloss 6.08858  last_update 7\n",
      "train: iter 86  trainloss 3.21118  validloss 6.58903±0.00000  bestvalidloss 6.08858  last_update 8\n",
      "train: iter 87  trainloss 3.22076  validloss 6.35577±0.00000  bestvalidloss 6.08858  last_update 9\n",
      "train: iter 88  trainloss 3.19500  validloss 6.18618±0.00000  bestvalidloss 6.08858  last_update 10\n",
      "train: iter 89  trainloss 3.23405  validloss 5.89806±0.00000  bestvalidloss 5.89806  last_update 0\n",
      "train: iter 90  trainloss 3.23823  validloss 6.24045±0.00000  bestvalidloss 5.89806  last_update 1\n",
      "train: iter 91  trainloss 3.20508  validloss 6.54895±0.00000  bestvalidloss 5.89806  last_update 2\n",
      "train: iter 92  trainloss 3.19111  validloss 6.43203±0.00000  bestvalidloss 5.89806  last_update 3\n",
      "train: iter 93  trainloss 3.20234  validloss 6.67709±0.00000  bestvalidloss 5.89806  last_update 4\n",
      "train: iter 94  trainloss 3.27507  validloss 6.60380±0.00000  bestvalidloss 5.89806  last_update 5\n",
      "train: iter 95  trainloss 3.21635  validloss 6.10237±0.00000  bestvalidloss 5.89806  last_update 6\n",
      "train: iter 96  trainloss 3.23087  validloss 6.34976±0.00000  bestvalidloss 5.89806  last_update 7\n",
      "train: iter 97  trainloss 3.25353  validloss 7.05624±0.00000  bestvalidloss 5.89806  last_update 8\n",
      "train: iter 98  trainloss 3.25342  validloss 6.86169±0.00000  bestvalidloss 5.89806  last_update 9\n",
      "train: iter 99  trainloss 3.18797  validloss 6.23271±0.00000  bestvalidloss 5.89806  last_update 10\n",
      "train: iter 100  trainloss 3.27541  validloss 6.15179±0.00000  bestvalidloss 5.89806  last_update 11\n",
      "train: iter 101  trainloss 3.22056  validloss 6.35603±0.00000  bestvalidloss 5.89806  last_update 12\n",
      "train: iter 102  trainloss 3.17479  validloss 6.66762±0.00000  bestvalidloss 5.89806  last_update 13\n",
      "train: iter 103  trainloss 3.19114  validloss 6.28929±0.00000  bestvalidloss 5.89806  last_update 14\n",
      "train: iter 104  trainloss 3.16838  validloss 6.45929±0.00000  bestvalidloss 5.89806  last_update 15\n",
      "train: iter 105  trainloss 3.26064  validloss 6.27599±0.00000  bestvalidloss 5.89806  last_update 16\n",
      "train: iter 106  trainloss 3.18581  validloss 6.40982±0.00000  bestvalidloss 5.89806  last_update 17\n",
      "train: iter 107  trainloss 3.17924  validloss 6.16156±0.00000  bestvalidloss 5.89806  last_update 18\n",
      "train: iter 108  trainloss 3.20670  validloss 6.47112±0.00000  bestvalidloss 5.89806  last_update 19\n",
      "train: iter 109  trainloss 3.22644  validloss 6.04142±0.00000  bestvalidloss 5.89806  last_update 20\n",
      "train: iter 110  trainloss 3.23650  validloss 6.16919±0.00000  bestvalidloss 5.89806  last_update 21\n",
      "train: iter 111  trainloss 3.17907  validloss 6.66198±0.00000  bestvalidloss 5.89806  last_update 22\n",
      "train: iter 112  trainloss 3.25298  validloss 6.62270±0.00000  bestvalidloss 5.89806  last_update 23\n",
      "train: iter 113  trainloss 3.17455  validloss 6.65954±0.00000  bestvalidloss 5.89806  last_update 24\n",
      "train: iter 114  trainloss 3.20658  validloss 6.39701±0.00000  bestvalidloss 5.89806  last_update 25\n",
      "train: iter 115  trainloss 3.14312  validloss 6.39979±0.00000  bestvalidloss 5.89806  last_update 26\n",
      "train: iter 116  trainloss 3.19707  validloss 6.54611±0.00000  bestvalidloss 5.89806  last_update 27\n",
      "train: iter 117  trainloss 3.15945  validloss 6.27274±0.00000  bestvalidloss 5.89806  last_update 28\n",
      "train: iter 118  trainloss 3.19514  validloss 6.16449±0.00000  bestvalidloss 5.89806  last_update 29\n",
      "train: iter 119  trainloss 3.17359  validloss 6.35455±0.00000  bestvalidloss 5.89806  last_update 30\n",
      "train: iter 120  trainloss 3.20070  validloss 6.47577±0.00000  bestvalidloss 5.89806  last_update 31\n",
      "train: iter 121  trainloss 3.19945  validloss 6.64631±0.00000  bestvalidloss 5.89806  last_update 32\n",
      "train: iter 122  trainloss 3.22886  validloss 6.46085±0.00000  bestvalidloss 5.89806  last_update 33\n",
      "train: iter 123  trainloss 3.15912  validloss 6.19914±0.00000  bestvalidloss 5.89806  last_update 34\n",
      "train: iter 124  trainloss 3.16756  validloss 6.32195±0.00000  bestvalidloss 5.89806  last_update 35\n",
      "train: iter 125  trainloss 3.15473  validloss 6.39325±0.00000  bestvalidloss 5.89806  last_update 36\n",
      "train: iter 126  trainloss 3.15092  validloss 6.54971±0.00000  bestvalidloss 5.89806  last_update 37\n",
      "train: iter 127  trainloss 3.19983  validloss 6.87084±0.00000  bestvalidloss 5.89806  last_update 38\n",
      "train: iter 128  trainloss 3.23385  validloss 6.52561±0.00000  bestvalidloss 5.89806  last_update 39\n",
      "train: iter 129  trainloss 3.19631  validloss 6.20058±0.00000  bestvalidloss 5.89806  last_update 40\n",
      "train: iter 130  trainloss 3.17981  validloss 6.42268±0.00000  bestvalidloss 5.89806  last_update 41\n",
      "train: iter 131  trainloss 3.16856  validloss 6.19697±0.00000  bestvalidloss 5.89806  last_update 42\n",
      "train: iter 132  trainloss 3.17519  validloss 6.52863±0.00000  bestvalidloss 5.89806  last_update 43\n",
      "train: iter 133  trainloss 3.12183  validloss 6.31655±0.00000  bestvalidloss 5.89806  last_update 44\n",
      "train: iter 134  trainloss 3.18862  validloss 6.65713±0.00000  bestvalidloss 5.89806  last_update 45\n",
      "train: iter 135  trainloss 3.19093  validloss 6.10922±0.00000  bestvalidloss 5.89806  last_update 46\n",
      "train: iter 136  trainloss 3.18736  validloss 6.25288±0.00000  bestvalidloss 5.89806  last_update 47\n",
      "train: iter 137  trainloss 3.14939  validloss 6.05814±0.00000  bestvalidloss 5.89806  last_update 48\n",
      "train: iter 138  trainloss 3.15186  validloss 6.77149±0.00000  bestvalidloss 5.89806  last_update 49\n",
      "train: iter 139  trainloss 3.19372  validloss 6.41252±0.00000  bestvalidloss 5.89806  last_update 50\n",
      "train: iter 140  trainloss 3.19268  validloss 6.57684±0.00000  bestvalidloss 5.89806  last_update 51\n",
      "train: iter 141  trainloss 3.17408  validloss 6.34331±0.00000  bestvalidloss 5.89806  last_update 52\n",
      "train: iter 142  trainloss 3.12844  validloss 6.53287±0.00000  bestvalidloss 5.89806  last_update 53\n",
      "train: iter 143  trainloss 3.13623  validloss 5.99659±0.00000  bestvalidloss 5.89806  last_update 54\n",
      "train: iter 144  trainloss 3.17744  validloss 6.27929±0.00000  bestvalidloss 5.89806  last_update 55\n",
      "train: iter 145  trainloss 3.15126  validloss 6.42196±0.00000  bestvalidloss 5.89806  last_update 56\n",
      "train: iter 146  trainloss 3.16349  validloss 6.43028±0.00000  bestvalidloss 5.89806  last_update 57\n",
      "train: iter 147  trainloss 3.16204  validloss 6.43411±0.00000  bestvalidloss 5.89806  last_update 58\n",
      "train: iter 148  trainloss 3.13123  validloss 6.72758±0.00000  bestvalidloss 5.89806  last_update 59\n",
      "train: iter 149  trainloss 3.10231  validloss 6.56186±0.00000  bestvalidloss 5.89806  last_update 60\n",
      "train: iter 150  trainloss 3.14302  validloss 6.34331±0.00000  bestvalidloss 5.89806  last_update 61\n",
      "train: iter 151  trainloss 3.15380  validloss 6.05169±0.00000  bestvalidloss 5.89806  last_update 62\n",
      "train: iter 152  trainloss 3.13470  validloss 6.23057±0.00000  bestvalidloss 5.89806  last_update 63\n",
      "train: iter 153  trainloss 3.20952  validloss 6.49945±0.00000  bestvalidloss 5.89806  last_update 64\n",
      "train: iter 154  trainloss 3.21489  validloss 6.72169±0.00000  bestvalidloss 5.89806  last_update 65\n",
      "train: iter 155  trainloss 3.15124  validloss 6.12084±0.00000  bestvalidloss 5.89806  last_update 66\n",
      "train: iter 156  trainloss 3.16841  validloss 6.29499±0.00000  bestvalidloss 5.89806  last_update 67\n",
      "train: iter 157  trainloss 3.18215  validloss 6.62769±0.00000  bestvalidloss 5.89806  last_update 68\n",
      "train: iter 158  trainloss 3.15901  validloss 6.54764±0.00000  bestvalidloss 5.89806  last_update 69\n",
      "train: iter 159  trainloss 3.13306  validloss 6.28733±0.00000  bestvalidloss 5.89806  last_update 70\n",
      "train: iter 160  trainloss 3.12746  validloss 6.24348±0.00000  bestvalidloss 5.89806  last_update 71\n",
      "train: iter 161  trainloss 3.14868  validloss 6.40984±0.00000  bestvalidloss 5.89806  last_update 72\n",
      "train: iter 162  trainloss 3.13461  validloss 6.37749±0.00000  bestvalidloss 5.89806  last_update 73\n",
      "train: iter 163  trainloss 3.21687  validloss 6.01394±0.00000  bestvalidloss 5.89806  last_update 74\n",
      "train: iter 164  trainloss 3.14714  validloss 6.19760±0.00000  bestvalidloss 5.89806  last_update 75\n",
      "train: iter 165  trainloss 3.10921  validloss 6.31908±0.00000  bestvalidloss 5.89806  last_update 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 166  trainloss 3.15722  validloss 6.82354±0.00000  bestvalidloss 5.89806  last_update 77\n",
      "train: iter 167  trainloss 3.13279  validloss 6.63803±0.00000  bestvalidloss 5.89806  last_update 78\n",
      "train: iter 168  trainloss 3.10183  validloss 6.46408±0.00000  bestvalidloss 5.89806  last_update 79\n",
      "train: iter 169  trainloss 3.15021  validloss 6.83833±0.00000  bestvalidloss 5.89806  last_update 80\n",
      "train: iter 170  trainloss 3.11251  validloss 6.36456±0.00000  bestvalidloss 5.89806  last_update 81\n",
      "train: iter 171  trainloss 3.13539  validloss 6.27526±0.00000  bestvalidloss 5.89806  last_update 82\n",
      "train: iter 172  trainloss 3.16361  validloss 6.52600±0.00000  bestvalidloss 5.89806  last_update 83\n",
      "train: iter 173  trainloss 3.16821  validloss 6.58881±0.00000  bestvalidloss 5.89806  last_update 84\n",
      "train: iter 174  trainloss 3.14437  validloss 6.41626±0.00000  bestvalidloss 5.89806  last_update 85\n",
      "train: iter 175  trainloss 3.16861  validloss 6.16920±0.00000  bestvalidloss 5.89806  last_update 86\n",
      "train: iter 176  trainloss 3.11628  validloss 6.23322±0.00000  bestvalidloss 5.89806  last_update 87\n",
      "train: iter 177  trainloss 3.13484  validloss 6.63815±0.00000  bestvalidloss 5.89806  last_update 88\n",
      "train: iter 178  trainloss 3.09539  validloss 6.31483±0.00000  bestvalidloss 5.89806  last_update 89\n",
      "train: iter 179  trainloss 3.13171  validloss 6.33803±0.00000  bestvalidloss 5.89806  last_update 90\n",
      "train: iter 180  trainloss 3.12743  validloss 6.34217±0.00000  bestvalidloss 5.89806  last_update 91\n",
      "train: iter 181  trainloss 3.13118  validloss 6.65224±0.00000  bestvalidloss 5.89806  last_update 92\n",
      "train: iter 182  trainloss 3.10615  validloss 6.35062±0.00000  bestvalidloss 5.89806  last_update 93\n",
      "train: iter 183  trainloss 3.14708  validloss 6.36903±0.00000  bestvalidloss 5.89806  last_update 94\n",
      "train: iter 184  trainloss 3.12652  validloss 6.22607±0.00000  bestvalidloss 5.89806  last_update 95\n",
      "train: iter 185  trainloss 3.09210  validloss 6.49167±0.00000  bestvalidloss 5.89806  last_update 96\n",
      "train: iter 186  trainloss 3.16919  validloss 6.80460±0.00000  bestvalidloss 5.89806  last_update 97\n",
      "train: iter 187  trainloss 3.12703  validloss 6.39322±0.00000  bestvalidloss 5.89806  last_update 98\n",
      "train: iter 188  trainloss 3.15094  validloss 6.33998±0.00000  bestvalidloss 5.89806  last_update 99\n",
      "train: iter 189  trainloss 3.13599  validloss 6.25723±0.00000  bestvalidloss 5.89806  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-4.7190)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-5.4964)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.159570651560175\n",
      "tensor([-0.2419])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8ebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d6e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15274c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d9a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
