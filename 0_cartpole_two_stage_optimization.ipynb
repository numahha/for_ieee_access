{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-20497.0352)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 19051.46793  validloss 20869.94328±0.00000  bestvalidloss 20869.94328  last_update 0\n",
      "train: iter 1  trainloss 2170.79988  validloss 1318.04865±0.00000  bestvalidloss 1318.04865  last_update 0\n",
      "train: iter 2  trainloss 1511.67232  validloss 1207.23717±0.00000  bestvalidloss 1207.23717  last_update 0\n",
      "train: iter 3  trainloss 1233.11430  validloss 1268.54904±0.00000  bestvalidloss 1207.23717  last_update 1\n",
      "train: iter 4  trainloss 1103.43021  validloss 1092.06158±0.00000  bestvalidloss 1092.06158  last_update 0\n",
      "train: iter 5  trainloss 979.53467  validloss 1016.78927±0.00000  bestvalidloss 1016.78927  last_update 0\n",
      "train: iter 6  trainloss 900.03035  validloss 996.97883±0.00000  bestvalidloss 996.97883  last_update 0\n",
      "train: iter 7  trainloss 874.28969  validloss 1019.47540±0.00000  bestvalidloss 996.97883  last_update 1\n",
      "train: iter 8  trainloss 818.35685  validloss 1152.27263±0.00000  bestvalidloss 996.97883  last_update 2\n",
      "train: iter 9  trainloss 765.89515  validloss 1161.53709±0.00000  bestvalidloss 996.97883  last_update 3\n",
      "train: iter 10  trainloss 730.02595  validloss 1026.85540±0.00000  bestvalidloss 996.97883  last_update 4\n",
      "train: iter 11  trainloss 712.98243  validloss 3188.71958±0.00000  bestvalidloss 996.97883  last_update 5\n",
      "train: iter 12  trainloss 732.36727  validloss 1088.00213±0.00000  bestvalidloss 996.97883  last_update 6\n",
      "train: iter 13  trainloss 717.75453  validloss 727.00446±0.00000  bestvalidloss 727.00446  last_update 0\n",
      "train: iter 14  trainloss 643.44176  validloss 694.22586±0.00000  bestvalidloss 694.22586  last_update 0\n",
      "train: iter 15  trainloss 561.75004  validloss 630.15265±0.00000  bestvalidloss 630.15265  last_update 0\n",
      "train: iter 16  trainloss 502.71950  validloss 663.78886±0.00000  bestvalidloss 630.15265  last_update 1\n",
      "train: iter 17  trainloss 458.27211  validloss 635.44803±0.00000  bestvalidloss 630.15265  last_update 2\n",
      "train: iter 18  trainloss 419.66566  validloss 570.84841±0.00000  bestvalidloss 570.84841  last_update 0\n",
      "train: iter 19  trainloss 380.74134  validloss 652.92701±0.00000  bestvalidloss 570.84841  last_update 1\n",
      "train: iter 20  trainloss 336.79504  validloss 470.48919±0.00000  bestvalidloss 470.48919  last_update 0\n",
      "train: iter 21  trainloss 285.88157  validloss 470.33673±0.00000  bestvalidloss 470.33673  last_update 0\n",
      "train: iter 22  trainloss 248.76135  validloss 398.53267±0.00000  bestvalidloss 398.53267  last_update 0\n",
      "train: iter 23  trainloss 197.14684  validloss 362.64413±0.00000  bestvalidloss 362.64413  last_update 0\n",
      "train: iter 24  trainloss 162.85117  validloss 312.57720±0.00000  bestvalidloss 312.57720  last_update 0\n",
      "train: iter 25  trainloss 118.74376  validloss 255.19794±0.00000  bestvalidloss 255.19794  last_update 0\n",
      "train: iter 26  trainloss 88.29831  validloss 169.18625±0.00000  bestvalidloss 169.18625  last_update 0\n",
      "train: iter 27  trainloss 45.33219  validloss 201.47853±0.00000  bestvalidloss 169.18625  last_update 1\n",
      "train: iter 28  trainloss 40.10742  validloss 284.28830±0.00000  bestvalidloss 169.18625  last_update 2\n",
      "train: iter 29  trainloss -10.30072  validloss 39.66332±0.00000  bestvalidloss 39.66332  last_update 0\n",
      "train: iter 30  trainloss -50.36511  validloss 91.60257±0.00000  bestvalidloss 39.66332  last_update 1\n",
      "train: iter 31  trainloss -50.73162  validloss -19.59106±0.00000  bestvalidloss -19.59106  last_update 0\n",
      "train: iter 32  trainloss -59.57918  validloss 71.29052±0.00000  bestvalidloss -19.59106  last_update 1\n",
      "train: iter 33  trainloss -119.28648  validloss -59.99474±0.00000  bestvalidloss -59.99474  last_update 0\n",
      "train: iter 34  trainloss -153.07347  validloss -76.42882±0.00000  bestvalidloss -76.42882  last_update 0\n",
      "train: iter 35  trainloss -136.23359  validloss 66.33181±0.00000  bestvalidloss -76.42882  last_update 1\n",
      "train: iter 36  trainloss -182.99007  validloss -2.40472±0.00000  bestvalidloss -76.42882  last_update 2\n",
      "train: iter 37  trainloss -190.82269  validloss -91.10000±0.00000  bestvalidloss -91.10000  last_update 0\n",
      "train: iter 38  trainloss -239.00698  validloss -202.50920±0.00000  bestvalidloss -202.50920  last_update 0\n",
      "train: iter 39  trainloss -239.16152  validloss -189.51516±0.00000  bestvalidloss -202.50920  last_update 1\n",
      "train: iter 40  trainloss -255.04034  validloss -224.02776±0.00000  bestvalidloss -224.02776  last_update 0\n",
      "train: iter 41  trainloss -274.82939  validloss -201.17706±0.00000  bestvalidloss -224.02776  last_update 1\n",
      "train: iter 42  trainloss -311.54544  validloss -240.26883±0.00000  bestvalidloss -240.26883  last_update 0\n",
      "train: iter 43  trainloss -325.36165  validloss -287.32144±0.00000  bestvalidloss -287.32144  last_update 0\n",
      "train: iter 44  trainloss -318.19577  validloss -217.15006±0.00000  bestvalidloss -287.32144  last_update 1\n",
      "train: iter 45  trainloss -349.21262  validloss -280.24971±0.00000  bestvalidloss -287.32144  last_update 2\n",
      "train: iter 46  trainloss -355.20506  validloss -308.63096±0.00000  bestvalidloss -308.63096  last_update 0\n",
      "train: iter 47  trainloss -401.10312  validloss -323.91594±0.00000  bestvalidloss -323.91594  last_update 0\n",
      "train: iter 48  trainloss -407.52062  validloss -331.85825±0.00000  bestvalidloss -331.85825  last_update 0\n",
      "train: iter 49  trainloss -313.61604  validloss -265.98002±0.00000  bestvalidloss -331.85825  last_update 1\n",
      "train: iter 50  trainloss -408.98898  validloss -143.92970±0.00000  bestvalidloss -331.85825  last_update 2\n",
      "train: iter 51  trainloss -403.60508  validloss -377.34098±0.00000  bestvalidloss -377.34098  last_update 0\n",
      "train: iter 52  trainloss -437.20674  validloss -347.69961±0.00000  bestvalidloss -377.34098  last_update 1\n",
      "train: iter 53  trainloss -469.46146  validloss -332.33079±0.00000  bestvalidloss -377.34098  last_update 2\n",
      "train: iter 54  trainloss -480.16153  validloss -413.34652±0.00000  bestvalidloss -413.34652  last_update 0\n",
      "train: iter 55  trainloss -484.70655  validloss -421.96710±0.00000  bestvalidloss -421.96710  last_update 0\n",
      "train: iter 56  trainloss -470.92622  validloss -420.33236±0.00000  bestvalidloss -421.96710  last_update 1\n",
      "train: iter 57  trainloss -487.48937  validloss -417.73627±0.00000  bestvalidloss -421.96710  last_update 2\n",
      "train: iter 58  trainloss -438.26804  validloss -265.46913±0.00000  bestvalidloss -421.96710  last_update 3\n",
      "train: iter 59  trainloss -503.23614  validloss -377.27174±0.00000  bestvalidloss -421.96710  last_update 4\n",
      "train: iter 60  trainloss -485.40344  validloss -465.53034±0.00000  bestvalidloss -465.53034  last_update 0\n",
      "train: iter 61  trainloss -540.82381  validloss -451.78770±0.00000  bestvalidloss -465.53034  last_update 1\n",
      "train: iter 62  trainloss -488.16204  validloss -456.94760±0.00000  bestvalidloss -465.53034  last_update 2\n",
      "train: iter 63  trainloss -535.54702  validloss -414.04060±0.00000  bestvalidloss -465.53034  last_update 3\n",
      "train: iter 64  trainloss -509.00529  validloss -439.12809±0.00000  bestvalidloss -465.53034  last_update 4\n",
      "train: iter 65  trainloss -532.41462  validloss -455.78934±0.00000  bestvalidloss -465.53034  last_update 5\n",
      "train: iter 66  trainloss -577.15866  validloss -443.29813±0.00000  bestvalidloss -465.53034  last_update 6\n",
      "train: iter 67  trainloss -433.83185  validloss -540.47156±0.00000  bestvalidloss -540.47156  last_update 0\n",
      "train: iter 68  trainloss -491.23876  validloss -346.49677±0.00000  bestvalidloss -540.47156  last_update 1\n",
      "train: iter 69  trainloss -560.73711  validloss -468.53980±0.00000  bestvalidloss -540.47156  last_update 2\n",
      "train: iter 70  trainloss -595.75359  validloss -532.71417±0.00000  bestvalidloss -540.47156  last_update 3\n",
      "train: iter 71  trainloss -568.02550  validloss -528.56024±0.00000  bestvalidloss -540.47156  last_update 4\n",
      "train: iter 72  trainloss -609.97203  validloss -551.56871±0.00000  bestvalidloss -551.56871  last_update 0\n",
      "train: iter 73  trainloss -566.70248  validloss -480.72522±0.00000  bestvalidloss -551.56871  last_update 1\n",
      "train: iter 74  trainloss -603.53045  validloss -562.10523±0.00000  bestvalidloss -562.10523  last_update 0\n",
      "train: iter 75  trainloss -618.07131  validloss -386.67357±0.00000  bestvalidloss -562.10523  last_update 1\n",
      "train: iter 76  trainloss -589.49737  validloss -577.12133±0.00000  bestvalidloss -577.12133  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -665.31143  validloss -518.79138±0.00000  bestvalidloss -577.12133  last_update 1\n",
      "train: iter 78  trainloss -668.87007  validloss -559.85938±0.00000  bestvalidloss -577.12133  last_update 2\n",
      "train: iter 79  trainloss -569.13606  validloss -496.16539±0.00000  bestvalidloss -577.12133  last_update 3\n",
      "train: iter 80  trainloss -548.35174  validloss -397.80622±0.00000  bestvalidloss -577.12133  last_update 4\n",
      "train: iter 81  trainloss -579.36594  validloss -506.74560±0.00000  bestvalidloss -577.12133  last_update 5\n",
      "train: iter 82  trainloss -581.23370  validloss -480.39468±0.00000  bestvalidloss -577.12133  last_update 6\n",
      "train: iter 83  trainloss -625.04902  validloss -560.36255±0.00000  bestvalidloss -577.12133  last_update 7\n",
      "train: iter 84  trainloss -581.67070  validloss -634.02512±0.00000  bestvalidloss -634.02512  last_update 0\n",
      "train: iter 85  trainloss -647.99009  validloss -507.29285±0.00000  bestvalidloss -634.02512  last_update 1\n",
      "train: iter 86  trainloss -650.03646  validloss -441.33872±0.00000  bestvalidloss -634.02512  last_update 2\n",
      "train: iter 87  trainloss -718.29705  validloss -656.49318±0.00000  bestvalidloss -656.49318  last_update 0\n",
      "train: iter 88  trainloss -723.87150  validloss -591.32993±0.00000  bestvalidloss -656.49318  last_update 1\n",
      "train: iter 89  trainloss -640.01419  validloss -556.32103±0.00000  bestvalidloss -656.49318  last_update 2\n",
      "train: iter 90  trainloss -704.18875  validloss -609.75936±0.00000  bestvalidloss -656.49318  last_update 3\n",
      "train: iter 91  trainloss -613.64183  validloss -327.65390±0.00000  bestvalidloss -656.49318  last_update 4\n",
      "train: iter 92  trainloss -704.27496  validloss -604.98090±0.00000  bestvalidloss -656.49318  last_update 5\n",
      "train: iter 93  trainloss -608.30267  validloss -623.73516±0.00000  bestvalidloss -656.49318  last_update 6\n",
      "train: iter 94  trainloss -658.99949  validloss -396.17451±0.00000  bestvalidloss -656.49318  last_update 7\n",
      "train: iter 95  trainloss -732.42589  validloss -628.74921±0.00000  bestvalidloss -656.49318  last_update 8\n",
      "train: iter 96  trainloss -726.78058  validloss -727.66550±0.00000  bestvalidloss -727.66550  last_update 0\n",
      "train: iter 97  trainloss -587.77125  validloss -479.11374±0.00000  bestvalidloss -727.66550  last_update 1\n",
      "train: iter 98  trainloss -775.67083  validloss -671.73006±0.00000  bestvalidloss -727.66550  last_update 2\n",
      "train: iter 99  trainloss -611.45099  validloss -721.94232±0.00000  bestvalidloss -727.66550  last_update 3\n",
      "train: iter 100  trainloss -592.95750  validloss -416.22911±0.00000  bestvalidloss -727.66550  last_update 4\n",
      "train: iter 101  trainloss -727.39611  validloss -548.76672±0.00000  bestvalidloss -727.66550  last_update 5\n",
      "train: iter 102  trainloss -697.63198  validloss -701.97004±0.00000  bestvalidloss -727.66550  last_update 6\n",
      "train: iter 103  trainloss -760.65017  validloss -698.20095±0.00000  bestvalidloss -727.66550  last_update 7\n",
      "train: iter 104  trainloss -638.45043  validloss -662.41137±0.00000  bestvalidloss -727.66550  last_update 8\n",
      "train: iter 105  trainloss -695.24751  validloss -501.01974±0.00000  bestvalidloss -727.66550  last_update 9\n",
      "train: iter 106  trainloss -751.84820  validloss -697.11496±0.00000  bestvalidloss -727.66550  last_update 10\n",
      "train: iter 107  trainloss -534.46471  validloss -682.00977±0.00000  bestvalidloss -727.66550  last_update 11\n",
      "train: iter 108  trainloss -743.83308  validloss -575.32472±0.00000  bestvalidloss -727.66550  last_update 12\n",
      "train: iter 109  trainloss -775.35539  validloss -714.43450±0.00000  bestvalidloss -727.66550  last_update 13\n",
      "train: iter 110  trainloss -809.83849  validloss -713.73006±0.00000  bestvalidloss -727.66550  last_update 14\n",
      "train: iter 111  trainloss -735.71154  validloss -661.34291±0.00000  bestvalidloss -727.66550  last_update 15\n",
      "train: iter 112  trainloss -657.37499  validloss -619.53100±0.00000  bestvalidloss -727.66550  last_update 16\n",
      "train: iter 113  trainloss -780.57627  validloss -720.07623±0.00000  bestvalidloss -727.66550  last_update 17\n",
      "train: iter 114  trainloss -739.16783  validloss -746.94975±0.00000  bestvalidloss -746.94975  last_update 0\n",
      "train: iter 115  trainloss -691.33236  validloss -573.33089±0.00000  bestvalidloss -746.94975  last_update 1\n",
      "train: iter 116  trainloss -709.42528  validloss -811.20557±0.00000  bestvalidloss -811.20557  last_update 0\n",
      "train: iter 117  trainloss -825.58969  validloss -668.44572±0.00000  bestvalidloss -811.20557  last_update 1\n",
      "train: iter 118  trainloss -731.25159  validloss -760.73759±0.00000  bestvalidloss -811.20557  last_update 2\n",
      "train: iter 119  trainloss -771.26780  validloss -596.40987±0.00000  bestvalidloss -811.20557  last_update 3\n",
      "train: iter 120  trainloss -865.06284  validloss -787.73953±0.00000  bestvalidloss -811.20557  last_update 4\n",
      "train: iter 121  trainloss -737.03264  validloss -727.49651±0.00000  bestvalidloss -811.20557  last_update 5\n",
      "train: iter 122  trainloss -879.20977  validloss -759.00693±0.00000  bestvalidloss -811.20557  last_update 6\n",
      "train: iter 123  trainloss -781.51286  validloss -864.53514±0.00000  bestvalidloss -864.53514  last_update 0\n",
      "train: iter 124  trainloss -810.66176  validloss -466.00448±0.00000  bestvalidloss -864.53514  last_update 1\n",
      "train: iter 125  trainloss -817.71868  validloss -486.67879±0.00000  bestvalidloss -864.53514  last_update 2\n",
      "train: iter 126  trainloss -781.80837  validloss -158.62766±0.00000  bestvalidloss -864.53514  last_update 3\n",
      "train: iter 127  trainloss -832.79593  validloss -605.25306±0.00000  bestvalidloss -864.53514  last_update 4\n",
      "train: iter 128  trainloss -785.36545  validloss -614.80142±0.00000  bestvalidloss -864.53514  last_update 5\n",
      "train: iter 129  trainloss -721.50668  validloss -350.25535±0.00000  bestvalidloss -864.53514  last_update 6\n",
      "train: iter 130  trainloss -849.92663  validloss -786.38503±0.00000  bestvalidloss -864.53514  last_update 7\n",
      "train: iter 131  trainloss -902.14060  validloss -762.75583±0.00000  bestvalidloss -864.53514  last_update 8\n",
      "train: iter 132  trainloss -817.25829  validloss -866.48035±0.00000  bestvalidloss -866.48035  last_update 0\n",
      "train: iter 133  trainloss -928.80682  validloss -776.79869±0.00000  bestvalidloss -866.48035  last_update 1\n",
      "train: iter 134  trainloss -753.44227  validloss -636.25941±0.00000  bestvalidloss -866.48035  last_update 2\n",
      "train: iter 135  trainloss -801.95348  validloss -873.36316±0.00000  bestvalidloss -873.36316  last_update 0\n",
      "train: iter 136  trainloss -801.88865  validloss -795.20810±0.00000  bestvalidloss -873.36316  last_update 1\n",
      "train: iter 137  trainloss -898.91407  validloss -798.36869±0.00000  bestvalidloss -873.36316  last_update 2\n",
      "train: iter 138  trainloss -794.75705  validloss -865.26746±0.00000  bestvalidloss -873.36316  last_update 3\n",
      "train: iter 139  trainloss -791.22748  validloss -672.60126±0.00000  bestvalidloss -873.36316  last_update 4\n",
      "train: iter 140  trainloss -892.08250  validloss -782.60115±0.00000  bestvalidloss -873.36316  last_update 5\n",
      "train: iter 141  trainloss -801.22173  validloss -937.39986±0.00000  bestvalidloss -937.39986  last_update 0\n",
      "train: iter 142  trainloss -925.82194  validloss -578.06883±0.00000  bestvalidloss -937.39986  last_update 1\n",
      "train: iter 143  trainloss -943.97078  validloss -911.75754±0.00000  bestvalidloss -937.39986  last_update 2\n",
      "train: iter 144  trainloss -912.76889  validloss -791.45273±0.00000  bestvalidloss -937.39986  last_update 3\n",
      "train: iter 145  trainloss -912.40867  validloss -817.73034±0.00000  bestvalidloss -937.39986  last_update 4\n",
      "train: iter 146  trainloss -455.07962  validloss -705.74825±0.00000  bestvalidloss -937.39986  last_update 5\n",
      "train: iter 147  trainloss -548.18678  validloss -476.29155±0.00000  bestvalidloss -937.39986  last_update 6\n",
      "train: iter 148  trainloss -817.59590  validloss -643.79096±0.00000  bestvalidloss -937.39986  last_update 7\n",
      "train: iter 149  trainloss -805.32253  validloss -603.08301±0.00000  bestvalidloss -937.39986  last_update 8\n",
      "train: iter 150  trainloss -904.38824  validloss -599.66089±0.00000  bestvalidloss -937.39986  last_update 9\n",
      "train: iter 151  trainloss -896.32609  validloss -942.93669±0.00000  bestvalidloss -942.93669  last_update 0\n",
      "train: iter 152  trainloss -918.43758  validloss -786.45995±0.00000  bestvalidloss -942.93669  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -877.18827  validloss -859.41870±0.00000  bestvalidloss -942.93669  last_update 2\n",
      "train: iter 154  trainloss -1002.36432  validloss -725.06163±0.00000  bestvalidloss -942.93669  last_update 3\n",
      "train: iter 155  trainloss -933.56057  validloss -956.26198±0.00000  bestvalidloss -956.26198  last_update 0\n",
      "train: iter 156  trainloss -905.50056  validloss -943.16220±0.00000  bestvalidloss -956.26198  last_update 1\n",
      "train: iter 157  trainloss -917.14723  validloss -838.17372±0.00000  bestvalidloss -956.26198  last_update 2\n",
      "train: iter 158  trainloss -430.42976  validloss -264.48766±0.00000  bestvalidloss -956.26198  last_update 3\n",
      "train: iter 159  trainloss -323.67264  validloss -234.00377±0.00000  bestvalidloss -956.26198  last_update 4\n",
      "train: iter 160  trainloss -545.28695  validloss -398.16158±0.00000  bestvalidloss -956.26198  last_update 5\n",
      "train: iter 161  trainloss -443.01045  validloss -634.32335±0.00000  bestvalidloss -956.26198  last_update 6\n",
      "train: iter 162  trainloss -936.46531  validloss -795.95234±0.00000  bestvalidloss -956.26198  last_update 7\n",
      "train: iter 163  trainloss -940.96669  validloss -904.27354±0.00000  bestvalidloss -956.26198  last_update 8\n",
      "train: iter 164  trainloss -927.71992  validloss -995.97908±0.00000  bestvalidloss -995.97908  last_update 0\n",
      "train: iter 165  trainloss -831.18340  validloss -638.58804±0.00000  bestvalidloss -995.97908  last_update 1\n",
      "train: iter 166  trainloss -1022.45667  validloss -918.32640±0.00000  bestvalidloss -995.97908  last_update 2\n",
      "train: iter 167  trainloss -804.21562  validloss -901.24152±0.00000  bestvalidloss -995.97908  last_update 3\n",
      "train: iter 168  trainloss -948.61088  validloss -864.22067±0.00000  bestvalidloss -995.97908  last_update 4\n",
      "train: iter 169  trainloss -954.42543  validloss -773.96665±0.00000  bestvalidloss -995.97908  last_update 5\n",
      "train: iter 170  trainloss -996.94592  validloss -1003.96850±0.00000  bestvalidloss -1003.96850  last_update 0\n",
      "train: iter 171  trainloss -986.92911  validloss -880.01267±0.00000  bestvalidloss -1003.96850  last_update 1\n",
      "train: iter 172  trainloss -1006.09235  validloss -917.12925±0.00000  bestvalidloss -1003.96850  last_update 2\n",
      "train: iter 173  trainloss -950.85743  validloss -969.18751±0.00000  bestvalidloss -1003.96850  last_update 3\n",
      "train: iter 174  trainloss -593.35329  validloss -887.83061±0.00000  bestvalidloss -1003.96850  last_update 4\n",
      "train: iter 175  trainloss -213.47108  validloss -115.73094±0.00000  bestvalidloss -1003.96850  last_update 5\n",
      "train: iter 176  trainloss -520.97225  validloss -364.06282±0.00000  bestvalidloss -1003.96850  last_update 6\n",
      "train: iter 177  trainloss -893.69364  validloss -687.24425±0.00000  bestvalidloss -1003.96850  last_update 7\n",
      "train: iter 178  trainloss -917.67113  validloss -957.97592±0.00000  bestvalidloss -1003.96850  last_update 8\n",
      "train: iter 179  trainloss -994.68800  validloss -748.99931±0.00000  bestvalidloss -1003.96850  last_update 9\n",
      "train: iter 180  trainloss -417.58224  validloss -998.39825±0.00000  bestvalidloss -1003.96850  last_update 10\n",
      "train: iter 181  trainloss -854.17139  validloss -540.10331±0.00000  bestvalidloss -1003.96850  last_update 11\n",
      "train: iter 182  trainloss -1048.95310  validloss -904.99363±0.00000  bestvalidloss -1003.96850  last_update 12\n",
      "train: iter 183  trainloss -1036.65184  validloss -1039.60481±0.00000  bestvalidloss -1039.60481  last_update 0\n",
      "train: iter 184  trainloss -1078.89361  validloss -1042.25892±0.00000  bestvalidloss -1042.25892  last_update 0\n",
      "train: iter 185  trainloss -1057.11769  validloss -909.32364±0.00000  bestvalidloss -1042.25892  last_update 1\n",
      "train: iter 186  trainloss -1021.67196  validloss -1035.66003±0.00000  bestvalidloss -1042.25892  last_update 2\n",
      "train: iter 187  trainloss -1038.41662  validloss -908.31027±0.00000  bestvalidloss -1042.25892  last_update 3\n",
      "train: iter 188  trainloss -980.71136  validloss -813.63545±0.00000  bestvalidloss -1042.25892  last_update 4\n",
      "train: iter 189  trainloss -980.14683  validloss -1024.95804±0.00000  bestvalidloss -1042.25892  last_update 5\n",
      "train: iter 190  trainloss -1104.47136  validloss -1030.53478±0.00000  bestvalidloss -1042.25892  last_update 6\n",
      "train: iter 191  trainloss -1084.91187  validloss -1005.46387±0.00000  bestvalidloss -1042.25892  last_update 7\n",
      "train: iter 192  trainloss -986.19766  validloss -971.39274±0.00000  bestvalidloss -1042.25892  last_update 8\n",
      "train: iter 193  trainloss -808.73717  validloss -850.62298±0.00000  bestvalidloss -1042.25892  last_update 9\n",
      "train: iter 194  trainloss -946.57019  validloss -708.22491±0.00000  bestvalidloss -1042.25892  last_update 10\n",
      "train: iter 195  trainloss -949.82792  validloss -809.71468±0.00000  bestvalidloss -1042.25892  last_update 11\n",
      "train: iter 196  trainloss -1008.36830  validloss -968.70701±0.00000  bestvalidloss -1042.25892  last_update 12\n",
      "train: iter 197  trainloss -1096.77311  validloss -945.58879±0.00000  bestvalidloss -1042.25892  last_update 13\n",
      "train: iter 198  trainloss -1011.75511  validloss -1081.76156±0.00000  bestvalidloss -1081.76156  last_update 0\n",
      "train: iter 199  trainloss -1017.25813  validloss -864.60558±0.00000  bestvalidloss -1081.76156  last_update 1\n",
      "train: iter 200  trainloss -1047.49522  validloss -894.55206±0.00000  bestvalidloss -1081.76156  last_update 2\n",
      "train: iter 201  trainloss -1059.96851  validloss -1037.77889±0.00000  bestvalidloss -1081.76156  last_update 3\n",
      "train: iter 202  trainloss -969.44117  validloss -1010.55391±0.00000  bestvalidloss -1081.76156  last_update 4\n",
      "train: iter 203  trainloss -1047.47002  validloss -942.30345±0.00000  bestvalidloss -1081.76156  last_update 5\n",
      "train: iter 204  trainloss -967.62667  validloss -1015.91086±0.00000  bestvalidloss -1081.76156  last_update 6\n",
      "train: iter 205  trainloss -974.51492  validloss -1009.79175±0.00000  bestvalidloss -1081.76156  last_update 7\n",
      "train: iter 206  trainloss -1016.06424  validloss -975.11433±0.00000  bestvalidloss -1081.76156  last_update 8\n",
      "train: iter 207  trainloss -1053.77295  validloss -950.04259±0.00000  bestvalidloss -1081.76156  last_update 9\n",
      "train: iter 208  trainloss -1057.28895  validloss -1024.70459±0.00000  bestvalidloss -1081.76156  last_update 10\n",
      "train: iter 209  trainloss -788.77436  validloss -1067.50525±0.00000  bestvalidloss -1081.76156  last_update 11\n",
      "train: iter 210  trainloss -768.42574  validloss -737.67230±0.00000  bestvalidloss -1081.76156  last_update 12\n",
      "train: iter 211  trainloss -614.30924  validloss -992.85170±0.00000  bestvalidloss -1081.76156  last_update 13\n",
      "train: iter 212  trainloss -664.50134  validloss -881.20656±0.00000  bestvalidloss -1081.76156  last_update 14\n",
      "train: iter 213  trainloss -880.52596  validloss -839.46358±0.00000  bestvalidloss -1081.76156  last_update 15\n",
      "train: iter 214  trainloss -978.33803  validloss -971.03112±0.00000  bestvalidloss -1081.76156  last_update 16\n",
      "train: iter 215  trainloss -1016.48001  validloss -799.29189±0.00000  bestvalidloss -1081.76156  last_update 17\n",
      "train: iter 216  trainloss -1075.57355  validloss -973.96144±0.00000  bestvalidloss -1081.76156  last_update 18\n",
      "train: iter 217  trainloss -1057.21956  validloss -987.24245±0.00000  bestvalidloss -1081.76156  last_update 19\n",
      "train: iter 218  trainloss -1069.26207  validloss -1057.16501±0.00000  bestvalidloss -1081.76156  last_update 20\n",
      "train: iter 219  trainloss -1117.18632  validloss -1090.32710±0.00000  bestvalidloss -1090.32710  last_update 0\n",
      "train: iter 220  trainloss -1117.00231  validloss -797.31219±0.00000  bestvalidloss -1090.32710  last_update 1\n",
      "train: iter 221  trainloss -960.89203  validloss -1113.74291±0.00000  bestvalidloss -1113.74291  last_update 0\n",
      "train: iter 222  trainloss -874.15569  validloss -892.23965±0.00000  bestvalidloss -1113.74291  last_update 1\n",
      "train: iter 223  trainloss -1104.82972  validloss -1035.67861±0.00000  bestvalidloss -1113.74291  last_update 2\n",
      "train: iter 224  trainloss -1004.73390  validloss -771.05870±0.00000  bestvalidloss -1113.74291  last_update 3\n",
      "train: iter 225  trainloss -1018.39304  validloss -929.51952±0.00000  bestvalidloss -1113.74291  last_update 4\n",
      "train: iter 226  trainloss -1111.07387  validloss -1063.35122±0.00000  bestvalidloss -1113.74291  last_update 5\n",
      "train: iter 227  trainloss -985.31310  validloss -1063.75277±0.00000  bestvalidloss -1113.74291  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1134.03569  validloss -1050.90223±0.00000  bestvalidloss -1113.74291  last_update 7\n",
      "train: iter 229  trainloss -1034.00858  validloss -1092.70904±0.00000  bestvalidloss -1113.74291  last_update 8\n",
      "train: iter 230  trainloss -1054.31550  validloss -860.96334±0.00000  bestvalidloss -1113.74291  last_update 9\n",
      "train: iter 231  trainloss -1078.40790  validloss -1110.39591±0.00000  bestvalidloss -1113.74291  last_update 10\n",
      "train: iter 232  trainloss -1157.31203  validloss -1067.70600±0.00000  bestvalidloss -1113.74291  last_update 11\n",
      "train: iter 233  trainloss -861.94938  validloss -1049.64593±0.00000  bestvalidloss -1113.74291  last_update 12\n",
      "train: iter 234  trainloss -960.95518  validloss -840.36923±0.00000  bestvalidloss -1113.74291  last_update 13\n",
      "train: iter 235  trainloss -1129.16029  validloss -999.73260±0.00000  bestvalidloss -1113.74291  last_update 14\n",
      "train: iter 236  trainloss -1078.94675  validloss -1107.94112±0.00000  bestvalidloss -1113.74291  last_update 15\n",
      "train: iter 237  trainloss -933.87210  validloss -1052.34066±0.00000  bestvalidloss -1113.74291  last_update 16\n",
      "train: iter 238  trainloss -900.52868  validloss -422.11820±0.00000  bestvalidloss -1113.74291  last_update 17\n",
      "train: iter 239  trainloss -1014.38049  validloss -969.23424±0.00000  bestvalidloss -1113.74291  last_update 18\n",
      "train: iter 240  trainloss -1094.49402  validloss -1022.07698±0.00000  bestvalidloss -1113.74291  last_update 19\n",
      "train: iter 241  trainloss -835.80202  validloss -1118.18873±0.00000  bestvalidloss -1118.18873  last_update 0\n",
      "train: iter 242  trainloss -920.21380  validloss -930.36804±0.00000  bestvalidloss -1118.18873  last_update 1\n",
      "train: iter 243  trainloss -1062.75391  validloss -635.19120±0.00000  bestvalidloss -1118.18873  last_update 2\n",
      "train: iter 244  trainloss -1177.91735  validloss -1072.81470±0.00000  bestvalidloss -1118.18873  last_update 3\n",
      "train: iter 245  trainloss -1002.99153  validloss -1143.34536±0.00000  bestvalidloss -1143.34536  last_update 0\n",
      "train: iter 246  trainloss -950.32668  validloss -673.75985±0.00000  bestvalidloss -1143.34536  last_update 1\n",
      "train: iter 247  trainloss -1072.93213  validloss -1068.04756±0.00000  bestvalidloss -1143.34536  last_update 2\n",
      "train: iter 248  trainloss -962.58165  validloss -844.62282±0.00000  bestvalidloss -1143.34536  last_update 3\n",
      "train: iter 249  trainloss -1078.77454  validloss -971.26793±0.00000  bestvalidloss -1143.34536  last_update 4\n",
      "train: iter 250  trainloss -1018.30407  validloss -873.82334±0.00000  bestvalidloss -1143.34536  last_update 5\n",
      "train: iter 251  trainloss -1072.71548  validloss -955.01815±0.00000  bestvalidloss -1143.34536  last_update 6\n",
      "train: iter 252  trainloss -1063.19041  validloss -1019.34147±0.00000  bestvalidloss -1143.34536  last_update 7\n",
      "train: iter 253  trainloss -336.19296  validloss -1078.67382±0.00000  bestvalidloss -1143.34536  last_update 8\n",
      "train: iter 254  trainloss -466.37157  validloss -146.27031±0.00000  bestvalidloss -1143.34536  last_update 9\n",
      "train: iter 255  trainloss -822.95960  validloss -688.52675±0.00000  bestvalidloss -1143.34536  last_update 10\n",
      "train: iter 256  trainloss -926.99164  validloss -954.14275±0.00000  bestvalidloss -1143.34536  last_update 11\n",
      "train: iter 257  trainloss -1134.62965  validloss -1068.51711±0.00000  bestvalidloss -1143.34536  last_update 12\n",
      "train: iter 258  trainloss -1017.16516  validloss -1114.12070±0.00000  bestvalidloss -1143.34536  last_update 13\n",
      "train: iter 259  trainloss -1092.74886  validloss -989.62637±0.00000  bestvalidloss -1143.34536  last_update 14\n",
      "train: iter 260  trainloss -1155.66696  validloss -1073.14606±0.00000  bestvalidloss -1143.34536  last_update 15\n",
      "train: iter 261  trainloss -1120.97722  validloss -1063.90705±0.00000  bestvalidloss -1143.34536  last_update 16\n",
      "train: iter 262  trainloss -1011.66971  validloss -1106.04472±0.00000  bestvalidloss -1143.34536  last_update 17\n",
      "train: iter 263  trainloss -713.19708  validloss -806.06560±0.00000  bestvalidloss -1143.34536  last_update 18\n",
      "train: iter 264  trainloss -1007.56330  validloss -735.63542±0.00000  bestvalidloss -1143.34536  last_update 19\n",
      "train: iter 265  trainloss -1158.29803  validloss -1067.11601±0.00000  bestvalidloss -1143.34536  last_update 20\n",
      "train: iter 266  trainloss -1023.10078  validloss -1097.60330±0.00000  bestvalidloss -1143.34536  last_update 21\n",
      "train: iter 267  trainloss -1165.95087  validloss -1012.34827±0.00000  bestvalidloss -1143.34536  last_update 22\n",
      "train: iter 268  trainloss -1170.97527  validloss -1125.04528±0.00000  bestvalidloss -1143.34536  last_update 23\n",
      "train: iter 269  trainloss -1104.38180  validloss -1162.99157±0.00000  bestvalidloss -1162.99157  last_update 0\n",
      "train: iter 270  trainloss -1182.94465  validloss -1114.41219±0.00000  bestvalidloss -1162.99157  last_update 1\n",
      "train: iter 271  trainloss -981.27139  validloss -895.25082±0.00000  bestvalidloss -1162.99157  last_update 2\n",
      "train: iter 272  trainloss -1168.89029  validloss -946.70683±0.00000  bestvalidloss -1162.99157  last_update 3\n",
      "train: iter 273  trainloss -1092.05067  validloss -1142.34288±0.00000  bestvalidloss -1162.99157  last_update 4\n",
      "train: iter 274  trainloss -956.60863  validloss -611.60425±0.00000  bestvalidloss -1162.99157  last_update 5\n",
      "train: iter 275  trainloss -1128.91432  validloss -1093.54227±0.00000  bestvalidloss -1162.99157  last_update 6\n",
      "train: iter 276  trainloss -930.56026  validloss -960.42028±0.00000  bestvalidloss -1162.99157  last_update 7\n",
      "train: iter 277  trainloss -1099.85897  validloss -1114.58470±0.00000  bestvalidloss -1162.99157  last_update 8\n",
      "train: iter 278  trainloss -1036.46603  validloss -1123.51089±0.00000  bestvalidloss -1162.99157  last_update 9\n",
      "train: iter 279  trainloss -1092.64144  validloss -1042.35707±0.00000  bestvalidloss -1162.99157  last_update 10\n",
      "train: iter 280  trainloss -946.66194  validloss -857.14063±0.00000  bestvalidloss -1162.99157  last_update 11\n",
      "train: iter 281  trainloss -1186.73756  validloss -988.23130±0.00000  bestvalidloss -1162.99157  last_update 12\n",
      "train: iter 282  trainloss -1074.04343  validloss -1010.73358±0.00000  bestvalidloss -1162.99157  last_update 13\n",
      "train: iter 283  trainloss -1095.71130  validloss -1084.55940±0.00000  bestvalidloss -1162.99157  last_update 14\n",
      "train: iter 284  trainloss -1209.36074  validloss -1107.40230±0.00000  bestvalidloss -1162.99157  last_update 15\n",
      "train: iter 285  trainloss -855.92691  validloss -1103.21221±0.00000  bestvalidloss -1162.99157  last_update 16\n",
      "train: iter 286  trainloss -986.66102  validloss -988.43214±0.00000  bestvalidloss -1162.99157  last_update 17\n",
      "train: iter 287  trainloss -1054.07474  validloss -757.42073±0.00000  bestvalidloss -1162.99157  last_update 18\n",
      "train: iter 288  trainloss -1195.48287  validloss -1138.81712±0.00000  bestvalidloss -1162.99157  last_update 19\n",
      "train: iter 289  trainloss -1120.94579  validloss -1150.58501±0.00000  bestvalidloss -1162.99157  last_update 20\n",
      "train: iter 290  trainloss -1133.94052  validloss -1056.75822±0.00000  bestvalidloss -1162.99157  last_update 21\n",
      "train: iter 291  trainloss -1140.83421  validloss -1090.22916±0.00000  bestvalidloss -1162.99157  last_update 22\n",
      "train: iter 292  trainloss -1234.18423  validloss -1152.89873±0.00000  bestvalidloss -1162.99157  last_update 23\n",
      "train: iter 293  trainloss -990.91994  validloss -779.58913±0.00000  bestvalidloss -1162.99157  last_update 24\n",
      "train: iter 294  trainloss -1108.99697  validloss -1020.62793±0.00000  bestvalidloss -1162.99157  last_update 25\n",
      "train: iter 295  trainloss -1164.53834  validloss -975.86293±0.00000  bestvalidloss -1162.99157  last_update 26\n",
      "train: iter 296  trainloss -1165.93665  validloss -1141.68604±0.00000  bestvalidloss -1162.99157  last_update 27\n",
      "train: iter 297  trainloss -1167.10360  validloss -1118.93374±0.00000  bestvalidloss -1162.99157  last_update 28\n",
      "train: iter 298  trainloss -1090.71603  validloss -1198.41346±0.00000  bestvalidloss -1198.41346  last_update 0\n",
      "train: iter 299  trainloss -1132.99301  validloss -1090.45941±0.00000  bestvalidloss -1198.41346  last_update 1\n",
      "train: iter 300  trainloss -1148.83965  validloss -1162.50973±0.00000  bestvalidloss -1198.41346  last_update 2\n",
      "train: iter 301  trainloss -1164.40513  validloss -1085.32731±0.00000  bestvalidloss -1198.41346  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 302  trainloss -1142.54653  validloss -939.55977±0.00000  bestvalidloss -1198.41346  last_update 4\n",
      "train: iter 303  trainloss -1088.94950  validloss -1089.23735±0.00000  bestvalidloss -1198.41346  last_update 5\n",
      "train: iter 304  trainloss -1166.01507  validloss -1024.50706±0.00000  bestvalidloss -1198.41346  last_update 6\n",
      "train: iter 305  trainloss -1169.41665  validloss -708.24817±0.00000  bestvalidloss -1198.41346  last_update 7\n",
      "train: iter 306  trainloss -1104.73692  validloss -1173.10681±0.00000  bestvalidloss -1198.41346  last_update 8\n",
      "train: iter 307  trainloss -1087.36490  validloss -1013.85107±0.00000  bestvalidloss -1198.41346  last_update 9\n",
      "train: iter 308  trainloss -1013.04187  validloss -1158.98261±0.00000  bestvalidloss -1198.41346  last_update 10\n",
      "train: iter 309  trainloss -1004.27816  validloss -705.82992±0.00000  bestvalidloss -1198.41346  last_update 11\n",
      "train: iter 310  trainloss -1181.05608  validloss -1077.48868±0.00000  bestvalidloss -1198.41346  last_update 12\n",
      "train: iter 311  trainloss -1075.18676  validloss -841.65745±0.00000  bestvalidloss -1198.41346  last_update 13\n",
      "train: iter 312  trainloss -1200.14303  validloss -1146.38509±0.00000  bestvalidloss -1198.41346  last_update 14\n",
      "train: iter 313  trainloss -974.79254  validloss -1011.09957±0.00000  bestvalidloss -1198.41346  last_update 15\n",
      "train: iter 314  trainloss -1209.16483  validloss -1109.08182±0.00000  bestvalidloss -1198.41346  last_update 16\n",
      "train: iter 315  trainloss -863.61151  validloss -945.04753±0.00000  bestvalidloss -1198.41346  last_update 17\n",
      "train: iter 316  trainloss -1040.32237  validloss -1026.38515±0.00000  bestvalidloss -1198.41346  last_update 18\n",
      "train: iter 317  trainloss -1150.03432  validloss -1068.72532±0.00000  bestvalidloss -1198.41346  last_update 19\n",
      "train: iter 318  trainloss -1252.73547  validloss -987.68089±0.00000  bestvalidloss -1198.41346  last_update 20\n",
      "train: iter 319  trainloss -1137.02702  validloss -1198.10059±0.00000  bestvalidloss -1198.41346  last_update 21\n",
      "train: iter 320  trainloss -1221.38477  validloss -862.97219±0.00000  bestvalidloss -1198.41346  last_update 22\n",
      "train: iter 321  trainloss -1166.78904  validloss -1134.16422±0.00000  bestvalidloss -1198.41346  last_update 23\n",
      "train: iter 322  trainloss -1104.00343  validloss -994.92080±0.00000  bestvalidloss -1198.41346  last_update 24\n",
      "train: iter 323  trainloss -1228.86641  validloss -1126.41745±0.00000  bestvalidloss -1198.41346  last_update 25\n",
      "train: iter 324  trainloss -1185.69936  validloss -1143.24754±0.00000  bestvalidloss -1198.41346  last_update 26\n",
      "train: iter 325  trainloss -1285.84292  validloss -1219.08638±0.00000  bestvalidloss -1219.08638  last_update 0\n",
      "train: iter 326  trainloss -1151.31471  validloss -1195.66739±0.00000  bestvalidloss -1219.08638  last_update 1\n",
      "train: iter 327  trainloss -1183.89586  validloss -1045.51107±0.00000  bestvalidloss -1219.08638  last_update 2\n",
      "train: iter 328  trainloss -1250.13001  validloss -1221.07676±0.00000  bestvalidloss -1221.07676  last_update 0\n",
      "train: iter 329  trainloss -1094.71682  validloss -1149.45791±0.00000  bestvalidloss -1221.07676  last_update 1\n",
      "train: iter 330  trainloss -1215.76675  validloss -916.60468±0.00000  bestvalidloss -1221.07676  last_update 2\n",
      "train: iter 331  trainloss -1063.68737  validloss -1230.37252±0.00000  bestvalidloss -1230.37252  last_update 0\n",
      "train: iter 332  trainloss -1167.46247  validloss -887.53806±0.00000  bestvalidloss -1230.37252  last_update 1\n",
      "train: iter 333  trainloss -947.82294  validloss -877.08463±0.00000  bestvalidloss -1230.37252  last_update 2\n",
      "train: iter 334  trainloss -1071.78003  validloss -894.43820±0.00000  bestvalidloss -1230.37252  last_update 3\n",
      "train: iter 335  trainloss -1217.42884  validloss -1143.88065±0.00000  bestvalidloss -1230.37252  last_update 4\n",
      "train: iter 336  trainloss -1159.80168  validloss -938.23014±0.00000  bestvalidloss -1230.37252  last_update 5\n",
      "train: iter 337  trainloss -1202.68277  validloss -1189.27198±0.00000  bestvalidloss -1230.37252  last_update 6\n",
      "train: iter 338  trainloss -1292.47216  validloss -1160.86489±0.00000  bestvalidloss -1230.37252  last_update 7\n",
      "train: iter 339  trainloss -1159.74618  validloss -1260.97098±0.00000  bestvalidloss -1260.97098  last_update 0\n",
      "train: iter 340  trainloss -1199.18370  validloss -1029.35361±0.00000  bestvalidloss -1260.97098  last_update 1\n",
      "train: iter 341  trainloss -1178.22313  validloss -1203.52458±0.00000  bestvalidloss -1260.97098  last_update 2\n",
      "train: iter 342  trainloss -1117.76120  validloss -1027.77634±0.00000  bestvalidloss -1260.97098  last_update 3\n",
      "train: iter 343  trainloss -1201.45001  validloss -855.88802±0.00000  bestvalidloss -1260.97098  last_update 4\n",
      "train: iter 344  trainloss -886.54863  validloss -1114.86336±0.00000  bestvalidloss -1260.97098  last_update 5\n",
      "train: iter 345  trainloss -1049.93528  validloss -1049.67807±0.00000  bestvalidloss -1260.97098  last_update 6\n",
      "train: iter 346  trainloss -1210.81378  validloss -950.85352±0.00000  bestvalidloss -1260.97098  last_update 7\n",
      "train: iter 347  trainloss -1269.75700  validloss -1244.41312±0.00000  bestvalidloss -1260.97098  last_update 8\n",
      "train: iter 348  trainloss -1063.43055  validloss -1149.53337±0.00000  bestvalidloss -1260.97098  last_update 9\n",
      "train: iter 349  trainloss -1232.31979  validloss -1170.47941±0.00000  bestvalidloss -1260.97098  last_update 10\n",
      "train: iter 350  trainloss -1227.13706  validloss -953.48913±0.00000  bestvalidloss -1260.97098  last_update 11\n",
      "train: iter 351  trainloss -1128.33097  validloss -1202.32586±0.00000  bestvalidloss -1260.97098  last_update 12\n",
      "train: iter 352  trainloss -1266.40235  validloss -1199.45919±0.00000  bestvalidloss -1260.97098  last_update 13\n",
      "train: iter 353  trainloss -1249.65200  validloss -1141.32430±0.00000  bestvalidloss -1260.97098  last_update 14\n",
      "train: iter 354  trainloss -1106.55681  validloss -382.17414±0.00000  bestvalidloss -1260.97098  last_update 15\n",
      "train: iter 355  trainloss -1160.98788  validloss -1192.59386±0.00000  bestvalidloss -1260.97098  last_update 16\n",
      "train: iter 356  trainloss -1255.80833  validloss -961.79855±0.00000  bestvalidloss -1260.97098  last_update 17\n",
      "train: iter 357  trainloss -1237.33650  validloss -1234.15963±0.00000  bestvalidloss -1260.97098  last_update 18\n",
      "train: iter 358  trainloss -1216.89084  validloss -1177.68660±0.00000  bestvalidloss -1260.97098  last_update 19\n",
      "train: iter 359  trainloss -1350.04052  validloss -1259.94972±0.00000  bestvalidloss -1260.97098  last_update 20\n",
      "train: iter 360  trainloss -1301.22290  validloss -1269.78625±0.00000  bestvalidloss -1269.78625  last_update 0\n",
      "train: iter 361  trainloss -1327.51732  validloss -1240.55999±0.00000  bestvalidloss -1269.78625  last_update 1\n",
      "train: iter 362  trainloss -1155.04965  validloss -1302.56580±0.00000  bestvalidloss -1302.56580  last_update 0\n",
      "train: iter 363  trainloss -1313.67870  validloss -1073.40387±0.00000  bestvalidloss -1302.56580  last_update 1\n",
      "train: iter 364  trainloss -1294.49015  validloss -1168.04173±0.00000  bestvalidloss -1302.56580  last_update 2\n",
      "train: iter 365  trainloss -1186.07070  validloss -1236.22360±0.00000  bestvalidloss -1302.56580  last_update 3\n",
      "train: iter 366  trainloss -917.80367  validloss -1024.65271±0.00000  bestvalidloss -1302.56580  last_update 4\n",
      "train: iter 367  trainloss -1212.56776  validloss -1040.24298±0.00000  bestvalidloss -1302.56580  last_update 5\n",
      "train: iter 368  trainloss -1266.87535  validloss -1131.22923±0.00000  bestvalidloss -1302.56580  last_update 6\n",
      "train: iter 369  trainloss -688.54166  validloss -1208.24810±0.00000  bestvalidloss -1302.56580  last_update 7\n",
      "train: iter 370  trainloss -1065.86302  validloss -929.66573±0.00000  bestvalidloss -1302.56580  last_update 8\n",
      "train: iter 371  trainloss -1143.67974  validloss -554.78923±0.00000  bestvalidloss -1302.56580  last_update 9\n",
      "train: iter 372  trainloss -1347.47966  validloss -1194.77747±0.00000  bestvalidloss -1302.56580  last_update 10\n",
      "train: iter 373  trainloss -1211.74173  validloss -1274.90370±0.00000  bestvalidloss -1302.56580  last_update 11\n",
      "train: iter 374  trainloss -1203.00970  validloss -1079.08837±0.00000  bestvalidloss -1302.56580  last_update 12\n",
      "train: iter 375  trainloss -1334.88593  validloss -1213.47149±0.00000  bestvalidloss -1302.56580  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 376  trainloss -1408.68877  validloss -1283.18788±0.00000  bestvalidloss -1302.56580  last_update 14\n",
      "train: iter 377  trainloss -1211.11232  validloss -1270.05412±0.00000  bestvalidloss -1302.56580  last_update 15\n",
      "train: iter 378  trainloss -1308.10352  validloss -1190.97033±0.00000  bestvalidloss -1302.56580  last_update 16\n",
      "train: iter 379  trainloss -1136.82443  validloss -986.04239±0.00000  bestvalidloss -1302.56580  last_update 17\n",
      "train: iter 380  trainloss -1332.05985  validloss -1162.93960±0.00000  bestvalidloss -1302.56580  last_update 18\n",
      "train: iter 381  trainloss -1333.98477  validloss -1058.34519±0.00000  bestvalidloss -1302.56580  last_update 19\n",
      "train: iter 382  trainloss -1337.38777  validloss -1255.60278±0.00000  bestvalidloss -1302.56580  last_update 20\n",
      "train: iter 383  trainloss -1341.64946  validloss -1299.95299±0.00000  bestvalidloss -1302.56580  last_update 21\n",
      "train: iter 384  trainloss -1373.64599  validloss -1147.73214±0.00000  bestvalidloss -1302.56580  last_update 22\n",
      "train: iter 385  trainloss -1341.96752  validloss -1264.25894±0.00000  bestvalidloss -1302.56580  last_update 23\n",
      "train: iter 386  trainloss -1307.43112  validloss -1233.80524±0.00000  bestvalidloss -1302.56580  last_update 24\n",
      "train: iter 387  trainloss -1265.48225  validloss -1155.16771±0.00000  bestvalidloss -1302.56580  last_update 25\n",
      "train: iter 388  trainloss -1335.83790  validloss -1255.91211±0.00000  bestvalidloss -1302.56580  last_update 26\n",
      "train: iter 389  trainloss -1302.17182  validloss -1273.21177±0.00000  bestvalidloss -1302.56580  last_update 27\n",
      "train: iter 390  trainloss -1301.54955  validloss -1206.50319±0.00000  bestvalidloss -1302.56580  last_update 28\n",
      "train: iter 391  trainloss -1304.19127  validloss -1284.92010±0.00000  bestvalidloss -1302.56580  last_update 29\n",
      "train: iter 392  trainloss -1320.34840  validloss -1321.38589±0.00000  bestvalidloss -1321.38589  last_update 0\n",
      "train: iter 393  trainloss -1285.85681  validloss -1191.73550±0.00000  bestvalidloss -1321.38589  last_update 1\n",
      "train: iter 394  trainloss -1360.63943  validloss -1258.44028±0.00000  bestvalidloss -1321.38589  last_update 2\n",
      "train: iter 395  trainloss -1174.69014  validloss -1275.84808±0.00000  bestvalidloss -1321.38589  last_update 3\n",
      "train: iter 396  trainloss -1245.97339  validloss -1192.39396±0.00000  bestvalidloss -1321.38589  last_update 4\n",
      "train: iter 397  trainloss -1303.32436  validloss -1235.50461±0.00000  bestvalidloss -1321.38589  last_update 5\n",
      "train: iter 398  trainloss -1262.40703  validloss -1178.67670±0.00000  bestvalidloss -1321.38589  last_update 6\n",
      "train: iter 399  trainloss -1073.87314  validloss -808.48848±0.00000  bestvalidloss -1321.38589  last_update 7\n",
      "train: iter 400  trainloss -1299.41480  validloss -845.25071±0.00000  bestvalidloss -1321.38589  last_update 8\n",
      "train: iter 401  trainloss -1207.85396  validloss -1243.62775±0.00000  bestvalidloss -1321.38589  last_update 9\n",
      "train: iter 402  trainloss -1248.99508  validloss -963.66869±0.00000  bestvalidloss -1321.38589  last_update 10\n",
      "train: iter 403  trainloss -1353.33331  validloss -1239.16586±0.00000  bestvalidloss -1321.38589  last_update 11\n",
      "train: iter 404  trainloss -1373.08515  validloss -1284.83218±0.00000  bestvalidloss -1321.38589  last_update 12\n",
      "train: iter 405  trainloss -1311.76058  validloss -1257.28104±0.00000  bestvalidloss -1321.38589  last_update 13\n",
      "train: iter 406  trainloss -1301.33042  validloss -847.80860±0.00000  bestvalidloss -1321.38589  last_update 14\n",
      "train: iter 407  trainloss -1409.60032  validloss -1128.83066±0.00000  bestvalidloss -1321.38589  last_update 15\n",
      "train: iter 408  trainloss -1258.74086  validloss -1293.97822±0.00000  bestvalidloss -1321.38589  last_update 16\n",
      "train: iter 409  trainloss -1224.90506  validloss -973.55373±0.00000  bestvalidloss -1321.38589  last_update 17\n",
      "train: iter 410  trainloss -1323.34920  validloss -1082.07977±0.00000  bestvalidloss -1321.38589  last_update 18\n",
      "train: iter 411  trainloss -1394.38919  validloss -723.98652±0.00000  bestvalidloss -1321.38589  last_update 19\n",
      "train: iter 412  trainloss -1246.06409  validloss -1266.26849±0.00000  bestvalidloss -1321.38589  last_update 20\n",
      "train: iter 413  trainloss -1394.72980  validloss -1252.21139±0.00000  bestvalidloss -1321.38589  last_update 21\n",
      "train: iter 414  trainloss -1449.93433  validloss -1327.87125±0.00000  bestvalidloss -1327.87125  last_update 0\n",
      "train: iter 415  trainloss -882.36582  validloss -1202.87456±0.00000  bestvalidloss -1327.87125  last_update 1\n",
      "train: iter 416  trainloss -1247.23814  validloss -799.81028±0.00000  bestvalidloss -1327.87125  last_update 2\n",
      "train: iter 417  trainloss -1339.77151  validloss -1281.45125±0.00000  bestvalidloss -1327.87125  last_update 3\n",
      "train: iter 418  trainloss -1431.77646  validloss -1328.44191±0.00000  bestvalidloss -1328.44191  last_update 0\n",
      "train: iter 419  trainloss -1374.74790  validloss -1191.39223±0.00000  bestvalidloss -1328.44191  last_update 1\n",
      "train: iter 420  trainloss -1416.67442  validloss -1340.05087±0.00000  bestvalidloss -1340.05087  last_update 0\n",
      "train: iter 421  trainloss -1169.43472  validloss -1206.96623±0.00000  bestvalidloss -1340.05087  last_update 1\n",
      "train: iter 422  trainloss -1409.15498  validloss -1275.08894±0.00000  bestvalidloss -1340.05087  last_update 2\n",
      "train: iter 423  trainloss -1392.09719  validloss -1357.47620±0.00000  bestvalidloss -1357.47620  last_update 0\n",
      "train: iter 424  trainloss -1173.39482  validloss -1328.50020±0.00000  bestvalidloss -1357.47620  last_update 1\n",
      "train: iter 425  trainloss -1355.60854  validloss -1196.57760±0.00000  bestvalidloss -1357.47620  last_update 2\n",
      "train: iter 426  trainloss -1408.61536  validloss -1321.96017±0.00000  bestvalidloss -1357.47620  last_update 3\n",
      "train: iter 427  trainloss -1117.32215  validloss -1124.38465±0.00000  bestvalidloss -1357.47620  last_update 4\n",
      "train: iter 428  trainloss -1228.61327  validloss -341.75310±0.00000  bestvalidloss -1357.47620  last_update 5\n",
      "train: iter 429  trainloss -1399.78121  validloss -1272.41871±0.00000  bestvalidloss -1357.47620  last_update 6\n",
      "train: iter 430  trainloss -1284.43004  validloss -1213.17935±0.00000  bestvalidloss -1357.47620  last_update 7\n",
      "train: iter 431  trainloss -1348.93186  validloss -1212.55886±0.00000  bestvalidloss -1357.47620  last_update 8\n",
      "train: iter 432  trainloss -1422.86752  validloss -1068.96312±0.00000  bestvalidloss -1357.47620  last_update 9\n",
      "train: iter 433  trainloss -1467.19703  validloss -1326.62806±0.00000  bestvalidloss -1357.47620  last_update 10\n",
      "train: iter 434  trainloss -1221.05997  validloss -1129.95390±0.00000  bestvalidloss -1357.47620  last_update 11\n",
      "train: iter 435  trainloss -1350.72520  validloss -1278.24619±0.00000  bestvalidloss -1357.47620  last_update 12\n",
      "train: iter 436  trainloss -1371.71434  validloss -1260.75382±0.00000  bestvalidloss -1357.47620  last_update 13\n",
      "train: iter 437  trainloss -1362.36750  validloss -1300.61441±0.00000  bestvalidloss -1357.47620  last_update 14\n",
      "train: iter 438  trainloss -1277.40514  validloss -1085.42815±0.00000  bestvalidloss -1357.47620  last_update 15\n",
      "train: iter 439  trainloss -1440.24312  validloss -1272.00440±0.00000  bestvalidloss -1357.47620  last_update 16\n",
      "train: iter 440  trainloss -1453.40729  validloss -1357.19566±0.00000  bestvalidloss -1357.47620  last_update 17\n",
      "train: iter 441  trainloss -1346.55214  validloss -1379.09911±0.00000  bestvalidloss -1379.09911  last_update 0\n",
      "train: iter 442  trainloss -845.28782  validloss -1291.76159±0.00000  bestvalidloss -1379.09911  last_update 1\n",
      "train: iter 443  trainloss -1179.38115  validloss -1236.96691±0.00000  bestvalidloss -1379.09911  last_update 2\n",
      "train: iter 444  trainloss -1391.90829  validloss -1212.96099±0.00000  bestvalidloss -1379.09911  last_update 3\n",
      "train: iter 445  trainloss -909.80753  validloss -1270.91661±0.00000  bestvalidloss -1379.09911  last_update 4\n",
      "train: iter 446  trainloss -1296.07479  validloss -1089.14567±0.00000  bestvalidloss -1379.09911  last_update 5\n",
      "train: iter 447  trainloss -1225.98932  validloss -1086.36680±0.00000  bestvalidloss -1379.09911  last_update 6\n",
      "train: iter 448  trainloss -1383.53348  validloss -1239.27793±0.00000  bestvalidloss -1379.09911  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 449  trainloss -1462.19712  validloss -1312.93632±0.00000  bestvalidloss -1379.09911  last_update 8\n",
      "train: iter 450  trainloss -1414.81809  validloss -1328.54948±0.00000  bestvalidloss -1379.09911  last_update 9\n",
      "train: iter 451  trainloss -1368.15752  validloss -1364.62549±0.00000  bestvalidloss -1379.09911  last_update 10\n",
      "train: iter 452  trainloss -1176.57112  validloss -1263.97022±0.00000  bestvalidloss -1379.09911  last_update 11\n",
      "train: iter 453  trainloss -1325.63845  validloss -1277.15471±0.00000  bestvalidloss -1379.09911  last_update 12\n",
      "train: iter 454  trainloss -1380.34443  validloss -1210.66479±0.00000  bestvalidloss -1379.09911  last_update 13\n",
      "train: iter 455  trainloss -1475.66150  validloss -1338.74859±0.00000  bestvalidloss -1379.09911  last_update 14\n",
      "train: iter 456  trainloss -1348.48129  validloss -1385.88194±0.00000  bestvalidloss -1385.88194  last_update 0\n",
      "train: iter 457  trainloss -1257.57549  validloss -1318.16056±0.00000  bestvalidloss -1385.88194  last_update 1\n",
      "train: iter 458  trainloss -1441.15427  validloss -1319.76049±0.00000  bestvalidloss -1385.88194  last_update 2\n",
      "train: iter 459  trainloss -1416.75110  validloss -1386.95403±0.00000  bestvalidloss -1386.95403  last_update 0\n",
      "train: iter 460  trainloss -1411.14311  validloss -1111.76342±0.00000  bestvalidloss -1386.95403  last_update 1\n",
      "train: iter 461  trainloss -1181.36661  validloss -1309.73660±0.00000  bestvalidloss -1386.95403  last_update 2\n",
      "train: iter 462  trainloss -1444.41455  validloss -1091.80398±0.00000  bestvalidloss -1386.95403  last_update 3\n",
      "train: iter 463  trainloss -1253.36522  validloss -1408.83827±0.00000  bestvalidloss -1408.83827  last_update 0\n",
      "train: iter 464  trainloss -1440.97556  validloss -1339.18367±0.00000  bestvalidloss -1408.83827  last_update 1\n",
      "train: iter 465  trainloss -1250.94552  validloss -1222.46252±0.00000  bestvalidloss -1408.83827  last_update 2\n",
      "train: iter 466  trainloss -1322.44849  validloss -1290.43508±0.00000  bestvalidloss -1408.83827  last_update 3\n",
      "train: iter 467  trainloss -1433.88589  validloss -1292.87620±0.00000  bestvalidloss -1408.83827  last_update 4\n",
      "train: iter 468  trainloss -1468.53007  validloss -1339.08640±0.00000  bestvalidloss -1408.83827  last_update 5\n",
      "train: iter 469  trainloss -1294.34005  validloss -1307.22605±0.00000  bestvalidloss -1408.83827  last_update 6\n",
      "train: iter 470  trainloss -1202.40059  validloss -1173.53623±0.00000  bestvalidloss -1408.83827  last_update 7\n",
      "train: iter 471  trainloss -1353.39701  validloss -811.96231±0.00000  bestvalidloss -1408.83827  last_update 8\n",
      "train: iter 472  trainloss -1409.30860  validloss -1309.24409±0.00000  bestvalidloss -1408.83827  last_update 9\n",
      "train: iter 473  trainloss -1468.33944  validloss -1354.64270±0.00000  bestvalidloss -1408.83827  last_update 10\n",
      "train: iter 474  trainloss -1346.06041  validloss -1375.72033±0.00000  bestvalidloss -1408.83827  last_update 11\n",
      "train: iter 475  trainloss -1444.07589  validloss -1334.41167±0.00000  bestvalidloss -1408.83827  last_update 12\n",
      "train: iter 476  trainloss -1262.86354  validloss -1375.95337±0.00000  bestvalidloss -1408.83827  last_update 13\n",
      "train: iter 477  trainloss -1373.74201  validloss -1292.73495±0.00000  bestvalidloss -1408.83827  last_update 14\n",
      "train: iter 478  trainloss -1389.16950  validloss -1362.70133±0.00000  bestvalidloss -1408.83827  last_update 15\n",
      "train: iter 479  trainloss -1503.78151  validloss -1380.52795±0.00000  bestvalidloss -1408.83827  last_update 16\n",
      "train: iter 480  trainloss -1161.62679  validloss -1257.87727±0.00000  bestvalidloss -1408.83827  last_update 17\n",
      "train: iter 481  trainloss -1293.43953  validloss -937.68705±0.00000  bestvalidloss -1408.83827  last_update 18\n",
      "train: iter 482  trainloss -1360.85859  validloss -1284.66296±0.00000  bestvalidloss -1408.83827  last_update 19\n",
      "train: iter 483  trainloss -1447.40131  validloss -1351.02384±0.00000  bestvalidloss -1408.83827  last_update 20\n",
      "train: iter 484  trainloss -1475.51983  validloss -1348.73301±0.00000  bestvalidloss -1408.83827  last_update 21\n",
      "train: iter 485  trainloss -1391.31412  validloss -1360.25242±0.00000  bestvalidloss -1408.83827  last_update 22\n",
      "train: iter 486  trainloss -1343.43946  validloss -1394.76224±0.00000  bestvalidloss -1408.83827  last_update 23\n",
      "train: iter 487  trainloss -1277.65657  validloss -1230.16169±0.00000  bestvalidloss -1408.83827  last_update 24\n",
      "train: iter 488  trainloss -1475.17744  validloss -1280.06118±0.00000  bestvalidloss -1408.83827  last_update 25\n",
      "train: iter 489  trainloss -1376.11870  validloss -1318.44665±0.00000  bestvalidloss -1408.83827  last_update 26\n",
      "train: iter 490  trainloss -1325.12042  validloss -1266.36178±0.00000  bestvalidloss -1408.83827  last_update 27\n",
      "train: iter 491  trainloss -1434.62943  validloss -1397.28759±0.00000  bestvalidloss -1408.83827  last_update 28\n",
      "train: iter 492  trainloss -1445.71484  validloss -1335.15067±0.00000  bestvalidloss -1408.83827  last_update 29\n",
      "train: iter 493  trainloss -1439.99799  validloss -1401.96717±0.00000  bestvalidloss -1408.83827  last_update 30\n",
      "train: iter 494  trainloss -1337.08535  validloss -1322.46712±0.00000  bestvalidloss -1408.83827  last_update 31\n",
      "train: iter 495  trainloss -1365.23759  validloss -1082.58385±0.00000  bestvalidloss -1408.83827  last_update 32\n",
      "train: iter 496  trainloss -1263.53765  validloss -1317.93636±0.00000  bestvalidloss -1408.83827  last_update 33\n",
      "train: iter 497  trainloss -1507.83087  validloss -1387.73782±0.00000  bestvalidloss -1408.83827  last_update 34\n",
      "train: iter 498  trainloss -1242.59392  validloss -1244.67372±0.00000  bestvalidloss -1408.83827  last_update 35\n",
      "train: iter 499  trainloss -1432.72636  validloss -1354.25171±0.00000  bestvalidloss -1408.83827  last_update 36\n",
      "train: iter 500  trainloss -1392.97215  validloss -1341.55630±0.00000  bestvalidloss -1408.83827  last_update 37\n",
      "train: iter 501  trainloss -1459.69879  validloss -1191.77218±0.00000  bestvalidloss -1408.83827  last_update 38\n",
      "train: iter 502  trainloss -1455.74691  validloss -1407.33208±0.00000  bestvalidloss -1408.83827  last_update 39\n",
      "train: iter 503  trainloss -1221.64362  validloss -1311.91467±0.00000  bestvalidloss -1408.83827  last_update 40\n",
      "train: iter 504  trainloss -1426.12830  validloss -1212.19230±0.00000  bestvalidloss -1408.83827  last_update 41\n",
      "train: iter 505  trainloss -1494.99978  validloss -1387.84521±0.00000  bestvalidloss -1408.83827  last_update 42\n",
      "train: iter 506  trainloss -1374.78289  validloss -1431.20338±0.00000  bestvalidloss -1431.20338  last_update 0\n",
      "train: iter 507  trainloss -1375.64056  validloss -1371.73889±0.00000  bestvalidloss -1431.20338  last_update 1\n",
      "train: iter 508  trainloss -1381.35560  validloss -1171.81100±0.00000  bestvalidloss -1431.20338  last_update 2\n",
      "train: iter 509  trainloss -1451.86030  validloss -1220.88256±0.00000  bestvalidloss -1431.20338  last_update 3\n",
      "train: iter 510  trainloss -1507.10191  validloss -1309.71963±0.00000  bestvalidloss -1431.20338  last_update 4\n",
      "train: iter 511  trainloss -1065.37109  validloss -1370.72510±0.00000  bestvalidloss -1431.20338  last_update 5\n",
      "train: iter 512  trainloss -1360.45955  validloss -1310.73698±0.00000  bestvalidloss -1431.20338  last_update 6\n",
      "train: iter 513  trainloss -1491.81763  validloss -1373.58269±0.00000  bestvalidloss -1431.20338  last_update 7\n",
      "train: iter 514  trainloss -1518.88933  validloss -1420.48617±0.00000  bestvalidloss -1431.20338  last_update 8\n",
      "train: iter 515  trainloss -1310.50683  validloss -1365.57083±0.00000  bestvalidloss -1431.20338  last_update 9\n",
      "train: iter 516  trainloss -1463.07864  validloss -1230.85896±0.00000  bestvalidloss -1431.20338  last_update 10\n",
      "train: iter 517  trainloss -1375.55257  validloss -1249.55403±0.00000  bestvalidloss -1431.20338  last_update 11\n",
      "train: iter 518  trainloss -1262.74496  validloss -1303.61798±0.00000  bestvalidloss -1431.20338  last_update 12\n",
      "train: iter 519  trainloss -1426.90361  validloss -1279.89627±0.00000  bestvalidloss -1431.20338  last_update 13\n",
      "train: iter 520  trainloss -1443.35267  validloss -1253.34053±0.00000  bestvalidloss -1431.20338  last_update 14\n",
      "train: iter 521  trainloss -1221.62612  validloss -1364.60279±0.00000  bestvalidloss -1431.20338  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 522  trainloss -1367.62252  validloss -1230.93358±0.00000  bestvalidloss -1431.20338  last_update 16\n",
      "train: iter 523  trainloss -1446.59536  validloss -1377.87223±0.00000  bestvalidloss -1431.20338  last_update 17\n",
      "train: iter 524  trainloss -1419.69538  validloss -1382.64006±0.00000  bestvalidloss -1431.20338  last_update 18\n",
      "train: iter 525  trainloss -1276.06353  validloss -898.08007±0.00000  bestvalidloss -1431.20338  last_update 19\n",
      "train: iter 526  trainloss -1429.54304  validloss -1350.21277±0.00000  bestvalidloss -1431.20338  last_update 20\n",
      "train: iter 527  trainloss -1456.76238  validloss -1394.10492±0.00000  bestvalidloss -1431.20338  last_update 21\n",
      "train: iter 528  trainloss -1467.65791  validloss -1254.05077±0.00000  bestvalidloss -1431.20338  last_update 22\n",
      "train: iter 529  trainloss -1484.08736  validloss -1404.25675±0.00000  bestvalidloss -1431.20338  last_update 23\n",
      "train: iter 530  trainloss -1473.42842  validloss -1326.18518±0.00000  bestvalidloss -1431.20338  last_update 24\n",
      "train: iter 531  trainloss -1475.81087  validloss -1415.49784±0.00000  bestvalidloss -1431.20338  last_update 25\n",
      "train: iter 532  trainloss -1372.12214  validloss -998.96211±0.00000  bestvalidloss -1431.20338  last_update 26\n",
      "train: iter 533  trainloss -1398.48184  validloss -1388.07017±0.00000  bestvalidloss -1431.20338  last_update 27\n",
      "train: iter 534  trainloss -1373.64485  validloss -1312.90428±0.00000  bestvalidloss -1431.20338  last_update 28\n",
      "train: iter 535  trainloss -544.78152  validloss -727.53310±0.00000  bestvalidloss -1431.20338  last_update 29\n",
      "train: iter 536  trainloss -614.35178  validloss -1105.78303±0.00000  bestvalidloss -1431.20338  last_update 30\n",
      "train: iter 537  trainloss -1038.46019  validloss -546.35100±0.00000  bestvalidloss -1431.20338  last_update 31\n",
      "train: iter 538  trainloss -1327.89171  validloss -1161.05464±0.00000  bestvalidloss -1431.20338  last_update 32\n",
      "train: iter 539  trainloss -1407.94744  validloss -1324.41916±0.00000  bestvalidloss -1431.20338  last_update 33\n",
      "train: iter 540  trainloss -1393.31916  validloss -1352.29712±0.00000  bestvalidloss -1431.20338  last_update 34\n",
      "train: iter 541  trainloss -1449.29738  validloss -1372.29345±0.00000  bestvalidloss -1431.20338  last_update 35\n",
      "train: iter 542  trainloss -1434.51784  validloss -1262.58416±0.00000  bestvalidloss -1431.20338  last_update 36\n",
      "train: iter 543  trainloss -1504.48395  validloss -1317.54442±0.00000  bestvalidloss -1431.20338  last_update 37\n",
      "train: iter 544  trainloss -1463.97965  validloss -1401.47737±0.00000  bestvalidloss -1431.20338  last_update 38\n",
      "train: iter 545  trainloss -1501.83224  validloss -1387.94712±0.00000  bestvalidloss -1431.20338  last_update 39\n",
      "train: iter 546  trainloss -1495.27212  validloss -1412.83199±0.00000  bestvalidloss -1431.20338  last_update 40\n",
      "train: iter 547  trainloss -1409.87507  validloss -1422.23298±0.00000  bestvalidloss -1431.20338  last_update 41\n",
      "train: iter 548  trainloss -1445.50176  validloss -1268.93857±0.00000  bestvalidloss -1431.20338  last_update 42\n",
      "train: iter 549  trainloss -1534.66591  validloss -1387.45222±0.00000  bestvalidloss -1431.20338  last_update 43\n",
      "train: iter 550  trainloss -1219.96070  validloss -1345.46569±0.00000  bestvalidloss -1431.20338  last_update 44\n",
      "train: iter 551  trainloss -1396.03098  validloss -1102.04279±0.00000  bestvalidloss -1431.20338  last_update 45\n",
      "train: iter 552  trainloss -1533.82799  validloss -1372.90879±0.00000  bestvalidloss -1431.20338  last_update 46\n",
      "train: iter 553  trainloss -1369.39258  validloss -1400.67507±0.00000  bestvalidloss -1431.20338  last_update 47\n",
      "train: iter 554  trainloss -1387.88718  validloss -1429.99063±0.00000  bestvalidloss -1431.20338  last_update 48\n",
      "train: iter 555  trainloss -1417.88959  validloss -1350.20005±0.00000  bestvalidloss -1431.20338  last_update 49\n",
      "train: iter 556  trainloss -1467.17581  validloss -1350.34768±0.00000  bestvalidloss -1431.20338  last_update 50\n",
      "train: iter 557  trainloss -1443.72657  validloss -1361.14190±0.00000  bestvalidloss -1431.20338  last_update 51\n",
      "train: iter 558  trainloss -1526.51230  validloss -1262.39366±0.00000  bestvalidloss -1431.20338  last_update 52\n",
      "train: iter 559  trainloss -1453.38203  validloss -1414.25272±0.00000  bestvalidloss -1431.20338  last_update 53\n",
      "train: iter 560  trainloss -1450.95619  validloss -1390.45967±0.00000  bestvalidloss -1431.20338  last_update 54\n",
      "train: iter 561  trainloss -1438.95745  validloss -1441.92402±0.00000  bestvalidloss -1441.92402  last_update 0\n",
      "train: iter 562  trainloss -1457.38449  validloss -1314.84986±0.00000  bestvalidloss -1441.92402  last_update 1\n",
      "train: iter 563  trainloss -1475.17191  validloss -1332.25989±0.00000  bestvalidloss -1441.92402  last_update 2\n",
      "train: iter 564  trainloss -1487.24394  validloss -1384.99008±0.00000  bestvalidloss -1441.92402  last_update 3\n",
      "train: iter 565  trainloss -1356.09846  validloss -1393.00977±0.00000  bestvalidloss -1441.92402  last_update 4\n",
      "train: iter 566  trainloss -1466.31614  validloss -1400.05826±0.00000  bestvalidloss -1441.92402  last_update 5\n",
      "train: iter 567  trainloss -1517.87743  validloss -1393.49065±0.00000  bestvalidloss -1441.92402  last_update 6\n",
      "train: iter 568  trainloss -1519.34425  validloss -1461.25883±0.00000  bestvalidloss -1461.25883  last_update 0\n",
      "train: iter 569  trainloss -1231.04787  validloss -1224.17210±0.00000  bestvalidloss -1461.25883  last_update 1\n",
      "train: iter 570  trainloss -1222.09696  validloss -601.91364±0.00000  bestvalidloss -1461.25883  last_update 2\n",
      "train: iter 571  trainloss -1272.20743  validloss -1233.35060±0.00000  bestvalidloss -1461.25883  last_update 3\n",
      "train: iter 572  trainloss -1433.36286  validloss -1253.23687±0.00000  bestvalidloss -1461.25883  last_update 4\n",
      "train: iter 573  trainloss -1489.19987  validloss -1430.07868±0.00000  bestvalidloss -1461.25883  last_update 5\n",
      "train: iter 574  trainloss -1457.52425  validloss -1325.35412±0.00000  bestvalidloss -1461.25883  last_update 6\n",
      "train: iter 575  trainloss -1539.25453  validloss -1404.52040±0.00000  bestvalidloss -1461.25883  last_update 7\n",
      "train: iter 576  trainloss -1512.36267  validloss -1450.65165±0.00000  bestvalidloss -1461.25883  last_update 8\n",
      "train: iter 577  trainloss -1503.16870  validloss -1372.41793±0.00000  bestvalidloss -1461.25883  last_update 9\n",
      "train: iter 578  trainloss -1488.33179  validloss -1352.50286±0.00000  bestvalidloss -1461.25883  last_update 10\n",
      "train: iter 579  trainloss -1312.82515  validloss -985.84575±0.00000  bestvalidloss -1461.25883  last_update 11\n",
      "train: iter 580  trainloss -1481.76488  validloss -1384.73200±0.00000  bestvalidloss -1461.25883  last_update 12\n",
      "train: iter 581  trainloss -1521.98981  validloss -1418.17852±0.00000  bestvalidloss -1461.25883  last_update 13\n",
      "train: iter 582  trainloss -1218.65016  validloss -1331.52632±0.00000  bestvalidloss -1461.25883  last_update 14\n",
      "train: iter 583  trainloss -1398.48670  validloss -1271.39726±0.00000  bestvalidloss -1461.25883  last_update 15\n",
      "train: iter 584  trainloss -1469.48694  validloss -1154.11369±0.00000  bestvalidloss -1461.25883  last_update 16\n",
      "train: iter 585  trainloss -1498.22277  validloss -1420.65927±0.00000  bestvalidloss -1461.25883  last_update 17\n",
      "train: iter 586  trainloss -1549.57748  validloss -1422.54761±0.00000  bestvalidloss -1461.25883  last_update 18\n",
      "train: iter 587  trainloss -1468.90389  validloss -1427.11306±0.00000  bestvalidloss -1461.25883  last_update 19\n",
      "train: iter 588  trainloss -1571.69861  validloss -1459.64213±0.00000  bestvalidloss -1461.25883  last_update 20\n",
      "train: iter 589  trainloss -1456.62486  validloss -1467.07679±0.00000  bestvalidloss -1467.07679  last_update 0\n",
      "train: iter 590  trainloss -1497.64621  validloss -1394.93036±0.00000  bestvalidloss -1467.07679  last_update 1\n",
      "train: iter 591  trainloss -1431.12912  validloss -1299.00656±0.00000  bestvalidloss -1467.07679  last_update 2\n",
      "train: iter 592  trainloss -1511.31142  validloss -1427.11612±0.00000  bestvalidloss -1467.07679  last_update 3\n",
      "train: iter 593  trainloss -1464.81421  validloss -1455.52481±0.00000  bestvalidloss -1467.07679  last_update 4\n",
      "train: iter 594  trainloss -1429.50895  validloss -1477.34774±0.00000  bestvalidloss -1477.34774  last_update 0\n",
      "train: iter 595  trainloss -1521.35128  validloss -1424.45144±0.00000  bestvalidloss -1477.34774  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 596  trainloss -1539.56922  validloss -1388.78851±0.00000  bestvalidloss -1477.34774  last_update 2\n",
      "train: iter 597  trainloss -1498.00300  validloss -1355.60597±0.00000  bestvalidloss -1477.34774  last_update 3\n",
      "train: iter 598  trainloss -1390.90664  validloss -1455.55924±0.00000  bestvalidloss -1477.34774  last_update 4\n",
      "train: iter 599  trainloss -1495.92789  validloss -1343.18330±0.00000  bestvalidloss -1477.34774  last_update 5\n",
      "train: iter 600  trainloss -1504.75745  validloss -1462.08475±0.00000  bestvalidloss -1477.34774  last_update 6\n",
      "train: iter 601  trainloss -1413.26904  validloss -1331.35352±0.00000  bestvalidloss -1477.34774  last_update 7\n",
      "train: iter 602  trainloss -1368.35705  validloss -1298.95597±0.00000  bestvalidloss -1477.34774  last_update 8\n",
      "train: iter 603  trainloss -1568.03218  validloss -1404.22286±0.00000  bestvalidloss -1477.34774  last_update 9\n",
      "train: iter 604  trainloss -1473.42069  validloss -1455.37630±0.00000  bestvalidloss -1477.34774  last_update 10\n",
      "train: iter 605  trainloss -1256.52359  validloss -1216.56076±0.00000  bestvalidloss -1477.34774  last_update 11\n",
      "train: iter 606  trainloss -1528.03094  validloss -1382.31678±0.00000  bestvalidloss -1477.34774  last_update 12\n",
      "train: iter 607  trainloss -1497.82113  validloss -1470.19163±0.00000  bestvalidloss -1477.34774  last_update 13\n",
      "train: iter 608  trainloss -1577.49702  validloss -1444.54959±0.00000  bestvalidloss -1477.34774  last_update 14\n",
      "train: iter 609  trainloss -1510.13835  validloss -1489.46134±0.00000  bestvalidloss -1489.46134  last_update 0\n",
      "train: iter 610  trainloss -1390.67098  validloss -1341.55339±0.00000  bestvalidloss -1489.46134  last_update 1\n",
      "train: iter 611  trainloss -1483.24802  validloss -1309.92540±0.00000  bestvalidloss -1489.46134  last_update 2\n",
      "train: iter 612  trainloss -1558.60260  validloss -1400.62725±0.00000  bestvalidloss -1489.46134  last_update 3\n",
      "train: iter 613  trainloss -1412.65510  validloss -1433.03843±0.00000  bestvalidloss -1489.46134  last_update 4\n",
      "train: iter 614  trainloss -1442.10989  validloss -1293.08379±0.00000  bestvalidloss -1489.46134  last_update 5\n",
      "train: iter 615  trainloss -1531.05698  validloss -1387.62285±0.00000  bestvalidloss -1489.46134  last_update 6\n",
      "train: iter 616  trainloss -1567.30157  validloss -1503.42792±0.00000  bestvalidloss -1503.42792  last_update 0\n",
      "train: iter 617  trainloss -1285.80899  validloss -1412.95637±0.00000  bestvalidloss -1503.42792  last_update 1\n",
      "train: iter 618  trainloss -1529.80117  validloss -1318.32407±0.00000  bestvalidloss -1503.42792  last_update 2\n",
      "train: iter 619  trainloss -1516.60070  validloss -1461.18747±0.00000  bestvalidloss -1503.42792  last_update 3\n",
      "train: iter 620  trainloss -1526.53553  validloss -1364.82638±0.00000  bestvalidloss -1503.42792  last_update 4\n",
      "train: iter 621  trainloss -1478.31872  validloss -1466.05809±0.00000  bestvalidloss -1503.42792  last_update 5\n",
      "train: iter 622  trainloss -1515.50940  validloss -1251.56910±0.00000  bestvalidloss -1503.42792  last_update 6\n",
      "train: iter 623  trainloss -1458.77913  validloss -1402.30069±0.00000  bestvalidloss -1503.42792  last_update 7\n",
      "train: iter 624  trainloss -1520.66571  validloss -1441.30255±0.00000  bestvalidloss -1503.42792  last_update 8\n",
      "train: iter 625  trainloss -1554.49519  validloss -1334.33283±0.00000  bestvalidloss -1503.42792  last_update 9\n",
      "train: iter 626  trainloss -1054.43171  validloss -1457.91800±0.00000  bestvalidloss -1503.42792  last_update 10\n",
      "train: iter 627  trainloss -1260.35673  validloss -1003.19876±0.00000  bestvalidloss -1503.42792  last_update 11\n",
      "train: iter 628  trainloss -1480.20085  validloss -1225.08471±0.00000  bestvalidloss -1503.42792  last_update 12\n",
      "train: iter 629  trainloss -1533.05848  validloss -1372.62924±0.00000  bestvalidloss -1503.42792  last_update 13\n",
      "train: iter 630  trainloss -1584.64218  validloss -1431.85883±0.00000  bestvalidloss -1503.42792  last_update 14\n",
      "train: iter 631  trainloss -1551.76787  validloss -1302.09711±0.00000  bestvalidloss -1503.42792  last_update 15\n",
      "train: iter 632  trainloss -1598.33311  validloss -1478.65947±0.00000  bestvalidloss -1503.42792  last_update 16\n",
      "train: iter 633  trainloss -1562.47941  validloss -1471.48916±0.00000  bestvalidloss -1503.42792  last_update 17\n",
      "train: iter 634  trainloss -1350.44772  validloss -1438.15467±0.00000  bestvalidloss -1503.42792  last_update 18\n",
      "train: iter 635  trainloss -1502.53289  validloss -1175.78485±0.00000  bestvalidloss -1503.42792  last_update 19\n",
      "train: iter 636  trainloss -1467.84465  validloss -1503.11079±0.00000  bestvalidloss -1503.42792  last_update 20\n",
      "train: iter 637  trainloss -1466.95813  validloss -1332.55240±0.00000  bestvalidloss -1503.42792  last_update 21\n",
      "train: iter 638  trainloss -1601.57348  validloss -1416.59245±0.00000  bestvalidloss -1503.42792  last_update 22\n",
      "train: iter 639  trainloss -1567.80098  validloss -1484.09852±0.00000  bestvalidloss -1503.42792  last_update 23\n",
      "train: iter 640  trainloss -1516.51669  validloss -1336.23063±0.00000  bestvalidloss -1503.42792  last_update 24\n",
      "train: iter 641  trainloss -1514.80904  validloss -1485.04225±0.00000  bestvalidloss -1503.42792  last_update 25\n",
      "train: iter 642  trainloss -1406.15885  validloss -1228.74025±0.00000  bestvalidloss -1503.42792  last_update 26\n",
      "train: iter 643  trainloss -1467.50017  validloss -1394.05738±0.00000  bestvalidloss -1503.42792  last_update 27\n",
      "train: iter 644  trainloss -1388.88057  validloss -1428.35006±0.00000  bestvalidloss -1503.42792  last_update 28\n",
      "train: iter 645  trainloss -1566.36087  validloss -1395.89504±0.00000  bestvalidloss -1503.42792  last_update 29\n",
      "train: iter 646  trainloss -1367.50109  validloss -1463.31918±0.00000  bestvalidloss -1503.42792  last_update 30\n",
      "train: iter 647  trainloss -1386.85723  validloss -1121.47572±0.00000  bestvalidloss -1503.42792  last_update 31\n",
      "train: iter 648  trainloss -1526.49869  validloss -1415.55181±0.00000  bestvalidloss -1503.42792  last_update 32\n",
      "train: iter 649  trainloss -1531.76540  validloss -1411.38387±0.00000  bestvalidloss -1503.42792  last_update 33\n",
      "train: iter 650  trainloss -1561.52029  validloss -1500.55336±0.00000  bestvalidloss -1503.42792  last_update 34\n",
      "train: iter 651  trainloss -1414.83328  validloss -1197.46589±0.00000  bestvalidloss -1503.42792  last_update 35\n",
      "train: iter 652  trainloss -1551.82543  validloss -1380.47821±0.00000  bestvalidloss -1503.42792  last_update 36\n",
      "train: iter 653  trainloss -1509.72180  validloss -1435.10444±0.00000  bestvalidloss -1503.42792  last_update 37\n",
      "train: iter 654  trainloss -1591.89852  validloss -1448.17513±0.00000  bestvalidloss -1503.42792  last_update 38\n",
      "train: iter 655  trainloss -1414.28287  validloss -1463.66073±0.00000  bestvalidloss -1503.42792  last_update 39\n",
      "train: iter 656  trainloss -1578.72422  validloss -1357.46079±0.00000  bestvalidloss -1503.42792  last_update 40\n",
      "train: iter 657  trainloss -1620.50257  validloss -1511.32547±0.00000  bestvalidloss -1511.32547  last_update 0\n",
      "train: iter 658  trainloss -1446.97579  validloss -1361.66512±0.00000  bestvalidloss -1511.32547  last_update 1\n",
      "train: iter 659  trainloss -1571.91759  validloss -1424.82007±0.00000  bestvalidloss -1511.32547  last_update 2\n",
      "train: iter 660  trainloss -1419.48455  validloss -1412.59602±0.00000  bestvalidloss -1511.32547  last_update 3\n",
      "train: iter 661  trainloss -1460.48825  validloss -1258.23050±0.00000  bestvalidloss -1511.32547  last_update 4\n",
      "train: iter 662  trainloss -1513.43018  validloss -1387.78353±0.00000  bestvalidloss -1511.32547  last_update 5\n",
      "train: iter 663  trainloss -1587.39989  validloss -1477.61725±0.00000  bestvalidloss -1511.32547  last_update 6\n",
      "train: iter 664  trainloss -1557.52233  validloss -1274.89639±0.00000  bestvalidloss -1511.32547  last_update 7\n",
      "train: iter 665  trainloss -1563.71256  validloss -1504.32114±0.00000  bestvalidloss -1511.32547  last_update 8\n",
      "train: iter 666  trainloss -1555.61970  validloss -1404.61271±0.00000  bestvalidloss -1511.32547  last_update 9\n",
      "train: iter 667  trainloss -1379.75661  validloss -1367.72329±0.00000  bestvalidloss -1511.32547  last_update 10\n",
      "train: iter 668  trainloss -1537.14674  validloss -1431.86890±0.00000  bestvalidloss -1511.32547  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 669  trainloss -1453.06646  validloss -1310.57410±0.00000  bestvalidloss -1511.32547  last_update 12\n",
      "train: iter 670  trainloss -1575.97908  validloss -1451.45265±0.00000  bestvalidloss -1511.32547  last_update 13\n",
      "train: iter 671  trainloss -1497.39138  validloss -1443.80029±0.00000  bestvalidloss -1511.32547  last_update 14\n",
      "train: iter 672  trainloss -1482.80707  validloss -1170.04080±0.00000  bestvalidloss -1511.32547  last_update 15\n",
      "train: iter 673  trainloss -1390.63745  validloss -1430.40922±0.00000  bestvalidloss -1511.32547  last_update 16\n",
      "train: iter 674  trainloss -1483.39736  validloss -1298.63796±0.00000  bestvalidloss -1511.32547  last_update 17\n",
      "train: iter 675  trainloss -1578.21021  validloss -1357.05255±0.00000  bestvalidloss -1511.32547  last_update 18\n",
      "train: iter 676  trainloss -1606.67966  validloss -1485.09853±0.00000  bestvalidloss -1511.32547  last_update 19\n",
      "train: iter 677  trainloss -1601.35290  validloss -1511.71631±0.00000  bestvalidloss -1511.71631  last_update 0\n",
      "train: iter 678  trainloss -1479.70980  validloss -1177.53616±0.00000  bestvalidloss -1511.71631  last_update 1\n",
      "train: iter 679  trainloss -1500.30581  validloss -1426.31943±0.00000  bestvalidloss -1511.71631  last_update 2\n",
      "train: iter 680  trainloss -1574.55063  validloss -1405.46406±0.00000  bestvalidloss -1511.71631  last_update 3\n",
      "train: iter 681  trainloss -1473.93657  validloss -1476.27721±0.00000  bestvalidloss -1511.71631  last_update 4\n",
      "train: iter 682  trainloss -1595.91263  validloss -1472.43591±0.00000  bestvalidloss -1511.71631  last_update 5\n",
      "train: iter 683  trainloss -1531.12445  validloss -1485.84111±0.00000  bestvalidloss -1511.71631  last_update 6\n",
      "train: iter 684  trainloss -1560.02296  validloss -1445.01124±0.00000  bestvalidloss -1511.71631  last_update 7\n",
      "train: iter 685  trainloss -1550.57878  validloss -1425.15463±0.00000  bestvalidloss -1511.71631  last_update 8\n",
      "train: iter 686  trainloss -1500.10251  validloss -1327.20285±0.00000  bestvalidloss -1511.71631  last_update 9\n",
      "train: iter 687  trainloss -1586.53795  validloss -1490.28608±0.00000  bestvalidloss -1511.71631  last_update 10\n",
      "train: iter 688  trainloss -1544.96602  validloss -1543.79199±0.00000  bestvalidloss -1543.79199  last_update 0\n",
      "train: iter 689  trainloss -1399.46490  validloss -1300.65860±0.00000  bestvalidloss -1543.79199  last_update 1\n",
      "train: iter 690  trainloss -1573.18308  validloss -1472.16005±0.00000  bestvalidloss -1543.79199  last_update 2\n",
      "train: iter 691  trainloss -1517.89524  validloss -1488.58087±0.00000  bestvalidloss -1543.79199  last_update 3\n",
      "train: iter 692  trainloss -1589.06536  validloss -1479.49951±0.00000  bestvalidloss -1543.79199  last_update 4\n",
      "train: iter 693  trainloss -1619.67747  validloss -1501.99774±0.00000  bestvalidloss -1543.79199  last_update 5\n",
      "train: iter 694  trainloss -1603.57671  validloss -1513.04244±0.00000  bestvalidloss -1543.79199  last_update 6\n",
      "train: iter 695  trainloss -1384.67200  validloss -1393.19582±0.00000  bestvalidloss -1543.79199  last_update 7\n",
      "train: iter 696  trainloss -1518.96966  validloss -1406.65473±0.00000  bestvalidloss -1543.79199  last_update 8\n",
      "train: iter 697  trainloss -1545.73302  validloss -1460.56896±0.00000  bestvalidloss -1543.79199  last_update 9\n",
      "train: iter 698  trainloss -1558.66731  validloss -1436.78739±0.00000  bestvalidloss -1543.79199  last_update 10\n",
      "train: iter 699  trainloss -1600.35312  validloss -1448.27768±0.00000  bestvalidloss -1543.79199  last_update 11\n",
      "train: iter 700  trainloss -1575.27485  validloss -1519.24325±0.00000  bestvalidloss -1543.79199  last_update 12\n",
      "train: iter 701  trainloss -1453.83169  validloss -1420.53432±0.00000  bestvalidloss -1543.79199  last_update 13\n",
      "train: iter 702  trainloss -1483.49793  validloss -1355.66904±0.00000  bestvalidloss -1543.79199  last_update 14\n",
      "train: iter 703  trainloss -1599.52623  validloss -1434.23738±0.00000  bestvalidloss -1543.79199  last_update 15\n",
      "train: iter 704  trainloss -1609.72751  validloss -1446.02037±0.00000  bestvalidloss -1543.79199  last_update 16\n",
      "train: iter 705  trainloss -1323.89119  validloss -1538.08659±0.00000  bestvalidloss -1543.79199  last_update 17\n",
      "train: iter 706  trainloss -1325.93604  validloss -1295.72922±0.00000  bestvalidloss -1543.79199  last_update 18\n",
      "train: iter 707  trainloss -1538.70855  validloss -1325.74745±0.00000  bestvalidloss -1543.79199  last_update 19\n",
      "train: iter 708  trainloss -1535.40597  validloss -1354.03534±0.00000  bestvalidloss -1543.79199  last_update 20\n",
      "train: iter 709  trainloss -1577.70597  validloss -1466.04452±0.00000  bestvalidloss -1543.79199  last_update 21\n",
      "train: iter 710  trainloss -1623.13033  validloss -1471.92964±0.00000  bestvalidloss -1543.79199  last_update 22\n",
      "train: iter 711  trainloss -1527.34321  validloss -1522.65783±0.00000  bestvalidloss -1543.79199  last_update 23\n",
      "train: iter 712  trainloss -1408.07868  validloss -1237.27510±0.00000  bestvalidloss -1543.79199  last_update 24\n",
      "train: iter 713  trainloss -1598.58768  validloss -1450.65365±0.00000  bestvalidloss -1543.79199  last_update 25\n",
      "train: iter 714  trainloss -1550.51177  validloss -1471.16678±0.00000  bestvalidloss -1543.79199  last_update 26\n",
      "train: iter 715  trainloss -1534.05964  validloss -1367.61324±0.00000  bestvalidloss -1543.79199  last_update 27\n",
      "train: iter 716  trainloss -1628.33521  validloss -1410.82261±0.00000  bestvalidloss -1543.79199  last_update 28\n",
      "train: iter 717  trainloss -1650.86234  validloss -1495.66621±0.00000  bestvalidloss -1543.79199  last_update 29\n",
      "train: iter 718  trainloss -1598.70163  validloss -1507.52155±0.00000  bestvalidloss -1543.79199  last_update 30\n",
      "train: iter 719  trainloss -1544.30234  validloss -1424.72503±0.00000  bestvalidloss -1543.79199  last_update 31\n",
      "train: iter 720  trainloss -1609.33241  validloss -1433.38665±0.00000  bestvalidloss -1543.79199  last_update 32\n",
      "train: iter 721  trainloss -1547.94041  validloss -1413.93940±0.00000  bestvalidloss -1543.79199  last_update 33\n",
      "train: iter 722  trainloss -1573.06932  validloss -1378.44073±0.00000  bestvalidloss -1543.79199  last_update 34\n",
      "train: iter 723  trainloss -1506.18144  validloss -1131.33310±0.00000  bestvalidloss -1543.79199  last_update 35\n",
      "train: iter 724  trainloss -1553.72923  validloss -1481.45404±0.00000  bestvalidloss -1543.79199  last_update 36\n",
      "train: iter 725  trainloss -1413.88955  validloss -1300.98658±0.00000  bestvalidloss -1543.79199  last_update 37\n",
      "train: iter 726  trainloss -1577.81541  validloss -1389.12773±0.00000  bestvalidloss -1543.79199  last_update 38\n",
      "train: iter 727  trainloss -1609.91441  validloss -1452.50861±0.00000  bestvalidloss -1543.79199  last_update 39\n",
      "train: iter 728  trainloss -1615.17047  validloss -1275.16922±0.00000  bestvalidloss -1543.79199  last_update 40\n",
      "train: iter 729  trainloss -1568.85923  validloss -1528.09435±0.00000  bestvalidloss -1543.79199  last_update 41\n",
      "train: iter 730  trainloss -1577.18997  validloss -1433.58861±0.00000  bestvalidloss -1543.79199  last_update 42\n",
      "train: iter 731  trainloss -1582.49738  validloss -1518.83977±0.00000  bestvalidloss -1543.79199  last_update 43\n",
      "train: iter 732  trainloss -1259.93375  validloss -1424.91699±0.00000  bestvalidloss -1543.79199  last_update 44\n",
      "train: iter 733  trainloss -1423.60269  validloss -942.99192±0.00000  bestvalidloss -1543.79199  last_update 45\n",
      "train: iter 734  trainloss -1596.49665  validloss -1454.07894±0.00000  bestvalidloss -1543.79199  last_update 46\n",
      "train: iter 735  trainloss -1635.45278  validloss -1490.53339±0.00000  bestvalidloss -1543.79199  last_update 47\n",
      "train: iter 736  trainloss -1613.22657  validloss -1513.41013±0.00000  bestvalidloss -1543.79199  last_update 48\n",
      "train: iter 737  trainloss -1462.23124  validloss -1454.69696±0.00000  bestvalidloss -1543.79199  last_update 49\n",
      "train: iter 738  trainloss -1614.82331  validloss -1458.78058±0.00000  bestvalidloss -1543.79199  last_update 50\n",
      "train: iter 739  trainloss -1482.44591  validloss -1443.82516±0.00000  bestvalidloss -1543.79199  last_update 51\n",
      "train: iter 740  trainloss -1451.32724  validloss -1339.38444±0.00000  bestvalidloss -1543.79199  last_update 52\n",
      "train: iter 741  trainloss -1633.57236  validloss -1425.98702±0.00000  bestvalidloss -1543.79199  last_update 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 742  trainloss -1567.86385  validloss -1208.14489±0.00000  bestvalidloss -1543.79199  last_update 54\n",
      "train: iter 743  trainloss -1608.06916  validloss -1467.74183±0.00000  bestvalidloss -1543.79199  last_update 55\n",
      "train: iter 744  trainloss -1455.12481  validloss -1446.71014±0.00000  bestvalidloss -1543.79199  last_update 56\n",
      "train: iter 745  trainloss -1579.42091  validloss -1420.20763±0.00000  bestvalidloss -1543.79199  last_update 57\n",
      "train: iter 746  trainloss -1631.14473  validloss -1461.29078±0.00000  bestvalidloss -1543.79199  last_update 58\n",
      "train: iter 747  trainloss -1508.61916  validloss -1468.21527±0.00000  bestvalidloss -1543.79199  last_update 59\n",
      "train: iter 748  trainloss -1593.25155  validloss -1508.29013±0.00000  bestvalidloss -1543.79199  last_update 60\n",
      "train: iter 749  trainloss -1599.97404  validloss -1470.22588±0.00000  bestvalidloss -1543.79199  last_update 61\n",
      "train: iter 750  trainloss -1613.27545  validloss -1394.01191±0.00000  bestvalidloss -1543.79199  last_update 62\n",
      "train: iter 751  trainloss -1413.24755  validloss -1391.42672±0.00000  bestvalidloss -1543.79199  last_update 63\n",
      "train: iter 752  trainloss -1620.97273  validloss -1413.03346±0.00000  bestvalidloss -1543.79199  last_update 64\n",
      "train: iter 753  trainloss -1563.41107  validloss -1461.44957±0.00000  bestvalidloss -1543.79199  last_update 65\n",
      "train: iter 754  trainloss -1574.75349  validloss -1445.02878±0.00000  bestvalidloss -1543.79199  last_update 66\n",
      "train: iter 755  trainloss -1232.75670  validloss -1476.86945±0.00000  bestvalidloss -1543.79199  last_update 67\n",
      "train: iter 756  trainloss -1566.20502  validloss -1431.39939±0.00000  bestvalidloss -1543.79199  last_update 68\n",
      "train: iter 757  trainloss -1610.79438  validloss -1465.38399±0.00000  bestvalidloss -1543.79199  last_update 69\n",
      "train: iter 758  trainloss -1613.30035  validloss -1505.50556±0.00000  bestvalidloss -1543.79199  last_update 70\n",
      "train: iter 759  trainloss -1518.08288  validloss -1249.35824±0.00000  bestvalidloss -1543.79199  last_update 71\n",
      "train: iter 760  trainloss -1592.65666  validloss -1485.07568±0.00000  bestvalidloss -1543.79199  last_update 72\n",
      "train: iter 761  trainloss -1623.33661  validloss -1349.79708±0.00000  bestvalidloss -1543.79199  last_update 73\n",
      "train: iter 762  trainloss -1616.89997  validloss -1511.05862±0.00000  bestvalidloss -1543.79199  last_update 74\n",
      "train: iter 763  trainloss -1630.06827  validloss -1534.87008±0.00000  bestvalidloss -1543.79199  last_update 75\n",
      "train: iter 764  trainloss -1647.03117  validloss -1292.95109±0.00000  bestvalidloss -1543.79199  last_update 76\n",
      "train: iter 765  trainloss -1496.60310  validloss -1483.53833±0.00000  bestvalidloss -1543.79199  last_update 77\n",
      "train: iter 766  trainloss -1541.67739  validloss -1269.04672±0.00000  bestvalidloss -1543.79199  last_update 78\n",
      "train: iter 767  trainloss -1638.50261  validloss -1501.21164±0.00000  bestvalidloss -1543.79199  last_update 79\n",
      "train: iter 768  trainloss -1565.06186  validloss -1445.06351±0.00000  bestvalidloss -1543.79199  last_update 80\n",
      "train: iter 769  trainloss -1484.41440  validloss -1388.25453±0.00000  bestvalidloss -1543.79199  last_update 81\n",
      "train: iter 770  trainloss -1613.69889  validloss -1425.27288±0.00000  bestvalidloss -1543.79199  last_update 82\n",
      "train: iter 771  trainloss -1667.03668  validloss -1439.13936±0.00000  bestvalidloss -1543.79199  last_update 83\n",
      "train: iter 772  trainloss -1653.62745  validloss -1517.69282±0.00000  bestvalidloss -1543.79199  last_update 84\n",
      "train: iter 773  trainloss -1497.59982  validloss -1289.74422±0.00000  bestvalidloss -1543.79199  last_update 85\n",
      "train: iter 774  trainloss -1493.20290  validloss -1511.59397±0.00000  bestvalidloss -1543.79199  last_update 86\n",
      "train: iter 775  trainloss -1562.13074  validloss -1464.69540±0.00000  bestvalidloss -1543.79199  last_update 87\n",
      "train: iter 776  trainloss -1594.81844  validloss -1490.14924±0.00000  bestvalidloss -1543.79199  last_update 88\n",
      "train: iter 777  trainloss -1557.96675  validloss -1449.56826±0.00000  bestvalidloss -1543.79199  last_update 89\n",
      "train: iter 778  trainloss -1599.32865  validloss -1532.27468±0.00000  bestvalidloss -1543.79199  last_update 90\n",
      "train: iter 779  trainloss -1486.19557  validloss -1343.32016±0.00000  bestvalidloss -1543.79199  last_update 91\n",
      "train: iter 780  trainloss -1521.31214  validloss -1392.31013±0.00000  bestvalidloss -1543.79199  last_update 92\n",
      "train: iter 781  trainloss -1593.71432  validloss -1338.67967±0.00000  bestvalidloss -1543.79199  last_update 93\n",
      "train: iter 782  trainloss -1560.93542  validloss -1437.37200±0.00000  bestvalidloss -1543.79199  last_update 94\n",
      "train: iter 783  trainloss -1535.48820  validloss -1508.14707±0.00000  bestvalidloss -1543.79199  last_update 95\n",
      "train: iter 784  trainloss -1604.71081  validloss -1475.96165±0.00000  bestvalidloss -1543.79199  last_update 96\n",
      "train: iter 785  trainloss -1620.64627  validloss -1506.51026±0.00000  bestvalidloss -1543.79199  last_update 97\n",
      "train: iter 786  trainloss -1594.68976  validloss -1422.06553±0.00000  bestvalidloss -1543.79199  last_update 98\n",
      "train: iter 787  trainloss -1600.30023  validloss -1388.60554±0.00000  bestvalidloss -1543.79199  last_update 99\n",
      "train: iter 788  trainloss -1550.10956  validloss -1492.39957±0.00000  bestvalidloss -1543.79199  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.3066) penalty_target_max tensor(8.3031)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPbUlEQVR4nO3deVxUVeMG8OfODDOAOCAiIAruK+4bUmqLJJpZlr2pmZmabVguvVa26e9tsb2sTLNFWyyXSnNLI9xScUNxQcUNxYVFQRjWYZbz++PKwAgoKNerw/P9fCZm7j1z55yZZB7OPedcSQghQERERORiNGpXgIiIiEgJDDlERETkkhhyiIiIyCUx5BAREZFLYsghIiIil8SQQ0RERC6JIYeIiIhcEkMOERERuSSd2hVQk91ux7lz51C7dm1IkqR2dYiIiKgShBDIyclBUFAQNJqK+2tqdMg5d+4cgoOD1a4GERERXYPTp0+jYcOGFe6v0SGndu3aAOQ3yWg0qlwbIiIiqgyTyYTg4GDH93hFanTIKT5FZTQaGXKIiIhuMVcbasKBx0REROSSGHKIiIjIJTHkEBERkUtiyCEiIiKXxJBDRERELokhh4iIiFwSQw4RERG5JIYcIiIickkMOUREROSSGHKIiIjIJTHkEBERkUtiyCEiIiKXVKMv0KmYdW8D5hzg9gmAMUjt2hAREdVI7MlRwu4fge1zgPwMtWtCRERUYzHkKEkItWtARERUYzHkKEJSuwJEREQ1HkOOotiTQ0REpBaGHCVI7MkhIiJSG0OOkjgmh4iISDUMOYpgTw4REZHaGHIUxZ4cIiIitTDkKIFjcoiIiFRXpZAzY8YMdO/eHbVr14a/vz8GDx6MxMREpzKFhYWIiopC3bp14eXlhSFDhiAtLc2pTHJyMgYOHAhPT0/4+/tjypQpsFqtTmU2bNiALl26wGAwoHnz5pg/f36Z+syaNQuNGzeGu7s7wsLCsGPHjqo0R3kck0NERKSaKoWcjRs3IioqCtu2bUN0dDQsFgv69euHvLw8R5lJkyZhxYoVWLJkCTZu3Ihz587hoYcecuy32WwYOHAgioqKsHXrVvzwww+YP38+3nzzTUeZpKQkDBw4EHfddRfi4+MxceJEPPnkk1i7dq2jzKJFizB58mRMmzYNu3fvRseOHREZGYn09PTreT+qCXtyiIiIVCeuQ3p6ugAgNm7cKIQQIisrS7i5uYklS5Y4yhw6dEgAELGxsUIIIVavXi00Go1ITU11lJk9e7YwGo3CbDYLIYR46aWXRGhoqNNrDR06VERGRjoe9+jRQ0RFRTke22w2ERQUJGbMmFHp+mdnZwsAIjs7uwqtroSP2woxzSjEmV3Ve1wiIiKq9Pf3dY3Jyc7OBgD4+voCAOLi4mCxWBAREeEo07p1a4SEhCA2NhYAEBsbi/bt2yMgIMBRJjIyEiaTCQkJCY4ypY9RXKb4GEVFRYiLi3Mqo9FoEBER4ShTHrPZDJPJ5HRTBMfkEBERqe6aQ47dbsfEiRNx++23o127dgCA1NRU6PV6+Pj4OJUNCAhAamqqo0zpgFO8v3jflcqYTCYUFBTgwoULsNls5ZYpPkZ5ZsyYAW9vb8ctODi46g2vCg7JISIiUs01h5yoqCgcOHAACxcurM76KGrq1KnIzs523E6fPq3QK7Enh4iISG26a3nS+PHjsXLlSmzatAkNGzZ0bA8MDERRURGysrKcenPS0tIQGBjoKHP5LKji2Vely1w+IystLQ1GoxEeHh7QarXQarXllik+RnkMBgMMBkPVG3zN2JVDRESklir15AghMH78eCxduhTr1q1DkyZNnPZ37doVbm5uiImJcWxLTExEcnIywsPDAQDh4eHYv3+/0yyo6OhoGI1GtG3b1lGm9DGKyxQfQ6/Xo2vXrk5l7HY7YmJiHGVUxY4cIiIi1VWpJycqKgq//PIL/vzzT9SuXdsx/sXb2xseHh7w9vbG2LFjMXnyZPj6+sJoNOL5559HeHg4evbsCQDo168f2rZti5EjR+KDDz5AamoqXn/9dURFRTl6WZ555hl8+eWXeOmllzBmzBisW7cOixcvxqpVqxx1mTx5MkaNGoVu3bqhR48e+Oyzz5CXl4fRo0dX13tz/bhODhERkXqqMmUL8vmXMrd58+Y5yhQUFIjnnntO1KlTR3h6eooHH3xQpKSkOB3n5MmTYsCAAcLDw0P4+fmJF198UVgsFqcy69evF506dRJ6vV40bdrU6TWKffHFFyIkJETo9XrRo0cPsW3btqo0R7kp5J+2l6eQJ++o3uMSERFRpb+/JSFqbneDyWSCt7c3srOzYTQaq+/An3UAsk4BY6OB4B7Vd1wiIiKq9Pc3r12lBK6TQ0REpDqGHCXV3E4yIiIi1THkKII9OURERGpjyFEUe3KIiIjUwpCjBI7JISIiUh1DjpI4JoeIiEg1DDkKMBXaAABZBUUq14SIiKjmYshRwMV8Odxk5THkEBERqYUhRxHymBzBgcdERESqYchREIfkEBERqYchRwHMNkREROpjyFEU4w4REZFaGHIUwXVyiIiI1MaQoyQ7e3KIiIjUwpCjAMEVj4mIiFTHkKMgAbvaVSAiIqqxGHIUIIrXyeHZKiIiItUw5ChAcvxkyiEiIlILQ44CxGU/iYiI6MZjyFEUYw4REZFaGHIUwDE5RERE6mPIUZDElENERKQahhwFOHpyVK4HERFRTcaQo4Di2VWCPTlERESqYchRgOC1q4iIiFTHkKMornhMRESkFoYcBQh25BAREamOIUdJHJNDRESkGoYcRXB2FRERkdoYcpTElENERKQahhwFcHYVERGR+hhyFOCIOByTQ0REpBqGHAWUrHjMkENERKQWhhwlsSeHiIhINQw5CmC0ISIiUh9DjoJ47SoiIiL1MOQogrOriIiI1MaQoyj25BAREamFIUcBXCeHiIhIfQw5SuKYHCIiItUw5ChB4rWriIiI1MaQoyCJPTlERESqYchRgOBVyImIiFTHkKMk9uQQERGphiFHQbx2FRERkXoYchTEieRERETqYchRgGNMDjtyiIiIVMOQoyCeriIiIlIPQ44ieKKKiIhIbQw5ShJ2tWtARERUYzHkKEBI7MkhIiJSG0OOojgmh4iISC0MOUpixiEiIlINQ44iik9XMeUQERGphSFHAeKyn0RERHTjMeQowDHsmKsBEhERqYYhRwHFKx4z5BAREamHIYeIiIhcEkOOAtiTQ0REpD6GHCUUZxx1a0FERFSjMeQoglPIiYiI1MaQoyRmHCIiItUw5CiKKYeIiEgtDDkKYsQhIiJST5VDzqZNmzBo0CAEBQVBkiQsW7bMaf8TTzwBSZKcbv3793cqk5mZiREjRsBoNMLHxwdjx45Fbm6uU5l9+/ahd+/ecHd3R3BwMD744IMydVmyZAlat24Nd3d3tG/fHqtXr65qcxTB2VVERETqq3LIycvLQ8eOHTFr1qwKy/Tv3x8pKSmO26+//uq0f8SIEUhISEB0dDRWrlyJTZs24amnnnLsN5lM6NevHxo1aoS4uDh8+OGHmD59OubOnesos3XrVgwfPhxjx47Fnj17MHjwYAwePBgHDhyoapOIiIjIBemq+oQBAwZgwIABVyxjMBgQGBhY7r5Dhw5hzZo12LlzJ7p16wYA+OKLL3Dvvffio48+QlBQEBYsWICioiJ8//330Ov1CA0NRXx8PD755BNHGJo5cyb69++PKVOmAADeeustREdH48svv8ScOXOq2qzqJXF2FRERkdoUGZOzYcMG+Pv7o1WrVnj22WeRkZHh2BcbGwsfHx9HwAGAiIgIaDQabN++3VGmT58+0Ov1jjKRkZFITEzExYsXHWUiIiKcXjcyMhKxsbEV1stsNsNkMjndiIiIyDVVe8jp378/fvzxR8TExOD999/Hxo0bMWDAANhsNgBAamoq/P39nZ6j0+ng6+uL1NRUR5mAgACnMsWPr1ameH95ZsyYAW9vb8ctODj4+hpbAY7JISIiUl+VT1ddzbBhwxz327dvjw4dOqBZs2bYsGED+vbtW90vVyVTp07F5MmTHY9NJpNiQYeIiIjUpfgU8qZNm8LPzw/Hjh0DAAQGBiI9Pd2pjNVqRWZmpmMcT2BgINLS0pzKFD++WpmKxgIB8lgho9HodFOSYE8OERGRahQPOWfOnEFGRgbq168PAAgPD0dWVhbi4uIcZdatWwe73Y6wsDBHmU2bNsFisTjKREdHo1WrVqhTp46jTExMjNNrRUdHIzw8XOkmXZXjdBURERGppsohJzc3F/Hx8YiPjwcAJCUlIT4+HsnJycjNzcWUKVOwbds2nDx5EjExMXjggQfQvHlzREZGAgDatGmD/v37Y9y4cdixYwe2bNmC8ePHY9iwYQgKCgIAPProo9Dr9Rg7diwSEhKwaNEizJw50+lU04QJE7BmzRp8/PHHOHz4MKZPn45du3Zh/Pjx1fC2VBP25BAREalHVNH69esF5LnRTrdRo0aJ/Px80a9fP1GvXj3h5uYmGjVqJMaNGydSU1OdjpGRkSGGDx8uvLy8hNFoFKNHjxY5OTlOZfbu3St69eolDAaDaNCggXjvvffK1GXx4sWiZcuWQq/Xi9DQULFq1aoqtSU7O1sAENnZ2VV9G65oz7t3CTHNKHYvn1WtxyUiIqLKf39LQtTc7gaTyQRvb29kZ2dX6/ic+Bl3o5M5DvFdZ6DToOeq7bhERERU+e9vXrtKAcVjcmpufCQiIlIfQ44CSoYdM+UQERGphSFHAZxdRUREpD6GHCUJu9o1ICIiqrEYchTBnhwiIiK1MeQoimNyiIiI1MKQowR25BAREamOIUdJ7MghIiJSDUOOAhzr5DDlEBERqYYhRwFcJ4eIiEh9DDkKcKyTw4xDRESkGoYcRTHlEBERqYUhRwG8dhUREZH6GHIUIF06WyWxJ4eIiEg1DDkKKJldRURERGphyFESz1cRERGphiFHEVzymIiISG0MOYpiTw4REZFaGHKIiIjIJTHkKIljcoiIiFTDkKMAIXF2FRERkdoYchRQPOxYYk8OERGRahhyFMB1coiIiNTHkKMk9uQQERGphiFHEVwnh4iISG0MOYpiTw4REZFaGHIUUDy7ioiIiNTDkKOA4ogjOCaHiIhINQw5ChAck0NERKQ6hhwlsSeHiIhINQw5SmBHDhERkeoYchTFnhwiIiK1MOQogl05REREamPIURLH5BAREamGIUcR7MkhIiJSG0OOotiTQ0REpBaGHAVwxWMiIiL1MeQowBFxOCaHiIhINQw5Cihe8ZgRh4iISD0MOUpiTw4REZFqGHIUwTE5REREamPIURR7coiIiNTCkKMEzq4iIiJSHUOOkjgmh4iISDUMOQrg7CoiIiL1MeQoSGLMISIiUg1DDhEREbkkhhwFcMVjIiIi9THkKIDXriIiIlIfQ46S2JNDRESkGoYcRXB2FRERkdoYchTFmENERKQWhhwlcEwOERGR6hhylMQxOURERKphyFEEe3KIiIjUxpCjKPbkEBERqYUhRwGCPTlERESqY8hREsfkEBERqYYhRwkS18khIiJSG0OOAiTHT8YcIiIitTDkKIDRhoiISH0MOQqQivtyOCaHiIhINQw5CuDsKiIiIvVVOeRs2rQJgwYNQlBQECRJwrJly5z2CyHw5ptvon79+vDw8EBERASOHj3qVCYzMxMjRoyA0WiEj48Pxo4di9zcXKcy+/btQ+/eveHu7o7g4GB88MEHZeqyZMkStG7dGu7u7mjfvj1Wr15d1eYoozjjsCeHiIhINVUOOXl5eejYsSNmzZpV7v4PPvgAn3/+OebMmYPt27ejVq1aiIyMRGFhoaPMiBEjkJCQgOjoaKxcuRKbNm3CU0895dhvMpnQr18/NGrUCHFxcfjwww8xffp0zJ0711Fm69atGD58OMaOHYs9e/Zg8ODBGDx4MA4cOFDVJhEREZErEtcBgFi6dKnjsd1uF4GBgeLDDz90bMvKyhIGg0H8+uuvQgghDh48KACInTt3Osr89ddfQpIkcfbsWSGEEF999ZWoU6eOMJvNjjIvv/yyaNWqlePxI488IgYOHOhUn7CwMPH0009Xuv7Z2dkCgMjOzq70cyojduZIIaYZxbbvXqzW4xIREVHlv7+rdUxOUlISUlNTERER4djm7e2NsLAwxMbGAgBiY2Ph4+ODbt26OcpERERAo9Fg+/btjjJ9+vSBXq93lImMjERiYiIuXrzoKFP6dYrLFL+OqngVciIiItXpqvNgqampAICAgACn7QEBAY59qamp8Pf3d66ETgdfX1+nMk2aNClzjOJ9derUQWpq6hVfpzxmsxlms9nx2GQyVaV5VcchOURERKqpUbOrZsyYAW9vb8ctODhYoVdiTw4REZHaqjXkBAYGAgDS0tKctqelpTn2BQYGIj093Wm/1WpFZmamU5nyjlH6NSoqU7y/PFOnTkV2drbjdvr06ao2sUoE7Ioen4iIiCpWrSGnSZMmCAwMRExMjGObyWTC9u3bER4eDgAIDw9HVlYW4uLiHGXWrVsHu92OsLAwR5lNmzbBYrE4ykRHR6NVq1aoU6eOo0zp1ykuU/w65TEYDDAajU43ZRQvBqjQ4YmIiOiqqhxycnNzER8fj/j4eADyYOP4+HgkJydDkiRMnDgRb7/9NpYvX479+/fj8ccfR1BQEAYPHgwAaNOmDfr3749x48Zhx44d2LJlC8aPH49hw4YhKCgIAPDoo49Cr9dj7NixSEhIwKJFizBz5kxMnjzZUY8JEyZgzZo1+Pjjj3H48GFMnz4du3btwvjx46//XblejrNVTDlERESqqeq0rfXr1wvI395Ot1GjRgkh5Gnkb7zxhggICBAGg0H07dtXJCYmOh0jIyNDDB8+XHh5eQmj0ShGjx4tcnJynMrs3btX9OrVSxgMBtGgQQPx3nvvlanL4sWLRcuWLYVerxehoaFi1apVVWqLUlPIt34xWohpRhH7zcRqPS4RERFV/vtbEqLmLstrMpng7e2N7Ozsaj11te3LMeh54XdsazgGPZ/8tNqOS0RERJX//q5Rs6tulJJrV9XY/EhERKQ6hhwFSLx2FRERkeoYchTBdXKIiIjUxpBDRERELokhRxHsySEiIlIbQ46SBFc8JiIiUgtDjgIEr0JORESkOoYcIiIickkMOUREROSSGHIUIDku0Ml1coiIiNTCkKMAwdlVREREqmPIUQKvQk5ERKQ6hhxFMeQQERGphSFHScw4REREqmHIUQTH5BAREamNIUcJHJNDRESkOoYcRbAnh4iISG0MOUriOjlERESqYchRAq9dRUREpDqGHEWxJ4eIiEgtDDmKYE8OERGR2hhyFMFrVxEREamNIYeIiIhcEkOOErhODhERkeoYchTBMTlERERqY8hRkMSeHCIiItUw5ChC7snhuGMiIiL1MOQoQSr+wZRDRESkFoYcRXBMDhERkdoYcpTE81VERESqYchRAq9dRUREpDqGHEWxJ4eIiEgtDDkKkIpnV6lcDyIiopqMIUdBPGlFRESkHoYcBQipuCeHfTlERERqYchRQHEPjsTZVURERKphyFGA4IkqIiIi1THkKIARh4iISH0MOQoQXCeHiIhIdQw5CnBEHI7JISIiUg1DjiLYk0NERKQ2hhxFsSeHiIhILQw5SuCYHCIiItUx5CiJY3KIiIhUw5BDRERELokhRwmXTldJHJNDRESkGoYcRfAq5ERERGpjyFEQe3KIiIjUw5CjiEs9Ocw4REREqmHIUYJU/IMph4iISC0MOQpixCEiIlIPQ44ipFL/JSIiIjUw5CiBKx4TERGpjiFHScKudg2IiIhqLIYcRbAnh4iISG0MOUREROSSGHIUwCE5RERE6mPIUQSvXUVERKQ2hhxFcMVjIiIitTHkKIErHhMREamOIUcRvAo5ERGR2hhyFMSeHCIiIvUw5BAREZFLYshRQvEcco48JiIiUk21h5zp06dDkiSnW+vWrR37CwsLERUVhbp168LLywtDhgxBWlqa0zGSk5MxcOBAeHp6wt/fH1OmTIHVanUqs2HDBnTp0gUGgwHNmzfH/Pnzq7sp14EL5RAREalNkZ6c0NBQpKSkOG6bN2927Js0aRJWrFiBJUuWYOPGjTh37hweeughx36bzYaBAweiqKgIW7duxQ8//ID58+fjzTffdJRJSkrCwIEDcddddyE+Ph4TJ07Ek08+ibVr1yrRnOvAnhwiIiK16BQ5qE6HwMDAMtuzs7Px3Xff4ZdffsHdd98NAJg3bx7atGmDbdu2oWfPnvj7779x8OBB/PPPPwgICECnTp3w1ltv4eWXX8b06dOh1+sxZ84cNGnSBB9//DEAoE2bNti8eTM+/fRTREZGKtGkqmFHDhERkeoU6ck5evQogoKC0LRpU4wYMQLJyckAgLi4OFgsFkRERDjKtm7dGiEhIYiNjQUAxMbGon379ggICHCUiYyMhMlkQkJCgqNM6WMUlyk+RkXMZjNMJpPTTVnsySEiIlJLtYecsLAwzJ8/H2vWrMHs2bORlJSE3r17IycnB6mpqdDr9fDx8XF6TkBAAFJTUwEAqampTgGneH/xviuVMZlMKCgoqLBuM2bMgLe3t+MWHBx8vc0tl1TclcOMQ0REpJpqP101YMAAx/0OHTogLCwMjRo1wuLFi+Hh4VHdL1clU6dOxeTJkx2PTSaTYkEH4FkrIiIiNSk+hdzHxwctW7bEsWPHEBgYiKKiImRlZTmVSUtLc4zhCQwMLDPbqvjx1coYjcYrBimDwQCj0eh0U4Qkv62CXTlERESqUTzk5Obm4vjx46hfvz66du0KNzc3xMTEOPYnJiYiOTkZ4eHhAIDw8HDs378f6enpjjLR0dEwGo1o27ato0zpYxSXKT6G6iSnH0RERKSCag85//3vf7Fx40acPHkSW7duxYMPPgitVovhw4fD29sbY8eOxeTJk7F+/XrExcVh9OjRCA8PR8+ePQEA/fr1Q9u2bTFy5Ejs3bsXa9euxeuvv46oqCgYDAYAwDPPPIMTJ07gpZdewuHDh/HVV19h8eLFmDRpUnU3h4iIiG5R1T4m58yZMxg+fDgyMjJQr1499OrVC9u2bUO9evUAAJ9++ik0Gg2GDBkCs9mMyMhIfPXVV47na7VarFy5Es8++yzCw8NRq1YtjBo1Cv/73/8cZZo0aYJVq1Zh0qRJmDlzJho2bIhvv/325pg+jtI9ODxdRUREpBZJiJp77QGTyQRvb29kZ2dX6/icHQvfRY/D72NXrTvRbcqf1XZcIiIiqvz3N69dpYTia1exJ4eIiEg1DDmK4JBjIiIitTHkKEhiTw4REZFqGHIUIEnsySEiIlIbQ46i2JNDRESkFoYcRbAnh4iISG0MOUpiRw4REZFqGHKUwCnkREREqmPIUYB02U8iIiK68RhyFCAuxRv24xAREamHIUcBkuMq5Iw5REREamHIUVLNvSwYERGR6hhyFMHROERERGpjyFHCpfNVPF1FRESkHoYcBTHiEBERqYchRxHsySEiIlIbQw4RERG5JIYcJRTPIWdHDhERkWoYcoiIiMglMeQoQKro2lWHVwGfdwbOxN3wOhEREdU0DDk30sJHgcwTwK9D1a4JERGRy2PIUcLV1skx597AyhAREdVMDDkK4HrHRERE6mPIUYBABWNyiIiI6IZhyFEAe3KIiIjUx5CjhOIxObwKORERkWoYchTEiENERKQehhwl8CrkREREqmPIISIiIpfEkKMEiUOPiYiI1MaQo6iKTlfxNBYREZHSGHIUIIFXISciIlIbQ44SeLaKiIhIdQw5iuDsKiIiIrUx5ChAYlcOERGR6hhyFCBp5JAjuOIxERGRahhyFODhpgUA2OwMOURERGphyFGAuyPk2FWuCRERUc3FkKMAd/bkEBERqY4hRwHueh0AwG63lx90OFaHiIhIcQw5CigekwMAuWarijUhIiKquRhyFOCmld9WCUBOoUXdyhAREdVQDDkKyym81JPDQchEREQ3FEOOEi5dhVySRKmQw9NWRERENxJDjiJKVjx2nK5iyCEiIrqhGHIUJEEgPccsP7BzbA4REdGNxJCjBKmkJ+dURr58x8aeHCIiohuJIUdBraVkXExLlh+UPl0lbOpUiIiIqAZhyFFCncYAAG8pHxOTx8vbSp+uslu5ICAREZHCGHKUUL8ThEYv37WnITf1GLBmqnMZO3tziIiIlMSQowRJgvT4MsfDvD//Cxxa7lyGA5GJiIgUxZCjlMa3I67eQwCAgJT1ZfdbCm5whYiIiGoWhhwF6cKfhk1I5e/MSb2xlSEiIqphGHIUFNqxB151+y+22EKxpslUiHHrAXdveafpnLqVIyIicnEMOQrSaTVoe/djGGF5Dc8cao+laf5Awx7yzhyGHCIiIiUx5Cjs8fBGePqOpgCAN/9MwCmL3JMj2JNDRESkKIYchUmShCn9WqF74zrINVvxxzF5fZzCzbOBpH/lAcjWIpVrSURE5HoYcm4AnVaDbx7vhog2/lhuvw0m4QkPaxbww33AO4HArB4MOkRERNWMIecG8fHU49tR3bHu3bH4us6LzjsvJgFp+9WpGBERkYtiyLnBJEnC3Q+OQR/zp5htvb9kx4b31KsUERGRC2LIUUHXRr4IDe2I961DsRD95Y1H/waO/aNuxYiIiFwIQ45KPni4Azo09MGHhQ8gDXXljcueAy6eVLVeREREroIhRyW13d3ww+geqBvQAPcUzsBJTQiQmwb8Pg44tBLY9BGvVE5ERHQdbvmQM2vWLDRu3Bju7u4ICwvDjh071K5SpdWppce80T3gYayLxwpeRL7kCZzZASwaAax7Czi1Ve0qEhER3bJu6ZCzaNEiTJ48GdOmTcPu3bvRsWNHREZGIj09Xe2qVVoDHw98/0R3XHQLxDtFw5x3XjiiTqWIiIhcwC0dcj755BOMGzcOo0ePRtu2bTFnzhx4enri+++/V7tqVRIa5I3Zj3XFUnEHEu0NS3asnAhs/hQ4n8heHSIioiq6ZUNOUVER4uLiEBER4dim0WgQERGB2NhYFWt2bfq0rIe3H+6GwdZ38KZlVMmOf6bLiwXOGwAkrlGtfkRERLeaWzbkXLhwATabDQEBAU7bAwICkJqaWu5zzGYzTCaT0+1m8lCXhvhsRE/8KzqXX+Dv1zgYmYiIqJJu2ZBzLWbMmAFvb2/HLTg4WO0qlREZGohFU4ejn/sCHLU3cN6ZcQxI3lb+EzOTAHOu8hWsLnb7jXutExuBVS/K1wm7VQgBZBxnqCUiug63bMjx8/ODVqtFWlqa0/a0tDQEBgaW+5ypU6ciOzvbcTt9+vSNqGqV+dd2x6/j78GaO/7E05ZJWGfrhCT7pR6ref2BLZ8DueeB3EsDrE/vAD7vBCx7VrU6V8maV4EPmwHZZ27M6/14P7Dz21trVemN7wNfdAH+/VjtmhAR3bJu2ZCj1+vRtWtXxMTEOLbZ7XbExMQgPDy83OcYDAYYjUan282qrpcBz/dtgfuHPo0xlpfwunVMyc7oN4CPmgMftQAS/5LH7QDAoeUlf/nnpAIH/rixPSaVtW0WUJAJ7Jh7fccx5wKLRwHfRVaqlyb3yMbre70bacMM+ee6t9StBxHRLeyWDTkAMHnyZHzzzTf44YcfcOjQITz77LPIy8vD6NGj1a5atRnYoT6SZtyLQQ8Mwyz7EBQIvXOBX4cBp7aUPN78ifyFv2Q08NtoYPsc5/L5mSU9QJV1Lh7Y9X31nDqx20rum3Ou7xTbnp+Bg8uA09uAk5uvWrzo4tlrfy2q2bLPABeOqV0LIqqiWzrkDB06FB999BHefPNNdOrUCfHx8VizZk2Zwci3OkmSMCysMYa9NBsr7tuNYZqPkGyvV37hmP8Bv40Fki9NOd/0oRwkMk/IvTrf9gW+6imHHUDu7dl1acr9sX+AM3Fljzn3DmDlJGDpM0DSv/I2m7XqYQlwfs6u74HZ4dccniwZJx33zydsuGp5H+sFmK02ZOUXXdPrVauivAp3ZebdBPW7Ecw5wPLngePr1a7JlQkBfBoKfNkVKMhSuzZEVAU6tStwvcaPH4/x48erXY0boq6XAY90D8YdrUbit7i7sGL3KTTO2IQumqPooTmETpoTcsHEVSVPKsgEZjQoe7DDq4CQcLm3BwA86gBLnpDvP78bSD8I7PgGGDy75Dn7Fsq3qB3Anp+ArV8Aj/0ONI8oc/gKHVzm/DgrGSjMBjx8yi1eZLXjm793o3+IQLN23Z32paSlIOTS/SNx61HrXis89c7/S+earfC6dF8DOx78cgsOpuZgx2t94V/bvfL1rk7//J/c4/bkOqBh1zK7U7ML4atCtW64TR8Bu3+Ub9Oz1a5NxazmkvvZpyv8f5WIbj63fMipiQKM7oi6qzmi7mqOn7c1x+r9KZh37jx8C09hkDYWQ7UbYIUW9aQrfHEsvywYFgccQB7wWizmf2WfO6tHyf1FjwN9XoT14Cps6DYLd3duDY1Gqvh117xSdlvehQq/OH7ffQbtYieh2Y59EF6rIDXu5dhXmJPpuN9CcxZL95zFiLBGTs9Pu5jjCDkAkJ56Bj01Z7F1XzAG396h4noqafMn8s/oN4DRq8vszi+ywiK0cJNsZfa5lIwqnP4pNAHuKo2hKyp1SlW6pTu/qyTPbEXKxRw0l84B/m0B6Qr/roluUjXnX6yLeqxnI/wyridipw3Ce1EjsbvlJDzo9TO6m2cjrPBLzLYOwgzLcIwsKidcVMa+hVfeb8kDYv4HXUocIlb0xN4fXgRsFvm01J9RQPQ0IP0wsHdhxado8so57ZX0L7DgEeSnncAd2n0AAGn+QOBUyUKPOnNJiPOXsqApzCpzmIyMDKfHT+pWY6H+bdy95bErt+sqzmUVILvAcl3HgCh/UHiu2Qoz3Kp2rMwT8mBzV7Tlc+C9YLn3UQ2lQ461UJ06qOC1pfux48vRwOzbrn+SAACYzl2aDOHi4Z1uKuzJcSHtG3pj7uPdHI9zCi345t8wrNufAh9PN9x1qh6e0/2J/VJrhIs9GKDd6fT876wDsNfeFJ/rZ11zHTqf+g7mT/6CIe9cycYtn12qUAVfwpkngPXvAk36AH2mACc2AD8NBgDc73HUuezPQ4CXTwI6PfQW58Uc659aDswZD0RMc5xCy8zKdCrzjG4FAMCYf+oaWidLMxXi7o83wNdTj+XP94Kfl+HaDiTsQMxbwNG1QOS7gHdDwLcpcs1WFJX+p2m3ARptxcfJzwQ+v7SA5M182udylRiLJYSAFP2G/GDZs8AryQpXqhylB8cX5d/411fJsvhz+Mz90nip9e8CYU9f3wHn9ALyM4D7PgW6jbl6eaJqwJDjwmq7u2HyPS0x+Z6WAIAzFzvBU/84WmTm45PoI/gwMx/Z+UWoW3ACx0UQarkbMP7u5vgreodTANpnbwI/KRtBUmZFL+XEKeCU9s80+ad3MESLfpB2fSc/XvcOkHMOOPkvENAOWDjc8ZR6BSecj2HJA478BWQmwdMmf6FfkOrAT1zEnSc+ksv8PMTxZZ+VlVVxRYUo2wX/7yfAuT3Ag18Des9yn7Zz/yH0sW1HdHZXLNiWjAkRLSp+jSux24B/L9X5h0Hyz+nZyDNbUVS6J6cgC6hVF2mmQny25G881rQQoXc9UrK/9IVcLQWAm0fZ1yrKA/S1rlwf0zng9yeBHuOAhGXyOK1Bn11Dwyrr6iHnzT8T4JhE73aV+l+Lc/HAoRVA78kVvz+leyAtNSfktNOWBEohaXDdJ6vyL/WqHlnLkEM3DENODdKwjvyl7VtLjx/HlIyr2XrsAlbsO4eB7YPQq4Uf0GstFu04iT/+XIpceCBBNAYAGJGLfe5PlTluVcePJJmNuHd7P7wuTmKELkYOOMVKBZzS4u3N0EA6j3qSCVj8uNyOS/sSvG7DHTnOpzLMPz0CQ+Mw5JoaokJmE+DuDVw4CtSuD7vdBk3M/8n7Gvcq9y/X/CIr2v/zGO7Tn8EUy1PISsoHDiUCbe4Djv4jn84w5wA7vwEe+VHunSmt9LpF5pyydbIUIKfQCjdYHZtEVjKkWnUx48/d+Oz0SOA0gFYtgaBOl45ZUhb5GWVfc+MH8kKIo1YADbvJs+Sa3QV0edy53Jqp8nIEpZck6Pc2YPCC4ux2QFP27PlP207hreLx4eWFt8ooypeXGWjUC9BdtgTD3Dvkn5IEtB0MnD8MtH/4sueX+pyUCjlCAGd3A/6trx5Gb5CVbiWnuAWk6w85DhzbQzcOQw7htuZ+uK25X8kGjRZDezZD+5CnsOf0RdzRsh5qG9yQY7bgp+hvsC7+CDRaLfr0DMfMzanwqu2DQF9v7D6Zjp6aQzgpAtBbsx8z3L4r9/V8C5JQYLEhSVv+ytTlmWMdhHG6VXLIuUxaUF/nGWUADMfXAsfXwr3e5IoPakoBTu8EFgwB2j2MTbrbcGfxvsMrgTqN5b/iQx909PhsTDyPAUJeqflDt7nA2bnAIgAjl8nHKW3FRODRRcDWz3HRvydOb/oBbTyyHX001owTZf8BfnM3vANegAdKppHnpiSidoPOaHCu1AVa0w6UhJy8CyXb8y7Ip1f2LwF6T8a2M4Xouf4ded8/04GuTwAJf8i3y0NO5vGy79G3fXF6aDTWHLyAET1D4JlxUA5BPZ4qewrNnAuc2QHUawMY65dszzgOy47vYb7tRXh5VzBvzFpQ7pe7hFKhsIKetava/Cmw6QN5NuHov4CUeHlmV99pjiIidR+kTR/KD7z85VOnxUr35FRwuuqT6CM4n1OIdx9sD+laBujuWwwsfUo+zfrY71V//vUqr1ez9G4GE7pFMeRQhdoGGdE2qGRGi7enG0Y+8ggeHmxDjtkC/9ruGDWwpLzNLjB3Uzt0NFtwb/uHYMJzOLZwCv57/l4ESBfxidts1Jcy8Y9dnjb9k+0e3Kfdhk6acr5cS7kovLDO3hmvYUG5+zTN7saZw35oKF0os/+x859UfOCFj5Z8sR/4DZkio+SPzKRN8g2QA0WTO4AmfZCRfKj8Y+39tey2MzvlBQv/mY46AOpctlsnyhm4nH4Q/0l/xumP3ZOJ+9C+2zAE20sug2E3pcqzBlZMBOLmObbHHTqKLrtfg5SXBuSlY9jWSJx09IS4y71XxQqz5Z4sQD5tk7q/bH3OH8Y387/D/gwJJ87fjRn7e8vb9bWcQ9K6t+U1mYrd+SrQayKgM0B8cxfcCrMRu2sXwl/4AW7GAPnUmNPCkLlOIedsVgE+XHMYvijVi6K7xp6cs7vkn8mxQE6KfDozPwM4n1hSJBdw9H+l7HMOOaXH5JTTk2O12fF5jDx27O+ENEy8pyVG9mxUptwVxX4p/zz2j/P2vAtA0kag9aCyvVDVJWkTsGgkcO9HQIf/ALg0FqpUEbsArjAq7Op4DTZ12KzAqc1Aw+43TQ/hjcaQQ1XmodfCQ1/2V55WI+HZO5uV2uKNLpOXIkYI/LrjNF6L74Yxnv9iyIPP4QGPuiiy2fHoHG/0TFuEs8IPQwNT8Ht6fQw3bEEP2x4AcojpZZuNdS9H4OQXjRBsP+/0mjHa29EyqA5+t/XGBN3SCut80Lcv2mbGOG+8rOfiIamCRen+/dhxDakK52TtW1R2W2EWjm1bjuYV1qpyfI4vg2W1QBPryZJDH1kHz07DnAIOAHT998mSB7t/RGOpY8ljt1oQRXklX14/DwGe/EceEF582qYc/8udDhiAvXt/KJmPufx5oN3Dcu/KxZPOAQcANrwr9wz0mQKpUB4f1ce2DbYvugBdRpSdrbNgCPBMyarVU5bsxe7j59BcKjU7rnTA2PGNfJquZyWu11ZYKth90qbkfkbJoPak9OySkKO57NfiVcbklJ5ll5FXhDeWHah6yLFVsADkgoflMWJ3vwH0+W/VjllZi0YChVnAH0/KIacwG9bdC5zm99kgVXW+n7OKLruSlgBs/RK482W551Rpx/6Rx5o1KLs+lUva/Amw/h2g9X3AsLJ/JNYEDDmkOEmS8GhYCB4NCwFwNwD5fzydVoMlUXfi+PluOHjOhNs7N0AvSQKEQP7Gz7H8hB3JPj2w+o5OaFjHE37jf0TGmul4bH9nvKb7GUYPPcJHfoCgBt7YHfY4ECeHnGFFr+MN3U8I1cgzqLJQG80e+wxxc8eha2EFV3G/JEX4YrOtHf6j21QtbW9+/p+rF7qKYPtZYMdXCCu1zfPsFnkV3qtYqi85JYMjf0E68lfJ4zM7cTH1JHySoyt1MqKj5rJB4H+/DoT0BFZMKP8J69+Rb6VorXnlT0dO3V8yiyx5G1omL8Iv7t87l8k4Jve+eNYFVl/6wr94Euj/3pVPteSkXLV99UWp8Gy97Au59JiczCT51FK7h+UxRDmpyDKVjCWSYEcr6QxEYTak4l6y8ly+7k/pBQdLOyeHfez9tfyQYzXLA88D2lX4HmTnW7Ak7jTu7xgEf2M5C2BeHkDWTIVbvPMXov16O2IKS836Kz2G7IdBcq9axlE5cCto38FD6LD40inlNy+WOwbM5Wz9Qv55eKW69VBRDfiU6WbmptWgdaARD3VpWDKWQZLgeecEDBszCS89dDsa1ZW7Wd19G6Duo99gxnOPYu/dP6LVSzFoENwYkiThiUF3AyOXYXHobHi1ugvGUb8itsFo/K/taqSPi4fBNwTt/rsa68J/wJLajyNPlEz7PmX3h1m4Ybe9OeY0/gypdzpf+dsuJNiEhHW2Tsgv9TzxzBa81GotnimaWG3vx157U8y2DnI8tojrOkmAOtKVrw1WZ05HSKuvsYdg13fAH+OqbzCu6Sws548B30diuvb7svuthfJClPuXlGzbPkdefTv3vDzG6vIL0trtsJuuvn5QiK3U1PT8DKd9mRcvljyImye3+YvO8iVQPmsP37UlC2u+pluANYZXIObeVf4pmsOrgene8ro/e34u1bZSIae8i+pWtAjhXy/LU7PL60m8ZPqKBLy96hCe/HFX+QUuD0cHyo4J0loqWOPqwO/Ax62BU1srfH0AziGn9CnT4vf6zM6S9bUU8uZPf5c8yDp59SeciZMDfF7G1cveDOJ+AE5ucd7G04TsyaFbT6dgH3QK9im7o9ldeKQZUDy5OrjZZyh9PXqDTou7Iwcj546BWLL5CRxLPoM7e3RDi0Bv3D57KzQaDX4aEAb/2gY8t+cTPI3fkXvn/yFb44NmDQLRu14trNt/Cs1PLUSz7gMgBbbDGw9a8JGnFz4+UIAXLV8DAH613oWPrY9ghPYfPKT9F4008i/umdYH0UNKRCftMey5fTY6b3kObrBAd2lwbY7GGx/7/g85khE9PXzQrl0nTFl+HJ/pv3K04bzwxhZ7KAZrr/yl8mTRi+ij2YfHddHl7k8XPvCXsirzdgMADtlD0Eaj7Bo1tu/vxVLvx/HIVcrZ/37D+a+z5c+X3O88EmjRDzCbsGnvUWjS96EXrj7zT49S46O2foEVB7MRbWkPu8EbX2Z+UfYJF08C38q9knWS10KHEaiDHDypk3vKNJnHkX82AVHR+Rhc/yIe6N4cqNvMefbgn1FAy/5ALT9YiwpKfhkXZgGevsjIMqFu8TbpUti1WeXeruJgUny68p//AzoMBbbMREHdtoDOHR5BocCChxF2pg6WYTT2nXFeQ6nIakeu2QrfMv1cZXuEDPZ8wFpUdlzQb5emgi99GphYzpguR5tKvXZh2ckDQtIgb+kkeB34GXgyptzLnZRhKZAvnOpXuSUcfEoH/rSDgG9TIHmbHBQHvC/3SgIlg7Avfb4ouAgEdQZaDQTqtbz6C104Bvz8IBD+PBD2lDxeLf0Q8J8fAK1CX7kntwArXpDvO62VVU7IEUKexl+/o/MEgVLsdnHlletvIZIQNTfqmUwmeHt7Izs7G0ajSkvG003BbLVBp9FAe43/sG12ga3HzqOxPRn+TUKh1Rlw/HweYg6noV/ruvhqxRbU9m+MVvUMiGhWC/4BQUBWMo6lXsTrP69HlO9O9I6aAxhqOx13T/JFHD0Ujy2pGni4e+KFvs3w5IIEnEk5h1lun8NHysVM6xCMrJuIjLCXMcA/A7aiAnT6BbDaBfxxEQUw4DHtP+ij2Ydz8EVd5GCGdTjWGkqmCC+R+mFKwRP42O0rDNFuhl3SYlDh/zBatxb/2Lpgvb0TxmpX4yW3xQCAedZIjNatLfe9WGy9A4/oNjptm2W9HwFSFh7WVs9pwJvNNMso/J/bD07btrX8L5IOxmG4bj3snvXwfpvfMTWuj1MZq+SGnDvfQp31JZ9F9tht+OmQHYHWZDy8YxgAwObTGNqxf8M6qyeEdwjcQgfJA78/qvgLXgSEQkpLAABMsTyFJbY7cfLhNIg1U5Hi2QqpFk90KYh1flL3cfKFc4UcDDNEbehhRW2pALjvM/laeGHPAm4eMO34Gca/LvViudUCXjsHZJ+Vr0UW/lzJoHYAqbv+RODKUgPVJx0EvBvIvVqX6/QYMPgqC5LabTi/6HnUS1yAvId/Qa12l2ZACAEU5SFfckdGbhGCfT2B7V8Deefx3xgTPnKT/xDBna/K44DeqS/3RLr7AK+cAg6tBBaPBB7+3vlSNwCgcwdeTyt5nH4IiF8AtBsiv26DS5fDWTQSOLRcvv/mReB/l6YcjPgdaFGF6/w52mqXT/Hp9HIo+/1JoN9b8qzPYrFfAWunyvdfPy8PsvdvA+unHaGzXeppLQ4/B/+Ul+HwbQq8sKfMy730215sPnoBfz/iBa/tnwD3/A/wayn3uiWuBtr/R17OQQggNw2oXflZstWpst/fDDkMOaSydFMhjB5ucHer/Kkpq82OnEIrUrIK0MivFjzctE5/eR1Lz4HFJrB412k82LkBsgss8NRr8fvus1h7IBWrXuiN2m52uO//GdoW9wC+TSCEgCm/CEZNPoTBBwdTTNh2IgPbTmRicOcgfLDqAO7KXYkEz27Yk+eH5zVL0Ek6jiDpAi4Ib3RyT4Fu0Mf4b0JTnNu3Dr8Z5OuenWz8H6wOmYK0I7swLSUKa+zdsdbWDS01Z/C3rRsm635zXLqjtEP2EEy3jEKENg59NPvQSlNqdpmQ8KLlGXyqn13meeW5Uii7UWxCgla6+q/bldq7cZ9tXZntaQ36IeDs3+U8o3I22DqinSEVfta0qxe+JMHeCGmiDu7Wxpds7DgcaHqn3Htzid3gDc3jy4Bv7pI3tBsC2CwQ3sFI7z4FZ2PmoMvB95wP/tQGYO6dZV+082PAA7OADe8D22YBT6wGAtvJM/KykoHDKyF2fgfp0mnSC+4h8HviF2Dtq3KPUcpezK0dBePFBNx1zyAErH+x/Mb5tQIulMyww9ho4Lt7rvyGTMuSVxjX1wI+awfklRrL9UI8sPF955mWwWHA6e3y/QdmyW2zFMjLGphzgP2/yctMFAek0nLPI61Qg4vzh6NxwUEYHvoS0rq3Sq75Ni2rpEcv5q2ShUUvsQV0gDk1EZ6SuaS83Qq8VWq5kHJWSG/8irwcxxGvp6C3Xur9Ch9fMgOwyyjg/s+BbbPlaxEOng10ehQ4s0uum7EB0KT3ld/HasCQUwkMOVTTFP9zv5a1XFKyC5BbaEWLALm36YuYo0jKyMPTfZqhXm0DfD3dHL90405dxOzFKxDV3Qud73wIAFBQZMOi9TvQPbQFmvj74JftyejRxBc2u8Dby/eiY8pveNPtJ1iFBg/YP8AbTzyII+m5aFbPCxO+/RvP6f6ECZ7oJB3HfFs/bLB3wru6b/Gobj1+tvbF77Y+GKzdjFGXTtFlCi8ssEVgvvZhZJg1CEQGbtMk4AHtVqywh+Mp7Up8an0Y9aVMvOn20xXbbhY6fGe7FzvsrTBf/2G5ZbJELfxouwdx9lZ4x+27cpc0uNUc0LbFUnNXvKG78vtzJYftwWitOQ1A7hmqK5WzCGZpHr7Ac9uAj+VTQ/bW90MEh0Eb/Vq5xU0ab+g8jPDMO33Ndays7E5Pwzv+62t7ct0WwPid8umxHSXHEN7BsL+wF+u+nQp/n1roOOQVeTD5t/fgvL4B6uVXcCFbTz/gkR8An0bAklHA2bgyRQqFG9ylS6diXz4F7PwWWPdWSYEnY+SZZqe3w/TvHBT5tUP4+hawQ8Jx95EVtyXsWWB7qT8wJh0EPm1b8viFPfI4uV3fy5fq8bveOaZlMeRUAkMO0c3h5IU8vL7sAOobDRjWvQGaB/jA27Nk0vKcjceRW2jFl+vlX/jP3dkMnnotTpzPw5oD5xDg7Yln72iGXLMVdzathX1b/sLnJ+pj8oB2iAwNhJtWg4t5RRj+zTYcTi37JdtJOgY9LDgt/PGQ9l/UkXKggw1tNMlYaL0LO0UrnBH+AIAu0hHkwgNHRDDcYcZP+hnorjmCtyyP4Tvbvejdwg+Hjh7HW27fo6PmOF60PIuv3T6BUZJnMe2zN0EHTRIA4CXLOHjCjDy4Y5OtA+br30cbTcmXtUVo8bp1DP6j3YhuGvnyHa9bRuNtt5KlA5y+yMox1zoQT+lKFsuMsXXGM5ZJGK9bhgm6P674uXzd9EscdmuN0ISP8YR2LXRS+ReVrazPrYPxgm7ZdR3DFR1v8xyaHfrq6gWvQ7pPJ/hnxZfd0bi3fEmd6mTwBoovoBz6EPCfeVcufw0YciqBIYfo1hJ3KhNrDqTixX6tHKf38sxWGHQa6LRXnyxqtwvkW2xYufccCi023NuhPpbuPosP1yailkGHUbc1xucxR2HQadCzaV3c3zEIqaZC1Pd2R06hFUIITF9xEEZ3HWKn9sUn0Ucwb/NxdKidg4/HDULyxQKEBhnR54P1KLTYMXNoR8zeeAI5qSfgIZnhobHinK0ObtckoL6Uga9t9wGQYNBpMKZXE3y94Sh8kQOjQcJ5sw61kQ/JJxhnswrQVDqHttIprLT3RCfpOO7W7kaOVBvzLfegmyYRu+0t0FA6j4e1m7DH3hyv637GIttdmGUbDAOK8LB2E+7U7MUblieQemlIswQ7OkgnkCp80U1zBO00SeiuSUSCvRGsnR7H4w/eh6x8Cx6esxVnM0yoh2w8pVuJUM1JCEj43Pogjtob4l23b+EvZWFU0ct4WrcSz+hWIk8YEGWZgK6aI3j+UrCZ4v81IlK+QaRWnum13d4a71uGYaLud8yz9cdQ7Qb00ewrOcVS0ecoJGjKOfV3yu7vGOhfkZvh1GVNYpd00Lx0HPDwqdbjMuRUAkMOEQHA+RwzbHaBQO9y1pEpRQiBlftSUK+2AT2b1oXdLrD3TBYCjO4I8ilZkXlP8kVkF1hwZyt/nMsqwNcbj2Ncn6ao7e4Go7sOF3KL4GXQQa/T4PfdZ1DPy4A+Levh1x3JaFTXE90a+eKd1Qexcl8K/prQG+sOp6OgyIbeLerhj91n8NydzZGWU4i6tfTYcjwDL/y6B28Nbocgb3dYbHasTUjD2YsF+HRYJwz9OhamAgs0GglZ+RY8GhaC/7s/FLmFVni565CaLYe4P+PP4a8D8nT73i38MOq2xk5t35CYjifmyRfu1Uhl185Z9FRPDJ0rr0N1W+PaeKi9H1YdycWmoxfQSJxFiHQe0ydPwHt/HcaahFS0kpKRKtVDtl1+37o2qoO4UxcdgcwOCUttvTBG+xckAD/ZItBVcxR1kINV9p4IlU4iB554UbcE3TWH8aplLNbau6OrdAS/6N/BAlsEDokQeMKMZbbb4YUCNNOcwxZ0hGS34jWdvBbQbZoE1JVM2GlvhXDNQcy23o+vbfchUrMTx0QDvKr7BQHSRYwqehm9NPsxU/8VzgsjIswfoRYK8bn+S3TTHMFM64OYaR2CztJRnBKBuAAjZrnNxEDtDsywDIevZEIbKRnJwh8GWBxrcR2xN0BLzVlYhQbvWEegneYkhmj/RbStC+pJWeikOYFoW1fE2VvgFbeFAOSZmhoIPK1dgRRRF/2L3kML6Sye0q3Ct9Z7MVf/iWP25BJrH9ymTUADKQNLbbfjbctj8JVycJdmD06JAEzRLUZ9KQPPWCahQOjxqG4dGkgX0E5KQq1ywuZhezBes4zBQv3bZa5ZOMXyFO7TbHMaY3fIHgLzoDno1P32K/7bqiqGnEpgyCGim1VVxk+ZCi0wupe/JnGhxQY3rQY5hRaczixA+4ZXWKTwKoqsdmgkuU6nMvKw5dgFhFxax+qOlvWQa7ZiQ2K64xRhcTv2nM6Ch5sWberLv2e3HruA/WezMax7CLzcddielIGODX1wONWEx7/bgbwiG169tzUe7hoMg06DlfvOIc1kxtN3NIUQwNurDmJD4nk8c0czvL7sAOrW0mNcn6ZYvT8FkaGBmLvxONo1MGJA+yA09/eCViPhy3XHEBkaiOwCC95fcxgAYNBp8MezPfH8gjicyDSjTX0jfhzTA99vScLaA6mYeE9LLNl1Gv8eLRlf5Q4z3GBDDjxxf8cgLN97DhLs8PU0QKvVID3HjNcHtsG5rEJ8v+UEgpCBc6iL0lPz9bDgBd0f2Gtvhmh7NxiRi1owQ/JugBRTIUJxAidFIDQQGKVdi4st/4OfD9nQTDoLAQknRBAAwAOFsEMDM5yn9gciAx01x5Eu6mCPaA4DLKgLE87BD5fTwA53FCEfzgFfDwss0MILhRiqXY9Ye+ilizULABIaSukAJJiEB7xQiD7afVhsuxMSBHSwQUCCB8xo2TgYv4zr6fj/obow5FQCQw4R0c3HZheOMHU1eWYrbEI4hTwhxBWfeyjFhANns9G+oTdaBxqx/0w2didfxPAeIdDryv8yzjVbEXs8A9tPZCAzvwgfPtwRGgnYczoLbesbHadPL+YVoU4tPSw2OxZsO4WU7EKMuq0xbHaBuFMXMbBDfeSZrUjOzEdokDf2n83Gx38nok19I/7brxV2J19EcmY+ejapix9jT6JlYG080i0YK/aew3ebk/BoWAjsdoG5/57AifN5aFqvFh7o2ADj+jSBh5sWi3aextqEVNzWzA99WtZDSnYBXvh1D9y0GnRrXAdmqx0bEs8jMjQA53PMOJ9rRr+2gdh05Dxqu+swJbI1BAR+2HoSQgDpOWYkpuagwCL32vh5GWCx2ZFdYEEDHw/MH90dG4+ch16nQZeQOsg1W7H+cDriTl1E9ya+GNe7KXxrVf911xhyKoEhh4iIbkWFFhtOnM9Dm/q1rxoGr3dxv4IiG7ILLAgwGmAXwKmMPMQcSkf/doHyWkQqqOz3N1c8JiIiusW4u2nRNqhyf5xf7+rFpS/KrJWApvW80LSe13Ud80bhtauIiIjIJTHkEBERkUtiyCEiIiKXxJBDRERELokhh4iIiFwSQw4RERG5JIYcIiIickkMOUREROSSGHKIiIjIJTHkEBERkUtiyCEiIiKXxJBDRERELokhh4iIiFxSjb4KuRACgHzJdiIiIro1FH9vF3+PV6RGh5ycnBwAQHBwsMo1ISIioqrKycmBt7d3hfslcbUY5MLsdjvOnTuH2rVrQ5KkajuuyWRCcHAwTp8+DaPRWG3HvZnUhDYCNaOdbKNrYBtdR01o5/W2UQiBnJwcBAUFQaOpeORNje7J0Wg0aNiwoWLHNxqNLvs/aLGa0EagZrSTbXQNbKPrqAntvJ42XqkHpxgHHhMREZFLYsghIiIil8SQowCDwYBp06bBYDCoXRXF1IQ2AjWjnWyja2AbXUdNaOeNamONHnhMREREros9OUREROSSGHKIiIjIJTHkEBERkUtiyCEiIiKXxJCjgFmzZqFx48Zwd3dHWFgYduzYoXaVKm3Tpk0YNGgQgoKCIEkSli1b5rRfCIE333wT9evXh4eHByIiInD06FGnMpmZmRgxYgSMRiN8fHwwduxY5Obm3sBWVGzGjBno3r07ateuDX9/fwwePBiJiYlOZQoLCxEVFYW6devCy8sLQ4YMQVpamlOZ5ORkDBw4EJ6envD398eUKVNgtVpvZFOuaPbs2ejQoYNjoa3w8HD89ddfjv2u0MbLvffee5AkCRMnTnRsu9XbOX36dEiS5HRr3bq1Y/+t3r5iZ8+exWOPPYa6devCw8MD7du3x65duxz7b/XfOwDQuHHjMp+lJEmIiooC4Bqfpc1mwxtvvIEmTZrAw8MDzZo1w1tvveV0fakb/lkKqlYLFy4Uer1efP/99yIhIUGMGzdO+Pj4iLS0NLWrVimrV68Wr732mvjjjz8EALF06VKn/e+9957w9vYWy5YtE3v37hX333+/aNKkiSgoKHCU6d+/v+jYsaPYtm2b+Pfff0Xz5s3F8OHDb3BLyhcZGSnmzZsnDhw4IOLj48W9994rQkJCRG5urqPMM888I4KDg0VMTIzYtWuX6Nmzp7jtttsc+61Wq2jXrp2IiIgQe/bsEatXrxZ+fn5i6tSpajSpXMuXLxerVq0SR44cEYmJieLVV18Vbm5u4sCBA0II12hjaTt27BCNGzcWHTp0EBMmTHBsv9XbOW3aNBEaGipSUlIct/Pnzzv23+rtE0KIzMxM0ahRI/HEE0+I7du3ixMnToi1a9eKY8eOOcrc6r93hBAiPT3d6XOMjo4WAMT69euFEK7xWb7zzjuibt26YuXKlSIpKUksWbJEeHl5iZkzZzrK3OjPkiGnmvXo0UNERUU5HttsNhEUFCRmzJihYq2uzeUhx263i8DAQPHhhx86tmVlZQmDwSB+/fVXIYQQBw8eFADEzp07HWX++usvIUmSOHv27A2re2Wlp6cLAGLjxo1CCLk9bm5uYsmSJY4yhw4dEgBEbGysEEIOghqNRqSmpjrKzJ49WxiNRmE2m29sA6qgTp064ttvv3W5Nubk5IgWLVqI6OhocccddzhCjiu0c9q0aaJjx47l7nOF9gkhxMsvvyx69epV4X5X/L0jhBATJkwQzZo1E3a73WU+y4EDB4oxY8Y4bXvooYfEiBEjhBDqfJY8XVWNioqKEBcXh4iICMc2jUaDiIgIxMbGqliz6pGUlITU1FSn9nl7eyMsLMzRvtjYWPj4+KBbt26OMhEREdBoNNi+ffsNr/PVZGdnAwB8fX0BAHFxcbBYLE5tbN26NUJCQpza2L59ewQEBDjKREZGwmQyISEh4QbWvnJsNhsWLlyIvLw8hIeHu1wbo6KiMHDgQKf2AK7zWR49ehRBQUFo2rQpRowYgeTkZACu077ly5ejW7du+M9//gN/f3907twZ33zzjWO/K/7eKSoqws8//4wxY8ZAkiSX+Sxvu+02xMTE4MiRIwCAvXv3YvPmzRgwYAAAdT7LGn2Bzup24cIF2Gw2p/8JASAgIACHDx9WqVbVJzU1FQDKbV/xvtTUVPj7+zvt1+l08PX1dZS5WdjtdkycOBG333472rVrB0Cuv16vh4+Pj1PZy9tY3ntQvO9msX//foSHh6OwsBBeXl5YunQp2rZti/j4eJdp48KFC7F7927s3LmzzD5X+CzDwsIwf/58tGrVCikpKfi///s/9O7dGwcOHHCJ9gHAiRMnMHv2bEyePBmvvvoqdu7ciRdeeAF6vR6jRo1yud87ALBs2TJkZWXhiSeeAOAa/68CwCuvvAKTyYTWrVtDq9XCZrPhnXfewYgRIwCo8x3CkEM1VlRUFA4cOIDNmzerXRVFtGrVCvHx8cjOzsZvv/2GUaNGYePGjWpXq9qcPn0aEyZMQHR0NNzd3dWujiKK/wIGgA4dOiAsLAyNGjXC4sWL4eHhoWLNqo/dbke3bt3w7rvvAgA6d+6MAwcOYM6cORg1apTKtVPGd999hwEDBiAoKEjtqlSrxYsXY8GCBfjll18QGhqK+Ph4TJw4EUFBQap9ljxdVY38/Pyg1WrLjIhPS0tDYGCgSrWqPsVtuFL7AgMDkZ6e7rTfarUiMzPzpnoPxo8fj5UrV2L9+vVo2LChY3tgYCCKioqQlZXlVP7yNpb3HhTvu1no9Xo0b94cXbt2xYwZM9CxY0fMnDnTZdoYFxeH9PR0dOnSBTqdDjqdDhs3bsTnn38OnU6HgIAAl2hnaT4+PmjZsiWOHTvmMp9j/fr10bZtW6dtbdq0cZyWc6XfOwBw6tQp/PPPP3jyyScd21zls5wyZQpeeeUVDBs2DO3bt8fIkSMxadIkzJgxA4A6nyVDTjXS6/Xo2rUrYmJiHNvsdjtiYmIQHh6uYs2qR5MmTRAYGOjUPpPJhO3btzvaFx4ejqysLMTFxTnKrFu3Dna7HWFhYTe8zpcTQmD8+PFYunQp1q1bhyZNmjjt79q1K9zc3JzamJiYiOTkZKc27t+/3+kfYnR0NIxGY5lf1jcTu90Os9nsMm3s27cv9u/fj/j4eMetW7duGDFihOO+K7SztNzcXBw/fhz169d3mc/x9ttvL7OMw5EjR9CoUSMArvF7p7R58+bB398fAwcOdGxzlc8yPz8fGo1zrNBqtbDb7QBU+iyvYQA1XcHChQuFwWAQ8+fPFwcPHhRPPfWU8PHxcRoRfzPLyckRe/bsEXv27BEAxCeffCL27NkjTp06JYSQp//5+PiIP//8U+zbt0888MAD5U7/69y5s9i+fbvYvHmzaNGixU0zlfPZZ58V3t7eYsOGDU7TOfPz8x1lnnnmGRESEiLWrVsndu3aJcLDw0V4eLhjf/FUzn79+on4+HixZs0aUa9evZtqKucrr7wiNm7cKJKSksS+ffvEK6+8IiRJEn///bcQwjXaWJ7Ss6uEuPXb+eKLL4oNGzaIpKQksWXLFhERESH8/PxEenq6EOLWb58Q8vR/nU4n3nnnHXH06FGxYMEC4enpKX7++WdHmVv9904xm80mQkJCxMsvv1xmnyt8lqNGjRINGjRwTCH/448/hJ+fn3jppZccZW70Z8mQo4AvvvhChISECL1eL3r06CG2bdumdpUqbf369QJAmduoUaOEEPIUwDfeeEMEBAQIg8Eg+vbtKxITE52OkZGRIYYPHy68vLyE0WgUo0ePFjk5OSq0pqzy2gZAzJs3z1GmoKBAPPfcc6JOnTrC09NTPPjggyIlJcXpOCdPnhQDBgwQHh4ews/PT7z44ovCYrHc4NZUbMyYMaJRo0ZCr9eLevXqib59+zoCjhCu0cbyXB5ybvV2Dh06VNSvX1/o9XrRoEEDMXToUKf1Y2719hVbsWKFaNeunTAYDKJ169Zi7ty5Tvtv9d87xdauXSsAlKm7EK7xWZpMJjFhwgQREhIi3N3dRdOmTcVrr73mNMX9Rn+WkhClliIkIiIichEck0NEREQuiSGHiIiIXBJDDhEREbkkhhwiIiJySQw5RERE5JIYcoiIiMglMeQQERGRS2LIISIiIpfEkENEREQuiSGHiIiIXBJDDhEREbkkhhwiIiJySf8PpszKkox0OioAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 5.82997  validloss 6.11904±0.00000  bestvalidloss 6.11904  last_update 0\n",
      "train: iter 1  trainloss 5.37213  validloss 5.59965±0.00000  bestvalidloss 5.59965  last_update 0\n",
      "train: iter 2  trainloss 4.99091  validloss 5.18558±0.00000  bestvalidloss 5.18558  last_update 0\n",
      "train: iter 3  trainloss 4.67417  validloss 4.84149±0.00000  bestvalidloss 4.84149  last_update 0\n",
      "train: iter 4  trainloss 4.42913  validloss 4.54976±0.00000  bestvalidloss 4.54976  last_update 0\n",
      "train: iter 5  trainloss 4.19990  validloss 4.31969±0.00000  bestvalidloss 4.31969  last_update 0\n",
      "train: iter 6  trainloss 4.00458  validloss 4.10862±0.00000  bestvalidloss 4.10862  last_update 0\n",
      "train: iter 7  trainloss 3.83848  validloss 3.91816±0.00000  bestvalidloss 3.91816  last_update 0\n",
      "train: iter 8  trainloss 3.67869  validloss 3.77259±0.00000  bestvalidloss 3.77259  last_update 0\n",
      "train: iter 9  trainloss 3.52392  validloss 3.60283±0.00000  bestvalidloss 3.60283  last_update 0\n",
      "train: iter 10  trainloss 3.38727  validloss 3.45661±0.00000  bestvalidloss 3.45661  last_update 0\n",
      "train: iter 11  trainloss 3.24596  validloss 3.33671±0.00000  bestvalidloss 3.33671  last_update 0\n",
      "train: iter 12  trainloss 3.11212  validloss 3.19417±0.00000  bestvalidloss 3.19417  last_update 0\n",
      "train: iter 13  trainloss 2.98627  validloss 3.04476±0.00000  bestvalidloss 3.04476  last_update 0\n",
      "train: iter 14  trainloss 2.85341  validloss 2.92784±0.00000  bestvalidloss 2.92784  last_update 0\n",
      "train: iter 15  trainloss 2.72804  validloss 2.79345±0.00000  bestvalidloss 2.79345  last_update 0\n",
      "train: iter 16  trainloss 2.59982  validloss 2.66625±0.00000  bestvalidloss 2.66625  last_update 0\n",
      "train: iter 17  trainloss 2.47238  validloss 2.54519±0.00000  bestvalidloss 2.54519  last_update 0\n",
      "train: iter 18  trainloss 2.36027  validloss 2.41858±0.00000  bestvalidloss 2.41858  last_update 0\n",
      "train: iter 19  trainloss 2.24429  validloss 2.30381±0.00000  bestvalidloss 2.30381  last_update 0\n",
      "train: iter 20  trainloss 2.13714  validloss 2.19448±0.00000  bestvalidloss 2.19448  last_update 0\n",
      "train: iter 21  trainloss 2.03455  validloss 2.09900±0.00000  bestvalidloss 2.09900  last_update 0\n",
      "train: iter 22  trainloss 1.94500  validloss 2.00649±0.00000  bestvalidloss 2.00649  last_update 0\n",
      "train: iter 23  trainloss 1.85585  validloss 1.90643±0.00000  bestvalidloss 1.90643  last_update 0\n",
      "train: iter 24  trainloss 1.77128  validloss 1.82629±0.00000  bestvalidloss 1.82629  last_update 0\n",
      "train: iter 25  trainloss 1.68730  validloss 1.74052±0.00000  bestvalidloss 1.74052  last_update 0\n",
      "train: iter 26  trainloss 1.60645  validloss 1.66315±0.00000  bestvalidloss 1.66315  last_update 0\n",
      "train: iter 27  trainloss 1.52850  validloss 1.58115±0.00000  bestvalidloss 1.58115  last_update 0\n",
      "train: iter 28  trainloss 1.45314  validloss 1.50601±0.00000  bestvalidloss 1.50601  last_update 0\n",
      "train: iter 29  trainloss 1.36824  validloss 1.41293±0.00000  bestvalidloss 1.41293  last_update 0\n",
      "train: iter 30  trainloss 1.28596  validloss 1.33814±0.00000  bestvalidloss 1.33814  last_update 0\n",
      "train: iter 31  trainloss 1.20349  validloss 1.26346±0.00000  bestvalidloss 1.26346  last_update 0\n",
      "train: iter 32  trainloss 1.12017  validloss 1.18237±0.00000  bestvalidloss 1.18237  last_update 0\n",
      "train: iter 33  trainloss 1.03515  validloss 1.10068±0.00000  bestvalidloss 1.10068  last_update 0\n",
      "train: iter 34  trainloss 0.95323  validloss 1.02350±0.00000  bestvalidloss 1.02350  last_update 0\n",
      "train: iter 35  trainloss 0.86706  validloss 0.93056±0.00000  bestvalidloss 0.93056  last_update 0\n",
      "train: iter 36  trainloss 0.78643  validloss 0.84342±0.00000  bestvalidloss 0.84342  last_update 0\n",
      "train: iter 37  trainloss 0.69770  validloss 0.77028±0.00000  bestvalidloss 0.77028  last_update 0\n",
      "train: iter 38  trainloss 0.60922  validloss 0.68465±0.00000  bestvalidloss 0.68465  last_update 0\n",
      "train: iter 39  trainloss 0.52661  validloss 0.59235±0.00000  bestvalidloss 0.59235  last_update 0\n",
      "train: iter 40  trainloss 0.43451  validloss 0.51336±0.00000  bestvalidloss 0.51336  last_update 0\n",
      "train: iter 41  trainloss 0.35403  validloss 0.43259±0.00000  bestvalidloss 0.43259  last_update 0\n",
      "train: iter 42  trainloss 0.26757  validloss 0.34633±0.00000  bestvalidloss 0.34633  last_update 0\n",
      "train: iter 43  trainloss 0.18214  validloss 0.24926±0.00000  bestvalidloss 0.24926  last_update 0\n",
      "train: iter 44  trainloss 0.09963  validloss 0.17954±0.00000  bestvalidloss 0.17954  last_update 0\n",
      "train: iter 45  trainloss 0.02296  validloss 0.10156±0.00000  bestvalidloss 0.10156  last_update 0\n",
      "train: iter 46  trainloss -0.04888  validloss 0.00539±0.00000  bestvalidloss 0.00539  last_update 0\n",
      "train: iter 47  trainloss -0.13448  validloss -0.04869±0.00000  bestvalidloss -0.04869  last_update 0\n",
      "train: iter 48  trainloss -0.20405  validloss -0.10534±0.00000  bestvalidloss -0.10534  last_update 0\n",
      "train: iter 49  trainloss -0.27474  validloss -0.17513±0.00000  bestvalidloss -0.17513  last_update 0\n",
      "train: iter 50  trainloss -0.34698  validloss -0.27535±0.00000  bestvalidloss -0.27535  last_update 0\n",
      "train: iter 51  trainloss -0.41535  validloss -0.27000±0.00000  bestvalidloss -0.27535  last_update 1\n",
      "train: iter 52  trainloss -0.47860  validloss -0.34139±0.00000  bestvalidloss -0.34139  last_update 0\n",
      "train: iter 53  trainloss -0.54014  validloss -0.42724±0.00000  bestvalidloss -0.42724  last_update 0\n",
      "train: iter 54  trainloss -0.58888  validloss -0.46585±0.00000  bestvalidloss -0.46585  last_update 0\n",
      "train: iter 55  trainloss -0.65458  validloss -0.53505±0.00000  bestvalidloss -0.53505  last_update 0\n",
      "train: iter 56  trainloss -0.71702  validloss -0.60640±0.00000  bestvalidloss -0.60640  last_update 0\n",
      "train: iter 57  trainloss -0.77470  validloss -0.69415±0.00000  bestvalidloss -0.69415  last_update 0\n",
      "train: iter 58  trainloss -0.84083  validloss -0.64983±0.00000  bestvalidloss -0.69415  last_update 1\n",
      "train: iter 59  trainloss -0.87838  validloss -0.67314±0.00000  bestvalidloss -0.69415  last_update 2\n",
      "train: iter 60  trainloss -0.90182  validloss -0.79319±0.00000  bestvalidloss -0.79319  last_update 0\n",
      "train: iter 61  trainloss -0.95426  validloss -0.78941±0.00000  bestvalidloss -0.79319  last_update 1\n",
      "train: iter 62  trainloss -1.02705  validloss -0.82527±0.00000  bestvalidloss -0.82527  last_update 0\n",
      "train: iter 63  trainloss -1.06938  validloss -0.93881±0.00000  bestvalidloss -0.93881  last_update 0\n",
      "train: iter 64  trainloss -1.09079  validloss -0.91382±0.00000  bestvalidloss -0.93881  last_update 1\n",
      "train: iter 65  trainloss -1.12883  validloss -0.92601±0.00000  bestvalidloss -0.93881  last_update 2\n",
      "train: iter 66  trainloss -1.15561  validloss -0.99384±0.00000  bestvalidloss -0.99384  last_update 0\n",
      "train: iter 67  trainloss -1.21513  validloss -1.07638±0.00000  bestvalidloss -1.07638  last_update 0\n",
      "train: iter 68  trainloss -1.23896  validloss -1.00124±0.00000  bestvalidloss -1.07638  last_update 1\n",
      "train: iter 69  trainloss -1.26355  validloss -1.06003±0.00000  bestvalidloss -1.07638  last_update 2\n",
      "train: iter 70  trainloss -1.28589  validloss -1.08483±0.00000  bestvalidloss -1.08483  last_update 0\n",
      "train: iter 71  trainloss -1.31617  validloss -1.19161±0.00000  bestvalidloss -1.19161  last_update 0\n",
      "train: iter 72  trainloss -1.34136  validloss -1.15034±0.00000  bestvalidloss -1.19161  last_update 1\n",
      "train: iter 73  trainloss -1.33460  validloss -1.16472±0.00000  bestvalidloss -1.19161  last_update 2\n",
      "train: iter 74  trainloss -1.41551  validloss -1.20894±0.00000  bestvalidloss -1.20894  last_update 0\n",
      "train: iter 75  trainloss -1.40227  validloss -1.18017±0.00000  bestvalidloss -1.20894  last_update 1\n",
      "train: iter 76  trainloss -1.36684  validloss -1.11967±0.00000  bestvalidloss -1.20894  last_update 2\n",
      "train: iter 77  trainloss -1.38983  validloss -1.14842±0.00000  bestvalidloss -1.20894  last_update 3\n",
      "train: iter 78  trainloss -1.47277  validloss -1.15549±0.00000  bestvalidloss -1.20894  last_update 4\n",
      "train: iter 79  trainloss -1.48222  validloss -1.22825±0.00000  bestvalidloss -1.22825  last_update 0\n",
      "train: iter 80  trainloss -1.48476  validloss -1.25663±0.00000  bestvalidloss -1.25663  last_update 0\n",
      "train: iter 81  trainloss -1.52443  validloss -1.18360±0.00000  bestvalidloss -1.25663  last_update 1\n",
      "train: iter 82  trainloss -1.48885  validloss -1.24209±0.00000  bestvalidloss -1.25663  last_update 2\n",
      "train: iter 83  trainloss -1.49056  validloss -1.22873±0.00000  bestvalidloss -1.25663  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss -1.51279  validloss -1.27258±0.00000  bestvalidloss -1.27258  last_update 0\n",
      "train: iter 85  trainloss -1.55534  validloss -1.27883±0.00000  bestvalidloss -1.27883  last_update 0\n",
      "train: iter 86  trainloss -1.48583  validloss -1.10300±0.00000  bestvalidloss -1.27883  last_update 1\n",
      "train: iter 87  trainloss -1.55040  validloss -1.39655±0.00000  bestvalidloss -1.39655  last_update 0\n",
      "train: iter 88  trainloss -1.50532  validloss -1.04251±0.00000  bestvalidloss -1.39655  last_update 1\n",
      "train: iter 89  trainloss -1.51445  validloss -1.34743±0.00000  bestvalidloss -1.39655  last_update 2\n",
      "train: iter 90  trainloss -1.52136  validloss -1.13846±0.00000  bestvalidloss -1.39655  last_update 3\n",
      "train: iter 91  trainloss -1.53150  validloss -1.33884±0.00000  bestvalidloss -1.39655  last_update 4\n",
      "train: iter 92  trainloss -1.53099  validloss -1.14175±0.00000  bestvalidloss -1.39655  last_update 5\n",
      "train: iter 93  trainloss -1.54264  validloss -1.21768±0.00000  bestvalidloss -1.39655  last_update 6\n",
      "train: iter 94  trainloss -1.54103  validloss -1.27978±0.00000  bestvalidloss -1.39655  last_update 7\n",
      "train: iter 95  trainloss -1.56857  validloss -1.23281±0.00000  bestvalidloss -1.39655  last_update 8\n",
      "train: iter 96  trainloss -1.57260  validloss -1.15322±0.00000  bestvalidloss -1.39655  last_update 9\n",
      "train: iter 97  trainloss -1.54099  validloss -1.35481±0.00000  bestvalidloss -1.39655  last_update 10\n",
      "train: iter 98  trainloss -1.59474  validloss -1.23065±0.00000  bestvalidloss -1.39655  last_update 11\n",
      "train: iter 99  trainloss -1.50227  validloss -1.39408±0.00000  bestvalidloss -1.39655  last_update 12\n",
      "train: iter 100  trainloss -1.52436  validloss -1.26210±0.00000  bestvalidloss -1.39655  last_update 13\n",
      "train: iter 101  trainloss -1.50243  validloss -1.13353±0.00000  bestvalidloss -1.39655  last_update 14\n",
      "train: iter 102  trainloss -1.51550  validloss -1.30438±0.00000  bestvalidloss -1.39655  last_update 15\n",
      "train: iter 103  trainloss -1.51166  validloss -1.21103±0.00000  bestvalidloss -1.39655  last_update 16\n",
      "train: iter 104  trainloss -1.51111  validloss -1.28313±0.00000  bestvalidloss -1.39655  last_update 17\n",
      "train: iter 105  trainloss -1.50306  validloss -1.20162±0.00000  bestvalidloss -1.39655  last_update 18\n",
      "train: iter 106  trainloss -1.57958  validloss -1.25638±0.00000  bestvalidloss -1.39655  last_update 19\n",
      "train: iter 107  trainloss -1.54318  validloss -1.33884±0.00000  bestvalidloss -1.39655  last_update 20\n",
      "train: iter 108  trainloss -1.52466  validloss -1.04140±0.00000  bestvalidloss -1.39655  last_update 21\n",
      "train: iter 109  trainloss -1.49679  validloss -1.25536±0.00000  bestvalidloss -1.39655  last_update 22\n",
      "train: iter 110  trainloss -1.56773  validloss -1.45181±0.00000  bestvalidloss -1.45181  last_update 0\n",
      "train: iter 111  trainloss -1.49763  validloss -1.29076±0.00000  bestvalidloss -1.45181  last_update 1\n",
      "train: iter 112  trainloss -1.47205  validloss -1.07723±0.00000  bestvalidloss -1.45181  last_update 2\n",
      "train: iter 113  trainloss -1.45287  validloss -1.42569±0.00000  bestvalidloss -1.45181  last_update 3\n",
      "train: iter 114  trainloss -1.49573  validloss -1.25086±0.00000  bestvalidloss -1.45181  last_update 4\n",
      "train: iter 115  trainloss -1.56870  validloss -1.12122±0.00000  bestvalidloss -1.45181  last_update 5\n",
      "train: iter 116  trainloss -1.50913  validloss -1.31792±0.00000  bestvalidloss -1.45181  last_update 6\n",
      "train: iter 117  trainloss -1.54487  validloss -1.26153±0.00000  bestvalidloss -1.45181  last_update 7\n",
      "train: iter 118  trainloss -1.55102  validloss -1.34636±0.00000  bestvalidloss -1.45181  last_update 8\n",
      "train: iter 119  trainloss -1.50252  validloss -1.22978±0.00000  bestvalidloss -1.45181  last_update 9\n",
      "train: iter 120  trainloss -1.51783  validloss -1.16262±0.00000  bestvalidloss -1.45181  last_update 10\n",
      "train: iter 121  trainloss -1.56327  validloss -1.23358±0.00000  bestvalidloss -1.45181  last_update 11\n",
      "train: iter 122  trainloss -1.57929  validloss -1.21566±0.00000  bestvalidloss -1.45181  last_update 12\n",
      "train: iter 123  trainloss -1.50943  validloss -1.21292±0.00000  bestvalidloss -1.45181  last_update 13\n",
      "train: iter 124  trainloss -1.55696  validloss -1.22526±0.00000  bestvalidloss -1.45181  last_update 14\n",
      "train: iter 125  trainloss -1.55827  validloss -1.24728±0.00000  bestvalidloss -1.45181  last_update 15\n",
      "train: iter 126  trainloss -1.52075  validloss -1.23241±0.00000  bestvalidloss -1.45181  last_update 16\n",
      "train: iter 127  trainloss -1.53763  validloss -1.04527±0.00000  bestvalidloss -1.45181  last_update 17\n",
      "train: iter 128  trainloss -1.48880  validloss -1.33795±0.00000  bestvalidloss -1.45181  last_update 18\n",
      "train: iter 129  trainloss -1.48857  validloss -1.18772±0.00000  bestvalidloss -1.45181  last_update 19\n",
      "train: iter 130  trainloss -1.48761  validloss -1.30077±0.00000  bestvalidloss -1.45181  last_update 20\n",
      "train: iter 131  trainloss -1.51616  validloss -1.33036±0.00000  bestvalidloss -1.45181  last_update 21\n",
      "train: iter 132  trainloss -1.53466  validloss -1.22226±0.00000  bestvalidloss -1.45181  last_update 22\n",
      "train: iter 133  trainloss -1.51607  validloss -1.46234±0.00000  bestvalidloss -1.46234  last_update 0\n",
      "train: iter 134  trainloss -1.56791  validloss -1.17140±0.00000  bestvalidloss -1.46234  last_update 1\n",
      "train: iter 135  trainloss -1.50336  validloss -1.33628±0.00000  bestvalidloss -1.46234  last_update 2\n",
      "train: iter 136  trainloss -1.51063  validloss -1.26110±0.00000  bestvalidloss -1.46234  last_update 3\n",
      "train: iter 137  trainloss -1.56634  validloss -1.32239±0.00000  bestvalidloss -1.46234  last_update 4\n",
      "train: iter 138  trainloss -1.49511  validloss -1.25336±0.00000  bestvalidloss -1.46234  last_update 5\n",
      "train: iter 139  trainloss -1.55315  validloss -1.36258±0.00000  bestvalidloss -1.46234  last_update 6\n",
      "train: iter 140  trainloss -1.58789  validloss -1.12729±0.00000  bestvalidloss -1.46234  last_update 7\n",
      "train: iter 141  trainloss -1.47380  validloss -1.20497±0.00000  bestvalidloss -1.46234  last_update 8\n",
      "train: iter 142  trainloss -1.47125  validloss -1.32567±0.00000  bestvalidloss -1.46234  last_update 9\n",
      "train: iter 143  trainloss -1.51369  validloss -1.26405±0.00000  bestvalidloss -1.46234  last_update 10\n",
      "train: iter 144  trainloss -1.58224  validloss -1.43448±0.00000  bestvalidloss -1.46234  last_update 11\n",
      "train: iter 145  trainloss -1.53723  validloss -1.22451±0.00000  bestvalidloss -1.46234  last_update 12\n",
      "train: iter 146  trainloss -1.56278  validloss -1.28013±0.00000  bestvalidloss -1.46234  last_update 13\n",
      "train: iter 147  trainloss -1.53176  validloss -1.25458±0.00000  bestvalidloss -1.46234  last_update 14\n",
      "train: iter 148  trainloss -1.55585  validloss -1.21745±0.00000  bestvalidloss -1.46234  last_update 15\n",
      "train: iter 149  trainloss -1.57635  validloss -1.32121±0.00000  bestvalidloss -1.46234  last_update 16\n",
      "train: iter 150  trainloss -1.53748  validloss -1.25123±0.00000  bestvalidloss -1.46234  last_update 17\n",
      "train: iter 151  trainloss -1.53235  validloss -1.39376±0.00000  bestvalidloss -1.46234  last_update 18\n",
      "train: iter 152  trainloss -1.58080  validloss -1.39702±0.00000  bestvalidloss -1.46234  last_update 19\n",
      "train: iter 153  trainloss -1.59847  validloss -1.07617±0.00000  bestvalidloss -1.46234  last_update 20\n",
      "train: iter 154  trainloss -1.53448  validloss -1.26420±0.00000  bestvalidloss -1.46234  last_update 21\n",
      "train: iter 155  trainloss -1.54556  validloss -1.25130±0.00000  bestvalidloss -1.46234  last_update 22\n",
      "train: iter 156  trainloss -1.48533  validloss -1.23154±0.00000  bestvalidloss -1.46234  last_update 23\n",
      "train: iter 157  trainloss -1.56551  validloss -1.28829±0.00000  bestvalidloss -1.46234  last_update 24\n",
      "train: iter 158  trainloss -1.51511  validloss -1.22840±0.00000  bestvalidloss -1.46234  last_update 25\n",
      "train: iter 159  trainloss -1.56937  validloss -1.22159±0.00000  bestvalidloss -1.46234  last_update 26\n",
      "train: iter 160  trainloss -1.46376  validloss -1.29062±0.00000  bestvalidloss -1.46234  last_update 27\n",
      "train: iter 161  trainloss -1.51126  validloss -1.36465±0.00000  bestvalidloss -1.46234  last_update 28\n",
      "train: iter 162  trainloss -1.58464  validloss -1.29264±0.00000  bestvalidloss -1.46234  last_update 29\n",
      "train: iter 163  trainloss -1.59532  validloss -1.23916±0.00000  bestvalidloss -1.46234  last_update 30\n",
      "train: iter 164  trainloss -1.50055  validloss -1.32196±0.00000  bestvalidloss -1.46234  last_update 31\n",
      "train: iter 165  trainloss -1.55119  validloss -1.15051±0.00000  bestvalidloss -1.46234  last_update 32\n",
      "train: iter 166  trainloss -1.53818  validloss -1.20913±0.00000  bestvalidloss -1.46234  last_update 33\n",
      "train: iter 167  trainloss -1.51470  validloss -1.19496±0.00000  bestvalidloss -1.46234  last_update 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss -1.51104  validloss -1.23680±0.00000  bestvalidloss -1.46234  last_update 35\n",
      "train: iter 169  trainloss -1.54362  validloss -1.32714±0.00000  bestvalidloss -1.46234  last_update 36\n",
      "train: iter 170  trainloss -1.48868  validloss -1.24575±0.00000  bestvalidloss -1.46234  last_update 37\n",
      "train: iter 171  trainloss -1.61418  validloss -1.37090±0.00000  bestvalidloss -1.46234  last_update 38\n",
      "train: iter 172  trainloss -1.58022  validloss -1.26149±0.00000  bestvalidloss -1.46234  last_update 39\n",
      "train: iter 173  trainloss -1.52151  validloss -1.27389±0.00000  bestvalidloss -1.46234  last_update 40\n",
      "train: iter 174  trainloss -1.54038  validloss -1.27758±0.00000  bestvalidloss -1.46234  last_update 41\n",
      "train: iter 175  trainloss -1.55579  validloss -1.22936±0.00000  bestvalidloss -1.46234  last_update 42\n",
      "train: iter 176  trainloss -1.53526  validloss -1.36794±0.00000  bestvalidloss -1.46234  last_update 43\n",
      "train: iter 177  trainloss -1.43776  validloss -1.25896±0.00000  bestvalidloss -1.46234  last_update 44\n",
      "train: iter 178  trainloss -1.54860  validloss -1.25727±0.00000  bestvalidloss -1.46234  last_update 45\n",
      "train: iter 179  trainloss -1.56375  validloss -1.33910±0.00000  bestvalidloss -1.46234  last_update 46\n",
      "train: iter 180  trainloss -1.59188  validloss -1.38090±0.00000  bestvalidloss -1.46234  last_update 47\n",
      "train: iter 181  trainloss -1.52502  validloss -1.24441±0.00000  bestvalidloss -1.46234  last_update 48\n",
      "train: iter 182  trainloss -1.55128  validloss -1.12461±0.00000  bestvalidloss -1.46234  last_update 49\n",
      "train: iter 183  trainloss -1.54767  validloss -1.20784±0.00000  bestvalidloss -1.46234  last_update 50\n",
      "train: iter 184  trainloss -1.46555  validloss -0.94235±0.00000  bestvalidloss -1.46234  last_update 51\n",
      "train: iter 185  trainloss -1.60227  validloss -1.25570±0.00000  bestvalidloss -1.46234  last_update 52\n",
      "train: iter 186  trainloss -1.49261  validloss -1.27694±0.00000  bestvalidloss -1.46234  last_update 53\n",
      "train: iter 187  trainloss -1.58801  validloss -1.15964±0.00000  bestvalidloss -1.46234  last_update 54\n",
      "train: iter 188  trainloss -1.57915  validloss -1.28123±0.00000  bestvalidloss -1.46234  last_update 55\n",
      "train: iter 189  trainloss -1.49715  validloss -1.17820±0.00000  bestvalidloss -1.46234  last_update 56\n",
      "train: iter 190  trainloss -1.57366  validloss -1.22302±0.00000  bestvalidloss -1.46234  last_update 57\n",
      "train: iter 191  trainloss -1.56912  validloss -1.14542±0.00000  bestvalidloss -1.46234  last_update 58\n",
      "train: iter 192  trainloss -1.50980  validloss -1.28619±0.00000  bestvalidloss -1.46234  last_update 59\n",
      "train: iter 193  trainloss -1.59556  validloss -1.22334±0.00000  bestvalidloss -1.46234  last_update 60\n",
      "train: iter 194  trainloss -1.48118  validloss -1.07502±0.00000  bestvalidloss -1.46234  last_update 61\n",
      "train: iter 195  trainloss -1.47088  validloss -0.98277±0.00000  bestvalidloss -1.46234  last_update 62\n",
      "train: iter 196  trainloss -1.52056  validloss -1.05594±0.00000  bestvalidloss -1.46234  last_update 63\n",
      "train: iter 197  trainloss -1.55407  validloss -1.22390±0.00000  bestvalidloss -1.46234  last_update 64\n",
      "train: iter 198  trainloss -1.56435  validloss -1.18221±0.00000  bestvalidloss -1.46234  last_update 65\n",
      "train: iter 199  trainloss -1.58661  validloss -1.13548±0.00000  bestvalidloss -1.46234  last_update 66\n",
      "train: iter 200  trainloss -1.53830  validloss -1.43071±0.00000  bestvalidloss -1.46234  last_update 67\n",
      "train: iter 201  trainloss -1.55785  validloss -1.32121±0.00000  bestvalidloss -1.46234  last_update 68\n",
      "train: iter 202  trainloss -1.55223  validloss -1.31230±0.00000  bestvalidloss -1.46234  last_update 69\n",
      "train: iter 203  trainloss -1.49897  validloss -1.16203±0.00000  bestvalidloss -1.46234  last_update 70\n",
      "train: iter 204  trainloss -1.52545  validloss -1.14086±0.00000  bestvalidloss -1.46234  last_update 71\n",
      "train: iter 205  trainloss -1.57976  validloss -1.16176±0.00000  bestvalidloss -1.46234  last_update 72\n",
      "train: iter 206  trainloss -1.56339  validloss -1.27861±0.00000  bestvalidloss -1.46234  last_update 73\n",
      "train: iter 207  trainloss -1.54255  validloss -1.34494±0.00000  bestvalidloss -1.46234  last_update 74\n",
      "train: iter 208  trainloss -1.53217  validloss -1.27727±0.00000  bestvalidloss -1.46234  last_update 75\n",
      "train: iter 209  trainloss -1.50285  validloss -1.37475±0.00000  bestvalidloss -1.46234  last_update 76\n",
      "train: iter 210  trainloss -1.51838  validloss -1.24577±0.00000  bestvalidloss -1.46234  last_update 77\n",
      "train: iter 211  trainloss -1.49973  validloss -1.25438±0.00000  bestvalidloss -1.46234  last_update 78\n",
      "train: iter 212  trainloss -1.60250  validloss -1.19352±0.00000  bestvalidloss -1.46234  last_update 79\n",
      "train: iter 213  trainloss -1.49645  validloss -1.16765±0.00000  bestvalidloss -1.46234  last_update 80\n",
      "train: iter 214  trainloss -1.54622  validloss -1.05841±0.00000  bestvalidloss -1.46234  last_update 81\n",
      "train: iter 215  trainloss -1.49030  validloss -1.26291±0.00000  bestvalidloss -1.46234  last_update 82\n",
      "train: iter 216  trainloss -1.56526  validloss -1.23947±0.00000  bestvalidloss -1.46234  last_update 83\n",
      "train: iter 217  trainloss -1.58766  validloss -1.26515±0.00000  bestvalidloss -1.46234  last_update 84\n",
      "train: iter 218  trainloss -1.53672  validloss -1.01984±0.00000  bestvalidloss -1.46234  last_update 85\n",
      "train: iter 219  trainloss -1.51346  validloss -1.39036±0.00000  bestvalidloss -1.46234  last_update 86\n",
      "train: iter 220  trainloss -1.54980  validloss -1.32039±0.00000  bestvalidloss -1.46234  last_update 87\n",
      "train: iter 221  trainloss -1.59162  validloss -1.36692±0.00000  bestvalidloss -1.46234  last_update 88\n",
      "train: iter 222  trainloss -1.47065  validloss -1.12262±0.00000  bestvalidloss -1.46234  last_update 89\n",
      "train: iter 223  trainloss -1.50507  validloss -1.31474±0.00000  bestvalidloss -1.46234  last_update 90\n",
      "train: iter 224  trainloss -1.54386  validloss -1.21274±0.00000  bestvalidloss -1.46234  last_update 91\n",
      "train: iter 225  trainloss -1.51830  validloss -1.23251±0.00000  bestvalidloss -1.46234  last_update 92\n",
      "train: iter 226  trainloss -1.55680  validloss -1.28979±0.00000  bestvalidloss -1.46234  last_update 93\n",
      "train: iter 227  trainloss -1.58694  validloss -1.23977±0.00000  bestvalidloss -1.46234  last_update 94\n",
      "train: iter 228  trainloss -1.51625  validloss -1.19874±0.00000  bestvalidloss -1.46234  last_update 95\n",
      "train: iter 229  trainloss -1.48918  validloss -1.31977±0.00000  bestvalidloss -1.46234  last_update 96\n",
      "train: iter 230  trainloss -1.52184  validloss -1.19640±0.00000  bestvalidloss -1.46234  last_update 97\n",
      "train: iter 231  trainloss -1.44189  validloss -1.22930±0.00000  bestvalidloss -1.46234  last_update 98\n",
      "train: iter 232  trainloss -1.47623  validloss -1.17044±0.00000  bestvalidloss -1.46234  last_update 99\n",
      "train: iter 233  trainloss -1.53432  validloss -1.22005±0.00000  bestvalidloss -1.46234  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 2.5174,  1.4688, -3.3910, -5.3142], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 66.98410  validloss 69.57251±0.00000  bestvalidloss 69.57251  last_update 0\n",
      "train: iter 1  trainloss 50.62194  validloss 55.28785±0.00000  bestvalidloss 55.28785  last_update 0\n",
      "train: iter 2  trainloss 36.81756  validloss 40.63443±0.00000  bestvalidloss 40.63443  last_update 0\n",
      "train: iter 3  trainloss 27.60614  validloss 30.18450±0.00000  bestvalidloss 30.18450  last_update 0\n",
      "train: iter 4  trainloss 21.60081  validloss 23.91598±0.00000  bestvalidloss 23.91598  last_update 0\n",
      "train: iter 5  trainloss 17.54349  validloss 19.57892±0.00000  bestvalidloss 19.57892  last_update 0\n",
      "train: iter 6  trainloss 14.60917  validloss 16.60128±0.00000  bestvalidloss 16.60128  last_update 0\n",
      "train: iter 7  trainloss 12.39676  validloss 14.58467±0.00000  bestvalidloss 14.58467  last_update 0\n",
      "train: iter 8  trainloss 10.80987  validloss 13.20180±0.00000  bestvalidloss 13.20180  last_update 0\n",
      "train: iter 9  trainloss 9.69271  validloss 12.09242±0.00000  bestvalidloss 12.09242  last_update 0\n",
      "train: iter 10  trainloss 8.75890  validloss 11.65874±0.00000  bestvalidloss 11.65874  last_update 0\n",
      "train: iter 11  trainloss 7.95553  validloss 10.98751±0.00000  bestvalidloss 10.98751  last_update 0\n",
      "train: iter 12  trainloss 7.29192  validloss 10.94707±0.00000  bestvalidloss 10.94707  last_update 0\n",
      "train: iter 13  trainloss 6.81192  validloss 10.84338±0.00000  bestvalidloss 10.84338  last_update 0\n",
      "train: iter 14  trainloss 6.40164  validloss 10.56056±0.00000  bestvalidloss 10.56056  last_update 0\n",
      "train: iter 15  trainloss 5.98374  validloss 10.43181±0.00000  bestvalidloss 10.43181  last_update 0\n",
      "train: iter 16  trainloss 5.65345  validloss 10.08554±0.00000  bestvalidloss 10.08554  last_update 0\n",
      "train: iter 17  trainloss 5.37916  validloss 9.53169±0.00000  bestvalidloss 9.53169  last_update 0\n",
      "train: iter 18  trainloss 5.07003  validloss 9.24782±0.00000  bestvalidloss 9.24782  last_update 0\n",
      "train: iter 19  trainloss 4.92942  validloss 8.92677±0.00000  bestvalidloss 8.92677  last_update 0\n",
      "train: iter 20  trainloss 4.70205  validloss 8.36154±0.00000  bestvalidloss 8.36154  last_update 0\n",
      "train: iter 21  trainloss 4.55283  validloss 8.42300±0.00000  bestvalidloss 8.36154  last_update 1\n",
      "train: iter 22  trainloss 4.45099  validloss 7.95527±0.00000  bestvalidloss 7.95527  last_update 0\n",
      "train: iter 23  trainloss 4.33135  validloss 7.73212±0.00000  bestvalidloss 7.73212  last_update 0\n",
      "train: iter 24  trainloss 4.29396  validloss 7.34156±0.00000  bestvalidloss 7.34156  last_update 0\n",
      "train: iter 25  trainloss 4.23064  validloss 7.89143±0.00000  bestvalidloss 7.34156  last_update 1\n",
      "train: iter 26  trainloss 4.11393  validloss 7.61435±0.00000  bestvalidloss 7.34156  last_update 2\n",
      "train: iter 27  trainloss 4.07722  validloss 7.53744±0.00000  bestvalidloss 7.34156  last_update 3\n",
      "train: iter 28  trainloss 4.00856  validloss 7.50376±0.00000  bestvalidloss 7.34156  last_update 4\n",
      "train: iter 29  trainloss 3.96402  validloss 7.36584±0.00000  bestvalidloss 7.34156  last_update 5\n",
      "train: iter 30  trainloss 3.90334  validloss 7.12675±0.00000  bestvalidloss 7.12675  last_update 0\n",
      "train: iter 31  trainloss 3.91087  validloss 7.16602±0.00000  bestvalidloss 7.12675  last_update 1\n",
      "train: iter 32  trainloss 3.86545  validloss 6.99136±0.00000  bestvalidloss 6.99136  last_update 0\n",
      "train: iter 33  trainloss 3.84378  validloss 6.93948±0.00000  bestvalidloss 6.93948  last_update 0\n",
      "train: iter 34  trainloss 3.81491  validloss 7.05191±0.00000  bestvalidloss 6.93948  last_update 1\n",
      "train: iter 35  trainloss 3.79429  validloss 7.12959±0.00000  bestvalidloss 6.93948  last_update 2\n",
      "train: iter 36  trainloss 3.75667  validloss 7.32823±0.00000  bestvalidloss 6.93948  last_update 3\n",
      "train: iter 37  trainloss 3.75292  validloss 6.88864±0.00000  bestvalidloss 6.88864  last_update 0\n",
      "train: iter 38  trainloss 3.71346  validloss 6.87072±0.00000  bestvalidloss 6.87072  last_update 0\n",
      "train: iter 39  trainloss 3.71288  validloss 6.84284±0.00000  bestvalidloss 6.84284  last_update 0\n",
      "train: iter 40  trainloss 3.63499  validloss 6.82337±0.00000  bestvalidloss 6.82337  last_update 0\n",
      "train: iter 41  trainloss 3.65176  validloss 6.82774±0.00000  bestvalidloss 6.82337  last_update 1\n",
      "train: iter 42  trainloss 3.65613  validloss 6.43610±0.00000  bestvalidloss 6.43610  last_update 0\n",
      "train: iter 43  trainloss 3.66148  validloss 6.77024±0.00000  bestvalidloss 6.43610  last_update 1\n",
      "train: iter 44  trainloss 3.63430  validloss 6.70956±0.00000  bestvalidloss 6.43610  last_update 2\n",
      "train: iter 45  trainloss 3.62652  validloss 7.01958±0.00000  bestvalidloss 6.43610  last_update 3\n",
      "train: iter 46  trainloss 3.63421  validloss 6.83422±0.00000  bestvalidloss 6.43610  last_update 4\n",
      "train: iter 47  trainloss 3.59494  validloss 6.99470±0.00000  bestvalidloss 6.43610  last_update 5\n",
      "train: iter 48  trainloss 3.62859  validloss 6.92879±0.00000  bestvalidloss 6.43610  last_update 6\n",
      "train: iter 49  trainloss 3.57976  validloss 6.92768±0.00000  bestvalidloss 6.43610  last_update 7\n",
      "train: iter 50  trainloss 3.53964  validloss 6.79102±0.00000  bestvalidloss 6.43610  last_update 8\n",
      "train: iter 51  trainloss 3.51930  validloss 6.36851±0.00000  bestvalidloss 6.36851  last_update 0\n",
      "train: iter 52  trainloss 3.50248  validloss 6.88254±0.00000  bestvalidloss 6.36851  last_update 1\n",
      "train: iter 53  trainloss 3.52663  validloss 6.59722±0.00000  bestvalidloss 6.36851  last_update 2\n",
      "train: iter 54  trainloss 3.55948  validloss 6.67222±0.00000  bestvalidloss 6.36851  last_update 3\n",
      "train: iter 55  trainloss 3.48810  validloss 6.49408±0.00000  bestvalidloss 6.36851  last_update 4\n",
      "train: iter 56  trainloss 3.44816  validloss 6.49002±0.00000  bestvalidloss 6.36851  last_update 5\n",
      "train: iter 57  trainloss 3.45706  validloss 6.26849±0.00000  bestvalidloss 6.26849  last_update 0\n",
      "train: iter 58  trainloss 3.41699  validloss 6.79964±0.00000  bestvalidloss 6.26849  last_update 1\n",
      "train: iter 59  trainloss 3.34711  validloss 7.04172±0.00000  bestvalidloss 6.26849  last_update 2\n",
      "train: iter 60  trainloss 3.34470  validloss 6.62804±0.00000  bestvalidloss 6.26849  last_update 3\n",
      "train: iter 61  trainloss 3.38121  validloss 6.48204±0.00000  bestvalidloss 6.26849  last_update 4\n",
      "train: iter 62  trainloss 3.31671  validloss 6.09620±0.00000  bestvalidloss 6.09620  last_update 0\n",
      "train: iter 63  trainloss 3.30705  validloss 6.49129±0.00000  bestvalidloss 6.09620  last_update 1\n",
      "train: iter 64  trainloss 3.27548  validloss 6.46290±0.00000  bestvalidloss 6.09620  last_update 2\n",
      "train: iter 65  trainloss 3.40670  validloss 6.53088±0.00000  bestvalidloss 6.09620  last_update 3\n",
      "train: iter 66  trainloss 3.27132  validloss 6.57007±0.00000  bestvalidloss 6.09620  last_update 4\n",
      "train: iter 67  trainloss 3.31347  validloss 6.59251±0.00000  bestvalidloss 6.09620  last_update 5\n",
      "train: iter 68  trainloss 3.28715  validloss 6.31383±0.00000  bestvalidloss 6.09620  last_update 6\n",
      "train: iter 69  trainloss 3.30225  validloss 6.17562±0.00000  bestvalidloss 6.09620  last_update 7\n",
      "train: iter 70  trainloss 3.35774  validloss 6.54836±0.00000  bestvalidloss 6.09620  last_update 8\n",
      "train: iter 71  trainloss 3.27402  validloss 6.70952±0.00000  bestvalidloss 6.09620  last_update 9\n",
      "train: iter 72  trainloss 3.25274  validloss 6.16408±0.00000  bestvalidloss 6.09620  last_update 10\n",
      "train: iter 73  trainloss 3.30183  validloss 6.60459±0.00000  bestvalidloss 6.09620  last_update 11\n",
      "train: iter 74  trainloss 3.32129  validloss 6.19853±0.00000  bestvalidloss 6.09620  last_update 12\n",
      "train: iter 75  trainloss 3.29332  validloss 6.55002±0.00000  bestvalidloss 6.09620  last_update 13\n",
      "train: iter 76  trainloss 3.27128  validloss 6.54799±0.00000  bestvalidloss 6.09620  last_update 14\n",
      "train: iter 77  trainloss 3.31978  validloss 6.63978±0.00000  bestvalidloss 6.09620  last_update 15\n",
      "train: iter 78  trainloss 3.27869  validloss 6.08858±0.00000  bestvalidloss 6.08858  last_update 0\n",
      "train: iter 79  trainloss 3.26049  validloss 6.50218±0.00000  bestvalidloss 6.08858  last_update 1\n",
      "train: iter 80  trainloss 3.26139  validloss 6.62819±0.00000  bestvalidloss 6.08858  last_update 2\n",
      "train: iter 81  trainloss 3.22021  validloss 6.18320±0.00000  bestvalidloss 6.08858  last_update 3\n",
      "train: iter 82  trainloss 3.26414  validloss 6.43273±0.00000  bestvalidloss 6.08858  last_update 4\n",
      "train: iter 83  trainloss 3.25398  validloss 6.42012±0.00000  bestvalidloss 6.08858  last_update 5\n",
      "train: iter 84  trainloss 3.29773  validloss 6.23125±0.00000  bestvalidloss 6.08858  last_update 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 85  trainloss 3.23740  validloss 6.47500±0.00000  bestvalidloss 6.08858  last_update 7\n",
      "train: iter 86  trainloss 3.21118  validloss 6.58903±0.00000  bestvalidloss 6.08858  last_update 8\n",
      "train: iter 87  trainloss 3.22076  validloss 6.35577±0.00000  bestvalidloss 6.08858  last_update 9\n",
      "train: iter 88  trainloss 3.19500  validloss 6.18618±0.00000  bestvalidloss 6.08858  last_update 10\n",
      "train: iter 89  trainloss 3.23405  validloss 5.89806±0.00000  bestvalidloss 5.89806  last_update 0\n",
      "train: iter 90  trainloss 3.23823  validloss 6.24045±0.00000  bestvalidloss 5.89806  last_update 1\n",
      "train: iter 91  trainloss 3.20508  validloss 6.54895±0.00000  bestvalidloss 5.89806  last_update 2\n",
      "train: iter 92  trainloss 3.19111  validloss 6.43203±0.00000  bestvalidloss 5.89806  last_update 3\n",
      "train: iter 93  trainloss 3.20234  validloss 6.67709±0.00000  bestvalidloss 5.89806  last_update 4\n",
      "train: iter 94  trainloss 3.27507  validloss 6.60380±0.00000  bestvalidloss 5.89806  last_update 5\n",
      "train: iter 95  trainloss 3.21635  validloss 6.10237±0.00000  bestvalidloss 5.89806  last_update 6\n",
      "train: iter 96  trainloss 3.23087  validloss 6.34976±0.00000  bestvalidloss 5.89806  last_update 7\n",
      "train: iter 97  trainloss 3.25353  validloss 7.05624±0.00000  bestvalidloss 5.89806  last_update 8\n",
      "train: iter 98  trainloss 3.25342  validloss 6.86169±0.00000  bestvalidloss 5.89806  last_update 9\n",
      "train: iter 99  trainloss 3.18797  validloss 6.23271±0.00000  bestvalidloss 5.89806  last_update 10\n",
      "train: iter 100  trainloss 3.27541  validloss 6.15179±0.00000  bestvalidloss 5.89806  last_update 11\n",
      "train: iter 101  trainloss 3.22056  validloss 6.35603±0.00000  bestvalidloss 5.89806  last_update 12\n",
      "train: iter 102  trainloss 3.17479  validloss 6.66762±0.00000  bestvalidloss 5.89806  last_update 13\n",
      "train: iter 103  trainloss 3.19114  validloss 6.28929±0.00000  bestvalidloss 5.89806  last_update 14\n",
      "train: iter 104  trainloss 3.16838  validloss 6.45929±0.00000  bestvalidloss 5.89806  last_update 15\n",
      "train: iter 105  trainloss 3.26064  validloss 6.27599±0.00000  bestvalidloss 5.89806  last_update 16\n",
      "train: iter 106  trainloss 3.18581  validloss 6.40982±0.00000  bestvalidloss 5.89806  last_update 17\n",
      "train: iter 107  trainloss 3.17924  validloss 6.16156±0.00000  bestvalidloss 5.89806  last_update 18\n",
      "train: iter 108  trainloss 3.20670  validloss 6.47112±0.00000  bestvalidloss 5.89806  last_update 19\n",
      "train: iter 109  trainloss 3.22644  validloss 6.04142±0.00000  bestvalidloss 5.89806  last_update 20\n",
      "train: iter 110  trainloss 3.23650  validloss 6.16919±0.00000  bestvalidloss 5.89806  last_update 21\n",
      "train: iter 111  trainloss 3.17907  validloss 6.66198±0.00000  bestvalidloss 5.89806  last_update 22\n",
      "train: iter 112  trainloss 3.25298  validloss 6.62270±0.00000  bestvalidloss 5.89806  last_update 23\n",
      "train: iter 113  trainloss 3.17455  validloss 6.65954±0.00000  bestvalidloss 5.89806  last_update 24\n",
      "train: iter 114  trainloss 3.20658  validloss 6.39701±0.00000  bestvalidloss 5.89806  last_update 25\n",
      "train: iter 115  trainloss 3.14312  validloss 6.39979±0.00000  bestvalidloss 5.89806  last_update 26\n",
      "train: iter 116  trainloss 3.19707  validloss 6.54611±0.00000  bestvalidloss 5.89806  last_update 27\n",
      "train: iter 117  trainloss 3.15945  validloss 6.27274±0.00000  bestvalidloss 5.89806  last_update 28\n",
      "train: iter 118  trainloss 3.19514  validloss 6.16449±0.00000  bestvalidloss 5.89806  last_update 29\n",
      "train: iter 119  trainloss 3.17359  validloss 6.35455±0.00000  bestvalidloss 5.89806  last_update 30\n",
      "train: iter 120  trainloss 3.20070  validloss 6.47577±0.00000  bestvalidloss 5.89806  last_update 31\n",
      "train: iter 121  trainloss 3.19945  validloss 6.64631±0.00000  bestvalidloss 5.89806  last_update 32\n",
      "train: iter 122  trainloss 3.22886  validloss 6.46085±0.00000  bestvalidloss 5.89806  last_update 33\n",
      "train: iter 123  trainloss 3.15912  validloss 6.19914±0.00000  bestvalidloss 5.89806  last_update 34\n",
      "train: iter 124  trainloss 3.16756  validloss 6.32195±0.00000  bestvalidloss 5.89806  last_update 35\n",
      "train: iter 125  trainloss 3.15473  validloss 6.39325±0.00000  bestvalidloss 5.89806  last_update 36\n",
      "train: iter 126  trainloss 3.15092  validloss 6.54971±0.00000  bestvalidloss 5.89806  last_update 37\n",
      "train: iter 127  trainloss 3.19983  validloss 6.87084±0.00000  bestvalidloss 5.89806  last_update 38\n",
      "train: iter 128  trainloss 3.23385  validloss 6.52561±0.00000  bestvalidloss 5.89806  last_update 39\n",
      "train: iter 129  trainloss 3.19631  validloss 6.20058±0.00000  bestvalidloss 5.89806  last_update 40\n",
      "train: iter 130  trainloss 3.17981  validloss 6.42268±0.00000  bestvalidloss 5.89806  last_update 41\n",
      "train: iter 131  trainloss 3.16856  validloss 6.19697±0.00000  bestvalidloss 5.89806  last_update 42\n",
      "train: iter 132  trainloss 3.17519  validloss 6.52863±0.00000  bestvalidloss 5.89806  last_update 43\n",
      "train: iter 133  trainloss 3.12183  validloss 6.31655±0.00000  bestvalidloss 5.89806  last_update 44\n",
      "train: iter 134  trainloss 3.18862  validloss 6.65713±0.00000  bestvalidloss 5.89806  last_update 45\n",
      "train: iter 135  trainloss 3.19093  validloss 6.10922±0.00000  bestvalidloss 5.89806  last_update 46\n",
      "train: iter 136  trainloss 3.18736  validloss 6.25288±0.00000  bestvalidloss 5.89806  last_update 47\n",
      "train: iter 137  trainloss 3.14939  validloss 6.05814±0.00000  bestvalidloss 5.89806  last_update 48\n",
      "train: iter 138  trainloss 3.15186  validloss 6.77149±0.00000  bestvalidloss 5.89806  last_update 49\n",
      "train: iter 139  trainloss 3.19372  validloss 6.41252±0.00000  bestvalidloss 5.89806  last_update 50\n",
      "train: iter 140  trainloss 3.19268  validloss 6.57684±0.00000  bestvalidloss 5.89806  last_update 51\n",
      "train: iter 141  trainloss 3.17408  validloss 6.34331±0.00000  bestvalidloss 5.89806  last_update 52\n",
      "train: iter 142  trainloss 3.12844  validloss 6.53287±0.00000  bestvalidloss 5.89806  last_update 53\n",
      "train: iter 143  trainloss 3.13623  validloss 5.99659±0.00000  bestvalidloss 5.89806  last_update 54\n",
      "train: iter 144  trainloss 3.17744  validloss 6.27929±0.00000  bestvalidloss 5.89806  last_update 55\n",
      "train: iter 145  trainloss 3.15126  validloss 6.42196±0.00000  bestvalidloss 5.89806  last_update 56\n",
      "train: iter 146  trainloss 3.16349  validloss 6.43028±0.00000  bestvalidloss 5.89806  last_update 57\n",
      "train: iter 147  trainloss 3.16204  validloss 6.43411±0.00000  bestvalidloss 5.89806  last_update 58\n",
      "train: iter 148  trainloss 3.13123  validloss 6.72758±0.00000  bestvalidloss 5.89806  last_update 59\n",
      "train: iter 149  trainloss 3.10231  validloss 6.56186±0.00000  bestvalidloss 5.89806  last_update 60\n",
      "train: iter 150  trainloss 3.14302  validloss 6.34331±0.00000  bestvalidloss 5.89806  last_update 61\n",
      "train: iter 151  trainloss 3.15380  validloss 6.05169±0.00000  bestvalidloss 5.89806  last_update 62\n",
      "train: iter 152  trainloss 3.13470  validloss 6.23057±0.00000  bestvalidloss 5.89806  last_update 63\n",
      "train: iter 153  trainloss 3.20952  validloss 6.49945±0.00000  bestvalidloss 5.89806  last_update 64\n",
      "train: iter 154  trainloss 3.21489  validloss 6.72169±0.00000  bestvalidloss 5.89806  last_update 65\n",
      "train: iter 155  trainloss 3.15124  validloss 6.12084±0.00000  bestvalidloss 5.89806  last_update 66\n",
      "train: iter 156  trainloss 3.16841  validloss 6.29499±0.00000  bestvalidloss 5.89806  last_update 67\n",
      "train: iter 157  trainloss 3.18215  validloss 6.62769±0.00000  bestvalidloss 5.89806  last_update 68\n",
      "train: iter 158  trainloss 3.15901  validloss 6.54764±0.00000  bestvalidloss 5.89806  last_update 69\n",
      "train: iter 159  trainloss 3.13306  validloss 6.28733±0.00000  bestvalidloss 5.89806  last_update 70\n",
      "train: iter 160  trainloss 3.12746  validloss 6.24348±0.00000  bestvalidloss 5.89806  last_update 71\n",
      "train: iter 161  trainloss 3.14868  validloss 6.40984±0.00000  bestvalidloss 5.89806  last_update 72\n",
      "train: iter 162  trainloss 3.13461  validloss 6.37749±0.00000  bestvalidloss 5.89806  last_update 73\n",
      "train: iter 163  trainloss 3.21687  validloss 6.01394±0.00000  bestvalidloss 5.89806  last_update 74\n",
      "train: iter 164  trainloss 3.14714  validloss 6.19760±0.00000  bestvalidloss 5.89806  last_update 75\n",
      "train: iter 165  trainloss 3.10921  validloss 6.31908±0.00000  bestvalidloss 5.89806  last_update 76\n",
      "train: iter 166  trainloss 3.15722  validloss 6.82354±0.00000  bestvalidloss 5.89806  last_update 77\n",
      "train: iter 167  trainloss 3.13279  validloss 6.63803±0.00000  bestvalidloss 5.89806  last_update 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 3.10183  validloss 6.46408±0.00000  bestvalidloss 5.89806  last_update 79\n",
      "train: iter 169  trainloss 3.15021  validloss 6.83833±0.00000  bestvalidloss 5.89806  last_update 80\n",
      "train: iter 170  trainloss 3.11251  validloss 6.36456±0.00000  bestvalidloss 5.89806  last_update 81\n",
      "train: iter 171  trainloss 3.13539  validloss 6.27526±0.00000  bestvalidloss 5.89806  last_update 82\n",
      "train: iter 172  trainloss 3.16361  validloss 6.52600±0.00000  bestvalidloss 5.89806  last_update 83\n",
      "train: iter 173  trainloss 3.16821  validloss 6.58881±0.00000  bestvalidloss 5.89806  last_update 84\n",
      "train: iter 174  trainloss 3.14437  validloss 6.41626±0.00000  bestvalidloss 5.89806  last_update 85\n",
      "train: iter 175  trainloss 3.16861  validloss 6.16920±0.00000  bestvalidloss 5.89806  last_update 86\n",
      "train: iter 176  trainloss 3.11628  validloss 6.23322±0.00000  bestvalidloss 5.89806  last_update 87\n",
      "train: iter 177  trainloss 3.13484  validloss 6.63815±0.00000  bestvalidloss 5.89806  last_update 88\n",
      "train: iter 178  trainloss 3.09539  validloss 6.31483±0.00000  bestvalidloss 5.89806  last_update 89\n",
      "train: iter 179  trainloss 3.13171  validloss 6.33803±0.00000  bestvalidloss 5.89806  last_update 90\n",
      "train: iter 180  trainloss 3.12743  validloss 6.34217±0.00000  bestvalidloss 5.89806  last_update 91\n",
      "train: iter 181  trainloss 3.13118  validloss 6.65224±0.00000  bestvalidloss 5.89806  last_update 92\n",
      "train: iter 182  trainloss 3.10615  validloss 6.35062±0.00000  bestvalidloss 5.89806  last_update 93\n",
      "train: iter 183  trainloss 3.14708  validloss 6.36903±0.00000  bestvalidloss 5.89806  last_update 94\n",
      "train: iter 184  trainloss 3.12652  validloss 6.22607±0.00000  bestvalidloss 5.89806  last_update 95\n",
      "train: iter 185  trainloss 3.09210  validloss 6.49167±0.00000  bestvalidloss 5.89806  last_update 96\n",
      "train: iter 186  trainloss 3.16919  validloss 6.80460±0.00000  bestvalidloss 5.89806  last_update 97\n",
      "train: iter 187  trainloss 3.12703  validloss 6.39322±0.00000  bestvalidloss 5.89806  last_update 98\n",
      "train: iter 188  trainloss 3.15094  validloss 6.33998±0.00000  bestvalidloss 5.89806  last_update 99\n",
      "train: iter 189  trainloss 3.13599  validloss 6.25723±0.00000  bestvalidloss 5.89806  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-4.7190)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(-5.4964)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.159570651560175\n",
      "tensor([-0.2419])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00668164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca3b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d5ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef8791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95733b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
