{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(-3111.6760)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 9628.78181  validloss 145387.74301±0.00000  bestvalidloss 145387.74301  last_update 0\n",
      "train: iter 1  trainloss 1602.82315  validloss 1308.59082±0.00000  bestvalidloss 1308.59082  last_update 0\n",
      "train: iter 2  trainloss 1211.60794  validloss 1882.29360±0.00000  bestvalidloss 1308.59082  last_update 1\n",
      "train: iter 3  trainloss 1037.39418  validloss 1270.23140±0.00000  bestvalidloss 1270.23140  last_update 0\n",
      "train: iter 4  trainloss 1049.77237  validloss 1131.20697±0.00000  bestvalidloss 1131.20697  last_update 0\n",
      "train: iter 5  trainloss 942.96856  validloss 1025.91362±0.00000  bestvalidloss 1025.91362  last_update 0\n",
      "train: iter 6  trainloss 901.62190  validloss 907.96852±0.00000  bestvalidloss 907.96852  last_update 0\n",
      "train: iter 7  trainloss 865.15896  validloss 889.73529±0.00000  bestvalidloss 889.73529  last_update 0\n",
      "train: iter 8  trainloss 837.50042  validloss 871.04382±0.00000  bestvalidloss 871.04382  last_update 0\n",
      "train: iter 9  trainloss 812.85901  validloss 844.93710±0.00000  bestvalidloss 844.93710  last_update 0\n",
      "train: iter 10  trainloss 832.26312  validloss 843.29950±0.00000  bestvalidloss 843.29950  last_update 0\n",
      "train: iter 11  trainloss 785.26924  validloss 818.69009±0.00000  bestvalidloss 818.69009  last_update 0\n",
      "train: iter 12  trainloss 783.65239  validloss 795.47641±0.00000  bestvalidloss 795.47641  last_update 0\n",
      "train: iter 13  trainloss 730.55653  validloss 746.75695±0.00000  bestvalidloss 746.75695  last_update 0\n",
      "train: iter 14  trainloss 692.89314  validloss 738.82713±0.00000  bestvalidloss 738.82713  last_update 0\n",
      "train: iter 15  trainloss 700.12209  validloss 724.15729±0.00000  bestvalidloss 724.15729  last_update 0\n",
      "train: iter 16  trainloss 610.22483  validloss 669.37566±0.00000  bestvalidloss 669.37566  last_update 0\n",
      "train: iter 17  trainloss 534.78390  validloss 621.72222±0.00000  bestvalidloss 621.72222  last_update 0\n",
      "train: iter 18  trainloss 480.16329  validloss 604.58786±0.00000  bestvalidloss 604.58786  last_update 0\n",
      "train: iter 19  trainloss 374.34597  validloss 482.76102±0.00000  bestvalidloss 482.76102  last_update 0\n",
      "train: iter 20  trainloss 296.40732  validloss 348.03359±0.00000  bestvalidloss 348.03359  last_update 0\n",
      "train: iter 21  trainloss 242.38054  validloss 291.63911±0.00000  bestvalidloss 291.63911  last_update 0\n",
      "train: iter 22  trainloss 246.90679  validloss 408.56609±0.00000  bestvalidloss 291.63911  last_update 1\n",
      "train: iter 23  trainloss 221.73739  validloss 246.91163±0.00000  bestvalidloss 246.91163  last_update 0\n",
      "train: iter 24  trainloss 120.87295  validloss 196.45255±0.00000  bestvalidloss 196.45255  last_update 0\n",
      "train: iter 25  trainloss 80.40764  validloss 220.83432±0.00000  bestvalidloss 196.45255  last_update 1\n",
      "train: iter 26  trainloss 39.55891  validloss 155.44316±0.00000  bestvalidloss 155.44316  last_update 0\n",
      "train: iter 27  trainloss 6.80086  validloss 69.02376±0.00000  bestvalidloss 69.02376  last_update 0\n",
      "train: iter 28  trainloss -54.23621  validloss 44.51058±0.00000  bestvalidloss 44.51058  last_update 0\n",
      "train: iter 29  trainloss -44.55462  validloss 59.94146±0.00000  bestvalidloss 44.51058  last_update 1\n",
      "train: iter 30  trainloss -117.50838  validloss -6.46861±0.00000  bestvalidloss -6.46861  last_update 0\n",
      "train: iter 31  trainloss -120.47864  validloss -84.69630±0.00000  bestvalidloss -84.69630  last_update 0\n",
      "train: iter 32  trainloss -58.86446  validloss 34.22713±0.00000  bestvalidloss -84.69630  last_update 1\n",
      "train: iter 33  trainloss -162.02336  validloss -97.95608±0.00000  bestvalidloss -97.95608  last_update 0\n",
      "train: iter 34  trainloss -203.59767  validloss -139.70317±0.00000  bestvalidloss -139.70317  last_update 0\n",
      "train: iter 35  trainloss -205.12598  validloss -155.47739±0.00000  bestvalidloss -155.47739  last_update 0\n",
      "train: iter 36  trainloss -236.08213  validloss -145.26075±0.00000  bestvalidloss -155.47739  last_update 1\n",
      "train: iter 37  trainloss -196.69634  validloss -87.35274±0.00000  bestvalidloss -155.47739  last_update 2\n",
      "train: iter 38  trainloss -268.28528  validloss -93.99523±0.00000  bestvalidloss -155.47739  last_update 3\n",
      "train: iter 39  trainloss -238.55401  validloss -132.75218±0.00000  bestvalidloss -155.47739  last_update 4\n",
      "train: iter 40  trainloss -334.27486  validloss -243.08621±0.00000  bestvalidloss -243.08621  last_update 0\n",
      "train: iter 41  trainloss -294.71982  validloss -57.90268±0.00000  bestvalidloss -243.08621  last_update 1\n",
      "train: iter 42  trainloss -314.25103  validloss -267.31320±0.00000  bestvalidloss -267.31320  last_update 0\n",
      "train: iter 43  trainloss -384.38976  validloss -309.13525±0.00000  bestvalidloss -309.13525  last_update 0\n",
      "train: iter 44  trainloss -398.43907  validloss -208.78485±0.00000  bestvalidloss -309.13525  last_update 1\n",
      "train: iter 45  trainloss -386.29974  validloss -113.65207±0.00000  bestvalidloss -309.13525  last_update 2\n",
      "train: iter 46  trainloss -389.64361  validloss -267.98198±0.00000  bestvalidloss -309.13525  last_update 3\n",
      "train: iter 47  trainloss -393.29964  validloss -316.58865±0.00000  bestvalidloss -316.58865  last_update 0\n",
      "train: iter 48  trainloss -335.61614  validloss -279.23789±0.00000  bestvalidloss -316.58865  last_update 1\n",
      "train: iter 49  trainloss -325.32787  validloss -309.71050±0.00000  bestvalidloss -316.58865  last_update 2\n",
      "train: iter 50  trainloss -459.75110  validloss -387.89139±0.00000  bestvalidloss -387.89139  last_update 0\n",
      "train: iter 51  trainloss -302.68088  validloss -227.21075±0.00000  bestvalidloss -387.89139  last_update 1\n",
      "train: iter 52  trainloss -265.40725  validloss -233.52017±0.00000  bestvalidloss -387.89139  last_update 2\n",
      "train: iter 53  trainloss -501.37149  validloss -436.30995±0.00000  bestvalidloss -436.30995  last_update 0\n",
      "train: iter 54  trainloss -509.26415  validloss -416.48374±0.00000  bestvalidloss -436.30995  last_update 1\n",
      "train: iter 55  trainloss -526.07806  validloss -485.12163±0.00000  bestvalidloss -485.12163  last_update 0\n",
      "train: iter 56  trainloss -482.64797  validloss -308.28428±0.00000  bestvalidloss -485.12163  last_update 1\n",
      "train: iter 57  trainloss -510.37429  validloss -409.68428±0.00000  bestvalidloss -485.12163  last_update 2\n",
      "train: iter 58  trainloss -334.05103  validloss -287.00760±0.00000  bestvalidloss -485.12163  last_update 3\n",
      "train: iter 59  trainloss -573.47598  validloss -461.33176±0.00000  bestvalidloss -485.12163  last_update 4\n",
      "train: iter 60  trainloss -575.96611  validloss -402.41251±0.00000  bestvalidloss -485.12163  last_update 5\n",
      "train: iter 61  trainloss -577.98218  validloss -520.38774±0.00000  bestvalidloss -520.38774  last_update 0\n",
      "train: iter 62  trainloss -569.63186  validloss -519.23585±0.00000  bestvalidloss -520.38774  last_update 1\n",
      "train: iter 63  trainloss -638.49208  validloss -517.83978±0.00000  bestvalidloss -520.38774  last_update 2\n",
      "train: iter 64  trainloss -643.23116  validloss -511.67582±0.00000  bestvalidloss -520.38774  last_update 3\n",
      "train: iter 65  trainloss -617.20141  validloss -549.95222±0.00000  bestvalidloss -549.95222  last_update 0\n",
      "train: iter 66  trainloss -631.36212  validloss -514.47554±0.00000  bestvalidloss -549.95222  last_update 1\n",
      "train: iter 67  trainloss -651.25894  validloss -352.27622±0.00000  bestvalidloss -549.95222  last_update 2\n",
      "train: iter 68  trainloss -469.18351  validloss -553.56456±0.00000  bestvalidloss -553.56456  last_update 0\n",
      "train: iter 69  trainloss -441.90733  validloss -122.78662±0.00000  bestvalidloss -553.56456  last_update 1\n",
      "train: iter 70  trainloss -692.58917  validloss -586.09183±0.00000  bestvalidloss -586.09183  last_update 0\n",
      "train: iter 71  trainloss -601.52822  validloss -627.54835±0.00000  bestvalidloss -627.54835  last_update 0\n",
      "train: iter 72  trainloss -586.20078  validloss -569.89803±0.00000  bestvalidloss -627.54835  last_update 1\n",
      "train: iter 73  trainloss -615.69850  validloss -573.09343±0.00000  bestvalidloss -627.54835  last_update 2\n",
      "train: iter 74  trainloss -663.19674  validloss -525.32929±0.00000  bestvalidloss -627.54835  last_update 3\n",
      "train: iter 75  trainloss -658.35251  validloss -665.63492±0.00000  bestvalidloss -665.63492  last_update 0\n",
      "train: iter 76  trainloss -698.35205  validloss -522.29709±0.00000  bestvalidloss -665.63492  last_update 1\n",
      "train: iter 77  trainloss -725.48785  validloss -706.40923±0.00000  bestvalidloss -706.40923  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 78  trainloss -742.02817  validloss -725.76196±0.00000  bestvalidloss -725.76196  last_update 0\n",
      "train: iter 79  trainloss -695.48756  validloss -615.90422±0.00000  bestvalidloss -725.76196  last_update 1\n",
      "train: iter 80  trainloss -494.16154  validloss -468.33003±0.00000  bestvalidloss -725.76196  last_update 2\n",
      "train: iter 81  trainloss -674.88547  validloss -548.54527±0.00000  bestvalidloss -725.76196  last_update 3\n",
      "train: iter 82  trainloss -680.38605  validloss -602.75893±0.00000  bestvalidloss -725.76196  last_update 4\n",
      "train: iter 83  trainloss -782.48152  validloss -692.98703±0.00000  bestvalidloss -725.76196  last_update 5\n",
      "train: iter 84  trainloss -750.47007  validloss -704.46642±0.00000  bestvalidloss -725.76196  last_update 6\n",
      "train: iter 85  trainloss -716.97749  validloss -612.64568±0.00000  bestvalidloss -725.76196  last_update 7\n",
      "train: iter 86  trainloss -804.95307  validloss -741.85679±0.00000  bestvalidloss -741.85679  last_update 0\n",
      "train: iter 87  trainloss -780.51680  validloss -711.02816±0.00000  bestvalidloss -741.85679  last_update 1\n",
      "train: iter 88  trainloss -814.36302  validloss -739.72394±0.00000  bestvalidloss -741.85679  last_update 2\n",
      "train: iter 89  trainloss -692.82063  validloss -693.29284±0.00000  bestvalidloss -741.85679  last_update 3\n",
      "train: iter 90  trainloss -793.83761  validloss -759.62645±0.00000  bestvalidloss -759.62645  last_update 0\n",
      "train: iter 91  trainloss -784.18947  validloss -644.25407±0.00000  bestvalidloss -759.62645  last_update 1\n",
      "train: iter 92  trainloss -802.63654  validloss -747.83212±0.00000  bestvalidloss -759.62645  last_update 2\n",
      "train: iter 93  trainloss -783.78516  validloss -750.13485±0.00000  bestvalidloss -759.62645  last_update 3\n",
      "train: iter 94  trainloss -704.90994  validloss -604.58936±0.00000  bestvalidloss -759.62645  last_update 4\n",
      "train: iter 95  trainloss -655.23583  validloss -822.95293±0.00000  bestvalidloss -822.95293  last_update 0\n",
      "train: iter 96  trainloss -774.35243  validloss -600.17300±0.00000  bestvalidloss -822.95293  last_update 1\n",
      "train: iter 97  trainloss -751.11750  validloss -635.32876±0.00000  bestvalidloss -822.95293  last_update 2\n",
      "train: iter 98  trainloss -830.59541  validloss -682.95670±0.00000  bestvalidloss -822.95293  last_update 3\n",
      "train: iter 99  trainloss -656.60518  validloss -740.03614±0.00000  bestvalidloss -822.95293  last_update 4\n",
      "train: iter 100  trainloss -759.12050  validloss -686.18795±0.00000  bestvalidloss -822.95293  last_update 5\n",
      "train: iter 101  trainloss -798.85173  validloss -841.94203±0.00000  bestvalidloss -841.94203  last_update 0\n",
      "train: iter 102  trainloss -817.25664  validloss -766.32965±0.00000  bestvalidloss -841.94203  last_update 1\n",
      "train: iter 103  trainloss -855.36895  validloss -764.98959±0.00000  bestvalidloss -841.94203  last_update 2\n",
      "train: iter 104  trainloss -915.59640  validloss -806.82583±0.00000  bestvalidloss -841.94203  last_update 3\n",
      "train: iter 105  trainloss -584.91360  validloss -788.13534±0.00000  bestvalidloss -841.94203  last_update 4\n",
      "train: iter 106  trainloss -662.48078  validloss -693.56211±0.00000  bestvalidloss -841.94203  last_update 5\n",
      "train: iter 107  trainloss -782.04489  validloss -651.99207±0.00000  bestvalidloss -841.94203  last_update 6\n",
      "train: iter 108  trainloss -751.46865  validloss -740.00212±0.00000  bestvalidloss -841.94203  last_update 7\n",
      "train: iter 109  trainloss -767.13524  validloss -721.35357±0.00000  bestvalidloss -841.94203  last_update 8\n",
      "train: iter 110  trainloss -848.46456  validloss -825.76664±0.00000  bestvalidloss -841.94203  last_update 9\n",
      "train: iter 111  trainloss -796.59334  validloss -823.86573±0.00000  bestvalidloss -841.94203  last_update 10\n",
      "train: iter 112  trainloss -913.66880  validloss -873.10391±0.00000  bestvalidloss -873.10391  last_update 0\n",
      "train: iter 113  trainloss -854.79789  validloss -876.67054±0.00000  bestvalidloss -876.67054  last_update 0\n",
      "train: iter 114  trainloss -904.70171  validloss -845.89051±0.00000  bestvalidloss -876.67054  last_update 1\n",
      "train: iter 115  trainloss -858.60980  validloss -882.55872±0.00000  bestvalidloss -882.55872  last_update 0\n",
      "train: iter 116  trainloss -922.94515  validloss -918.64751±0.00000  bestvalidloss -918.64751  last_update 0\n",
      "train: iter 117  trainloss -833.32270  validloss -846.87804±0.00000  bestvalidloss -918.64751  last_update 1\n",
      "train: iter 118  trainloss -891.82279  validloss -795.44533±0.00000  bestvalidloss -918.64751  last_update 2\n",
      "train: iter 119  trainloss -892.86889  validloss -875.90307±0.00000  bestvalidloss -918.64751  last_update 3\n",
      "train: iter 120  trainloss -845.30162  validloss -797.49714±0.00000  bestvalidloss -918.64751  last_update 4\n",
      "train: iter 121  trainloss -906.28473  validloss -893.75466±0.00000  bestvalidloss -918.64751  last_update 5\n",
      "train: iter 122  trainloss -630.38209  validloss -827.52023±0.00000  bestvalidloss -918.64751  last_update 6\n",
      "train: iter 123  trainloss -881.01639  validloss -560.21554±0.00000  bestvalidloss -918.64751  last_update 7\n",
      "train: iter 124  trainloss -840.70360  validloss -876.74925±0.00000  bestvalidloss -918.64751  last_update 8\n",
      "train: iter 125  trainloss -866.05130  validloss -732.82470±0.00000  bestvalidloss -918.64751  last_update 9\n",
      "train: iter 126  trainloss -919.38739  validloss -696.03558±0.00000  bestvalidloss -918.64751  last_update 10\n",
      "train: iter 127  trainloss -944.56898  validloss -934.03951±0.00000  bestvalidloss -934.03951  last_update 0\n",
      "train: iter 128  trainloss -1003.14566  validloss -923.16509±0.00000  bestvalidloss -934.03951  last_update 1\n",
      "train: iter 129  trainloss -946.29556  validloss -938.62651±0.00000  bestvalidloss -938.62651  last_update 0\n",
      "train: iter 130  trainloss -868.30945  validloss -928.17731±0.00000  bestvalidloss -938.62651  last_update 1\n",
      "train: iter 131  trainloss -818.94874  validloss -561.28129±0.00000  bestvalidloss -938.62651  last_update 2\n",
      "train: iter 132  trainloss -963.51416  validloss -872.47429±0.00000  bestvalidloss -938.62651  last_update 3\n",
      "train: iter 133  trainloss -850.20042  validloss -935.12402±0.00000  bestvalidloss -938.62651  last_update 4\n",
      "train: iter 134  trainloss -869.66872  validloss -593.83598±0.00000  bestvalidloss -938.62651  last_update 5\n",
      "train: iter 135  trainloss -937.67099  validloss -919.64806±0.00000  bestvalidloss -938.62651  last_update 6\n",
      "train: iter 136  trainloss -936.47308  validloss -905.64156±0.00000  bestvalidloss -938.62651  last_update 7\n",
      "train: iter 137  trainloss -911.65769  validloss -921.94546±0.00000  bestvalidloss -938.62651  last_update 8\n",
      "train: iter 138  trainloss -874.85368  validloss -962.30985±0.00000  bestvalidloss -962.30985  last_update 0\n",
      "train: iter 139  trainloss -933.11757  validloss -895.05756±0.00000  bestvalidloss -962.30985  last_update 1\n",
      "train: iter 140  trainloss -993.21609  validloss -845.32259±0.00000  bestvalidloss -962.30985  last_update 2\n",
      "train: iter 141  trainloss -983.90114  validloss -854.48036±0.00000  bestvalidloss -962.30985  last_update 3\n",
      "train: iter 142  trainloss -946.27373  validloss -823.09797±0.00000  bestvalidloss -962.30985  last_update 4\n",
      "train: iter 143  trainloss -988.50799  validloss -911.61665±0.00000  bestvalidloss -962.30985  last_update 5\n",
      "train: iter 144  trainloss -1050.15869  validloss -1012.27430±0.00000  bestvalidloss -1012.27430  last_update 0\n",
      "train: iter 145  trainloss -1038.71730  validloss -953.65859±0.00000  bestvalidloss -1012.27430  last_update 1\n",
      "train: iter 146  trainloss -854.90615  validloss -824.38680±0.00000  bestvalidloss -1012.27430  last_update 2\n",
      "train: iter 147  trainloss -996.44672  validloss -924.40447±0.00000  bestvalidloss -1012.27430  last_update 3\n",
      "train: iter 148  trainloss -976.79625  validloss -857.85058±0.00000  bestvalidloss -1012.27430  last_update 4\n",
      "train: iter 149  trainloss -1018.74780  validloss -844.78662±0.00000  bestvalidloss -1012.27430  last_update 5\n",
      "train: iter 150  trainloss -863.36655  validloss -920.83668±0.00000  bestvalidloss -1012.27430  last_update 6\n",
      "train: iter 151  trainloss -827.24587  validloss -467.07195±0.00000  bestvalidloss -1012.27430  last_update 7\n",
      "train: iter 152  trainloss -1025.50853  validloss -889.11797±0.00000  bestvalidloss -1012.27430  last_update 8\n",
      "train: iter 153  trainloss -998.45880  validloss -1053.19674±0.00000  bestvalidloss -1053.19674  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 154  trainloss -1012.52669  validloss -901.55830±0.00000  bestvalidloss -1053.19674  last_update 1\n",
      "train: iter 155  trainloss -645.35456  validloss -807.54348±0.00000  bestvalidloss -1053.19674  last_update 2\n",
      "train: iter 156  trainloss -613.91693  validloss -467.96801±0.00000  bestvalidloss -1053.19674  last_update 3\n",
      "train: iter 157  trainloss -654.95817  validloss -212.02460±0.00000  bestvalidloss -1053.19674  last_update 4\n",
      "train: iter 158  trainloss -937.53009  validloss -822.39913±0.00000  bestvalidloss -1053.19674  last_update 5\n",
      "train: iter 159  trainloss -970.74425  validloss -901.43059±0.00000  bestvalidloss -1053.19674  last_update 6\n",
      "train: iter 160  trainloss -1021.25822  validloss -937.10359±0.00000  bestvalidloss -1053.19674  last_update 7\n",
      "train: iter 161  trainloss -957.23495  validloss -982.16740±0.00000  bestvalidloss -1053.19674  last_update 8\n",
      "train: iter 162  trainloss -925.61025  validloss -813.19858±0.00000  bestvalidloss -1053.19674  last_update 9\n",
      "train: iter 163  trainloss -1003.31508  validloss -1020.34215±0.00000  bestvalidloss -1053.19674  last_update 10\n",
      "train: iter 164  trainloss -869.93080  validloss -705.21259±0.00000  bestvalidloss -1053.19674  last_update 11\n",
      "train: iter 165  trainloss -998.47955  validloss -961.85102±0.00000  bestvalidloss -1053.19674  last_update 12\n",
      "train: iter 166  trainloss -902.72601  validloss -970.19681±0.00000  bestvalidloss -1053.19674  last_update 13\n",
      "train: iter 167  trainloss -798.72627  validloss -601.07315±0.00000  bestvalidloss -1053.19674  last_update 14\n",
      "train: iter 168  trainloss -1002.59002  validloss -860.54898±0.00000  bestvalidloss -1053.19674  last_update 15\n",
      "train: iter 169  trainloss -1110.32245  validloss -1051.77831±0.00000  bestvalidloss -1053.19674  last_update 16\n",
      "train: iter 170  trainloss -786.94365  validloss -1019.60610±0.00000  bestvalidloss -1053.19674  last_update 17\n",
      "train: iter 171  trainloss -962.24717  validloss -929.93520±0.00000  bestvalidloss -1053.19674  last_update 18\n",
      "train: iter 172  trainloss -1106.27034  validloss -1066.21219±0.00000  bestvalidloss -1066.21219  last_update 0\n",
      "train: iter 173  trainloss -1038.12557  validloss -898.32016±0.00000  bestvalidloss -1066.21219  last_update 1\n",
      "train: iter 174  trainloss -1065.76622  validloss -923.50859±0.00000  bestvalidloss -1066.21219  last_update 2\n",
      "train: iter 175  trainloss -1098.03797  validloss -1108.43365±0.00000  bestvalidloss -1108.43365  last_update 0\n",
      "train: iter 176  trainloss -1108.05606  validloss -1118.71010±0.00000  bestvalidloss -1118.71010  last_update 0\n",
      "train: iter 177  trainloss -1013.97199  validloss -1033.87209±0.00000  bestvalidloss -1118.71010  last_update 1\n",
      "train: iter 178  trainloss -1089.19726  validloss -1049.71935±0.00000  bestvalidloss -1118.71010  last_update 2\n",
      "train: iter 179  trainloss -1122.76908  validloss -958.68281±0.00000  bestvalidloss -1118.71010  last_update 3\n",
      "train: iter 180  trainloss -1040.86370  validloss -1116.41975±0.00000  bestvalidloss -1118.71010  last_update 4\n",
      "train: iter 181  trainloss -1101.95197  validloss -1041.88342±0.00000  bestvalidloss -1118.71010  last_update 5\n",
      "train: iter 182  trainloss -1090.95141  validloss -1061.18611±0.00000  bestvalidloss -1118.71010  last_update 6\n",
      "train: iter 183  trainloss -1001.12414  validloss -1128.99836±0.00000  bestvalidloss -1128.99836  last_update 0\n",
      "train: iter 184  trainloss -1069.76490  validloss -771.09685±0.00000  bestvalidloss -1128.99836  last_update 1\n",
      "train: iter 185  trainloss -1091.51219  validloss -1054.11875±0.00000  bestvalidloss -1128.99836  last_update 2\n",
      "train: iter 186  trainloss -1111.40369  validloss -1065.40812±0.00000  bestvalidloss -1128.99836  last_update 3\n",
      "train: iter 187  trainloss -1111.44389  validloss -1003.08484±0.00000  bestvalidloss -1128.99836  last_update 4\n",
      "train: iter 188  trainloss -1148.53053  validloss -1020.52986±0.00000  bestvalidloss -1128.99836  last_update 5\n",
      "train: iter 189  trainloss -1122.23456  validloss -888.48604±0.00000  bestvalidloss -1128.99836  last_update 6\n",
      "train: iter 190  trainloss -1116.36656  validloss -1014.33717±0.00000  bestvalidloss -1128.99836  last_update 7\n",
      "train: iter 191  trainloss -1188.44129  validloss -1157.33405±0.00000  bestvalidloss -1157.33405  last_update 0\n",
      "train: iter 192  trainloss -1074.68375  validloss -1114.56561±0.00000  bestvalidloss -1157.33405  last_update 1\n",
      "train: iter 193  trainloss -1025.10320  validloss -1088.23656±0.00000  bestvalidloss -1157.33405  last_update 2\n",
      "train: iter 194  trainloss -1115.80019  validloss -1009.17484±0.00000  bestvalidloss -1157.33405  last_update 3\n",
      "train: iter 195  trainloss -989.24767  validloss -1016.27788±0.00000  bestvalidloss -1157.33405  last_update 4\n",
      "train: iter 196  trainloss -1131.31853  validloss -1055.41684±0.00000  bestvalidloss -1157.33405  last_update 5\n",
      "train: iter 197  trainloss -1050.96353  validloss -1069.98042±0.00000  bestvalidloss -1157.33405  last_update 6\n",
      "train: iter 198  trainloss -1079.26583  validloss -1056.56311±0.00000  bestvalidloss -1157.33405  last_update 7\n",
      "train: iter 199  trainloss -1202.65292  validloss -1136.19292±0.00000  bestvalidloss -1157.33405  last_update 8\n",
      "train: iter 200  trainloss -1210.99347  validloss -1148.10321±0.00000  bestvalidloss -1157.33405  last_update 9\n",
      "train: iter 201  trainloss -1043.40552  validloss -1162.33799±0.00000  bestvalidloss -1162.33799  last_update 0\n",
      "train: iter 202  trainloss -995.17043  validloss -899.97212±0.00000  bestvalidloss -1162.33799  last_update 1\n",
      "train: iter 203  trainloss -1036.33940  validloss -824.06742±0.00000  bestvalidloss -1162.33799  last_update 2\n",
      "train: iter 204  trainloss -1072.44287  validloss -1060.28708±0.00000  bestvalidloss -1162.33799  last_update 3\n",
      "train: iter 205  trainloss -1184.02866  validloss -1138.14151±0.00000  bestvalidloss -1162.33799  last_update 4\n",
      "train: iter 206  trainloss -1144.20767  validloss -1141.23954±0.00000  bestvalidloss -1162.33799  last_update 5\n",
      "train: iter 207  trainloss -1193.34993  validloss -1126.29739±0.00000  bestvalidloss -1162.33799  last_update 6\n",
      "train: iter 208  trainloss -1122.63821  validloss -1169.01659±0.00000  bestvalidloss -1169.01659  last_update 0\n",
      "train: iter 209  trainloss -1171.35453  validloss -1121.10717±0.00000  bestvalidloss -1169.01659  last_update 1\n",
      "train: iter 210  trainloss -1190.46175  validloss -1191.75193±0.00000  bestvalidloss -1191.75193  last_update 0\n",
      "train: iter 211  trainloss -1153.89029  validloss -1039.13443±0.00000  bestvalidloss -1191.75193  last_update 1\n",
      "train: iter 212  trainloss -1207.19444  validloss -1129.30516±0.00000  bestvalidloss -1191.75193  last_update 2\n",
      "train: iter 213  trainloss -1128.92934  validloss -1155.69023±0.00000  bestvalidloss -1191.75193  last_update 3\n",
      "train: iter 214  trainloss -1126.96007  validloss -1020.40610±0.00000  bestvalidloss -1191.75193  last_update 4\n",
      "train: iter 215  trainloss -1222.70827  validloss -1095.42267±0.00000  bestvalidloss -1191.75193  last_update 5\n",
      "train: iter 216  trainloss -1042.36164  validloss -1211.49632±0.00000  bestvalidloss -1211.49632  last_update 0\n",
      "train: iter 217  trainloss -1093.47796  validloss -1065.03854±0.00000  bestvalidloss -1211.49632  last_update 1\n",
      "train: iter 218  trainloss -1150.52281  validloss -976.22985±0.00000  bestvalidloss -1211.49632  last_update 2\n",
      "train: iter 219  trainloss -1240.73127  validloss -1114.64125±0.00000  bestvalidloss -1211.49632  last_update 3\n",
      "train: iter 220  trainloss -1213.59117  validloss -1215.42001±0.00000  bestvalidloss -1215.42001  last_update 0\n",
      "train: iter 221  trainloss -1039.74013  validloss -1138.83098±0.00000  bestvalidloss -1215.42001  last_update 1\n",
      "train: iter 222  trainloss -1220.26506  validloss -1060.82275±0.00000  bestvalidloss -1215.42001  last_update 2\n",
      "train: iter 223  trainloss -1256.46470  validloss -1227.30662±0.00000  bestvalidloss -1227.30662  last_update 0\n",
      "train: iter 224  trainloss -1085.66221  validloss -815.98072±0.00000  bestvalidloss -1227.30662  last_update 1\n",
      "train: iter 225  trainloss -1103.12332  validloss -1071.37745±0.00000  bestvalidloss -1227.30662  last_update 2\n",
      "train: iter 226  trainloss -1066.31439  validloss -834.77975±0.00000  bestvalidloss -1227.30662  last_update 3\n",
      "train: iter 227  trainloss -1193.17946  validloss -1170.82000±0.00000  bestvalidloss -1227.30662  last_update 4\n",
      "train: iter 228  trainloss -1196.32607  validloss -1131.52504±0.00000  bestvalidloss -1227.30662  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 229  trainloss -1258.22914  validloss -1171.80625±0.00000  bestvalidloss -1227.30662  last_update 6\n",
      "train: iter 230  trainloss -1254.26547  validloss -1241.31862±0.00000  bestvalidloss -1241.31862  last_update 0\n",
      "train: iter 231  trainloss -1138.46404  validloss -1192.89447±0.00000  bestvalidloss -1241.31862  last_update 1\n",
      "train: iter 232  trainloss -1189.56068  validloss -1143.29841±0.00000  bestvalidloss -1241.31862  last_update 2\n",
      "train: iter 233  trainloss -1248.49881  validloss -1181.12134±0.00000  bestvalidloss -1241.31862  last_update 3\n",
      "train: iter 234  trainloss -1240.89950  validloss -1227.09728±0.00000  bestvalidloss -1241.31862  last_update 4\n",
      "train: iter 235  trainloss -1193.19250  validloss -1150.65998±0.00000  bestvalidloss -1241.31862  last_update 5\n",
      "train: iter 236  trainloss -1207.72840  validloss -1097.60614±0.00000  bestvalidloss -1241.31862  last_update 6\n",
      "train: iter 237  trainloss -1049.53756  validloss -1146.11715±0.00000  bestvalidloss -1241.31862  last_update 7\n",
      "train: iter 238  trainloss -1275.55730  validloss -1183.31682±0.00000  bestvalidloss -1241.31862  last_update 8\n",
      "train: iter 239  trainloss -1239.88876  validloss -1237.54218±0.00000  bestvalidloss -1241.31862  last_update 9\n",
      "train: iter 240  trainloss -1186.89634  validloss -1226.88492±0.00000  bestvalidloss -1241.31862  last_update 10\n",
      "train: iter 241  trainloss -1282.75285  validloss -1250.01590±0.00000  bestvalidloss -1250.01590  last_update 0\n",
      "train: iter 242  trainloss -1288.70529  validloss -1218.67441±0.00000  bestvalidloss -1250.01590  last_update 1\n",
      "train: iter 243  trainloss -1251.59728  validloss -1236.70796±0.00000  bestvalidloss -1250.01590  last_update 2\n",
      "train: iter 244  trainloss -1285.67132  validloss -1235.75531±0.00000  bestvalidloss -1250.01590  last_update 3\n",
      "train: iter 245  trainloss -1171.63065  validloss -1156.17580±0.00000  bestvalidloss -1250.01590  last_update 4\n",
      "train: iter 246  trainloss -1263.36659  validloss -1190.26229±0.00000  bestvalidloss -1250.01590  last_update 5\n",
      "train: iter 247  trainloss -1203.98165  validloss -1194.54097±0.00000  bestvalidloss -1250.01590  last_update 6\n",
      "train: iter 248  trainloss -1255.82323  validloss -1078.12081±0.00000  bestvalidloss -1250.01590  last_update 7\n",
      "train: iter 249  trainloss -1268.63579  validloss -1235.48391±0.00000  bestvalidloss -1250.01590  last_update 8\n",
      "train: iter 250  trainloss -1274.83043  validloss -1174.35815±0.00000  bestvalidloss -1250.01590  last_update 9\n",
      "train: iter 251  trainloss -1262.02048  validloss -1241.43322±0.00000  bestvalidloss -1250.01590  last_update 10\n",
      "train: iter 252  trainloss -1219.39557  validloss -1026.58514±0.00000  bestvalidloss -1250.01590  last_update 11\n",
      "train: iter 253  trainloss -1311.02394  validloss -1212.44224±0.00000  bestvalidloss -1250.01590  last_update 12\n",
      "train: iter 254  trainloss -1269.80999  validloss -1303.00768±0.00000  bestvalidloss -1303.00768  last_update 0\n",
      "train: iter 255  trainloss -1283.24927  validloss -1180.01237±0.00000  bestvalidloss -1303.00768  last_update 1\n",
      "train: iter 256  trainloss -934.03170  validloss -1222.65484±0.00000  bestvalidloss -1303.00768  last_update 2\n",
      "train: iter 257  trainloss -1216.08798  validloss -1032.70135±0.00000  bestvalidloss -1303.00768  last_update 3\n",
      "train: iter 258  trainloss -1305.40286  validloss -1213.70241±0.00000  bestvalidloss -1303.00768  last_update 4\n",
      "train: iter 259  trainloss -1173.15179  validloss -1216.35913±0.00000  bestvalidloss -1303.00768  last_update 5\n",
      "train: iter 260  trainloss -1251.00751  validloss -1197.00343±0.00000  bestvalidloss -1303.00768  last_update 6\n",
      "train: iter 261  trainloss -1183.89952  validloss -1199.28767±0.00000  bestvalidloss -1303.00768  last_update 7\n",
      "train: iter 262  trainloss -1138.58692  validloss -1126.00834±0.00000  bestvalidloss -1303.00768  last_update 8\n",
      "train: iter 263  trainloss -1285.60028  validloss -842.53763±0.00000  bestvalidloss -1303.00768  last_update 9\n",
      "train: iter 264  trainloss -1312.03535  validloss -1238.63295±0.00000  bestvalidloss -1303.00768  last_update 10\n",
      "train: iter 265  trainloss -1324.34894  validloss -1244.86105±0.00000  bestvalidloss -1303.00768  last_update 11\n",
      "train: iter 266  trainloss -1352.95656  validloss -1326.27064±0.00000  bestvalidloss -1326.27064  last_update 0\n",
      "train: iter 267  trainloss -1214.01939  validloss -1243.70449±0.00000  bestvalidloss -1326.27064  last_update 1\n",
      "train: iter 268  trainloss -1200.73251  validloss -1083.26094±0.00000  bestvalidloss -1326.27064  last_update 2\n",
      "train: iter 269  trainloss -1272.96342  validloss -1217.60886±0.00000  bestvalidloss -1326.27064  last_update 3\n",
      "train: iter 270  trainloss -1306.68810  validloss -1292.43364±0.00000  bestvalidloss -1326.27064  last_update 4\n",
      "train: iter 271  trainloss -1127.99294  validloss -1280.84118±0.00000  bestvalidloss -1326.27064  last_update 5\n",
      "train: iter 272  trainloss -1313.17505  validloss -1207.93857±0.00000  bestvalidloss -1326.27064  last_update 6\n",
      "train: iter 273  trainloss -1294.89298  validloss -1284.91927±0.00000  bestvalidloss -1326.27064  last_update 7\n",
      "train: iter 274  trainloss -1370.84952  validloss -1319.93836±0.00000  bestvalidloss -1326.27064  last_update 8\n",
      "train: iter 275  trainloss -1347.09665  validloss -1282.33845±0.00000  bestvalidloss -1326.27064  last_update 9\n",
      "train: iter 276  trainloss -1352.57050  validloss -1292.68075±0.00000  bestvalidloss -1326.27064  last_update 10\n",
      "train: iter 277  trainloss -1366.92866  validloss -1341.95234±0.00000  bestvalidloss -1341.95234  last_update 0\n",
      "train: iter 278  trainloss -1069.38141  validloss -1292.34605±0.00000  bestvalidloss -1341.95234  last_update 1\n",
      "train: iter 279  trainloss -1101.82047  validloss -903.68258±0.00000  bestvalidloss -1341.95234  last_update 2\n",
      "train: iter 280  trainloss -1242.34065  validloss -968.69468±0.00000  bestvalidloss -1341.95234  last_update 3\n",
      "train: iter 281  trainloss -1330.31839  validloss -1240.31292±0.00000  bestvalidloss -1341.95234  last_update 4\n",
      "train: iter 282  trainloss -1354.23930  validloss -1299.83230±0.00000  bestvalidloss -1341.95234  last_update 5\n",
      "train: iter 283  trainloss -1329.63319  validloss -1284.00783±0.00000  bestvalidloss -1341.95234  last_update 6\n",
      "train: iter 284  trainloss -1333.45429  validloss -1215.72413±0.00000  bestvalidloss -1341.95234  last_update 7\n",
      "train: iter 285  trainloss -1394.21634  validloss -1336.39949±0.00000  bestvalidloss -1341.95234  last_update 8\n",
      "train: iter 286  trainloss -1213.62692  validloss -1352.94751±0.00000  bestvalidloss -1352.94751  last_update 0\n",
      "train: iter 287  trainloss -1152.84014  validloss -1031.79288±0.00000  bestvalidloss -1352.94751  last_update 1\n",
      "train: iter 288  trainloss -1280.90138  validloss -1259.93766±0.00000  bestvalidloss -1352.94751  last_update 2\n",
      "train: iter 289  trainloss -1378.17792  validloss -1148.82136±0.00000  bestvalidloss -1352.94751  last_update 3\n",
      "train: iter 290  trainloss -1399.29238  validloss -1370.37202±0.00000  bestvalidloss -1370.37202  last_update 0\n",
      "train: iter 291  trainloss -1375.11223  validloss -1388.17607±0.00000  bestvalidloss -1388.17607  last_update 0\n",
      "train: iter 292  trainloss -1320.28403  validloss -1078.75511±0.00000  bestvalidloss -1388.17607  last_update 1\n",
      "train: iter 293  trainloss -1376.94763  validloss -1329.25797±0.00000  bestvalidloss -1388.17607  last_update 2\n",
      "train: iter 294  trainloss -1381.54985  validloss -1369.29285±0.00000  bestvalidloss -1388.17607  last_update 3\n",
      "train: iter 295  trainloss -1373.60526  validloss -1384.41675±0.00000  bestvalidloss -1388.17607  last_update 4\n",
      "train: iter 296  trainloss -1327.49224  validloss -1344.57290±0.00000  bestvalidloss -1388.17607  last_update 5\n",
      "train: iter 297  trainloss -1440.39087  validloss -1316.22016±0.00000  bestvalidloss -1388.17607  last_update 6\n",
      "train: iter 298  trainloss -1297.70935  validloss -1355.57558±0.00000  bestvalidloss -1388.17607  last_update 7\n",
      "train: iter 299  trainloss -1364.48897  validloss -1278.92344±0.00000  bestvalidloss -1388.17607  last_update 8\n",
      "train: iter 300  trainloss -1326.69997  validloss -1312.89720±0.00000  bestvalidloss -1388.17607  last_update 9\n",
      "train: iter 301  trainloss -1276.61858  validloss -929.02429±0.00000  bestvalidloss -1388.17607  last_update 10\n",
      "train: iter 302  trainloss -1390.89900  validloss -1339.49233±0.00000  bestvalidloss -1388.17607  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 303  trainloss -1174.69213  validloss -1226.35614±0.00000  bestvalidloss -1388.17607  last_update 12\n",
      "train: iter 304  trainloss -1387.45459  validloss -1318.47112±0.00000  bestvalidloss -1388.17607  last_update 13\n",
      "train: iter 305  trainloss -1411.38744  validloss -1371.19371±0.00000  bestvalidloss -1388.17607  last_update 14\n",
      "train: iter 306  trainloss -1244.40435  validloss -1390.94641±0.00000  bestvalidloss -1390.94641  last_update 0\n",
      "train: iter 307  trainloss -1307.53243  validloss -1353.02233±0.00000  bestvalidloss -1390.94641  last_update 1\n",
      "train: iter 308  trainloss -1361.70063  validloss -1284.65811±0.00000  bestvalidloss -1390.94641  last_update 2\n",
      "train: iter 309  trainloss -1383.91832  validloss -1361.94177±0.00000  bestvalidloss -1390.94641  last_update 3\n",
      "train: iter 310  trainloss -1242.22861  validloss -1360.10658±0.00000  bestvalidloss -1390.94641  last_update 4\n",
      "train: iter 311  trainloss -1376.07108  validloss -1278.22784±0.00000  bestvalidloss -1390.94641  last_update 5\n",
      "train: iter 312  trainloss -1287.68414  validloss -1312.55544±0.00000  bestvalidloss -1390.94641  last_update 6\n",
      "train: iter 313  trainloss -1254.16167  validloss -1298.98852±0.00000  bestvalidloss -1390.94641  last_update 7\n",
      "train: iter 314  trainloss -1243.56164  validloss -1160.52738±0.00000  bestvalidloss -1390.94641  last_update 8\n",
      "train: iter 315  trainloss -1364.24715  validloss -1213.60315±0.00000  bestvalidloss -1390.94641  last_update 9\n",
      "train: iter 316  trainloss -1438.08074  validloss -1361.87743±0.00000  bestvalidloss -1390.94641  last_update 10\n",
      "train: iter 317  trainloss -1483.35043  validloss -1409.86702±0.00000  bestvalidloss -1409.86702  last_update 0\n",
      "train: iter 318  trainloss -1430.35406  validloss -1431.97701±0.00000  bestvalidloss -1431.97701  last_update 0\n",
      "train: iter 319  trainloss -1241.68470  validloss -1333.22488±0.00000  bestvalidloss -1431.97701  last_update 1\n",
      "train: iter 320  trainloss -1455.31583  validloss -1324.24708±0.00000  bestvalidloss -1431.97701  last_update 2\n",
      "train: iter 321  trainloss -1427.05336  validloss -1359.98399±0.00000  bestvalidloss -1431.97701  last_update 3\n",
      "train: iter 322  trainloss -1413.53831  validloss -1399.47308±0.00000  bestvalidloss -1431.97701  last_update 4\n",
      "train: iter 323  trainloss -1470.87113  validloss -1431.15752±0.00000  bestvalidloss -1431.97701  last_update 5\n",
      "train: iter 324  trainloss -1458.81936  validloss -1452.17251±0.00000  bestvalidloss -1452.17251  last_update 0\n",
      "train: iter 325  trainloss -1376.81169  validloss -1409.85956±0.00000  bestvalidloss -1452.17251  last_update 1\n",
      "train: iter 326  trainloss -1445.40237  validloss -1331.80658±0.00000  bestvalidloss -1452.17251  last_update 2\n",
      "train: iter 327  trainloss -1500.66500  validloss -1328.73416±0.00000  bestvalidloss -1452.17251  last_update 3\n",
      "train: iter 328  trainloss -1178.26167  validloss -1410.86664±0.00000  bestvalidloss -1452.17251  last_update 4\n",
      "train: iter 329  trainloss -1262.40156  validloss -1225.76666±0.00000  bestvalidloss -1452.17251  last_update 5\n",
      "train: iter 330  trainloss -1384.75565  validloss -1269.53375±0.00000  bestvalidloss -1452.17251  last_update 6\n",
      "train: iter 331  trainloss -1444.88699  validloss -1400.94040±0.00000  bestvalidloss -1452.17251  last_update 7\n",
      "train: iter 332  trainloss -1449.46963  validloss -1423.96143±0.00000  bestvalidloss -1452.17251  last_update 8\n",
      "train: iter 333  trainloss -1407.13410  validloss -1328.89640±0.00000  bestvalidloss -1452.17251  last_update 9\n",
      "train: iter 334  trainloss -1444.23695  validloss -1241.26125±0.00000  bestvalidloss -1452.17251  last_update 10\n",
      "train: iter 335  trainloss -1477.94191  validloss -1430.08936±0.00000  bestvalidloss -1452.17251  last_update 11\n",
      "train: iter 336  trainloss -1352.09821  validloss -1388.69508±0.00000  bestvalidloss -1452.17251  last_update 12\n",
      "train: iter 337  trainloss -1473.20325  validloss -1399.68398±0.00000  bestvalidloss -1452.17251  last_update 13\n",
      "train: iter 338  trainloss -1497.14478  validloss -1404.35939±0.00000  bestvalidloss -1452.17251  last_update 14\n",
      "train: iter 339  trainloss -1291.48344  validloss -1396.86628±0.00000  bestvalidloss -1452.17251  last_update 15\n",
      "train: iter 340  trainloss -1471.95150  validloss -1332.77513±0.00000  bestvalidloss -1452.17251  last_update 16\n",
      "train: iter 341  trainloss -1505.39561  validloss -1467.77122±0.00000  bestvalidloss -1467.77122  last_update 0\n",
      "train: iter 342  trainloss -1387.86164  validloss -1378.63813±0.00000  bestvalidloss -1467.77122  last_update 1\n",
      "train: iter 343  trainloss -1399.04061  validloss -1429.04449±0.00000  bestvalidloss -1467.77122  last_update 2\n",
      "train: iter 344  trainloss -1435.50950  validloss -1378.67377±0.00000  bestvalidloss -1467.77122  last_update 3\n",
      "train: iter 345  trainloss -1454.30968  validloss -1459.75985±0.00000  bestvalidloss -1467.77122  last_update 4\n",
      "train: iter 346  trainloss -1467.84513  validloss -1448.33141±0.00000  bestvalidloss -1467.77122  last_update 5\n",
      "train: iter 347  trainloss -1190.20875  validloss -1325.14427±0.00000  bestvalidloss -1467.77122  last_update 6\n",
      "train: iter 348  trainloss -1429.07185  validloss -1293.66249±0.00000  bestvalidloss -1467.77122  last_update 7\n",
      "train: iter 349  trainloss -1367.55789  validloss -1392.98846±0.00000  bestvalidloss -1467.77122  last_update 8\n",
      "train: iter 350  trainloss -1460.84613  validloss -1348.03037±0.00000  bestvalidloss -1467.77122  last_update 9\n",
      "train: iter 351  trainloss -1403.92253  validloss -1303.84350±0.00000  bestvalidloss -1467.77122  last_update 10\n",
      "train: iter 352  trainloss -1493.23647  validloss -1396.71251±0.00000  bestvalidloss -1467.77122  last_update 11\n",
      "train: iter 353  trainloss -1536.06650  validloss -1488.76362±0.00000  bestvalidloss -1488.76362  last_update 0\n",
      "train: iter 354  trainloss -1321.31314  validloss -1430.29366±0.00000  bestvalidloss -1488.76362  last_update 1\n",
      "train: iter 355  trainloss -1484.46864  validloss -1381.72743±0.00000  bestvalidloss -1488.76362  last_update 2\n",
      "train: iter 356  trainloss -1517.70472  validloss -1439.02710±0.00000  bestvalidloss -1488.76362  last_update 3\n",
      "train: iter 357  trainloss -1521.80019  validloss -1446.79843±0.00000  bestvalidloss -1488.76362  last_update 4\n",
      "train: iter 358  trainloss -1225.20708  validloss -1409.73431±0.00000  bestvalidloss -1488.76362  last_update 5\n",
      "train: iter 359  trainloss -1416.03795  validloss -1389.68825±0.00000  bestvalidloss -1488.76362  last_update 6\n",
      "train: iter 360  trainloss -1346.53341  validloss -1044.10616±0.00000  bestvalidloss -1488.76362  last_update 7\n",
      "train: iter 361  trainloss -1558.06911  validloss -1483.53563±0.00000  bestvalidloss -1488.76362  last_update 8\n",
      "train: iter 362  trainloss -1436.04293  validloss -1468.35616±0.00000  bestvalidloss -1488.76362  last_update 9\n",
      "train: iter 363  trainloss -1478.30941  validloss -1435.53754±0.00000  bestvalidloss -1488.76362  last_update 10\n",
      "train: iter 364  trainloss -1544.48803  validloss -1430.70757±0.00000  bestvalidloss -1488.76362  last_update 11\n",
      "train: iter 365  trainloss -1526.91519  validloss -1508.26104±0.00000  bestvalidloss -1508.26104  last_update 0\n",
      "train: iter 366  trainloss -1511.63859  validloss -1432.42484±0.00000  bestvalidloss -1508.26104  last_update 1\n",
      "train: iter 367  trainloss -1472.97042  validloss -1487.86841±0.00000  bestvalidloss -1508.26104  last_update 2\n",
      "train: iter 368  trainloss -1450.27523  validloss -1392.71998±0.00000  bestvalidloss -1508.26104  last_update 3\n",
      "train: iter 369  trainloss -1286.55992  validloss -1463.41642±0.00000  bestvalidloss -1508.26104  last_update 4\n",
      "train: iter 370  trainloss -1410.51030  validloss -1192.31591±0.00000  bestvalidloss -1508.26104  last_update 5\n",
      "train: iter 371  trainloss -1436.45470  validloss -1260.27419±0.00000  bestvalidloss -1508.26104  last_update 6\n",
      "train: iter 372  trainloss -1513.96081  validloss -1405.85000±0.00000  bestvalidloss -1508.26104  last_update 7\n",
      "train: iter 373  trainloss -1260.95763  validloss -1406.06904±0.00000  bestvalidloss -1508.26104  last_update 8\n",
      "train: iter 374  trainloss -1386.71339  validloss -1126.91594±0.00000  bestvalidloss -1508.26104  last_update 9\n",
      "train: iter 375  trainloss -1535.11624  validloss -1442.41621±0.00000  bestvalidloss -1508.26104  last_update 10\n",
      "train: iter 376  trainloss -1525.26035  validloss -1469.18745±0.00000  bestvalidloss -1508.26104  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 377  trainloss -1416.06228  validloss -1520.48298±0.00000  bestvalidloss -1520.48298  last_update 0\n",
      "train: iter 378  trainloss -1458.81197  validloss -1347.67050±0.00000  bestvalidloss -1520.48298  last_update 1\n",
      "train: iter 379  trainloss -1390.14422  validloss -1474.41425±0.00000  bestvalidloss -1520.48298  last_update 2\n",
      "train: iter 380  trainloss -1513.74353  validloss -1463.43217±0.00000  bestvalidloss -1520.48298  last_update 3\n",
      "train: iter 381  trainloss -1525.74631  validloss -1504.98348±0.00000  bestvalidloss -1520.48298  last_update 4\n",
      "train: iter 382  trainloss -1536.55518  validloss -1484.40366±0.00000  bestvalidloss -1520.48298  last_update 5\n",
      "train: iter 383  trainloss -1355.77686  validloss -1347.68488±0.00000  bestvalidloss -1520.48298  last_update 6\n",
      "train: iter 384  trainloss -1492.41089  validloss -1398.32019±0.00000  bestvalidloss -1520.48298  last_update 7\n",
      "train: iter 385  trainloss -1538.53041  validloss -1508.55985±0.00000  bestvalidloss -1520.48298  last_update 8\n",
      "train: iter 386  trainloss -875.86266  validloss -1056.48291±0.00000  bestvalidloss -1520.48298  last_update 9\n",
      "train: iter 387  trainloss -1447.11107  validloss -1300.72347±0.00000  bestvalidloss -1520.48298  last_update 10\n",
      "train: iter 388  trainloss -1506.03003  validloss -1452.84232±0.00000  bestvalidloss -1520.48298  last_update 11\n",
      "train: iter 389  trainloss -1550.18114  validloss -1469.35275±0.00000  bestvalidloss -1520.48298  last_update 12\n",
      "train: iter 390  trainloss -1520.55605  validloss -1493.54937±0.00000  bestvalidloss -1520.48298  last_update 13\n",
      "train: iter 391  trainloss -1487.30159  validloss -1424.08804±0.00000  bestvalidloss -1520.48298  last_update 14\n",
      "train: iter 392  trainloss -1442.00903  validloss -1348.49146±0.00000  bestvalidloss -1520.48298  last_update 15\n",
      "train: iter 393  trainloss -1523.48755  validloss -1479.93154±0.00000  bestvalidloss -1520.48298  last_update 16\n",
      "train: iter 394  trainloss -1441.86537  validloss -1414.14227±0.00000  bestvalidloss -1520.48298  last_update 17\n",
      "train: iter 395  trainloss -1480.66761  validloss -1498.52134±0.00000  bestvalidloss -1520.48298  last_update 18\n",
      "train: iter 396  trainloss -1433.40123  validloss -1383.26376±0.00000  bestvalidloss -1520.48298  last_update 19\n",
      "train: iter 397  trainloss -1473.62054  validloss -1454.15231±0.00000  bestvalidloss -1520.48298  last_update 20\n",
      "train: iter 398  trainloss -1541.49695  validloss -1503.37082±0.00000  bestvalidloss -1520.48298  last_update 21\n",
      "train: iter 399  trainloss -1549.52690  validloss -1469.90194±0.00000  bestvalidloss -1520.48298  last_update 22\n",
      "train: iter 400  trainloss -1382.29211  validloss -1222.53915±0.00000  bestvalidloss -1520.48298  last_update 23\n",
      "train: iter 401  trainloss -1525.10412  validloss -1389.26179±0.00000  bestvalidloss -1520.48298  last_update 24\n",
      "train: iter 402  trainloss -1534.06739  validloss -1513.65218±0.00000  bestvalidloss -1520.48298  last_update 25\n",
      "train: iter 403  trainloss -1487.66149  validloss -1495.69025±0.00000  bestvalidloss -1520.48298  last_update 26\n",
      "train: iter 404  trainloss -1514.70660  validloss -1240.13304±0.00000  bestvalidloss -1520.48298  last_update 27\n",
      "train: iter 405  trainloss -1498.90237  validloss -1472.45676±0.00000  bestvalidloss -1520.48298  last_update 28\n",
      "train: iter 406  trainloss -1506.02269  validloss -1526.62117±0.00000  bestvalidloss -1526.62117  last_update 0\n",
      "train: iter 407  trainloss -1538.68416  validloss -1489.79193±0.00000  bestvalidloss -1526.62117  last_update 1\n",
      "train: iter 408  trainloss -1483.56764  validloss -1503.14339±0.00000  bestvalidloss -1526.62117  last_update 2\n",
      "train: iter 409  trainloss -1565.76644  validloss -1491.85058±0.00000  bestvalidloss -1526.62117  last_update 3\n",
      "train: iter 410  trainloss -1572.87311  validloss -1522.42095±0.00000  bestvalidloss -1526.62117  last_update 4\n",
      "train: iter 411  trainloss -1505.34250  validloss -1523.18450±0.00000  bestvalidloss -1526.62117  last_update 5\n",
      "train: iter 412  trainloss -1504.11801  validloss -1338.84486±0.00000  bestvalidloss -1526.62117  last_update 6\n",
      "train: iter 413  trainloss -1481.36835  validloss -1543.76076±0.00000  bestvalidloss -1543.76076  last_update 0\n",
      "train: iter 414  trainloss -1464.95726  validloss -1470.61943±0.00000  bestvalidloss -1543.76076  last_update 1\n",
      "train: iter 415  trainloss -1522.06055  validloss -1493.86694±0.00000  bestvalidloss -1543.76076  last_update 2\n",
      "train: iter 416  trainloss -1529.18886  validloss -1491.21709±0.00000  bestvalidloss -1543.76076  last_update 3\n",
      "train: iter 417  trainloss -1594.58697  validloss -1537.28735±0.00000  bestvalidloss -1543.76076  last_update 4\n",
      "train: iter 418  trainloss -1447.51899  validloss -1546.14307±0.00000  bestvalidloss -1546.14307  last_update 0\n",
      "train: iter 419  trainloss -1534.63589  validloss -1398.75676±0.00000  bestvalidloss -1546.14307  last_update 1\n",
      "train: iter 420  trainloss -1450.70500  validloss -1538.04840±0.00000  bestvalidloss -1546.14307  last_update 2\n",
      "train: iter 421  trainloss -1543.19722  validloss -1431.06451±0.00000  bestvalidloss -1546.14307  last_update 3\n",
      "train: iter 422  trainloss -1487.61374  validloss -1521.02277±0.00000  bestvalidloss -1546.14307  last_update 4\n",
      "train: iter 423  trainloss -1484.70315  validloss -1424.47904±0.00000  bestvalidloss -1546.14307  last_update 5\n",
      "train: iter 424  trainloss -1577.67032  validloss -1473.76705±0.00000  bestvalidloss -1546.14307  last_update 6\n",
      "train: iter 425  trainloss -1606.90017  validloss -1535.10571±0.00000  bestvalidloss -1546.14307  last_update 7\n",
      "train: iter 426  trainloss -1014.15250  validloss -1542.05493±0.00000  bestvalidloss -1546.14307  last_update 8\n",
      "train: iter 427  trainloss -1263.25542  validloss -1104.68660±0.00000  bestvalidloss -1546.14307  last_update 9\n",
      "train: iter 428  trainloss -1397.56123  validloss -1203.46049±0.00000  bestvalidloss -1546.14307  last_update 10\n",
      "train: iter 429  trainloss -1529.47868  validloss -1402.84352±0.00000  bestvalidloss -1546.14307  last_update 11\n",
      "train: iter 430  trainloss -1540.18262  validloss -1483.79348±0.00000  bestvalidloss -1546.14307  last_update 12\n",
      "train: iter 431  trainloss -1539.67439  validloss -1481.73718±0.00000  bestvalidloss -1546.14307  last_update 13\n",
      "train: iter 432  trainloss -1536.00021  validloss -1507.73064±0.00000  bestvalidloss -1546.14307  last_update 14\n",
      "train: iter 433  trainloss -1491.76021  validloss -1468.60754±0.00000  bestvalidloss -1546.14307  last_update 15\n",
      "train: iter 434  trainloss -1547.67678  validloss -1427.61611±0.00000  bestvalidloss -1546.14307  last_update 16\n",
      "train: iter 435  trainloss -1459.52284  validloss -1487.63973±0.00000  bestvalidloss -1546.14307  last_update 17\n",
      "train: iter 436  trainloss -1544.81366  validloss -1523.78528±0.00000  bestvalidloss -1546.14307  last_update 18\n",
      "train: iter 437  trainloss -1581.58779  validloss -1526.54195±0.00000  bestvalidloss -1546.14307  last_update 19\n",
      "train: iter 438  trainloss -1552.94644  validloss -1543.41978±0.00000  bestvalidloss -1546.14307  last_update 20\n",
      "train: iter 439  trainloss -1436.98305  validloss -1436.97880±0.00000  bestvalidloss -1546.14307  last_update 21\n",
      "train: iter 440  trainloss -1516.04109  validloss -1524.60978±0.00000  bestvalidloss -1546.14307  last_update 22\n",
      "train: iter 441  trainloss -1484.56864  validloss -1436.89269±0.00000  bestvalidloss -1546.14307  last_update 23\n",
      "train: iter 442  trainloss -1516.54120  validloss -1500.71353±0.00000  bestvalidloss -1546.14307  last_update 24\n",
      "train: iter 443  trainloss -1565.06636  validloss -1457.82890±0.00000  bestvalidloss -1546.14307  last_update 25\n",
      "train: iter 444  trainloss -1514.19401  validloss -1504.04674±0.00000  bestvalidloss -1546.14307  last_update 26\n",
      "train: iter 445  trainloss -1467.96485  validloss -1510.66232±0.00000  bestvalidloss -1546.14307  last_update 27\n",
      "train: iter 446  trainloss -1548.42755  validloss -1451.71565±0.00000  bestvalidloss -1546.14307  last_update 28\n",
      "train: iter 447  trainloss -1558.62909  validloss -1468.48278±0.00000  bestvalidloss -1546.14307  last_update 29\n",
      "train: iter 448  trainloss -1584.38944  validloss -1508.67223±0.00000  bestvalidloss -1546.14307  last_update 30\n",
      "train: iter 449  trainloss -1384.02169  validloss -1478.95190±0.00000  bestvalidloss -1546.14307  last_update 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 450  trainloss -1516.01860  validloss -1297.72803±0.00000  bestvalidloss -1546.14307  last_update 32\n",
      "train: iter 451  trainloss -1609.99011  validloss -1558.81552±0.00000  bestvalidloss -1558.81552  last_update 0\n",
      "train: iter 452  trainloss -1634.50649  validloss -1581.73737±0.00000  bestvalidloss -1581.73737  last_update 0\n",
      "train: iter 453  trainloss -1165.00519  validloss -1365.38703±0.00000  bestvalidloss -1581.73737  last_update 1\n",
      "train: iter 454  trainloss -1137.53953  validloss -1384.69094±0.00000  bestvalidloss -1581.73737  last_update 2\n",
      "train: iter 455  trainloss -1198.44268  validloss -868.92381±0.00000  bestvalidloss -1581.73737  last_update 3\n",
      "train: iter 456  trainloss -1375.14048  validloss -1300.19933±0.00000  bestvalidloss -1581.73737  last_update 4\n",
      "train: iter 457  trainloss -1471.23514  validloss -1393.79107±0.00000  bestvalidloss -1581.73737  last_update 5\n",
      "train: iter 458  trainloss -1528.43276  validloss -1463.81905±0.00000  bestvalidloss -1581.73737  last_update 6\n",
      "train: iter 459  trainloss -1244.70676  validloss -1401.98357±0.00000  bestvalidloss -1581.73737  last_update 7\n",
      "train: iter 460  trainloss -1477.21693  validloss -1228.99374±0.00000  bestvalidloss -1581.73737  last_update 8\n",
      "train: iter 461  trainloss -1524.85136  validloss -1465.37734±0.00000  bestvalidloss -1581.73737  last_update 9\n",
      "train: iter 462  trainloss -1493.93929  validloss -1422.58392±0.00000  bestvalidloss -1581.73737  last_update 10\n",
      "train: iter 463  trainloss -1568.36157  validloss -1505.87570±0.00000  bestvalidloss -1581.73737  last_update 11\n",
      "train: iter 464  trainloss -1520.28595  validloss -1521.03013±0.00000  bestvalidloss -1581.73737  last_update 12\n",
      "train: iter 465  trainloss -1548.81497  validloss -1469.60470±0.00000  bestvalidloss -1581.73737  last_update 13\n",
      "train: iter 466  trainloss -1569.63232  validloss -1543.07149±0.00000  bestvalidloss -1581.73737  last_update 14\n",
      "train: iter 467  trainloss -1592.19011  validloss -1478.78398±0.00000  bestvalidloss -1581.73737  last_update 15\n",
      "train: iter 468  trainloss -1602.70172  validloss -1553.99332±0.00000  bestvalidloss -1581.73737  last_update 16\n",
      "train: iter 469  trainloss -1440.53301  validloss -1407.66327±0.00000  bestvalidloss -1581.73737  last_update 17\n",
      "train: iter 470  trainloss -1564.51575  validloss -1392.76725±0.00000  bestvalidloss -1581.73737  last_update 18\n",
      "train: iter 471  trainloss -1597.19677  validloss -1541.05608±0.00000  bestvalidloss -1581.73737  last_update 19\n",
      "train: iter 472  trainloss -1555.94788  validloss -1560.45687±0.00000  bestvalidloss -1581.73737  last_update 20\n",
      "train: iter 473  trainloss -1372.97564  validloss -1382.49037±0.00000  bestvalidloss -1581.73737  last_update 21\n",
      "train: iter 474  trainloss -1581.71331  validloss -1497.54552±0.00000  bestvalidloss -1581.73737  last_update 22\n",
      "train: iter 475  trainloss -1587.42609  validloss -1555.10786±0.00000  bestvalidloss -1581.73737  last_update 23\n",
      "train: iter 476  trainloss -1589.43042  validloss -1559.13589±0.00000  bestvalidloss -1581.73737  last_update 24\n",
      "train: iter 477  trainloss -1588.04996  validloss -1476.19849±0.00000  bestvalidloss -1581.73737  last_update 25\n",
      "train: iter 478  trainloss -1464.19723  validloss -1559.55071±0.00000  bestvalidloss -1581.73737  last_update 26\n",
      "train: iter 479  trainloss -1618.39216  validloss -1553.02383±0.00000  bestvalidloss -1581.73737  last_update 27\n",
      "train: iter 480  trainloss -1520.63682  validloss -1545.27981±0.00000  bestvalidloss -1581.73737  last_update 28\n",
      "train: iter 481  trainloss -1562.05624  validloss -1432.40338±0.00000  bestvalidloss -1581.73737  last_update 29\n",
      "train: iter 482  trainloss -1423.90247  validloss -1573.32592±0.00000  bestvalidloss -1581.73737  last_update 30\n",
      "train: iter 483  trainloss -1508.77107  validloss -1465.85255±0.00000  bestvalidloss -1581.73737  last_update 31\n",
      "train: iter 484  trainloss -1582.36616  validloss -1487.38318±0.00000  bestvalidloss -1581.73737  last_update 32\n",
      "train: iter 485  trainloss -1544.73044  validloss -1536.26351±0.00000  bestvalidloss -1581.73737  last_update 33\n",
      "train: iter 486  trainloss -1384.26637  validloss -1461.01037±0.00000  bestvalidloss -1581.73737  last_update 34\n",
      "train: iter 487  trainloss -1507.73399  validloss -1426.91156±0.00000  bestvalidloss -1581.73737  last_update 35\n",
      "train: iter 488  trainloss -1475.79245  validloss -1505.36721±0.00000  bestvalidloss -1581.73737  last_update 36\n",
      "train: iter 489  trainloss -1459.43824  validloss -1409.17897±0.00000  bestvalidloss -1581.73737  last_update 37\n",
      "train: iter 490  trainloss -1522.15569  validloss -1359.85881±0.00000  bestvalidloss -1581.73737  last_update 38\n",
      "train: iter 491  trainloss -1587.44347  validloss -1501.17455±0.00000  bestvalidloss -1581.73737  last_update 39\n",
      "train: iter 492  trainloss -1566.85521  validloss -1482.12834±0.00000  bestvalidloss -1581.73737  last_update 40\n",
      "train: iter 493  trainloss -1571.37268  validloss -1546.96361±0.00000  bestvalidloss -1581.73737  last_update 41\n",
      "train: iter 494  trainloss -1573.68007  validloss -1427.28279±0.00000  bestvalidloss -1581.73737  last_update 42\n",
      "train: iter 495  trainloss -1564.30403  validloss -1561.02097±0.00000  bestvalidloss -1581.73737  last_update 43\n",
      "train: iter 496  trainloss -1509.56578  validloss -1443.42818±0.00000  bestvalidloss -1581.73737  last_update 44\n",
      "train: iter 497  trainloss -1537.99748  validloss -1507.01733±0.00000  bestvalidloss -1581.73737  last_update 45\n",
      "train: iter 498  trainloss -1566.27443  validloss -1474.96308±0.00000  bestvalidloss -1581.73737  last_update 46\n",
      "train: iter 499  trainloss -1615.41515  validloss -1500.56062±0.00000  bestvalidloss -1581.73737  last_update 47\n",
      "train: iter 500  trainloss -1608.85338  validloss -1574.68634±0.00000  bestvalidloss -1581.73737  last_update 48\n",
      "train: iter 501  trainloss -1298.03198  validloss -1531.37105±0.00000  bestvalidloss -1581.73737  last_update 49\n",
      "train: iter 502  trainloss -1537.89485  validloss -1389.45880±0.00000  bestvalidloss -1581.73737  last_update 50\n",
      "train: iter 503  trainloss -1568.39432  validloss -1521.41646±0.00000  bestvalidloss -1581.73737  last_update 51\n",
      "train: iter 504  trainloss -1555.30283  validloss -1531.48305±0.00000  bestvalidloss -1581.73737  last_update 52\n",
      "train: iter 505  trainloss -1635.85439  validloss -1568.15547±0.00000  bestvalidloss -1581.73737  last_update 53\n",
      "train: iter 506  trainloss -1508.99651  validloss -1534.42077±0.00000  bestvalidloss -1581.73737  last_update 54\n",
      "train: iter 507  trainloss -1516.78521  validloss -1335.33361±0.00000  bestvalidloss -1581.73737  last_update 55\n",
      "train: iter 508  trainloss -1630.26158  validloss -1562.93665±0.00000  bestvalidloss -1581.73737  last_update 56\n",
      "train: iter 509  trainloss -1627.24392  validloss -1550.81270±0.00000  bestvalidloss -1581.73737  last_update 57\n",
      "train: iter 510  trainloss -1506.62178  validloss -1544.83896±0.00000  bestvalidloss -1581.73737  last_update 58\n",
      "train: iter 511  trainloss -1529.19305  validloss -1438.39660±0.00000  bestvalidloss -1581.73737  last_update 59\n",
      "train: iter 512  trainloss -1608.35459  validloss -1563.74466±0.00000  bestvalidloss -1581.73737  last_update 60\n",
      "train: iter 513  trainloss -1510.08918  validloss -1480.94943±0.00000  bestvalidloss -1581.73737  last_update 61\n",
      "train: iter 514  trainloss -1573.76869  validloss -1357.61670±0.00000  bestvalidloss -1581.73737  last_update 62\n",
      "train: iter 515  trainloss -1565.37956  validloss -1566.84592±0.00000  bestvalidloss -1581.73737  last_update 63\n",
      "train: iter 516  trainloss -1609.46977  validloss -1546.70092±0.00000  bestvalidloss -1581.73737  last_update 64\n",
      "train: iter 517  trainloss -1385.97110  validloss -1465.77788±0.00000  bestvalidloss -1581.73737  last_update 65\n",
      "train: iter 518  trainloss -1411.20505  validloss -1516.14958±0.00000  bestvalidloss -1581.73737  last_update 66\n",
      "train: iter 519  trainloss -1522.68409  validloss -1424.04955±0.00000  bestvalidloss -1581.73737  last_update 67\n",
      "train: iter 520  trainloss -1593.82895  validloss -1490.56182±0.00000  bestvalidloss -1581.73737  last_update 68\n",
      "train: iter 521  trainloss -1603.39745  validloss -1307.32456±0.00000  bestvalidloss -1581.73737  last_update 69\n",
      "train: iter 522  trainloss -1609.32806  validloss -1558.77585±0.00000  bestvalidloss -1581.73737  last_update 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 523  trainloss -1570.50996  validloss -1441.19163±0.00000  bestvalidloss -1581.73737  last_update 71\n",
      "train: iter 524  trainloss -1532.94949  validloss -1536.15614±0.00000  bestvalidloss -1581.73737  last_update 72\n",
      "train: iter 525  trainloss -1501.29975  validloss -1518.30818±0.00000  bestvalidloss -1581.73737  last_update 73\n",
      "train: iter 526  trainloss -1555.46399  validloss -1333.95991±0.00000  bestvalidloss -1581.73737  last_update 74\n",
      "train: iter 527  trainloss -1639.70131  validloss -1538.74412±0.00000  bestvalidloss -1581.73737  last_update 75\n",
      "train: iter 528  trainloss -1595.35965  validloss -1570.06972±0.00000  bestvalidloss -1581.73737  last_update 76\n",
      "train: iter 529  trainloss -1437.96778  validloss -1567.77242±0.00000  bestvalidloss -1581.73737  last_update 77\n",
      "train: iter 530  trainloss -1616.42636  validloss -1392.93255±0.00000  bestvalidloss -1581.73737  last_update 78\n",
      "train: iter 531  trainloss -1468.79100  validloss -1566.67436±0.00000  bestvalidloss -1581.73737  last_update 79\n",
      "train: iter 532  trainloss -1299.11077  validloss -1436.58426±0.00000  bestvalidloss -1581.73737  last_update 80\n",
      "train: iter 533  trainloss -1516.24275  validloss -1409.18564±0.00000  bestvalidloss -1581.73737  last_update 81\n",
      "train: iter 534  trainloss -1588.53248  validloss -1521.81316±0.00000  bestvalidloss -1581.73737  last_update 82\n",
      "train: iter 535  trainloss -1596.47639  validloss -1549.23862±0.00000  bestvalidloss -1581.73737  last_update 83\n",
      "train: iter 536  trainloss -1541.40265  validloss -1560.74358±0.00000  bestvalidloss -1581.73737  last_update 84\n",
      "train: iter 537  trainloss -1609.80980  validloss -1588.33731±0.00000  bestvalidloss -1588.33731  last_update 0\n",
      "train: iter 538  trainloss -1580.20049  validloss -1531.57144±0.00000  bestvalidloss -1588.33731  last_update 1\n",
      "train: iter 539  trainloss -1612.54649  validloss -1560.97508±0.00000  bestvalidloss -1588.33731  last_update 2\n",
      "train: iter 540  trainloss -1600.17476  validloss -1544.97359±0.00000  bestvalidloss -1588.33731  last_update 3\n",
      "train: iter 541  trainloss -1533.37935  validloss -1496.96026±0.00000  bestvalidloss -1588.33731  last_update 4\n",
      "train: iter 542  trainloss -1621.80059  validloss -1559.63259±0.00000  bestvalidloss -1588.33731  last_update 5\n",
      "train: iter 543  trainloss -1631.38024  validloss -1577.04961±0.00000  bestvalidloss -1588.33731  last_update 6\n",
      "train: iter 544  trainloss -1553.19600  validloss -1468.26773±0.00000  bestvalidloss -1588.33731  last_update 7\n",
      "train: iter 545  trainloss -1629.31699  validloss -1536.71160±0.00000  bestvalidloss -1588.33731  last_update 8\n",
      "train: iter 546  trainloss -1609.42402  validloss -1580.67568±0.00000  bestvalidloss -1588.33731  last_update 9\n",
      "train: iter 547  trainloss -1452.96626  validloss -1500.14987±0.00000  bestvalidloss -1588.33731  last_update 10\n",
      "train: iter 548  trainloss -1532.68653  validloss -1374.65118±0.00000  bestvalidloss -1588.33731  last_update 11\n",
      "train: iter 549  trainloss -1606.03828  validloss -1535.11856±0.00000  bestvalidloss -1588.33731  last_update 12\n",
      "train: iter 550  trainloss -1504.97528  validloss -1560.71461±0.00000  bestvalidloss -1588.33731  last_update 13\n",
      "train: iter 551  trainloss -1445.98145  validloss -963.45073±0.00000  bestvalidloss -1588.33731  last_update 14\n",
      "train: iter 552  trainloss -1591.95860  validloss -1525.96007±0.00000  bestvalidloss -1588.33731  last_update 15\n",
      "train: iter 553  trainloss -1629.81099  validloss -1568.27909±0.00000  bestvalidloss -1588.33731  last_update 16\n",
      "train: iter 554  trainloss -1633.48922  validloss -1599.02084±0.00000  bestvalidloss -1599.02084  last_update 0\n",
      "train: iter 555  trainloss -1630.81920  validloss -1552.96431±0.00000  bestvalidloss -1599.02084  last_update 1\n",
      "train: iter 556  trainloss -1594.90725  validloss -1595.51358±0.00000  bestvalidloss -1599.02084  last_update 2\n",
      "train: iter 557  trainloss -1664.06663  validloss -1534.00526±0.00000  bestvalidloss -1599.02084  last_update 3\n",
      "train: iter 558  trainloss -1602.20065  validloss -1577.47206±0.00000  bestvalidloss -1599.02084  last_update 4\n",
      "train: iter 559  trainloss -1605.41979  validloss -1491.68572±0.00000  bestvalidloss -1599.02084  last_update 5\n",
      "train: iter 560  trainloss -1606.25985  validloss -1596.28307±0.00000  bestvalidloss -1599.02084  last_update 6\n",
      "train: iter 561  trainloss -1633.85213  validloss -1490.95046±0.00000  bestvalidloss -1599.02084  last_update 7\n",
      "train: iter 562  trainloss -1618.65650  validloss -1596.49422±0.00000  bestvalidloss -1599.02084  last_update 8\n",
      "train: iter 563  trainloss -1506.40974  validloss -1485.90674±0.00000  bestvalidloss -1599.02084  last_update 9\n",
      "train: iter 564  trainloss -1492.45966  validloss -1535.34740±0.00000  bestvalidloss -1599.02084  last_update 10\n",
      "train: iter 565  trainloss -1508.86374  validloss -1124.70815±0.00000  bestvalidloss -1599.02084  last_update 11\n",
      "train: iter 566  trainloss -1648.99402  validloss -1580.30193±0.00000  bestvalidloss -1599.02084  last_update 12\n",
      "train: iter 567  trainloss -1532.77932  validloss -1550.48582±0.00000  bestvalidloss -1599.02084  last_update 13\n",
      "train: iter 568  trainloss -1601.63897  validloss -1505.14967±0.00000  bestvalidloss -1599.02084  last_update 14\n",
      "train: iter 569  trainloss -1626.27466  validloss -1554.31055±0.00000  bestvalidloss -1599.02084  last_update 15\n",
      "train: iter 570  trainloss -1326.36679  validloss -1588.69924±0.00000  bestvalidloss -1599.02084  last_update 16\n",
      "train: iter 571  trainloss -1491.15113  validloss -1331.09065±0.00000  bestvalidloss -1599.02084  last_update 17\n",
      "train: iter 572  trainloss -1592.59111  validloss -1526.59754±0.00000  bestvalidloss -1599.02084  last_update 18\n",
      "train: iter 573  trainloss -1619.12934  validloss -1539.87283±0.00000  bestvalidloss -1599.02084  last_update 19\n",
      "train: iter 574  trainloss -1607.52050  validloss -1587.74261±0.00000  bestvalidloss -1599.02084  last_update 20\n",
      "train: iter 575  trainloss -1600.50844  validloss -1310.00616±0.00000  bestvalidloss -1599.02084  last_update 21\n",
      "train: iter 576  trainloss -1634.95747  validloss -1537.14358±0.00000  bestvalidloss -1599.02084  last_update 22\n",
      "train: iter 577  trainloss -1571.17245  validloss -1608.05811±0.00000  bestvalidloss -1608.05811  last_update 0\n",
      "train: iter 578  trainloss -1575.16694  validloss -1425.29854±0.00000  bestvalidloss -1608.05811  last_update 1\n",
      "train: iter 579  trainloss -1588.84719  validloss -1486.33081±0.00000  bestvalidloss -1608.05811  last_update 2\n",
      "train: iter 580  trainloss -1625.82134  validloss -1589.91572±0.00000  bestvalidloss -1608.05811  last_update 3\n",
      "train: iter 581  trainloss -1428.19270  validloss -1604.99919±0.00000  bestvalidloss -1608.05811  last_update 4\n",
      "train: iter 582  trainloss -1535.26152  validloss -1425.34096±0.00000  bestvalidloss -1608.05811  last_update 5\n",
      "train: iter 583  trainloss -1611.90946  validloss -1441.91311±0.00000  bestvalidloss -1608.05811  last_update 6\n",
      "train: iter 584  trainloss -1587.48921  validloss -1585.52545±0.00000  bestvalidloss -1608.05811  last_update 7\n",
      "train: iter 585  trainloss -1669.88254  validloss -1597.76823±0.00000  bestvalidloss -1608.05811  last_update 8\n",
      "train: iter 586  trainloss -1524.39457  validloss -1581.47878±0.00000  bestvalidloss -1608.05811  last_update 9\n",
      "train: iter 587  trainloss -1628.00369  validloss -1501.92143±0.00000  bestvalidloss -1608.05811  last_update 10\n",
      "train: iter 588  trainloss -1347.08745  validloss -1493.98451±0.00000  bestvalidloss -1608.05811  last_update 11\n",
      "train: iter 589  trainloss -1435.33085  validloss -967.16444±0.00000  bestvalidloss -1608.05811  last_update 12\n",
      "train: iter 590  trainloss -1581.83218  validloss -1471.00662±0.00000  bestvalidloss -1608.05811  last_update 13\n",
      "train: iter 591  trainloss -1620.37671  validloss -1544.79910±0.00000  bestvalidloss -1608.05811  last_update 14\n",
      "train: iter 592  trainloss -1581.82740  validloss -1482.68223±0.00000  bestvalidloss -1608.05811  last_update 15\n",
      "train: iter 593  trainloss -1628.14299  validloss -1544.18188±0.00000  bestvalidloss -1608.05811  last_update 16\n",
      "train: iter 594  trainloss -1492.56599  validloss -1002.90189±0.00000  bestvalidloss -1608.05811  last_update 17\n",
      "train: iter 595  trainloss -1592.91139  validloss -1485.41125±0.00000  bestvalidloss -1608.05811  last_update 18\n",
      "train: iter 596  trainloss -1473.78823  validloss -1474.16417±0.00000  bestvalidloss -1608.05811  last_update 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 597  trainloss -1484.96624  validloss -1287.54766±0.00000  bestvalidloss -1608.05811  last_update 20\n",
      "train: iter 598  trainloss -1654.89174  validloss -1561.15212±0.00000  bestvalidloss -1608.05811  last_update 21\n",
      "train: iter 599  trainloss -1611.10097  validloss -1563.46480±0.00000  bestvalidloss -1608.05811  last_update 22\n",
      "train: iter 600  trainloss -1555.75324  validloss -1580.52094±0.00000  bestvalidloss -1608.05811  last_update 23\n",
      "train: iter 601  trainloss -1368.40466  validloss -1584.63467±0.00000  bestvalidloss -1608.05811  last_update 24\n",
      "train: iter 602  trainloss -1599.37994  validloss -1510.70138±0.00000  bestvalidloss -1608.05811  last_update 25\n",
      "train: iter 603  trainloss -1664.51679  validloss -1597.46528±0.00000  bestvalidloss -1608.05811  last_update 26\n",
      "train: iter 604  trainloss -1559.15238  validloss -1602.72633±0.00000  bestvalidloss -1608.05811  last_update 27\n",
      "train: iter 605  trainloss -1628.66292  validloss -1535.23027±0.00000  bestvalidloss -1608.05811  last_update 28\n",
      "train: iter 606  trainloss -1572.33500  validloss -1401.64954±0.00000  bestvalidloss -1608.05811  last_update 29\n",
      "train: iter 607  trainloss -1642.81094  validloss -1588.23189±0.00000  bestvalidloss -1608.05811  last_update 30\n",
      "train: iter 608  trainloss -1509.11082  validloss -1553.43909±0.00000  bestvalidloss -1608.05811  last_update 31\n",
      "train: iter 609  trainloss -1642.67807  validloss -1548.75330±0.00000  bestvalidloss -1608.05811  last_update 32\n",
      "train: iter 610  trainloss -1624.56018  validloss -1593.10424±0.00000  bestvalidloss -1608.05811  last_update 33\n",
      "train: iter 611  trainloss -1618.34467  validloss -1490.99790±0.00000  bestvalidloss -1608.05811  last_update 34\n",
      "train: iter 612  trainloss -1639.56091  validloss -1575.20912±0.00000  bestvalidloss -1608.05811  last_update 35\n",
      "train: iter 613  trainloss -1572.47330  validloss -1579.21610±0.00000  bestvalidloss -1608.05811  last_update 36\n",
      "train: iter 614  trainloss -1667.44718  validloss -1585.90112±0.00000  bestvalidloss -1608.05811  last_update 37\n",
      "train: iter 615  trainloss -1610.25843  validloss -1580.20227±0.00000  bestvalidloss -1608.05811  last_update 38\n",
      "train: iter 616  trainloss -1570.41548  validloss -1308.94191±0.00000  bestvalidloss -1608.05811  last_update 39\n",
      "train: iter 617  trainloss -1541.94784  validloss -1560.35975±0.00000  bestvalidloss -1608.05811  last_update 40\n",
      "train: iter 618  trainloss -1535.32534  validloss -1481.18360±0.00000  bestvalidloss -1608.05811  last_update 41\n",
      "train: iter 619  trainloss -1648.65732  validloss -1594.51666±0.00000  bestvalidloss -1608.05811  last_update 42\n",
      "train: iter 620  trainloss -1643.50055  validloss -1624.07838±0.00000  bestvalidloss -1624.07838  last_update 0\n",
      "train: iter 621  trainloss -1370.22602  validloss -1599.83016±0.00000  bestvalidloss -1624.07838  last_update 1\n",
      "train: iter 622  trainloss -1608.26850  validloss -1501.68468±0.00000  bestvalidloss -1624.07838  last_update 2\n",
      "train: iter 623  trainloss -1661.48110  validloss -1508.33182±0.00000  bestvalidloss -1624.07838  last_update 3\n",
      "train: iter 624  trainloss -1672.76602  validloss -1583.38952±0.00000  bestvalidloss -1624.07838  last_update 4\n",
      "train: iter 625  trainloss -1614.14836  validloss -1588.53963±0.00000  bestvalidloss -1624.07838  last_update 5\n",
      "train: iter 626  trainloss -1605.67355  validloss -1517.15703±0.00000  bestvalidloss -1624.07838  last_update 6\n",
      "train: iter 627  trainloss -1575.39712  validloss -1456.96127±0.00000  bestvalidloss -1624.07838  last_update 7\n",
      "train: iter 628  trainloss -1672.28047  validloss -1581.85366±0.00000  bestvalidloss -1624.07838  last_update 8\n",
      "train: iter 629  trainloss -1628.40656  validloss -1619.08804±0.00000  bestvalidloss -1624.07838  last_update 9\n",
      "train: iter 630  trainloss -1632.72029  validloss -1536.86302±0.00000  bestvalidloss -1624.07838  last_update 10\n",
      "train: iter 631  trainloss -1582.06445  validloss -1546.99767±0.00000  bestvalidloss -1624.07838  last_update 11\n",
      "train: iter 632  trainloss -1633.46102  validloss -1548.38830±0.00000  bestvalidloss -1624.07838  last_update 12\n",
      "train: iter 633  trainloss -1547.94468  validloss -1373.97500±0.00000  bestvalidloss -1624.07838  last_update 13\n",
      "train: iter 634  trainloss -1624.92010  validloss -1585.50005±0.00000  bestvalidloss -1624.07838  last_update 14\n",
      "train: iter 635  trainloss -1405.20860  validloss -1598.30152±0.00000  bestvalidloss -1624.07838  last_update 15\n",
      "train: iter 636  trainloss -1621.57912  validloss -1523.54722±0.00000  bestvalidloss -1624.07838  last_update 16\n",
      "train: iter 637  trainloss -1643.52826  validloss -1596.70021±0.00000  bestvalidloss -1624.07838  last_update 17\n",
      "train: iter 638  trainloss -1587.25319  validloss -1268.52651±0.00000  bestvalidloss -1624.07838  last_update 18\n",
      "train: iter 639  trainloss -1623.57769  validloss -1615.04377±0.00000  bestvalidloss -1624.07838  last_update 19\n",
      "train: iter 640  trainloss -1632.02676  validloss -1549.26102±0.00000  bestvalidloss -1624.07838  last_update 20\n",
      "train: iter 641  trainloss -1563.68899  validloss -1364.31882±0.00000  bestvalidloss -1624.07838  last_update 21\n",
      "train: iter 642  trainloss -1676.61047  validloss -1536.41546±0.00000  bestvalidloss -1624.07838  last_update 22\n",
      "train: iter 643  trainloss -1650.94754  validloss -1531.16293±0.00000  bestvalidloss -1624.07838  last_update 23\n",
      "train: iter 644  trainloss -1602.88988  validloss -1490.80176±0.00000  bestvalidloss -1624.07838  last_update 24\n",
      "train: iter 645  trainloss -1680.73280  validloss -1592.82423±0.00000  bestvalidloss -1624.07838  last_update 25\n",
      "train: iter 646  trainloss -1479.04112  validloss -1604.22334±0.00000  bestvalidloss -1624.07838  last_update 26\n",
      "train: iter 647  trainloss -1680.40694  validloss -1493.55504±0.00000  bestvalidloss -1624.07838  last_update 27\n",
      "train: iter 648  trainloss -1655.02471  validloss -1610.33554±0.00000  bestvalidloss -1624.07838  last_update 28\n",
      "train: iter 649  trainloss -1605.33110  validloss -1381.60255±0.00000  bestvalidloss -1624.07838  last_update 29\n",
      "train: iter 650  trainloss -1560.06303  validloss -1573.10222±0.00000  bestvalidloss -1624.07838  last_update 30\n",
      "train: iter 651  trainloss -1633.01925  validloss -1443.00714±0.00000  bestvalidloss -1624.07838  last_update 31\n",
      "train: iter 652  trainloss -1621.06468  validloss -1598.25372±0.00000  bestvalidloss -1624.07838  last_update 32\n",
      "train: iter 653  trainloss -971.17945  validloss -1256.96282±0.00000  bestvalidloss -1624.07838  last_update 33\n",
      "train: iter 654  trainloss -1440.42026  validloss -1314.31045±0.00000  bestvalidloss -1624.07838  last_update 34\n",
      "train: iter 655  trainloss -1370.15144  validloss -1486.78407±0.00000  bestvalidloss -1624.07838  last_update 35\n",
      "train: iter 656  trainloss -1539.34898  validloss -1400.31836±0.00000  bestvalidloss -1624.07838  last_update 36\n",
      "train: iter 657  trainloss -1586.07554  validloss -1508.80256±0.00000  bestvalidloss -1624.07838  last_update 37\n",
      "train: iter 658  trainloss -1585.65685  validloss -1543.61618±0.00000  bestvalidloss -1624.07838  last_update 38\n",
      "train: iter 659  trainloss -1590.38063  validloss -1467.65394±0.00000  bestvalidloss -1624.07838  last_update 39\n",
      "train: iter 660  trainloss -1614.09974  validloss -1507.85869±0.00000  bestvalidloss -1624.07838  last_update 40\n",
      "train: iter 661  trainloss -1631.97328  validloss -1489.20079±0.00000  bestvalidloss -1624.07838  last_update 41\n",
      "train: iter 662  trainloss -1643.25396  validloss -1543.50899±0.00000  bestvalidloss -1624.07838  last_update 42\n",
      "train: iter 663  trainloss -1654.80677  validloss -1600.82858±0.00000  bestvalidloss -1624.07838  last_update 43\n",
      "train: iter 664  trainloss -1679.15245  validloss -1559.45112±0.00000  bestvalidloss -1624.07838  last_update 44\n",
      "train: iter 665  trainloss -1525.31014  validloss -1582.99774±0.00000  bestvalidloss -1624.07838  last_update 45\n",
      "train: iter 666  trainloss -1338.86302  validloss -1380.89505±0.00000  bestvalidloss -1624.07838  last_update 46\n",
      "train: iter 667  trainloss -1521.60114  validloss -1382.76868±0.00000  bestvalidloss -1624.07838  last_update 47\n",
      "train: iter 668  trainloss -1598.58581  validloss -1431.70253±0.00000  bestvalidloss -1624.07838  last_update 48\n",
      "train: iter 669  trainloss -1585.56333  validloss -1547.44373±0.00000  bestvalidloss -1624.07838  last_update 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 670  trainloss -1417.13464  validloss -1161.87293±0.00000  bestvalidloss -1624.07838  last_update 50\n",
      "train: iter 671  trainloss -1658.47343  validloss -1549.76625±0.00000  bestvalidloss -1624.07838  last_update 51\n",
      "train: iter 672  trainloss -1665.71521  validloss -1580.08807±0.00000  bestvalidloss -1624.07838  last_update 52\n",
      "train: iter 673  trainloss -1625.07437  validloss -1551.32353±0.00000  bestvalidloss -1624.07838  last_update 53\n",
      "train: iter 674  trainloss -1625.39252  validloss -1527.64852±0.00000  bestvalidloss -1624.07838  last_update 54\n",
      "train: iter 675  trainloss -1595.41447  validloss -1533.95605±0.00000  bestvalidloss -1624.07838  last_update 55\n",
      "train: iter 676  trainloss -1633.30388  validloss -1436.74462±0.00000  bestvalidloss -1624.07838  last_update 56\n",
      "train: iter 677  trainloss -1653.00393  validloss -1611.63818±0.00000  bestvalidloss -1624.07838  last_update 57\n",
      "train: iter 678  trainloss -1641.06470  validloss -1600.24303±0.00000  bestvalidloss -1624.07838  last_update 58\n",
      "train: iter 679  trainloss -1471.75793  validloss -1397.44872±0.00000  bestvalidloss -1624.07838  last_update 59\n",
      "train: iter 680  trainloss -1629.69995  validloss -1554.50919±0.00000  bestvalidloss -1624.07838  last_update 60\n",
      "train: iter 681  trainloss -1690.77711  validloss -1570.90843±0.00000  bestvalidloss -1624.07838  last_update 61\n",
      "train: iter 682  trainloss -1660.81903  validloss -1595.82345±0.00000  bestvalidloss -1624.07838  last_update 62\n",
      "train: iter 683  trainloss -1639.05300  validloss -1599.75339±0.00000  bestvalidloss -1624.07838  last_update 63\n",
      "train: iter 684  trainloss -1637.43815  validloss -1564.39269±0.00000  bestvalidloss -1624.07838  last_update 64\n",
      "train: iter 685  trainloss -1510.27722  validloss -1488.40567±0.00000  bestvalidloss -1624.07838  last_update 65\n",
      "train: iter 686  trainloss -1580.05870  validloss -1470.59252±0.00000  bestvalidloss -1624.07838  last_update 66\n",
      "train: iter 687  trainloss -1655.86425  validloss -1526.80423±0.00000  bestvalidloss -1624.07838  last_update 67\n",
      "train: iter 688  trainloss -1648.19383  validloss -1579.14249±0.00000  bestvalidloss -1624.07838  last_update 68\n",
      "train: iter 689  trainloss -1560.36212  validloss -1187.24149±0.00000  bestvalidloss -1624.07838  last_update 69\n",
      "train: iter 690  trainloss -1633.18538  validloss -1437.49458±0.00000  bestvalidloss -1624.07838  last_update 70\n",
      "train: iter 691  trainloss -1623.90159  validloss -1487.84697±0.00000  bestvalidloss -1624.07838  last_update 71\n",
      "train: iter 692  trainloss -1623.28553  validloss -1528.69512±0.00000  bestvalidloss -1624.07838  last_update 72\n",
      "train: iter 693  trainloss -1682.67447  validloss -1449.72769±0.00000  bestvalidloss -1624.07838  last_update 73\n",
      "train: iter 694  trainloss -1656.51474  validloss -1465.48683±0.00000  bestvalidloss -1624.07838  last_update 74\n",
      "train: iter 695  trainloss -1624.98221  validloss -1502.06514±0.00000  bestvalidloss -1624.07838  last_update 75\n",
      "train: iter 696  trainloss -1713.99999  validloss -1537.40756±0.00000  bestvalidloss -1624.07838  last_update 76\n",
      "train: iter 697  trainloss -1440.67111  validloss -1507.02748±0.00000  bestvalidloss -1624.07838  last_update 77\n",
      "train: iter 698  trainloss -1440.69087  validloss -1306.69434±0.00000  bestvalidloss -1624.07838  last_update 78\n",
      "train: iter 699  trainloss -1634.33349  validloss -1518.63174±0.00000  bestvalidloss -1624.07838  last_update 79\n",
      "train: iter 700  trainloss -1619.62582  validloss -1568.35624±0.00000  bestvalidloss -1624.07838  last_update 80\n",
      "train: iter 701  trainloss -1638.43401  validloss -1529.91295±0.00000  bestvalidloss -1624.07838  last_update 81\n",
      "train: iter 702  trainloss -1648.02801  validloss -1558.94532±0.00000  bestvalidloss -1624.07838  last_update 82\n",
      "train: iter 703  trainloss -1478.86613  validloss -1540.57619±0.00000  bestvalidloss -1624.07838  last_update 83\n",
      "train: iter 704  trainloss -1603.54034  validloss -1530.85951±0.00000  bestvalidloss -1624.07838  last_update 84\n",
      "train: iter 705  trainloss -1576.18330  validloss -1468.11502±0.00000  bestvalidloss -1624.07838  last_update 85\n",
      "train: iter 706  trainloss -1494.93184  validloss -1356.07582±0.00000  bestvalidloss -1624.07838  last_update 86\n",
      "train: iter 707  trainloss -1616.10364  validloss -1489.26549±0.00000  bestvalidloss -1624.07838  last_update 87\n",
      "train: iter 708  trainloss -1683.82216  validloss -1580.02068±0.00000  bestvalidloss -1624.07838  last_update 88\n",
      "train: iter 709  trainloss -1610.76817  validloss -1402.87464±0.00000  bestvalidloss -1624.07838  last_update 89\n",
      "train: iter 710  trainloss -1678.04664  validloss -1515.30506±0.00000  bestvalidloss -1624.07838  last_update 90\n",
      "train: iter 711  trainloss -1671.58845  validloss -1558.93390±0.00000  bestvalidloss -1624.07838  last_update 91\n",
      "train: iter 712  trainloss -1662.54680  validloss -1525.23752±0.00000  bestvalidloss -1624.07838  last_update 92\n",
      "train: iter 713  trainloss -1557.82590  validloss -1531.20090±0.00000  bestvalidloss -1624.07838  last_update 93\n",
      "train: iter 714  trainloss -1617.31811  validloss -1582.43484±0.00000  bestvalidloss -1624.07838  last_update 94\n",
      "train: iter 715  trainloss -1502.59048  validloss -1356.27733±0.00000  bestvalidloss -1624.07838  last_update 95\n",
      "train: iter 716  trainloss -1662.86505  validloss -1503.15520±0.00000  bestvalidloss -1624.07838  last_update 96\n",
      "train: iter 717  trainloss -1715.23586  validloss -1594.54528±0.00000  bestvalidloss -1624.07838  last_update 97\n",
      "train: iter 718  trainloss -1601.23513  validloss -1527.64467±0.00000  bestvalidloss -1624.07838  last_update 98\n",
      "train: iter 719  trainloss -1670.14245  validloss -1561.26806±0.00000  bestvalidloss -1624.07838  last_update 99\n",
      "train: iter 720  trainloss -1440.71491  validloss -1466.98053±0.00000  bestvalidloss -1624.07838  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.6716) penalty_target_max tensor(5.3178)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 9.06906  validloss 9.43641±0.00000  bestvalidloss 9.43641  last_update 0\n",
      "train: iter 1  trainloss 8.27585  validloss 8.61592±0.00000  bestvalidloss 8.61592  last_update 0\n",
      "train: iter 2  trainloss 7.62311  validloss 7.88254±0.00000  bestvalidloss 7.88254  last_update 0\n",
      "train: iter 3  trainloss 7.07153  validloss 7.30516±0.00000  bestvalidloss 7.30516  last_update 0\n",
      "train: iter 4  trainloss 6.61364  validloss 6.78842±0.00000  bestvalidloss 6.78842  last_update 0\n",
      "train: iter 5  trainloss 6.20297  validloss 6.35972±0.00000  bestvalidloss 6.35972  last_update 0\n",
      "train: iter 6  trainloss 5.87493  validloss 5.99271±0.00000  bestvalidloss 5.99271  last_update 0\n",
      "train: iter 7  trainloss 5.56247  validloss 5.67944±0.00000  bestvalidloss 5.67944  last_update 0\n",
      "train: iter 8  trainloss 5.31155  validloss 5.40417±0.00000  bestvalidloss 5.40417  last_update 0\n",
      "train: iter 9  trainloss 5.07535  validloss 5.15574±0.00000  bestvalidloss 5.15574  last_update 0\n",
      "train: iter 10  trainloss 4.85944  validloss 4.94507±0.00000  bestvalidloss 4.94507  last_update 0\n",
      "train: iter 11  trainloss 4.66696  validloss 4.73453±0.00000  bestvalidloss 4.73453  last_update 0\n",
      "train: iter 12  trainloss 4.49619  validloss 4.55188±0.00000  bestvalidloss 4.55188  last_update 0\n",
      "train: iter 13  trainloss 4.33280  validloss 4.39013±0.00000  bestvalidloss 4.39013  last_update 0\n",
      "train: iter 14  trainloss 4.18941  validloss 4.24688±0.00000  bestvalidloss 4.24688  last_update 0\n",
      "train: iter 15  trainloss 4.05258  validloss 4.10396±0.00000  bestvalidloss 4.10396  last_update 0\n",
      "train: iter 16  trainloss 3.92074  validloss 3.97285±0.00000  bestvalidloss 3.97285  last_update 0\n",
      "train: iter 17  trainloss 3.78996  validloss 3.82940±0.00000  bestvalidloss 3.82940  last_update 0\n",
      "train: iter 18  trainloss 3.66414  validloss 3.71008±0.00000  bestvalidloss 3.71008  last_update 0\n",
      "train: iter 19  trainloss 3.55202  validloss 3.59923±0.00000  bestvalidloss 3.59923  last_update 0\n",
      "train: iter 20  trainloss 3.43835  validloss 3.49043±0.00000  bestvalidloss 3.49043  last_update 0\n",
      "train: iter 21  trainloss 3.33446  validloss 3.36841±0.00000  bestvalidloss 3.36841  last_update 0\n",
      "train: iter 22  trainloss 3.23170  validloss 3.26847±0.00000  bestvalidloss 3.26847  last_update 0\n",
      "train: iter 23  trainloss 3.12772  validloss 3.17011±0.00000  bestvalidloss 3.17011  last_update 0\n",
      "train: iter 24  trainloss 3.03846  validloss 3.07269±0.00000  bestvalidloss 3.07269  last_update 0\n",
      "train: iter 25  trainloss 2.94521  validloss 2.97600±0.00000  bestvalidloss 2.97600  last_update 0\n",
      "train: iter 26  trainloss 2.85690  validloss 2.89718±0.00000  bestvalidloss 2.89718  last_update 0\n",
      "train: iter 27  trainloss 2.77870  validloss 2.81389±0.00000  bestvalidloss 2.81389  last_update 0\n",
      "train: iter 28  trainloss 2.70728  validloss 2.73399±0.00000  bestvalidloss 2.73399  last_update 0\n",
      "train: iter 29  trainloss 2.63156  validloss 2.67293±0.00000  bestvalidloss 2.67293  last_update 0\n",
      "train: iter 30  trainloss 2.56351  validloss 2.59870±0.00000  bestvalidloss 2.59870  last_update 0\n",
      "train: iter 31  trainloss 2.50290  validloss 2.53773±0.00000  bestvalidloss 2.53773  last_update 0\n",
      "train: iter 32  trainloss 2.44487  validloss 2.48132±0.00000  bestvalidloss 2.48132  last_update 0\n",
      "train: iter 33  trainloss 2.38213  validloss 2.43392±0.00000  bestvalidloss 2.43392  last_update 0\n",
      "train: iter 34  trainloss 2.33605  validloss 2.35996±0.00000  bestvalidloss 2.35996  last_update 0\n",
      "train: iter 35  trainloss 2.27620  validloss 2.30951±0.00000  bestvalidloss 2.30951  last_update 0\n",
      "train: iter 36  trainloss 2.23089  validloss 2.26235±0.00000  bestvalidloss 2.26235  last_update 0\n",
      "train: iter 37  trainloss 2.17879  validloss 2.21663±0.00000  bestvalidloss 2.21663  last_update 0\n",
      "train: iter 38  trainloss 2.12860  validloss 2.17512±0.00000  bestvalidloss 2.17512  last_update 0\n",
      "train: iter 39  trainloss 2.09095  validloss 2.12498±0.00000  bestvalidloss 2.12498  last_update 0\n",
      "train: iter 40  trainloss 2.04093  validloss 2.07990±0.00000  bestvalidloss 2.07990  last_update 0\n",
      "train: iter 41  trainloss 2.00527  validloss 2.04478±0.00000  bestvalidloss 2.04478  last_update 0\n",
      "train: iter 42  trainloss 1.94910  validloss 2.00037±0.00000  bestvalidloss 2.00037  last_update 0\n",
      "train: iter 43  trainloss 1.91283  validloss 1.97173±0.00000  bestvalidloss 1.97173  last_update 0\n",
      "train: iter 44  trainloss 1.87871  validloss 1.91019±0.00000  bestvalidloss 1.91019  last_update 0\n",
      "train: iter 45  trainloss 1.83591  validloss 1.87363±0.00000  bestvalidloss 1.87363  last_update 0\n",
      "train: iter 46  trainloss 1.79120  validloss 1.84997±0.00000  bestvalidloss 1.84997  last_update 0\n",
      "train: iter 47  trainloss 1.74925  validloss 1.78351±0.00000  bestvalidloss 1.78351  last_update 0\n",
      "train: iter 48  trainloss 1.71581  validloss 1.73530±0.00000  bestvalidloss 1.73530  last_update 0\n",
      "train: iter 49  trainloss 1.66854  validloss 1.72287±0.00000  bestvalidloss 1.72287  last_update 0\n",
      "train: iter 50  trainloss 1.63652  validloss 1.70663±0.00000  bestvalidloss 1.70663  last_update 0\n",
      "train: iter 51  trainloss 1.60694  validloss 1.63825±0.00000  bestvalidloss 1.63825  last_update 0\n",
      "train: iter 52  trainloss 1.55078  validloss 1.60513±0.00000  bestvalidloss 1.60513  last_update 0\n",
      "train: iter 53  trainloss 1.51627  validloss 1.55079±0.00000  bestvalidloss 1.55079  last_update 0\n",
      "train: iter 54  trainloss 1.46896  validloss 1.55915±0.00000  bestvalidloss 1.55079  last_update 1\n",
      "train: iter 55  trainloss 1.42708  validloss 1.47269±0.00000  bestvalidloss 1.47269  last_update 0\n",
      "train: iter 56  trainloss 1.37922  validloss 1.45075±0.00000  bestvalidloss 1.45075  last_update 0\n",
      "train: iter 57  trainloss 1.33072  validloss 1.38452±0.00000  bestvalidloss 1.38452  last_update 0\n",
      "train: iter 58  trainloss 1.27850  validloss 1.36348±0.00000  bestvalidloss 1.36348  last_update 0\n",
      "train: iter 59  trainloss 1.23209  validloss 1.30796±0.00000  bestvalidloss 1.30796  last_update 0\n",
      "train: iter 60  trainloss 1.17876  validloss 1.26753±0.00000  bestvalidloss 1.26753  last_update 0\n",
      "train: iter 61  trainloss 1.14825  validloss 1.20536±0.00000  bestvalidloss 1.20536  last_update 0\n",
      "train: iter 62  trainloss 1.06996  validloss 1.17469±0.00000  bestvalidloss 1.17469  last_update 0\n",
      "train: iter 63  trainloss 1.04344  validloss 1.08705±0.00000  bestvalidloss 1.08705  last_update 0\n",
      "train: iter 64  trainloss 0.98356  validloss 1.06831±0.00000  bestvalidloss 1.06831  last_update 0\n",
      "train: iter 65  trainloss 0.94000  validloss 0.97690±0.00000  bestvalidloss 0.97690  last_update 0\n",
      "train: iter 66  trainloss 0.88608  validloss 0.94550±0.00000  bestvalidloss 0.94550  last_update 0\n",
      "train: iter 67  trainloss 0.84961  validloss 0.96118±0.00000  bestvalidloss 0.94550  last_update 1\n",
      "train: iter 68  trainloss 0.80551  validloss 0.89081±0.00000  bestvalidloss 0.89081  last_update 0\n",
      "train: iter 69  trainloss 0.76979  validloss 0.83080±0.00000  bestvalidloss 0.83080  last_update 0\n",
      "train: iter 70  trainloss 0.71083  validloss 0.77445±0.00000  bestvalidloss 0.77445  last_update 0\n",
      "train: iter 71  trainloss 0.68102  validloss 0.73731±0.00000  bestvalidloss 0.73731  last_update 0\n",
      "train: iter 72  trainloss 0.62805  validloss 0.75972±0.00000  bestvalidloss 0.73731  last_update 1\n",
      "train: iter 73  trainloss 0.58240  validloss 0.67030±0.00000  bestvalidloss 0.67030  last_update 0\n",
      "train: iter 74  trainloss 0.53940  validloss 0.62470±0.00000  bestvalidloss 0.62470  last_update 0\n",
      "train: iter 75  trainloss 0.49261  validloss 0.60619±0.00000  bestvalidloss 0.60619  last_update 0\n",
      "train: iter 76  trainloss 0.47606  validloss 0.52797±0.00000  bestvalidloss 0.52797  last_update 0\n",
      "train: iter 77  trainloss 0.43573  validloss 0.54462±0.00000  bestvalidloss 0.52797  last_update 1\n",
      "train: iter 78  trainloss 0.39644  validloss 0.43990±0.00000  bestvalidloss 0.43990  last_update 0\n",
      "train: iter 79  trainloss 0.35317  validloss 0.45781±0.00000  bestvalidloss 0.43990  last_update 1\n",
      "train: iter 80  trainloss 0.32348  validloss 0.44265±0.00000  bestvalidloss 0.43990  last_update 2\n",
      "train: iter 81  trainloss 0.26683  validloss 0.35967±0.00000  bestvalidloss 0.35967  last_update 0\n",
      "train: iter 82  trainloss 0.22552  validloss 0.38274±0.00000  bestvalidloss 0.35967  last_update 1\n",
      "train: iter 83  trainloss 0.20561  validloss 0.25853±0.00000  bestvalidloss 0.25853  last_update 0\n",
      "train: iter 84  trainloss 0.14001  validloss 0.18641±0.00000  bestvalidloss 0.18641  last_update 0\n",
      "train: iter 85  trainloss 0.10825  validloss 0.15332±0.00000  bestvalidloss 0.15332  last_update 0\n",
      "train: iter 86  trainloss 0.08037  validloss 0.14507±0.00000  bestvalidloss 0.14507  last_update 0\n",
      "train: iter 87  trainloss 0.02793  validloss 0.14458±0.00000  bestvalidloss 0.14458  last_update 0\n",
      "train: iter 88  trainloss -0.00145  validloss 0.09941±0.00000  bestvalidloss 0.09941  last_update 0\n",
      "train: iter 89  trainloss -0.04359  validloss 0.04118±0.00000  bestvalidloss 0.04118  last_update 0\n",
      "train: iter 90  trainloss -0.08038  validloss 0.00070±0.00000  bestvalidloss 0.00070  last_update 0\n",
      "train: iter 91  trainloss -0.11349  validloss -0.02401±0.00000  bestvalidloss -0.02401  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 92  trainloss -0.13128  validloss -0.08569±0.00000  bestvalidloss -0.08569  last_update 0\n",
      "train: iter 93  trainloss -0.18728  validloss -0.17766±0.00000  bestvalidloss -0.17766  last_update 0\n",
      "train: iter 94  trainloss -0.21707  validloss -0.15599±0.00000  bestvalidloss -0.17766  last_update 1\n",
      "train: iter 95  trainloss -0.25401  validloss -0.20957±0.00000  bestvalidloss -0.20957  last_update 0\n",
      "train: iter 96  trainloss -0.26867  validloss -0.22845±0.00000  bestvalidloss -0.22845  last_update 0\n",
      "train: iter 97  trainloss -0.32376  validloss -0.23168±0.00000  bestvalidloss -0.23168  last_update 0\n",
      "train: iter 98  trainloss -0.35347  validloss -0.29175±0.00000  bestvalidloss -0.29175  last_update 0\n",
      "train: iter 99  trainloss -0.39159  validloss -0.33325±0.00000  bestvalidloss -0.33325  last_update 0\n",
      "train: iter 100  trainloss -0.41677  validloss -0.38612±0.00000  bestvalidloss -0.38612  last_update 0\n",
      "train: iter 101  trainloss -0.45883  validloss -0.42036±0.00000  bestvalidloss -0.42036  last_update 0\n",
      "train: iter 102  trainloss -0.46955  validloss -0.45187±0.00000  bestvalidloss -0.45187  last_update 0\n",
      "train: iter 103  trainloss -0.52039  validloss -0.43943±0.00000  bestvalidloss -0.45187  last_update 1\n",
      "train: iter 104  trainloss -0.54140  validloss -0.48965±0.00000  bestvalidloss -0.48965  last_update 0\n",
      "train: iter 105  trainloss -0.59854  validloss -0.52141±0.00000  bestvalidloss -0.52141  last_update 0\n",
      "train: iter 106  trainloss -0.57936  validloss -0.56902±0.00000  bestvalidloss -0.56902  last_update 0\n",
      "train: iter 107  trainloss -0.63517  validloss -0.64298±0.00000  bestvalidloss -0.64298  last_update 0\n",
      "train: iter 108  trainloss -0.64842  validloss -0.64701±0.00000  bestvalidloss -0.64701  last_update 0\n",
      "train: iter 109  trainloss -0.69176  validloss -0.64394±0.00000  bestvalidloss -0.64701  last_update 1\n",
      "train: iter 110  trainloss -0.71813  validloss -0.67329±0.00000  bestvalidloss -0.67329  last_update 0\n",
      "train: iter 111  trainloss -0.75354  validloss -0.63884±0.00000  bestvalidloss -0.67329  last_update 1\n",
      "train: iter 112  trainloss -0.75905  validloss -0.75007±0.00000  bestvalidloss -0.75007  last_update 0\n",
      "train: iter 113  trainloss -0.76705  validloss -0.71871±0.00000  bestvalidloss -0.75007  last_update 1\n",
      "train: iter 114  trainloss -0.80138  validloss -0.73452±0.00000  bestvalidloss -0.75007  last_update 2\n",
      "train: iter 115  trainloss -0.84106  validloss -0.80527±0.00000  bestvalidloss -0.80527  last_update 0\n",
      "train: iter 116  trainloss -0.82936  validloss -0.80524±0.00000  bestvalidloss -0.80527  last_update 1\n",
      "train: iter 117  trainloss -0.85196  validloss -0.84754±0.00000  bestvalidloss -0.84754  last_update 0\n",
      "train: iter 118  trainloss -0.87458  validloss -0.86707±0.00000  bestvalidloss -0.86707  last_update 0\n",
      "train: iter 119  trainloss -0.89943  validloss -0.92562±0.00000  bestvalidloss -0.92562  last_update 0\n",
      "train: iter 120  trainloss -0.91671  validloss -0.92465±0.00000  bestvalidloss -0.92562  last_update 1\n",
      "train: iter 121  trainloss -0.90542  validloss -0.96686±0.00000  bestvalidloss -0.96686  last_update 0\n",
      "train: iter 122  trainloss -0.90819  validloss -0.97020±0.00000  bestvalidloss -0.97020  last_update 0\n",
      "train: iter 123  trainloss -0.93867  validloss -0.95898±0.00000  bestvalidloss -0.97020  last_update 1\n",
      "train: iter 124  trainloss -0.95274  validloss -0.97638±0.00000  bestvalidloss -0.97638  last_update 0\n",
      "train: iter 125  trainloss -0.96697  validloss -1.03976±0.00000  bestvalidloss -1.03976  last_update 0\n",
      "train: iter 126  trainloss -0.98132  validloss -1.02195±0.00000  bestvalidloss -1.03976  last_update 1\n",
      "train: iter 127  trainloss -0.97466  validloss -1.00979±0.00000  bestvalidloss -1.03976  last_update 2\n",
      "train: iter 128  trainloss -1.02475  validloss -1.00437±0.00000  bestvalidloss -1.03976  last_update 3\n",
      "train: iter 129  trainloss -0.96919  validloss -1.00948±0.00000  bestvalidloss -1.03976  last_update 4\n",
      "train: iter 130  trainloss -0.99995  validloss -0.94600±0.00000  bestvalidloss -1.03976  last_update 5\n",
      "train: iter 131  trainloss -1.04381  validloss -1.08358±0.00000  bestvalidloss -1.08358  last_update 0\n",
      "train: iter 132  trainloss -0.99380  validloss -1.04240±0.00000  bestvalidloss -1.08358  last_update 1\n",
      "train: iter 133  trainloss -1.03303  validloss -1.07123±0.00000  bestvalidloss -1.08358  last_update 2\n",
      "train: iter 134  trainloss -1.01957  validloss -1.05272±0.00000  bestvalidloss -1.08358  last_update 3\n",
      "train: iter 135  trainloss -0.98345  validloss -1.07860±0.00000  bestvalidloss -1.08358  last_update 4\n",
      "train: iter 136  trainloss -1.01137  validloss -1.14457±0.00000  bestvalidloss -1.14457  last_update 0\n",
      "train: iter 137  trainloss -1.01338  validloss -1.13468±0.00000  bestvalidloss -1.14457  last_update 1\n",
      "train: iter 138  trainloss -0.98835  validloss -1.09008±0.00000  bestvalidloss -1.14457  last_update 2\n",
      "train: iter 139  trainloss -0.97459  validloss -1.06681±0.00000  bestvalidloss -1.14457  last_update 3\n",
      "train: iter 140  trainloss -0.97504  validloss -1.11501±0.00000  bestvalidloss -1.14457  last_update 4\n",
      "train: iter 141  trainloss -1.01269  validloss -1.09725±0.00000  bestvalidloss -1.14457  last_update 5\n",
      "train: iter 142  trainloss -0.98803  validloss -1.02137±0.00000  bestvalidloss -1.14457  last_update 6\n",
      "train: iter 143  trainloss -0.99773  validloss -1.06754±0.00000  bestvalidloss -1.14457  last_update 7\n",
      "train: iter 144  trainloss -0.99124  validloss -1.00449±0.00000  bestvalidloss -1.14457  last_update 8\n",
      "train: iter 145  trainloss -1.04291  validloss -0.99002±0.00000  bestvalidloss -1.14457  last_update 9\n",
      "train: iter 146  trainloss -1.03725  validloss -1.08776±0.00000  bestvalidloss -1.14457  last_update 10\n",
      "train: iter 147  trainloss -1.02161  validloss -1.01682±0.00000  bestvalidloss -1.14457  last_update 11\n",
      "train: iter 148  trainloss -0.99759  validloss -1.14414±0.00000  bestvalidloss -1.14457  last_update 12\n",
      "train: iter 149  trainloss -1.05312  validloss -1.06184±0.00000  bestvalidloss -1.14457  last_update 13\n",
      "train: iter 150  trainloss -1.02789  validloss -1.04214±0.00000  bestvalidloss -1.14457  last_update 14\n",
      "train: iter 151  trainloss -0.96466  validloss -1.12622±0.00000  bestvalidloss -1.14457  last_update 15\n",
      "train: iter 152  trainloss -0.99980  validloss -1.10875±0.00000  bestvalidloss -1.14457  last_update 16\n",
      "train: iter 153  trainloss -1.01331  validloss -1.13078±0.00000  bestvalidloss -1.14457  last_update 17\n",
      "train: iter 154  trainloss -1.03280  validloss -1.12951±0.00000  bestvalidloss -1.14457  last_update 18\n",
      "train: iter 155  trainloss -1.00771  validloss -1.10275±0.00000  bestvalidloss -1.14457  last_update 19\n",
      "train: iter 156  trainloss -1.03390  validloss -1.07942±0.00000  bestvalidloss -1.14457  last_update 20\n",
      "train: iter 157  trainloss -1.01106  validloss -1.07649±0.00000  bestvalidloss -1.14457  last_update 21\n",
      "train: iter 158  trainloss -1.02440  validloss -1.08527±0.00000  bestvalidloss -1.14457  last_update 22\n",
      "train: iter 159  trainloss -0.98013  validloss -1.07135±0.00000  bestvalidloss -1.14457  last_update 23\n",
      "train: iter 160  trainloss -0.96798  validloss -1.05758±0.00000  bestvalidloss -1.14457  last_update 24\n",
      "train: iter 161  trainloss -1.04660  validloss -1.03558±0.00000  bestvalidloss -1.14457  last_update 25\n",
      "train: iter 162  trainloss -0.98416  validloss -1.09197±0.00000  bestvalidloss -1.14457  last_update 26\n",
      "train: iter 163  trainloss -1.01019  validloss -1.02948±0.00000  bestvalidloss -1.14457  last_update 27\n",
      "train: iter 164  trainloss -1.01498  validloss -1.09601±0.00000  bestvalidloss -1.14457  last_update 28\n",
      "train: iter 165  trainloss -1.04478  validloss -1.01182±0.00000  bestvalidloss -1.14457  last_update 29\n",
      "train: iter 166  trainloss -1.03272  validloss -1.15321±0.00000  bestvalidloss -1.15321  last_update 0\n",
      "train: iter 167  trainloss -1.01816  validloss -1.07862±0.00000  bestvalidloss -1.15321  last_update 1\n",
      "train: iter 168  trainloss -0.98275  validloss -1.03740±0.00000  bestvalidloss -1.15321  last_update 2\n",
      "train: iter 169  trainloss -1.03969  validloss -1.09579±0.00000  bestvalidloss -1.15321  last_update 3\n",
      "train: iter 170  trainloss -1.02002  validloss -1.10513±0.00000  bestvalidloss -1.15321  last_update 4\n",
      "train: iter 171  trainloss -0.98375  validloss -1.13007±0.00000  bestvalidloss -1.15321  last_update 5\n",
      "train: iter 172  trainloss -0.98746  validloss -1.02271±0.00000  bestvalidloss -1.15321  last_update 6\n",
      "train: iter 173  trainloss -1.02627  validloss -1.12823±0.00000  bestvalidloss -1.15321  last_update 7\n",
      "train: iter 174  trainloss -1.06877  validloss -1.03593±0.00000  bestvalidloss -1.15321  last_update 8\n",
      "train: iter 175  trainloss -1.01713  validloss -1.11098±0.00000  bestvalidloss -1.15321  last_update 9\n",
      "train: iter 176  trainloss -1.02866  validloss -1.08491±0.00000  bestvalidloss -1.15321  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 177  trainloss -0.95576  validloss -1.13592±0.00000  bestvalidloss -1.15321  last_update 11\n",
      "train: iter 178  trainloss -1.00040  validloss -1.10935±0.00000  bestvalidloss -1.15321  last_update 12\n",
      "train: iter 179  trainloss -1.05998  validloss -1.08950±0.00000  bestvalidloss -1.15321  last_update 13\n",
      "train: iter 180  trainloss -1.01015  validloss -1.11965±0.00000  bestvalidloss -1.15321  last_update 14\n",
      "train: iter 181  trainloss -1.01067  validloss -1.08814±0.00000  bestvalidloss -1.15321  last_update 15\n",
      "train: iter 182  trainloss -1.00223  validloss -1.04431±0.00000  bestvalidloss -1.15321  last_update 16\n",
      "train: iter 183  trainloss -1.02776  validloss -1.09287±0.00000  bestvalidloss -1.15321  last_update 17\n",
      "train: iter 184  trainloss -1.03520  validloss -1.08053±0.00000  bestvalidloss -1.15321  last_update 18\n",
      "train: iter 185  trainloss -0.99189  validloss -1.02213±0.00000  bestvalidloss -1.15321  last_update 19\n",
      "train: iter 186  trainloss -1.01683  validloss -1.09495±0.00000  bestvalidloss -1.15321  last_update 20\n",
      "train: iter 187  trainloss -1.01786  validloss -1.01981±0.00000  bestvalidloss -1.15321  last_update 21\n",
      "train: iter 188  trainloss -0.99476  validloss -1.06976±0.00000  bestvalidloss -1.15321  last_update 22\n",
      "train: iter 189  trainloss -1.01751  validloss -1.07156±0.00000  bestvalidloss -1.15321  last_update 23\n",
      "train: iter 190  trainloss -1.00503  validloss -1.06634±0.00000  bestvalidloss -1.15321  last_update 24\n",
      "train: iter 191  trainloss -0.98600  validloss -1.14153±0.00000  bestvalidloss -1.15321  last_update 25\n",
      "train: iter 192  trainloss -1.06252  validloss -1.09256±0.00000  bestvalidloss -1.15321  last_update 26\n",
      "train: iter 193  trainloss -1.06039  validloss -1.07801±0.00000  bestvalidloss -1.15321  last_update 27\n",
      "train: iter 194  trainloss -0.99972  validloss -1.19116±0.00000  bestvalidloss -1.19116  last_update 0\n",
      "train: iter 195  trainloss -0.99741  validloss -1.11046±0.00000  bestvalidloss -1.19116  last_update 1\n",
      "train: iter 196  trainloss -0.97200  validloss -1.15723±0.00000  bestvalidloss -1.19116  last_update 2\n",
      "train: iter 197  trainloss -1.02903  validloss -1.21999±0.00000  bestvalidloss -1.21999  last_update 0\n",
      "train: iter 198  trainloss -1.03377  validloss -1.15452±0.00000  bestvalidloss -1.21999  last_update 1\n",
      "train: iter 199  trainloss -0.94168  validloss -1.05369±0.00000  bestvalidloss -1.21999  last_update 2\n",
      "train: iter 200  trainloss -1.06331  validloss -1.07355±0.00000  bestvalidloss -1.21999  last_update 3\n",
      "train: iter 201  trainloss -1.02382  validloss -1.05072±0.00000  bestvalidloss -1.21999  last_update 4\n",
      "train: iter 202  trainloss -1.01074  validloss -1.12617±0.00000  bestvalidloss -1.21999  last_update 5\n",
      "train: iter 203  trainloss -0.97394  validloss -1.09025±0.00000  bestvalidloss -1.21999  last_update 6\n",
      "train: iter 204  trainloss -0.99342  validloss -1.07493±0.00000  bestvalidloss -1.21999  last_update 7\n",
      "train: iter 205  trainloss -0.96783  validloss -1.13120±0.00000  bestvalidloss -1.21999  last_update 8\n",
      "train: iter 206  trainloss -1.00719  validloss -1.12915±0.00000  bestvalidloss -1.21999  last_update 9\n",
      "train: iter 207  trainloss -1.02027  validloss -1.08976±0.00000  bestvalidloss -1.21999  last_update 10\n",
      "train: iter 208  trainloss -1.00527  validloss -1.05671±0.00000  bestvalidloss -1.21999  last_update 11\n",
      "train: iter 209  trainloss -0.99112  validloss -1.07767±0.00000  bestvalidloss -1.21999  last_update 12\n",
      "train: iter 210  trainloss -1.02249  validloss -1.12076±0.00000  bestvalidloss -1.21999  last_update 13\n",
      "train: iter 211  trainloss -1.02286  validloss -1.12346±0.00000  bestvalidloss -1.21999  last_update 14\n",
      "train: iter 212  trainloss -0.96360  validloss -1.12209±0.00000  bestvalidloss -1.21999  last_update 15\n",
      "train: iter 213  trainloss -1.02545  validloss -1.12783±0.00000  bestvalidloss -1.21999  last_update 16\n",
      "train: iter 214  trainloss -1.02741  validloss -0.98758±0.00000  bestvalidloss -1.21999  last_update 17\n",
      "train: iter 215  trainloss -1.00282  validloss -1.10130±0.00000  bestvalidloss -1.21999  last_update 18\n",
      "train: iter 216  trainloss -1.01671  validloss -0.99028±0.00000  bestvalidloss -1.21999  last_update 19\n",
      "train: iter 217  trainloss -1.01455  validloss -0.97995±0.00000  bestvalidloss -1.21999  last_update 20\n",
      "train: iter 218  trainloss -1.02235  validloss -1.15885±0.00000  bestvalidloss -1.21999  last_update 21\n",
      "train: iter 219  trainloss -0.98664  validloss -1.11468±0.00000  bestvalidloss -1.21999  last_update 22\n",
      "train: iter 220  trainloss -1.06954  validloss -1.10635±0.00000  bestvalidloss -1.21999  last_update 23\n",
      "train: iter 221  trainloss -0.98204  validloss -1.07415±0.00000  bestvalidloss -1.21999  last_update 24\n",
      "train: iter 222  trainloss -1.01222  validloss -1.11786±0.00000  bestvalidloss -1.21999  last_update 25\n",
      "train: iter 223  trainloss -1.04832  validloss -1.15220±0.00000  bestvalidloss -1.21999  last_update 26\n",
      "train: iter 224  trainloss -1.02171  validloss -1.04963±0.00000  bestvalidloss -1.21999  last_update 27\n",
      "train: iter 225  trainloss -0.99425  validloss -1.10211±0.00000  bestvalidloss -1.21999  last_update 28\n",
      "train: iter 226  trainloss -1.03753  validloss -1.01329±0.00000  bestvalidloss -1.21999  last_update 29\n",
      "train: iter 227  trainloss -1.01469  validloss -1.09898±0.00000  bestvalidloss -1.21999  last_update 30\n",
      "train: iter 228  trainloss -1.06534  validloss -1.16944±0.00000  bestvalidloss -1.21999  last_update 31\n",
      "train: iter 229  trainloss -1.00006  validloss -1.09746±0.00000  bestvalidloss -1.21999  last_update 32\n",
      "train: iter 230  trainloss -1.05273  validloss -1.15077±0.00000  bestvalidloss -1.21999  last_update 33\n",
      "train: iter 231  trainloss -0.99997  validloss -1.17060±0.00000  bestvalidloss -1.21999  last_update 34\n",
      "train: iter 232  trainloss -1.02987  validloss -1.13978±0.00000  bestvalidloss -1.21999  last_update 35\n",
      "train: iter 233  trainloss -1.00006  validloss -1.10386±0.00000  bestvalidloss -1.21999  last_update 36\n",
      "train: iter 234  trainloss -1.00633  validloss -1.07696±0.00000  bestvalidloss -1.21999  last_update 37\n",
      "train: iter 235  trainloss -1.05448  validloss -1.16104±0.00000  bestvalidloss -1.21999  last_update 38\n",
      "train: iter 236  trainloss -1.00250  validloss -1.18336±0.00000  bestvalidloss -1.21999  last_update 39\n",
      "train: iter 237  trainloss -1.01935  validloss -1.15090±0.00000  bestvalidloss -1.21999  last_update 40\n",
      "train: iter 238  trainloss -1.00242  validloss -1.09075±0.00000  bestvalidloss -1.21999  last_update 41\n",
      "train: iter 239  trainloss -1.03673  validloss -1.14632±0.00000  bestvalidloss -1.21999  last_update 42\n",
      "train: iter 240  trainloss -1.02735  validloss -1.03664±0.00000  bestvalidloss -1.21999  last_update 43\n",
      "train: iter 241  trainloss -0.99025  validloss -1.17774±0.00000  bestvalidloss -1.21999  last_update 44\n",
      "train: iter 242  trainloss -1.00070  validloss -1.13561±0.00000  bestvalidloss -1.21999  last_update 45\n",
      "train: iter 243  trainloss -1.00570  validloss -1.18178±0.00000  bestvalidloss -1.21999  last_update 46\n",
      "train: iter 244  trainloss -1.01102  validloss -1.04039±0.00000  bestvalidloss -1.21999  last_update 47\n",
      "train: iter 245  trainloss -1.01538  validloss -1.11874±0.00000  bestvalidloss -1.21999  last_update 48\n",
      "train: iter 246  trainloss -1.05685  validloss -1.07913±0.00000  bestvalidloss -1.21999  last_update 49\n",
      "train: iter 247  trainloss -1.05301  validloss -0.96647±0.00000  bestvalidloss -1.21999  last_update 50\n",
      "train: iter 248  trainloss -1.01099  validloss -0.99322±0.00000  bestvalidloss -1.21999  last_update 51\n",
      "train: iter 249  trainloss -1.01873  validloss -1.17338±0.00000  bestvalidloss -1.21999  last_update 52\n",
      "train: iter 250  trainloss -1.00335  validloss -1.15564±0.00000  bestvalidloss -1.21999  last_update 53\n",
      "train: iter 251  trainloss -1.00489  validloss -1.01951±0.00000  bestvalidloss -1.21999  last_update 54\n",
      "train: iter 252  trainloss -1.03295  validloss -0.98441±0.00000  bestvalidloss -1.21999  last_update 55\n",
      "train: iter 253  trainloss -1.05282  validloss -1.12871±0.00000  bestvalidloss -1.21999  last_update 56\n",
      "train: iter 254  trainloss -1.02628  validloss -0.99995±0.00000  bestvalidloss -1.21999  last_update 57\n",
      "train: iter 255  trainloss -1.02383  validloss -1.15402±0.00000  bestvalidloss -1.21999  last_update 58\n",
      "train: iter 256  trainloss -1.00970  validloss -1.06918±0.00000  bestvalidloss -1.21999  last_update 59\n",
      "train: iter 257  trainloss -1.06215  validloss -1.05908±0.00000  bestvalidloss -1.21999  last_update 60\n",
      "train: iter 258  trainloss -1.01635  validloss -1.07502±0.00000  bestvalidloss -1.21999  last_update 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 259  trainloss -1.00698  validloss -1.00965±0.00000  bestvalidloss -1.21999  last_update 62\n",
      "train: iter 260  trainloss -1.00321  validloss -1.09617±0.00000  bestvalidloss -1.21999  last_update 63\n",
      "train: iter 261  trainloss -1.02305  validloss -1.10809±0.00000  bestvalidloss -1.21999  last_update 64\n",
      "train: iter 262  trainloss -1.02315  validloss -1.11754±0.00000  bestvalidloss -1.21999  last_update 65\n",
      "train: iter 263  trainloss -1.01064  validloss -1.12985±0.00000  bestvalidloss -1.21999  last_update 66\n",
      "train: iter 264  trainloss -0.98995  validloss -1.13691±0.00000  bestvalidloss -1.21999  last_update 67\n",
      "train: iter 265  trainloss -1.00186  validloss -1.11254±0.00000  bestvalidloss -1.21999  last_update 68\n",
      "train: iter 266  trainloss -1.01714  validloss -1.14164±0.00000  bestvalidloss -1.21999  last_update 69\n",
      "train: iter 267  trainloss -1.03723  validloss -1.11351±0.00000  bestvalidloss -1.21999  last_update 70\n",
      "train: iter 268  trainloss -0.99345  validloss -1.15537±0.00000  bestvalidloss -1.21999  last_update 71\n",
      "train: iter 269  trainloss -1.01105  validloss -1.07770±0.00000  bestvalidloss -1.21999  last_update 72\n",
      "train: iter 270  trainloss -1.02487  validloss -1.11992±0.00000  bestvalidloss -1.21999  last_update 73\n",
      "train: iter 271  trainloss -1.01542  validloss -1.13045±0.00000  bestvalidloss -1.21999  last_update 74\n",
      "train: iter 272  trainloss -1.03432  validloss -1.06637±0.00000  bestvalidloss -1.21999  last_update 75\n",
      "train: iter 273  trainloss -1.02156  validloss -1.18275±0.00000  bestvalidloss -1.21999  last_update 76\n",
      "train: iter 274  trainloss -1.04845  validloss -1.12900±0.00000  bestvalidloss -1.21999  last_update 77\n",
      "train: iter 275  trainloss -1.01132  validloss -1.08459±0.00000  bestvalidloss -1.21999  last_update 78\n",
      "train: iter 276  trainloss -1.01194  validloss -1.09855±0.00000  bestvalidloss -1.21999  last_update 79\n",
      "train: iter 277  trainloss -0.98253  validloss -1.15831±0.00000  bestvalidloss -1.21999  last_update 80\n",
      "train: iter 278  trainloss -1.04819  validloss -1.08316±0.00000  bestvalidloss -1.21999  last_update 81\n",
      "train: iter 279  trainloss -1.02292  validloss -1.08149±0.00000  bestvalidloss -1.21999  last_update 82\n",
      "train: iter 280  trainloss -1.03028  validloss -1.04056±0.00000  bestvalidloss -1.21999  last_update 83\n",
      "train: iter 281  trainloss -1.02244  validloss -1.15588±0.00000  bestvalidloss -1.21999  last_update 84\n",
      "train: iter 282  trainloss -0.99678  validloss -1.11274±0.00000  bestvalidloss -1.21999  last_update 85\n",
      "train: iter 283  trainloss -1.02321  validloss -1.09222±0.00000  bestvalidloss -1.21999  last_update 86\n",
      "train: iter 284  trainloss -0.98698  validloss -1.07751±0.00000  bestvalidloss -1.21999  last_update 87\n",
      "train: iter 285  trainloss -1.03541  validloss -1.10207±0.00000  bestvalidloss -1.21999  last_update 88\n",
      "train: iter 286  trainloss -1.01399  validloss -1.10803±0.00000  bestvalidloss -1.21999  last_update 89\n",
      "train: iter 287  trainloss -1.00094  validloss -1.01660±0.00000  bestvalidloss -1.21999  last_update 90\n",
      "train: iter 288  trainloss -0.96940  validloss -1.01907±0.00000  bestvalidloss -1.21999  last_update 91\n",
      "train: iter 289  trainloss -1.03652  validloss -1.18796±0.00000  bestvalidloss -1.21999  last_update 92\n",
      "train: iter 290  trainloss -1.02306  validloss -1.14446±0.00000  bestvalidloss -1.21999  last_update 93\n",
      "train: iter 291  trainloss -1.00706  validloss -1.09607±0.00000  bestvalidloss -1.21999  last_update 94\n",
      "train: iter 292  trainloss -0.98626  validloss -1.11134±0.00000  bestvalidloss -1.21999  last_update 95\n",
      "train: iter 293  trainloss -1.03403  validloss -1.07085±0.00000  bestvalidloss -1.21999  last_update 96\n",
      "train: iter 294  trainloss -0.99024  validloss -1.12244±0.00000  bestvalidloss -1.21999  last_update 97\n",
      "train: iter 295  trainloss -1.06994  validloss -1.11158±0.00000  bestvalidloss -1.21999  last_update 98\n",
      "train: iter 296  trainloss -1.05277  validloss -1.10389±0.00000  bestvalidloss -1.21999  last_update 99\n",
      "train: iter 297  trainloss -1.00589  validloss -1.11425±0.00000  bestvalidloss -1.21999  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.6967, -3.5203, -2.6963, -5.0048], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 72.59647  validloss 75.94363±0.00000  bestvalidloss 75.94363  last_update 0\n",
      "train: iter 1  trainloss 53.85311  validloss 59.98156±0.00000  bestvalidloss 59.98156  last_update 0\n",
      "train: iter 2  trainloss 38.12986  validloss 41.57259±0.00000  bestvalidloss 41.57259  last_update 0\n",
      "train: iter 3  trainloss 29.13618  validloss 31.04668±0.00000  bestvalidloss 31.04668  last_update 0\n",
      "train: iter 4  trainloss 23.40203  validloss 24.28565±0.00000  bestvalidloss 24.28565  last_update 0\n",
      "train: iter 5  trainloss 19.34425  validloss 20.21054±0.00000  bestvalidloss 20.21054  last_update 0\n",
      "train: iter 6  trainloss 16.38047  validloss 17.17107±0.00000  bestvalidloss 17.17107  last_update 0\n",
      "train: iter 7  trainloss 14.08745  validloss 14.72715±0.00000  bestvalidloss 14.72715  last_update 0\n",
      "train: iter 8  trainloss 12.41216  validloss 13.23228±0.00000  bestvalidloss 13.23228  last_update 0\n",
      "train: iter 9  trainloss 11.13069  validloss 12.03227±0.00000  bestvalidloss 12.03227  last_update 0\n",
      "train: iter 10  trainloss 10.15481  validloss 11.11933±0.00000  bestvalidloss 11.11933  last_update 0\n",
      "train: iter 11  trainloss 9.31669  validloss 10.56670±0.00000  bestvalidloss 10.56670  last_update 0\n",
      "train: iter 12  trainloss 8.68157  validloss 9.95285±0.00000  bestvalidloss 9.95285  last_update 0\n",
      "train: iter 13  trainloss 8.11402  validloss 9.58514±0.00000  bestvalidloss 9.58514  last_update 0\n",
      "train: iter 14  trainloss 7.53375  validloss 9.05498±0.00000  bestvalidloss 9.05498  last_update 0\n",
      "train: iter 15  trainloss 7.04708  validloss 8.61200±0.00000  bestvalidloss 8.61200  last_update 0\n",
      "train: iter 16  trainloss 6.54605  validloss 8.35039±0.00000  bestvalidloss 8.35039  last_update 0\n",
      "train: iter 17  trainloss 6.18701  validloss 8.09052±0.00000  bestvalidloss 8.09052  last_update 0\n",
      "train: iter 18  trainloss 6.00710  validloss 7.84725±0.00000  bestvalidloss 7.84725  last_update 0\n",
      "train: iter 19  trainloss 5.82362  validloss 7.79934±0.00000  bestvalidloss 7.79934  last_update 0\n",
      "train: iter 20  trainloss 5.66526  validloss 7.58374±0.00000  bestvalidloss 7.58374  last_update 0\n",
      "train: iter 21  trainloss 5.59576  validloss 7.54575±0.00000  bestvalidloss 7.54575  last_update 0\n",
      "train: iter 22  trainloss 5.44170  validloss 7.40607±0.00000  bestvalidloss 7.40607  last_update 0\n",
      "train: iter 23  trainloss 5.39157  validloss 7.46652±0.00000  bestvalidloss 7.40607  last_update 1\n",
      "train: iter 24  trainloss 5.33794  validloss 7.24840±0.00000  bestvalidloss 7.24840  last_update 0\n",
      "train: iter 25  trainloss 5.26204  validloss 7.06619±0.00000  bestvalidloss 7.06619  last_update 0\n",
      "train: iter 26  trainloss 5.15838  validloss 7.06542±0.00000  bestvalidloss 7.06542  last_update 0\n",
      "train: iter 27  trainloss 5.15942  validloss 7.01876±0.00000  bestvalidloss 7.01876  last_update 0\n",
      "train: iter 28  trainloss 5.07604  validloss 6.81041±0.00000  bestvalidloss 6.81041  last_update 0\n",
      "train: iter 29  trainloss 5.06568  validloss 6.79586±0.00000  bestvalidloss 6.79586  last_update 0\n",
      "train: iter 30  trainloss 4.99908  validloss 6.86258±0.00000  bestvalidloss 6.79586  last_update 1\n",
      "train: iter 31  trainloss 4.97565  validloss 6.67849±0.00000  bestvalidloss 6.67849  last_update 0\n",
      "train: iter 32  trainloss 4.88920  validloss 6.51171±0.00000  bestvalidloss 6.51171  last_update 0\n",
      "train: iter 33  trainloss 4.85154  validloss 6.61045±0.00000  bestvalidloss 6.51171  last_update 1\n",
      "train: iter 34  trainloss 4.91117  validloss 6.49060±0.00000  bestvalidloss 6.49060  last_update 0\n",
      "train: iter 35  trainloss 4.77868  validloss 6.33815±0.00000  bestvalidloss 6.33815  last_update 0\n",
      "train: iter 36  trainloss 4.84369  validloss 6.57117±0.00000  bestvalidloss 6.33815  last_update 1\n",
      "train: iter 37  trainloss 4.81911  validloss 6.29519±0.00000  bestvalidloss 6.29519  last_update 0\n",
      "train: iter 38  trainloss 4.70847  validloss 6.38328±0.00000  bestvalidloss 6.29519  last_update 1\n",
      "train: iter 39  trainloss 4.72131  validloss 6.35218±0.00000  bestvalidloss 6.29519  last_update 2\n",
      "train: iter 40  trainloss 4.65718  validloss 6.32751±0.00000  bestvalidloss 6.29519  last_update 3\n",
      "train: iter 41  trainloss 4.66713  validloss 6.24182±0.00000  bestvalidloss 6.24182  last_update 0\n",
      "train: iter 42  trainloss 4.64334  validloss 6.11767±0.00000  bestvalidloss 6.11767  last_update 0\n",
      "train: iter 43  trainloss 4.56913  validloss 6.37398±0.00000  bestvalidloss 6.11767  last_update 1\n",
      "train: iter 44  trainloss 4.58040  validloss 5.97036±0.00000  bestvalidloss 5.97036  last_update 0\n",
      "train: iter 45  trainloss 4.48462  validloss 6.02300±0.00000  bestvalidloss 5.97036  last_update 1\n",
      "train: iter 46  trainloss 4.58606  validloss 6.07402±0.00000  bestvalidloss 5.97036  last_update 2\n",
      "train: iter 47  trainloss 4.51177  validloss 6.08921±0.00000  bestvalidloss 5.97036  last_update 3\n",
      "train: iter 48  trainloss 4.45543  validloss 5.89041±0.00000  bestvalidloss 5.89041  last_update 0\n",
      "train: iter 49  trainloss 4.47832  validloss 5.95597±0.00000  bestvalidloss 5.89041  last_update 1\n",
      "train: iter 50  trainloss 4.41083  validloss 6.07375±0.00000  bestvalidloss 5.89041  last_update 2\n",
      "train: iter 51  trainloss 4.40291  validloss 5.89931±0.00000  bestvalidloss 5.89041  last_update 3\n",
      "train: iter 52  trainloss 4.38563  validloss 6.13055±0.00000  bestvalidloss 5.89041  last_update 4\n",
      "train: iter 53  trainloss 4.36551  validloss 5.87956±0.00000  bestvalidloss 5.87956  last_update 0\n",
      "train: iter 54  trainloss 4.33593  validloss 5.76179±0.00000  bestvalidloss 5.76179  last_update 0\n",
      "train: iter 55  trainloss 4.25646  validloss 5.85107±0.00000  bestvalidloss 5.76179  last_update 1\n",
      "train: iter 56  trainloss 4.25367  validloss 5.82182±0.00000  bestvalidloss 5.76179  last_update 2\n",
      "train: iter 57  trainloss 4.19674  validloss 5.71892±0.00000  bestvalidloss 5.71892  last_update 0\n",
      "train: iter 58  trainloss 4.21569  validloss 5.72638±0.00000  bestvalidloss 5.71892  last_update 1\n",
      "train: iter 59  trainloss 4.19995  validloss 5.81463±0.00000  bestvalidloss 5.71892  last_update 2\n",
      "train: iter 60  trainloss 4.19523  validloss 5.87034±0.00000  bestvalidloss 5.71892  last_update 3\n",
      "train: iter 61  trainloss 4.17347  validloss 5.77898±0.00000  bestvalidloss 5.71892  last_update 4\n",
      "train: iter 62  trainloss 4.16340  validloss 5.83902±0.00000  bestvalidloss 5.71892  last_update 5\n",
      "train: iter 63  trainloss 4.22991  validloss 5.79756±0.00000  bestvalidloss 5.71892  last_update 6\n",
      "train: iter 64  trainloss 4.04334  validloss 5.77495±0.00000  bestvalidloss 5.71892  last_update 7\n",
      "train: iter 65  trainloss 4.15825  validloss 5.66945±0.00000  bestvalidloss 5.66945  last_update 0\n",
      "train: iter 66  trainloss 4.10487  validloss 5.77984±0.00000  bestvalidloss 5.66945  last_update 1\n",
      "train: iter 67  trainloss 4.12583  validloss 5.74619±0.00000  bestvalidloss 5.66945  last_update 2\n",
      "train: iter 68  trainloss 4.04373  validloss 5.78682±0.00000  bestvalidloss 5.66945  last_update 3\n",
      "train: iter 69  trainloss 4.07861  validloss 5.65754±0.00000  bestvalidloss 5.65754  last_update 0\n",
      "train: iter 70  trainloss 4.08941  validloss 5.71426±0.00000  bestvalidloss 5.65754  last_update 1\n",
      "train: iter 71  trainloss 4.09057  validloss 5.77862±0.00000  bestvalidloss 5.65754  last_update 2\n",
      "train: iter 72  trainloss 4.11991  validloss 5.81185±0.00000  bestvalidloss 5.65754  last_update 3\n",
      "train: iter 73  trainloss 4.06114  validloss 5.66924±0.00000  bestvalidloss 5.65754  last_update 4\n",
      "train: iter 74  trainloss 4.03514  validloss 5.64936±0.00000  bestvalidloss 5.64936  last_update 0\n",
      "train: iter 75  trainloss 4.03397  validloss 5.79238±0.00000  bestvalidloss 5.64936  last_update 1\n",
      "train: iter 76  trainloss 4.03582  validloss 5.75112±0.00000  bestvalidloss 5.64936  last_update 2\n",
      "train: iter 77  trainloss 4.05141  validloss 5.80899±0.00000  bestvalidloss 5.64936  last_update 3\n",
      "train: iter 78  trainloss 3.98318  validloss 5.74515±0.00000  bestvalidloss 5.64936  last_update 4\n",
      "train: iter 79  trainloss 4.00955  validloss 5.67759±0.00000  bestvalidloss 5.64936  last_update 5\n",
      "train: iter 80  trainloss 4.07373  validloss 5.82707±0.00000  bestvalidloss 5.64936  last_update 6\n",
      "train: iter 81  trainloss 4.01437  validloss 5.66436±0.00000  bestvalidloss 5.64936  last_update 7\n",
      "train: iter 82  trainloss 4.01045  validloss 5.65215±0.00000  bestvalidloss 5.64936  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 4.01382  validloss 5.54500±0.00000  bestvalidloss 5.54500  last_update 0\n",
      "train: iter 84  trainloss 4.02261  validloss 5.70381±0.00000  bestvalidloss 5.54500  last_update 1\n",
      "train: iter 85  trainloss 3.98222  validloss 5.52451±0.00000  bestvalidloss 5.52451  last_update 0\n",
      "train: iter 86  trainloss 4.02555  validloss 5.79789±0.00000  bestvalidloss 5.52451  last_update 1\n",
      "train: iter 87  trainloss 3.99560  validloss 5.72679±0.00000  bestvalidloss 5.52451  last_update 2\n",
      "train: iter 88  trainloss 4.03406  validloss 5.60791±0.00000  bestvalidloss 5.52451  last_update 3\n",
      "train: iter 89  trainloss 4.01298  validloss 5.57816±0.00000  bestvalidloss 5.52451  last_update 4\n",
      "train: iter 90  trainloss 4.01612  validloss 5.71379±0.00000  bestvalidloss 5.52451  last_update 5\n",
      "train: iter 91  trainloss 4.03272  validloss 5.61010±0.00000  bestvalidloss 5.52451  last_update 6\n",
      "train: iter 92  trainloss 3.97114  validloss 5.57794±0.00000  bestvalidloss 5.52451  last_update 7\n",
      "train: iter 93  trainloss 3.94270  validloss 5.72489±0.00000  bestvalidloss 5.52451  last_update 8\n",
      "train: iter 94  trainloss 3.98209  validloss 5.59799±0.00000  bestvalidloss 5.52451  last_update 9\n",
      "train: iter 95  trainloss 4.02542  validloss 5.60049±0.00000  bestvalidloss 5.52451  last_update 10\n",
      "train: iter 96  trainloss 4.00487  validloss 5.44400±0.00000  bestvalidloss 5.44400  last_update 0\n",
      "train: iter 97  trainloss 4.00370  validloss 5.88860±0.00000  bestvalidloss 5.44400  last_update 1\n",
      "train: iter 98  trainloss 4.00144  validloss 5.67787±0.00000  bestvalidloss 5.44400  last_update 2\n",
      "train: iter 99  trainloss 4.00148  validloss 5.64921±0.00000  bestvalidloss 5.44400  last_update 3\n",
      "train: iter 100  trainloss 3.98180  validloss 5.65589±0.00000  bestvalidloss 5.44400  last_update 4\n",
      "train: iter 101  trainloss 3.98360  validloss 5.76140±0.00000  bestvalidloss 5.44400  last_update 5\n",
      "train: iter 102  trainloss 3.97490  validloss 5.62941±0.00000  bestvalidloss 5.44400  last_update 6\n",
      "train: iter 103  trainloss 3.94840  validloss 5.65388±0.00000  bestvalidloss 5.44400  last_update 7\n",
      "train: iter 104  trainloss 4.01008  validloss 5.98414±0.00000  bestvalidloss 5.44400  last_update 8\n",
      "train: iter 105  trainloss 3.98503  validloss 5.53425±0.00000  bestvalidloss 5.44400  last_update 9\n",
      "train: iter 106  trainloss 3.98543  validloss 5.56928±0.00000  bestvalidloss 5.44400  last_update 10\n",
      "train: iter 107  trainloss 3.95461  validloss 5.78817±0.00000  bestvalidloss 5.44400  last_update 11\n",
      "train: iter 108  trainloss 4.01276  validloss 5.72126±0.00000  bestvalidloss 5.44400  last_update 12\n",
      "train: iter 109  trainloss 3.96161  validloss 5.87616±0.00000  bestvalidloss 5.44400  last_update 13\n",
      "train: iter 110  trainloss 3.93310  validloss 5.59191±0.00000  bestvalidloss 5.44400  last_update 14\n",
      "train: iter 111  trainloss 3.96551  validloss 5.65634±0.00000  bestvalidloss 5.44400  last_update 15\n",
      "train: iter 112  trainloss 4.04491  validloss 5.69090±0.00000  bestvalidloss 5.44400  last_update 16\n",
      "train: iter 113  trainloss 3.95318  validloss 5.63328±0.00000  bestvalidloss 5.44400  last_update 17\n",
      "train: iter 114  trainloss 3.96574  validloss 5.51067±0.00000  bestvalidloss 5.44400  last_update 18\n",
      "train: iter 115  trainloss 3.98707  validloss 5.65778±0.00000  bestvalidloss 5.44400  last_update 19\n",
      "train: iter 116  trainloss 3.99294  validloss 5.80129±0.00000  bestvalidloss 5.44400  last_update 20\n",
      "train: iter 117  trainloss 3.95430  validloss 5.63669±0.00000  bestvalidloss 5.44400  last_update 21\n",
      "train: iter 118  trainloss 3.94133  validloss 5.70144±0.00000  bestvalidloss 5.44400  last_update 22\n",
      "train: iter 119  trainloss 3.93328  validloss 5.68015±0.00000  bestvalidloss 5.44400  last_update 23\n",
      "train: iter 120  trainloss 3.95927  validloss 5.84438±0.00000  bestvalidloss 5.44400  last_update 24\n",
      "train: iter 121  trainloss 3.92623  validloss 5.58561±0.00000  bestvalidloss 5.44400  last_update 25\n",
      "train: iter 122  trainloss 3.89503  validloss 5.69962±0.00000  bestvalidloss 5.44400  last_update 26\n",
      "train: iter 123  trainloss 3.95723  validloss 5.87664±0.00000  bestvalidloss 5.44400  last_update 27\n",
      "train: iter 124  trainloss 3.94243  validloss 5.66583±0.00000  bestvalidloss 5.44400  last_update 28\n",
      "train: iter 125  trainloss 3.95008  validloss 5.75138±0.00000  bestvalidloss 5.44400  last_update 29\n",
      "train: iter 126  trainloss 3.96711  validloss 5.63585±0.00000  bestvalidloss 5.44400  last_update 30\n",
      "train: iter 127  trainloss 3.92680  validloss 5.66915±0.00000  bestvalidloss 5.44400  last_update 31\n",
      "train: iter 128  trainloss 3.94780  validloss 5.63778±0.00000  bestvalidloss 5.44400  last_update 32\n",
      "train: iter 129  trainloss 3.97800  validloss 5.61545±0.00000  bestvalidloss 5.44400  last_update 33\n",
      "train: iter 130  trainloss 3.93390  validloss 5.64781±0.00000  bestvalidloss 5.44400  last_update 34\n",
      "train: iter 131  trainloss 3.94266  validloss 6.02914±0.00000  bestvalidloss 5.44400  last_update 35\n",
      "train: iter 132  trainloss 3.93630  validloss 5.50946±0.00000  bestvalidloss 5.44400  last_update 36\n",
      "train: iter 133  trainloss 3.94815  validloss 5.58227±0.00000  bestvalidloss 5.44400  last_update 37\n",
      "train: iter 134  trainloss 3.93328  validloss 5.67342±0.00000  bestvalidloss 5.44400  last_update 38\n",
      "train: iter 135  trainloss 3.98934  validloss 5.59202±0.00000  bestvalidloss 5.44400  last_update 39\n",
      "train: iter 136  trainloss 3.90539  validloss 5.82282±0.00000  bestvalidloss 5.44400  last_update 40\n",
      "train: iter 137  trainloss 3.90515  validloss 5.68544±0.00000  bestvalidloss 5.44400  last_update 41\n",
      "train: iter 138  trainloss 3.96900  validloss 5.69465±0.00000  bestvalidloss 5.44400  last_update 42\n",
      "train: iter 139  trainloss 3.93986  validloss 5.63345±0.00000  bestvalidloss 5.44400  last_update 43\n",
      "train: iter 140  trainloss 3.93743  validloss 5.58466±0.00000  bestvalidloss 5.44400  last_update 44\n",
      "train: iter 141  trainloss 3.93847  validloss 5.53140±0.00000  bestvalidloss 5.44400  last_update 45\n",
      "train: iter 142  trainloss 3.94504  validloss 5.57436±0.00000  bestvalidloss 5.44400  last_update 46\n",
      "train: iter 143  trainloss 3.92320  validloss 5.56916±0.00000  bestvalidloss 5.44400  last_update 47\n",
      "train: iter 144  trainloss 3.94610  validloss 5.55822±0.00000  bestvalidloss 5.44400  last_update 48\n",
      "train: iter 145  trainloss 3.91838  validloss 5.61062±0.00000  bestvalidloss 5.44400  last_update 49\n",
      "train: iter 146  trainloss 3.95300  validloss 5.73386±0.00000  bestvalidloss 5.44400  last_update 50\n",
      "train: iter 147  trainloss 3.92398  validloss 5.66147±0.00000  bestvalidloss 5.44400  last_update 51\n",
      "train: iter 148  trainloss 3.92665  validloss 5.51487±0.00000  bestvalidloss 5.44400  last_update 52\n",
      "train: iter 149  trainloss 3.89163  validloss 5.72210±0.00000  bestvalidloss 5.44400  last_update 53\n",
      "train: iter 150  trainloss 3.94169  validloss 5.69331±0.00000  bestvalidloss 5.44400  last_update 54\n",
      "train: iter 151  trainloss 3.91227  validloss 5.62259±0.00000  bestvalidloss 5.44400  last_update 55\n",
      "train: iter 152  trainloss 3.96021  validloss 5.71489±0.00000  bestvalidloss 5.44400  last_update 56\n",
      "train: iter 153  trainloss 3.90728  validloss 5.74188±0.00000  bestvalidloss 5.44400  last_update 57\n",
      "train: iter 154  trainloss 3.94655  validloss 5.55725±0.00000  bestvalidloss 5.44400  last_update 58\n",
      "train: iter 155  trainloss 3.90128  validloss 5.60493±0.00000  bestvalidloss 5.44400  last_update 59\n",
      "train: iter 156  trainloss 3.91816  validloss 5.63627±0.00000  bestvalidloss 5.44400  last_update 60\n",
      "train: iter 157  trainloss 3.99657  validloss 5.70899±0.00000  bestvalidloss 5.44400  last_update 61\n",
      "train: iter 158  trainloss 3.86950  validloss 5.54222±0.00000  bestvalidloss 5.44400  last_update 62\n",
      "train: iter 159  trainloss 3.92580  validloss 5.62761±0.00000  bestvalidloss 5.44400  last_update 63\n",
      "train: iter 160  trainloss 4.01089  validloss 5.61055±0.00000  bestvalidloss 5.44400  last_update 64\n",
      "train: iter 161  trainloss 3.89966  validloss 5.63669±0.00000  bestvalidloss 5.44400  last_update 65\n",
      "train: iter 162  trainloss 3.91198  validloss 5.73090±0.00000  bestvalidloss 5.44400  last_update 66\n",
      "train: iter 163  trainloss 3.96181  validloss 5.75104±0.00000  bestvalidloss 5.44400  last_update 67\n",
      "train: iter 164  trainloss 3.92662  validloss 5.64612±0.00000  bestvalidloss 5.44400  last_update 68\n",
      "train: iter 165  trainloss 3.88109  validloss 5.67742±0.00000  bestvalidloss 5.44400  last_update 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 166  trainloss 3.88455  validloss 5.51228±0.00000  bestvalidloss 5.44400  last_update 70\n",
      "train: iter 167  trainloss 4.01112  validloss 5.79500±0.00000  bestvalidloss 5.44400  last_update 71\n",
      "train: iter 168  trainloss 3.91704  validloss 5.74537±0.00000  bestvalidloss 5.44400  last_update 72\n",
      "train: iter 169  trainloss 3.89557  validloss 5.74345±0.00000  bestvalidloss 5.44400  last_update 73\n",
      "train: iter 170  trainloss 3.89397  validloss 5.55257±0.00000  bestvalidloss 5.44400  last_update 74\n",
      "train: iter 171  trainloss 3.89908  validloss 5.56228±0.00000  bestvalidloss 5.44400  last_update 75\n",
      "train: iter 172  trainloss 3.90697  validloss 5.52669±0.00000  bestvalidloss 5.44400  last_update 76\n",
      "train: iter 173  trainloss 3.91182  validloss 5.61052±0.00000  bestvalidloss 5.44400  last_update 77\n",
      "train: iter 174  trainloss 3.96022  validloss 5.51277±0.00000  bestvalidloss 5.44400  last_update 78\n",
      "train: iter 175  trainloss 3.93901  validloss 5.61847±0.00000  bestvalidloss 5.44400  last_update 79\n",
      "train: iter 176  trainloss 3.90544  validloss 5.59007±0.00000  bestvalidloss 5.44400  last_update 80\n",
      "train: iter 177  trainloss 3.98293  validloss 5.62320±0.00000  bestvalidloss 5.44400  last_update 81\n",
      "train: iter 178  trainloss 3.88810  validloss 5.63279±0.00000  bestvalidloss 5.44400  last_update 82\n",
      "train: iter 179  trainloss 3.87906  validloss 5.55306±0.00000  bestvalidloss 5.44400  last_update 83\n",
      "train: iter 180  trainloss 3.96611  validloss 5.58822±0.00000  bestvalidloss 5.44400  last_update 84\n",
      "train: iter 181  trainloss 3.92436  validloss 5.59784±0.00000  bestvalidloss 5.44400  last_update 85\n",
      "train: iter 182  trainloss 3.90071  validloss 5.53436±0.00000  bestvalidloss 5.44400  last_update 86\n",
      "train: iter 183  trainloss 3.87360  validloss 5.57391±0.00000  bestvalidloss 5.44400  last_update 87\n",
      "train: iter 184  trainloss 3.88795  validloss 5.57345±0.00000  bestvalidloss 5.44400  last_update 88\n",
      "train: iter 185  trainloss 3.88932  validloss 5.55659±0.00000  bestvalidloss 5.44400  last_update 89\n",
      "train: iter 186  trainloss 3.88398  validloss 5.65527±0.00000  bestvalidloss 5.44400  last_update 90\n",
      "train: iter 187  trainloss 3.85576  validloss 5.55904±0.00000  bestvalidloss 5.44400  last_update 91\n",
      "train: iter 188  trainloss 3.92831  validloss 5.68345±0.00000  bestvalidloss 5.44400  last_update 92\n",
      "train: iter 189  trainloss 3.89170  validloss 5.74525±0.00000  bestvalidloss 5.44400  last_update 93\n",
      "train: iter 190  trainloss 3.88645  validloss 5.53595±0.00000  bestvalidloss 5.44400  last_update 94\n",
      "train: iter 191  trainloss 3.88804  validloss 5.55512±0.00000  bestvalidloss 5.44400  last_update 95\n",
      "train: iter 192  trainloss 3.86019  validloss 5.63272±0.00000  bestvalidloss 5.44400  last_update 96\n",
      "train: iter 193  trainloss 3.87594  validloss 5.56257±0.00000  bestvalidloss 5.44400  last_update 97\n",
      "train: iter 194  trainloss 3.89663  validloss 5.82239±0.00000  bestvalidloss 5.44400  last_update 98\n",
      "train: iter 195  trainloss 3.87984  validloss 5.57932±0.00000  bestvalidloss 5.44400  last_update 99\n",
      "train: iter 196  trainloss 3.88844  validloss 5.59629±0.00000  bestvalidloss 5.44400  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-12.9182)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(8.5986)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.33380855681015925\n",
      "tensor([2.6833])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1543ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c65ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1aaee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5543e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35e98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
