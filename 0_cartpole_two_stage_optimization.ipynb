{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(2008.6974)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 117826.31256  validloss 69047.59462±0.00000  bestvalidloss 69047.59462  last_update 0\n",
      "train: iter 1  trainloss 46026.26114  validloss 4684.49555±0.00000  bestvalidloss 4684.49555  last_update 0\n",
      "train: iter 2  trainloss 1128.31838  validloss 2320.33839±0.00000  bestvalidloss 2320.33839  last_update 0\n",
      "train: iter 3  trainloss 1021.82582  validloss 1209.55135±0.00000  bestvalidloss 1209.55135  last_update 0\n",
      "train: iter 4  trainloss 869.26511  validloss 1507.30125±0.00000  bestvalidloss 1209.55135  last_update 1\n",
      "train: iter 5  trainloss 779.66786  validloss 1003.83429±0.00000  bestvalidloss 1003.83429  last_update 0\n",
      "train: iter 6  trainloss 767.12738  validloss 995.14189±0.00000  bestvalidloss 995.14189  last_update 0\n",
      "train: iter 7  trainloss 717.18211  validloss 975.32162±0.00000  bestvalidloss 975.32162  last_update 0\n",
      "train: iter 8  trainloss 686.37156  validloss 928.11358±0.00000  bestvalidloss 928.11358  last_update 0\n",
      "train: iter 9  trainloss 678.31631  validloss 903.83190±0.00000  bestvalidloss 903.83190  last_update 0\n",
      "train: iter 10  trainloss 638.78848  validloss 743.85051±0.00000  bestvalidloss 743.85051  last_update 0\n",
      "train: iter 11  trainloss 629.58097  validloss 883.77424±0.00000  bestvalidloss 743.85051  last_update 1\n",
      "train: iter 12  trainloss 572.16998  validloss 746.47295±0.00000  bestvalidloss 743.85051  last_update 2\n",
      "train: iter 13  trainloss 522.22139  validloss 768.47658±0.00000  bestvalidloss 743.85051  last_update 3\n",
      "train: iter 14  trainloss 476.96498  validloss 810.81603±0.00000  bestvalidloss 743.85051  last_update 4\n",
      "train: iter 15  trainloss 402.42441  validloss 760.91789±0.00000  bestvalidloss 743.85051  last_update 5\n",
      "train: iter 16  trainloss 329.59231  validloss 571.29251±0.00000  bestvalidloss 571.29251  last_update 0\n",
      "train: iter 17  trainloss 267.05711  validloss 510.00135±0.00000  bestvalidloss 510.00135  last_update 0\n",
      "train: iter 18  trainloss 262.36243  validloss 342.51203±0.00000  bestvalidloss 342.51203  last_update 0\n",
      "train: iter 19  trainloss 180.88805  validloss 416.91012±0.00000  bestvalidloss 342.51203  last_update 1\n",
      "train: iter 20  trainloss 142.15500  validloss 196.22769±0.00000  bestvalidloss 196.22769  last_update 0\n",
      "train: iter 21  trainloss 109.10684  validloss 384.53001±0.00000  bestvalidloss 196.22769  last_update 1\n",
      "train: iter 22  trainloss 58.42198  validloss 203.03222±0.00000  bestvalidloss 196.22769  last_update 2\n",
      "train: iter 23  trainloss 59.37190  validloss 179.19426±0.00000  bestvalidloss 179.19426  last_update 0\n",
      "train: iter 24  trainloss 3.72244  validloss 111.74292±0.00000  bestvalidloss 111.74292  last_update 0\n",
      "train: iter 25  trainloss -27.89624  validloss 53.81757±0.00000  bestvalidloss 53.81757  last_update 0\n",
      "train: iter 26  trainloss -33.72818  validloss 128.86838±0.00000  bestvalidloss 53.81757  last_update 1\n",
      "train: iter 27  trainloss -72.57731  validloss -25.09039±0.00000  bestvalidloss -25.09039  last_update 0\n",
      "train: iter 28  trainloss -63.72535  validloss -16.34231±0.00000  bestvalidloss -25.09039  last_update 1\n",
      "train: iter 29  trainloss -76.96203  validloss 29.97357±0.00000  bestvalidloss -25.09039  last_update 2\n",
      "train: iter 30  trainloss -118.84916  validloss -75.53954±0.00000  bestvalidloss -75.53954  last_update 0\n",
      "train: iter 31  trainloss -137.84905  validloss -28.11641±0.00000  bestvalidloss -75.53954  last_update 1\n",
      "train: iter 32  trainloss -157.69226  validloss -68.99407±0.00000  bestvalidloss -75.53954  last_update 2\n",
      "train: iter 33  trainloss -175.31499  validloss -143.71965±0.00000  bestvalidloss -143.71965  last_update 0\n",
      "train: iter 34  trainloss -139.98124  validloss -129.03603±0.00000  bestvalidloss -143.71965  last_update 1\n",
      "train: iter 35  trainloss -202.65364  validloss -128.81878±0.00000  bestvalidloss -143.71965  last_update 2\n",
      "train: iter 36  trainloss -224.29978  validloss -187.59570±0.00000  bestvalidloss -187.59570  last_update 0\n",
      "train: iter 37  trainloss -219.50845  validloss -225.96145±0.00000  bestvalidloss -225.96145  last_update 0\n",
      "train: iter 38  trainloss -232.28404  validloss -231.56610±0.00000  bestvalidloss -231.56610  last_update 0\n",
      "train: iter 39  trainloss -221.10303  validloss -180.91037±0.00000  bestvalidloss -231.56610  last_update 1\n",
      "train: iter 40  trainloss -269.82522  validloss -256.43541±0.00000  bestvalidloss -256.43541  last_update 0\n",
      "train: iter 41  trainloss -284.05291  validloss -245.46109±0.00000  bestvalidloss -256.43541  last_update 1\n",
      "train: iter 42  trainloss -272.98147  validloss -211.17014±0.00000  bestvalidloss -256.43541  last_update 2\n",
      "train: iter 43  trainloss -287.07885  validloss -220.91746±0.00000  bestvalidloss -256.43541  last_update 3\n",
      "train: iter 44  trainloss -309.98502  validloss -290.32924±0.00000  bestvalidloss -290.32924  last_update 0\n",
      "train: iter 45  trainloss -311.73818  validloss -224.51784±0.00000  bestvalidloss -290.32924  last_update 1\n",
      "train: iter 46  trainloss -351.55892  validloss -302.66820±0.00000  bestvalidloss -302.66820  last_update 0\n",
      "train: iter 47  trainloss -352.60673  validloss -375.07708±0.00000  bestvalidloss -375.07708  last_update 0\n",
      "train: iter 48  trainloss -323.84744  validloss -364.41183±0.00000  bestvalidloss -375.07708  last_update 1\n",
      "train: iter 49  trainloss -320.35306  validloss -376.16812±0.00000  bestvalidloss -376.16812  last_update 0\n",
      "train: iter 50  trainloss -347.04760  validloss -391.63035±0.00000  bestvalidloss -391.63035  last_update 0\n",
      "train: iter 51  trainloss -367.35640  validloss -426.44036±0.00000  bestvalidloss -426.44036  last_update 0\n",
      "train: iter 52  trainloss -391.31273  validloss -399.34439±0.00000  bestvalidloss -426.44036  last_update 1\n",
      "train: iter 53  trainloss -367.87110  validloss -338.96933±0.00000  bestvalidloss -426.44036  last_update 2\n",
      "train: iter 54  trainloss -397.16087  validloss -456.62672±0.00000  bestvalidloss -456.62672  last_update 0\n",
      "train: iter 55  trainloss -379.15139  validloss -414.69108±0.00000  bestvalidloss -456.62672  last_update 1\n",
      "train: iter 56  trainloss -353.23367  validloss -338.23974±0.00000  bestvalidloss -456.62672  last_update 2\n",
      "train: iter 57  trainloss -378.29034  validloss -419.99023±0.00000  bestvalidloss -456.62672  last_update 3\n",
      "train: iter 58  trainloss -395.61479  validloss -449.76319±0.00000  bestvalidloss -456.62672  last_update 4\n",
      "train: iter 59  trainloss -399.96259  validloss -481.38743±0.00000  bestvalidloss -481.38743  last_update 0\n",
      "train: iter 60  trainloss -442.00422  validloss -477.19294±0.00000  bestvalidloss -481.38743  last_update 1\n",
      "train: iter 61  trainloss -411.01749  validloss -508.05492±0.00000  bestvalidloss -508.05492  last_update 0\n",
      "train: iter 62  trainloss -420.44706  validloss -387.99423±0.00000  bestvalidloss -508.05492  last_update 1\n",
      "train: iter 63  trainloss -462.00849  validloss -467.75385±0.00000  bestvalidloss -508.05492  last_update 2\n",
      "train: iter 64  trainloss -459.00334  validloss -500.26216±0.00000  bestvalidloss -508.05492  last_update 3\n",
      "train: iter 65  trainloss -475.13891  validloss -508.14929±0.00000  bestvalidloss -508.14929  last_update 0\n",
      "train: iter 66  trainloss -461.57442  validloss -518.45443±0.00000  bestvalidloss -518.45443  last_update 0\n",
      "train: iter 67  trainloss -481.01650  validloss -534.14050±0.00000  bestvalidloss -534.14050  last_update 0\n",
      "train: iter 68  trainloss -368.30989  validloss -122.22466±0.00000  bestvalidloss -534.14050  last_update 1\n",
      "train: iter 69  trainloss -429.38076  validloss -329.78913±0.00000  bestvalidloss -534.14050  last_update 2\n",
      "train: iter 70  trainloss -501.61589  validloss -577.80023±0.00000  bestvalidloss -577.80023  last_update 0\n",
      "train: iter 71  trainloss -397.41642  validloss -554.66986±0.00000  bestvalidloss -577.80023  last_update 1\n",
      "train: iter 72  trainloss -470.80649  validloss -491.37150±0.00000  bestvalidloss -577.80023  last_update 2\n",
      "train: iter 73  trainloss -514.82725  validloss -534.68424±0.00000  bestvalidloss -577.80023  last_update 3\n",
      "train: iter 74  trainloss -524.27033  validloss -600.10178±0.00000  bestvalidloss -600.10178  last_update 0\n",
      "train: iter 75  trainloss -539.25842  validloss -559.04953±0.00000  bestvalidloss -600.10178  last_update 1\n",
      "train: iter 76  trainloss -528.42087  validloss -470.11385±0.00000  bestvalidloss -600.10178  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 77  trainloss -512.44206  validloss -523.74870±0.00000  bestvalidloss -600.10178  last_update 3\n",
      "train: iter 78  trainloss -512.27821  validloss -455.08649±0.00000  bestvalidloss -600.10178  last_update 4\n",
      "train: iter 79  trainloss -547.68939  validloss -588.11619±0.00000  bestvalidloss -600.10178  last_update 5\n",
      "train: iter 80  trainloss -568.18723  validloss -622.60888±0.00000  bestvalidloss -622.60888  last_update 0\n",
      "train: iter 81  trainloss -550.67822  validloss -633.06181±0.00000  bestvalidloss -633.06181  last_update 0\n",
      "train: iter 82  trainloss -529.41579  validloss -495.62324±0.00000  bestvalidloss -633.06181  last_update 1\n",
      "train: iter 83  trainloss -576.63605  validloss -565.46241±0.00000  bestvalidloss -633.06181  last_update 2\n",
      "train: iter 84  trainloss -487.09961  validloss -584.82957±0.00000  bestvalidloss -633.06181  last_update 3\n",
      "train: iter 85  trainloss -389.77824  validloss -499.81106±0.00000  bestvalidloss -633.06181  last_update 4\n",
      "train: iter 86  trainloss -554.35907  validloss -591.38204±0.00000  bestvalidloss -633.06181  last_update 5\n",
      "train: iter 87  trainloss -444.58123  validloss -612.82346±0.00000  bestvalidloss -633.06181  last_update 6\n",
      "train: iter 88  trainloss -279.76958  validloss -343.17201±0.00000  bestvalidloss -633.06181  last_update 7\n",
      "train: iter 89  trainloss -453.45311  validloss -530.98324±0.00000  bestvalidloss -633.06181  last_update 8\n",
      "train: iter 90  trainloss -491.60709  validloss -481.45842±0.00000  bestvalidloss -633.06181  last_update 9\n",
      "train: iter 91  trainloss -508.02901  validloss -592.74840±0.00000  bestvalidloss -633.06181  last_update 10\n",
      "train: iter 92  trainloss -507.39304  validloss -590.52005±0.00000  bestvalidloss -633.06181  last_update 11\n",
      "train: iter 93  trainloss -547.44969  validloss -530.70851±0.00000  bestvalidloss -633.06181  last_update 12\n",
      "train: iter 94  trainloss -568.18880  validloss -644.97948±0.00000  bestvalidloss -644.97948  last_update 0\n",
      "train: iter 95  trainloss -558.90261  validloss -647.57286±0.00000  bestvalidloss -647.57286  last_update 0\n",
      "train: iter 96  trainloss -576.79772  validloss -653.80147±0.00000  bestvalidloss -653.80147  last_update 0\n",
      "train: iter 97  trainloss -617.03682  validloss -662.37979±0.00000  bestvalidloss -662.37979  last_update 0\n",
      "train: iter 98  trainloss -610.85203  validloss -681.20758±0.00000  bestvalidloss -681.20758  last_update 0\n",
      "train: iter 99  trainloss -633.42237  validloss -688.98662±0.00000  bestvalidloss -688.98662  last_update 0\n",
      "train: iter 100  trainloss -520.54492  validloss -627.72534±0.00000  bestvalidloss -688.98662  last_update 1\n",
      "train: iter 101  trainloss -620.77988  validloss -680.03397±0.00000  bestvalidloss -688.98662  last_update 2\n",
      "train: iter 102  trainloss -445.72888  validloss -707.06153±0.00000  bestvalidloss -707.06153  last_update 0\n",
      "train: iter 103  trainloss -535.37748  validloss -521.06704±0.00000  bestvalidloss -707.06153  last_update 1\n",
      "train: iter 104  trainloss -598.73955  validloss -559.06201±0.00000  bestvalidloss -707.06153  last_update 2\n",
      "train: iter 105  trainloss -660.54672  validloss -722.06655±0.00000  bestvalidloss -722.06655  last_update 0\n",
      "train: iter 106  trainloss -615.78701  validloss -732.69716±0.00000  bestvalidloss -732.69716  last_update 0\n",
      "train: iter 107  trainloss -606.44494  validloss -639.12616±0.00000  bestvalidloss -732.69716  last_update 1\n",
      "train: iter 108  trainloss -588.77890  validloss -682.03862±0.00000  bestvalidloss -732.69716  last_update 2\n",
      "train: iter 109  trainloss -670.23879  validloss -653.39965±0.00000  bestvalidloss -732.69716  last_update 3\n",
      "train: iter 110  trainloss -659.47477  validloss -681.82271±0.00000  bestvalidloss -732.69716  last_update 4\n",
      "train: iter 111  trainloss -672.20419  validloss -663.42695±0.00000  bestvalidloss -732.69716  last_update 5\n",
      "train: iter 112  trainloss -572.10723  validloss -742.12480±0.00000  bestvalidloss -742.12480  last_update 0\n",
      "train: iter 113  trainloss -608.75743  validloss -626.43592±0.00000  bestvalidloss -742.12480  last_update 1\n",
      "train: iter 114  trainloss -657.38777  validloss -697.26770±0.00000  bestvalidloss -742.12480  last_update 2\n",
      "train: iter 115  trainloss -662.06661  validloss -735.22073±0.00000  bestvalidloss -742.12480  last_update 3\n",
      "train: iter 116  trainloss -669.55844  validloss -642.30258±0.00000  bestvalidloss -742.12480  last_update 4\n",
      "train: iter 117  trainloss -667.55778  validloss -747.04962±0.00000  bestvalidloss -747.04962  last_update 0\n",
      "train: iter 118  trainloss -680.77005  validloss -667.81960±0.00000  bestvalidloss -747.04962  last_update 1\n",
      "train: iter 119  trainloss -593.89778  validloss -747.84296±0.00000  bestvalidloss -747.84296  last_update 0\n",
      "train: iter 120  trainloss -623.02163  validloss -602.85503±0.00000  bestvalidloss -747.84296  last_update 1\n",
      "train: iter 121  trainloss -597.48264  validloss -692.62145±0.00000  bestvalidloss -747.84296  last_update 2\n",
      "train: iter 122  trainloss -699.74156  validloss -660.47855±0.00000  bestvalidloss -747.84296  last_update 3\n",
      "train: iter 123  trainloss -689.89502  validloss -793.92866±0.00000  bestvalidloss -793.92866  last_update 0\n",
      "train: iter 124  trainloss -711.07243  validloss -627.17769±0.00000  bestvalidloss -793.92866  last_update 1\n",
      "train: iter 125  trainloss -659.63492  validloss -772.08398±0.00000  bestvalidloss -793.92866  last_update 2\n",
      "train: iter 126  trainloss -685.62020  validloss -711.19106±0.00000  bestvalidloss -793.92866  last_update 3\n",
      "train: iter 127  trainloss -626.59220  validloss -577.90883±0.00000  bestvalidloss -793.92866  last_update 4\n",
      "train: iter 128  trainloss -723.97818  validloss -648.99583±0.00000  bestvalidloss -793.92866  last_update 5\n",
      "train: iter 129  trainloss -685.47231  validloss -765.23229±0.00000  bestvalidloss -793.92866  last_update 6\n",
      "train: iter 130  trainloss -709.77364  validloss -822.06102±0.00000  bestvalidloss -822.06102  last_update 0\n",
      "train: iter 131  trainloss -721.71500  validloss -818.78461±0.00000  bestvalidloss -822.06102  last_update 1\n",
      "train: iter 132  trainloss -707.01993  validloss -814.27031±0.00000  bestvalidloss -822.06102  last_update 2\n",
      "train: iter 133  trainloss -746.25613  validloss -782.37587±0.00000  bestvalidloss -822.06102  last_update 3\n",
      "train: iter 134  trainloss -749.16703  validloss -819.58234±0.00000  bestvalidloss -822.06102  last_update 4\n",
      "train: iter 135  trainloss -556.35720  validloss -497.36589±0.00000  bestvalidloss -822.06102  last_update 5\n",
      "train: iter 136  trainloss -712.17766  validloss -809.21867±0.00000  bestvalidloss -822.06102  last_update 6\n",
      "train: iter 137  trainloss -726.38711  validloss -669.51296±0.00000  bestvalidloss -822.06102  last_update 7\n",
      "train: iter 138  trainloss -755.74490  validloss -859.50389±0.00000  bestvalidloss -859.50389  last_update 0\n",
      "train: iter 139  trainloss -654.21785  validloss -842.31451±0.00000  bestvalidloss -859.50389  last_update 1\n",
      "train: iter 140  trainloss -746.78183  validloss -802.78098±0.00000  bestvalidloss -859.50389  last_update 2\n",
      "train: iter 141  trainloss -727.60332  validloss -873.32821±0.00000  bestvalidloss -873.32821  last_update 0\n",
      "train: iter 142  trainloss -706.95092  validloss -864.27841±0.00000  bestvalidloss -873.32821  last_update 1\n",
      "train: iter 143  trainloss -640.18657  validloss -813.07287±0.00000  bestvalidloss -873.32821  last_update 2\n",
      "train: iter 144  trainloss -690.32822  validloss -784.44088±0.00000  bestvalidloss -873.32821  last_update 3\n",
      "train: iter 145  trainloss -597.74488  validloss -825.17903±0.00000  bestvalidloss -873.32821  last_update 4\n",
      "train: iter 146  trainloss -623.85733  validloss -742.71776±0.00000  bestvalidloss -873.32821  last_update 5\n",
      "train: iter 147  trainloss -519.92533  validloss -262.05260±0.00000  bestvalidloss -873.32821  last_update 6\n",
      "train: iter 148  trainloss -353.77153  validloss -69.19538±0.00000  bestvalidloss -873.32821  last_update 7\n",
      "train: iter 149  trainloss -706.89959  validloss -740.22749±0.00000  bestvalidloss -873.32821  last_update 8\n",
      "train: iter 150  trainloss -810.39799  validloss -853.47522±0.00000  bestvalidloss -873.32821  last_update 9\n",
      "train: iter 151  trainloss -816.70386  validloss -820.67362±0.00000  bestvalidloss -873.32821  last_update 10\n",
      "train: iter 152  trainloss -835.68396  validloss -910.26702±0.00000  bestvalidloss -910.26702  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 153  trainloss -835.09664  validloss -915.17638±0.00000  bestvalidloss -915.17638  last_update 0\n",
      "train: iter 154  trainloss -809.70895  validloss -795.38656±0.00000  bestvalidloss -915.17638  last_update 1\n",
      "train: iter 155  trainloss -686.94646  validloss -834.80084±0.00000  bestvalidloss -915.17638  last_update 2\n",
      "train: iter 156  trainloss -771.14612  validloss -923.54550±0.00000  bestvalidloss -923.54550  last_update 0\n",
      "train: iter 157  trainloss -864.91195  validloss -883.53936±0.00000  bestvalidloss -923.54550  last_update 1\n",
      "train: iter 158  trainloss -861.13782  validloss -965.80063±0.00000  bestvalidloss -965.80063  last_update 0\n",
      "train: iter 159  trainloss -892.41853  validloss -972.50673±0.00000  bestvalidloss -972.50673  last_update 0\n",
      "train: iter 160  trainloss -827.61928  validloss -850.08518±0.00000  bestvalidloss -972.50673  last_update 1\n",
      "train: iter 161  trainloss -569.44260  validloss -567.92762±0.00000  bestvalidloss -972.50673  last_update 2\n",
      "train: iter 162  trainloss -803.62951  validloss -848.83476±0.00000  bestvalidloss -972.50673  last_update 3\n",
      "train: iter 163  trainloss -793.03639  validloss -951.92925±0.00000  bestvalidloss -972.50673  last_update 4\n",
      "train: iter 164  trainloss -861.85789  validloss -820.39990±0.00000  bestvalidloss -972.50673  last_update 5\n",
      "train: iter 165  trainloss -917.44429  validloss -925.41470±0.00000  bestvalidloss -972.50673  last_update 6\n",
      "train: iter 166  trainloss -729.99415  validloss -995.70539±0.00000  bestvalidloss -995.70539  last_update 0\n",
      "train: iter 167  trainloss -864.10362  validloss -902.69267±0.00000  bestvalidloss -995.70539  last_update 1\n",
      "train: iter 168  trainloss -900.76741  validloss -956.90208±0.00000  bestvalidloss -995.70539  last_update 2\n",
      "train: iter 169  trainloss -932.47964  validloss -994.32913±0.00000  bestvalidloss -995.70539  last_update 3\n",
      "train: iter 170  trainloss -926.71372  validloss -986.54926±0.00000  bestvalidloss -995.70539  last_update 4\n",
      "train: iter 171  trainloss -892.39374  validloss -1054.95393±0.00000  bestvalidloss -1054.95393  last_update 0\n",
      "train: iter 172  trainloss -890.14073  validloss -843.33483±0.00000  bestvalidloss -1054.95393  last_update 1\n",
      "train: iter 173  trainloss -943.89855  validloss -978.42125±0.00000  bestvalidloss -1054.95393  last_update 2\n",
      "train: iter 174  trainloss -941.73470  validloss -931.70602±0.00000  bestvalidloss -1054.95393  last_update 3\n",
      "train: iter 175  trainloss -892.85366  validloss -1040.44672±0.00000  bestvalidloss -1054.95393  last_update 4\n",
      "train: iter 176  trainloss -779.34136  validloss -723.25088±0.00000  bestvalidloss -1054.95393  last_update 5\n",
      "train: iter 177  trainloss -913.52453  validloss -1021.38223±0.00000  bestvalidloss -1054.95393  last_update 6\n",
      "train: iter 178  trainloss -958.67439  validloss -999.57445±0.00000  bestvalidloss -1054.95393  last_update 7\n",
      "train: iter 179  trainloss -862.60628  validloss -970.17519±0.00000  bestvalidloss -1054.95393  last_update 8\n",
      "train: iter 180  trainloss -845.70260  validloss -1026.24596±0.00000  bestvalidloss -1054.95393  last_update 9\n",
      "train: iter 181  trainloss -895.06669  validloss -999.19206±0.00000  bestvalidloss -1054.95393  last_update 10\n",
      "train: iter 182  trainloss -889.62755  validloss -907.29601±0.00000  bestvalidloss -1054.95393  last_update 11\n",
      "train: iter 183  trainloss -668.28306  validloss -913.64278±0.00000  bestvalidloss -1054.95393  last_update 12\n",
      "train: iter 184  trainloss -916.71671  validloss -865.52427±0.00000  bestvalidloss -1054.95393  last_update 13\n",
      "train: iter 185  trainloss -934.22183  validloss -1058.06878±0.00000  bestvalidloss -1058.06878  last_update 0\n",
      "train: iter 186  trainloss -989.47046  validloss -1083.64993±0.00000  bestvalidloss -1083.64993  last_update 0\n",
      "train: iter 187  trainloss -957.15857  validloss -1013.07459±0.00000  bestvalidloss -1083.64993  last_update 1\n",
      "train: iter 188  trainloss -993.09726  validloss -1057.27037±0.00000  bestvalidloss -1083.64993  last_update 2\n",
      "train: iter 189  trainloss -942.58700  validloss -708.68340±0.00000  bestvalidloss -1083.64993  last_update 3\n",
      "train: iter 190  trainloss -975.17988  validloss -938.61090±0.00000  bestvalidloss -1083.64993  last_update 4\n",
      "train: iter 191  trainloss -956.96565  validloss -1037.45494±0.00000  bestvalidloss -1083.64993  last_update 5\n",
      "train: iter 192  trainloss -941.46466  validloss -962.46130±0.00000  bestvalidloss -1083.64993  last_update 6\n",
      "train: iter 193  trainloss -991.01596  validloss -1074.07531±0.00000  bestvalidloss -1083.64993  last_update 7\n",
      "train: iter 194  trainloss -926.80467  validloss -1114.78616±0.00000  bestvalidloss -1114.78616  last_update 0\n",
      "train: iter 195  trainloss -1032.93341  validloss -1058.49412±0.00000  bestvalidloss -1114.78616  last_update 1\n",
      "train: iter 196  trainloss -895.69209  validloss -1124.57277±0.00000  bestvalidloss -1124.57277  last_update 0\n",
      "train: iter 197  trainloss -892.14107  validloss -677.20468±0.00000  bestvalidloss -1124.57277  last_update 1\n",
      "train: iter 198  trainloss -879.56506  validloss -993.83731±0.00000  bestvalidloss -1124.57277  last_update 2\n",
      "train: iter 199  trainloss -1029.95890  validloss -1018.78160±0.00000  bestvalidloss -1124.57277  last_update 3\n",
      "train: iter 200  trainloss -1031.25868  validloss -1109.73959±0.00000  bestvalidloss -1124.57277  last_update 4\n",
      "train: iter 201  trainloss -946.71453  validloss -938.53813±0.00000  bestvalidloss -1124.57277  last_update 5\n",
      "train: iter 202  trainloss -864.38760  validloss -1124.04929±0.00000  bestvalidloss -1124.57277  last_update 6\n",
      "train: iter 203  trainloss -1026.08639  validloss -1008.39439±0.00000  bestvalidloss -1124.57277  last_update 7\n",
      "train: iter 204  trainloss -904.53953  validloss -1045.65622±0.00000  bestvalidloss -1124.57277  last_update 8\n",
      "train: iter 205  trainloss -914.09353  validloss -1008.02517±0.00000  bestvalidloss -1124.57277  last_update 9\n",
      "train: iter 206  trainloss -1024.43021  validloss -1012.58814±0.00000  bestvalidloss -1124.57277  last_update 10\n",
      "train: iter 207  trainloss -1030.93267  validloss -1101.39058±0.00000  bestvalidloss -1124.57277  last_update 11\n",
      "train: iter 208  trainloss -1044.60390  validloss -1151.67422±0.00000  bestvalidloss -1151.67422  last_update 0\n",
      "train: iter 209  trainloss -991.55234  validloss -926.74857±0.00000  bestvalidloss -1151.67422  last_update 1\n",
      "train: iter 210  trainloss -827.98954  validloss -994.77132±0.00000  bestvalidloss -1151.67422  last_update 2\n",
      "train: iter 211  trainloss -886.09704  validloss -737.89642±0.00000  bestvalidloss -1151.67422  last_update 3\n",
      "train: iter 212  trainloss -1061.11656  validloss -1085.92635±0.00000  bestvalidloss -1151.67422  last_update 4\n",
      "train: iter 213  trainloss -955.96651  validloss -889.23961±0.00000  bestvalidloss -1151.67422  last_update 5\n",
      "train: iter 214  trainloss -995.97954  validloss -911.80593±0.00000  bestvalidloss -1151.67422  last_update 6\n",
      "train: iter 215  trainloss -1022.45659  validloss -1088.21497±0.00000  bestvalidloss -1151.67422  last_update 7\n",
      "train: iter 216  trainloss -918.67172  validloss -1058.02921±0.00000  bestvalidloss -1151.67422  last_update 8\n",
      "train: iter 217  trainloss -1003.77638  validloss -1054.18621±0.00000  bestvalidloss -1151.67422  last_update 9\n",
      "train: iter 218  trainloss -963.95343  validloss -977.26795±0.00000  bestvalidloss -1151.67422  last_update 10\n",
      "train: iter 219  trainloss -1065.28821  validloss -1083.55527±0.00000  bestvalidloss -1151.67422  last_update 11\n",
      "train: iter 220  trainloss -1070.63511  validloss -1184.66245±0.00000  bestvalidloss -1184.66245  last_update 0\n",
      "train: iter 221  trainloss -854.95458  validloss -960.11467±0.00000  bestvalidloss -1184.66245  last_update 1\n",
      "train: iter 222  trainloss -1042.75109  validloss -961.15378±0.00000  bestvalidloss -1184.66245  last_update 2\n",
      "train: iter 223  trainloss -1119.16864  validloss -1178.92569±0.00000  bestvalidloss -1184.66245  last_update 3\n",
      "train: iter 224  trainloss -1085.00523  validloss -1074.72787±0.00000  bestvalidloss -1184.66245  last_update 4\n",
      "train: iter 225  trainloss -984.76100  validloss -1138.25049±0.00000  bestvalidloss -1184.66245  last_update 5\n",
      "train: iter 226  trainloss -1062.94161  validloss -1014.39896±0.00000  bestvalidloss -1184.66245  last_update 6\n",
      "train: iter 227  trainloss -1048.39988  validloss -1119.68604±0.00000  bestvalidloss -1184.66245  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 228  trainloss -1015.94662  validloss -935.77985±0.00000  bestvalidloss -1184.66245  last_update 8\n",
      "train: iter 229  trainloss -991.97211  validloss -1090.25651±0.00000  bestvalidloss -1184.66245  last_update 9\n",
      "train: iter 230  trainloss -934.81578  validloss -1071.50567±0.00000  bestvalidloss -1184.66245  last_update 10\n",
      "train: iter 231  trainloss -1079.38537  validloss -1048.75897±0.00000  bestvalidloss -1184.66245  last_update 11\n",
      "train: iter 232  trainloss -1110.25392  validloss -1050.41624±0.00000  bestvalidloss -1184.66245  last_update 12\n",
      "train: iter 233  trainloss -1171.31201  validloss -1204.49204±0.00000  bestvalidloss -1204.49204  last_update 0\n",
      "train: iter 234  trainloss -916.75838  validloss -1207.82611±0.00000  bestvalidloss -1207.82611  last_update 0\n",
      "train: iter 235  trainloss -1060.27584  validloss -1045.67327±0.00000  bestvalidloss -1207.82611  last_update 1\n",
      "train: iter 236  trainloss -721.49137  validloss -1175.90383±0.00000  bestvalidloss -1207.82611  last_update 2\n",
      "train: iter 237  trainloss -896.46504  validloss -518.44305±0.00000  bestvalidloss -1207.82611  last_update 3\n",
      "train: iter 238  trainloss -1103.62842  validloss -1185.48711±0.00000  bestvalidloss -1207.82611  last_update 4\n",
      "train: iter 239  trainloss -1090.39840  validloss -1212.80723±0.00000  bestvalidloss -1212.80723  last_update 0\n",
      "train: iter 240  trainloss -1082.73981  validloss -1135.69931±0.00000  bestvalidloss -1212.80723  last_update 1\n",
      "train: iter 241  trainloss -498.55880  validloss -1215.16748±0.00000  bestvalidloss -1215.16748  last_update 0\n",
      "train: iter 242  trainloss -872.18086  validloss -886.11558±0.00000  bestvalidloss -1215.16748  last_update 1\n",
      "train: iter 243  trainloss -1026.48948  validloss -1046.30570±0.00000  bestvalidloss -1215.16748  last_update 2\n",
      "train: iter 244  trainloss -1086.58640  validloss -1158.67171±0.00000  bestvalidloss -1215.16748  last_update 3\n",
      "train: iter 245  trainloss -1074.13031  validloss -946.62720±0.00000  bestvalidloss -1215.16748  last_update 4\n",
      "train: iter 246  trainloss -1100.44073  validloss -1205.50340±0.00000  bestvalidloss -1215.16748  last_update 5\n",
      "train: iter 247  trainloss -1035.97365  validloss -1223.18966±0.00000  bestvalidloss -1223.18966  last_update 0\n",
      "train: iter 248  trainloss -987.88584  validloss -525.48195±0.00000  bestvalidloss -1223.18966  last_update 1\n",
      "train: iter 249  trainloss -1175.71531  validloss -1232.55250±0.00000  bestvalidloss -1232.55250  last_update 0\n",
      "train: iter 250  trainloss -1133.02994  validloss -1254.41016±0.00000  bestvalidloss -1254.41016  last_update 0\n",
      "train: iter 251  trainloss -1005.49228  validloss -648.93761±0.00000  bestvalidloss -1254.41016  last_update 1\n",
      "train: iter 252  trainloss -1157.36790  validloss -1187.22485±0.00000  bestvalidloss -1254.41016  last_update 2\n",
      "train: iter 253  trainloss -1136.41755  validloss -1019.93352±0.00000  bestvalidloss -1254.41016  last_update 3\n",
      "train: iter 254  trainloss -1056.99437  validloss -1162.27539±0.00000  bestvalidloss -1254.41016  last_update 4\n",
      "train: iter 255  trainloss -1068.92128  validloss -1130.83192±0.00000  bestvalidloss -1254.41016  last_update 5\n",
      "train: iter 256  trainloss -992.07446  validloss -1019.10672±0.00000  bestvalidloss -1254.41016  last_update 6\n",
      "train: iter 257  trainloss -1087.83672  validloss -1091.82939±0.00000  bestvalidloss -1254.41016  last_update 7\n",
      "train: iter 258  trainloss -1165.46174  validloss -1186.65512±0.00000  bestvalidloss -1254.41016  last_update 8\n",
      "train: iter 259  trainloss -1142.67933  validloss -1242.06261±0.00000  bestvalidloss -1254.41016  last_update 9\n",
      "train: iter 260  trainloss -1154.24296  validloss -1226.26614±0.00000  bestvalidloss -1254.41016  last_update 10\n",
      "train: iter 261  trainloss -1062.25907  validloss -1220.11210±0.00000  bestvalidloss -1254.41016  last_update 11\n",
      "train: iter 262  trainloss -1069.88153  validloss -1055.10724±0.00000  bestvalidloss -1254.41016  last_update 12\n",
      "train: iter 263  trainloss -1117.43152  validloss -1193.55778±0.00000  bestvalidloss -1254.41016  last_update 13\n",
      "train: iter 264  trainloss -1089.86942  validloss -1020.87101±0.00000  bestvalidloss -1254.41016  last_update 14\n",
      "train: iter 265  trainloss -1137.37766  validloss -1182.90023±0.00000  bestvalidloss -1254.41016  last_update 15\n",
      "train: iter 266  trainloss -1198.72854  validloss -1251.57343±0.00000  bestvalidloss -1254.41016  last_update 16\n",
      "train: iter 267  trainloss -1033.95583  validloss -1135.95456±0.00000  bestvalidloss -1254.41016  last_update 17\n",
      "train: iter 268  trainloss -1207.44303  validloss -1233.75396±0.00000  bestvalidloss -1254.41016  last_update 18\n",
      "train: iter 269  trainloss -1226.53880  validloss -1238.71793±0.00000  bestvalidloss -1254.41016  last_update 19\n",
      "train: iter 270  trainloss -1124.99044  validloss -1270.00827±0.00000  bestvalidloss -1270.00827  last_update 0\n",
      "train: iter 271  trainloss -1086.04079  validloss -1082.03533±0.00000  bestvalidloss -1270.00827  last_update 1\n",
      "train: iter 272  trainloss -1127.03668  validloss -1187.08552±0.00000  bestvalidloss -1270.00827  last_update 2\n",
      "train: iter 273  trainloss -1110.06787  validloss -1292.00145±0.00000  bestvalidloss -1292.00145  last_update 0\n",
      "train: iter 274  trainloss -1210.98501  validloss -1280.99570±0.00000  bestvalidloss -1292.00145  last_update 1\n",
      "train: iter 275  trainloss -1152.98263  validloss -1287.59467±0.00000  bestvalidloss -1292.00145  last_update 2\n",
      "train: iter 276  trainloss -953.14340  validloss -1158.78999±0.00000  bestvalidloss -1292.00145  last_update 3\n",
      "train: iter 277  trainloss -1132.22319  validloss -1097.59170±0.00000  bestvalidloss -1292.00145  last_update 4\n",
      "train: iter 278  trainloss -1180.14519  validloss -1244.37261±0.00000  bestvalidloss -1292.00145  last_update 5\n",
      "train: iter 279  trainloss -1231.63045  validloss -1272.13885±0.00000  bestvalidloss -1292.00145  last_update 6\n",
      "train: iter 280  trainloss -1032.39347  validloss -1315.51176±0.00000  bestvalidloss -1315.51176  last_update 0\n",
      "train: iter 281  trainloss -925.25833  validloss -1211.41668±0.00000  bestvalidloss -1315.51176  last_update 1\n",
      "train: iter 282  trainloss -1081.67083  validloss -1216.73076±0.00000  bestvalidloss -1315.51176  last_update 2\n",
      "train: iter 283  trainloss -1140.83488  validloss -1199.89954±0.00000  bestvalidloss -1315.51176  last_update 3\n",
      "train: iter 284  trainloss -1216.04918  validloss -1234.49249±0.00000  bestvalidloss -1315.51176  last_update 4\n",
      "train: iter 285  trainloss -1090.61765  validloss -1208.18535±0.00000  bestvalidloss -1315.51176  last_update 5\n",
      "train: iter 286  trainloss -1242.78215  validloss -1255.66010±0.00000  bestvalidloss -1315.51176  last_update 6\n",
      "train: iter 287  trainloss -1027.78075  validloss -1280.11457±0.00000  bestvalidloss -1315.51176  last_update 7\n",
      "train: iter 288  trainloss -1156.52435  validloss -1174.42636±0.00000  bestvalidloss -1315.51176  last_update 8\n",
      "train: iter 289  trainloss -1188.45438  validloss -1306.48655±0.00000  bestvalidloss -1315.51176  last_update 9\n",
      "train: iter 290  trainloss -1222.79678  validloss -1323.39765±0.00000  bestvalidloss -1323.39765  last_update 0\n",
      "train: iter 291  trainloss -1021.82906  validloss -1075.55629±0.00000  bestvalidloss -1323.39765  last_update 1\n",
      "train: iter 292  trainloss -1216.74713  validloss -1290.65093±0.00000  bestvalidloss -1323.39765  last_update 2\n",
      "train: iter 293  trainloss -1193.53051  validloss -1079.87038±0.00000  bestvalidloss -1323.39765  last_update 3\n",
      "train: iter 294  trainloss -1112.24045  validloss -1176.24635±0.00000  bestvalidloss -1323.39765  last_update 4\n",
      "train: iter 295  trainloss -1125.73617  validloss -1250.46510±0.00000  bestvalidloss -1323.39765  last_update 5\n",
      "train: iter 296  trainloss -1272.81772  validloss -1286.81271±0.00000  bestvalidloss -1323.39765  last_update 6\n",
      "train: iter 297  trainloss -1090.92012  validloss -1254.14685±0.00000  bestvalidloss -1323.39765  last_update 7\n",
      "train: iter 298  trainloss -1219.99264  validloss -1239.50984±0.00000  bestvalidloss -1323.39765  last_update 8\n",
      "train: iter 299  trainloss -1212.83441  validloss -1245.78245±0.00000  bestvalidloss -1323.39765  last_update 9\n",
      "train: iter 300  trainloss -1257.67443  validloss -1277.62370±0.00000  bestvalidloss -1323.39765  last_update 10\n",
      "train: iter 301  trainloss -1186.81154  validloss -1321.36712±0.00000  bestvalidloss -1323.39765  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 302  trainloss -1041.03284  validloss -554.32118±0.00000  bestvalidloss -1323.39765  last_update 12\n",
      "train: iter 303  trainloss -1135.23968  validloss -1319.66721±0.00000  bestvalidloss -1323.39765  last_update 13\n",
      "train: iter 304  trainloss -1258.65176  validloss -1298.81521±0.00000  bestvalidloss -1323.39765  last_update 14\n",
      "train: iter 305  trainloss -1038.79481  validloss -1285.80536±0.00000  bestvalidloss -1323.39765  last_update 15\n",
      "train: iter 306  trainloss -1263.07090  validloss -1244.84414±0.00000  bestvalidloss -1323.39765  last_update 16\n",
      "train: iter 307  trainloss -1249.20413  validloss -1260.59950±0.00000  bestvalidloss -1323.39765  last_update 17\n",
      "train: iter 308  trainloss -1252.03017  validloss -1306.20548±0.00000  bestvalidloss -1323.39765  last_update 18\n",
      "train: iter 309  trainloss -1209.21333  validloss -1329.70174±0.00000  bestvalidloss -1329.70174  last_update 0\n",
      "train: iter 310  trainloss -1253.78882  validloss -1294.39085±0.00000  bestvalidloss -1329.70174  last_update 1\n",
      "train: iter 311  trainloss -1281.06497  validloss -1328.82604±0.00000  bestvalidloss -1329.70174  last_update 2\n",
      "train: iter 312  trainloss -1249.01250  validloss -1032.90636±0.00000  bestvalidloss -1329.70174  last_update 3\n",
      "train: iter 313  trainloss -1110.01433  validloss -1332.08684±0.00000  bestvalidloss -1332.08684  last_update 0\n",
      "train: iter 314  trainloss -1099.76892  validloss -1108.10989±0.00000  bestvalidloss -1332.08684  last_update 1\n",
      "train: iter 315  trainloss -1146.88201  validloss -1112.22123±0.00000  bestvalidloss -1332.08684  last_update 2\n",
      "train: iter 316  trainloss -1157.46001  validloss -1233.11759±0.00000  bestvalidloss -1332.08684  last_update 3\n",
      "train: iter 317  trainloss -1256.49185  validloss -1203.48585±0.00000  bestvalidloss -1332.08684  last_update 4\n",
      "train: iter 318  trainloss -1107.79602  validloss -1376.27063±0.00000  bestvalidloss -1376.27063  last_update 0\n",
      "train: iter 319  trainloss -1188.57543  validloss -1166.41428±0.00000  bestvalidloss -1376.27063  last_update 1\n",
      "train: iter 320  trainloss -1276.14238  validloss -1343.84793±0.00000  bestvalidloss -1376.27063  last_update 2\n",
      "train: iter 321  trainloss -1280.21360  validloss -1381.22131±0.00000  bestvalidloss -1381.22131  last_update 0\n",
      "train: iter 322  trainloss -1213.13842  validloss -1274.67854±0.00000  bestvalidloss -1381.22131  last_update 1\n",
      "train: iter 323  trainloss -1258.82930  validloss -1286.82010±0.00000  bestvalidloss -1381.22131  last_update 2\n",
      "train: iter 324  trainloss -1248.15006  validloss -1374.48638±0.00000  bestvalidloss -1381.22131  last_update 3\n",
      "train: iter 325  trainloss -1235.57449  validloss -1352.13904±0.00000  bestvalidloss -1381.22131  last_update 4\n",
      "train: iter 326  trainloss -1148.69657  validloss -1171.84856±0.00000  bestvalidloss -1381.22131  last_update 5\n",
      "train: iter 327  trainloss -1224.62697  validloss -1304.43803±0.00000  bestvalidloss -1381.22131  last_update 6\n",
      "train: iter 328  trainloss -1235.79108  validloss -1190.63446±0.00000  bestvalidloss -1381.22131  last_update 7\n",
      "train: iter 329  trainloss -1146.03660  validloss -1327.76064±0.00000  bestvalidloss -1381.22131  last_update 8\n",
      "train: iter 330  trainloss -1205.24618  validloss -1347.22964±0.00000  bestvalidloss -1381.22131  last_update 9\n",
      "train: iter 331  trainloss -1204.97032  validloss -1257.60644±0.00000  bestvalidloss -1381.22131  last_update 10\n",
      "train: iter 332  trainloss -1246.45569  validloss -1190.20818±0.00000  bestvalidloss -1381.22131  last_update 11\n",
      "train: iter 333  trainloss -1303.43188  validloss -1337.37310±0.00000  bestvalidloss -1381.22131  last_update 12\n",
      "train: iter 334  trainloss -1146.71541  validloss -1385.81094±0.00000  bestvalidloss -1385.81094  last_update 0\n",
      "train: iter 335  trainloss -1206.14180  validloss -1281.70061±0.00000  bestvalidloss -1385.81094  last_update 1\n",
      "train: iter 336  trainloss -1302.53657  validloss -1313.37242±0.00000  bestvalidloss -1385.81094  last_update 2\n",
      "train: iter 337  trainloss -1113.09713  validloss -1330.20123±0.00000  bestvalidloss -1385.81094  last_update 3\n",
      "train: iter 338  trainloss -1238.22393  validloss -1215.70918±0.00000  bestvalidloss -1385.81094  last_update 4\n",
      "train: iter 339  trainloss -1298.65858  validloss -1367.64806±0.00000  bestvalidloss -1385.81094  last_update 5\n",
      "train: iter 340  trainloss -1258.18854  validloss -1176.92467±0.00000  bestvalidloss -1385.81094  last_update 6\n",
      "train: iter 341  trainloss -1257.83955  validloss -1372.72628±0.00000  bestvalidloss -1385.81094  last_update 7\n",
      "train: iter 342  trainloss -993.82489  validloss -1202.81349±0.00000  bestvalidloss -1385.81094  last_update 8\n",
      "train: iter 343  trainloss -1304.50417  validloss -1211.27318±0.00000  bestvalidloss -1385.81094  last_update 9\n",
      "train: iter 344  trainloss -1229.17877  validloss -1418.38863±0.00000  bestvalidloss -1418.38863  last_update 0\n",
      "train: iter 345  trainloss -1338.61341  validloss -1337.43140±0.00000  bestvalidloss -1418.38863  last_update 1\n",
      "train: iter 346  trainloss -1246.66109  validloss -1329.48635±0.00000  bestvalidloss -1418.38863  last_update 2\n",
      "train: iter 347  trainloss -1317.61134  validloss -1359.51277±0.00000  bestvalidloss -1418.38863  last_update 3\n",
      "train: iter 348  trainloss -1316.01889  validloss -1378.63365±0.00000  bestvalidloss -1418.38863  last_update 4\n",
      "train: iter 349  trainloss -1353.23252  validloss -1318.67305±0.00000  bestvalidloss -1418.38863  last_update 5\n",
      "train: iter 350  trainloss -1251.22336  validloss -1422.22165±0.00000  bestvalidloss -1422.22165  last_update 0\n",
      "train: iter 351  trainloss -1293.20486  validloss -1338.29509±0.00000  bestvalidloss -1422.22165  last_update 1\n",
      "train: iter 352  trainloss -1021.08564  validloss -1296.00916±0.00000  bestvalidloss -1422.22165  last_update 2\n",
      "train: iter 353  trainloss -1315.92290  validloss -1316.15490±0.00000  bestvalidloss -1422.22165  last_update 3\n",
      "train: iter 354  trainloss -1315.24207  validloss -1342.68398±0.00000  bestvalidloss -1422.22165  last_update 4\n",
      "train: iter 355  trainloss -1206.89404  validloss -1319.42746±0.00000  bestvalidloss -1422.22165  last_update 5\n",
      "train: iter 356  trainloss -1289.28088  validloss -1401.08479±0.00000  bestvalidloss -1422.22165  last_update 6\n",
      "train: iter 357  trainloss -1337.58908  validloss -1362.81988±0.00000  bestvalidloss -1422.22165  last_update 7\n",
      "train: iter 358  trainloss -1259.29100  validloss -1350.33737±0.00000  bestvalidloss -1422.22165  last_update 8\n",
      "train: iter 359  trainloss -1296.19135  validloss -1382.38558±0.00000  bestvalidloss -1422.22165  last_update 9\n",
      "train: iter 360  trainloss -1274.68712  validloss -1426.52544±0.00000  bestvalidloss -1426.52544  last_update 0\n",
      "train: iter 361  trainloss -1044.57917  validloss -1330.41503±0.00000  bestvalidloss -1426.52544  last_update 1\n",
      "train: iter 362  trainloss -1307.92107  validloss -1307.04564±0.00000  bestvalidloss -1426.52544  last_update 2\n",
      "train: iter 363  trainloss -1340.65905  validloss -1408.29713±0.00000  bestvalidloss -1426.52544  last_update 3\n",
      "train: iter 364  trainloss -1261.71737  validloss -1283.80387±0.00000  bestvalidloss -1426.52544  last_update 4\n",
      "train: iter 365  trainloss -1288.40336  validloss -1354.42543±0.00000  bestvalidloss -1426.52544  last_update 5\n",
      "train: iter 366  trainloss -1349.18531  validloss -1325.11433±0.00000  bestvalidloss -1426.52544  last_update 6\n",
      "train: iter 367  trainloss -1362.08489  validloss -1424.08846±0.00000  bestvalidloss -1426.52544  last_update 7\n",
      "train: iter 368  trainloss -1167.74966  validloss -1352.13518±0.00000  bestvalidloss -1426.52544  last_update 8\n",
      "train: iter 369  trainloss -1318.41678  validloss -1262.82406±0.00000  bestvalidloss -1426.52544  last_update 9\n",
      "train: iter 370  trainloss -1252.06393  validloss -1423.41750±0.00000  bestvalidloss -1426.52544  last_update 10\n",
      "train: iter 371  trainloss -1304.99208  validloss -1239.94651±0.00000  bestvalidloss -1426.52544  last_update 11\n",
      "train: iter 372  trainloss -1232.26796  validloss -1456.25467±0.00000  bestvalidloss -1456.25467  last_update 0\n",
      "train: iter 373  trainloss -1112.28282  validloss -1029.67431±0.00000  bestvalidloss -1456.25467  last_update 1\n",
      "train: iter 374  trainloss -1217.87811  validloss -1326.85429±0.00000  bestvalidloss -1456.25467  last_update 2\n",
      "train: iter 375  trainloss -1305.50567  validloss -1349.23262±0.00000  bestvalidloss -1456.25467  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 376  trainloss -886.46555  validloss -1291.89894±0.00000  bestvalidloss -1456.25467  last_update 4\n",
      "train: iter 377  trainloss -1244.24900  validloss -1226.70942±0.00000  bestvalidloss -1456.25467  last_update 5\n",
      "train: iter 378  trainloss -1314.42490  validloss -1364.72857±0.00000  bestvalidloss -1456.25467  last_update 6\n",
      "train: iter 379  trainloss -1329.87080  validloss -1368.62313±0.00000  bestvalidloss -1456.25467  last_update 7\n",
      "train: iter 380  trainloss -1326.16865  validloss -1413.32789±0.00000  bestvalidloss -1456.25467  last_update 8\n",
      "train: iter 381  trainloss -1366.24591  validloss -1378.80718±0.00000  bestvalidloss -1456.25467  last_update 9\n",
      "train: iter 382  trainloss -1282.26229  validloss -1267.38587±0.00000  bestvalidloss -1456.25467  last_update 10\n",
      "train: iter 383  trainloss -1259.46005  validloss -1247.81787±0.00000  bestvalidloss -1456.25467  last_update 11\n",
      "train: iter 384  trainloss -1289.99792  validloss -1277.42194±0.00000  bestvalidloss -1456.25467  last_update 12\n",
      "train: iter 385  trainloss -1332.66138  validloss -1319.64102±0.00000  bestvalidloss -1456.25467  last_update 13\n",
      "train: iter 386  trainloss -1381.50722  validloss -1377.23140±0.00000  bestvalidloss -1456.25467  last_update 14\n",
      "train: iter 387  trainloss -1344.11287  validloss -1455.53488±0.00000  bestvalidloss -1456.25467  last_update 15\n",
      "train: iter 388  trainloss -1340.61784  validloss -1369.34970±0.00000  bestvalidloss -1456.25467  last_update 16\n",
      "train: iter 389  trainloss -1397.18377  validloss -1416.34403±0.00000  bestvalidloss -1456.25467  last_update 17\n",
      "train: iter 390  trainloss -1309.55011  validloss -1463.11021±0.00000  bestvalidloss -1463.11021  last_update 0\n",
      "train: iter 391  trainloss -1260.55351  validloss -1245.75260±0.00000  bestvalidloss -1463.11021  last_update 1\n",
      "train: iter 392  trainloss -1356.85428  validloss -1313.43208±0.00000  bestvalidloss -1463.11021  last_update 2\n",
      "train: iter 393  trainloss -1361.48509  validloss -1402.57191±0.00000  bestvalidloss -1463.11021  last_update 3\n",
      "train: iter 394  trainloss -1309.42137  validloss -1298.29222±0.00000  bestvalidloss -1463.11021  last_update 4\n",
      "train: iter 395  trainloss -1374.60029  validloss -1404.54283±0.00000  bestvalidloss -1463.11021  last_update 5\n",
      "train: iter 396  trainloss -1403.86576  validloss -1440.51298±0.00000  bestvalidloss -1463.11021  last_update 6\n",
      "train: iter 397  trainloss -1098.37141  validloss -1391.56995±0.00000  bestvalidloss -1463.11021  last_update 7\n",
      "train: iter 398  trainloss -1332.54301  validloss -1348.28570±0.00000  bestvalidloss -1463.11021  last_update 8\n",
      "train: iter 399  trainloss -1381.87991  validloss -1449.54481±0.00000  bestvalidloss -1463.11021  last_update 9\n",
      "train: iter 400  trainloss -1385.93627  validloss -1446.63168±0.00000  bestvalidloss -1463.11021  last_update 10\n",
      "train: iter 401  trainloss -1182.85700  validloss -1282.88621±0.00000  bestvalidloss -1463.11021  last_update 11\n",
      "train: iter 402  trainloss -1357.22447  validloss -1399.97424±0.00000  bestvalidloss -1463.11021  last_update 12\n",
      "train: iter 403  trainloss -1395.72253  validloss -1428.68024±0.00000  bestvalidloss -1463.11021  last_update 13\n",
      "train: iter 404  trainloss -1249.68775  validloss -971.54620±0.00000  bestvalidloss -1463.11021  last_update 14\n",
      "train: iter 405  trainloss -1348.29317  validloss -1401.33744±0.00000  bestvalidloss -1463.11021  last_update 15\n",
      "train: iter 406  trainloss -1371.49794  validloss -1416.47696±0.00000  bestvalidloss -1463.11021  last_update 16\n",
      "train: iter 407  trainloss -1379.83112  validloss -1440.95518±0.00000  bestvalidloss -1463.11021  last_update 17\n",
      "train: iter 408  trainloss -1296.26119  validloss -1430.25365±0.00000  bestvalidloss -1463.11021  last_update 18\n",
      "train: iter 409  trainloss -1196.57568  validloss -1214.63559±0.00000  bestvalidloss -1463.11021  last_update 19\n",
      "train: iter 410  trainloss -1347.58529  validloss -1406.11884±0.00000  bestvalidloss -1463.11021  last_update 20\n",
      "train: iter 411  trainloss -1397.45650  validloss -1410.67149±0.00000  bestvalidloss -1463.11021  last_update 21\n",
      "train: iter 412  trainloss -1278.19298  validloss -1442.38721±0.00000  bestvalidloss -1463.11021  last_update 22\n",
      "train: iter 413  trainloss -1401.96767  validloss -1462.67616±0.00000  bestvalidloss -1463.11021  last_update 23\n",
      "train: iter 414  trainloss -1246.02081  validloss -1423.24366±0.00000  bestvalidloss -1463.11021  last_update 24\n",
      "train: iter 415  trainloss -1354.18693  validloss -1407.70873±0.00000  bestvalidloss -1463.11021  last_update 25\n",
      "train: iter 416  trainloss -1302.41023  validloss -1279.33328±0.00000  bestvalidloss -1463.11021  last_update 26\n",
      "train: iter 417  trainloss -1387.61824  validloss -1438.79080±0.00000  bestvalidloss -1463.11021  last_update 27\n",
      "train: iter 418  trainloss -1362.92924  validloss -1400.74889±0.00000  bestvalidloss -1463.11021  last_update 28\n",
      "train: iter 419  trainloss -1370.37245  validloss -1409.84339±0.00000  bestvalidloss -1463.11021  last_update 29\n",
      "train: iter 420  trainloss -1214.57859  validloss -1431.84516±0.00000  bestvalidloss -1463.11021  last_update 30\n",
      "train: iter 421  trainloss -1411.83319  validloss -1372.03561±0.00000  bestvalidloss -1463.11021  last_update 31\n",
      "train: iter 422  trainloss -1420.19382  validloss -1473.69002±0.00000  bestvalidloss -1473.69002  last_update 0\n",
      "train: iter 423  trainloss -1397.06905  validloss -1374.85613±0.00000  bestvalidloss -1473.69002  last_update 1\n",
      "train: iter 424  trainloss -1308.02174  validloss -1445.05542±0.00000  bestvalidloss -1473.69002  last_update 2\n",
      "train: iter 425  trainloss -1416.16710  validloss -1448.10536±0.00000  bestvalidloss -1473.69002  last_update 3\n",
      "train: iter 426  trainloss -1370.21414  validloss -1432.58556±0.00000  bestvalidloss -1473.69002  last_update 4\n",
      "train: iter 427  trainloss -1261.31896  validloss -1246.35348±0.00000  bestvalidloss -1473.69002  last_update 5\n",
      "train: iter 428  trainloss -1304.38154  validloss -1356.76186±0.00000  bestvalidloss -1473.69002  last_update 6\n",
      "train: iter 429  trainloss -1374.07987  validloss -1397.06551±0.00000  bestvalidloss -1473.69002  last_update 7\n",
      "train: iter 430  trainloss -1330.78654  validloss -1389.66954±0.00000  bestvalidloss -1473.69002  last_update 8\n",
      "train: iter 431  trainloss -1388.33223  validloss -1430.55766±0.00000  bestvalidloss -1473.69002  last_update 9\n",
      "train: iter 432  trainloss -1368.01974  validloss -1432.30512±0.00000  bestvalidloss -1473.69002  last_update 10\n",
      "train: iter 433  trainloss -1409.80234  validloss -1426.53849±0.00000  bestvalidloss -1473.69002  last_update 11\n",
      "train: iter 434  trainloss -1309.58124  validloss -1367.69936±0.00000  bestvalidloss -1473.69002  last_update 12\n",
      "train: iter 435  trainloss -1413.06970  validloss -1437.05784±0.00000  bestvalidloss -1473.69002  last_update 13\n",
      "train: iter 436  trainloss -1249.72200  validloss -1291.50895±0.00000  bestvalidloss -1473.69002  last_update 14\n",
      "train: iter 437  trainloss -1352.60082  validloss -1383.25069±0.00000  bestvalidloss -1473.69002  last_update 15\n",
      "train: iter 438  trainloss -1134.39902  validloss -1320.28994±0.00000  bestvalidloss -1473.69002  last_update 16\n",
      "train: iter 439  trainloss -1358.37522  validloss -1323.54416±0.00000  bestvalidloss -1473.69002  last_update 17\n",
      "train: iter 440  trainloss -1416.67172  validloss -1428.53542±0.00000  bestvalidloss -1473.69002  last_update 18\n",
      "train: iter 441  trainloss -1386.63121  validloss -1425.45495±0.00000  bestvalidloss -1473.69002  last_update 19\n",
      "train: iter 442  trainloss -1432.02630  validloss -1423.32419±0.00000  bestvalidloss -1473.69002  last_update 20\n",
      "train: iter 443  trainloss -1358.03255  validloss -1460.49370±0.00000  bestvalidloss -1473.69002  last_update 21\n",
      "train: iter 444  trainloss -1347.02900  validloss -1053.61202±0.00000  bestvalidloss -1473.69002  last_update 22\n",
      "train: iter 445  trainloss -1410.37826  validloss -1489.86240±0.00000  bestvalidloss -1489.86240  last_update 0\n",
      "train: iter 446  trainloss -1426.59988  validloss -1435.58537±0.00000  bestvalidloss -1489.86240  last_update 1\n",
      "train: iter 447  trainloss -1182.14290  validloss -1321.79425±0.00000  bestvalidloss -1489.86240  last_update 2\n",
      "train: iter 448  trainloss -1399.72972  validloss -1388.42258±0.00000  bestvalidloss -1489.86240  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 449  trainloss -1325.32423  validloss -1346.86137±0.00000  bestvalidloss -1489.86240  last_update 4\n",
      "train: iter 450  trainloss -1319.47299  validloss -1403.42768±0.00000  bestvalidloss -1489.86240  last_update 5\n",
      "train: iter 451  trainloss -1385.65086  validloss -1387.79487±0.00000  bestvalidloss -1489.86240  last_update 6\n",
      "train: iter 452  trainloss -1386.08577  validloss -1459.45963±0.00000  bestvalidloss -1489.86240  last_update 7\n",
      "train: iter 453  trainloss -1312.26211  validloss -1277.10598±0.00000  bestvalidloss -1489.86240  last_update 8\n",
      "train: iter 454  trainloss -1453.17927  validloss -1492.88172±0.00000  bestvalidloss -1492.88172  last_update 0\n",
      "train: iter 455  trainloss -1449.35823  validloss -1448.99738±0.00000  bestvalidloss -1492.88172  last_update 1\n",
      "train: iter 456  trainloss -1333.67553  validloss -1353.26472±0.00000  bestvalidloss -1492.88172  last_update 2\n",
      "train: iter 457  trainloss -1425.13609  validloss -1478.09277±0.00000  bestvalidloss -1492.88172  last_update 3\n",
      "train: iter 458  trainloss -1293.77453  validloss -1369.95317±0.00000  bestvalidloss -1492.88172  last_update 4\n",
      "train: iter 459  trainloss -1388.50577  validloss -1344.51992±0.00000  bestvalidloss -1492.88172  last_update 5\n",
      "train: iter 460  trainloss -1406.84883  validloss -1479.77947±0.00000  bestvalidloss -1492.88172  last_update 6\n",
      "train: iter 461  trainloss -1379.69370  validloss -1482.44124±0.00000  bestvalidloss -1492.88172  last_update 7\n",
      "train: iter 462  trainloss -1390.70736  validloss -1445.02140±0.00000  bestvalidloss -1492.88172  last_update 8\n",
      "train: iter 463  trainloss -1292.16499  validloss -1450.67779±0.00000  bestvalidloss -1492.88172  last_update 9\n",
      "train: iter 464  trainloss -1377.94652  validloss -1440.95147±0.00000  bestvalidloss -1492.88172  last_update 10\n",
      "train: iter 465  trainloss -1367.72294  validloss -1466.64495±0.00000  bestvalidloss -1492.88172  last_update 11\n",
      "train: iter 466  trainloss -1409.47151  validloss -1421.52556±0.00000  bestvalidloss -1492.88172  last_update 12\n",
      "train: iter 467  trainloss -1456.10547  validloss -1455.93519±0.00000  bestvalidloss -1492.88172  last_update 13\n",
      "train: iter 468  trainloss -1317.63346  validloss -1400.76127±0.00000  bestvalidloss -1492.88172  last_update 14\n",
      "train: iter 469  trainloss -1274.66236  validloss -1342.79256±0.00000  bestvalidloss -1492.88172  last_update 15\n",
      "train: iter 470  trainloss -1412.56488  validloss -1432.00386±0.00000  bestvalidloss -1492.88172  last_update 16\n",
      "train: iter 471  trainloss -1255.68914  validloss -1207.51407±0.00000  bestvalidloss -1492.88172  last_update 17\n",
      "train: iter 472  trainloss -1389.48120  validloss -1331.99854±0.00000  bestvalidloss -1492.88172  last_update 18\n",
      "train: iter 473  trainloss -1323.73421  validloss -1455.64797±0.00000  bestvalidloss -1492.88172  last_update 19\n",
      "train: iter 474  trainloss -1317.16433  validloss -1314.23440±0.00000  bestvalidloss -1492.88172  last_update 20\n",
      "train: iter 475  trainloss -1430.14950  validloss -1418.48524±0.00000  bestvalidloss -1492.88172  last_update 21\n",
      "train: iter 476  trainloss -1176.13162  validloss -1469.42368±0.00000  bestvalidloss -1492.88172  last_update 22\n",
      "train: iter 477  trainloss -1295.30450  validloss -1245.26671±0.00000  bestvalidloss -1492.88172  last_update 23\n",
      "train: iter 478  trainloss -1278.54425  validloss -1437.69387±0.00000  bestvalidloss -1492.88172  last_update 24\n",
      "train: iter 479  trainloss -1368.42652  validloss -1347.27411±0.00000  bestvalidloss -1492.88172  last_update 25\n",
      "train: iter 480  trainloss -1356.59549  validloss -1376.27560±0.00000  bestvalidloss -1492.88172  last_update 26\n",
      "train: iter 481  trainloss -1296.04336  validloss -1419.05641±0.00000  bestvalidloss -1492.88172  last_update 27\n",
      "train: iter 482  trainloss -1372.83872  validloss -1367.75468±0.00000  bestvalidloss -1492.88172  last_update 28\n",
      "train: iter 483  trainloss -1248.54712  validloss -1379.68513±0.00000  bestvalidloss -1492.88172  last_update 29\n",
      "train: iter 484  trainloss -1303.19212  validloss -1373.32023±0.00000  bestvalidloss -1492.88172  last_update 30\n",
      "train: iter 485  trainloss -1422.46269  validloss -1345.17113±0.00000  bestvalidloss -1492.88172  last_update 31\n",
      "train: iter 486  trainloss -1421.64661  validloss -1489.57566±0.00000  bestvalidloss -1492.88172  last_update 32\n",
      "train: iter 487  trainloss -1448.26209  validloss -1411.12089±0.00000  bestvalidloss -1492.88172  last_update 33\n",
      "train: iter 488  trainloss -1185.97064  validloss -1461.57520±0.00000  bestvalidloss -1492.88172  last_update 34\n",
      "train: iter 489  trainloss -1370.83183  validloss -1290.50340±0.00000  bestvalidloss -1492.88172  last_update 35\n",
      "train: iter 490  trainloss -1455.66108  validloss -1443.98584±0.00000  bestvalidloss -1492.88172  last_update 36\n",
      "train: iter 491  trainloss -1437.24082  validloss -1484.56721±0.00000  bestvalidloss -1492.88172  last_update 37\n",
      "train: iter 492  trainloss -1438.47196  validloss -1364.46359±0.00000  bestvalidloss -1492.88172  last_update 38\n",
      "train: iter 493  trainloss -1362.55852  validloss -1501.07908±0.00000  bestvalidloss -1501.07908  last_update 0\n",
      "train: iter 494  trainloss -1408.14004  validloss -1425.88232±0.00000  bestvalidloss -1501.07908  last_update 1\n",
      "train: iter 495  trainloss -1457.00784  validloss -1500.88520±0.00000  bestvalidloss -1501.07908  last_update 2\n",
      "train: iter 496  trainloss -1419.67465  validloss -1481.67156±0.00000  bestvalidloss -1501.07908  last_update 3\n",
      "train: iter 497  trainloss -1386.98578  validloss -1416.56449±0.00000  bestvalidloss -1501.07908  last_update 4\n",
      "train: iter 498  trainloss -1465.13333  validloss -1501.88539±0.00000  bestvalidloss -1501.88539  last_update 0\n",
      "train: iter 499  trainloss -1333.81130  validloss -1479.72689±0.00000  bestvalidloss -1501.88539  last_update 1\n",
      "train: iter 500  trainloss -1415.40824  validloss -1416.16717±0.00000  bestvalidloss -1501.88539  last_update 2\n",
      "train: iter 501  trainloss -1443.90631  validloss -1446.36252±0.00000  bestvalidloss -1501.88539  last_update 3\n",
      "train: iter 502  trainloss -1417.42411  validloss -1459.59386±0.00000  bestvalidloss -1501.88539  last_update 4\n",
      "train: iter 503  trainloss -1367.20080  validloss -1293.99239±0.00000  bestvalidloss -1501.88539  last_update 5\n",
      "train: iter 504  trainloss -1350.18860  validloss -1460.85692±0.00000  bestvalidloss -1501.88539  last_update 6\n",
      "train: iter 505  trainloss -1426.97492  validloss -1475.30671±0.00000  bestvalidloss -1501.88539  last_update 7\n",
      "train: iter 506  trainloss -1446.36479  validloss -1345.78212±0.00000  bestvalidloss -1501.88539  last_update 8\n",
      "train: iter 507  trainloss -1271.92619  validloss -1521.43948±0.00000  bestvalidloss -1521.43948  last_update 0\n",
      "train: iter 508  trainloss -1099.08947  validloss -1042.75102±0.00000  bestvalidloss -1521.43948  last_update 1\n",
      "train: iter 509  trainloss -1342.27285  validloss -1304.68379±0.00000  bestvalidloss -1521.43948  last_update 2\n",
      "train: iter 510  trainloss -1343.39961  validloss -1463.18701±0.00000  bestvalidloss -1521.43948  last_update 3\n",
      "train: iter 511  trainloss -1148.19159  validloss -1414.63231±0.00000  bestvalidloss -1521.43948  last_update 4\n",
      "train: iter 512  trainloss -1314.80141  validloss -1225.49100±0.00000  bestvalidloss -1521.43948  last_update 5\n",
      "train: iter 513  trainloss -1364.43665  validloss -1388.19162±0.00000  bestvalidloss -1521.43948  last_update 6\n",
      "train: iter 514  trainloss -1379.17573  validloss -1346.88397±0.00000  bestvalidloss -1521.43948  last_update 7\n",
      "train: iter 515  trainloss -1428.93896  validloss -1466.89059±0.00000  bestvalidloss -1521.43948  last_update 8\n",
      "train: iter 516  trainloss -1440.14076  validloss -1471.11355±0.00000  bestvalidloss -1521.43948  last_update 9\n",
      "train: iter 517  trainloss -1433.96872  validloss -1499.13549±0.00000  bestvalidloss -1521.43948  last_update 10\n",
      "train: iter 518  trainloss -1388.72313  validloss -1375.82304±0.00000  bestvalidloss -1521.43948  last_update 11\n",
      "train: iter 519  trainloss -1467.35425  validloss -1399.92547±0.00000  bestvalidloss -1521.43948  last_update 12\n",
      "train: iter 520  trainloss -1424.97692  validloss -1468.17276±0.00000  bestvalidloss -1521.43948  last_update 13\n",
      "train: iter 521  trainloss -1451.97844  validloss -1480.67942±0.00000  bestvalidloss -1521.43948  last_update 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 522  trainloss -1268.87665  validloss -650.21060±0.00000  bestvalidloss -1521.43948  last_update 15\n",
      "train: iter 523  trainloss -1355.37078  validloss -1413.50856±0.00000  bestvalidloss -1521.43948  last_update 16\n",
      "train: iter 524  trainloss -1323.33766  validloss -1399.40332±0.00000  bestvalidloss -1521.43948  last_update 17\n",
      "train: iter 525  trainloss -1463.21411  validloss -1489.76730±0.00000  bestvalidloss -1521.43948  last_update 18\n",
      "train: iter 526  trainloss -1469.39726  validloss -1508.48570±0.00000  bestvalidloss -1521.43948  last_update 19\n",
      "train: iter 527  trainloss -1368.15441  validloss -1466.46555±0.00000  bestvalidloss -1521.43948  last_update 20\n",
      "train: iter 528  trainloss -1457.73980  validloss -1486.22678±0.00000  bestvalidloss -1521.43948  last_update 21\n",
      "train: iter 529  trainloss -1441.20953  validloss -1520.64729±0.00000  bestvalidloss -1521.43948  last_update 22\n",
      "train: iter 530  trainloss -1420.78604  validloss -1461.98731±0.00000  bestvalidloss -1521.43948  last_update 23\n",
      "train: iter 531  trainloss -1443.59701  validloss -1390.96769±0.00000  bestvalidloss -1521.43948  last_update 24\n",
      "train: iter 532  trainloss -1364.57652  validloss -1326.85803±0.00000  bestvalidloss -1521.43948  last_update 25\n",
      "train: iter 533  trainloss -1469.76110  validloss -1429.17111±0.00000  bestvalidloss -1521.43948  last_update 26\n",
      "train: iter 534  trainloss -1455.39718  validloss -1506.29482±0.00000  bestvalidloss -1521.43948  last_update 27\n",
      "train: iter 535  trainloss -1314.29743  validloss -1321.08915±0.00000  bestvalidloss -1521.43948  last_update 28\n",
      "train: iter 536  trainloss -1410.05940  validloss -1433.24163±0.00000  bestvalidloss -1521.43948  last_update 29\n",
      "train: iter 537  trainloss -1471.70239  validloss -1448.60220±0.00000  bestvalidloss -1521.43948  last_update 30\n",
      "train: iter 538  trainloss -1368.42626  validloss -1524.22276±0.00000  bestvalidloss -1524.22276  last_update 0\n",
      "train: iter 539  trainloss -1410.49787  validloss -1399.93048±0.00000  bestvalidloss -1524.22276  last_update 1\n",
      "train: iter 540  trainloss -1439.29644  validloss -1469.15429±0.00000  bestvalidloss -1524.22276  last_update 2\n",
      "train: iter 541  trainloss -1436.54756  validloss -1505.05181±0.00000  bestvalidloss -1524.22276  last_update 3\n",
      "train: iter 542  trainloss -1366.18336  validloss -1376.76532±0.00000  bestvalidloss -1524.22276  last_update 4\n",
      "train: iter 543  trainloss -1451.66589  validloss -1463.77960±0.00000  bestvalidloss -1524.22276  last_update 5\n",
      "train: iter 544  trainloss -1469.19077  validloss -1487.93824±0.00000  bestvalidloss -1524.22276  last_update 6\n",
      "train: iter 545  trainloss -1431.68175  validloss -1484.17495±0.00000  bestvalidloss -1524.22276  last_update 7\n",
      "train: iter 546  trainloss -1170.44375  validloss -1518.43488±0.00000  bestvalidloss -1524.22276  last_update 8\n",
      "train: iter 547  trainloss -1348.27773  validloss -1257.72969±0.00000  bestvalidloss -1524.22276  last_update 9\n",
      "train: iter 548  trainloss -1401.35941  validloss -1453.44242±0.00000  bestvalidloss -1524.22276  last_update 10\n",
      "train: iter 549  trainloss -1447.07337  validloss -1493.34688±0.00000  bestvalidloss -1524.22276  last_update 11\n",
      "train: iter 550  trainloss -1465.75460  validloss -1504.54590±0.00000  bestvalidloss -1524.22276  last_update 12\n",
      "train: iter 551  trainloss -1391.20996  validloss -1466.65290±0.00000  bestvalidloss -1524.22276  last_update 13\n",
      "train: iter 552  trainloss -1392.02125  validloss -1394.34118±0.00000  bestvalidloss -1524.22276  last_update 14\n",
      "train: iter 553  trainloss -1461.64133  validloss -1370.87723±0.00000  bestvalidloss -1524.22276  last_update 15\n",
      "train: iter 554  trainloss -1451.49664  validloss -1505.00260±0.00000  bestvalidloss -1524.22276  last_update 16\n",
      "train: iter 555  trainloss -1429.81901  validloss -1466.54557±0.00000  bestvalidloss -1524.22276  last_update 17\n",
      "train: iter 556  trainloss -1460.22102  validloss -1483.85617±0.00000  bestvalidloss -1524.22276  last_update 18\n",
      "train: iter 557  trainloss -1424.51201  validloss -1482.96281±0.00000  bestvalidloss -1524.22276  last_update 19\n",
      "train: iter 558  trainloss -1355.64309  validloss -1361.77141±0.00000  bestvalidloss -1524.22276  last_update 20\n",
      "train: iter 559  trainloss -1336.90613  validloss -1260.97142±0.00000  bestvalidloss -1524.22276  last_update 21\n",
      "train: iter 560  trainloss -1469.33078  validloss -1440.72840±0.00000  bestvalidloss -1524.22276  last_update 22\n",
      "train: iter 561  trainloss -1449.82920  validloss -1527.49484±0.00000  bestvalidloss -1527.49484  last_update 0\n",
      "train: iter 562  trainloss -1444.58229  validloss -1523.50596±0.00000  bestvalidloss -1527.49484  last_update 1\n",
      "train: iter 563  trainloss -1414.31127  validloss -1297.70484±0.00000  bestvalidloss -1527.49484  last_update 2\n",
      "train: iter 564  trainloss -1404.30817  validloss -1466.95623±0.00000  bestvalidloss -1527.49484  last_update 3\n",
      "train: iter 565  trainloss -1427.32363  validloss -1367.24605±0.00000  bestvalidloss -1527.49484  last_update 4\n",
      "train: iter 566  trainloss -1487.68512  validloss -1520.24709±0.00000  bestvalidloss -1527.49484  last_update 5\n",
      "train: iter 567  trainloss -1421.52380  validloss -1493.21739±0.00000  bestvalidloss -1527.49484  last_update 6\n",
      "train: iter 568  trainloss -1369.45532  validloss -1322.00719±0.00000  bestvalidloss -1527.49484  last_update 7\n",
      "train: iter 569  trainloss -1427.10301  validloss -1155.27053±0.00000  bestvalidloss -1527.49484  last_update 8\n",
      "train: iter 570  trainloss -1479.46456  validloss -1465.57079±0.00000  bestvalidloss -1527.49484  last_update 9\n",
      "train: iter 571  trainloss -1359.77512  validloss -1242.39730±0.00000  bestvalidloss -1527.49484  last_update 10\n",
      "train: iter 572  trainloss -1464.19971  validloss -1474.09778±0.00000  bestvalidloss -1527.49484  last_update 11\n",
      "train: iter 573  trainloss -1479.38641  validloss -1523.26269±0.00000  bestvalidloss -1527.49484  last_update 12\n",
      "train: iter 574  trainloss -1435.19855  validloss -1476.60664±0.00000  bestvalidloss -1527.49484  last_update 13\n",
      "train: iter 575  trainloss -1389.26412  validloss -1413.12837±0.00000  bestvalidloss -1527.49484  last_update 14\n",
      "train: iter 576  trainloss -1507.89526  validloss -1521.59336±0.00000  bestvalidloss -1527.49484  last_update 15\n",
      "train: iter 577  trainloss -1306.64467  validloss -1511.07179±0.00000  bestvalidloss -1527.49484  last_update 16\n",
      "train: iter 578  trainloss -1438.69096  validloss -1480.18015±0.00000  bestvalidloss -1527.49484  last_update 17\n",
      "train: iter 579  trainloss -1371.06772  validloss -1489.45084±0.00000  bestvalidloss -1527.49484  last_update 18\n",
      "train: iter 580  trainloss -1375.10581  validloss -1238.86849±0.00000  bestvalidloss -1527.49484  last_update 19\n",
      "train: iter 581  trainloss -1435.61440  validloss -1484.15079±0.00000  bestvalidloss -1527.49484  last_update 20\n",
      "train: iter 582  trainloss -1467.27992  validloss -1460.63280±0.00000  bestvalidloss -1527.49484  last_update 21\n",
      "train: iter 583  trainloss -1489.56135  validloss -1543.62395±0.00000  bestvalidloss -1543.62395  last_update 0\n",
      "train: iter 584  trainloss -1382.09294  validloss -1525.89068±0.00000  bestvalidloss -1543.62395  last_update 1\n",
      "train: iter 585  trainloss -1369.65813  validloss -1215.11109±0.00000  bestvalidloss -1543.62395  last_update 2\n",
      "train: iter 586  trainloss -1418.30858  validloss -1506.46924±0.00000  bestvalidloss -1543.62395  last_update 3\n",
      "train: iter 587  trainloss -1481.26037  validloss -1486.97847±0.00000  bestvalidloss -1543.62395  last_update 4\n",
      "train: iter 588  trainloss -1425.47560  validloss -1470.32101±0.00000  bestvalidloss -1543.62395  last_update 5\n",
      "train: iter 589  trainloss -1220.81106  validloss -1415.56288±0.00000  bestvalidloss -1543.62395  last_update 6\n",
      "train: iter 590  trainloss -1361.40971  validloss -981.66577±0.00000  bestvalidloss -1543.62395  last_update 7\n",
      "train: iter 591  trainloss -1500.43287  validloss -1523.16048±0.00000  bestvalidloss -1543.62395  last_update 8\n",
      "train: iter 592  trainloss -1323.67342  validloss -1467.11827±0.00000  bestvalidloss -1543.62395  last_update 9\n",
      "train: iter 593  trainloss -1457.21338  validloss -1466.38101±0.00000  bestvalidloss -1543.62395  last_update 10\n",
      "train: iter 594  trainloss -1458.71510  validloss -1360.18106±0.00000  bestvalidloss -1543.62395  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 595  trainloss -1019.56594  validloss -1470.91873±0.00000  bestvalidloss -1543.62395  last_update 12\n",
      "train: iter 596  trainloss -953.36579  validloss -614.40741±0.00000  bestvalidloss -1543.62395  last_update 13\n",
      "train: iter 597  trainloss -1292.37616  validloss -1282.16000±0.00000  bestvalidloss -1543.62395  last_update 14\n",
      "train: iter 598  trainloss -1317.59754  validloss -1430.92459±0.00000  bestvalidloss -1543.62395  last_update 15\n",
      "train: iter 599  trainloss -1206.77447  validloss -1414.93863±0.00000  bestvalidloss -1543.62395  last_update 16\n",
      "train: iter 600  trainloss -1383.92917  validloss -1353.89675±0.00000  bestvalidloss -1543.62395  last_update 17\n",
      "train: iter 601  trainloss -1434.41302  validloss -1413.24291±0.00000  bestvalidloss -1543.62395  last_update 18\n",
      "train: iter 602  trainloss -1414.25092  validloss -1473.26180±0.00000  bestvalidloss -1543.62395  last_update 19\n",
      "train: iter 603  trainloss -1115.93912  validloss -1425.35293±0.00000  bestvalidloss -1543.62395  last_update 20\n",
      "train: iter 604  trainloss -1428.29821  validloss -1393.99894±0.00000  bestvalidloss -1543.62395  last_update 21\n",
      "train: iter 605  trainloss -1487.85871  validloss -1509.25541±0.00000  bestvalidloss -1543.62395  last_update 22\n",
      "train: iter 606  trainloss -1437.50491  validloss -1522.00133±0.00000  bestvalidloss -1543.62395  last_update 23\n",
      "train: iter 607  trainloss -1455.29164  validloss -1406.17249±0.00000  bestvalidloss -1543.62395  last_update 24\n",
      "train: iter 608  trainloss -1474.52525  validloss -1508.44079±0.00000  bestvalidloss -1543.62395  last_update 25\n",
      "train: iter 609  trainloss -1438.24484  validloss -1457.10091±0.00000  bestvalidloss -1543.62395  last_update 26\n",
      "train: iter 610  trainloss -1501.13001  validloss -1518.38756±0.00000  bestvalidloss -1543.62395  last_update 27\n",
      "train: iter 611  trainloss -1489.68719  validloss -1500.27563±0.00000  bestvalidloss -1543.62395  last_update 28\n",
      "train: iter 612  trainloss -1347.53234  validloss -1472.28213±0.00000  bestvalidloss -1543.62395  last_update 29\n",
      "train: iter 613  trainloss -1399.63345  validloss -1323.27004±0.00000  bestvalidloss -1543.62395  last_update 30\n",
      "train: iter 614  trainloss -1482.68711  validloss -1495.33000±0.00000  bestvalidloss -1543.62395  last_update 31\n",
      "train: iter 615  trainloss -1461.79291  validloss -1498.53255±0.00000  bestvalidloss -1543.62395  last_update 32\n",
      "train: iter 616  trainloss -1421.01536  validloss -1482.02934±0.00000  bestvalidloss -1543.62395  last_update 33\n",
      "train: iter 617  trainloss -1475.16741  validloss -1408.74963±0.00000  bestvalidloss -1543.62395  last_update 34\n",
      "train: iter 618  trainloss -1512.94948  validloss -1530.08769±0.00000  bestvalidloss -1543.62395  last_update 35\n",
      "train: iter 619  trainloss -1318.28366  validloss -1410.05013±0.00000  bestvalidloss -1543.62395  last_update 36\n",
      "train: iter 620  trainloss -1406.01858  validloss -1284.19956±0.00000  bestvalidloss -1543.62395  last_update 37\n",
      "train: iter 621  trainloss -1476.18596  validloss -1479.60447±0.00000  bestvalidloss -1543.62395  last_update 38\n",
      "train: iter 622  trainloss -1460.93439  validloss -1508.51038±0.00000  bestvalidloss -1543.62395  last_update 39\n",
      "train: iter 623  trainloss -1457.76988  validloss -1313.22545±0.00000  bestvalidloss -1543.62395  last_update 40\n",
      "train: iter 624  trainloss -1499.46368  validloss -1508.59373±0.00000  bestvalidloss -1543.62395  last_update 41\n",
      "train: iter 625  trainloss -1515.07815  validloss -1506.07901±0.00000  bestvalidloss -1543.62395  last_update 42\n",
      "train: iter 626  trainloss -1367.69844  validloss -1550.56754±0.00000  bestvalidloss -1550.56754  last_update 0\n",
      "train: iter 627  trainloss -1446.98477  validloss -1270.87194±0.00000  bestvalidloss -1550.56754  last_update 1\n",
      "train: iter 628  trainloss -1472.84865  validloss -1485.96353±0.00000  bestvalidloss -1550.56754  last_update 2\n",
      "train: iter 629  trainloss -1496.40431  validloss -1536.93802±0.00000  bestvalidloss -1550.56754  last_update 3\n",
      "train: iter 630  trainloss -1472.69380  validloss -1493.84540±0.00000  bestvalidloss -1550.56754  last_update 4\n",
      "train: iter 631  trainloss -1397.33749  validloss -1480.58813±0.00000  bestvalidloss -1550.56754  last_update 5\n",
      "train: iter 632  trainloss -1498.03444  validloss -1477.32810±0.00000  bestvalidloss -1550.56754  last_update 6\n",
      "train: iter 633  trainloss -1422.35378  validloss -1559.94592±0.00000  bestvalidloss -1559.94592  last_update 0\n",
      "train: iter 634  trainloss -1401.18555  validloss -1345.23007±0.00000  bestvalidloss -1559.94592  last_update 1\n",
      "train: iter 635  trainloss -1484.79386  validloss -1325.94537±0.00000  bestvalidloss -1559.94592  last_update 2\n",
      "train: iter 636  trainloss -1362.07327  validloss -1404.97608±0.00000  bestvalidloss -1559.94592  last_update 3\n",
      "train: iter 637  trainloss -1423.64763  validloss -1372.63770±0.00000  bestvalidloss -1559.94592  last_update 4\n",
      "train: iter 638  trainloss -1500.77079  validloss -1538.20072±0.00000  bestvalidloss -1559.94592  last_update 5\n",
      "train: iter 639  trainloss -1513.08501  validloss -1518.42269±0.00000  bestvalidloss -1559.94592  last_update 6\n",
      "train: iter 640  trainloss -1393.69153  validloss -1431.67782±0.00000  bestvalidloss -1559.94592  last_update 7\n",
      "train: iter 641  trainloss -1414.33925  validloss -1435.15044±0.00000  bestvalidloss -1559.94592  last_update 8\n",
      "train: iter 642  trainloss -1517.79194  validloss -1149.62801±0.00000  bestvalidloss -1559.94592  last_update 9\n",
      "train: iter 643  trainloss -1520.01338  validloss -1568.35467±0.00000  bestvalidloss -1568.35467  last_update 0\n",
      "train: iter 644  trainloss -1449.69625  validloss -1496.19359±0.00000  bestvalidloss -1568.35467  last_update 1\n",
      "train: iter 645  trainloss -1488.30077  validloss -1460.68183±0.00000  bestvalidloss -1568.35467  last_update 2\n",
      "train: iter 646  trainloss -1446.96539  validloss -1522.14653±0.00000  bestvalidloss -1568.35467  last_update 3\n",
      "train: iter 647  trainloss -1460.13513  validloss -1557.48316±0.00000  bestvalidloss -1568.35467  last_update 4\n",
      "train: iter 648  trainloss -1443.15525  validloss -1438.41871±0.00000  bestvalidloss -1568.35467  last_update 5\n",
      "train: iter 649  trainloss -1436.27263  validloss -1396.87172±0.00000  bestvalidloss -1568.35467  last_update 6\n",
      "train: iter 650  trainloss -1435.24300  validloss -1481.49261±0.00000  bestvalidloss -1568.35467  last_update 7\n",
      "train: iter 651  trainloss -1520.22046  validloss -1542.33868±0.00000  bestvalidloss -1568.35467  last_update 8\n",
      "train: iter 652  trainloss -1530.22625  validloss -1560.95249±0.00000  bestvalidloss -1568.35467  last_update 9\n",
      "train: iter 653  trainloss -1267.94652  validloss -1415.88979±0.00000  bestvalidloss -1568.35467  last_update 10\n",
      "train: iter 654  trainloss -1454.53712  validloss -1464.64601±0.00000  bestvalidloss -1568.35467  last_update 11\n",
      "train: iter 655  trainloss -1495.82046  validloss -1460.18834±0.00000  bestvalidloss -1568.35467  last_update 12\n",
      "train: iter 656  trainloss -1520.38296  validloss -1539.08135±0.00000  bestvalidloss -1568.35467  last_update 13\n",
      "train: iter 657  trainloss -1372.58808  validloss -1381.58600±0.00000  bestvalidloss -1568.35467  last_update 14\n",
      "train: iter 658  trainloss -1481.54343  validloss -1437.51025±0.00000  bestvalidloss -1568.35467  last_update 15\n",
      "train: iter 659  trainloss -1521.36612  validloss -1546.46456±0.00000  bestvalidloss -1568.35467  last_update 16\n",
      "train: iter 660  trainloss -1531.17018  validloss -1554.38333±0.00000  bestvalidloss -1568.35467  last_update 17\n",
      "train: iter 661  trainloss -1245.01882  validloss -1478.40041±0.00000  bestvalidloss -1568.35467  last_update 18\n",
      "train: iter 662  trainloss -1394.35655  validloss -1338.44449±0.00000  bestvalidloss -1568.35467  last_update 19\n",
      "train: iter 663  trainloss -1491.97341  validloss -1503.70338±0.00000  bestvalidloss -1568.35467  last_update 20\n",
      "train: iter 664  trainloss -1507.69032  validloss -1507.46004±0.00000  bestvalidloss -1568.35467  last_update 21\n",
      "train: iter 665  trainloss -1476.59125  validloss -1539.88980±0.00000  bestvalidloss -1568.35467  last_update 22\n",
      "train: iter 666  trainloss -1471.93249  validloss -1425.47648±0.00000  bestvalidloss -1568.35467  last_update 23\n",
      "train: iter 667  trainloss -1438.09801  validloss -1463.31477±0.00000  bestvalidloss -1568.35467  last_update 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 668  trainloss -1484.27321  validloss -1289.38046±0.00000  bestvalidloss -1568.35467  last_update 25\n",
      "train: iter 669  trainloss -1468.34561  validloss -1556.43698±0.00000  bestvalidloss -1568.35467  last_update 26\n",
      "train: iter 670  trainloss -1334.75386  validloss -1023.28665±0.00000  bestvalidloss -1568.35467  last_update 27\n",
      "train: iter 671  trainloss -1445.25394  validloss -1496.51585±0.00000  bestvalidloss -1568.35467  last_update 28\n",
      "train: iter 672  trainloss -1494.27113  validloss -1448.27812±0.00000  bestvalidloss -1568.35467  last_update 29\n",
      "train: iter 673  trainloss -1468.49713  validloss -1484.36902±0.00000  bestvalidloss -1568.35467  last_update 30\n",
      "train: iter 674  trainloss -1519.71885  validloss -1499.80654±0.00000  bestvalidloss -1568.35467  last_update 31\n",
      "train: iter 675  trainloss -1529.24093  validloss -1577.48085±0.00000  bestvalidloss -1577.48085  last_update 0\n",
      "train: iter 676  trainloss -1354.73288  validloss -1368.66902±0.00000  bestvalidloss -1577.48085  last_update 1\n",
      "train: iter 677  trainloss -1377.15823  validloss -1250.04015±0.00000  bestvalidloss -1577.48085  last_update 2\n",
      "train: iter 678  trainloss -1396.29985  validloss -1431.73036±0.00000  bestvalidloss -1577.48085  last_update 3\n",
      "train: iter 679  trainloss -1428.76714  validloss -1460.96500±0.00000  bestvalidloss -1577.48085  last_update 4\n",
      "train: iter 680  trainloss -1370.16385  validloss -1490.29593±0.00000  bestvalidloss -1577.48085  last_update 5\n",
      "train: iter 681  trainloss -1340.71385  validloss -1271.41971±0.00000  bestvalidloss -1577.48085  last_update 6\n",
      "train: iter 682  trainloss -1460.26973  validloss -1389.31331±0.00000  bestvalidloss -1577.48085  last_update 7\n",
      "train: iter 683  trainloss -1511.44326  validloss -1537.43492±0.00000  bestvalidloss -1577.48085  last_update 8\n",
      "train: iter 684  trainloss -1461.35311  validloss -1548.09739±0.00000  bestvalidloss -1577.48085  last_update 9\n",
      "train: iter 685  trainloss -1477.60775  validloss -1490.45617±0.00000  bestvalidloss -1577.48085  last_update 10\n",
      "train: iter 686  trainloss -1447.84210  validloss -1374.17994±0.00000  bestvalidloss -1577.48085  last_update 11\n",
      "train: iter 687  trainloss -1447.70740  validloss -1173.60334±0.00000  bestvalidloss -1577.48085  last_update 12\n",
      "train: iter 688  trainloss -1517.32333  validloss -1524.90759±0.00000  bestvalidloss -1577.48085  last_update 13\n",
      "train: iter 689  trainloss -1454.56373  validloss -1525.90032±0.00000  bestvalidloss -1577.48085  last_update 14\n",
      "train: iter 690  trainloss -1510.58762  validloss -1460.74125±0.00000  bestvalidloss -1577.48085  last_update 15\n",
      "train: iter 691  trainloss -1389.41742  validloss -1529.02594±0.00000  bestvalidloss -1577.48085  last_update 16\n",
      "train: iter 692  trainloss -1402.33493  validloss -1361.59750±0.00000  bestvalidloss -1577.48085  last_update 17\n",
      "train: iter 693  trainloss -1508.47572  validloss -1485.95019±0.00000  bestvalidloss -1577.48085  last_update 18\n",
      "train: iter 694  trainloss -1490.89570  validloss -1509.42876±0.00000  bestvalidloss -1577.48085  last_update 19\n",
      "train: iter 695  trainloss -1516.04567  validloss -1469.44124±0.00000  bestvalidloss -1577.48085  last_update 20\n",
      "train: iter 696  trainloss -1549.48432  validloss -1553.28940±0.00000  bestvalidloss -1577.48085  last_update 21\n",
      "train: iter 697  trainloss -1363.02664  validloss -1582.54802±0.00000  bestvalidloss -1582.54802  last_update 0\n",
      "train: iter 698  trainloss -1486.04883  validloss -1355.34773±0.00000  bestvalidloss -1582.54802  last_update 1\n",
      "train: iter 699  trainloss -1543.82933  validloss -1485.26732±0.00000  bestvalidloss -1582.54802  last_update 2\n",
      "train: iter 700  trainloss -1390.62617  validloss -1546.05464±0.00000  bestvalidloss -1582.54802  last_update 3\n",
      "train: iter 701  trainloss -1410.35972  validloss -1425.43476±0.00000  bestvalidloss -1582.54802  last_update 4\n",
      "train: iter 702  trainloss -1519.68042  validloss -1530.05497±0.00000  bestvalidloss -1582.54802  last_update 5\n",
      "train: iter 703  trainloss -1298.34344  validloss -1468.28790±0.00000  bestvalidloss -1582.54802  last_update 6\n",
      "train: iter 704  trainloss -1490.14000  validloss -1493.33243±0.00000  bestvalidloss -1582.54802  last_update 7\n",
      "train: iter 705  trainloss -1476.40174  validloss -1517.18937±0.00000  bestvalidloss -1582.54802  last_update 8\n",
      "train: iter 706  trainloss -1512.86855  validloss -1503.67962±0.00000  bestvalidloss -1582.54802  last_update 9\n",
      "train: iter 707  trainloss -1456.20567  validloss -1477.74044±0.00000  bestvalidloss -1582.54802  last_update 10\n",
      "train: iter 708  trainloss -1539.59373  validloss -1534.60774±0.00000  bestvalidloss -1582.54802  last_update 11\n",
      "train: iter 709  trainloss -1532.20711  validloss -1500.66726±0.00000  bestvalidloss -1582.54802  last_update 12\n",
      "train: iter 710  trainloss -1493.87232  validloss -1482.97131±0.00000  bestvalidloss -1582.54802  last_update 13\n",
      "train: iter 711  trainloss -1556.03321  validloss -1540.75359±0.00000  bestvalidloss -1582.54802  last_update 14\n",
      "train: iter 712  trainloss -1515.12902  validloss -1535.27138±0.00000  bestvalidloss -1582.54802  last_update 15\n",
      "train: iter 713  trainloss -1473.86813  validloss -1492.69445±0.00000  bestvalidloss -1582.54802  last_update 16\n",
      "train: iter 714  trainloss -1476.97028  validloss -1522.06386±0.00000  bestvalidloss -1582.54802  last_update 17\n",
      "train: iter 715  trainloss -1520.51344  validloss -1488.14293±0.00000  bestvalidloss -1582.54802  last_update 18\n",
      "train: iter 716  trainloss -1498.35526  validloss -1514.64489±0.00000  bestvalidloss -1582.54802  last_update 19\n",
      "train: iter 717  trainloss -1523.47018  validloss -1441.84476±0.00000  bestvalidloss -1582.54802  last_update 20\n",
      "train: iter 718  trainloss -1453.69156  validloss -1578.17522±0.00000  bestvalidloss -1582.54802  last_update 21\n",
      "train: iter 719  trainloss -1451.08111  validloss -1499.16208±0.00000  bestvalidloss -1582.54802  last_update 22\n",
      "train: iter 720  trainloss -1531.28987  validloss -1531.66071±0.00000  bestvalidloss -1582.54802  last_update 23\n",
      "train: iter 721  trainloss -1501.01784  validloss -1556.06368±0.00000  bestvalidloss -1582.54802  last_update 24\n",
      "train: iter 722  trainloss -1507.13341  validloss -1462.94665±0.00000  bestvalidloss -1582.54802  last_update 25\n",
      "train: iter 723  trainloss -1489.74728  validloss -1426.04664±0.00000  bestvalidloss -1582.54802  last_update 26\n",
      "train: iter 724  trainloss -1545.16018  validloss -1540.68214±0.00000  bestvalidloss -1582.54802  last_update 27\n",
      "train: iter 725  trainloss -1459.68729  validloss -1547.71428±0.00000  bestvalidloss -1582.54802  last_update 28\n",
      "train: iter 726  trainloss -1461.83755  validloss -1415.58035±0.00000  bestvalidloss -1582.54802  last_update 29\n",
      "train: iter 727  trainloss -1519.52872  validloss -1556.28922±0.00000  bestvalidloss -1582.54802  last_update 30\n",
      "train: iter 728  trainloss -1370.22811  validloss -1511.90985±0.00000  bestvalidloss -1582.54802  last_update 31\n",
      "train: iter 729  trainloss -1509.92712  validloss -1439.53436±0.00000  bestvalidloss -1582.54802  last_update 32\n",
      "train: iter 730  trainloss -1485.03459  validloss -1542.01387±0.00000  bestvalidloss -1582.54802  last_update 33\n",
      "train: iter 731  trainloss -1479.11712  validloss -1518.27674±0.00000  bestvalidloss -1582.54802  last_update 34\n",
      "train: iter 732  trainloss -1503.12306  validloss -1509.72634±0.00000  bestvalidloss -1582.54802  last_update 35\n",
      "train: iter 733  trainloss -1492.20018  validloss -1499.78524±0.00000  bestvalidloss -1582.54802  last_update 36\n",
      "train: iter 734  trainloss -1481.48284  validloss -1442.34810±0.00000  bestvalidloss -1582.54802  last_update 37\n",
      "train: iter 735  trainloss -1502.88945  validloss -1474.33492±0.00000  bestvalidloss -1582.54802  last_update 38\n",
      "train: iter 736  trainloss -1510.39795  validloss -1497.41985±0.00000  bestvalidloss -1582.54802  last_update 39\n",
      "train: iter 737  trainloss -1564.81108  validloss -1541.15095±0.00000  bestvalidloss -1582.54802  last_update 40\n",
      "train: iter 738  trainloss -1494.88221  validloss -1537.60422±0.00000  bestvalidloss -1582.54802  last_update 41\n",
      "train: iter 739  trainloss -1271.44638  validloss -1017.34126±0.00000  bestvalidloss -1582.54802  last_update 42\n",
      "train: iter 740  trainloss -1410.70198  validloss -1109.30791±0.00000  bestvalidloss -1582.54802  last_update 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 741  trainloss -1494.42388  validloss -1483.23777±0.00000  bestvalidloss -1582.54802  last_update 44\n",
      "train: iter 742  trainloss -1422.52842  validloss -1395.99921±0.00000  bestvalidloss -1582.54802  last_update 45\n",
      "train: iter 743  trainloss -1525.58486  validloss -1432.71768±0.00000  bestvalidloss -1582.54802  last_update 46\n",
      "train: iter 744  trainloss -1548.52915  validloss -1542.39775±0.00000  bestvalidloss -1582.54802  last_update 47\n",
      "train: iter 745  trainloss -1490.05167  validloss -1527.31726±0.00000  bestvalidloss -1582.54802  last_update 48\n",
      "train: iter 746  trainloss -1481.88852  validloss -1469.27017±0.00000  bestvalidloss -1582.54802  last_update 49\n",
      "train: iter 747  trainloss -1536.25986  validloss -1519.55494±0.00000  bestvalidloss -1582.54802  last_update 50\n",
      "train: iter 748  trainloss -1546.92738  validloss -1491.73862±0.00000  bestvalidloss -1582.54802  last_update 51\n",
      "train: iter 749  trainloss -1511.36242  validloss -1407.17768±0.00000  bestvalidloss -1582.54802  last_update 52\n",
      "train: iter 750  trainloss -1493.82217  validloss -1524.81856±0.00000  bestvalidloss -1582.54802  last_update 53\n",
      "train: iter 751  trainloss -1546.79218  validloss -1390.73861±0.00000  bestvalidloss -1582.54802  last_update 54\n",
      "train: iter 752  trainloss -1547.09561  validloss -1500.34813±0.00000  bestvalidloss -1582.54802  last_update 55\n",
      "train: iter 753  trainloss -1363.87482  validloss -1344.94095±0.00000  bestvalidloss -1582.54802  last_update 56\n",
      "train: iter 754  trainloss -1523.53117  validloss -1479.47080±0.00000  bestvalidloss -1582.54802  last_update 57\n",
      "train: iter 755  trainloss -1508.41992  validloss -1533.44867±0.00000  bestvalidloss -1582.54802  last_update 58\n",
      "train: iter 756  trainloss -1517.69542  validloss -1498.80418±0.00000  bestvalidloss -1582.54802  last_update 59\n",
      "train: iter 757  trainloss -1407.73796  validloss -1098.55041±0.00000  bestvalidloss -1582.54802  last_update 60\n",
      "train: iter 758  trainloss -1513.07304  validloss -1499.98302±0.00000  bestvalidloss -1582.54802  last_update 61\n",
      "train: iter 759  trainloss -1399.62669  validloss -1481.73695±0.00000  bestvalidloss -1582.54802  last_update 62\n",
      "train: iter 760  trainloss -1509.87350  validloss -1514.09082±0.00000  bestvalidloss -1582.54802  last_update 63\n",
      "train: iter 761  trainloss -1487.37065  validloss -1505.86484±0.00000  bestvalidloss -1582.54802  last_update 64\n",
      "train: iter 762  trainloss -1445.70200  validloss -1484.09625±0.00000  bestvalidloss -1582.54802  last_update 65\n",
      "train: iter 763  trainloss -1554.26897  validloss -1524.80537±0.00000  bestvalidloss -1582.54802  last_update 66\n",
      "train: iter 764  trainloss -1455.88260  validloss -1484.11145±0.00000  bestvalidloss -1582.54802  last_update 67\n",
      "train: iter 765  trainloss -1483.36932  validloss -1408.66646±0.00000  bestvalidloss -1582.54802  last_update 68\n",
      "train: iter 766  trainloss -1516.29579  validloss -1514.29749±0.00000  bestvalidloss -1582.54802  last_update 69\n",
      "train: iter 767  trainloss -1445.59755  validloss -1438.74828±0.00000  bestvalidloss -1582.54802  last_update 70\n",
      "train: iter 768  trainloss -1519.42917  validloss -1486.60945±0.00000  bestvalidloss -1582.54802  last_update 71\n",
      "train: iter 769  trainloss -1547.52341  validloss -1523.12220±0.00000  bestvalidloss -1582.54802  last_update 72\n",
      "train: iter 770  trainloss -1511.89200  validloss -1460.25213±0.00000  bestvalidloss -1582.54802  last_update 73\n",
      "train: iter 771  trainloss -1581.94779  validloss -1543.34149±0.00000  bestvalidloss -1582.54802  last_update 74\n",
      "train: iter 772  trainloss -1455.11222  validloss -1422.11839±0.00000  bestvalidloss -1582.54802  last_update 75\n",
      "train: iter 773  trainloss -1531.56173  validloss -1491.86446±0.00000  bestvalidloss -1582.54802  last_update 76\n",
      "train: iter 774  trainloss -1566.95686  validloss -1558.97688±0.00000  bestvalidloss -1582.54802  last_update 77\n",
      "train: iter 775  trainloss -1418.98529  validloss -1267.94319±0.00000  bestvalidloss -1582.54802  last_update 78\n",
      "train: iter 776  trainloss -1436.52090  validloss -1508.77276±0.00000  bestvalidloss -1582.54802  last_update 79\n",
      "train: iter 777  trainloss -1485.75671  validloss -1443.26503±0.00000  bestvalidloss -1582.54802  last_update 80\n",
      "train: iter 778  trainloss -1525.28374  validloss -1475.18721±0.00000  bestvalidloss -1582.54802  last_update 81\n",
      "train: iter 779  trainloss -1559.65314  validloss -1516.71569±0.00000  bestvalidloss -1582.54802  last_update 82\n",
      "train: iter 780  trainloss -1497.05913  validloss -1525.83813±0.00000  bestvalidloss -1582.54802  last_update 83\n",
      "train: iter 781  trainloss -1541.69384  validloss -1491.43753±0.00000  bestvalidloss -1582.54802  last_update 84\n",
      "train: iter 782  trainloss -1570.83245  validloss -1525.57169±0.00000  bestvalidloss -1582.54802  last_update 85\n",
      "train: iter 783  trainloss -1570.35939  validloss -1502.64744±0.00000  bestvalidloss -1582.54802  last_update 86\n",
      "train: iter 784  trainloss -1480.95982  validloss -1559.28276±0.00000  bestvalidloss -1582.54802  last_update 87\n",
      "train: iter 785  trainloss -1515.12306  validloss -1461.11315±0.00000  bestvalidloss -1582.54802  last_update 88\n",
      "train: iter 786  trainloss -1513.09247  validloss -1516.10037±0.00000  bestvalidloss -1582.54802  last_update 89\n",
      "train: iter 787  trainloss -1532.25943  validloss -1427.44744±0.00000  bestvalidloss -1582.54802  last_update 90\n",
      "train: iter 788  trainloss -1475.76529  validloss -1498.33633±0.00000  bestvalidloss -1582.54802  last_update 91\n",
      "train: iter 789  trainloss -1561.62573  validloss -1516.89886±0.00000  bestvalidloss -1582.54802  last_update 92\n",
      "train: iter 790  trainloss -1567.18206  validloss -1535.40636±0.00000  bestvalidloss -1582.54802  last_update 93\n",
      "train: iter 791  trainloss -1524.50486  validloss -1519.80421±0.00000  bestvalidloss -1582.54802  last_update 94\n",
      "train: iter 792  trainloss -1495.04351  validloss -1528.40706±0.00000  bestvalidloss -1582.54802  last_update 95\n",
      "train: iter 793  trainloss -1545.17684  validloss -1339.86070±0.00000  bestvalidloss -1582.54802  last_update 96\n",
      "train: iter 794  trainloss -1575.82539  validloss -1576.90753±0.00000  bestvalidloss -1582.54802  last_update 97\n",
      "train: iter 795  trainloss -1528.37742  validloss -1549.16522±0.00000  bestvalidloss -1582.54802  last_update 98\n",
      "train: iter 796  trainloss -1450.90473  validloss -1354.08029±0.00000  bestvalidloss -1582.54802  last_update 99\n",
      "train: iter 797  trainloss -1384.72740  validloss -1366.29544±0.00000  bestvalidloss -1582.54802  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.4383) penalty_target_max tensor(6.4395)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 8.85948  validloss 9.41001±0.00000  bestvalidloss 9.41001  last_update 0\n",
      "train: iter 1  trainloss 8.08904  validloss 8.55156±0.00000  bestvalidloss 8.55156  last_update 0\n",
      "train: iter 2  trainloss 7.41631  validloss 7.83448±0.00000  bestvalidloss 7.83448  last_update 0\n",
      "train: iter 3  trainloss 6.85176  validloss 7.21668±0.00000  bestvalidloss 7.21668  last_update 0\n",
      "train: iter 4  trainloss 6.36108  validloss 6.67638±0.00000  bestvalidloss 6.67638  last_update 0\n",
      "train: iter 5  trainloss 5.92267  validloss 6.20635±0.00000  bestvalidloss 6.20635  last_update 0\n",
      "train: iter 6  trainloss 5.55635  validloss 5.81688±0.00000  bestvalidloss 5.81688  last_update 0\n",
      "train: iter 7  trainloss 5.22613  validloss 5.44322±0.00000  bestvalidloss 5.44322  last_update 0\n",
      "train: iter 8  trainloss 4.93666  validloss 5.15329±0.00000  bestvalidloss 5.15329  last_update 0\n",
      "train: iter 9  trainloss 4.67603  validloss 4.84747±0.00000  bestvalidloss 4.84747  last_update 0\n",
      "train: iter 10  trainloss 4.44446  validloss 4.60079±0.00000  bestvalidloss 4.60079  last_update 0\n",
      "train: iter 11  trainloss 4.23291  validloss 4.38040±0.00000  bestvalidloss 4.38040  last_update 0\n",
      "train: iter 12  trainloss 4.04452  validloss 4.17553±0.00000  bestvalidloss 4.17553  last_update 0\n",
      "train: iter 13  trainloss 3.87988  validloss 3.98205±0.00000  bestvalidloss 3.98205  last_update 0\n",
      "train: iter 14  trainloss 3.71782  validloss 3.84225±0.00000  bestvalidloss 3.84225  last_update 0\n",
      "train: iter 15  trainloss 3.57336  validloss 3.66745±0.00000  bestvalidloss 3.66745  last_update 0\n",
      "train: iter 16  trainloss 3.44890  validloss 3.53534±0.00000  bestvalidloss 3.53534  last_update 0\n",
      "train: iter 17  trainloss 3.32344  validloss 3.40383±0.00000  bestvalidloss 3.40383  last_update 0\n",
      "train: iter 18  trainloss 3.21899  validloss 3.29005±0.00000  bestvalidloss 3.29005  last_update 0\n",
      "train: iter 19  trainloss 3.12060  validloss 3.18743±0.00000  bestvalidloss 3.18743  last_update 0\n",
      "train: iter 20  trainloss 3.02126  validloss 3.05954±0.00000  bestvalidloss 3.05954  last_update 0\n",
      "train: iter 21  trainloss 2.94282  validloss 2.98125±0.00000  bestvalidloss 2.98125  last_update 0\n",
      "train: iter 22  trainloss 2.86531  validloss 2.88284±0.00000  bestvalidloss 2.88284  last_update 0\n",
      "train: iter 23  trainloss 2.78699  validloss 2.82209±0.00000  bestvalidloss 2.82209  last_update 0\n",
      "train: iter 24  trainloss 2.71823  validloss 2.75265±0.00000  bestvalidloss 2.75265  last_update 0\n",
      "train: iter 25  trainloss 2.65665  validloss 2.66560±0.00000  bestvalidloss 2.66560  last_update 0\n",
      "train: iter 26  trainloss 2.59812  validloss 2.58190±0.00000  bestvalidloss 2.58190  last_update 0\n",
      "train: iter 27  trainloss 2.53015  validloss 2.55534±0.00000  bestvalidloss 2.55534  last_update 0\n",
      "train: iter 28  trainloss 2.48942  validloss 2.49079±0.00000  bestvalidloss 2.49079  last_update 0\n",
      "train: iter 29  trainloss 2.44918  validloss 2.42704±0.00000  bestvalidloss 2.42704  last_update 0\n",
      "train: iter 30  trainloss 2.39461  validloss 2.37396±0.00000  bestvalidloss 2.37396  last_update 0\n",
      "train: iter 31  trainloss 2.35406  validloss 2.34820±0.00000  bestvalidloss 2.34820  last_update 0\n",
      "train: iter 32  trainloss 2.31870  validloss 2.29714±0.00000  bestvalidloss 2.29714  last_update 0\n",
      "train: iter 33  trainloss 2.28671  validloss 2.23313±0.00000  bestvalidloss 2.23313  last_update 0\n",
      "train: iter 34  trainloss 2.24285  validloss 2.24581±0.00000  bestvalidloss 2.23313  last_update 1\n",
      "train: iter 35  trainloss 2.19580  validloss 2.19620±0.00000  bestvalidloss 2.19620  last_update 0\n",
      "train: iter 36  trainloss 2.19428  validloss 2.16725±0.00000  bestvalidloss 2.16725  last_update 0\n",
      "train: iter 37  trainloss 2.17418  validloss 2.09655±0.00000  bestvalidloss 2.09655  last_update 0\n",
      "train: iter 38  trainloss 2.14847  validloss 2.08586±0.00000  bestvalidloss 2.08586  last_update 0\n",
      "train: iter 39  trainloss 2.11879  validloss 2.07599±0.00000  bestvalidloss 2.07599  last_update 0\n",
      "train: iter 40  trainloss 2.07754  validloss 2.01135±0.00000  bestvalidloss 2.01135  last_update 0\n",
      "train: iter 41  trainloss 2.05183  validloss 1.96772±0.00000  bestvalidloss 1.96772  last_update 0\n",
      "train: iter 42  trainloss 2.04500  validloss 1.99932±0.00000  bestvalidloss 1.96772  last_update 1\n",
      "train: iter 43  trainloss 2.01366  validloss 1.97831±0.00000  bestvalidloss 1.96772  last_update 2\n",
      "train: iter 44  trainloss 1.98742  validloss 1.88967±0.00000  bestvalidloss 1.88967  last_update 0\n",
      "train: iter 45  trainloss 1.97605  validloss 1.90205±0.00000  bestvalidloss 1.88967  last_update 1\n",
      "train: iter 46  trainloss 1.92940  validloss 1.86406±0.00000  bestvalidloss 1.86406  last_update 0\n",
      "train: iter 47  trainloss 1.92353  validloss 1.83070±0.00000  bestvalidloss 1.83070  last_update 0\n",
      "train: iter 48  trainloss 1.87588  validloss 1.79947±0.00000  bestvalidloss 1.79947  last_update 0\n",
      "train: iter 49  trainloss 1.86338  validloss 1.80157±0.00000  bestvalidloss 1.79947  last_update 1\n",
      "train: iter 50  trainloss 1.85114  validloss 1.78885±0.00000  bestvalidloss 1.78885  last_update 0\n",
      "train: iter 51  trainloss 1.80713  validloss 1.73696±0.00000  bestvalidloss 1.73696  last_update 0\n",
      "train: iter 52  trainloss 1.77532  validloss 1.67108±0.00000  bestvalidloss 1.67108  last_update 0\n",
      "train: iter 53  trainloss 1.72375  validloss 1.67849±0.00000  bestvalidloss 1.67108  last_update 1\n",
      "train: iter 54  trainloss 1.71938  validloss 1.61912±0.00000  bestvalidloss 1.61912  last_update 0\n",
      "train: iter 55  trainloss 1.70102  validloss 1.62212±0.00000  bestvalidloss 1.61912  last_update 1\n",
      "train: iter 56  trainloss 1.64129  validloss 1.61159±0.00000  bestvalidloss 1.61159  last_update 0\n",
      "train: iter 57  trainloss 1.59957  validloss 1.54722±0.00000  bestvalidloss 1.54722  last_update 0\n",
      "train: iter 58  trainloss 1.60595  validloss 1.48400±0.00000  bestvalidloss 1.48400  last_update 0\n",
      "train: iter 59  trainloss 1.54324  validloss 1.45430±0.00000  bestvalidloss 1.45430  last_update 0\n",
      "train: iter 60  trainloss 1.50970  validloss 1.46064±0.00000  bestvalidloss 1.45430  last_update 1\n",
      "train: iter 61  trainloss 1.48814  validloss 1.34378±0.00000  bestvalidloss 1.34378  last_update 0\n",
      "train: iter 62  trainloss 1.44134  validloss 1.40214±0.00000  bestvalidloss 1.34378  last_update 1\n",
      "train: iter 63  trainloss 1.38955  validloss 1.29518±0.00000  bestvalidloss 1.29518  last_update 0\n",
      "train: iter 64  trainloss 1.32855  validloss 1.26742±0.00000  bestvalidloss 1.26742  last_update 0\n",
      "train: iter 65  trainloss 1.31458  validloss 1.24718±0.00000  bestvalidloss 1.24718  last_update 0\n",
      "train: iter 66  trainloss 1.26094  validloss 1.21091±0.00000  bestvalidloss 1.21091  last_update 0\n",
      "train: iter 67  trainloss 1.21734  validloss 1.09600±0.00000  bestvalidloss 1.09600  last_update 0\n",
      "train: iter 68  trainloss 1.18024  validloss 1.07244±0.00000  bestvalidloss 1.07244  last_update 0\n",
      "train: iter 69  trainloss 1.12049  validloss 1.05256±0.00000  bestvalidloss 1.05256  last_update 0\n",
      "train: iter 70  trainloss 1.05050  validloss 1.00995±0.00000  bestvalidloss 1.00995  last_update 0\n",
      "train: iter 71  trainloss 1.01987  validloss 0.91590±0.00000  bestvalidloss 0.91590  last_update 0\n",
      "train: iter 72  trainloss 0.97594  validloss 0.88639±0.00000  bestvalidloss 0.88639  last_update 0\n",
      "train: iter 73  trainloss 0.90880  validloss 0.85648±0.00000  bestvalidloss 0.85648  last_update 0\n",
      "train: iter 74  trainloss 0.88722  validloss 0.78865±0.00000  bestvalidloss 0.78865  last_update 0\n",
      "train: iter 75  trainloss 0.82153  validloss 0.77459±0.00000  bestvalidloss 0.77459  last_update 0\n",
      "train: iter 76  trainloss 0.80611  validloss 0.70161±0.00000  bestvalidloss 0.70161  last_update 0\n",
      "train: iter 77  trainloss 0.75516  validloss 0.67406±0.00000  bestvalidloss 0.67406  last_update 0\n",
      "train: iter 78  trainloss 0.70946  validloss 0.62181±0.00000  bestvalidloss 0.62181  last_update 0\n",
      "train: iter 79  trainloss 0.68424  validloss 0.57501±0.00000  bestvalidloss 0.57501  last_update 0\n",
      "train: iter 80  trainloss 0.63318  validloss 0.52757±0.00000  bestvalidloss 0.52757  last_update 0\n",
      "train: iter 81  trainloss 0.59042  validloss 0.47000±0.00000  bestvalidloss 0.47000  last_update 0\n",
      "train: iter 82  trainloss 0.55662  validloss 0.44662±0.00000  bestvalidloss 0.44662  last_update 0\n",
      "train: iter 83  trainloss 0.53834  validloss 0.42141±0.00000  bestvalidloss 0.42141  last_update 0\n",
      "train: iter 84  trainloss 0.48756  validloss 0.38911±0.00000  bestvalidloss 0.38911  last_update 0\n",
      "train: iter 85  trainloss 0.45123  validloss 0.35047±0.00000  bestvalidloss 0.35047  last_update 0\n",
      "train: iter 86  trainloss 0.40098  validloss 0.29420±0.00000  bestvalidloss 0.29420  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 87  trainloss 0.37103  validloss 0.21347±0.00000  bestvalidloss 0.21347  last_update 0\n",
      "train: iter 88  trainloss 0.34406  validloss 0.20824±0.00000  bestvalidloss 0.20824  last_update 0\n",
      "train: iter 89  trainloss 0.30359  validloss 0.24576±0.00000  bestvalidloss 0.20824  last_update 1\n",
      "train: iter 90  trainloss 0.26848  validloss 0.13048±0.00000  bestvalidloss 0.13048  last_update 0\n",
      "train: iter 91  trainloss 0.23324  validloss 0.15324±0.00000  bestvalidloss 0.13048  last_update 1\n",
      "train: iter 92  trainloss 0.19619  validloss 0.08357±0.00000  bestvalidloss 0.08357  last_update 0\n",
      "train: iter 93  trainloss 0.16915  validloss 0.03533±0.00000  bestvalidloss 0.03533  last_update 0\n",
      "train: iter 94  trainloss 0.13254  validloss 0.00876±0.00000  bestvalidloss 0.00876  last_update 0\n",
      "train: iter 95  trainloss 0.13447  validloss -0.00815±0.00000  bestvalidloss -0.00815  last_update 0\n",
      "train: iter 96  trainloss 0.09060  validloss -0.04335±0.00000  bestvalidloss -0.04335  last_update 0\n",
      "train: iter 97  trainloss 0.06233  validloss -0.08073±0.00000  bestvalidloss -0.08073  last_update 0\n",
      "train: iter 98  trainloss 0.04374  validloss -0.10312±0.00000  bestvalidloss -0.10312  last_update 0\n",
      "train: iter 99  trainloss -0.00839  validloss -0.11860±0.00000  bestvalidloss -0.11860  last_update 0\n",
      "train: iter 100  trainloss -0.05844  validloss -0.16653±0.00000  bestvalidloss -0.16653  last_update 0\n",
      "train: iter 101  trainloss -0.06965  validloss -0.18685±0.00000  bestvalidloss -0.18685  last_update 0\n",
      "train: iter 102  trainloss -0.08927  validloss -0.22089±0.00000  bestvalidloss -0.22089  last_update 0\n",
      "train: iter 103  trainloss -0.10530  validloss -0.26562±0.00000  bestvalidloss -0.26562  last_update 0\n",
      "train: iter 104  trainloss -0.12557  validloss -0.28111±0.00000  bestvalidloss -0.28111  last_update 0\n",
      "train: iter 105  trainloss -0.15376  validloss -0.36281±0.00000  bestvalidloss -0.36281  last_update 0\n",
      "train: iter 106  trainloss -0.18486  validloss -0.35453±0.00000  bestvalidloss -0.36281  last_update 1\n",
      "train: iter 107  trainloss -0.22720  validloss -0.31550±0.00000  bestvalidloss -0.36281  last_update 2\n",
      "train: iter 108  trainloss -0.20374  validloss -0.38881±0.00000  bestvalidloss -0.38881  last_update 0\n",
      "train: iter 109  trainloss -0.21767  validloss -0.38541±0.00000  bestvalidloss -0.38881  last_update 1\n",
      "train: iter 110  trainloss -0.24268  validloss -0.45217±0.00000  bestvalidloss -0.45217  last_update 0\n",
      "train: iter 111  trainloss -0.25457  validloss -0.45533±0.00000  bestvalidloss -0.45533  last_update 0\n",
      "train: iter 112  trainloss -0.30261  validloss -0.44208±0.00000  bestvalidloss -0.45533  last_update 1\n",
      "train: iter 113  trainloss -0.28260  validloss -0.45399±0.00000  bestvalidloss -0.45533  last_update 2\n",
      "train: iter 114  trainloss -0.28422  validloss -0.50914±0.00000  bestvalidloss -0.50914  last_update 0\n",
      "train: iter 115  trainloss -0.31112  validloss -0.51021±0.00000  bestvalidloss -0.51021  last_update 0\n",
      "train: iter 116  trainloss -0.31055  validloss -0.52596±0.00000  bestvalidloss -0.52596  last_update 0\n",
      "train: iter 117  trainloss -0.34205  validloss -0.53531±0.00000  bestvalidloss -0.53531  last_update 0\n",
      "train: iter 118  trainloss -0.32998  validloss -0.56030±0.00000  bestvalidloss -0.56030  last_update 0\n",
      "train: iter 119  trainloss -0.34333  validloss -0.51668±0.00000  bestvalidloss -0.56030  last_update 1\n",
      "train: iter 120  trainloss -0.36679  validloss -0.53738±0.00000  bestvalidloss -0.56030  last_update 2\n",
      "train: iter 121  trainloss -0.31950  validloss -0.54933±0.00000  bestvalidloss -0.56030  last_update 3\n",
      "train: iter 122  trainloss -0.37432  validloss -0.58378±0.00000  bestvalidloss -0.58378  last_update 0\n",
      "train: iter 123  trainloss -0.32011  validloss -0.62591±0.00000  bestvalidloss -0.62591  last_update 0\n",
      "train: iter 124  trainloss -0.36523  validloss -0.58513±0.00000  bestvalidloss -0.62591  last_update 1\n",
      "train: iter 125  trainloss -0.31705  validloss -0.58283±0.00000  bestvalidloss -0.62591  last_update 2\n",
      "train: iter 126  trainloss -0.36924  validloss -0.54954±0.00000  bestvalidloss -0.62591  last_update 3\n",
      "train: iter 127  trainloss -0.35203  validloss -0.56757±0.00000  bestvalidloss -0.62591  last_update 4\n",
      "train: iter 128  trainloss -0.38553  validloss -0.62023±0.00000  bestvalidloss -0.62591  last_update 5\n",
      "train: iter 129  trainloss -0.37733  validloss -0.62296±0.00000  bestvalidloss -0.62591  last_update 6\n",
      "train: iter 130  trainloss -0.37255  validloss -0.67476±0.00000  bestvalidloss -0.67476  last_update 0\n",
      "train: iter 131  trainloss -0.36670  validloss -0.67343±0.00000  bestvalidloss -0.67476  last_update 1\n",
      "train: iter 132  trainloss -0.38858  validloss -0.60109±0.00000  bestvalidloss -0.67476  last_update 2\n",
      "train: iter 133  trainloss -0.37571  validloss -0.66522±0.00000  bestvalidloss -0.67476  last_update 3\n",
      "train: iter 134  trainloss -0.42433  validloss -0.65796±0.00000  bestvalidloss -0.67476  last_update 4\n",
      "train: iter 135  trainloss -0.39244  validloss -0.69039±0.00000  bestvalidloss -0.69039  last_update 0\n",
      "train: iter 136  trainloss -0.37542  validloss -0.59195±0.00000  bestvalidloss -0.69039  last_update 1\n",
      "train: iter 137  trainloss -0.37908  validloss -0.66226±0.00000  bestvalidloss -0.69039  last_update 2\n",
      "train: iter 138  trainloss -0.37924  validloss -0.70162±0.00000  bestvalidloss -0.70162  last_update 0\n",
      "train: iter 139  trainloss -0.42348  validloss -0.64698±0.00000  bestvalidloss -0.70162  last_update 1\n",
      "train: iter 140  trainloss -0.44288  validloss -0.71538±0.00000  bestvalidloss -0.71538  last_update 0\n",
      "train: iter 141  trainloss -0.39695  validloss -0.68565±0.00000  bestvalidloss -0.71538  last_update 1\n",
      "train: iter 142  trainloss -0.39858  validloss -0.63289±0.00000  bestvalidloss -0.71538  last_update 2\n",
      "train: iter 143  trainloss -0.39046  validloss -0.69758±0.00000  bestvalidloss -0.71538  last_update 3\n",
      "train: iter 144  trainloss -0.38485  validloss -0.62564±0.00000  bestvalidloss -0.71538  last_update 4\n",
      "train: iter 145  trainloss -0.43502  validloss -0.67948±0.00000  bestvalidloss -0.71538  last_update 5\n",
      "train: iter 146  trainloss -0.36533  validloss -0.71089±0.00000  bestvalidloss -0.71538  last_update 6\n",
      "train: iter 147  trainloss -0.36876  validloss -0.63246±0.00000  bestvalidloss -0.71538  last_update 7\n",
      "train: iter 148  trainloss -0.42354  validloss -0.65643±0.00000  bestvalidloss -0.71538  last_update 8\n",
      "train: iter 149  trainloss -0.38848  validloss -0.63989±0.00000  bestvalidloss -0.71538  last_update 9\n",
      "train: iter 150  trainloss -0.38850  validloss -0.63335±0.00000  bestvalidloss -0.71538  last_update 10\n",
      "train: iter 151  trainloss -0.37485  validloss -0.69293±0.00000  bestvalidloss -0.71538  last_update 11\n",
      "train: iter 152  trainloss -0.35639  validloss -0.68307±0.00000  bestvalidloss -0.71538  last_update 12\n",
      "train: iter 153  trainloss -0.37959  validloss -0.66465±0.00000  bestvalidloss -0.71538  last_update 13\n",
      "train: iter 154  trainloss -0.43287  validloss -0.67955±0.00000  bestvalidloss -0.71538  last_update 14\n",
      "train: iter 155  trainloss -0.40376  validloss -0.66592±0.00000  bestvalidloss -0.71538  last_update 15\n",
      "train: iter 156  trainloss -0.40019  validloss -0.64270±0.00000  bestvalidloss -0.71538  last_update 16\n",
      "train: iter 157  trainloss -0.39978  validloss -0.63830±0.00000  bestvalidloss -0.71538  last_update 17\n",
      "train: iter 158  trainloss -0.38930  validloss -0.71272±0.00000  bestvalidloss -0.71538  last_update 18\n",
      "train: iter 159  trainloss -0.42057  validloss -0.71010±0.00000  bestvalidloss -0.71538  last_update 19\n",
      "train: iter 160  trainloss -0.38724  validloss -0.72895±0.00000  bestvalidloss -0.72895  last_update 0\n",
      "train: iter 161  trainloss -0.39751  validloss -0.67637±0.00000  bestvalidloss -0.72895  last_update 1\n",
      "train: iter 162  trainloss -0.41613  validloss -0.70648±0.00000  bestvalidloss -0.72895  last_update 2\n",
      "train: iter 163  trainloss -0.39941  validloss -0.70576±0.00000  bestvalidloss -0.72895  last_update 3\n",
      "train: iter 164  trainloss -0.41187  validloss -0.66482±0.00000  bestvalidloss -0.72895  last_update 4\n",
      "train: iter 165  trainloss -0.41008  validloss -0.73232±0.00000  bestvalidloss -0.73232  last_update 0\n",
      "train: iter 166  trainloss -0.40440  validloss -0.72191±0.00000  bestvalidloss -0.73232  last_update 1\n",
      "train: iter 167  trainloss -0.41906  validloss -0.64141±0.00000  bestvalidloss -0.73232  last_update 2\n",
      "train: iter 168  trainloss -0.38714  validloss -0.66516±0.00000  bestvalidloss -0.73232  last_update 3\n",
      "train: iter 169  trainloss -0.42357  validloss -0.67670±0.00000  bestvalidloss -0.73232  last_update 4\n",
      "train: iter 170  trainloss -0.33432  validloss -0.65877±0.00000  bestvalidloss -0.73232  last_update 5\n",
      "train: iter 171  trainloss -0.39198  validloss -0.69661±0.00000  bestvalidloss -0.73232  last_update 6\n",
      "train: iter 172  trainloss -0.39317  validloss -0.70566±0.00000  bestvalidloss -0.73232  last_update 7\n",
      "train: iter 173  trainloss -0.38433  validloss -0.67388±0.00000  bestvalidloss -0.73232  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 174  trainloss -0.40157  validloss -0.67486±0.00000  bestvalidloss -0.73232  last_update 9\n",
      "train: iter 175  trainloss -0.37248  validloss -0.61721±0.00000  bestvalidloss -0.73232  last_update 10\n",
      "train: iter 176  trainloss -0.39727  validloss -0.65507±0.00000  bestvalidloss -0.73232  last_update 11\n",
      "train: iter 177  trainloss -0.40857  validloss -0.64929±0.00000  bestvalidloss -0.73232  last_update 12\n",
      "train: iter 178  trainloss -0.39412  validloss -0.70985±0.00000  bestvalidloss -0.73232  last_update 13\n",
      "train: iter 179  trainloss -0.40040  validloss -0.65274±0.00000  bestvalidloss -0.73232  last_update 14\n",
      "train: iter 180  trainloss -0.37966  validloss -0.68197±0.00000  bestvalidloss -0.73232  last_update 15\n",
      "train: iter 181  trainloss -0.39846  validloss -0.71324±0.00000  bestvalidloss -0.73232  last_update 16\n",
      "train: iter 182  trainloss -0.37636  validloss -0.69395±0.00000  bestvalidloss -0.73232  last_update 17\n",
      "train: iter 183  trainloss -0.37303  validloss -0.68753±0.00000  bestvalidloss -0.73232  last_update 18\n",
      "train: iter 184  trainloss -0.41595  validloss -0.68418±0.00000  bestvalidloss -0.73232  last_update 19\n",
      "train: iter 185  trainloss -0.39618  validloss -0.69970±0.00000  bestvalidloss -0.73232  last_update 20\n",
      "train: iter 186  trainloss -0.43998  validloss -0.73959±0.00000  bestvalidloss -0.73959  last_update 0\n",
      "train: iter 187  trainloss -0.39759  validloss -0.67765±0.00000  bestvalidloss -0.73959  last_update 1\n",
      "train: iter 188  trainloss -0.42683  validloss -0.67718±0.00000  bestvalidloss -0.73959  last_update 2\n",
      "train: iter 189  trainloss -0.40973  validloss -0.71391±0.00000  bestvalidloss -0.73959  last_update 3\n",
      "train: iter 190  trainloss -0.42779  validloss -0.69866±0.00000  bestvalidloss -0.73959  last_update 4\n",
      "train: iter 191  trainloss -0.45599  validloss -0.68504±0.00000  bestvalidloss -0.73959  last_update 5\n",
      "train: iter 192  trainloss -0.39233  validloss -0.68812±0.00000  bestvalidloss -0.73959  last_update 6\n",
      "train: iter 193  trainloss -0.40916  validloss -0.73610±0.00000  bestvalidloss -0.73959  last_update 7\n",
      "train: iter 194  trainloss -0.41590  validloss -0.69030±0.00000  bestvalidloss -0.73959  last_update 8\n",
      "train: iter 195  trainloss -0.40420  validloss -0.72147±0.00000  bestvalidloss -0.73959  last_update 9\n",
      "train: iter 196  trainloss -0.45411  validloss -0.67221±0.00000  bestvalidloss -0.73959  last_update 10\n",
      "train: iter 197  trainloss -0.38920  validloss -0.67710±0.00000  bestvalidloss -0.73959  last_update 11\n",
      "train: iter 198  trainloss -0.40587  validloss -0.67404±0.00000  bestvalidloss -0.73959  last_update 12\n",
      "train: iter 199  trainloss -0.39453  validloss -0.67448±0.00000  bestvalidloss -0.73959  last_update 13\n",
      "train: iter 200  trainloss -0.39140  validloss -0.66633±0.00000  bestvalidloss -0.73959  last_update 14\n",
      "train: iter 201  trainloss -0.40076  validloss -0.66540±0.00000  bestvalidloss -0.73959  last_update 15\n",
      "train: iter 202  trainloss -0.41963  validloss -0.73146±0.00000  bestvalidloss -0.73959  last_update 16\n",
      "train: iter 203  trainloss -0.42436  validloss -0.72850±0.00000  bestvalidloss -0.73959  last_update 17\n",
      "train: iter 204  trainloss -0.39426  validloss -0.67036±0.00000  bestvalidloss -0.73959  last_update 18\n",
      "train: iter 205  trainloss -0.38076  validloss -0.69441±0.00000  bestvalidloss -0.73959  last_update 19\n",
      "train: iter 206  trainloss -0.39092  validloss -0.72034±0.00000  bestvalidloss -0.73959  last_update 20\n",
      "train: iter 207  trainloss -0.42423  validloss -0.69075±0.00000  bestvalidloss -0.73959  last_update 21\n",
      "train: iter 208  trainloss -0.37082  validloss -0.60148±0.00000  bestvalidloss -0.73959  last_update 22\n",
      "train: iter 209  trainloss -0.39497  validloss -0.69719±0.00000  bestvalidloss -0.73959  last_update 23\n",
      "train: iter 210  trainloss -0.39281  validloss -0.72255±0.00000  bestvalidloss -0.73959  last_update 24\n",
      "train: iter 211  trainloss -0.42268  validloss -0.68927±0.00000  bestvalidloss -0.73959  last_update 25\n",
      "train: iter 212  trainloss -0.40205  validloss -0.69828±0.00000  bestvalidloss -0.73959  last_update 26\n",
      "train: iter 213  trainloss -0.40741  validloss -0.67937±0.00000  bestvalidloss -0.73959  last_update 27\n",
      "train: iter 214  trainloss -0.41875  validloss -0.65141±0.00000  bestvalidloss -0.73959  last_update 28\n",
      "train: iter 215  trainloss -0.41611  validloss -0.68911±0.00000  bestvalidloss -0.73959  last_update 29\n",
      "train: iter 216  trainloss -0.39251  validloss -0.69248±0.00000  bestvalidloss -0.73959  last_update 30\n",
      "train: iter 217  trainloss -0.39186  validloss -0.70366±0.00000  bestvalidloss -0.73959  last_update 31\n",
      "train: iter 218  trainloss -0.40181  validloss -0.69788±0.00000  bestvalidloss -0.73959  last_update 32\n",
      "train: iter 219  trainloss -0.41765  validloss -0.66968±0.00000  bestvalidloss -0.73959  last_update 33\n",
      "train: iter 220  trainloss -0.41299  validloss -0.71325±0.00000  bestvalidloss -0.73959  last_update 34\n",
      "train: iter 221  trainloss -0.39602  validloss -0.66241±0.00000  bestvalidloss -0.73959  last_update 35\n",
      "train: iter 222  trainloss -0.42226  validloss -0.71398±0.00000  bestvalidloss -0.73959  last_update 36\n",
      "train: iter 223  trainloss -0.38509  validloss -0.70076±0.00000  bestvalidloss -0.73959  last_update 37\n",
      "train: iter 224  trainloss -0.39937  validloss -0.68519±0.00000  bestvalidloss -0.73959  last_update 38\n",
      "train: iter 225  trainloss -0.44389  validloss -0.67949±0.00000  bestvalidloss -0.73959  last_update 39\n",
      "train: iter 226  trainloss -0.39085  validloss -0.67427±0.00000  bestvalidloss -0.73959  last_update 40\n",
      "train: iter 227  trainloss -0.34359  validloss -0.72887±0.00000  bestvalidloss -0.73959  last_update 41\n",
      "train: iter 228  trainloss -0.40285  validloss -0.69956±0.00000  bestvalidloss -0.73959  last_update 42\n",
      "train: iter 229  trainloss -0.42546  validloss -0.71211±0.00000  bestvalidloss -0.73959  last_update 43\n",
      "train: iter 230  trainloss -0.39691  validloss -0.68366±0.00000  bestvalidloss -0.73959  last_update 44\n",
      "train: iter 231  trainloss -0.37938  validloss -0.68233±0.00000  bestvalidloss -0.73959  last_update 45\n",
      "train: iter 232  trainloss -0.39679  validloss -0.72256±0.00000  bestvalidloss -0.73959  last_update 46\n",
      "train: iter 233  trainloss -0.38160  validloss -0.71631±0.00000  bestvalidloss -0.73959  last_update 47\n",
      "train: iter 234  trainloss -0.38364  validloss -0.63470±0.00000  bestvalidloss -0.73959  last_update 48\n",
      "train: iter 235  trainloss -0.46427  validloss -0.62502±0.00000  bestvalidloss -0.73959  last_update 49\n",
      "train: iter 236  trainloss -0.39039  validloss -0.68477±0.00000  bestvalidloss -0.73959  last_update 50\n",
      "train: iter 237  trainloss -0.39097  validloss -0.73471±0.00000  bestvalidloss -0.73959  last_update 51\n",
      "train: iter 238  trainloss -0.36214  validloss -0.74781±0.00000  bestvalidloss -0.74781  last_update 0\n",
      "train: iter 239  trainloss -0.43515  validloss -0.74034±0.00000  bestvalidloss -0.74781  last_update 1\n",
      "train: iter 240  trainloss -0.44161  validloss -0.68798±0.00000  bestvalidloss -0.74781  last_update 2\n",
      "train: iter 241  trainloss -0.41385  validloss -0.73904±0.00000  bestvalidloss -0.74781  last_update 3\n",
      "train: iter 242  trainloss -0.41485  validloss -0.67819±0.00000  bestvalidloss -0.74781  last_update 4\n",
      "train: iter 243  trainloss -0.39286  validloss -0.75231±0.00000  bestvalidloss -0.75231  last_update 0\n",
      "train: iter 244  trainloss -0.41669  validloss -0.67074±0.00000  bestvalidloss -0.75231  last_update 1\n",
      "train: iter 245  trainloss -0.41405  validloss -0.68331±0.00000  bestvalidloss -0.75231  last_update 2\n",
      "train: iter 246  trainloss -0.38894  validloss -0.70860±0.00000  bestvalidloss -0.75231  last_update 3\n",
      "train: iter 247  trainloss -0.42033  validloss -0.69452±0.00000  bestvalidloss -0.75231  last_update 4\n",
      "train: iter 248  trainloss -0.38553  validloss -0.69850±0.00000  bestvalidloss -0.75231  last_update 5\n",
      "train: iter 249  trainloss -0.41617  validloss -0.73528±0.00000  bestvalidloss -0.75231  last_update 6\n",
      "train: iter 250  trainloss -0.41659  validloss -0.69288±0.00000  bestvalidloss -0.75231  last_update 7\n",
      "train: iter 251  trainloss -0.38489  validloss -0.66012±0.00000  bestvalidloss -0.75231  last_update 8\n",
      "train: iter 252  trainloss -0.41073  validloss -0.73285±0.00000  bestvalidloss -0.75231  last_update 9\n",
      "train: iter 253  trainloss -0.42041  validloss -0.69004±0.00000  bestvalidloss -0.75231  last_update 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 254  trainloss -0.41952  validloss -0.68056±0.00000  bestvalidloss -0.75231  last_update 11\n",
      "train: iter 255  trainloss -0.44435  validloss -0.68861±0.00000  bestvalidloss -0.75231  last_update 12\n",
      "train: iter 256  trainloss -0.37969  validloss -0.64044±0.00000  bestvalidloss -0.75231  last_update 13\n",
      "train: iter 257  trainloss -0.40943  validloss -0.74616±0.00000  bestvalidloss -0.75231  last_update 14\n",
      "train: iter 258  trainloss -0.37913  validloss -0.70080±0.00000  bestvalidloss -0.75231  last_update 15\n",
      "train: iter 259  trainloss -0.40663  validloss -0.72192±0.00000  bestvalidloss -0.75231  last_update 16\n",
      "train: iter 260  trainloss -0.39875  validloss -0.66566±0.00000  bestvalidloss -0.75231  last_update 17\n",
      "train: iter 261  trainloss -0.39920  validloss -0.72128±0.00000  bestvalidloss -0.75231  last_update 18\n",
      "train: iter 262  trainloss -0.39256  validloss -0.71185±0.00000  bestvalidloss -0.75231  last_update 19\n",
      "train: iter 263  trainloss -0.40102  validloss -0.70962±0.00000  bestvalidloss -0.75231  last_update 20\n",
      "train: iter 264  trainloss -0.43468  validloss -0.75335±0.00000  bestvalidloss -0.75335  last_update 0\n",
      "train: iter 265  trainloss -0.41130  validloss -0.64659±0.00000  bestvalidloss -0.75335  last_update 1\n",
      "train: iter 266  trainloss -0.41154  validloss -0.70134±0.00000  bestvalidloss -0.75335  last_update 2\n",
      "train: iter 267  trainloss -0.40101  validloss -0.66627±0.00000  bestvalidloss -0.75335  last_update 3\n",
      "train: iter 268  trainloss -0.39847  validloss -0.65450±0.00000  bestvalidloss -0.75335  last_update 4\n",
      "train: iter 269  trainloss -0.38583  validloss -0.64260±0.00000  bestvalidloss -0.75335  last_update 5\n",
      "train: iter 270  trainloss -0.38122  validloss -0.70439±0.00000  bestvalidloss -0.75335  last_update 6\n",
      "train: iter 271  trainloss -0.42912  validloss -0.70366±0.00000  bestvalidloss -0.75335  last_update 7\n",
      "train: iter 272  trainloss -0.38445  validloss -0.67796±0.00000  bestvalidloss -0.75335  last_update 8\n",
      "train: iter 273  trainloss -0.37634  validloss -0.68803±0.00000  bestvalidloss -0.75335  last_update 9\n",
      "train: iter 274  trainloss -0.43641  validloss -0.66055±0.00000  bestvalidloss -0.75335  last_update 10\n",
      "train: iter 275  trainloss -0.38790  validloss -0.64736±0.00000  bestvalidloss -0.75335  last_update 11\n",
      "train: iter 276  trainloss -0.40781  validloss -0.66321±0.00000  bestvalidloss -0.75335  last_update 12\n",
      "train: iter 277  trainloss -0.40873  validloss -0.65082±0.00000  bestvalidloss -0.75335  last_update 13\n",
      "train: iter 278  trainloss -0.46048  validloss -0.66400±0.00000  bestvalidloss -0.75335  last_update 14\n",
      "train: iter 279  trainloss -0.35514  validloss -0.74397±0.00000  bestvalidloss -0.75335  last_update 15\n",
      "train: iter 280  trainloss -0.43532  validloss -0.69724±0.00000  bestvalidloss -0.75335  last_update 16\n",
      "train: iter 281  trainloss -0.37551  validloss -0.71473±0.00000  bestvalidloss -0.75335  last_update 17\n",
      "train: iter 282  trainloss -0.41511  validloss -0.70499±0.00000  bestvalidloss -0.75335  last_update 18\n",
      "train: iter 283  trainloss -0.41535  validloss -0.68758±0.00000  bestvalidloss -0.75335  last_update 19\n",
      "train: iter 284  trainloss -0.39442  validloss -0.68105±0.00000  bestvalidloss -0.75335  last_update 20\n",
      "train: iter 285  trainloss -0.37476  validloss -0.64107±0.00000  bestvalidloss -0.75335  last_update 21\n",
      "train: iter 286  trainloss -0.35309  validloss -0.64664±0.00000  bestvalidloss -0.75335  last_update 22\n",
      "train: iter 287  trainloss -0.38591  validloss -0.58420±0.00000  bestvalidloss -0.75335  last_update 23\n",
      "train: iter 288  trainloss -0.40090  validloss -0.72511±0.00000  bestvalidloss -0.75335  last_update 24\n",
      "train: iter 289  trainloss -0.40620  validloss -0.69635±0.00000  bestvalidloss -0.75335  last_update 25\n",
      "train: iter 290  trainloss -0.40226  validloss -0.69543±0.00000  bestvalidloss -0.75335  last_update 26\n",
      "train: iter 291  trainloss -0.44021  validloss -0.72116±0.00000  bestvalidloss -0.75335  last_update 27\n",
      "train: iter 292  trainloss -0.42426  validloss -0.70090±0.00000  bestvalidloss -0.75335  last_update 28\n",
      "train: iter 293  trainloss -0.41856  validloss -0.68179±0.00000  bestvalidloss -0.75335  last_update 29\n",
      "train: iter 294  trainloss -0.38443  validloss -0.64579±0.00000  bestvalidloss -0.75335  last_update 30\n",
      "train: iter 295  trainloss -0.41995  validloss -0.69590±0.00000  bestvalidloss -0.75335  last_update 31\n",
      "train: iter 296  trainloss -0.43421  validloss -0.69124±0.00000  bestvalidloss -0.75335  last_update 32\n",
      "train: iter 297  trainloss -0.39813  validloss -0.70209±0.00000  bestvalidloss -0.75335  last_update 33\n",
      "train: iter 298  trainloss -0.38923  validloss -0.68730±0.00000  bestvalidloss -0.75335  last_update 34\n",
      "train: iter 299  trainloss -0.41158  validloss -0.69086±0.00000  bestvalidloss -0.75335  last_update 35\n",
      "train: iter 300  trainloss -0.40354  validloss -0.67063±0.00000  bestvalidloss -0.75335  last_update 36\n",
      "train: iter 301  trainloss -0.38289  validloss -0.72051±0.00000  bestvalidloss -0.75335  last_update 37\n",
      "train: iter 302  trainloss -0.37528  validloss -0.68249±0.00000  bestvalidloss -0.75335  last_update 38\n",
      "train: iter 303  trainloss -0.42274  validloss -0.65086±0.00000  bestvalidloss -0.75335  last_update 39\n",
      "train: iter 304  trainloss -0.38379  validloss -0.67016±0.00000  bestvalidloss -0.75335  last_update 40\n",
      "train: iter 305  trainloss -0.41911  validloss -0.70012±0.00000  bestvalidloss -0.75335  last_update 41\n",
      "train: iter 306  trainloss -0.38950  validloss -0.66926±0.00000  bestvalidloss -0.75335  last_update 42\n",
      "train: iter 307  trainloss -0.40763  validloss -0.69126±0.00000  bestvalidloss -0.75335  last_update 43\n",
      "train: iter 308  trainloss -0.41354  validloss -0.69336±0.00000  bestvalidloss -0.75335  last_update 44\n",
      "train: iter 309  trainloss -0.40670  validloss -0.72421±0.00000  bestvalidloss -0.75335  last_update 45\n",
      "train: iter 310  trainloss -0.40118  validloss -0.66628±0.00000  bestvalidloss -0.75335  last_update 46\n",
      "train: iter 311  trainloss -0.39795  validloss -0.60187±0.00000  bestvalidloss -0.75335  last_update 47\n",
      "train: iter 312  trainloss -0.36957  validloss -0.66129±0.00000  bestvalidloss -0.75335  last_update 48\n",
      "train: iter 313  trainloss -0.39476  validloss -0.72004±0.00000  bestvalidloss -0.75335  last_update 49\n",
      "train: iter 314  trainloss -0.41434  validloss -0.70959±0.00000  bestvalidloss -0.75335  last_update 50\n",
      "train: iter 315  trainloss -0.39883  validloss -0.69622±0.00000  bestvalidloss -0.75335  last_update 51\n",
      "train: iter 316  trainloss -0.38460  validloss -0.61623±0.00000  bestvalidloss -0.75335  last_update 52\n",
      "train: iter 317  trainloss -0.39458  validloss -0.70817±0.00000  bestvalidloss -0.75335  last_update 53\n",
      "train: iter 318  trainloss -0.40168  validloss -0.73149±0.00000  bestvalidloss -0.75335  last_update 54\n",
      "train: iter 319  trainloss -0.37553  validloss -0.70126±0.00000  bestvalidloss -0.75335  last_update 55\n",
      "train: iter 320  trainloss -0.39404  validloss -0.71579±0.00000  bestvalidloss -0.75335  last_update 56\n",
      "train: iter 321  trainloss -0.42685  validloss -0.70500±0.00000  bestvalidloss -0.75335  last_update 57\n",
      "train: iter 322  trainloss -0.37609  validloss -0.61103±0.00000  bestvalidloss -0.75335  last_update 58\n",
      "train: iter 323  trainloss -0.37532  validloss -0.70793±0.00000  bestvalidloss -0.75335  last_update 59\n",
      "train: iter 324  trainloss -0.39910  validloss -0.68951±0.00000  bestvalidloss -0.75335  last_update 60\n",
      "train: iter 325  trainloss -0.39730  validloss -0.72151±0.00000  bestvalidloss -0.75335  last_update 61\n",
      "train: iter 326  trainloss -0.45044  validloss -0.73137±0.00000  bestvalidloss -0.75335  last_update 62\n",
      "train: iter 327  trainloss -0.38407  validloss -0.67784±0.00000  bestvalidloss -0.75335  last_update 63\n",
      "train: iter 328  trainloss -0.40031  validloss -0.68331±0.00000  bestvalidloss -0.75335  last_update 64\n",
      "train: iter 329  trainloss -0.40845  validloss -0.63539±0.00000  bestvalidloss -0.75335  last_update 65\n",
      "train: iter 330  trainloss -0.40021  validloss -0.67269±0.00000  bestvalidloss -0.75335  last_update 66\n",
      "train: iter 331  trainloss -0.35741  validloss -0.67165±0.00000  bestvalidloss -0.75335  last_update 67\n",
      "train: iter 332  trainloss -0.37631  validloss -0.69273±0.00000  bestvalidloss -0.75335  last_update 68\n",
      "train: iter 333  trainloss -0.41498  validloss -0.71425±0.00000  bestvalidloss -0.75335  last_update 69\n",
      "train: iter 334  trainloss -0.40128  validloss -0.76164±0.00000  bestvalidloss -0.76164  last_update 0\n",
      "train: iter 335  trainloss -0.39672  validloss -0.73134±0.00000  bestvalidloss -0.76164  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 336  trainloss -0.40766  validloss -0.67319±0.00000  bestvalidloss -0.76164  last_update 2\n",
      "train: iter 337  trainloss -0.39237  validloss -0.69515±0.00000  bestvalidloss -0.76164  last_update 3\n",
      "train: iter 338  trainloss -0.41101  validloss -0.71869±0.00000  bestvalidloss -0.76164  last_update 4\n",
      "train: iter 339  trainloss -0.39209  validloss -0.70157±0.00000  bestvalidloss -0.76164  last_update 5\n",
      "train: iter 340  trainloss -0.38341  validloss -0.61518±0.00000  bestvalidloss -0.76164  last_update 6\n",
      "train: iter 341  trainloss -0.41881  validloss -0.68908±0.00000  bestvalidloss -0.76164  last_update 7\n",
      "train: iter 342  trainloss -0.37586  validloss -0.64707±0.00000  bestvalidloss -0.76164  last_update 8\n",
      "train: iter 343  trainloss -0.40417  validloss -0.67977±0.00000  bestvalidloss -0.76164  last_update 9\n",
      "train: iter 344  trainloss -0.41633  validloss -0.69649±0.00000  bestvalidloss -0.76164  last_update 10\n",
      "train: iter 345  trainloss -0.39358  validloss -0.67395±0.00000  bestvalidloss -0.76164  last_update 11\n",
      "train: iter 346  trainloss -0.39481  validloss -0.71660±0.00000  bestvalidloss -0.76164  last_update 12\n",
      "train: iter 347  trainloss -0.42142  validloss -0.65905±0.00000  bestvalidloss -0.76164  last_update 13\n",
      "train: iter 348  trainloss -0.36544  validloss -0.72520±0.00000  bestvalidloss -0.76164  last_update 14\n",
      "train: iter 349  trainloss -0.43023  validloss -0.66796±0.00000  bestvalidloss -0.76164  last_update 15\n",
      "train: iter 350  trainloss -0.39114  validloss -0.70431±0.00000  bestvalidloss -0.76164  last_update 16\n",
      "train: iter 351  trainloss -0.37807  validloss -0.62204±0.00000  bestvalidloss -0.76164  last_update 17\n",
      "train: iter 352  trainloss -0.37811  validloss -0.67005±0.00000  bestvalidloss -0.76164  last_update 18\n",
      "train: iter 353  trainloss -0.43112  validloss -0.69415±0.00000  bestvalidloss -0.76164  last_update 19\n",
      "train: iter 354  trainloss -0.38105  validloss -0.68011±0.00000  bestvalidloss -0.76164  last_update 20\n",
      "train: iter 355  trainloss -0.39358  validloss -0.66237±0.00000  bestvalidloss -0.76164  last_update 21\n",
      "train: iter 356  trainloss -0.42616  validloss -0.71304±0.00000  bestvalidloss -0.76164  last_update 22\n",
      "train: iter 357  trainloss -0.40654  validloss -0.70606±0.00000  bestvalidloss -0.76164  last_update 23\n",
      "train: iter 358  trainloss -0.36988  validloss -0.69773±0.00000  bestvalidloss -0.76164  last_update 24\n",
      "train: iter 359  trainloss -0.37700  validloss -0.67877±0.00000  bestvalidloss -0.76164  last_update 25\n",
      "train: iter 360  trainloss -0.41113  validloss -0.71766±0.00000  bestvalidloss -0.76164  last_update 26\n",
      "train: iter 361  trainloss -0.37901  validloss -0.67772±0.00000  bestvalidloss -0.76164  last_update 27\n",
      "train: iter 362  trainloss -0.38931  validloss -0.68514±0.00000  bestvalidloss -0.76164  last_update 28\n",
      "train: iter 363  trainloss -0.38444  validloss -0.72103±0.00000  bestvalidloss -0.76164  last_update 29\n",
      "train: iter 364  trainloss -0.41223  validloss -0.67070±0.00000  bestvalidloss -0.76164  last_update 30\n",
      "train: iter 365  trainloss -0.41354  validloss -0.69054±0.00000  bestvalidloss -0.76164  last_update 31\n",
      "train: iter 366  trainloss -0.41616  validloss -0.71032±0.00000  bestvalidloss -0.76164  last_update 32\n",
      "train: iter 367  trainloss -0.39733  validloss -0.64868±0.00000  bestvalidloss -0.76164  last_update 33\n",
      "train: iter 368  trainloss -0.39166  validloss -0.73987±0.00000  bestvalidloss -0.76164  last_update 34\n",
      "train: iter 369  trainloss -0.41789  validloss -0.72382±0.00000  bestvalidloss -0.76164  last_update 35\n",
      "train: iter 370  trainloss -0.39602  validloss -0.71110±0.00000  bestvalidloss -0.76164  last_update 36\n",
      "train: iter 371  trainloss -0.42711  validloss -0.67825±0.00000  bestvalidloss -0.76164  last_update 37\n",
      "train: iter 372  trainloss -0.40338  validloss -0.75266±0.00000  bestvalidloss -0.76164  last_update 38\n",
      "train: iter 373  trainloss -0.40222  validloss -0.67752±0.00000  bestvalidloss -0.76164  last_update 39\n",
      "train: iter 374  trainloss -0.41626  validloss -0.65203±0.00000  bestvalidloss -0.76164  last_update 40\n",
      "train: iter 375  trainloss -0.43864  validloss -0.65967±0.00000  bestvalidloss -0.76164  last_update 41\n",
      "train: iter 376  trainloss -0.40888  validloss -0.66181±0.00000  bestvalidloss -0.76164  last_update 42\n",
      "train: iter 377  trainloss -0.42298  validloss -0.71393±0.00000  bestvalidloss -0.76164  last_update 43\n",
      "train: iter 378  trainloss -0.38406  validloss -0.71288±0.00000  bestvalidloss -0.76164  last_update 44\n",
      "train: iter 379  trainloss -0.41695  validloss -0.61192±0.00000  bestvalidloss -0.76164  last_update 45\n",
      "train: iter 380  trainloss -0.38637  validloss -0.69869±0.00000  bestvalidloss -0.76164  last_update 46\n",
      "train: iter 381  trainloss -0.40462  validloss -0.72183±0.00000  bestvalidloss -0.76164  last_update 47\n",
      "train: iter 382  trainloss -0.40968  validloss -0.68347±0.00000  bestvalidloss -0.76164  last_update 48\n",
      "train: iter 383  trainloss -0.41129  validloss -0.71573±0.00000  bestvalidloss -0.76164  last_update 49\n",
      "train: iter 384  trainloss -0.36941  validloss -0.67379±0.00000  bestvalidloss -0.76164  last_update 50\n",
      "train: iter 385  trainloss -0.42548  validloss -0.65784±0.00000  bestvalidloss -0.76164  last_update 51\n",
      "train: iter 386  trainloss -0.38693  validloss -0.64993±0.00000  bestvalidloss -0.76164  last_update 52\n",
      "train: iter 387  trainloss -0.37626  validloss -0.67861±0.00000  bestvalidloss -0.76164  last_update 53\n",
      "train: iter 388  trainloss -0.39384  validloss -0.67593±0.00000  bestvalidloss -0.76164  last_update 54\n",
      "train: iter 389  trainloss -0.41706  validloss -0.73111±0.00000  bestvalidloss -0.76164  last_update 55\n",
      "train: iter 390  trainloss -0.40711  validloss -0.71173±0.00000  bestvalidloss -0.76164  last_update 56\n",
      "train: iter 391  trainloss -0.35289  validloss -0.68330±0.00000  bestvalidloss -0.76164  last_update 57\n",
      "train: iter 392  trainloss -0.41834  validloss -0.67734±0.00000  bestvalidloss -0.76164  last_update 58\n",
      "train: iter 393  trainloss -0.39606  validloss -0.68372±0.00000  bestvalidloss -0.76164  last_update 59\n",
      "train: iter 394  trainloss -0.43055  validloss -0.65808±0.00000  bestvalidloss -0.76164  last_update 60\n",
      "train: iter 395  trainloss -0.38920  validloss -0.68503±0.00000  bestvalidloss -0.76164  last_update 61\n",
      "train: iter 396  trainloss -0.40414  validloss -0.69463±0.00000  bestvalidloss -0.76164  last_update 62\n",
      "train: iter 397  trainloss -0.39571  validloss -0.66272±0.00000  bestvalidloss -0.76164  last_update 63\n",
      "train: iter 398  trainloss -0.38629  validloss -0.67090±0.00000  bestvalidloss -0.76164  last_update 64\n",
      "train: iter 399  trainloss -0.43091  validloss -0.59776±0.00000  bestvalidloss -0.76164  last_update 65\n",
      "train: iter 400  trainloss -0.42320  validloss -0.74955±0.00000  bestvalidloss -0.76164  last_update 66\n",
      "train: iter 401  trainloss -0.42835  validloss -0.62290±0.00000  bestvalidloss -0.76164  last_update 67\n",
      "train: iter 402  trainloss -0.39609  validloss -0.67795±0.00000  bestvalidloss -0.76164  last_update 68\n",
      "train: iter 403  trainloss -0.41105  validloss -0.70369±0.00000  bestvalidloss -0.76164  last_update 69\n",
      "train: iter 404  trainloss -0.40413  validloss -0.74271±0.00000  bestvalidloss -0.76164  last_update 70\n",
      "train: iter 405  trainloss -0.42007  validloss -0.66944±0.00000  bestvalidloss -0.76164  last_update 71\n",
      "train: iter 406  trainloss -0.38314  validloss -0.72015±0.00000  bestvalidloss -0.76164  last_update 72\n",
      "train: iter 407  trainloss -0.39258  validloss -0.74144±0.00000  bestvalidloss -0.76164  last_update 73\n",
      "train: iter 408  trainloss -0.40405  validloss -0.64660±0.00000  bestvalidloss -0.76164  last_update 74\n",
      "train: iter 409  trainloss -0.39695  validloss -0.70270±0.00000  bestvalidloss -0.76164  last_update 75\n",
      "train: iter 410  trainloss -0.43075  validloss -0.71420±0.00000  bestvalidloss -0.76164  last_update 76\n",
      "train: iter 411  trainloss -0.42844  validloss -0.70908±0.00000  bestvalidloss -0.76164  last_update 77\n",
      "train: iter 412  trainloss -0.40664  validloss -0.71001±0.00000  bestvalidloss -0.76164  last_update 78\n",
      "train: iter 413  trainloss -0.38746  validloss -0.68012±0.00000  bestvalidloss -0.76164  last_update 79\n",
      "train: iter 414  trainloss -0.40519  validloss -0.66610±0.00000  bestvalidloss -0.76164  last_update 80\n",
      "train: iter 415  trainloss -0.40034  validloss -0.70012±0.00000  bestvalidloss -0.76164  last_update 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 416  trainloss -0.42645  validloss -0.61552±0.00000  bestvalidloss -0.76164  last_update 82\n",
      "train: iter 417  trainloss -0.38054  validloss -0.74156±0.00000  bestvalidloss -0.76164  last_update 83\n",
      "train: iter 418  trainloss -0.41912  validloss -0.67138±0.00000  bestvalidloss -0.76164  last_update 84\n",
      "train: iter 419  trainloss -0.42384  validloss -0.72562±0.00000  bestvalidloss -0.76164  last_update 85\n",
      "train: iter 420  trainloss -0.39326  validloss -0.66618±0.00000  bestvalidloss -0.76164  last_update 86\n",
      "train: iter 421  trainloss -0.38991  validloss -0.66346±0.00000  bestvalidloss -0.76164  last_update 87\n",
      "train: iter 422  trainloss -0.44602  validloss -0.70310±0.00000  bestvalidloss -0.76164  last_update 88\n",
      "train: iter 423  trainloss -0.38955  validloss -0.70156±0.00000  bestvalidloss -0.76164  last_update 89\n",
      "train: iter 424  trainloss -0.39635  validloss -0.69202±0.00000  bestvalidloss -0.76164  last_update 90\n",
      "train: iter 425  trainloss -0.39250  validloss -0.73842±0.00000  bestvalidloss -0.76164  last_update 91\n",
      "train: iter 426  trainloss -0.39601  validloss -0.69305±0.00000  bestvalidloss -0.76164  last_update 92\n",
      "train: iter 427  trainloss -0.41186  validloss -0.59681±0.00000  bestvalidloss -0.76164  last_update 93\n",
      "train: iter 428  trainloss -0.36786  validloss -0.68369±0.00000  bestvalidloss -0.76164  last_update 94\n",
      "train: iter 429  trainloss -0.42443  validloss -0.67049±0.00000  bestvalidloss -0.76164  last_update 95\n",
      "train: iter 430  trainloss -0.38436  validloss -0.70623±0.00000  bestvalidloss -0.76164  last_update 96\n",
      "train: iter 431  trainloss -0.38085  validloss -0.66689±0.00000  bestvalidloss -0.76164  last_update 97\n",
      "train: iter 432  trainloss -0.45508  validloss -0.64722±0.00000  bestvalidloss -0.76164  last_update 98\n",
      "train: iter 433  trainloss -0.40495  validloss -0.69470±0.00000  bestvalidloss -0.76164  last_update 99\n",
      "train: iter 434  trainloss -0.42708  validloss -0.71614±0.00000  bestvalidloss -0.76164  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.8279, -0.3789, -3.8005, -2.6717], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 60.73382  validloss 70.59223±0.00000  bestvalidloss 70.59223  last_update 0\n",
      "train: iter 1  trainloss 42.68284  validloss 53.01281±0.00000  bestvalidloss 53.01281  last_update 0\n",
      "train: iter 2  trainloss 29.80274  validloss 36.29800±0.00000  bestvalidloss 36.29800  last_update 0\n",
      "train: iter 3  trainloss 22.02533  validloss 26.52244±0.00000  bestvalidloss 26.52244  last_update 0\n",
      "train: iter 4  trainloss 17.02197  validloss 20.39461±0.00000  bestvalidloss 20.39461  last_update 0\n",
      "train: iter 5  trainloss 13.93094  validloss 16.48977±0.00000  bestvalidloss 16.48977  last_update 0\n",
      "train: iter 6  trainloss 11.77662  validloss 13.87122±0.00000  bestvalidloss 13.87122  last_update 0\n",
      "train: iter 7  trainloss 10.33078  validloss 12.05871±0.00000  bestvalidloss 12.05871  last_update 0\n",
      "train: iter 8  trainloss 9.23660  validloss 10.87977±0.00000  bestvalidloss 10.87977  last_update 0\n",
      "train: iter 9  trainloss 8.53417  validloss 9.73301±0.00000  bestvalidloss 9.73301  last_update 0\n",
      "train: iter 10  trainloss 8.05838  validloss 9.01455±0.00000  bestvalidloss 9.01455  last_update 0\n",
      "train: iter 11  trainloss 7.47864  validloss 8.33355±0.00000  bestvalidloss 8.33355  last_update 0\n",
      "train: iter 12  trainloss 7.22718  validloss 7.86707±0.00000  bestvalidloss 7.86707  last_update 0\n",
      "train: iter 13  trainloss 6.85947  validloss 7.44222±0.00000  bestvalidloss 7.44222  last_update 0\n",
      "train: iter 14  trainloss 6.59045  validloss 7.15976±0.00000  bestvalidloss 7.15976  last_update 0\n",
      "train: iter 15  trainloss 6.36590  validloss 6.70551±0.00000  bestvalidloss 6.70551  last_update 0\n",
      "train: iter 16  trainloss 6.18276  validloss 6.41811±0.00000  bestvalidloss 6.41811  last_update 0\n",
      "train: iter 17  trainloss 6.05914  validloss 6.17559±0.00000  bestvalidloss 6.17559  last_update 0\n",
      "train: iter 18  trainloss 5.86896  validloss 5.99631±0.00000  bestvalidloss 5.99631  last_update 0\n",
      "train: iter 19  trainloss 5.74266  validloss 5.82739±0.00000  bestvalidloss 5.82739  last_update 0\n",
      "train: iter 20  trainloss 5.66180  validloss 5.67321±0.00000  bestvalidloss 5.67321  last_update 0\n",
      "train: iter 21  trainloss 5.54071  validloss 5.54065±0.00000  bestvalidloss 5.54065  last_update 0\n",
      "train: iter 22  trainloss 5.44899  validloss 5.50008±0.00000  bestvalidloss 5.50008  last_update 0\n",
      "train: iter 23  trainloss 5.37871  validloss 5.29004±0.00000  bestvalidloss 5.29004  last_update 0\n",
      "train: iter 24  trainloss 5.30348  validloss 5.17780±0.00000  bestvalidloss 5.17780  last_update 0\n",
      "train: iter 25  trainloss 5.26618  validloss 5.00884±0.00000  bestvalidloss 5.00884  last_update 0\n",
      "train: iter 26  trainloss 5.16883  validloss 5.05181±0.00000  bestvalidloss 5.00884  last_update 1\n",
      "train: iter 27  trainloss 5.11119  validloss 5.03104±0.00000  bestvalidloss 5.00884  last_update 2\n",
      "train: iter 28  trainloss 5.10048  validloss 4.93697±0.00000  bestvalidloss 4.93697  last_update 0\n",
      "train: iter 29  trainloss 5.05001  validloss 4.98074±0.00000  bestvalidloss 4.93697  last_update 1\n",
      "train: iter 30  trainloss 4.99150  validloss 4.88766±0.00000  bestvalidloss 4.88766  last_update 0\n",
      "train: iter 31  trainloss 4.94664  validloss 4.86203±0.00000  bestvalidloss 4.86203  last_update 0\n",
      "train: iter 32  trainloss 4.94498  validloss 4.67783±0.00000  bestvalidloss 4.67783  last_update 0\n",
      "train: iter 33  trainloss 4.86222  validloss 4.85335±0.00000  bestvalidloss 4.67783  last_update 1\n",
      "train: iter 34  trainloss 4.85093  validloss 4.76481±0.00000  bestvalidloss 4.67783  last_update 2\n",
      "train: iter 35  trainloss 4.88372  validloss 4.73408±0.00000  bestvalidloss 4.67783  last_update 3\n",
      "train: iter 36  trainloss 4.79387  validloss 4.65351±0.00000  bestvalidloss 4.65351  last_update 0\n",
      "train: iter 37  trainloss 4.79706  validloss 4.84258±0.00000  bestvalidloss 4.65351  last_update 1\n",
      "train: iter 38  trainloss 4.72883  validloss 4.64033±0.00000  bestvalidloss 4.64033  last_update 0\n",
      "train: iter 39  trainloss 4.70492  validloss 4.69877±0.00000  bestvalidloss 4.64033  last_update 1\n",
      "train: iter 40  trainloss 4.67643  validloss 4.55266±0.00000  bestvalidloss 4.55266  last_update 0\n",
      "train: iter 41  trainloss 4.66056  validloss 4.56415±0.00000  bestvalidloss 4.55266  last_update 1\n",
      "train: iter 42  trainloss 4.69078  validloss 4.58533±0.00000  bestvalidloss 4.55266  last_update 2\n",
      "train: iter 43  trainloss 4.62601  validloss 4.61023±0.00000  bestvalidloss 4.55266  last_update 3\n",
      "train: iter 44  trainloss 4.64720  validloss 4.56214±0.00000  bestvalidloss 4.55266  last_update 4\n",
      "train: iter 45  trainloss 4.61959  validloss 4.64719±0.00000  bestvalidloss 4.55266  last_update 5\n",
      "train: iter 46  trainloss 4.59140  validloss 4.59846±0.00000  bestvalidloss 4.55266  last_update 6\n",
      "train: iter 47  trainloss 4.60444  validloss 4.46698±0.00000  bestvalidloss 4.46698  last_update 0\n",
      "train: iter 48  trainloss 4.59186  validloss 4.62271±0.00000  bestvalidloss 4.46698  last_update 1\n",
      "train: iter 49  trainloss 4.58658  validloss 4.67666±0.00000  bestvalidloss 4.46698  last_update 2\n",
      "train: iter 50  trainloss 4.61560  validloss 4.56804±0.00000  bestvalidloss 4.46698  last_update 3\n",
      "train: iter 51  trainloss 4.57053  validloss 4.65665±0.00000  bestvalidloss 4.46698  last_update 4\n",
      "train: iter 52  trainloss 4.52301  validloss 4.65685±0.00000  bestvalidloss 4.46698  last_update 5\n",
      "train: iter 53  trainloss 4.56427  validloss 4.54838±0.00000  bestvalidloss 4.46698  last_update 6\n",
      "train: iter 54  trainloss 4.52895  validloss 4.57683±0.00000  bestvalidloss 4.46698  last_update 7\n",
      "train: iter 55  trainloss 4.51634  validloss 4.59395±0.00000  bestvalidloss 4.46698  last_update 8\n",
      "train: iter 56  trainloss 4.49611  validloss 4.48618±0.00000  bestvalidloss 4.46698  last_update 9\n",
      "train: iter 57  trainloss 4.52786  validloss 4.42011±0.00000  bestvalidloss 4.42011  last_update 0\n",
      "train: iter 58  trainloss 4.47703  validloss 4.48996±0.00000  bestvalidloss 4.42011  last_update 1\n",
      "train: iter 59  trainloss 4.46344  validloss 4.41682±0.00000  bestvalidloss 4.41682  last_update 0\n",
      "train: iter 60  trainloss 4.44464  validloss 4.31311±0.00000  bestvalidloss 4.31311  last_update 0\n",
      "train: iter 61  trainloss 4.43253  validloss 4.30621±0.00000  bestvalidloss 4.30621  last_update 0\n",
      "train: iter 62  trainloss 4.48532  validloss 4.47337±0.00000  bestvalidloss 4.30621  last_update 1\n",
      "train: iter 63  trainloss 4.40072  validloss 4.24714±0.00000  bestvalidloss 4.24714  last_update 0\n",
      "train: iter 64  trainloss 4.43730  validloss 4.51717±0.00000  bestvalidloss 4.24714  last_update 1\n",
      "train: iter 65  trainloss 4.38423  validloss 4.21440±0.00000  bestvalidloss 4.21440  last_update 0\n",
      "train: iter 66  trainloss 4.37076  validloss 4.29426±0.00000  bestvalidloss 4.21440  last_update 1\n",
      "train: iter 67  trainloss 4.32696  validloss 4.32037±0.00000  bestvalidloss 4.21440  last_update 2\n",
      "train: iter 68  trainloss 4.32941  validloss 4.16178±0.00000  bestvalidloss 4.16178  last_update 0\n",
      "train: iter 69  trainloss 4.27209  validloss 4.11373±0.00000  bestvalidloss 4.11373  last_update 0\n",
      "train: iter 70  trainloss 4.33430  validloss 4.37716±0.00000  bestvalidloss 4.11373  last_update 1\n",
      "train: iter 71  trainloss 4.29218  validloss 4.06632±0.00000  bestvalidloss 4.06632  last_update 0\n",
      "train: iter 72  trainloss 4.24298  validloss 4.18972±0.00000  bestvalidloss 4.06632  last_update 1\n",
      "train: iter 73  trainloss 4.26219  validloss 4.04487±0.00000  bestvalidloss 4.04487  last_update 0\n",
      "train: iter 74  trainloss 4.22547  validloss 4.05699±0.00000  bestvalidloss 4.04487  last_update 1\n",
      "train: iter 75  trainloss 4.21565  validloss 4.01022±0.00000  bestvalidloss 4.01022  last_update 0\n",
      "train: iter 76  trainloss 4.20825  validloss 4.07909±0.00000  bestvalidloss 4.01022  last_update 1\n",
      "train: iter 77  trainloss 4.15838  validloss 4.10219±0.00000  bestvalidloss 4.01022  last_update 2\n",
      "train: iter 78  trainloss 4.15881  validloss 4.02383±0.00000  bestvalidloss 4.01022  last_update 3\n",
      "train: iter 79  trainloss 4.17789  validloss 4.12778±0.00000  bestvalidloss 4.01022  last_update 4\n",
      "train: iter 80  trainloss 4.16776  validloss 4.23391±0.00000  bestvalidloss 4.01022  last_update 5\n",
      "train: iter 81  trainloss 4.15938  validloss 3.95451±0.00000  bestvalidloss 3.95451  last_update 0\n",
      "train: iter 82  trainloss 4.15651  validloss 4.02224±0.00000  bestvalidloss 3.95451  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 4.17784  validloss 3.92713±0.00000  bestvalidloss 3.92713  last_update 0\n",
      "train: iter 84  trainloss 4.17085  validloss 4.13368±0.00000  bestvalidloss 3.92713  last_update 1\n",
      "train: iter 85  trainloss 4.11794  validloss 4.03736±0.00000  bestvalidloss 3.92713  last_update 2\n",
      "train: iter 86  trainloss 4.15828  validloss 3.94111±0.00000  bestvalidloss 3.92713  last_update 3\n",
      "train: iter 87  trainloss 4.14047  validloss 4.07459±0.00000  bestvalidloss 3.92713  last_update 4\n",
      "train: iter 88  trainloss 4.13454  validloss 3.98636±0.00000  bestvalidloss 3.92713  last_update 5\n",
      "train: iter 89  trainloss 4.11822  validloss 4.11482±0.00000  bestvalidloss 3.92713  last_update 6\n",
      "train: iter 90  trainloss 4.13371  validloss 3.98406±0.00000  bestvalidloss 3.92713  last_update 7\n",
      "train: iter 91  trainloss 4.20559  validloss 4.24096±0.00000  bestvalidloss 3.92713  last_update 8\n",
      "train: iter 92  trainloss 4.13931  validloss 4.00628±0.00000  bestvalidloss 3.92713  last_update 9\n",
      "train: iter 93  trainloss 4.12549  validloss 4.00836±0.00000  bestvalidloss 3.92713  last_update 10\n",
      "train: iter 94  trainloss 4.11780  validloss 3.92444±0.00000  bestvalidloss 3.92444  last_update 0\n",
      "train: iter 95  trainloss 4.11090  validloss 3.94579±0.00000  bestvalidloss 3.92444  last_update 1\n",
      "train: iter 96  trainloss 4.10643  validloss 3.96198±0.00000  bestvalidloss 3.92444  last_update 2\n",
      "train: iter 97  trainloss 4.12025  validloss 3.97459±0.00000  bestvalidloss 3.92444  last_update 3\n",
      "train: iter 98  trainloss 4.11374  validloss 3.95169±0.00000  bestvalidloss 3.92444  last_update 4\n",
      "train: iter 99  trainloss 4.12256  validloss 4.07596±0.00000  bestvalidloss 3.92444  last_update 5\n",
      "train: iter 100  trainloss 4.09043  validloss 3.91575±0.00000  bestvalidloss 3.91575  last_update 0\n",
      "train: iter 101  trainloss 4.08718  validloss 3.96939±0.00000  bestvalidloss 3.91575  last_update 1\n",
      "train: iter 102  trainloss 4.11181  validloss 4.09450±0.00000  bestvalidloss 3.91575  last_update 2\n",
      "train: iter 103  trainloss 4.08167  validloss 3.91997±0.00000  bestvalidloss 3.91575  last_update 3\n",
      "train: iter 104  trainloss 4.12450  validloss 3.82067±0.00000  bestvalidloss 3.82067  last_update 0\n",
      "train: iter 105  trainloss 4.12240  validloss 4.11997±0.00000  bestvalidloss 3.82067  last_update 1\n",
      "train: iter 106  trainloss 4.07599  validloss 3.99558±0.00000  bestvalidloss 3.82067  last_update 2\n",
      "train: iter 107  trainloss 4.08739  validloss 4.02599±0.00000  bestvalidloss 3.82067  last_update 3\n",
      "train: iter 108  trainloss 4.08959  validloss 3.90879±0.00000  bestvalidloss 3.82067  last_update 4\n",
      "train: iter 109  trainloss 4.11217  validloss 3.88952±0.00000  bestvalidloss 3.82067  last_update 5\n",
      "train: iter 110  trainloss 4.08888  validloss 3.90742±0.00000  bestvalidloss 3.82067  last_update 6\n",
      "train: iter 111  trainloss 4.08633  validloss 3.98264±0.00000  bestvalidloss 3.82067  last_update 7\n",
      "train: iter 112  trainloss 4.13071  validloss 4.01323±0.00000  bestvalidloss 3.82067  last_update 8\n",
      "train: iter 113  trainloss 4.10831  validloss 4.00224±0.00000  bestvalidloss 3.82067  last_update 9\n",
      "train: iter 114  trainloss 4.06408  validloss 4.03176±0.00000  bestvalidloss 3.82067  last_update 10\n",
      "train: iter 115  trainloss 4.09287  validloss 3.97928±0.00000  bestvalidloss 3.82067  last_update 11\n",
      "train: iter 116  trainloss 4.10357  validloss 4.18877±0.00000  bestvalidloss 3.82067  last_update 12\n",
      "train: iter 117  trainloss 4.12010  validloss 4.09903±0.00000  bestvalidloss 3.82067  last_update 13\n",
      "train: iter 118  trainloss 4.06822  validloss 4.04284±0.00000  bestvalidloss 3.82067  last_update 14\n",
      "train: iter 119  trainloss 4.04184  validloss 4.09163±0.00000  bestvalidloss 3.82067  last_update 15\n",
      "train: iter 120  trainloss 4.06014  validloss 4.14116±0.00000  bestvalidloss 3.82067  last_update 16\n",
      "train: iter 121  trainloss 4.04752  validloss 4.01672±0.00000  bestvalidloss 3.82067  last_update 17\n",
      "train: iter 122  trainloss 4.06210  validloss 3.94605±0.00000  bestvalidloss 3.82067  last_update 18\n",
      "train: iter 123  trainloss 4.06838  validloss 3.95774±0.00000  bestvalidloss 3.82067  last_update 19\n",
      "train: iter 124  trainloss 4.03185  validloss 4.16985±0.00000  bestvalidloss 3.82067  last_update 20\n",
      "train: iter 125  trainloss 4.05478  validloss 4.02237±0.00000  bestvalidloss 3.82067  last_update 21\n",
      "train: iter 126  trainloss 4.04828  validloss 4.13292±0.00000  bestvalidloss 3.82067  last_update 22\n",
      "train: iter 127  trainloss 4.04171  validloss 4.08518±0.00000  bestvalidloss 3.82067  last_update 23\n",
      "train: iter 128  trainloss 4.06766  validloss 4.05367±0.00000  bestvalidloss 3.82067  last_update 24\n",
      "train: iter 129  trainloss 4.00950  validloss 4.01861±0.00000  bestvalidloss 3.82067  last_update 25\n",
      "train: iter 130  trainloss 4.07796  validloss 4.26438±0.00000  bestvalidloss 3.82067  last_update 26\n",
      "train: iter 131  trainloss 4.02199  validloss 3.97124±0.00000  bestvalidloss 3.82067  last_update 27\n",
      "train: iter 132  trainloss 4.03964  validloss 4.12135±0.00000  bestvalidloss 3.82067  last_update 28\n",
      "train: iter 133  trainloss 4.04781  validloss 4.09946±0.00000  bestvalidloss 3.82067  last_update 29\n",
      "train: iter 134  trainloss 4.05767  validloss 4.01585±0.00000  bestvalidloss 3.82067  last_update 30\n",
      "train: iter 135  trainloss 4.05794  validloss 4.16468±0.00000  bestvalidloss 3.82067  last_update 31\n",
      "train: iter 136  trainloss 4.01977  validloss 4.23431±0.00000  bestvalidloss 3.82067  last_update 32\n",
      "train: iter 137  trainloss 4.04952  validloss 4.01739±0.00000  bestvalidloss 3.82067  last_update 33\n",
      "train: iter 138  trainloss 4.09960  validloss 4.02548±0.00000  bestvalidloss 3.82067  last_update 34\n",
      "train: iter 139  trainloss 4.01892  validloss 3.99124±0.00000  bestvalidloss 3.82067  last_update 35\n",
      "train: iter 140  trainloss 4.02041  validloss 4.05026±0.00000  bestvalidloss 3.82067  last_update 36\n",
      "train: iter 141  trainloss 4.07069  validloss 3.96952±0.00000  bestvalidloss 3.82067  last_update 37\n",
      "train: iter 142  trainloss 4.03374  validloss 4.05241±0.00000  bestvalidloss 3.82067  last_update 38\n",
      "train: iter 143  trainloss 4.01895  validloss 4.04439±0.00000  bestvalidloss 3.82067  last_update 39\n",
      "train: iter 144  trainloss 4.05334  validloss 4.12942±0.00000  bestvalidloss 3.82067  last_update 40\n",
      "train: iter 145  trainloss 4.08263  validloss 3.90240±0.00000  bestvalidloss 3.82067  last_update 41\n",
      "train: iter 146  trainloss 4.05385  validloss 4.04689±0.00000  bestvalidloss 3.82067  last_update 42\n",
      "train: iter 147  trainloss 4.04235  validloss 4.11476±0.00000  bestvalidloss 3.82067  last_update 43\n",
      "train: iter 148  trainloss 4.03797  validloss 4.17903±0.00000  bestvalidloss 3.82067  last_update 44\n",
      "train: iter 149  trainloss 4.03300  validloss 4.12222±0.00000  bestvalidloss 3.82067  last_update 45\n",
      "train: iter 150  trainloss 4.05251  validloss 4.20571±0.00000  bestvalidloss 3.82067  last_update 46\n",
      "train: iter 151  trainloss 4.01999  validloss 4.02784±0.00000  bestvalidloss 3.82067  last_update 47\n",
      "train: iter 152  trainloss 4.01965  validloss 4.19052±0.00000  bestvalidloss 3.82067  last_update 48\n",
      "train: iter 153  trainloss 4.05166  validloss 4.00976±0.00000  bestvalidloss 3.82067  last_update 49\n",
      "train: iter 154  trainloss 4.00270  validloss 4.15790±0.00000  bestvalidloss 3.82067  last_update 50\n",
      "train: iter 155  trainloss 4.00963  validloss 4.03881±0.00000  bestvalidloss 3.82067  last_update 51\n",
      "train: iter 156  trainloss 3.98175  validloss 4.17229±0.00000  bestvalidloss 3.82067  last_update 52\n",
      "train: iter 157  trainloss 4.04635  validloss 3.94097±0.00000  bestvalidloss 3.82067  last_update 53\n",
      "train: iter 158  trainloss 3.99391  validloss 4.02971±0.00000  bestvalidloss 3.82067  last_update 54\n",
      "train: iter 159  trainloss 4.00036  validloss 4.26074±0.00000  bestvalidloss 3.82067  last_update 55\n",
      "train: iter 160  trainloss 4.02934  validloss 4.14383±0.00000  bestvalidloss 3.82067  last_update 56\n",
      "train: iter 161  trainloss 4.03581  validloss 4.01622±0.00000  bestvalidloss 3.82067  last_update 57\n",
      "train: iter 162  trainloss 4.03334  validloss 4.07923±0.00000  bestvalidloss 3.82067  last_update 58\n",
      "train: iter 163  trainloss 3.99275  validloss 4.01301±0.00000  bestvalidloss 3.82067  last_update 59\n",
      "train: iter 164  trainloss 4.03389  validloss 3.98923±0.00000  bestvalidloss 3.82067  last_update 60\n",
      "train: iter 165  trainloss 3.98857  validloss 4.00309±0.00000  bestvalidloss 3.82067  last_update 61\n",
      "train: iter 166  trainloss 3.98685  validloss 4.10377±0.00000  bestvalidloss 3.82067  last_update 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 4.01850  validloss 4.19165±0.00000  bestvalidloss 3.82067  last_update 63\n",
      "train: iter 168  trainloss 4.01128  validloss 4.21392±0.00000  bestvalidloss 3.82067  last_update 64\n",
      "train: iter 169  trainloss 4.02181  validloss 3.99897±0.00000  bestvalidloss 3.82067  last_update 65\n",
      "train: iter 170  trainloss 3.97786  validloss 4.11344±0.00000  bestvalidloss 3.82067  last_update 66\n",
      "train: iter 171  trainloss 4.00115  validloss 4.13885±0.00000  bestvalidloss 3.82067  last_update 67\n",
      "train: iter 172  trainloss 3.96536  validloss 3.97732±0.00000  bestvalidloss 3.82067  last_update 68\n",
      "train: iter 173  trainloss 4.03147  validloss 4.16821±0.00000  bestvalidloss 3.82067  last_update 69\n",
      "train: iter 174  trainloss 4.04018  validloss 4.08734±0.00000  bestvalidloss 3.82067  last_update 70\n",
      "train: iter 175  trainloss 4.06910  validloss 4.02147±0.00000  bestvalidloss 3.82067  last_update 71\n",
      "train: iter 176  trainloss 3.99374  validloss 4.12394±0.00000  bestvalidloss 3.82067  last_update 72\n",
      "train: iter 177  trainloss 4.01979  validloss 4.00825±0.00000  bestvalidloss 3.82067  last_update 73\n",
      "train: iter 178  trainloss 4.03994  validloss 4.21136±0.00000  bestvalidloss 3.82067  last_update 74\n",
      "train: iter 179  trainloss 3.99362  validloss 4.04431±0.00000  bestvalidloss 3.82067  last_update 75\n",
      "train: iter 180  trainloss 3.95693  validloss 3.94022±0.00000  bestvalidloss 3.82067  last_update 76\n",
      "train: iter 181  trainloss 3.91394  validloss 4.09605±0.00000  bestvalidloss 3.82067  last_update 77\n",
      "train: iter 182  trainloss 3.95738  validloss 4.05202±0.00000  bestvalidloss 3.82067  last_update 78\n",
      "train: iter 183  trainloss 3.97889  validloss 4.28231±0.00000  bestvalidloss 3.82067  last_update 79\n",
      "train: iter 184  trainloss 3.97467  validloss 4.07442±0.00000  bestvalidloss 3.82067  last_update 80\n",
      "train: iter 185  trainloss 3.97885  validloss 4.04429±0.00000  bestvalidloss 3.82067  last_update 81\n",
      "train: iter 186  trainloss 3.97576  validloss 4.12998±0.00000  bestvalidloss 3.82067  last_update 82\n",
      "train: iter 187  trainloss 4.02456  validloss 3.95558±0.00000  bestvalidloss 3.82067  last_update 83\n",
      "train: iter 188  trainloss 3.98242  validloss 3.96311±0.00000  bestvalidloss 3.82067  last_update 84\n",
      "train: iter 189  trainloss 3.99700  validloss 4.01020±0.00000  bestvalidloss 3.82067  last_update 85\n",
      "train: iter 190  trainloss 3.98055  validloss 3.96803±0.00000  bestvalidloss 3.82067  last_update 86\n",
      "train: iter 191  trainloss 3.95868  validloss 4.01446±0.00000  bestvalidloss 3.82067  last_update 87\n",
      "train: iter 192  trainloss 3.99308  validloss 4.21793±0.00000  bestvalidloss 3.82067  last_update 88\n",
      "train: iter 193  trainloss 3.99757  validloss 4.10756±0.00000  bestvalidloss 3.82067  last_update 89\n",
      "train: iter 194  trainloss 4.00761  validloss 4.19548±0.00000  bestvalidloss 3.82067  last_update 90\n",
      "train: iter 195  trainloss 3.97966  validloss 4.10231±0.00000  bestvalidloss 3.82067  last_update 91\n",
      "train: iter 196  trainloss 4.00466  validloss 4.17789±0.00000  bestvalidloss 3.82067  last_update 92\n",
      "train: iter 197  trainloss 3.96992  validloss 4.02644±0.00000  bestvalidloss 3.82067  last_update 93\n",
      "train: iter 198  trainloss 3.93547  validloss 4.24759±0.00000  bestvalidloss 3.82067  last_update 94\n",
      "train: iter 199  trainloss 3.95331  validloss 4.06237±0.00000  bestvalidloss 3.82067  last_update 95\n",
      "train: iter 200  trainloss 3.96757  validloss 4.18911±0.00000  bestvalidloss 3.82067  last_update 96\n",
      "train: iter 201  trainloss 3.97339  validloss 3.99957±0.00000  bestvalidloss 3.82067  last_update 97\n",
      "train: iter 202  trainloss 4.02252  validloss 4.05887±0.00000  bestvalidloss 3.82067  last_update 98\n",
      "train: iter 203  trainloss 3.93034  validloss 4.02635±0.00000  bestvalidloss 3.82067  last_update 99\n",
      "train: iter 204  trainloss 3.94300  validloss 4.21167±0.00000  bestvalidloss 3.82067  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-10.6790)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(5.9352)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.846486179716945\n",
      "tensor([0.1972])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fe71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c7ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11772bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62894c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978fafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
