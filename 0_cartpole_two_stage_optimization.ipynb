{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(6804.9561)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 760.52813  validloss 2236.71072±0.00000  bestvalidloss 2236.71072  last_update 0\n",
      "train: iter 1  trainloss 559.96670  validloss 878.05037±0.00000  bestvalidloss 878.05037  last_update 0\n",
      "train: iter 2  trainloss 262.63987  validloss 879.73117±0.00000  bestvalidloss 878.05037  last_update 1\n",
      "train: iter 3  trainloss 86.78176  validloss 480.16124±0.00000  bestvalidloss 480.16124  last_update 0\n",
      "train: iter 4  trainloss -86.67241  validloss 330.27684±0.00000  bestvalidloss 330.27684  last_update 0\n",
      "train: iter 5  trainloss -262.76072  validloss 225.61911±0.00000  bestvalidloss 225.61911  last_update 0\n",
      "train: iter 6  trainloss -289.50345  validloss 184.50145±0.00000  bestvalidloss 184.50145  last_update 0\n",
      "train: iter 7  trainloss -515.07055  validloss 47.40218±0.00000  bestvalidloss 47.40218  last_update 0\n",
      "train: iter 8  trainloss -572.59722  validloss -266.65000±0.00000  bestvalidloss -266.65000  last_update 0\n",
      "train: iter 9  trainloss -639.20318  validloss -289.28145±0.00000  bestvalidloss -289.28145  last_update 0\n",
      "train: iter 10  trainloss -624.00513  validloss -313.92537±0.00000  bestvalidloss -313.92537  last_update 0\n",
      "train: iter 11  trainloss -672.07965  validloss -354.42961±0.00000  bestvalidloss -354.42961  last_update 0\n",
      "train: iter 12  trainloss -777.12194  validloss -401.53374±0.00000  bestvalidloss -401.53374  last_update 0\n",
      "train: iter 13  trainloss -808.87325  validloss -294.79885±0.00000  bestvalidloss -401.53374  last_update 1\n",
      "train: iter 14  trainloss -832.87914  validloss -503.19097±0.00000  bestvalidloss -503.19097  last_update 0\n",
      "train: iter 15  trainloss -818.79404  validloss -566.27554±0.00000  bestvalidloss -566.27554  last_update 0\n",
      "train: iter 16  trainloss -868.72970  validloss -487.77575±0.00000  bestvalidloss -566.27554  last_update 1\n",
      "train: iter 17  trainloss -852.94545  validloss -615.53137±0.00000  bestvalidloss -615.53137  last_update 0\n",
      "train: iter 18  trainloss -927.84491  validloss -499.50940±0.00000  bestvalidloss -615.53137  last_update 1\n",
      "train: iter 19  trainloss -900.47063  validloss -386.12066±0.00000  bestvalidloss -615.53137  last_update 2\n",
      "train: iter 20  trainloss -932.08073  validloss -582.42987±0.00000  bestvalidloss -615.53137  last_update 3\n",
      "train: iter 21  trainloss -965.15647  validloss -440.43550±0.00000  bestvalidloss -615.53137  last_update 4\n",
      "train: iter 22  trainloss -979.67340  validloss -582.20105±0.00000  bestvalidloss -615.53137  last_update 5\n",
      "train: iter 23  trainloss -981.22680  validloss -562.93986±0.00000  bestvalidloss -615.53137  last_update 6\n",
      "train: iter 24  trainloss -964.40002  validloss -350.83242±0.00000  bestvalidloss -615.53137  last_update 7\n",
      "train: iter 25  trainloss -1029.86693  validloss -573.93592±0.00000  bestvalidloss -615.53137  last_update 8\n",
      "train: iter 26  trainloss -980.61996  validloss -627.47397±0.00000  bestvalidloss -627.47397  last_update 0\n",
      "train: iter 27  trainloss -1005.48332  validloss -704.09353±0.00000  bestvalidloss -704.09353  last_update 0\n",
      "train: iter 28  trainloss -978.60098  validloss -705.54599±0.00000  bestvalidloss -705.54599  last_update 0\n",
      "train: iter 29  trainloss -1083.96868  validloss -609.04134±0.00000  bestvalidloss -705.54599  last_update 1\n",
      "train: iter 30  trainloss -970.03093  validloss -290.66156±0.00000  bestvalidloss -705.54599  last_update 2\n",
      "train: iter 31  trainloss -1134.22518  validloss -724.08805±0.00000  bestvalidloss -724.08805  last_update 0\n",
      "train: iter 32  trainloss -1041.60296  validloss -756.70848±0.00000  bestvalidloss -756.70848  last_update 0\n",
      "train: iter 33  trainloss -1131.48713  validloss -680.54137±0.00000  bestvalidloss -756.70848  last_update 1\n",
      "train: iter 34  trainloss -1208.04469  validloss -855.79476±0.00000  bestvalidloss -855.79476  last_update 0\n",
      "train: iter 35  trainloss -1194.26503  validloss -869.43065±0.00000  bestvalidloss -869.43065  last_update 0\n",
      "train: iter 36  trainloss -850.55023  validloss -448.62743±0.00000  bestvalidloss -869.43065  last_update 1\n",
      "train: iter 37  trainloss -1208.97504  validloss -815.38414±0.00000  bestvalidloss -869.43065  last_update 2\n",
      "train: iter 38  trainloss -1159.86368  validloss -623.50867±0.00000  bestvalidloss -869.43065  last_update 3\n",
      "train: iter 39  trainloss -1242.81288  validloss -823.29673±0.00000  bestvalidloss -869.43065  last_update 4\n",
      "train: iter 40  trainloss -1192.89274  validloss -892.29825±0.00000  bestvalidloss -892.29825  last_update 0\n",
      "train: iter 41  trainloss -1075.24024  validloss -483.26626±0.00000  bestvalidloss -892.29825  last_update 1\n",
      "train: iter 42  trainloss -837.97832  validloss -598.24619±0.00000  bestvalidloss -892.29825  last_update 2\n",
      "train: iter 43  trainloss -1225.41660  validloss -676.41126±0.00000  bestvalidloss -892.29825  last_update 3\n",
      "train: iter 44  trainloss -1305.56118  validloss -795.69672±0.00000  bestvalidloss -892.29825  last_update 4\n",
      "train: iter 45  trainloss -1289.17146  validloss -1028.72371±0.00000  bestvalidloss -1028.72371  last_update 0\n",
      "train: iter 46  trainloss -1353.09052  validloss -904.51269±0.00000  bestvalidloss -1028.72371  last_update 1\n",
      "train: iter 47  trainloss -1364.75339  validloss -914.45817±0.00000  bestvalidloss -1028.72371  last_update 2\n",
      "train: iter 48  trainloss -1208.01605  validloss -933.12307±0.00000  bestvalidloss -1028.72371  last_update 3\n",
      "train: iter 49  trainloss -649.95204  validloss -678.35740±0.00000  bestvalidloss -1028.72371  last_update 4\n",
      "train: iter 50  trainloss -1138.55806  validloss -411.00013±0.00000  bestvalidloss -1028.72371  last_update 5\n",
      "train: iter 51  trainloss -1199.78075  validloss -833.70063±0.00000  bestvalidloss -1028.72371  last_update 6\n",
      "train: iter 52  trainloss -1347.48195  validloss -981.05330±0.00000  bestvalidloss -1028.72371  last_update 7\n",
      "train: iter 53  trainloss -1266.11855  validloss -958.91145±0.00000  bestvalidloss -1028.72371  last_update 8\n",
      "train: iter 54  trainloss -1356.45246  validloss -972.15036±0.00000  bestvalidloss -1028.72371  last_update 9\n",
      "train: iter 55  trainloss -1361.47287  validloss -802.12330±0.00000  bestvalidloss -1028.72371  last_update 10\n",
      "train: iter 56  trainloss -1409.85559  validloss -843.01910±0.00000  bestvalidloss -1028.72371  last_update 11\n",
      "train: iter 57  trainloss -1447.38323  validloss -926.43133±0.00000  bestvalidloss -1028.72371  last_update 12\n",
      "train: iter 58  trainloss -1456.35220  validloss -788.04103±0.00000  bestvalidloss -1028.72371  last_update 13\n",
      "train: iter 59  trainloss -1430.73431  validloss -1018.36398±0.00000  bestvalidloss -1028.72371  last_update 14\n",
      "train: iter 60  trainloss -1378.33418  validloss -1017.70816±0.00000  bestvalidloss -1028.72371  last_update 15\n",
      "train: iter 61  trainloss -1373.59162  validloss -631.35278±0.00000  bestvalidloss -1028.72371  last_update 16\n",
      "train: iter 62  trainloss -1433.80428  validloss -941.42194±0.00000  bestvalidloss -1028.72371  last_update 17\n",
      "train: iter 63  trainloss -1327.14155  validloss -970.64437±0.00000  bestvalidloss -1028.72371  last_update 18\n",
      "train: iter 64  trainloss -1390.75460  validloss -963.85409±0.00000  bestvalidloss -1028.72371  last_update 19\n",
      "train: iter 65  trainloss -1495.12410  validloss -1082.42444±0.00000  bestvalidloss -1082.42444  last_update 0\n",
      "train: iter 66  trainloss -1489.34093  validloss -1058.91525±0.00000  bestvalidloss -1082.42444  last_update 1\n",
      "train: iter 67  trainloss -1518.76012  validloss -1113.06124±0.00000  bestvalidloss -1113.06124  last_update 0\n",
      "train: iter 68  trainloss -1490.60735  validloss -1103.23338±0.00000  bestvalidloss -1113.06124  last_update 1\n",
      "train: iter 69  trainloss -1535.80859  validloss -1100.68438±0.00000  bestvalidloss -1113.06124  last_update 2\n",
      "train: iter 70  trainloss -1507.85864  validloss -1223.45007±0.00000  bestvalidloss -1223.45007  last_update 0\n",
      "train: iter 71  trainloss -1529.50692  validloss -1184.82103±0.00000  bestvalidloss -1223.45007  last_update 1\n",
      "train: iter 72  trainloss -1519.54818  validloss -1083.38586±0.00000  bestvalidloss -1223.45007  last_update 2\n",
      "train: iter 73  trainloss -1551.54701  validloss -1174.53000±0.00000  bestvalidloss -1223.45007  last_update 3\n",
      "train: iter 74  trainloss -1365.71761  validloss -843.09702±0.00000  bestvalidloss -1223.45007  last_update 4\n",
      "train: iter 75  trainloss -1507.10498  validloss -769.91662±0.00000  bestvalidloss -1223.45007  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 76  trainloss -1522.47808  validloss -1264.64537±0.00000  bestvalidloss -1264.64537  last_update 0\n",
      "train: iter 77  trainloss -1593.83716  validloss -1252.85492±0.00000  bestvalidloss -1264.64537  last_update 1\n",
      "train: iter 78  trainloss -1560.87371  validloss -1220.18467±0.00000  bestvalidloss -1264.64537  last_update 2\n",
      "train: iter 79  trainloss -1544.15555  validloss -975.24637±0.00000  bestvalidloss -1264.64537  last_update 3\n",
      "train: iter 80  trainloss -1555.40826  validloss -1257.92256±0.00000  bestvalidloss -1264.64537  last_update 4\n",
      "train: iter 81  trainloss -1560.14051  validloss -1263.25710±0.00000  bestvalidloss -1264.64537  last_update 5\n",
      "train: iter 82  trainloss -1527.79554  validloss -1061.48992±0.00000  bestvalidloss -1264.64537  last_update 6\n",
      "train: iter 83  trainloss -1647.97301  validloss -1340.60886±0.00000  bestvalidloss -1340.60886  last_update 0\n",
      "train: iter 84  trainloss -1627.21367  validloss -1294.42043±0.00000  bestvalidloss -1340.60886  last_update 1\n",
      "train: iter 85  trainloss -1518.35959  validloss -1171.19704±0.00000  bestvalidloss -1340.60886  last_update 2\n",
      "train: iter 86  trainloss -932.23079  validloss 1959.25881±0.00000  bestvalidloss -1340.60886  last_update 3\n",
      "train: iter 87  trainloss -997.69847  validloss -264.78190±0.00000  bestvalidloss -1340.60886  last_update 4\n",
      "train: iter 88  trainloss -1605.14612  validloss -1244.32853±0.00000  bestvalidloss -1340.60886  last_update 5\n",
      "train: iter 89  trainloss -1667.74688  validloss -1343.45824±0.00000  bestvalidloss -1343.45824  last_update 0\n",
      "train: iter 90  trainloss -1659.95775  validloss -1332.27146±0.00000  bestvalidloss -1343.45824  last_update 1\n",
      "train: iter 91  trainloss -1626.57104  validloss -1377.20517±0.00000  bestvalidloss -1377.20517  last_update 0\n",
      "train: iter 92  trainloss -1690.04946  validloss -1167.45594±0.00000  bestvalidloss -1377.20517  last_update 1\n",
      "train: iter 93  trainloss -1681.27278  validloss -1344.74557±0.00000  bestvalidloss -1377.20517  last_update 2\n",
      "train: iter 94  trainloss -1583.01596  validloss -1143.69385±0.00000  bestvalidloss -1377.20517  last_update 3\n",
      "train: iter 95  trainloss -1604.04231  validloss -941.43195±0.00000  bestvalidloss -1377.20517  last_update 4\n",
      "train: iter 96  trainloss -1652.29986  validloss -1450.97767±0.00000  bestvalidloss -1450.97767  last_update 0\n",
      "train: iter 97  trainloss -1684.37477  validloss -1408.56684±0.00000  bestvalidloss -1450.97767  last_update 1\n",
      "train: iter 98  trainloss -1708.07674  validloss -1447.09495±0.00000  bestvalidloss -1450.97767  last_update 2\n",
      "train: iter 99  trainloss -1705.42642  validloss -1348.52864±0.00000  bestvalidloss -1450.97767  last_update 3\n",
      "train: iter 100  trainloss -1643.69496  validloss -1462.29419±0.00000  bestvalidloss -1462.29419  last_update 0\n",
      "train: iter 101  trainloss -1730.04553  validloss -1442.81428±0.00000  bestvalidloss -1462.29419  last_update 1\n",
      "train: iter 102  trainloss -1679.02129  validloss -1254.08960±0.00000  bestvalidloss -1462.29419  last_update 2\n",
      "train: iter 103  trainloss -1570.19437  validloss -390.53322±0.00000  bestvalidloss -1462.29419  last_update 3\n",
      "train: iter 104  trainloss -1660.61538  validloss -1138.65038±0.00000  bestvalidloss -1462.29419  last_update 4\n",
      "train: iter 105  trainloss -1735.56609  validloss -1455.94066±0.00000  bestvalidloss -1462.29419  last_update 5\n",
      "train: iter 106  trainloss -1656.46067  validloss -1307.34329±0.00000  bestvalidloss -1462.29419  last_update 6\n",
      "train: iter 107  trainloss -1656.97518  validloss -1323.36454±0.00000  bestvalidloss -1462.29419  last_update 7\n",
      "train: iter 108  trainloss -1756.61851  validloss -1369.18601±0.00000  bestvalidloss -1462.29419  last_update 8\n",
      "train: iter 109  trainloss -1698.39482  validloss -1305.13474±0.00000  bestvalidloss -1462.29419  last_update 9\n",
      "train: iter 110  trainloss -1714.74835  validloss -1451.45172±0.00000  bestvalidloss -1462.29419  last_update 10\n",
      "train: iter 111  trainloss -1733.65975  validloss -1434.03861±0.00000  bestvalidloss -1462.29419  last_update 11\n",
      "train: iter 112  trainloss -1748.04934  validloss -1457.16715±0.00000  bestvalidloss -1462.29419  last_update 12\n",
      "train: iter 113  trainloss -1709.69892  validloss -1487.34831±0.00000  bestvalidloss -1487.34831  last_update 0\n",
      "train: iter 114  trainloss -1629.33231  validloss -1506.08472±0.00000  bestvalidloss -1506.08472  last_update 0\n",
      "train: iter 115  trainloss -1755.80899  validloss -1405.99062±0.00000  bestvalidloss -1506.08472  last_update 1\n",
      "train: iter 116  trainloss -1777.68030  validloss -1476.91134±0.00000  bestvalidloss -1506.08472  last_update 2\n",
      "train: iter 117  trainloss -1686.21896  validloss -1399.76268±0.00000  bestvalidloss -1506.08472  last_update 3\n",
      "train: iter 118  trainloss -1750.24130  validloss -1454.23426±0.00000  bestvalidloss -1506.08472  last_update 4\n",
      "train: iter 119  trainloss -1653.44825  validloss -1525.46249±0.00000  bestvalidloss -1525.46249  last_update 0\n",
      "train: iter 120  trainloss -1715.37591  validloss -1360.77167±0.00000  bestvalidloss -1525.46249  last_update 1\n",
      "train: iter 121  trainloss -1762.74745  validloss -1549.92402±0.00000  bestvalidloss -1549.92402  last_update 0\n",
      "train: iter 122  trainloss -1782.04080  validloss -1538.25391±0.00000  bestvalidloss -1549.92402  last_update 1\n",
      "train: iter 123  trainloss -1725.14821  validloss -1336.44985±0.00000  bestvalidloss -1549.92402  last_update 2\n",
      "train: iter 124  trainloss -1706.04103  validloss -1462.22227±0.00000  bestvalidloss -1549.92402  last_update 3\n",
      "train: iter 125  trainloss -1706.39957  validloss -975.73034±0.00000  bestvalidloss -1549.92402  last_update 4\n",
      "train: iter 126  trainloss -1782.66441  validloss -1560.99324±0.00000  bestvalidloss -1560.99324  last_update 0\n",
      "train: iter 127  trainloss -1810.32142  validloss -1506.69056±0.00000  bestvalidloss -1560.99324  last_update 1\n",
      "train: iter 128  trainloss -1795.20533  validloss -1470.60130±0.00000  bestvalidloss -1560.99324  last_update 2\n",
      "train: iter 129  trainloss -1727.15148  validloss -1586.05029±0.00000  bestvalidloss -1586.05029  last_update 0\n",
      "train: iter 130  trainloss -1723.53455  validloss -1415.29472±0.00000  bestvalidloss -1586.05029  last_update 1\n",
      "train: iter 131  trainloss -1795.16522  validloss -1428.39085±0.00000  bestvalidloss -1586.05029  last_update 2\n",
      "train: iter 132  trainloss -1775.21908  validloss -1538.76731±0.00000  bestvalidloss -1586.05029  last_update 3\n",
      "train: iter 133  trainloss -1767.41421  validloss -1447.53302±0.00000  bestvalidloss -1586.05029  last_update 4\n",
      "train: iter 134  trainloss -1841.24336  validloss -1551.35356±0.00000  bestvalidloss -1586.05029  last_update 5\n",
      "train: iter 135  trainloss -1575.93651  validloss -1553.80234±0.00000  bestvalidloss -1586.05029  last_update 6\n",
      "train: iter 136  trainloss -1682.95650  validloss -1137.28190±0.00000  bestvalidloss -1586.05029  last_update 7\n",
      "train: iter 137  trainloss -1749.21102  validloss -1568.20501±0.00000  bestvalidloss -1586.05029  last_update 8\n",
      "train: iter 138  trainloss -1729.87444  validloss -1562.16849±0.00000  bestvalidloss -1586.05029  last_update 9\n",
      "train: iter 139  trainloss -1508.97910  validloss -191.32151±0.00000  bestvalidloss -1586.05029  last_update 10\n",
      "train: iter 140  trainloss -1748.83605  validloss -1470.57183±0.00000  bestvalidloss -1586.05029  last_update 11\n",
      "train: iter 141  trainloss -1815.28882  validloss -1574.34120±0.00000  bestvalidloss -1586.05029  last_update 12\n",
      "train: iter 142  trainloss -1711.60167  validloss -1618.74923±0.00000  bestvalidloss -1618.74923  last_update 0\n",
      "train: iter 143  trainloss -1813.67463  validloss -1464.45697±0.00000  bestvalidloss -1618.74923  last_update 1\n",
      "train: iter 144  trainloss -1831.04777  validloss -1521.34971±0.00000  bestvalidloss -1618.74923  last_update 2\n",
      "train: iter 145  trainloss -1808.00559  validloss -1568.31832±0.00000  bestvalidloss -1618.74923  last_update 3\n",
      "train: iter 146  trainloss -1758.57054  validloss -1212.58310±0.00000  bestvalidloss -1618.74923  last_update 4\n",
      "train: iter 147  trainloss -1777.09235  validloss -1528.68064±0.00000  bestvalidloss -1618.74923  last_update 5\n",
      "train: iter 148  trainloss -1704.25435  validloss -1372.24365±0.00000  bestvalidloss -1618.74923  last_update 6\n",
      "train: iter 149  trainloss -1805.31846  validloss -1499.51829±0.00000  bestvalidloss -1618.74923  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 150  trainloss -1806.76513  validloss -1486.54864±0.00000  bestvalidloss -1618.74923  last_update 8\n",
      "train: iter 151  trainloss -1820.49084  validloss -1615.78284±0.00000  bestvalidloss -1618.74923  last_update 9\n",
      "train: iter 152  trainloss -1703.39506  validloss -1306.98220±0.00000  bestvalidloss -1618.74923  last_update 10\n",
      "train: iter 153  trainloss -1797.29507  validloss -1589.15685±0.00000  bestvalidloss -1618.74923  last_update 11\n",
      "train: iter 154  trainloss -1814.57725  validloss -1669.84924±0.00000  bestvalidloss -1669.84924  last_update 0\n",
      "train: iter 155  trainloss -1795.59461  validloss -1616.36617±0.00000  bestvalidloss -1669.84924  last_update 1\n",
      "train: iter 156  trainloss -1829.10943  validloss -1622.85171±0.00000  bestvalidloss -1669.84924  last_update 2\n",
      "train: iter 157  trainloss -1794.62045  validloss -1632.11739±0.00000  bestvalidloss -1669.84924  last_update 3\n",
      "train: iter 158  trainloss -1837.49129  validloss -1610.64608±0.00000  bestvalidloss -1669.84924  last_update 4\n",
      "train: iter 159  trainloss -1795.42580  validloss -1543.69664±0.00000  bestvalidloss -1669.84924  last_update 5\n",
      "train: iter 160  trainloss -1735.22912  validloss -1573.77922±0.00000  bestvalidloss -1669.84924  last_update 6\n",
      "train: iter 161  trainloss -1830.12626  validloss -1326.16921±0.00000  bestvalidloss -1669.84924  last_update 7\n",
      "train: iter 162  trainloss -1856.48911  validloss -1690.95539±0.00000  bestvalidloss -1690.95539  last_update 0\n",
      "train: iter 163  trainloss -1795.53553  validloss -1596.63855±0.00000  bestvalidloss -1690.95539  last_update 1\n",
      "train: iter 164  trainloss -1845.92977  validloss -1596.91912±0.00000  bestvalidloss -1690.95539  last_update 2\n",
      "train: iter 165  trainloss -1802.32579  validloss -1622.43766±0.00000  bestvalidloss -1690.95539  last_update 3\n",
      "train: iter 166  trainloss -1408.55510  validloss -1306.70299±0.00000  bestvalidloss -1690.95539  last_update 4\n",
      "train: iter 167  trainloss -1784.14087  validloss -1521.11091±0.00000  bestvalidloss -1690.95539  last_update 5\n",
      "train: iter 168  trainloss -1848.95418  validloss -1597.11647±0.00000  bestvalidloss -1690.95539  last_update 6\n",
      "train: iter 169  trainloss -1826.08918  validloss -1650.87439±0.00000  bestvalidloss -1690.95539  last_update 7\n",
      "train: iter 170  trainloss -1831.15562  validloss -1492.85439±0.00000  bestvalidloss -1690.95539  last_update 8\n",
      "train: iter 171  trainloss -1831.06006  validloss -1677.66927±0.00000  bestvalidloss -1690.95539  last_update 9\n",
      "train: iter 172  trainloss -1692.97125  validloss -1193.63038±0.00000  bestvalidloss -1690.95539  last_update 10\n",
      "train: iter 173  trainloss -1832.33760  validloss -1459.58342±0.00000  bestvalidloss -1690.95539  last_update 11\n",
      "train: iter 174  trainloss -1853.64568  validloss -1641.02176±0.00000  bestvalidloss -1690.95539  last_update 12\n",
      "train: iter 175  trainloss -1757.57767  validloss -1471.68601±0.00000  bestvalidloss -1690.95539  last_update 13\n",
      "train: iter 176  trainloss -1864.01417  validloss -1515.15269±0.00000  bestvalidloss -1690.95539  last_update 14\n",
      "train: iter 177  trainloss -1879.36511  validloss -1643.53002±0.00000  bestvalidloss -1690.95539  last_update 15\n",
      "train: iter 178  trainloss -1754.71855  validloss -1644.17223±0.00000  bestvalidloss -1690.95539  last_update 16\n",
      "train: iter 179  trainloss -1631.76346  validloss -1396.60130±0.00000  bestvalidloss -1690.95539  last_update 17\n",
      "train: iter 180  trainloss -1870.83257  validloss -1637.27637±0.00000  bestvalidloss -1690.95539  last_update 18\n",
      "train: iter 181  trainloss -1763.02016  validloss -1609.30420±0.00000  bestvalidloss -1690.95539  last_update 19\n",
      "train: iter 182  trainloss -1848.82066  validloss -1592.07196±0.00000  bestvalidloss -1690.95539  last_update 20\n",
      "train: iter 183  trainloss -1856.84619  validloss -1651.95790±0.00000  bestvalidloss -1690.95539  last_update 21\n",
      "train: iter 184  trainloss -1861.76733  validloss -1669.77075±0.00000  bestvalidloss -1690.95539  last_update 22\n",
      "train: iter 185  trainloss -1842.37018  validloss -1618.52218±0.00000  bestvalidloss -1690.95539  last_update 23\n",
      "train: iter 186  trainloss -1737.46440  validloss -1630.02892±0.00000  bestvalidloss -1690.95539  last_update 24\n",
      "train: iter 187  trainloss -1785.56992  validloss -1516.06786±0.00000  bestvalidloss -1690.95539  last_update 25\n",
      "train: iter 188  trainloss -1622.10420  validloss -1594.75597±0.00000  bestvalidloss -1690.95539  last_update 26\n",
      "train: iter 189  trainloss -1836.24612  validloss -1416.01060±0.00000  bestvalidloss -1690.95539  last_update 27\n",
      "train: iter 190  trainloss -1851.61447  validloss -1616.63915±0.00000  bestvalidloss -1690.95539  last_update 28\n",
      "train: iter 191  trainloss -1862.56520  validloss -1589.67353±0.00000  bestvalidloss -1690.95539  last_update 29\n",
      "train: iter 192  trainloss -1836.59629  validloss -1560.92608±0.00000  bestvalidloss -1690.95539  last_update 30\n",
      "train: iter 193  trainloss -1896.21446  validloss -1674.74925±0.00000  bestvalidloss -1690.95539  last_update 31\n",
      "train: iter 194  trainloss -1861.49183  validloss -1660.36190±0.00000  bestvalidloss -1690.95539  last_update 32\n",
      "train: iter 195  trainloss -1878.07696  validloss -1680.97246±0.00000  bestvalidloss -1690.95539  last_update 33\n",
      "train: iter 196  trainloss -1838.92582  validloss -1670.78102±0.00000  bestvalidloss -1690.95539  last_update 34\n",
      "train: iter 197  trainloss -1756.27172  validloss -1441.69963±0.00000  bestvalidloss -1690.95539  last_update 35\n",
      "train: iter 198  trainloss -1805.44497  validloss -1604.78685±0.00000  bestvalidloss -1690.95539  last_update 36\n",
      "train: iter 199  trainloss -1595.77712  validloss -1578.54244±0.00000  bestvalidloss -1690.95539  last_update 37\n",
      "train: iter 200  trainloss -1796.93327  validloss -1514.05041±0.00000  bestvalidloss -1690.95539  last_update 38\n",
      "train: iter 201  trainloss -1880.81787  validloss -1698.46346±0.00000  bestvalidloss -1698.46346  last_update 0\n",
      "train: iter 202  trainloss -1782.82243  validloss -1499.75510±0.00000  bestvalidloss -1698.46346  last_update 1\n",
      "train: iter 203  trainloss -1872.14869  validloss -1583.49946±0.00000  bestvalidloss -1698.46346  last_update 2\n",
      "train: iter 204  trainloss -1849.32737  validloss -1670.93751±0.00000  bestvalidloss -1698.46346  last_update 3\n",
      "train: iter 205  trainloss -1872.97295  validloss -1715.14945±0.00000  bestvalidloss -1715.14945  last_update 0\n",
      "train: iter 206  trainloss -1668.85130  validloss -1557.84345±0.00000  bestvalidloss -1715.14945  last_update 1\n",
      "train: iter 207  trainloss -1855.64060  validloss -1582.49931±0.00000  bestvalidloss -1715.14945  last_update 2\n",
      "train: iter 208  trainloss -1913.31275  validloss -1709.37068±0.00000  bestvalidloss -1715.14945  last_update 3\n",
      "train: iter 209  trainloss -1863.55570  validloss -1639.05533±0.00000  bestvalidloss -1715.14945  last_update 4\n",
      "train: iter 210  trainloss -1761.44618  validloss -1635.73147±0.00000  bestvalidloss -1715.14945  last_update 5\n",
      "train: iter 211  trainloss -1874.19495  validloss -1563.20905±0.00000  bestvalidloss -1715.14945  last_update 6\n",
      "train: iter 212  trainloss -1855.19703  validloss -1585.46666±0.00000  bestvalidloss -1715.14945  last_update 7\n",
      "train: iter 213  trainloss -1910.11385  validloss -1700.55482±0.00000  bestvalidloss -1715.14945  last_update 8\n",
      "train: iter 214  trainloss -1872.72255  validloss -1707.97978±0.00000  bestvalidloss -1715.14945  last_update 9\n",
      "train: iter 215  trainloss -1764.47331  validloss -1674.78353±0.00000  bestvalidloss -1715.14945  last_update 10\n",
      "train: iter 216  trainloss -1858.99855  validloss -1555.80016±0.00000  bestvalidloss -1715.14945  last_update 11\n",
      "train: iter 217  trainloss -1856.80373  validloss -1691.68672±0.00000  bestvalidloss -1715.14945  last_update 12\n",
      "train: iter 218  trainloss -1739.42543  validloss -1709.56642±0.00000  bestvalidloss -1715.14945  last_update 13\n",
      "train: iter 219  trainloss -1864.71261  validloss -1524.76079±0.00000  bestvalidloss -1715.14945  last_update 14\n",
      "train: iter 220  trainloss -1867.98595  validloss -1706.90226±0.00000  bestvalidloss -1715.14945  last_update 15\n",
      "train: iter 221  trainloss -1896.42297  validloss -1599.44799±0.00000  bestvalidloss -1715.14945  last_update 16\n",
      "train: iter 222  trainloss -1776.16668  validloss -1691.29453±0.00000  bestvalidloss -1715.14945  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -1828.01815  validloss -1420.63505±0.00000  bestvalidloss -1715.14945  last_update 18\n",
      "train: iter 224  trainloss -1919.61681  validloss -1697.40613±0.00000  bestvalidloss -1715.14945  last_update 19\n",
      "train: iter 225  trainloss -1900.66525  validloss -1687.30064±0.00000  bestvalidloss -1715.14945  last_update 20\n",
      "train: iter 226  trainloss -1832.33486  validloss -1653.80221±0.00000  bestvalidloss -1715.14945  last_update 21\n",
      "train: iter 227  trainloss -1846.61973  validloss -1680.52902±0.00000  bestvalidloss -1715.14945  last_update 22\n",
      "train: iter 228  trainloss -1846.20353  validloss -1586.88590±0.00000  bestvalidloss -1715.14945  last_update 23\n",
      "train: iter 229  trainloss -1844.38855  validloss -988.50041±0.00000  bestvalidloss -1715.14945  last_update 24\n",
      "train: iter 230  trainloss -1900.55891  validloss -1636.02100±0.00000  bestvalidloss -1715.14945  last_update 25\n",
      "train: iter 231  trainloss -1867.48995  validloss -1715.65711±0.00000  bestvalidloss -1715.65711  last_update 0\n",
      "train: iter 232  trainloss -1899.98052  validloss -1679.49756±0.00000  bestvalidloss -1715.65711  last_update 1\n",
      "train: iter 233  trainloss -1838.28116  validloss -1719.00271±0.00000  bestvalidloss -1719.00271  last_update 0\n",
      "train: iter 234  trainloss -1856.01676  validloss -1379.37905±0.00000  bestvalidloss -1719.00271  last_update 1\n",
      "train: iter 235  trainloss -1844.89288  validloss -1689.76048±0.00000  bestvalidloss -1719.00271  last_update 2\n",
      "train: iter 236  trainloss -1871.77572  validloss -1690.19989±0.00000  bestvalidloss -1719.00271  last_update 3\n",
      "train: iter 237  trainloss -1862.74414  validloss -1708.64709±0.00000  bestvalidloss -1719.00271  last_update 4\n",
      "train: iter 238  trainloss -1872.22878  validloss -1692.11055±0.00000  bestvalidloss -1719.00271  last_update 5\n",
      "train: iter 239  trainloss -1787.78532  validloss -1307.40976±0.00000  bestvalidloss -1719.00271  last_update 6\n",
      "train: iter 240  trainloss -1897.66848  validloss -1641.31272±0.00000  bestvalidloss -1719.00271  last_update 7\n",
      "train: iter 241  trainloss -1879.79130  validloss -1729.74007±0.00000  bestvalidloss -1729.74007  last_update 0\n",
      "train: iter 242  trainloss -1881.65433  validloss -1709.38768±0.00000  bestvalidloss -1729.74007  last_update 1\n",
      "train: iter 243  trainloss -1822.93844  validloss -1711.24160±0.00000  bestvalidloss -1729.74007  last_update 2\n",
      "train: iter 244  trainloss -1721.66950  validloss -1511.61965±0.00000  bestvalidloss -1729.74007  last_update 3\n",
      "train: iter 245  trainloss -1888.36829  validloss -1679.96511±0.00000  bestvalidloss -1729.74007  last_update 4\n",
      "train: iter 246  trainloss -1891.44832  validloss -1509.52380±0.00000  bestvalidloss -1729.74007  last_update 5\n",
      "train: iter 247  trainloss -1913.14378  validloss -1726.66372±0.00000  bestvalidloss -1729.74007  last_update 6\n",
      "train: iter 248  trainloss -1836.59649  validloss -1707.39788±0.00000  bestvalidloss -1729.74007  last_update 7\n",
      "train: iter 249  trainloss -1881.85551  validloss -1597.87919±0.00000  bestvalidloss -1729.74007  last_update 8\n",
      "train: iter 250  trainloss -1859.87268  validloss -1635.90763±0.00000  bestvalidloss -1729.74007  last_update 9\n",
      "train: iter 251  trainloss -1874.34856  validloss -1621.43302±0.00000  bestvalidloss -1729.74007  last_update 10\n",
      "train: iter 252  trainloss -1900.03373  validloss -1644.45278±0.00000  bestvalidloss -1729.74007  last_update 11\n",
      "train: iter 253  trainloss -1884.99647  validloss -1708.27740±0.00000  bestvalidloss -1729.74007  last_update 12\n",
      "train: iter 254  trainloss -1880.87768  validloss -1665.01503±0.00000  bestvalidloss -1729.74007  last_update 13\n",
      "train: iter 255  trainloss -1762.19704  validloss -1647.77716±0.00000  bestvalidloss -1729.74007  last_update 14\n",
      "train: iter 256  trainloss -1895.48077  validloss -1643.35468±0.00000  bestvalidloss -1729.74007  last_update 15\n",
      "train: iter 257  trainloss -1869.80158  validloss -1690.57877±0.00000  bestvalidloss -1729.74007  last_update 16\n",
      "train: iter 258  trainloss -1779.10369  validloss -1560.44825±0.00000  bestvalidloss -1729.74007  last_update 17\n",
      "train: iter 259  trainloss -1905.74972  validloss -1695.34614±0.00000  bestvalidloss -1729.74007  last_update 18\n",
      "train: iter 260  trainloss -1913.80490  validloss -1707.16195±0.00000  bestvalidloss -1729.74007  last_update 19\n",
      "train: iter 261  trainloss -1920.02300  validloss -1720.73995±0.00000  bestvalidloss -1729.74007  last_update 20\n",
      "train: iter 262  trainloss -1856.95141  validloss -1726.62733±0.00000  bestvalidloss -1729.74007  last_update 21\n",
      "train: iter 263  trainloss -1886.18284  validloss -1656.68978±0.00000  bestvalidloss -1729.74007  last_update 22\n",
      "train: iter 264  trainloss -1814.47308  validloss -1664.19723±0.00000  bestvalidloss -1729.74007  last_update 23\n",
      "train: iter 265  trainloss -1873.40500  validloss -1670.88571±0.00000  bestvalidloss -1729.74007  last_update 24\n",
      "train: iter 266  trainloss -1916.67400  validloss -1720.17110±0.00000  bestvalidloss -1729.74007  last_update 25\n",
      "train: iter 267  trainloss -1896.10355  validloss -1678.32246±0.00000  bestvalidloss -1729.74007  last_update 26\n",
      "train: iter 268  trainloss -1802.26359  validloss -1598.56207±0.00000  bestvalidloss -1729.74007  last_update 27\n",
      "train: iter 269  trainloss -1878.72680  validloss -1695.21852±0.00000  bestvalidloss -1729.74007  last_update 28\n",
      "train: iter 270  trainloss -1813.34767  validloss -1667.02511±0.00000  bestvalidloss -1729.74007  last_update 29\n",
      "train: iter 271  trainloss -1794.02193  validloss -1659.21476±0.00000  bestvalidloss -1729.74007  last_update 30\n",
      "train: iter 272  trainloss -1788.98153  validloss -1720.74851±0.00000  bestvalidloss -1729.74007  last_update 31\n",
      "train: iter 273  trainloss -1900.55350  validloss -1575.68148±0.00000  bestvalidloss -1729.74007  last_update 32\n",
      "train: iter 274  trainloss -1939.87103  validloss -1740.37441±0.00000  bestvalidloss -1740.37441  last_update 0\n",
      "train: iter 275  trainloss -1860.27480  validloss -1735.69753±0.00000  bestvalidloss -1740.37441  last_update 1\n",
      "train: iter 276  trainloss -1812.46933  validloss -1417.70642±0.00000  bestvalidloss -1740.37441  last_update 2\n",
      "train: iter 277  trainloss -1807.85723  validloss -1693.48385±0.00000  bestvalidloss -1740.37441  last_update 3\n",
      "train: iter 278  trainloss -1892.54736  validloss -1662.52684±0.00000  bestvalidloss -1740.37441  last_update 4\n",
      "train: iter 279  trainloss -1887.82618  validloss -1552.51282±0.00000  bestvalidloss -1740.37441  last_update 5\n",
      "train: iter 280  trainloss -1888.94893  validloss -1707.39142±0.00000  bestvalidloss -1740.37441  last_update 6\n",
      "train: iter 281  trainloss -1895.61434  validloss -1669.35939±0.00000  bestvalidloss -1740.37441  last_update 7\n",
      "train: iter 282  trainloss -1788.93328  validloss -1718.29659±0.00000  bestvalidloss -1740.37441  last_update 8\n",
      "train: iter 283  trainloss -1928.51150  validloss -1637.11416±0.00000  bestvalidloss -1740.37441  last_update 9\n",
      "train: iter 284  trainloss -1789.43648  validloss -1734.06576±0.00000  bestvalidloss -1740.37441  last_update 10\n",
      "train: iter 285  trainloss -1903.60433  validloss -1634.88442±0.00000  bestvalidloss -1740.37441  last_update 11\n",
      "train: iter 286  trainloss -1916.65411  validloss -1700.60645±0.00000  bestvalidloss -1740.37441  last_update 12\n",
      "train: iter 287  trainloss -1934.60313  validloss -1764.16567±0.00000  bestvalidloss -1764.16567  last_update 0\n",
      "train: iter 288  trainloss -1874.16581  validloss -1597.19182±0.00000  bestvalidloss -1764.16567  last_update 1\n",
      "train: iter 289  trainloss -1793.58636  validloss -1683.53532±0.00000  bestvalidloss -1764.16567  last_update 2\n",
      "train: iter 290  trainloss -1905.89405  validloss -1664.43684±0.00000  bestvalidloss -1764.16567  last_update 3\n",
      "train: iter 291  trainloss -1857.51403  validloss -1463.72952±0.00000  bestvalidloss -1764.16567  last_update 4\n",
      "train: iter 292  trainloss -1932.45374  validloss -1698.95894±0.00000  bestvalidloss -1764.16567  last_update 5\n",
      "train: iter 293  trainloss -1911.04687  validloss -1727.68277±0.00000  bestvalidloss -1764.16567  last_update 6\n",
      "train: iter 294  trainloss -1901.95861  validloss -1714.07319±0.00000  bestvalidloss -1764.16567  last_update 7\n",
      "train: iter 295  trainloss -1874.47734  validloss -1746.09059±0.00000  bestvalidloss -1764.16567  last_update 8\n",
      "train: iter 296  trainloss -1682.94368  validloss -1664.36723±0.00000  bestvalidloss -1764.16567  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 297  trainloss -1904.04055  validloss -1581.69881±0.00000  bestvalidloss -1764.16567  last_update 10\n",
      "train: iter 298  trainloss -1896.58233  validloss -1707.80071±0.00000  bestvalidloss -1764.16567  last_update 11\n",
      "train: iter 299  trainloss -1909.55534  validloss -1745.53712±0.00000  bestvalidloss -1764.16567  last_update 12\n",
      "train: iter 300  trainloss -1904.34339  validloss -1685.07990±0.00000  bestvalidloss -1764.16567  last_update 13\n",
      "train: iter 301  trainloss -1910.81311  validloss -1673.55713±0.00000  bestvalidloss -1764.16567  last_update 14\n",
      "train: iter 302  trainloss -1848.08221  validloss -1723.06705±0.00000  bestvalidloss -1764.16567  last_update 15\n",
      "train: iter 303  trainloss -1833.90711  validloss -1441.67338±0.00000  bestvalidloss -1764.16567  last_update 16\n",
      "train: iter 304  trainloss -1934.47201  validloss -1728.48884±0.00000  bestvalidloss -1764.16567  last_update 17\n",
      "train: iter 305  trainloss -1891.01606  validloss -1721.84212±0.00000  bestvalidloss -1764.16567  last_update 18\n",
      "train: iter 306  trainloss -1890.86164  validloss -1650.46437±0.00000  bestvalidloss -1764.16567  last_update 19\n",
      "train: iter 307  trainloss -1904.23061  validloss -1667.42556±0.00000  bestvalidloss -1764.16567  last_update 20\n",
      "train: iter 308  trainloss -1890.01529  validloss -1743.77159±0.00000  bestvalidloss -1764.16567  last_update 21\n",
      "train: iter 309  trainloss -1845.22487  validloss -1758.10116±0.00000  bestvalidloss -1764.16567  last_update 22\n",
      "train: iter 310  trainloss -1733.20146  validloss -866.90269±0.00000  bestvalidloss -1764.16567  last_update 23\n",
      "train: iter 311  trainloss -1904.32489  validloss -1537.63619±0.00000  bestvalidloss -1764.16567  last_update 24\n",
      "train: iter 312  trainloss -1898.06158  validloss -1724.50847±0.00000  bestvalidloss -1764.16567  last_update 25\n",
      "train: iter 313  trainloss -1842.13706  validloss -1723.65209±0.00000  bestvalidloss -1764.16567  last_update 26\n",
      "train: iter 314  trainloss -1884.26879  validloss -1658.71875±0.00000  bestvalidloss -1764.16567  last_update 27\n",
      "train: iter 315  trainloss -1929.70224  validloss -1738.14374±0.00000  bestvalidloss -1764.16567  last_update 28\n",
      "train: iter 316  trainloss -1907.13497  validloss -1734.48885±0.00000  bestvalidloss -1764.16567  last_update 29\n",
      "train: iter 317  trainloss -1864.22175  validloss -1537.29621±0.00000  bestvalidloss -1764.16567  last_update 30\n",
      "train: iter 318  trainloss -1852.96491  validloss -1696.43757±0.00000  bestvalidloss -1764.16567  last_update 31\n",
      "train: iter 319  trainloss -1887.56182  validloss -1625.93621±0.00000  bestvalidloss -1764.16567  last_update 32\n",
      "train: iter 320  trainloss -1932.81406  validloss -1706.73052±0.00000  bestvalidloss -1764.16567  last_update 33\n",
      "train: iter 321  trainloss -1931.64905  validloss -1763.13505±0.00000  bestvalidloss -1764.16567  last_update 34\n",
      "train: iter 322  trainloss -1852.01226  validloss -1709.94926±0.00000  bestvalidloss -1764.16567  last_update 35\n",
      "train: iter 323  trainloss -1862.85226  validloss -1658.71901±0.00000  bestvalidloss -1764.16567  last_update 36\n",
      "train: iter 324  trainloss -1892.42001  validloss -1712.26911±0.00000  bestvalidloss -1764.16567  last_update 37\n",
      "train: iter 325  trainloss -1898.72002  validloss -1711.24022±0.00000  bestvalidloss -1764.16567  last_update 38\n",
      "train: iter 326  trainloss -1870.34576  validloss -1692.59364±0.00000  bestvalidloss -1764.16567  last_update 39\n",
      "train: iter 327  trainloss -1919.38014  validloss -1713.70009±0.00000  bestvalidloss -1764.16567  last_update 40\n",
      "train: iter 328  trainloss -1680.94453  validloss -1598.35135±0.00000  bestvalidloss -1764.16567  last_update 41\n",
      "train: iter 329  trainloss -1937.64275  validloss -1689.07355±0.00000  bestvalidloss -1764.16567  last_update 42\n",
      "train: iter 330  trainloss -1917.50165  validloss -1731.95135±0.00000  bestvalidloss -1764.16567  last_update 43\n",
      "train: iter 331  trainloss -1909.61971  validloss -1740.52542±0.00000  bestvalidloss -1764.16567  last_update 44\n",
      "train: iter 332  trainloss -1803.43165  validloss -1528.31002±0.00000  bestvalidloss -1764.16567  last_update 45\n",
      "train: iter 333  trainloss -1835.88078  validloss -1511.36070±0.00000  bestvalidloss -1764.16567  last_update 46\n",
      "train: iter 334  trainloss -1924.21290  validloss -1741.84781±0.00000  bestvalidloss -1764.16567  last_update 47\n",
      "train: iter 335  trainloss -1893.65274  validloss -1678.86336±0.00000  bestvalidloss -1764.16567  last_update 48\n",
      "train: iter 336  trainloss -1886.83360  validloss -1723.49912±0.00000  bestvalidloss -1764.16567  last_update 49\n",
      "train: iter 337  trainloss -1909.23901  validloss -1710.90052±0.00000  bestvalidloss -1764.16567  last_update 50\n",
      "train: iter 338  trainloss -1936.26088  validloss -1705.76510±0.00000  bestvalidloss -1764.16567  last_update 51\n",
      "train: iter 339  trainloss -1888.79296  validloss -1721.04412±0.00000  bestvalidloss -1764.16567  last_update 52\n",
      "train: iter 340  trainloss -1900.25164  validloss -1717.35026±0.00000  bestvalidloss -1764.16567  last_update 53\n",
      "train: iter 341  trainloss -1887.60172  validloss -1676.38031±0.00000  bestvalidloss -1764.16567  last_update 54\n",
      "train: iter 342  trainloss -1903.98613  validloss -1670.56959±0.00000  bestvalidloss -1764.16567  last_update 55\n",
      "train: iter 343  trainloss -1912.73904  validloss -1683.38294±0.00000  bestvalidloss -1764.16567  last_update 56\n",
      "train: iter 344  trainloss -1864.09368  validloss -1567.56357±0.00000  bestvalidloss -1764.16567  last_update 57\n",
      "train: iter 345  trainloss -1945.13609  validloss -1735.42587±0.00000  bestvalidloss -1764.16567  last_update 58\n",
      "train: iter 346  trainloss -1909.93155  validloss -1774.93492±0.00000  bestvalidloss -1774.93492  last_update 0\n",
      "train: iter 347  trainloss -1877.69129  validloss -1679.41867±0.00000  bestvalidloss -1774.93492  last_update 1\n",
      "train: iter 348  trainloss -1848.27604  validloss -1684.08160±0.00000  bestvalidloss -1774.93492  last_update 2\n",
      "train: iter 349  trainloss -1935.72998  validloss -1726.79289±0.00000  bestvalidloss -1774.93492  last_update 3\n",
      "train: iter 350  trainloss -1793.27289  validloss -1656.66741±0.00000  bestvalidloss -1774.93492  last_update 4\n",
      "train: iter 351  trainloss -1899.25329  validloss -1685.46564±0.00000  bestvalidloss -1774.93492  last_update 5\n",
      "train: iter 352  trainloss -1686.53130  validloss -1544.54498±0.00000  bestvalidloss -1774.93492  last_update 6\n",
      "train: iter 353  trainloss -1924.84233  validloss -1691.31781±0.00000  bestvalidloss -1774.93492  last_update 7\n",
      "train: iter 354  trainloss -1927.28834  validloss -1752.55827±0.00000  bestvalidloss -1774.93492  last_update 8\n",
      "train: iter 355  trainloss -1821.56146  validloss -1738.76704±0.00000  bestvalidloss -1774.93492  last_update 9\n",
      "train: iter 356  trainloss -1940.02775  validloss -1701.19980±0.00000  bestvalidloss -1774.93492  last_update 10\n",
      "train: iter 357  trainloss -1950.24446  validloss -1742.89108±0.00000  bestvalidloss -1774.93492  last_update 11\n",
      "train: iter 358  trainloss -1908.59512  validloss -1757.01543±0.00000  bestvalidloss -1774.93492  last_update 12\n",
      "train: iter 359  trainloss -1959.75710  validloss -1715.35338±0.00000  bestvalidloss -1774.93492  last_update 13\n",
      "train: iter 360  trainloss -1858.95759  validloss -1789.40511±0.00000  bestvalidloss -1789.40511  last_update 0\n",
      "train: iter 361  trainloss -1890.90962  validloss -1548.93600±0.00000  bestvalidloss -1789.40511  last_update 1\n",
      "train: iter 362  trainloss -1909.30264  validloss -1678.66820±0.00000  bestvalidloss -1789.40511  last_update 2\n",
      "train: iter 363  trainloss -1798.95669  validloss -1728.69337±0.00000  bestvalidloss -1789.40511  last_update 3\n",
      "train: iter 364  trainloss -1939.03194  validloss -1684.26816±0.00000  bestvalidloss -1789.40511  last_update 4\n",
      "train: iter 365  trainloss -1816.01131  validloss -1642.36985±0.00000  bestvalidloss -1789.40511  last_update 5\n",
      "train: iter 366  trainloss -1935.60625  validloss -1676.96783±0.00000  bestvalidloss -1789.40511  last_update 6\n",
      "train: iter 367  trainloss -1940.02760  validloss -1735.39813±0.00000  bestvalidloss -1789.40511  last_update 7\n",
      "train: iter 368  trainloss -1939.37498  validloss -1696.37194±0.00000  bestvalidloss -1789.40511  last_update 8\n",
      "train: iter 369  trainloss -1925.62751  validloss -1601.92859±0.00000  bestvalidloss -1789.40511  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 370  trainloss -1771.17478  validloss -1256.44005±0.00000  bestvalidloss -1789.40511  last_update 10\n",
      "train: iter 371  trainloss -1944.22219  validloss -1680.77708±0.00000  bestvalidloss -1789.40511  last_update 11\n",
      "train: iter 372  trainloss -1945.86456  validloss -1714.25426±0.00000  bestvalidloss -1789.40511  last_update 12\n",
      "train: iter 373  trainloss -1952.59914  validloss -1753.97501±0.00000  bestvalidloss -1789.40511  last_update 13\n",
      "train: iter 374  trainloss -1907.20504  validloss -1627.47796±0.00000  bestvalidloss -1789.40511  last_update 14\n",
      "train: iter 375  trainloss -1934.61058  validloss -1709.57462±0.00000  bestvalidloss -1789.40511  last_update 15\n",
      "train: iter 376  trainloss -1830.30039  validloss -1671.47789±0.00000  bestvalidloss -1789.40511  last_update 16\n",
      "train: iter 377  trainloss -1938.28621  validloss -1706.34622±0.00000  bestvalidloss -1789.40511  last_update 17\n",
      "train: iter 378  trainloss -1910.17603  validloss -1614.41051±0.00000  bestvalidloss -1789.40511  last_update 18\n",
      "train: iter 379  trainloss -1870.04833  validloss -1710.65583±0.00000  bestvalidloss -1789.40511  last_update 19\n",
      "train: iter 380  trainloss -1847.28480  validloss -1280.96624±0.00000  bestvalidloss -1789.40511  last_update 20\n",
      "train: iter 381  trainloss -1943.52646  validloss -1740.87367±0.00000  bestvalidloss -1789.40511  last_update 21\n",
      "train: iter 382  trainloss -1951.50806  validloss -1729.24420±0.00000  bestvalidloss -1789.40511  last_update 22\n",
      "train: iter 383  trainloss -1924.86869  validloss -1749.56729±0.00000  bestvalidloss -1789.40511  last_update 23\n",
      "train: iter 384  trainloss -1821.77348  validloss -1758.39888±0.00000  bestvalidloss -1789.40511  last_update 24\n",
      "train: iter 385  trainloss -1930.58432  validloss -1588.11002±0.00000  bestvalidloss -1789.40511  last_update 25\n",
      "train: iter 386  trainloss -1942.34221  validloss -1701.95953±0.00000  bestvalidloss -1789.40511  last_update 26\n",
      "train: iter 387  trainloss -1938.89765  validloss -1751.73083±0.00000  bestvalidloss -1789.40511  last_update 27\n",
      "train: iter 388  trainloss -1829.79719  validloss -1400.81084±0.00000  bestvalidloss -1789.40511  last_update 28\n",
      "train: iter 389  trainloss -1901.93320  validloss -1518.11259±0.00000  bestvalidloss -1789.40511  last_update 29\n",
      "train: iter 390  trainloss -1770.29480  validloss -1756.96243±0.00000  bestvalidloss -1789.40511  last_update 30\n",
      "train: iter 391  trainloss -1900.74410  validloss -1502.10452±0.00000  bestvalidloss -1789.40511  last_update 31\n",
      "train: iter 392  trainloss -1898.28096  validloss -1717.91254±0.00000  bestvalidloss -1789.40511  last_update 32\n",
      "train: iter 393  trainloss -1940.19899  validloss -1720.27235±0.00000  bestvalidloss -1789.40511  last_update 33\n",
      "train: iter 394  trainloss -1956.50244  validloss -1761.92631±0.00000  bestvalidloss -1789.40511  last_update 34\n",
      "train: iter 395  trainloss -1943.37907  validloss -1777.05893±0.00000  bestvalidloss -1789.40511  last_update 35\n",
      "train: iter 396  trainloss -1916.98856  validloss -1734.14403±0.00000  bestvalidloss -1789.40511  last_update 36\n",
      "train: iter 397  trainloss -1933.73527  validloss -1715.61245±0.00000  bestvalidloss -1789.40511  last_update 37\n",
      "train: iter 398  trainloss -1930.37720  validloss -1718.13096±0.00000  bestvalidloss -1789.40511  last_update 38\n",
      "train: iter 399  trainloss -1932.96643  validloss -1745.66770±0.00000  bestvalidloss -1789.40511  last_update 39\n",
      "train: iter 400  trainloss -1962.10136  validloss -1710.20789±0.00000  bestvalidloss -1789.40511  last_update 40\n",
      "train: iter 401  trainloss -1764.63198  validloss -1772.08881±0.00000  bestvalidloss -1789.40511  last_update 41\n",
      "train: iter 402  trainloss -1643.94143  validloss -852.06374±0.00000  bestvalidloss -1789.40511  last_update 42\n",
      "train: iter 403  trainloss -1901.64652  validloss -1547.58374±0.00000  bestvalidloss -1789.40511  last_update 43\n",
      "train: iter 404  trainloss -1943.24021  validloss -1737.14924±0.00000  bestvalidloss -1789.40511  last_update 44\n",
      "train: iter 405  trainloss -1932.80651  validloss -1774.99925±0.00000  bestvalidloss -1789.40511  last_update 45\n",
      "train: iter 406  trainloss -1931.82546  validloss -1698.33159±0.00000  bestvalidloss -1789.40511  last_update 46\n",
      "train: iter 407  trainloss -1914.66712  validloss -1641.40055±0.00000  bestvalidloss -1789.40511  last_update 47\n",
      "train: iter 408  trainloss -1949.35078  validloss -1751.78826±0.00000  bestvalidloss -1789.40511  last_update 48\n",
      "train: iter 409  trainloss -1937.81572  validloss -1737.09460±0.00000  bestvalidloss -1789.40511  last_update 49\n",
      "train: iter 410  trainloss -1961.99810  validloss -1753.23191±0.00000  bestvalidloss -1789.40511  last_update 50\n",
      "train: iter 411  trainloss -1972.28826  validloss -1775.37529±0.00000  bestvalidloss -1789.40511  last_update 51\n",
      "train: iter 412  trainloss -1979.00043  validloss -1788.11673±0.00000  bestvalidloss -1789.40511  last_update 52\n",
      "train: iter 413  trainloss -1633.92045  validloss -1765.59960±0.00000  bestvalidloss -1789.40511  last_update 53\n",
      "train: iter 414  trainloss -1881.13433  validloss -1457.85252±0.00000  bestvalidloss -1789.40511  last_update 54\n",
      "train: iter 415  trainloss -1865.09093  validloss -1735.57118±0.00000  bestvalidloss -1789.40511  last_update 55\n",
      "train: iter 416  trainloss -1945.33669  validloss -1766.21584±0.00000  bestvalidloss -1789.40511  last_update 56\n",
      "train: iter 417  trainloss -1905.46688  validloss -1755.31069±0.00000  bestvalidloss -1789.40511  last_update 57\n",
      "train: iter 418  trainloss -1946.09095  validloss -1746.75404±0.00000  bestvalidloss -1789.40511  last_update 58\n",
      "train: iter 419  trainloss -1915.88867  validloss -1699.45867±0.00000  bestvalidloss -1789.40511  last_update 59\n",
      "train: iter 420  trainloss -1962.56488  validloss -1749.47695±0.00000  bestvalidloss -1789.40511  last_update 60\n",
      "train: iter 421  trainloss -1901.66468  validloss -1675.86872±0.00000  bestvalidloss -1789.40511  last_update 61\n",
      "train: iter 422  trainloss -1868.75859  validloss -1666.68807±0.00000  bestvalidloss -1789.40511  last_update 62\n",
      "train: iter 423  trainloss -1747.84705  validloss -1390.17148±0.00000  bestvalidloss -1789.40511  last_update 63\n",
      "train: iter 424  trainloss -1893.34830  validloss -1645.62041±0.00000  bestvalidloss -1789.40511  last_update 64\n",
      "train: iter 425  trainloss -1956.66694  validloss -1750.91577±0.00000  bestvalidloss -1789.40511  last_update 65\n",
      "train: iter 426  trainloss -1952.80665  validloss -1757.64047±0.00000  bestvalidloss -1789.40511  last_update 66\n",
      "train: iter 427  trainloss -1735.61412  validloss -1412.63631±0.00000  bestvalidloss -1789.40511  last_update 67\n",
      "train: iter 428  trainloss -1951.05313  validloss -1746.00022±0.00000  bestvalidloss -1789.40511  last_update 68\n",
      "train: iter 429  trainloss -1886.02444  validloss -1701.30523±0.00000  bestvalidloss -1789.40511  last_update 69\n",
      "train: iter 430  trainloss -1927.86032  validloss -1723.29209±0.00000  bestvalidloss -1789.40511  last_update 70\n",
      "train: iter 431  trainloss -1942.75410  validloss -1762.19753±0.00000  bestvalidloss -1789.40511  last_update 71\n",
      "train: iter 432  trainloss -1951.84714  validloss -1707.45909±0.00000  bestvalidloss -1789.40511  last_update 72\n",
      "train: iter 433  trainloss -1954.40721  validloss -1759.26227±0.00000  bestvalidloss -1789.40511  last_update 73\n",
      "train: iter 434  trainloss -1952.58247  validloss -1748.92116±0.00000  bestvalidloss -1789.40511  last_update 74\n",
      "train: iter 435  trainloss -1780.68476  validloss -1574.06207±0.00000  bestvalidloss -1789.40511  last_update 75\n",
      "train: iter 436  trainloss -1874.98603  validloss -1373.24557±0.00000  bestvalidloss -1789.40511  last_update 76\n",
      "train: iter 437  trainloss -1952.70988  validloss -1712.11521±0.00000  bestvalidloss -1789.40511  last_update 77\n",
      "train: iter 438  trainloss -1965.55561  validloss -1743.23913±0.00000  bestvalidloss -1789.40511  last_update 78\n",
      "train: iter 439  trainloss -1965.20249  validloss -1762.51898±0.00000  bestvalidloss -1789.40511  last_update 79\n",
      "train: iter 440  trainloss -1939.40700  validloss -1767.25341±0.00000  bestvalidloss -1789.40511  last_update 80\n",
      "train: iter 441  trainloss -1756.40561  validloss -1595.39324±0.00000  bestvalidloss -1789.40511  last_update 81\n",
      "train: iter 442  trainloss -1902.20661  validloss -1265.76029±0.00000  bestvalidloss -1789.40511  last_update 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 443  trainloss -1942.20327  validloss -1720.21609±0.00000  bestvalidloss -1789.40511  last_update 83\n",
      "train: iter 444  trainloss -1904.21444  validloss -1736.28821±0.00000  bestvalidloss -1789.40511  last_update 84\n",
      "train: iter 445  trainloss -1953.86121  validloss -1691.95770±0.00000  bestvalidloss -1789.40511  last_update 85\n",
      "train: iter 446  trainloss -1904.53993  validloss -1651.16192±0.00000  bestvalidloss -1789.40511  last_update 86\n",
      "train: iter 447  trainloss -1894.53816  validloss -1665.27889±0.00000  bestvalidloss -1789.40511  last_update 87\n",
      "train: iter 448  trainloss -1959.03612  validloss -1741.29286±0.00000  bestvalidloss -1789.40511  last_update 88\n",
      "train: iter 449  trainloss -1967.17360  validloss -1748.43324±0.00000  bestvalidloss -1789.40511  last_update 89\n",
      "train: iter 450  trainloss -1798.23607  validloss -1424.00986±0.00000  bestvalidloss -1789.40511  last_update 90\n",
      "train: iter 451  trainloss -1951.41938  validloss -1719.62004±0.00000  bestvalidloss -1789.40511  last_update 91\n",
      "train: iter 452  trainloss -1940.24391  validloss -1719.29004±0.00000  bestvalidloss -1789.40511  last_update 92\n",
      "train: iter 453  trainloss -1936.55283  validloss -1747.63432±0.00000  bestvalidloss -1789.40511  last_update 93\n",
      "train: iter 454  trainloss -1920.79586  validloss -1679.82998±0.00000  bestvalidloss -1789.40511  last_update 94\n",
      "train: iter 455  trainloss -1902.58228  validloss -1665.13949±0.00000  bestvalidloss -1789.40511  last_update 95\n",
      "train: iter 456  trainloss -1912.31040  validloss -1645.12434±0.00000  bestvalidloss -1789.40511  last_update 96\n",
      "train: iter 457  trainloss -1961.20977  validloss -1702.77569±0.00000  bestvalidloss -1789.40511  last_update 97\n",
      "train: iter 458  trainloss -1934.53856  validloss -1697.62156±0.00000  bestvalidloss -1789.40511  last_update 98\n",
      "train: iter 459  trainloss -1946.91408  validloss -1695.31339±0.00000  bestvalidloss -1789.40511  last_update 99\n",
      "train: iter 460  trainloss -1910.79942  validloss -1656.27165±0.00000  bestvalidloss -1789.40511  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.0940) penalty_target_max tensor(18.4545)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 8.34623  validloss 8.60471±0.00000  bestvalidloss 8.60471  last_update 0\n",
      "train: iter 1  trainloss 7.61238  validloss 7.79045±0.00000  bestvalidloss 7.79045  last_update 0\n",
      "train: iter 2  trainloss 7.00391  validloss 7.12602±0.00000  bestvalidloss 7.12602  last_update 0\n",
      "train: iter 3  trainloss 6.49376  validloss 6.61252±0.00000  bestvalidloss 6.61252  last_update 0\n",
      "train: iter 4  trainloss 6.08510  validloss 6.16922±0.00000  bestvalidloss 6.16922  last_update 0\n",
      "train: iter 5  trainloss 5.72749  validloss 5.79342±0.00000  bestvalidloss 5.79342  last_update 0\n",
      "train: iter 6  trainloss 5.42215  validloss 5.45898±0.00000  bestvalidloss 5.45898  last_update 0\n",
      "train: iter 7  trainloss 5.16584  validloss 5.20702±0.00000  bestvalidloss 5.20702  last_update 0\n",
      "train: iter 8  trainloss 4.93122  validloss 4.97379±0.00000  bestvalidloss 4.97379  last_update 0\n",
      "train: iter 9  trainloss 4.73927  validloss 4.75356±0.00000  bestvalidloss 4.75356  last_update 0\n",
      "train: iter 10  trainloss 4.56356  validloss 4.57928±0.00000  bestvalidloss 4.57928  last_update 0\n",
      "train: iter 11  trainloss 4.41459  validloss 4.41019±0.00000  bestvalidloss 4.41019  last_update 0\n",
      "train: iter 12  trainloss 4.26731  validloss 4.27450±0.00000  bestvalidloss 4.27450  last_update 0\n",
      "train: iter 13  trainloss 4.14541  validloss 4.14414±0.00000  bestvalidloss 4.14414  last_update 0\n",
      "train: iter 14  trainloss 4.03821  validloss 4.03003±0.00000  bestvalidloss 4.03003  last_update 0\n",
      "train: iter 15  trainloss 3.93074  validloss 3.92634±0.00000  bestvalidloss 3.92634  last_update 0\n",
      "train: iter 16  trainloss 3.83191  validloss 3.83276±0.00000  bestvalidloss 3.83276  last_update 0\n",
      "train: iter 17  trainloss 3.73724  validloss 3.74543±0.00000  bestvalidloss 3.74543  last_update 0\n",
      "train: iter 18  trainloss 3.64982  validloss 3.64703±0.00000  bestvalidloss 3.64703  last_update 0\n",
      "train: iter 19  trainloss 3.56628  validloss 3.56546±0.00000  bestvalidloss 3.56546  last_update 0\n",
      "train: iter 20  trainloss 3.48130  validloss 3.48878±0.00000  bestvalidloss 3.48878  last_update 0\n",
      "train: iter 21  trainloss 3.40350  validloss 3.40108±0.00000  bestvalidloss 3.40108  last_update 0\n",
      "train: iter 22  trainloss 3.32087  validloss 3.32319±0.00000  bestvalidloss 3.32319  last_update 0\n",
      "train: iter 23  trainloss 3.23860  validloss 3.24209±0.00000  bestvalidloss 3.24209  last_update 0\n",
      "train: iter 24  trainloss 3.15670  validloss 3.15230±0.00000  bestvalidloss 3.15230  last_update 0\n",
      "train: iter 25  trainloss 3.07254  validloss 3.07956±0.00000  bestvalidloss 3.07956  last_update 0\n",
      "train: iter 26  trainloss 2.99024  validloss 3.00764±0.00000  bestvalidloss 3.00764  last_update 0\n",
      "train: iter 27  trainloss 2.90658  validloss 2.91667±0.00000  bestvalidloss 2.91667  last_update 0\n",
      "train: iter 28  trainloss 2.82036  validloss 2.83079±0.00000  bestvalidloss 2.83079  last_update 0\n",
      "train: iter 29  trainloss 2.73249  validloss 2.74761±0.00000  bestvalidloss 2.74761  last_update 0\n",
      "train: iter 30  trainloss 2.64853  validloss 2.66466±0.00000  bestvalidloss 2.66466  last_update 0\n",
      "train: iter 31  trainloss 2.56021  validloss 2.58345±0.00000  bestvalidloss 2.58345  last_update 0\n",
      "train: iter 32  trainloss 2.47199  validloss 2.49054±0.00000  bestvalidloss 2.49054  last_update 0\n",
      "train: iter 33  trainloss 2.38358  validloss 2.40773±0.00000  bestvalidloss 2.40773  last_update 0\n",
      "train: iter 34  trainloss 2.29991  validloss 2.32645±0.00000  bestvalidloss 2.32645  last_update 0\n",
      "train: iter 35  trainloss 2.21827  validloss 2.24334±0.00000  bestvalidloss 2.24334  last_update 0\n",
      "train: iter 36  trainloss 2.13147  validloss 2.15761±0.00000  bestvalidloss 2.15761  last_update 0\n",
      "train: iter 37  trainloss 2.05255  validloss 2.08263±0.00000  bestvalidloss 2.08263  last_update 0\n",
      "train: iter 38  trainloss 1.97030  validloss 2.00508±0.00000  bestvalidloss 2.00508  last_update 0\n",
      "train: iter 39  trainloss 1.89328  validloss 1.93032±0.00000  bestvalidloss 1.93032  last_update 0\n",
      "train: iter 40  trainloss 1.81468  validloss 1.85526±0.00000  bestvalidloss 1.85526  last_update 0\n",
      "train: iter 41  trainloss 1.73550  validloss 1.78213±0.00000  bestvalidloss 1.78213  last_update 0\n",
      "train: iter 42  trainloss 1.65410  validloss 1.69559±0.00000  bestvalidloss 1.69559  last_update 0\n",
      "train: iter 43  trainloss 1.57501  validloss 1.61656±0.00000  bestvalidloss 1.61656  last_update 0\n",
      "train: iter 44  trainloss 1.49043  validloss 1.54955±0.00000  bestvalidloss 1.54955  last_update 0\n",
      "train: iter 45  trainloss 1.40720  validloss 1.46136±0.00000  bestvalidloss 1.46136  last_update 0\n",
      "train: iter 46  trainloss 1.32524  validloss 1.38836±0.00000  bestvalidloss 1.38836  last_update 0\n",
      "train: iter 47  trainloss 1.23877  validloss 1.31097±0.00000  bestvalidloss 1.31097  last_update 0\n",
      "train: iter 48  trainloss 1.15363  validloss 1.24051±0.00000  bestvalidloss 1.24051  last_update 0\n",
      "train: iter 49  trainloss 1.06488  validloss 1.14307±0.00000  bestvalidloss 1.14307  last_update 0\n",
      "train: iter 50  trainloss 0.97909  validloss 1.06340±0.00000  bestvalidloss 1.06340  last_update 0\n",
      "train: iter 51  trainloss 0.89107  validloss 0.97711±0.00000  bestvalidloss 0.97711  last_update 0\n",
      "train: iter 52  trainloss 0.80755  validloss 0.88769±0.00000  bestvalidloss 0.88769  last_update 0\n",
      "train: iter 53  trainloss 0.71663  validloss 0.80740±0.00000  bestvalidloss 0.80740  last_update 0\n",
      "train: iter 54  trainloss 0.62699  validloss 0.71897±0.00000  bestvalidloss 0.71897  last_update 0\n",
      "train: iter 55  trainloss 0.54370  validloss 0.63774±0.00000  bestvalidloss 0.63774  last_update 0\n",
      "train: iter 56  trainloss 0.46451  validloss 0.58307±0.00000  bestvalidloss 0.58307  last_update 0\n",
      "train: iter 57  trainloss 0.37725  validloss 0.52028±0.00000  bestvalidloss 0.52028  last_update 0\n",
      "train: iter 58  trainloss 0.30035  validloss 0.40671±0.00000  bestvalidloss 0.40671  last_update 0\n",
      "train: iter 59  trainloss 0.21663  validloss 0.34136±0.00000  bestvalidloss 0.34136  last_update 0\n",
      "train: iter 60  trainloss 0.14004  validloss 0.28470±0.00000  bestvalidloss 0.28470  last_update 0\n",
      "train: iter 61  trainloss 0.06739  validloss 0.21384±0.00000  bestvalidloss 0.21384  last_update 0\n",
      "train: iter 62  trainloss -0.00982  validloss 0.16087±0.00000  bestvalidloss 0.16087  last_update 0\n",
      "train: iter 63  trainloss -0.07653  validloss 0.05415±0.00000  bestvalidloss 0.05415  last_update 0\n",
      "train: iter 64  trainloss -0.15279  validloss 0.00720±0.00000  bestvalidloss 0.00720  last_update 0\n",
      "train: iter 65  trainloss -0.21174  validloss -0.05927±0.00000  bestvalidloss -0.05927  last_update 0\n",
      "train: iter 66  trainloss -0.28428  validloss -0.06909±0.00000  bestvalidloss -0.06909  last_update 0\n",
      "train: iter 67  trainloss -0.35079  validloss -0.16761±0.00000  bestvalidloss -0.16761  last_update 0\n",
      "train: iter 68  trainloss -0.43302  validloss -0.16288±0.00000  bestvalidloss -0.16761  last_update 1\n",
      "train: iter 69  trainloss -0.49502  validloss -0.26303±0.00000  bestvalidloss -0.26303  last_update 0\n",
      "train: iter 70  trainloss -0.56185  validloss -0.29259±0.00000  bestvalidloss -0.29259  last_update 0\n",
      "train: iter 71  trainloss -0.61242  validloss -0.34483±0.00000  bestvalidloss -0.34483  last_update 0\n",
      "train: iter 72  trainloss -0.67911  validloss -0.38636±0.00000  bestvalidloss -0.38636  last_update 0\n",
      "train: iter 73  trainloss -0.74399  validloss -0.46047±0.00000  bestvalidloss -0.46047  last_update 0\n",
      "train: iter 74  trainloss -0.81283  validloss -0.44744±0.00000  bestvalidloss -0.46047  last_update 1\n",
      "train: iter 75  trainloss -0.84869  validloss -0.55484±0.00000  bestvalidloss -0.55484  last_update 0\n",
      "train: iter 76  trainloss -0.90555  validloss -0.61398±0.00000  bestvalidloss -0.61398  last_update 0\n",
      "train: iter 77  trainloss -0.97241  validloss -0.54205±0.00000  bestvalidloss -0.61398  last_update 1\n",
      "train: iter 78  trainloss -1.02670  validloss -0.68318±0.00000  bestvalidloss -0.68318  last_update 0\n",
      "train: iter 79  trainloss -1.07658  validloss -0.68847±0.00000  bestvalidloss -0.68847  last_update 0\n",
      "train: iter 80  trainloss -1.13750  validloss -0.72706±0.00000  bestvalidloss -0.72706  last_update 0\n",
      "train: iter 81  trainloss -1.18818  validloss -0.72126±0.00000  bestvalidloss -0.72706  last_update 1\n",
      "train: iter 82  trainloss -1.21652  validloss -0.83154±0.00000  bestvalidloss -0.83154  last_update 0\n",
      "train: iter 83  trainloss -1.26644  validloss -0.78954±0.00000  bestvalidloss -0.83154  last_update 1\n",
      "train: iter 84  trainloss -1.35019  validloss -0.82840±0.00000  bestvalidloss -0.83154  last_update 2\n",
      "train: iter 85  trainloss -1.38065  validloss -0.81084±0.00000  bestvalidloss -0.83154  last_update 3\n",
      "train: iter 86  trainloss -1.40367  validloss -0.86178±0.00000  bestvalidloss -0.86178  last_update 0\n",
      "train: iter 87  trainloss -1.43802  validloss -0.93478±0.00000  bestvalidloss -0.93478  last_update 0\n",
      "train: iter 88  trainloss -1.52609  validloss -0.87171±0.00000  bestvalidloss -0.93478  last_update 1\n",
      "train: iter 89  trainloss -1.51770  validloss -0.97343±0.00000  bestvalidloss -0.97343  last_update 0\n",
      "train: iter 90  trainloss -1.55998  validloss -0.96094±0.00000  bestvalidloss -0.97343  last_update 1\n",
      "train: iter 91  trainloss -1.60908  validloss -1.06505±0.00000  bestvalidloss -1.06505  last_update 0\n",
      "train: iter 92  trainloss -1.67917  validloss -0.94231±0.00000  bestvalidloss -1.06505  last_update 1\n",
      "train: iter 93  trainloss -1.69887  validloss -1.01231±0.00000  bestvalidloss -1.06505  last_update 2\n",
      "train: iter 94  trainloss -1.72907  validloss -0.96672±0.00000  bestvalidloss -1.06505  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 95  trainloss -1.74233  validloss -0.94833±0.00000  bestvalidloss -1.06505  last_update 4\n",
      "train: iter 96  trainloss -1.80809  validloss -0.99181±0.00000  bestvalidloss -1.06505  last_update 5\n",
      "train: iter 97  trainloss -1.83656  validloss -0.85894±0.00000  bestvalidloss -1.06505  last_update 6\n",
      "train: iter 98  trainloss -1.83362  validloss -0.81474±0.00000  bestvalidloss -1.06505  last_update 7\n",
      "train: iter 99  trainloss -1.88300  validloss -1.05763±0.00000  bestvalidloss -1.06505  last_update 8\n",
      "train: iter 100  trainloss -1.89407  validloss -0.94402±0.00000  bestvalidloss -1.06505  last_update 9\n",
      "train: iter 101  trainloss -1.89441  validloss -0.95303±0.00000  bestvalidloss -1.06505  last_update 10\n",
      "train: iter 102  trainloss -1.97168  validloss -0.96053±0.00000  bestvalidloss -1.06505  last_update 11\n",
      "train: iter 103  trainloss -1.99629  validloss -1.09621±0.00000  bestvalidloss -1.09621  last_update 0\n",
      "train: iter 104  trainloss -2.02748  validloss -0.89144±0.00000  bestvalidloss -1.09621  last_update 1\n",
      "train: iter 105  trainloss -2.04712  validloss -0.96137±0.00000  bestvalidloss -1.09621  last_update 2\n",
      "train: iter 106  trainloss -2.06174  validloss -0.79898±0.00000  bestvalidloss -1.09621  last_update 3\n",
      "train: iter 107  trainloss -2.06807  validloss -0.93406±0.00000  bestvalidloss -1.09621  last_update 4\n",
      "train: iter 108  trainloss -2.12870  validloss -1.00402±0.00000  bestvalidloss -1.09621  last_update 5\n",
      "train: iter 109  trainloss -2.13735  validloss -0.86774±0.00000  bestvalidloss -1.09621  last_update 6\n",
      "train: iter 110  trainloss -2.15793  validloss -1.13759±0.00000  bestvalidloss -1.13759  last_update 0\n",
      "train: iter 111  trainloss -2.19797  validloss -0.89679±0.00000  bestvalidloss -1.13759  last_update 1\n",
      "train: iter 112  trainloss -2.16446  validloss -0.84057±0.00000  bestvalidloss -1.13759  last_update 2\n",
      "train: iter 113  trainloss -2.19486  validloss -0.72869±0.00000  bestvalidloss -1.13759  last_update 3\n",
      "train: iter 114  trainloss -2.24020  validloss -0.91046±0.00000  bestvalidloss -1.13759  last_update 4\n",
      "train: iter 115  trainloss -2.18890  validloss -0.53604±0.00000  bestvalidloss -1.13759  last_update 5\n",
      "train: iter 116  trainloss -2.26839  validloss -0.87465±0.00000  bestvalidloss -1.13759  last_update 6\n",
      "train: iter 117  trainloss -2.25999  validloss -0.57657±0.00000  bestvalidloss -1.13759  last_update 7\n",
      "train: iter 118  trainloss -2.27663  validloss -1.14306±0.00000  bestvalidloss -1.14306  last_update 0\n",
      "train: iter 119  trainloss -2.27956  validloss -0.51461±0.00000  bestvalidloss -1.14306  last_update 1\n",
      "train: iter 120  trainloss -2.26943  validloss -0.80113±0.00000  bestvalidloss -1.14306  last_update 2\n",
      "train: iter 121  trainloss -2.26187  validloss -0.75212±0.00000  bestvalidloss -1.14306  last_update 3\n",
      "train: iter 122  trainloss -2.33374  validloss -0.69905±0.00000  bestvalidloss -1.14306  last_update 4\n",
      "train: iter 123  trainloss -2.29888  validloss -0.74457±0.00000  bestvalidloss -1.14306  last_update 5\n",
      "train: iter 124  trainloss -2.29040  validloss -0.66262±0.00000  bestvalidloss -1.14306  last_update 6\n",
      "train: iter 125  trainloss -2.25753  validloss -0.51470±0.00000  bestvalidloss -1.14306  last_update 7\n",
      "train: iter 126  trainloss -2.31342  validloss -0.61238±0.00000  bestvalidloss -1.14306  last_update 8\n",
      "train: iter 127  trainloss -2.35263  validloss -0.55095±0.00000  bestvalidloss -1.14306  last_update 9\n",
      "train: iter 128  trainloss -2.30331  validloss -0.38428±0.00000  bestvalidloss -1.14306  last_update 10\n",
      "train: iter 129  trainloss -2.26625  validloss -0.76187±0.00000  bestvalidloss -1.14306  last_update 11\n",
      "train: iter 130  trainloss -2.24830  validloss -0.20419±0.00000  bestvalidloss -1.14306  last_update 12\n",
      "train: iter 131  trainloss -2.30350  validloss -0.67678±0.00000  bestvalidloss -1.14306  last_update 13\n",
      "train: iter 132  trainloss -2.31498  validloss -0.50548±0.00000  bestvalidloss -1.14306  last_update 14\n",
      "train: iter 133  trainloss -2.34337  validloss -0.35145±0.00000  bestvalidloss -1.14306  last_update 15\n",
      "train: iter 134  trainloss -2.31146  validloss -0.40465±0.00000  bestvalidloss -1.14306  last_update 16\n",
      "train: iter 135  trainloss -2.38968  validloss -0.71425±0.00000  bestvalidloss -1.14306  last_update 17\n",
      "train: iter 136  trainloss -2.26584  validloss -0.53501±0.00000  bestvalidloss -1.14306  last_update 18\n",
      "train: iter 137  trainloss -2.31312  validloss -0.50638±0.00000  bestvalidloss -1.14306  last_update 19\n",
      "train: iter 138  trainloss -2.28264  validloss -0.25941±0.00000  bestvalidloss -1.14306  last_update 20\n",
      "train: iter 139  trainloss -2.35153  validloss -0.55374±0.00000  bestvalidloss -1.14306  last_update 21\n",
      "train: iter 140  trainloss -2.32473  validloss -0.32545±0.00000  bestvalidloss -1.14306  last_update 22\n",
      "train: iter 141  trainloss -2.32866  validloss -0.36099±0.00000  bestvalidloss -1.14306  last_update 23\n",
      "train: iter 142  trainloss -2.35990  validloss -0.46180±0.00000  bestvalidloss -1.14306  last_update 24\n",
      "train: iter 143  trainloss -2.36406  validloss -0.13801±0.00000  bestvalidloss -1.14306  last_update 25\n",
      "train: iter 144  trainloss -2.37245  validloss -0.20100±0.00000  bestvalidloss -1.14306  last_update 26\n",
      "train: iter 145  trainloss -2.37562  validloss -0.08252±0.00000  bestvalidloss -1.14306  last_update 27\n",
      "train: iter 146  trainloss -2.38180  validloss -0.36512±0.00000  bestvalidloss -1.14306  last_update 28\n",
      "train: iter 147  trainloss -2.32599  validloss 0.15493±0.00000  bestvalidloss -1.14306  last_update 29\n",
      "train: iter 148  trainloss -2.31600  validloss 0.01961±0.00000  bestvalidloss -1.14306  last_update 30\n",
      "train: iter 149  trainloss -2.35939  validloss -0.44658±0.00000  bestvalidloss -1.14306  last_update 31\n",
      "train: iter 150  trainloss -2.36738  validloss -0.14172±0.00000  bestvalidloss -1.14306  last_update 32\n",
      "train: iter 151  trainloss -2.30553  validloss -0.01309±0.00000  bestvalidloss -1.14306  last_update 33\n",
      "train: iter 152  trainloss -2.39232  validloss -0.04090±0.00000  bestvalidloss -1.14306  last_update 34\n",
      "train: iter 153  trainloss -2.25208  validloss -0.04643±0.00000  bestvalidloss -1.14306  last_update 35\n",
      "train: iter 154  trainloss -2.32501  validloss -0.30708±0.00000  bestvalidloss -1.14306  last_update 36\n",
      "train: iter 155  trainloss -2.27755  validloss 0.13556±0.00000  bestvalidloss -1.14306  last_update 37\n",
      "train: iter 156  trainloss -2.40174  validloss -0.06194±0.00000  bestvalidloss -1.14306  last_update 38\n",
      "train: iter 157  trainloss -2.35215  validloss -0.22115±0.00000  bestvalidloss -1.14306  last_update 39\n",
      "train: iter 158  trainloss -2.37686  validloss 0.05900±0.00000  bestvalidloss -1.14306  last_update 40\n",
      "train: iter 159  trainloss -2.32341  validloss -0.03326±0.00000  bestvalidloss -1.14306  last_update 41\n",
      "train: iter 160  trainloss -2.33109  validloss 0.02436±0.00000  bestvalidloss -1.14306  last_update 42\n",
      "train: iter 161  trainloss -2.34761  validloss -0.28680±0.00000  bestvalidloss -1.14306  last_update 43\n",
      "train: iter 162  trainloss -2.39017  validloss -0.34915±0.00000  bestvalidloss -1.14306  last_update 44\n",
      "train: iter 163  trainloss -2.37749  validloss 0.07689±0.00000  bestvalidloss -1.14306  last_update 45\n",
      "train: iter 164  trainloss -2.43018  validloss -0.25787±0.00000  bestvalidloss -1.14306  last_update 46\n",
      "train: iter 165  trainloss -2.31655  validloss -0.35551±0.00000  bestvalidloss -1.14306  last_update 47\n",
      "train: iter 166  trainloss -2.35633  validloss 0.17697±0.00000  bestvalidloss -1.14306  last_update 48\n",
      "train: iter 167  trainloss -2.34522  validloss -0.29723±0.00000  bestvalidloss -1.14306  last_update 49\n",
      "train: iter 168  trainloss -2.38304  validloss -0.38594±0.00000  bestvalidloss -1.14306  last_update 50\n",
      "train: iter 169  trainloss -2.32452  validloss 0.09969±0.00000  bestvalidloss -1.14306  last_update 51\n",
      "train: iter 170  trainloss -2.34289  validloss -0.56765±0.00000  bestvalidloss -1.14306  last_update 52\n",
      "train: iter 171  trainloss -2.33716  validloss 0.44477±0.00000  bestvalidloss -1.14306  last_update 53\n",
      "train: iter 172  trainloss -2.33717  validloss -0.05340±0.00000  bestvalidloss -1.14306  last_update 54\n",
      "train: iter 173  trainloss -2.29577  validloss 0.02801±0.00000  bestvalidloss -1.14306  last_update 55\n",
      "train: iter 174  trainloss -2.37380  validloss -0.10157±0.00000  bestvalidloss -1.14306  last_update 56\n",
      "train: iter 175  trainloss -2.36493  validloss -0.42439±0.00000  bestvalidloss -1.14306  last_update 57\n",
      "train: iter 176  trainloss -2.25341  validloss 0.06898±0.00000  bestvalidloss -1.14306  last_update 58\n",
      "train: iter 177  trainloss -2.29380  validloss -0.19885±0.00000  bestvalidloss -1.14306  last_update 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 178  trainloss -2.35298  validloss -0.14196±0.00000  bestvalidloss -1.14306  last_update 60\n",
      "train: iter 179  trainloss -2.34057  validloss -0.00714±0.00000  bestvalidloss -1.14306  last_update 61\n",
      "train: iter 180  trainloss -2.33995  validloss 0.13118±0.00000  bestvalidloss -1.14306  last_update 62\n",
      "train: iter 181  trainloss -2.31709  validloss -0.37240±0.00000  bestvalidloss -1.14306  last_update 63\n",
      "train: iter 182  trainloss -2.28859  validloss -0.16563±0.00000  bestvalidloss -1.14306  last_update 64\n",
      "train: iter 183  trainloss -2.26493  validloss 0.26851±0.00000  bestvalidloss -1.14306  last_update 65\n",
      "train: iter 184  trainloss -2.33088  validloss 0.02361±0.00000  bestvalidloss -1.14306  last_update 66\n",
      "train: iter 185  trainloss -2.27819  validloss -0.22919±0.00000  bestvalidloss -1.14306  last_update 67\n",
      "train: iter 186  trainloss -2.34686  validloss -0.39746±0.00000  bestvalidloss -1.14306  last_update 68\n",
      "train: iter 187  trainloss -2.34117  validloss -0.18089±0.00000  bestvalidloss -1.14306  last_update 69\n",
      "train: iter 188  trainloss -2.39494  validloss -0.14790±0.00000  bestvalidloss -1.14306  last_update 70\n",
      "train: iter 189  trainloss -2.32807  validloss -0.45411±0.00000  bestvalidloss -1.14306  last_update 71\n",
      "train: iter 190  trainloss -2.36059  validloss -0.13617±0.00000  bestvalidloss -1.14306  last_update 72\n",
      "train: iter 191  trainloss -2.35169  validloss -0.05336±0.00000  bestvalidloss -1.14306  last_update 73\n",
      "train: iter 192  trainloss -2.29928  validloss -0.20407±0.00000  bestvalidloss -1.14306  last_update 74\n",
      "train: iter 193  trainloss -2.36684  validloss -0.49650±0.00000  bestvalidloss -1.14306  last_update 75\n",
      "train: iter 194  trainloss -2.33185  validloss 0.33420±0.00000  bestvalidloss -1.14306  last_update 76\n",
      "train: iter 195  trainloss -2.33944  validloss -0.35319±0.00000  bestvalidloss -1.14306  last_update 77\n",
      "train: iter 196  trainloss -2.37309  validloss -0.12592±0.00000  bestvalidloss -1.14306  last_update 78\n",
      "train: iter 197  trainloss -2.27822  validloss -0.40106±0.00000  bestvalidloss -1.14306  last_update 79\n",
      "train: iter 198  trainloss -2.36418  validloss 0.11977±0.00000  bestvalidloss -1.14306  last_update 80\n",
      "train: iter 199  trainloss -2.34535  validloss 0.14754±0.00000  bestvalidloss -1.14306  last_update 81\n",
      "train: iter 200  trainloss -2.36390  validloss -0.21184±0.00000  bestvalidloss -1.14306  last_update 82\n",
      "train: iter 201  trainloss -2.33094  validloss 0.24039±0.00000  bestvalidloss -1.14306  last_update 83\n",
      "train: iter 202  trainloss -2.27008  validloss -0.36807±0.00000  bestvalidloss -1.14306  last_update 84\n",
      "train: iter 203  trainloss -2.34376  validloss -0.21562±0.00000  bestvalidloss -1.14306  last_update 85\n",
      "train: iter 204  trainloss -2.35572  validloss -0.20742±0.00000  bestvalidloss -1.14306  last_update 86\n",
      "train: iter 205  trainloss -2.33422  validloss -0.26889±0.00000  bestvalidloss -1.14306  last_update 87\n",
      "train: iter 206  trainloss -2.28906  validloss 0.34361±0.00000  bestvalidloss -1.14306  last_update 88\n",
      "train: iter 207  trainloss -2.26003  validloss -0.25859±0.00000  bestvalidloss -1.14306  last_update 89\n",
      "train: iter 208  trainloss -2.35825  validloss 0.09243±0.00000  bestvalidloss -1.14306  last_update 90\n",
      "train: iter 209  trainloss -2.30666  validloss -0.03272±0.00000  bestvalidloss -1.14306  last_update 91\n",
      "train: iter 210  trainloss -2.33281  validloss -0.42706±0.00000  bestvalidloss -1.14306  last_update 92\n",
      "train: iter 211  trainloss -2.40170  validloss -0.14160±0.00000  bestvalidloss -1.14306  last_update 93\n",
      "train: iter 212  trainloss -2.35474  validloss -0.14133±0.00000  bestvalidloss -1.14306  last_update 94\n",
      "train: iter 213  trainloss -2.31125  validloss -0.03850±0.00000  bestvalidloss -1.14306  last_update 95\n",
      "train: iter 214  trainloss -2.29795  validloss 0.04945±0.00000  bestvalidloss -1.14306  last_update 96\n",
      "train: iter 215  trainloss -2.31114  validloss -0.32324±0.00000  bestvalidloss -1.14306  last_update 97\n",
      "train: iter 216  trainloss -2.37104  validloss -0.35520±0.00000  bestvalidloss -1.14306  last_update 98\n",
      "train: iter 217  trainloss -2.32861  validloss -0.07738±0.00000  bestvalidloss -1.14306  last_update 99\n",
      "train: iter 218  trainloss -2.32504  validloss 0.11004±0.00000  bestvalidloss -1.14306  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.0616, -2.1096, -5.4833, -4.8519], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 86.19999  validloss 85.10554±0.00000  bestvalidloss 85.10554  last_update 0\n",
      "train: iter 1  trainloss 64.99169  validloss 65.77870±0.00000  bestvalidloss 65.77870  last_update 0\n",
      "train: iter 2  trainloss 50.96455  validloss 50.00049±0.00000  bestvalidloss 50.00049  last_update 0\n",
      "train: iter 3  trainloss 40.79596  validloss 40.12970±0.00000  bestvalidloss 40.12970  last_update 0\n",
      "train: iter 4  trainloss 32.23129  validloss 32.27347±0.00000  bestvalidloss 32.27347  last_update 0\n",
      "train: iter 5  trainloss 25.71460  validloss 25.95654±0.00000  bestvalidloss 25.95654  last_update 0\n",
      "train: iter 6  trainloss 20.65241  validloss 21.51435±0.00000  bestvalidloss 21.51435  last_update 0\n",
      "train: iter 7  trainloss 16.69480  validloss 18.22109±0.00000  bestvalidloss 18.22109  last_update 0\n",
      "train: iter 8  trainloss 13.56745  validloss 15.44901±0.00000  bestvalidloss 15.44901  last_update 0\n",
      "train: iter 9  trainloss 11.12570  validloss 13.47407±0.00000  bestvalidloss 13.47407  last_update 0\n",
      "train: iter 10  trainloss 9.33019  validloss 12.25211±0.00000  bestvalidloss 12.25211  last_update 0\n",
      "train: iter 11  trainloss 7.86980  validloss 11.22632±0.00000  bestvalidloss 11.22632  last_update 0\n",
      "train: iter 12  trainloss 6.76216  validloss 10.69756±0.00000  bestvalidloss 10.69756  last_update 0\n",
      "train: iter 13  trainloss 5.95599  validloss 10.25371±0.00000  bestvalidloss 10.25371  last_update 0\n",
      "train: iter 14  trainloss 5.32527  validloss 10.25711±0.00000  bestvalidloss 10.25371  last_update 1\n",
      "train: iter 15  trainloss 4.88943  validloss 9.89431±0.00000  bestvalidloss 9.89431  last_update 0\n",
      "train: iter 16  trainloss 4.55643  validloss 10.13935±0.00000  bestvalidloss 9.89431  last_update 1\n",
      "train: iter 17  trainloss 4.33890  validloss 10.01813±0.00000  bestvalidloss 9.89431  last_update 2\n",
      "train: iter 18  trainloss 4.17051  validloss 9.82120±0.00000  bestvalidloss 9.82120  last_update 0\n",
      "train: iter 19  trainloss 4.02976  validloss 10.19241±0.00000  bestvalidloss 9.82120  last_update 1\n",
      "train: iter 20  trainloss 3.90992  validloss 10.13204±0.00000  bestvalidloss 9.82120  last_update 2\n",
      "train: iter 21  trainloss 3.81631  validloss 9.91154±0.00000  bestvalidloss 9.82120  last_update 3\n",
      "train: iter 22  trainloss 3.78716  validloss 10.10359±0.00000  bestvalidloss 9.82120  last_update 4\n",
      "train: iter 23  trainloss 3.71552  validloss 10.31738±0.00000  bestvalidloss 9.82120  last_update 5\n",
      "train: iter 24  trainloss 3.63316  validloss 10.28854±0.00000  bestvalidloss 9.82120  last_update 6\n",
      "train: iter 25  trainloss 3.54327  validloss 10.25900±0.00000  bestvalidloss 9.82120  last_update 7\n",
      "train: iter 26  trainloss 3.46455  validloss 10.17425±0.00000  bestvalidloss 9.82120  last_update 8\n",
      "train: iter 27  trainloss 3.28272  validloss 9.59129±0.00000  bestvalidloss 9.59129  last_update 0\n",
      "train: iter 28  trainloss 3.06587  validloss 9.01045±0.00000  bestvalidloss 9.01045  last_update 0\n",
      "train: iter 29  trainloss 2.96313  validloss 7.75552±0.00000  bestvalidloss 7.75552  last_update 0\n",
      "train: iter 30  trainloss 2.86321  validloss 7.75822±0.00000  bestvalidloss 7.75552  last_update 1\n",
      "train: iter 31  trainloss 2.79800  validloss 7.85848±0.00000  bestvalidloss 7.75552  last_update 2\n",
      "train: iter 32  trainloss 2.73308  validloss 7.42867±0.00000  bestvalidloss 7.42867  last_update 0\n",
      "train: iter 33  trainloss 2.68992  validloss 7.93535±0.00000  bestvalidloss 7.42867  last_update 1\n",
      "train: iter 34  trainloss 2.64148  validloss 6.98916±0.00000  bestvalidloss 6.98916  last_update 0\n",
      "train: iter 35  trainloss 2.62747  validloss 7.31023±0.00000  bestvalidloss 6.98916  last_update 1\n",
      "train: iter 36  trainloss 2.58188  validloss 7.22543±0.00000  bestvalidloss 6.98916  last_update 2\n",
      "train: iter 37  trainloss 2.55189  validloss 7.05361±0.00000  bestvalidloss 6.98916  last_update 3\n",
      "train: iter 38  trainloss 2.55566  validloss 7.32351±0.00000  bestvalidloss 6.98916  last_update 4\n",
      "train: iter 39  trainloss 2.54736  validloss 7.15674±0.00000  bestvalidloss 6.98916  last_update 5\n",
      "train: iter 40  trainloss 2.49726  validloss 6.66938±0.00000  bestvalidloss 6.66938  last_update 0\n",
      "train: iter 41  trainloss 2.47868  validloss 6.79091±0.00000  bestvalidloss 6.66938  last_update 1\n",
      "train: iter 42  trainloss 2.49813  validloss 6.56693±0.00000  bestvalidloss 6.56693  last_update 0\n",
      "train: iter 43  trainloss 2.49604  validloss 6.78359±0.00000  bestvalidloss 6.56693  last_update 1\n",
      "train: iter 44  trainloss 2.47636  validloss 7.20373±0.00000  bestvalidloss 6.56693  last_update 2\n",
      "train: iter 45  trainloss 2.45485  validloss 7.12898±0.00000  bestvalidloss 6.56693  last_update 3\n",
      "train: iter 46  trainloss 2.46212  validloss 6.94350±0.00000  bestvalidloss 6.56693  last_update 4\n",
      "train: iter 47  trainloss 2.41806  validloss 6.95938±0.00000  bestvalidloss 6.56693  last_update 5\n",
      "train: iter 48  trainloss 2.41796  validloss 6.85578±0.00000  bestvalidloss 6.56693  last_update 6\n",
      "train: iter 49  trainloss 2.41462  validloss 7.35967±0.00000  bestvalidloss 6.56693  last_update 7\n",
      "train: iter 50  trainloss 2.40661  validloss 6.86053±0.00000  bestvalidloss 6.56693  last_update 8\n",
      "train: iter 51  trainloss 2.37518  validloss 7.01623±0.00000  bestvalidloss 6.56693  last_update 9\n",
      "train: iter 52  trainloss 2.38928  validloss 6.60345±0.00000  bestvalidloss 6.56693  last_update 10\n",
      "train: iter 53  trainloss 2.36128  validloss 6.91736±0.00000  bestvalidloss 6.56693  last_update 11\n",
      "train: iter 54  trainloss 2.37394  validloss 6.72433±0.00000  bestvalidloss 6.56693  last_update 12\n",
      "train: iter 55  trainloss 2.33193  validloss 6.67951±0.00000  bestvalidloss 6.56693  last_update 13\n",
      "train: iter 56  trainloss 2.30726  validloss 6.68713±0.00000  bestvalidloss 6.56693  last_update 14\n",
      "train: iter 57  trainloss 2.34187  validloss 6.57606±0.00000  bestvalidloss 6.56693  last_update 15\n",
      "train: iter 58  trainloss 2.29502  validloss 6.85385±0.00000  bestvalidloss 6.56693  last_update 16\n",
      "train: iter 59  trainloss 2.31351  validloss 6.58345±0.00000  bestvalidloss 6.56693  last_update 17\n",
      "train: iter 60  trainloss 2.29630  validloss 6.92372±0.00000  bestvalidloss 6.56693  last_update 18\n",
      "train: iter 61  trainloss 2.25777  validloss 6.73334±0.00000  bestvalidloss 6.56693  last_update 19\n",
      "train: iter 62  trainloss 2.25698  validloss 6.36069±0.00000  bestvalidloss 6.36069  last_update 0\n",
      "train: iter 63  trainloss 2.27878  validloss 6.33322±0.00000  bestvalidloss 6.33322  last_update 0\n",
      "train: iter 64  trainloss 2.21840  validloss 6.22151±0.00000  bestvalidloss 6.22151  last_update 0\n",
      "train: iter 65  trainloss 2.20136  validloss 6.05786±0.00000  bestvalidloss 6.05786  last_update 0\n",
      "train: iter 66  trainloss 2.19841  validloss 6.50698±0.00000  bestvalidloss 6.05786  last_update 1\n",
      "train: iter 67  trainloss 2.20327  validloss 6.87757±0.00000  bestvalidloss 6.05786  last_update 2\n",
      "train: iter 68  trainloss 2.23220  validloss 6.74927±0.00000  bestvalidloss 6.05786  last_update 3\n",
      "train: iter 69  trainloss 2.18201  validloss 6.85432±0.00000  bestvalidloss 6.05786  last_update 4\n",
      "train: iter 70  trainloss 2.16185  validloss 6.72243±0.00000  bestvalidloss 6.05786  last_update 5\n",
      "train: iter 71  trainloss 2.17218  validloss 6.40285±0.00000  bestvalidloss 6.05786  last_update 6\n",
      "train: iter 72  trainloss 2.14719  validloss 6.36171±0.00000  bestvalidloss 6.05786  last_update 7\n",
      "train: iter 73  trainloss 2.19236  validloss 6.48510±0.00000  bestvalidloss 6.05786  last_update 8\n",
      "train: iter 74  trainloss 2.16729  validloss 6.47236±0.00000  bestvalidloss 6.05786  last_update 9\n",
      "train: iter 75  trainloss 2.15753  validloss 6.60420±0.00000  bestvalidloss 6.05786  last_update 10\n",
      "train: iter 76  trainloss 2.16408  validloss 6.81922±0.00000  bestvalidloss 6.05786  last_update 11\n",
      "train: iter 77  trainloss 2.16141  validloss 6.48002±0.00000  bestvalidloss 6.05786  last_update 12\n",
      "train: iter 78  trainloss 2.15336  validloss 6.25314±0.00000  bestvalidloss 6.05786  last_update 13\n",
      "train: iter 79  trainloss 2.17985  validloss 6.17581±0.00000  bestvalidloss 6.05786  last_update 14\n",
      "train: iter 80  trainloss 2.18376  validloss 6.27983±0.00000  bestvalidloss 6.05786  last_update 15\n",
      "train: iter 81  trainloss 2.15480  validloss 6.89721±0.00000  bestvalidloss 6.05786  last_update 16\n",
      "train: iter 82  trainloss 2.16057  validloss 6.70801±0.00000  bestvalidloss 6.05786  last_update 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 2.13771  validloss 6.41777±0.00000  bestvalidloss 6.05786  last_update 18\n",
      "train: iter 84  trainloss 2.13787  validloss 6.44125±0.00000  bestvalidloss 6.05786  last_update 19\n",
      "train: iter 85  trainloss 2.13847  validloss 6.70002±0.00000  bestvalidloss 6.05786  last_update 20\n",
      "train: iter 86  trainloss 2.18300  validloss 6.30698±0.00000  bestvalidloss 6.05786  last_update 21\n",
      "train: iter 87  trainloss 2.18752  validloss 6.62139±0.00000  bestvalidloss 6.05786  last_update 22\n",
      "train: iter 88  trainloss 2.16344  validloss 6.42258±0.00000  bestvalidloss 6.05786  last_update 23\n",
      "train: iter 89  trainloss 2.13028  validloss 6.04633±0.00000  bestvalidloss 6.04633  last_update 0\n",
      "train: iter 90  trainloss 2.15240  validloss 6.84309±0.00000  bestvalidloss 6.04633  last_update 1\n",
      "train: iter 91  trainloss 2.13718  validloss 6.17621±0.00000  bestvalidloss 6.04633  last_update 2\n",
      "train: iter 92  trainloss 2.14022  validloss 6.63693±0.00000  bestvalidloss 6.04633  last_update 3\n",
      "train: iter 93  trainloss 2.11029  validloss 6.91759±0.00000  bestvalidloss 6.04633  last_update 4\n",
      "train: iter 94  trainloss 2.18280  validloss 6.09794±0.00000  bestvalidloss 6.04633  last_update 5\n",
      "train: iter 95  trainloss 2.11112  validloss 6.01788±0.00000  bestvalidloss 6.01788  last_update 0\n",
      "train: iter 96  trainloss 2.16921  validloss 7.04912±0.00000  bestvalidloss 6.01788  last_update 1\n",
      "train: iter 97  trainloss 2.15303  validloss 6.62270±0.00000  bestvalidloss 6.01788  last_update 2\n",
      "train: iter 98  trainloss 2.15485  validloss 6.81982±0.00000  bestvalidloss 6.01788  last_update 3\n",
      "train: iter 99  trainloss 2.13729  validloss 6.35303±0.00000  bestvalidloss 6.01788  last_update 4\n",
      "train: iter 100  trainloss 2.11878  validloss 6.90840±0.00000  bestvalidloss 6.01788  last_update 5\n",
      "train: iter 101  trainloss 2.20712  validloss 6.05734±0.00000  bestvalidloss 6.01788  last_update 6\n",
      "train: iter 102  trainloss 2.13567  validloss 6.47939±0.00000  bestvalidloss 6.01788  last_update 7\n",
      "train: iter 103  trainloss 2.12923  validloss 6.26029±0.00000  bestvalidloss 6.01788  last_update 8\n",
      "train: iter 104  trainloss 2.14281  validloss 6.65445±0.00000  bestvalidloss 6.01788  last_update 9\n",
      "train: iter 105  trainloss 2.16164  validloss 6.31141±0.00000  bestvalidloss 6.01788  last_update 10\n",
      "train: iter 106  trainloss 2.14536  validloss 6.58599±0.00000  bestvalidloss 6.01788  last_update 11\n",
      "train: iter 107  trainloss 2.12351  validloss 6.48133±0.00000  bestvalidloss 6.01788  last_update 12\n",
      "train: iter 108  trainloss 2.15376  validloss 7.08604±0.00000  bestvalidloss 6.01788  last_update 13\n",
      "train: iter 109  trainloss 2.10018  validloss 6.54108±0.00000  bestvalidloss 6.01788  last_update 14\n",
      "train: iter 110  trainloss 2.11527  validloss 6.41228±0.00000  bestvalidloss 6.01788  last_update 15\n",
      "train: iter 111  trainloss 2.13240  validloss 6.12856±0.00000  bestvalidloss 6.01788  last_update 16\n",
      "train: iter 112  trainloss 2.15486  validloss 6.10285±0.00000  bestvalidloss 6.01788  last_update 17\n",
      "train: iter 113  trainloss 2.09967  validloss 6.35661±0.00000  bestvalidloss 6.01788  last_update 18\n",
      "train: iter 114  trainloss 2.12935  validloss 6.27361±0.00000  bestvalidloss 6.01788  last_update 19\n",
      "train: iter 115  trainloss 2.13493  validloss 6.24166±0.00000  bestvalidloss 6.01788  last_update 20\n",
      "train: iter 116  trainloss 2.18865  validloss 6.23889±0.00000  bestvalidloss 6.01788  last_update 21\n",
      "train: iter 117  trainloss 2.12830  validloss 6.36281±0.00000  bestvalidloss 6.01788  last_update 22\n",
      "train: iter 118  trainloss 2.13916  validloss 6.28024±0.00000  bestvalidloss 6.01788  last_update 23\n",
      "train: iter 119  trainloss 2.10918  validloss 6.49362±0.00000  bestvalidloss 6.01788  last_update 24\n",
      "train: iter 120  trainloss 2.12586  validloss 6.75950±0.00000  bestvalidloss 6.01788  last_update 25\n",
      "train: iter 121  trainloss 2.12462  validloss 6.60391±0.00000  bestvalidloss 6.01788  last_update 26\n",
      "train: iter 122  trainloss 2.11113  validloss 6.70595±0.00000  bestvalidloss 6.01788  last_update 27\n",
      "train: iter 123  trainloss 2.15636  validloss 6.32247±0.00000  bestvalidloss 6.01788  last_update 28\n",
      "train: iter 124  trainloss 2.12135  validloss 6.62717±0.00000  bestvalidloss 6.01788  last_update 29\n",
      "train: iter 125  trainloss 2.09405  validloss 6.78056±0.00000  bestvalidloss 6.01788  last_update 30\n",
      "train: iter 126  trainloss 2.12472  validloss 6.37385±0.00000  bestvalidloss 6.01788  last_update 31\n",
      "train: iter 127  trainloss 2.08647  validloss 6.55863±0.00000  bestvalidloss 6.01788  last_update 32\n",
      "train: iter 128  trainloss 2.12703  validloss 6.35315±0.00000  bestvalidloss 6.01788  last_update 33\n",
      "train: iter 129  trainloss 2.14469  validloss 6.51711±0.00000  bestvalidloss 6.01788  last_update 34\n",
      "train: iter 130  trainloss 2.11657  validloss 6.69571±0.00000  bestvalidloss 6.01788  last_update 35\n",
      "train: iter 131  trainloss 2.10957  validloss 6.71273±0.00000  bestvalidloss 6.01788  last_update 36\n",
      "train: iter 132  trainloss 2.11385  validloss 6.45492±0.00000  bestvalidloss 6.01788  last_update 37\n",
      "train: iter 133  trainloss 2.10757  validloss 6.60096±0.00000  bestvalidloss 6.01788  last_update 38\n",
      "train: iter 134  trainloss 2.14025  validloss 6.60476±0.00000  bestvalidloss 6.01788  last_update 39\n",
      "train: iter 135  trainloss 2.14297  validloss 6.38261±0.00000  bestvalidloss 6.01788  last_update 40\n",
      "train: iter 136  trainloss 2.09403  validloss 6.61973±0.00000  bestvalidloss 6.01788  last_update 41\n",
      "train: iter 137  trainloss 2.14060  validloss 6.52877±0.00000  bestvalidloss 6.01788  last_update 42\n",
      "train: iter 138  trainloss 2.15758  validloss 7.11268±0.00000  bestvalidloss 6.01788  last_update 43\n",
      "train: iter 139  trainloss 2.13496  validloss 6.94786±0.00000  bestvalidloss 6.01788  last_update 44\n",
      "train: iter 140  trainloss 2.09092  validloss 6.51173±0.00000  bestvalidloss 6.01788  last_update 45\n",
      "train: iter 141  trainloss 2.09862  validloss 6.30105±0.00000  bestvalidloss 6.01788  last_update 46\n",
      "train: iter 142  trainloss 2.09797  validloss 6.45904±0.00000  bestvalidloss 6.01788  last_update 47\n",
      "train: iter 143  trainloss 2.12928  validloss 6.35027±0.00000  bestvalidloss 6.01788  last_update 48\n",
      "train: iter 144  trainloss 2.11242  validloss 6.21478±0.00000  bestvalidloss 6.01788  last_update 49\n",
      "train: iter 145  trainloss 2.11339  validloss 6.64793±0.00000  bestvalidloss 6.01788  last_update 50\n",
      "train: iter 146  trainloss 2.10972  validloss 6.46318±0.00000  bestvalidloss 6.01788  last_update 51\n",
      "train: iter 147  trainloss 2.13317  validloss 6.50884±0.00000  bestvalidloss 6.01788  last_update 52\n",
      "train: iter 148  trainloss 2.11742  validloss 6.49946±0.00000  bestvalidloss 6.01788  last_update 53\n",
      "train: iter 149  trainloss 2.10036  validloss 6.16769±0.00000  bestvalidloss 6.01788  last_update 54\n",
      "train: iter 150  trainloss 2.11176  validloss 6.53904±0.00000  bestvalidloss 6.01788  last_update 55\n",
      "train: iter 151  trainloss 2.09813  validloss 6.47355±0.00000  bestvalidloss 6.01788  last_update 56\n",
      "train: iter 152  trainloss 2.12570  validloss 6.53754±0.00000  bestvalidloss 6.01788  last_update 57\n",
      "train: iter 153  trainloss 2.08732  validloss 6.53874±0.00000  bestvalidloss 6.01788  last_update 58\n",
      "train: iter 154  trainloss 2.08878  validloss 6.57181±0.00000  bestvalidloss 6.01788  last_update 59\n",
      "train: iter 155  trainloss 2.09258  validloss 6.36774±0.00000  bestvalidloss 6.01788  last_update 60\n",
      "train: iter 156  trainloss 2.10489  validloss 6.54613±0.00000  bestvalidloss 6.01788  last_update 61\n",
      "train: iter 157  trainloss 2.13219  validloss 6.57680±0.00000  bestvalidloss 6.01788  last_update 62\n",
      "train: iter 158  trainloss 2.14306  validloss 6.48829±0.00000  bestvalidloss 6.01788  last_update 63\n",
      "train: iter 159  trainloss 2.12396  validloss 6.23396±0.00000  bestvalidloss 6.01788  last_update 64\n",
      "train: iter 160  trainloss 2.13090  validloss 6.35651±0.00000  bestvalidloss 6.01788  last_update 65\n",
      "train: iter 161  trainloss 2.11838  validloss 6.34886±0.00000  bestvalidloss 6.01788  last_update 66\n",
      "train: iter 162  trainloss 2.13741  validloss 6.50998±0.00000  bestvalidloss 6.01788  last_update 67\n",
      "train: iter 163  trainloss 2.09239  validloss 6.40313±0.00000  bestvalidloss 6.01788  last_update 68\n",
      "train: iter 164  trainloss 2.10648  validloss 6.37774±0.00000  bestvalidloss 6.01788  last_update 69\n",
      "train: iter 165  trainloss 2.12213  validloss 6.68210±0.00000  bestvalidloss 6.01788  last_update 70\n",
      "train: iter 166  trainloss 2.10519  validloss 6.37909±0.00000  bestvalidloss 6.01788  last_update 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss 2.09458  validloss 6.37934±0.00000  bestvalidloss 6.01788  last_update 72\n",
      "train: iter 168  trainloss 2.15281  validloss 6.42083±0.00000  bestvalidloss 6.01788  last_update 73\n",
      "train: iter 169  trainloss 2.12347  validloss 6.22042±0.00000  bestvalidloss 6.01788  last_update 74\n",
      "train: iter 170  trainloss 2.09483  validloss 6.45367±0.00000  bestvalidloss 6.01788  last_update 75\n",
      "train: iter 171  trainloss 2.12019  validloss 6.38641±0.00000  bestvalidloss 6.01788  last_update 76\n",
      "train: iter 172  trainloss 2.14336  validloss 6.35804±0.00000  bestvalidloss 6.01788  last_update 77\n",
      "train: iter 173  trainloss 2.11788  validloss 6.61911±0.00000  bestvalidloss 6.01788  last_update 78\n",
      "train: iter 174  trainloss 2.11319  validloss 6.87274±0.00000  bestvalidloss 6.01788  last_update 79\n",
      "train: iter 175  trainloss 2.10928  validloss 6.50930±0.00000  bestvalidloss 6.01788  last_update 80\n",
      "train: iter 176  trainloss 2.14941  validloss 6.74828±0.00000  bestvalidloss 6.01788  last_update 81\n",
      "train: iter 177  trainloss 2.10753  validloss 6.51453±0.00000  bestvalidloss 6.01788  last_update 82\n",
      "train: iter 178  trainloss 2.12085  validloss 6.52561±0.00000  bestvalidloss 6.01788  last_update 83\n",
      "train: iter 179  trainloss 2.09335  validloss 6.56816±0.00000  bestvalidloss 6.01788  last_update 84\n",
      "train: iter 180  trainloss 2.15454  validloss 6.78525±0.00000  bestvalidloss 6.01788  last_update 85\n",
      "train: iter 181  trainloss 2.12431  validloss 6.75871±0.00000  bestvalidloss 6.01788  last_update 86\n",
      "train: iter 182  trainloss 2.09889  validloss 6.55843±0.00000  bestvalidloss 6.01788  last_update 87\n",
      "train: iter 183  trainloss 2.11571  validloss 6.77765±0.00000  bestvalidloss 6.01788  last_update 88\n",
      "train: iter 184  trainloss 2.09445  validloss 6.41220±0.00000  bestvalidloss 6.01788  last_update 89\n",
      "train: iter 185  trainloss 2.11476  validloss 6.83235±0.00000  bestvalidloss 6.01788  last_update 90\n",
      "train: iter 186  trainloss 2.09213  validloss 6.72965±0.00000  bestvalidloss 6.01788  last_update 91\n",
      "train: iter 187  trainloss 2.09278  validloss 6.56044±0.00000  bestvalidloss 6.01788  last_update 92\n",
      "train: iter 188  trainloss 2.10885  validloss 6.47397±0.00000  bestvalidloss 6.01788  last_update 93\n",
      "train: iter 189  trainloss 2.09926  validloss 6.58766±0.00000  bestvalidloss 6.01788  last_update 94\n",
      "train: iter 190  trainloss 2.09786  validloss 6.73188±0.00000  bestvalidloss 6.01788  last_update 95\n",
      "train: iter 191  trainloss 2.09544  validloss 6.39525±0.00000  bestvalidloss 6.01788  last_update 96\n",
      "train: iter 192  trainloss 2.14163  validloss 6.50101±0.00000  bestvalidloss 6.01788  last_update 97\n",
      "train: iter 193  trainloss 2.09908  validloss 6.56069±0.00000  bestvalidloss 6.01788  last_update 98\n",
      "train: iter 194  trainloss 2.07877  validloss 6.84591±0.00000  bestvalidloss 6.01788  last_update 99\n",
      "train: iter 195  trainloss 2.10364  validloss 6.72529±0.00000  bestvalidloss 6.01788  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-15.5064)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(3.7583)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7358152213658345\n",
      "tensor([-0.2217])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
