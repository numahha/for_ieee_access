{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 0\n",
      "cfg_env cartpole\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n",
    "print(\"seed\",seed)\n",
    "print(\"cfg_env\",cfg_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(16469.1855)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 64\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 17793.77168  validloss 1905589.98579±0.00000  bestvalidloss 1905589.98579  last_update 0\n",
      "train: iter 1  trainloss 1931.93514  validloss 17811.53105±0.00000  bestvalidloss 17811.53105  last_update 0\n",
      "train: iter 2  trainloss 1215.24433  validloss 5788.70973±0.00000  bestvalidloss 5788.70973  last_update 0\n",
      "train: iter 3  trainloss 1025.86580  validloss 3214.20152±0.00000  bestvalidloss 3214.20152  last_update 0\n",
      "train: iter 4  trainloss 916.88125  validloss 2390.12367±0.00000  bestvalidloss 2390.12367  last_update 0\n",
      "train: iter 5  trainloss 885.06088  validloss 1950.73109±0.00000  bestvalidloss 1950.73109  last_update 0\n",
      "train: iter 6  trainloss 810.96679  validloss 1442.34988±0.00000  bestvalidloss 1442.34988  last_update 0\n",
      "train: iter 7  trainloss 758.06064  validloss 1488.03048±0.00000  bestvalidloss 1442.34988  last_update 1\n",
      "train: iter 8  trainloss 784.11030  validloss 1681.69616±0.00000  bestvalidloss 1442.34988  last_update 2\n",
      "train: iter 9  trainloss 795.78068  validloss 1669.73795±0.00000  bestvalidloss 1442.34988  last_update 3\n",
      "train: iter 10  trainloss 708.99736  validloss 1702.86195±0.00000  bestvalidloss 1442.34988  last_update 4\n",
      "train: iter 11  trainloss 763.09538  validloss 1236.53420±0.00000  bestvalidloss 1236.53420  last_update 0\n",
      "train: iter 12  trainloss 677.22858  validloss 1597.53466±0.00000  bestvalidloss 1236.53420  last_update 1\n",
      "train: iter 13  trainloss 625.69149  validloss 1349.13273±0.00000  bestvalidloss 1236.53420  last_update 2\n",
      "train: iter 14  trainloss 586.22687  validloss 1479.44286±0.00000  bestvalidloss 1236.53420  last_update 3\n",
      "train: iter 15  trainloss 666.29755  validloss 1406.99593±0.00000  bestvalidloss 1236.53420  last_update 4\n",
      "train: iter 16  trainloss 578.57783  validloss 1416.55833±0.00000  bestvalidloss 1236.53420  last_update 5\n",
      "train: iter 17  trainloss 509.13887  validloss 1121.95733±0.00000  bestvalidloss 1121.95733  last_update 0\n",
      "train: iter 18  trainloss 521.06304  validloss 2178.89952±0.00000  bestvalidloss 1121.95733  last_update 1\n",
      "train: iter 19  trainloss 480.32779  validloss 1338.13682±0.00000  bestvalidloss 1121.95733  last_update 2\n",
      "train: iter 20  trainloss 524.47291  validloss 1129.87737±0.00000  bestvalidloss 1121.95733  last_update 3\n",
      "train: iter 21  trainloss 461.39199  validloss 1123.73137±0.00000  bestvalidloss 1121.95733  last_update 4\n",
      "train: iter 22  trainloss 425.96200  validloss 915.40508±0.00000  bestvalidloss 915.40508  last_update 0\n",
      "train: iter 23  trainloss 385.36160  validloss 937.88183±0.00000  bestvalidloss 915.40508  last_update 1\n",
      "train: iter 24  trainloss 368.99006  validloss 1103.34199±0.00000  bestvalidloss 915.40508  last_update 2\n",
      "train: iter 25  trainloss 335.04848  validloss 889.62311±0.00000  bestvalidloss 889.62311  last_update 0\n",
      "train: iter 26  trainloss 347.52107  validloss 1382.22289±0.00000  bestvalidloss 889.62311  last_update 1\n",
      "train: iter 27  trainloss 277.69997  validloss 747.50713±0.00000  bestvalidloss 747.50713  last_update 0\n",
      "train: iter 28  trainloss 300.14036  validloss 1029.26318±0.00000  bestvalidloss 747.50713  last_update 1\n",
      "train: iter 29  trainloss 211.28332  validloss 715.59468±0.00000  bestvalidloss 715.59468  last_update 0\n",
      "train: iter 30  trainloss 245.51910  validloss 755.51479±0.00000  bestvalidloss 715.59468  last_update 1\n",
      "train: iter 31  trainloss 190.00265  validloss 726.25733±0.00000  bestvalidloss 715.59468  last_update 2\n",
      "train: iter 32  trainloss 166.33278  validloss 608.39199±0.00000  bestvalidloss 608.39199  last_update 0\n",
      "train: iter 33  trainloss 293.20410  validloss 663.21826±0.00000  bestvalidloss 608.39199  last_update 1\n",
      "train: iter 34  trainloss 77.00691  validloss 475.98745±0.00000  bestvalidloss 475.98745  last_update 0\n",
      "train: iter 35  trainloss 110.69566  validloss 572.42490±0.00000  bestvalidloss 475.98745  last_update 1\n",
      "train: iter 36  trainloss 33.45757  validloss 531.13514±0.00000  bestvalidloss 475.98745  last_update 2\n",
      "train: iter 37  trainloss 8.62618  validloss 426.06243±0.00000  bestvalidloss 426.06243  last_update 0\n",
      "train: iter 38  trainloss 26.57886  validloss 348.26256±0.00000  bestvalidloss 348.26256  last_update 0\n",
      "train: iter 39  trainloss -85.62672  validloss 262.20027±0.00000  bestvalidloss 262.20027  last_update 0\n",
      "train: iter 40  trainloss -85.11739  validloss 316.09520±0.00000  bestvalidloss 262.20027  last_update 1\n",
      "train: iter 41  trainloss -133.00025  validloss 245.10309±0.00000  bestvalidloss 245.10309  last_update 0\n",
      "train: iter 42  trainloss -160.32168  validloss 385.85451±0.00000  bestvalidloss 245.10309  last_update 1\n",
      "train: iter 43  trainloss -152.73152  validloss 165.39364±0.00000  bestvalidloss 165.39364  last_update 0\n",
      "train: iter 44  trainloss -131.46271  validloss 331.15978±0.00000  bestvalidloss 165.39364  last_update 1\n",
      "train: iter 45  trainloss -226.05069  validloss 223.19496±0.00000  bestvalidloss 165.39364  last_update 2\n",
      "train: iter 46  trainloss -193.34802  validloss 112.98875±0.00000  bestvalidloss 112.98875  last_update 0\n",
      "train: iter 47  trainloss -201.78323  validloss 156.37211±0.00000  bestvalidloss 112.98875  last_update 1\n",
      "train: iter 48  trainloss -216.03139  validloss 83.89041±0.00000  bestvalidloss 83.89041  last_update 0\n",
      "train: iter 49  trainloss -205.84945  validloss 21.86298±0.00000  bestvalidloss 21.86298  last_update 0\n",
      "train: iter 50  trainloss -313.70106  validloss 64.35742±0.00000  bestvalidloss 21.86298  last_update 1\n",
      "train: iter 51  trainloss -284.41916  validloss 98.37516±0.00000  bestvalidloss 21.86298  last_update 2\n",
      "train: iter 52  trainloss -212.19595  validloss 47.19554±0.00000  bestvalidloss 21.86298  last_update 3\n",
      "train: iter 53  trainloss -258.39467  validloss 141.08650±0.00000  bestvalidloss 21.86298  last_update 4\n",
      "train: iter 54  trainloss -298.43543  validloss 46.39489±0.00000  bestvalidloss 21.86298  last_update 5\n",
      "train: iter 55  trainloss -366.51813  validloss -67.60353±0.00000  bestvalidloss -67.60353  last_update 0\n",
      "train: iter 56  trainloss -355.83881  validloss -33.28449±0.00000  bestvalidloss -67.60353  last_update 1\n",
      "train: iter 57  trainloss -356.87513  validloss 56.57528±0.00000  bestvalidloss -67.60353  last_update 2\n",
      "train: iter 58  trainloss -395.95598  validloss -61.89242±0.00000  bestvalidloss -67.60353  last_update 3\n",
      "train: iter 59  trainloss -335.30492  validloss 99.20438±0.00000  bestvalidloss -67.60353  last_update 4\n",
      "train: iter 60  trainloss -280.55142  validloss 207.54983±0.00000  bestvalidloss -67.60353  last_update 5\n",
      "train: iter 61  trainloss -137.60594  validloss 30.13234±0.00000  bestvalidloss -67.60353  last_update 6\n",
      "train: iter 62  trainloss -366.53865  validloss -48.94521±0.00000  bestvalidloss -67.60353  last_update 7\n",
      "train: iter 63  trainloss -402.75530  validloss -126.68046±0.00000  bestvalidloss -126.68046  last_update 0\n",
      "train: iter 64  trainloss -413.63932  validloss -100.36593±0.00000  bestvalidloss -126.68046  last_update 1\n",
      "train: iter 65  trainloss -448.14957  validloss -184.68129±0.00000  bestvalidloss -184.68129  last_update 0\n",
      "train: iter 66  trainloss -484.29079  validloss -148.05894±0.00000  bestvalidloss -184.68129  last_update 1\n",
      "train: iter 67  trainloss -469.38787  validloss -176.66966±0.00000  bestvalidloss -184.68129  last_update 2\n",
      "train: iter 68  trainloss -318.14289  validloss 73.56038±0.00000  bestvalidloss -184.68129  last_update 3\n",
      "train: iter 69  trainloss -483.44950  validloss -29.10846±0.00000  bestvalidloss -184.68129  last_update 4\n",
      "train: iter 70  trainloss -495.24737  validloss 72.15008±0.00000  bestvalidloss -184.68129  last_update 5\n",
      "train: iter 71  trainloss -526.78223  validloss 24.34390±0.00000  bestvalidloss -184.68129  last_update 6\n",
      "train: iter 72  trainloss -441.95809  validloss 49.46767±0.00000  bestvalidloss -184.68129  last_update 7\n",
      "train: iter 73  trainloss -533.06053  validloss -319.75914±0.00000  bestvalidloss -319.75914  last_update 0\n",
      "train: iter 74  trainloss -461.79007  validloss -36.97580±0.00000  bestvalidloss -319.75914  last_update 1\n",
      "train: iter 75  trainloss -548.76847  validloss -255.13853±0.00000  bestvalidloss -319.75914  last_update 2\n",
      "train: iter 76  trainloss -567.98455  validloss -243.70824±0.00000  bestvalidloss -319.75914  last_update 3\n",
      "train: iter 77  trainloss -311.10243  validloss -302.43859±0.00000  bestvalidloss -319.75914  last_update 4\n",
      "train: iter 78  trainloss -529.32328  validloss 307.96363±0.00000  bestvalidloss -319.75914  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 79  trainloss -389.14808  validloss 1308.97504±0.00000  bestvalidloss -319.75914  last_update 6\n",
      "train: iter 80  trainloss -458.69194  validloss -0.01413±0.00000  bestvalidloss -319.75914  last_update 7\n",
      "train: iter 81  trainloss -547.77273  validloss -109.22450±0.00000  bestvalidloss -319.75914  last_update 8\n",
      "train: iter 82  trainloss -575.04728  validloss -250.86057±0.00000  bestvalidloss -319.75914  last_update 9\n",
      "train: iter 83  trainloss -619.63084  validloss -323.07077±0.00000  bestvalidloss -323.07077  last_update 0\n",
      "train: iter 84  trainloss -488.56424  validloss -294.75700±0.00000  bestvalidloss -323.07077  last_update 1\n",
      "train: iter 85  trainloss -584.17362  validloss -101.13048±0.00000  bestvalidloss -323.07077  last_update 2\n",
      "train: iter 86  trainloss -522.71397  validloss 172.71575±0.00000  bestvalidloss -323.07077  last_update 3\n",
      "train: iter 87  trainloss -607.61204  validloss -400.91648±0.00000  bestvalidloss -400.91648  last_update 0\n",
      "train: iter 88  trainloss -670.33384  validloss -341.09089±0.00000  bestvalidloss -400.91648  last_update 1\n",
      "train: iter 89  trainloss -617.93851  validloss -482.71407±0.00000  bestvalidloss -482.71407  last_update 0\n",
      "train: iter 90  trainloss -485.21981  validloss -115.65050±0.00000  bestvalidloss -482.71407  last_update 1\n",
      "train: iter 91  trainloss -629.66873  validloss -342.90632±0.00000  bestvalidloss -482.71407  last_update 2\n",
      "train: iter 92  trainloss -632.77049  validloss -237.92348±0.00000  bestvalidloss -482.71407  last_update 3\n",
      "train: iter 93  trainloss -612.66386  validloss -255.15609±0.00000  bestvalidloss -482.71407  last_update 4\n",
      "train: iter 94  trainloss -665.74416  validloss -314.33185±0.00000  bestvalidloss -482.71407  last_update 5\n",
      "train: iter 95  trainloss -729.10065  validloss -477.14119±0.00000  bestvalidloss -482.71407  last_update 6\n",
      "train: iter 96  trainloss -706.01321  validloss -538.27087±0.00000  bestvalidloss -538.27087  last_update 0\n",
      "train: iter 97  trainloss -696.41392  validloss -414.84663±0.00000  bestvalidloss -538.27087  last_update 1\n",
      "train: iter 98  trainloss -615.71569  validloss -219.66014±0.00000  bestvalidloss -538.27087  last_update 2\n",
      "train: iter 99  trainloss -595.00473  validloss -262.58576±0.00000  bestvalidloss -538.27087  last_update 3\n",
      "train: iter 100  trainloss -622.85927  validloss -27.19260±0.00000  bestvalidloss -538.27087  last_update 4\n",
      "train: iter 101  trainloss -691.73686  validloss -436.31720±0.00000  bestvalidloss -538.27087  last_update 5\n",
      "train: iter 102  trainloss -688.59596  validloss -413.29941±0.00000  bestvalidloss -538.27087  last_update 6\n",
      "train: iter 103  trainloss -643.47419  validloss -200.39143±0.00000  bestvalidloss -538.27087  last_update 7\n",
      "train: iter 104  trainloss -570.80851  validloss -532.08568±0.00000  bestvalidloss -538.27087  last_update 8\n",
      "train: iter 105  trainloss -423.38950  validloss 33.37097±0.00000  bestvalidloss -538.27087  last_update 9\n",
      "train: iter 106  trainloss -701.03636  validloss -257.09374±0.00000  bestvalidloss -538.27087  last_update 10\n",
      "train: iter 107  trainloss -706.39804  validloss -527.84630±0.00000  bestvalidloss -538.27087  last_update 11\n",
      "train: iter 108  trainloss -663.89298  validloss 243.49631±0.00000  bestvalidloss -538.27087  last_update 12\n",
      "train: iter 109  trainloss -680.97422  validloss -414.40166±0.00000  bestvalidloss -538.27087  last_update 13\n",
      "train: iter 110  trainloss -693.77389  validloss -286.96910±0.00000  bestvalidloss -538.27087  last_update 14\n",
      "train: iter 111  trainloss -553.64285  validloss -176.00006±0.00000  bestvalidloss -538.27087  last_update 15\n",
      "train: iter 112  trainloss -703.81606  validloss -289.15263±0.00000  bestvalidloss -538.27087  last_update 16\n",
      "train: iter 113  trainloss -679.06361  validloss -243.62689±0.00000  bestvalidloss -538.27087  last_update 17\n",
      "train: iter 114  trainloss -724.49131  validloss -498.40833±0.00000  bestvalidloss -538.27087  last_update 18\n",
      "train: iter 115  trainloss -711.65389  validloss -545.08555±0.00000  bestvalidloss -545.08555  last_update 0\n",
      "train: iter 116  trainloss -734.48688  validloss -616.30897±0.00000  bestvalidloss -616.30897  last_update 0\n",
      "train: iter 117  trainloss -353.01736  validloss -542.28898±0.00000  bestvalidloss -616.30897  last_update 1\n",
      "train: iter 118  trainloss -606.46725  validloss -65.43823±0.00000  bestvalidloss -616.30897  last_update 2\n",
      "train: iter 119  trainloss -690.44658  validloss -477.03015±0.00000  bestvalidloss -616.30897  last_update 3\n",
      "train: iter 120  trainloss -793.25777  validloss -479.20757±0.00000  bestvalidloss -616.30897  last_update 4\n",
      "train: iter 121  trainloss -639.13366  validloss -288.86548±0.00000  bestvalidloss -616.30897  last_update 5\n",
      "train: iter 122  trainloss -709.41258  validloss -58.80283±0.00000  bestvalidloss -616.30897  last_update 6\n",
      "train: iter 123  trainloss -811.88361  validloss -543.29371±0.00000  bestvalidloss -616.30897  last_update 7\n",
      "train: iter 124  trainloss -813.74241  validloss -688.96138±0.00000  bestvalidloss -688.96138  last_update 0\n",
      "train: iter 125  trainloss -733.43799  validloss -659.53410±0.00000  bestvalidloss -688.96138  last_update 1\n",
      "train: iter 126  trainloss -747.62471  validloss -455.14904±0.00000  bestvalidloss -688.96138  last_update 2\n",
      "train: iter 127  trainloss -472.15643  validloss -247.86587±0.00000  bestvalidloss -688.96138  last_update 3\n",
      "train: iter 128  trainloss -599.46756  validloss -222.68378±0.00000  bestvalidloss -688.96138  last_update 4\n",
      "train: iter 129  trainloss -659.07527  validloss -271.92384±0.00000  bestvalidloss -688.96138  last_update 5\n",
      "train: iter 130  trainloss -839.66864  validloss -342.99419±0.00000  bestvalidloss -688.96138  last_update 6\n",
      "train: iter 131  trainloss -796.14346  validloss -633.35098±0.00000  bestvalidloss -688.96138  last_update 7\n",
      "train: iter 132  trainloss -813.66438  validloss -605.65202±0.00000  bestvalidloss -688.96138  last_update 8\n",
      "train: iter 133  trainloss -641.32708  validloss -573.30299±0.00000  bestvalidloss -688.96138  last_update 9\n",
      "train: iter 134  trainloss -759.47748  validloss -546.59604±0.00000  bestvalidloss -688.96138  last_update 10\n",
      "train: iter 135  trainloss -778.94756  validloss -622.31132±0.00000  bestvalidloss -688.96138  last_update 11\n",
      "train: iter 136  trainloss -758.21127  validloss -458.05232±0.00000  bestvalidloss -688.96138  last_update 12\n",
      "train: iter 137  trainloss -700.26956  validloss -506.23774±0.00000  bestvalidloss -688.96138  last_update 13\n",
      "train: iter 138  trainloss -723.57003  validloss -639.46650±0.00000  bestvalidloss -688.96138  last_update 14\n",
      "train: iter 139  trainloss -754.74686  validloss -489.27301±0.00000  bestvalidloss -688.96138  last_update 15\n",
      "train: iter 140  trainloss -735.74936  validloss -541.71346±0.00000  bestvalidloss -688.96138  last_update 16\n",
      "train: iter 141  trainloss -712.96668  validloss -572.20659±0.00000  bestvalidloss -688.96138  last_update 17\n",
      "train: iter 142  trainloss -602.30390  validloss -607.19479±0.00000  bestvalidloss -688.96138  last_update 18\n",
      "train: iter 143  trainloss -762.22912  validloss -397.91843±0.00000  bestvalidloss -688.96138  last_update 19\n",
      "train: iter 144  trainloss -802.30757  validloss -222.93371±0.00000  bestvalidloss -688.96138  last_update 20\n",
      "train: iter 145  trainloss -742.70732  validloss -745.20597±0.00000  bestvalidloss -745.20597  last_update 0\n",
      "train: iter 146  trainloss -821.58110  validloss -525.47206±0.00000  bestvalidloss -745.20597  last_update 1\n",
      "train: iter 147  trainloss -895.82402  validloss -598.62734±0.00000  bestvalidloss -745.20597  last_update 2\n",
      "train: iter 148  trainloss -828.62128  validloss -768.93537±0.00000  bestvalidloss -768.93537  last_update 0\n",
      "train: iter 149  trainloss -748.81287  validloss -312.03916±0.00000  bestvalidloss -768.93537  last_update 1\n",
      "train: iter 150  trainloss -871.85767  validloss -696.66015±0.00000  bestvalidloss -768.93537  last_update 2\n",
      "train: iter 151  trainloss -861.39882  validloss -694.14531±0.00000  bestvalidloss -768.93537  last_update 3\n",
      "train: iter 152  trainloss -867.06820  validloss -486.24283±0.00000  bestvalidloss -768.93537  last_update 4\n",
      "train: iter 153  trainloss -861.95714  validloss -760.97119±0.00000  bestvalidloss -768.93537  last_update 5\n",
      "train: iter 154  trainloss -888.83924  validloss -755.52052±0.00000  bestvalidloss -768.93537  last_update 6\n",
      "train: iter 155  trainloss -821.04573  validloss -603.92927±0.00000  bestvalidloss -768.93537  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 156  trainloss -779.86901  validloss -502.85508±0.00000  bestvalidloss -768.93537  last_update 8\n",
      "train: iter 157  trainloss -821.15044  validloss -731.02514±0.00000  bestvalidloss -768.93537  last_update 9\n",
      "train: iter 158  trainloss -848.20732  validloss -630.06737±0.00000  bestvalidloss -768.93537  last_update 10\n",
      "train: iter 159  trainloss -882.10422  validloss -661.18702±0.00000  bestvalidloss -768.93537  last_update 11\n",
      "train: iter 160  trainloss -784.46950  validloss -827.34118±0.00000  bestvalidloss -827.34118  last_update 0\n",
      "train: iter 161  trainloss -655.40674  validloss -60.76401±0.00000  bestvalidloss -827.34118  last_update 1\n",
      "train: iter 162  trainloss -849.69271  validloss -599.55074±0.00000  bestvalidloss -827.34118  last_update 2\n",
      "train: iter 163  trainloss -767.04069  validloss -615.98801±0.00000  bestvalidloss -827.34118  last_update 3\n",
      "train: iter 164  trainloss -931.43688  validloss -706.64153±0.00000  bestvalidloss -827.34118  last_update 4\n",
      "train: iter 165  trainloss -931.89701  validloss -826.60917±0.00000  bestvalidloss -827.34118  last_update 5\n",
      "train: iter 166  trainloss -772.73282  validloss -554.65310±0.00000  bestvalidloss -827.34118  last_update 6\n",
      "train: iter 167  trainloss -908.72517  validloss -767.37487±0.00000  bestvalidloss -827.34118  last_update 7\n",
      "train: iter 168  trainloss -928.80720  validloss -430.00511±0.00000  bestvalidloss -827.34118  last_update 8\n",
      "train: iter 169  trainloss -874.89482  validloss -765.88430±0.00000  bestvalidloss -827.34118  last_update 9\n",
      "train: iter 170  trainloss -923.74296  validloss -802.01166±0.00000  bestvalidloss -827.34118  last_update 10\n",
      "train: iter 171  trainloss -881.69000  validloss -758.23269±0.00000  bestvalidloss -827.34118  last_update 11\n",
      "train: iter 172  trainloss -889.16545  validloss -877.54755±0.00000  bestvalidloss -877.54755  last_update 0\n",
      "train: iter 173  trainloss -904.31003  validloss -685.19581±0.00000  bestvalidloss -877.54755  last_update 1\n",
      "train: iter 174  trainloss -815.42301  validloss -736.24578±0.00000  bestvalidloss -877.54755  last_update 2\n",
      "train: iter 175  trainloss -970.21035  validloss -671.62073±0.00000  bestvalidloss -877.54755  last_update 3\n",
      "train: iter 176  trainloss -779.76507  validloss -548.84048±0.00000  bestvalidloss -877.54755  last_update 4\n",
      "train: iter 177  trainloss -855.47744  validloss -450.85229±0.00000  bestvalidloss -877.54755  last_update 5\n",
      "train: iter 178  trainloss -890.75375  validloss -801.13091±0.00000  bestvalidloss -877.54755  last_update 6\n",
      "train: iter 179  trainloss -878.64359  validloss -492.92120±0.00000  bestvalidloss -877.54755  last_update 7\n",
      "train: iter 180  trainloss -981.37563  validloss -803.56842±0.00000  bestvalidloss -877.54755  last_update 8\n",
      "train: iter 181  trainloss -938.69189  validloss -488.25516±0.00000  bestvalidloss -877.54755  last_update 9\n",
      "train: iter 182  trainloss -743.33760  validloss -846.76969±0.00000  bestvalidloss -877.54755  last_update 10\n",
      "train: iter 183  trainloss -993.90765  validloss -494.05826±0.00000  bestvalidloss -877.54755  last_update 11\n",
      "train: iter 184  trainloss -1005.40248  validloss -808.70278±0.00000  bestvalidloss -877.54755  last_update 12\n",
      "train: iter 185  trainloss -881.79168  validloss -572.84701±0.00000  bestvalidloss -877.54755  last_update 13\n",
      "train: iter 186  trainloss -950.60053  validloss -733.67707±0.00000  bestvalidloss -877.54755  last_update 14\n",
      "train: iter 187  trainloss -873.78141  validloss -452.47770±0.00000  bestvalidloss -877.54755  last_update 15\n",
      "train: iter 188  trainloss -667.69975  validloss -780.04554±0.00000  bestvalidloss -877.54755  last_update 16\n",
      "train: iter 189  trainloss -959.12640  validloss -716.89420±0.00000  bestvalidloss -877.54755  last_update 17\n",
      "train: iter 190  trainloss -959.18296  validloss -879.98993±0.00000  bestvalidloss -879.98993  last_update 0\n",
      "train: iter 191  trainloss -680.18515  validloss -868.94380±0.00000  bestvalidloss -879.98993  last_update 1\n",
      "train: iter 192  trainloss -854.57903  validloss -591.12357±0.00000  bestvalidloss -879.98993  last_update 2\n",
      "train: iter 193  trainloss -523.86637  validloss -874.64121±0.00000  bestvalidloss -879.98993  last_update 3\n",
      "train: iter 194  trainloss -148.66635  validloss -78.38402±0.00000  bestvalidloss -879.98993  last_update 4\n",
      "train: iter 195  trainloss -266.75622  validloss 203.47514±0.00000  bestvalidloss -879.98993  last_update 5\n",
      "train: iter 196  trainloss -367.48835  validloss -267.36884±0.00000  bestvalidloss -879.98993  last_update 6\n",
      "train: iter 197  trainloss -583.30510  validloss 16.64177±0.00000  bestvalidloss -879.98993  last_update 7\n",
      "train: iter 198  trainloss -826.82171  validloss -446.52464±0.00000  bestvalidloss -879.98993  last_update 8\n",
      "train: iter 199  trainloss -910.19025  validloss -648.93270±0.00000  bestvalidloss -879.98993  last_update 9\n",
      "train: iter 200  trainloss -919.27603  validloss -618.25381±0.00000  bestvalidloss -879.98993  last_update 10\n",
      "train: iter 201  trainloss -931.16174  validloss -811.75521±0.00000  bestvalidloss -879.98993  last_update 11\n",
      "train: iter 202  trainloss -955.34712  validloss -848.54789±0.00000  bestvalidloss -879.98993  last_update 12\n",
      "train: iter 203  trainloss -998.23249  validloss -815.30770±0.00000  bestvalidloss -879.98993  last_update 13\n",
      "train: iter 204  trainloss -825.17853  validloss -582.55512±0.00000  bestvalidloss -879.98993  last_update 14\n",
      "train: iter 205  trainloss -1022.69101  validloss -813.97089±0.00000  bestvalidloss -879.98993  last_update 15\n",
      "train: iter 206  trainloss -876.97381  validloss -836.70079±0.00000  bestvalidloss -879.98993  last_update 16\n",
      "train: iter 207  trainloss -1009.26153  validloss -848.75423±0.00000  bestvalidloss -879.98993  last_update 17\n",
      "train: iter 208  trainloss -959.98772  validloss -907.53069±0.00000  bestvalidloss -907.53069  last_update 0\n",
      "train: iter 209  trainloss -964.36442  validloss -861.91273±0.00000  bestvalidloss -907.53069  last_update 1\n",
      "train: iter 210  trainloss -892.16281  validloss -897.32612±0.00000  bestvalidloss -907.53069  last_update 2\n",
      "train: iter 211  trainloss -1013.84419  validloss -786.77406±0.00000  bestvalidloss -907.53069  last_update 3\n",
      "train: iter 212  trainloss -1031.97454  validloss -775.29615±0.00000  bestvalidloss -907.53069  last_update 4\n",
      "train: iter 213  trainloss -884.58760  validloss -941.27080±0.00000  bestvalidloss -941.27080  last_update 0\n",
      "train: iter 214  trainloss -1017.04371  validloss -798.17436±0.00000  bestvalidloss -941.27080  last_update 1\n",
      "train: iter 215  trainloss -1003.48287  validloss -711.81842±0.00000  bestvalidloss -941.27080  last_update 2\n",
      "train: iter 216  trainloss -950.07717  validloss -435.63924±0.00000  bestvalidloss -941.27080  last_update 3\n",
      "train: iter 217  trainloss -1008.28867  validloss -886.99834±0.00000  bestvalidloss -941.27080  last_update 4\n",
      "train: iter 218  trainloss -1040.35858  validloss -935.56551±0.00000  bestvalidloss -941.27080  last_update 5\n",
      "train: iter 219  trainloss -880.68479  validloss -778.14733±0.00000  bestvalidloss -941.27080  last_update 6\n",
      "train: iter 220  trainloss -875.67759  validloss -939.93813±0.00000  bestvalidloss -941.27080  last_update 7\n",
      "train: iter 221  trainloss -1060.09786  validloss -738.44406±0.00000  bestvalidloss -941.27080  last_update 8\n",
      "train: iter 222  trainloss -895.65873  validloss -945.25375±0.00000  bestvalidloss -945.25375  last_update 0\n",
      "train: iter 223  trainloss -870.90505  validloss -692.86053±0.00000  bestvalidloss -945.25375  last_update 1\n",
      "train: iter 224  trainloss -963.99941  validloss -587.78515±0.00000  bestvalidloss -945.25375  last_update 2\n",
      "train: iter 225  trainloss -1055.64110  validloss -793.98680±0.00000  bestvalidloss -945.25375  last_update 3\n",
      "train: iter 226  trainloss -985.90652  validloss -457.46946±0.00000  bestvalidloss -945.25375  last_update 4\n",
      "train: iter 227  trainloss -1006.77323  validloss -860.95054±0.00000  bestvalidloss -945.25375  last_update 5\n",
      "train: iter 228  trainloss -1003.28579  validloss -741.27778±0.00000  bestvalidloss -945.25375  last_update 6\n",
      "train: iter 229  trainloss -1069.13881  validloss -901.79640±0.00000  bestvalidloss -945.25375  last_update 7\n",
      "train: iter 230  trainloss -1027.65080  validloss -930.17958±0.00000  bestvalidloss -945.25375  last_update 8\n",
      "train: iter 231  trainloss -989.42353  validloss -902.12200±0.00000  bestvalidloss -945.25375  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 232  trainloss -1047.91473  validloss -848.98682±0.00000  bestvalidloss -945.25375  last_update 10\n",
      "train: iter 233  trainloss -1099.37809  validloss -873.36293±0.00000  bestvalidloss -945.25375  last_update 11\n",
      "train: iter 234  trainloss -776.09549  validloss -897.00169±0.00000  bestvalidloss -945.25375  last_update 12\n",
      "train: iter 235  trainloss -1020.10354  validloss -747.52684±0.00000  bestvalidloss -945.25375  last_update 13\n",
      "train: iter 236  trainloss -1044.04803  validloss -477.78025±0.00000  bestvalidloss -945.25375  last_update 14\n",
      "train: iter 237  trainloss -980.42164  validloss -948.64480±0.00000  bestvalidloss -948.64480  last_update 0\n",
      "train: iter 238  trainloss -1051.25862  validloss -934.82109±0.00000  bestvalidloss -948.64480  last_update 1\n",
      "train: iter 239  trainloss -1064.64760  validloss -785.41258±0.00000  bestvalidloss -948.64480  last_update 2\n",
      "train: iter 240  trainloss -868.33539  validloss -796.51018±0.00000  bestvalidloss -948.64480  last_update 3\n",
      "train: iter 241  trainloss -1040.19147  validloss -801.36528±0.00000  bestvalidloss -948.64480  last_update 4\n",
      "train: iter 242  trainloss -1093.53701  validloss -870.13830±0.00000  bestvalidloss -948.64480  last_update 5\n",
      "train: iter 243  trainloss -968.25040  validloss -969.85522±0.00000  bestvalidloss -969.85522  last_update 0\n",
      "train: iter 244  trainloss -1034.15211  validloss -859.24112±0.00000  bestvalidloss -969.85522  last_update 1\n",
      "train: iter 245  trainloss -1025.46417  validloss -822.05650±0.00000  bestvalidloss -969.85522  last_update 2\n",
      "train: iter 246  trainloss -992.11238  validloss -536.64506±0.00000  bestvalidloss -969.85522  last_update 3\n",
      "train: iter 247  trainloss -930.63827  validloss -835.33034±0.00000  bestvalidloss -969.85522  last_update 4\n",
      "train: iter 248  trainloss -886.56380  validloss -940.22497±0.00000  bestvalidloss -969.85522  last_update 5\n",
      "train: iter 249  trainloss -871.98038  validloss -447.15379±0.00000  bestvalidloss -969.85522  last_update 6\n",
      "train: iter 250  trainloss -977.18458  validloss -787.30308±0.00000  bestvalidloss -969.85522  last_update 7\n",
      "train: iter 251  trainloss -1077.18607  validloss -914.65952±0.00000  bestvalidloss -969.85522  last_update 8\n",
      "train: iter 252  trainloss -968.55474  validloss -950.47885±0.00000  bestvalidloss -969.85522  last_update 9\n",
      "train: iter 253  trainloss -928.74923  validloss -722.75892±0.00000  bestvalidloss -969.85522  last_update 10\n",
      "train: iter 254  trainloss -1040.41994  validloss -738.62465±0.00000  bestvalidloss -969.85522  last_update 11\n",
      "train: iter 255  trainloss -1088.47076  validloss -956.25949±0.00000  bestvalidloss -969.85522  last_update 12\n",
      "train: iter 256  trainloss -1103.09613  validloss -905.37749±0.00000  bestvalidloss -969.85522  last_update 13\n",
      "train: iter 257  trainloss -1068.03463  validloss -942.60252±0.00000  bestvalidloss -969.85522  last_update 14\n",
      "train: iter 258  trainloss -1097.93400  validloss -846.74399±0.00000  bestvalidloss -969.85522  last_update 15\n",
      "train: iter 259  trainloss -961.55440  validloss -847.62638±0.00000  bestvalidloss -969.85522  last_update 16\n",
      "train: iter 260  trainloss -1064.49606  validloss -926.01379±0.00000  bestvalidloss -969.85522  last_update 17\n",
      "train: iter 261  trainloss -1059.94345  validloss -808.99965±0.00000  bestvalidloss -969.85522  last_update 18\n",
      "train: iter 262  trainloss -834.14759  validloss -846.75123±0.00000  bestvalidloss -969.85522  last_update 19\n",
      "train: iter 263  trainloss -1035.81771  validloss -642.16149±0.00000  bestvalidloss -969.85522  last_update 20\n",
      "train: iter 264  trainloss -1129.92115  validloss -870.36801±0.00000  bestvalidloss -969.85522  last_update 21\n",
      "train: iter 265  trainloss -835.53290  validloss -895.55343±0.00000  bestvalidloss -969.85522  last_update 22\n",
      "train: iter 266  trainloss -952.20868  validloss 108.34527±0.00000  bestvalidloss -969.85522  last_update 23\n",
      "train: iter 267  trainloss -1092.34176  validloss -931.35575±0.00000  bestvalidloss -969.85522  last_update 24\n",
      "train: iter 268  trainloss -1037.46674  validloss -748.71843±0.00000  bestvalidloss -969.85522  last_update 25\n",
      "train: iter 269  trainloss -1052.33183  validloss -1028.15658±0.00000  bestvalidloss -1028.15658  last_update 0\n",
      "train: iter 270  trainloss -892.16601  validloss -775.40873±0.00000  bestvalidloss -1028.15658  last_update 1\n",
      "train: iter 271  trainloss -1139.11928  validloss -916.30682±0.00000  bestvalidloss -1028.15658  last_update 2\n",
      "train: iter 272  trainloss -1028.91606  validloss -869.91652±0.00000  bestvalidloss -1028.15658  last_update 3\n",
      "train: iter 273  trainloss -1010.49670  validloss -852.32586±0.00000  bestvalidloss -1028.15658  last_update 4\n",
      "train: iter 274  trainloss -952.91907  validloss -605.03493±0.00000  bestvalidloss -1028.15658  last_update 5\n",
      "train: iter 275  trainloss -1090.02587  validloss -862.09291±0.00000  bestvalidloss -1028.15658  last_update 6\n",
      "train: iter 276  trainloss -1122.57603  validloss -886.17724±0.00000  bestvalidloss -1028.15658  last_update 7\n",
      "train: iter 277  trainloss -1014.56675  validloss -936.67739±0.00000  bestvalidloss -1028.15658  last_update 8\n",
      "train: iter 278  trainloss -1067.45680  validloss -710.79763±0.00000  bestvalidloss -1028.15658  last_update 9\n",
      "train: iter 279  trainloss -1049.39639  validloss -555.17631±0.00000  bestvalidloss -1028.15658  last_update 10\n",
      "train: iter 280  trainloss -1059.65184  validloss -822.20167±0.00000  bestvalidloss -1028.15658  last_update 11\n",
      "train: iter 281  trainloss -1113.52168  validloss -829.20652±0.00000  bestvalidloss -1028.15658  last_update 12\n",
      "train: iter 282  trainloss -1093.08155  validloss -912.54783±0.00000  bestvalidloss -1028.15658  last_update 13\n",
      "train: iter 283  trainloss -1060.04864  validloss -801.37656±0.00000  bestvalidloss -1028.15658  last_update 14\n",
      "train: iter 284  trainloss -1173.02132  validloss -1015.00916±0.00000  bestvalidloss -1028.15658  last_update 15\n",
      "train: iter 285  trainloss -636.51703  validloss -904.81709±0.00000  bestvalidloss -1028.15658  last_update 16\n",
      "train: iter 286  trainloss -1036.56349  validloss -657.74124±0.00000  bestvalidloss -1028.15658  last_update 17\n",
      "train: iter 287  trainloss -1154.35748  validloss -883.29473±0.00000  bestvalidloss -1028.15658  last_update 18\n",
      "train: iter 288  trainloss -1166.23642  validloss -995.36387±0.00000  bestvalidloss -1028.15658  last_update 19\n",
      "train: iter 289  trainloss -1137.51380  validloss -951.15485±0.00000  bestvalidloss -1028.15658  last_update 20\n",
      "train: iter 290  trainloss -1124.86851  validloss -950.12958±0.00000  bestvalidloss -1028.15658  last_update 21\n",
      "train: iter 291  trainloss -996.01442  validloss -1075.44924±0.00000  bestvalidloss -1075.44924  last_update 0\n",
      "train: iter 292  trainloss -724.70813  validloss -803.48388±0.00000  bestvalidloss -1075.44924  last_update 1\n",
      "train: iter 293  trainloss -471.38355  validloss 5746.59624±0.00000  bestvalidloss -1075.44924  last_update 2\n",
      "train: iter 294  trainloss -1009.39831  validloss -576.01214±0.00000  bestvalidloss -1075.44924  last_update 3\n",
      "train: iter 295  trainloss -1052.00392  validloss -872.24208±0.00000  bestvalidloss -1075.44924  last_update 4\n",
      "train: iter 296  trainloss -1069.71079  validloss -727.01813±0.00000  bestvalidloss -1075.44924  last_update 5\n",
      "train: iter 297  trainloss -1129.38586  validloss -932.79925±0.00000  bestvalidloss -1075.44924  last_update 6\n",
      "train: iter 298  trainloss -1172.40923  validloss -965.36575±0.00000  bestvalidloss -1075.44924  last_update 7\n",
      "train: iter 299  trainloss -1155.58945  validloss -1026.37725±0.00000  bestvalidloss -1075.44924  last_update 8\n",
      "train: iter 300  trainloss -1214.66662  validloss -1060.68864±0.00000  bestvalidloss -1075.44924  last_update 9\n",
      "train: iter 301  trainloss -1040.31907  validloss -855.32649±0.00000  bestvalidloss -1075.44924  last_update 10\n",
      "train: iter 302  trainloss -988.34027  validloss -905.24837±0.00000  bestvalidloss -1075.44924  last_update 11\n",
      "train: iter 303  trainloss -1094.23392  validloss -762.84425±0.00000  bestvalidloss -1075.44924  last_update 12\n",
      "train: iter 304  trainloss -1209.86178  validloss -945.33770±0.00000  bestvalidloss -1075.44924  last_update 13\n",
      "train: iter 305  trainloss -1236.55563  validloss -996.20920±0.00000  bestvalidloss -1075.44924  last_update 14\n",
      "train: iter 306  trainloss -970.49761  validloss -866.17793±0.00000  bestvalidloss -1075.44924  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 307  trainloss -1069.45189  validloss -666.29227±0.00000  bestvalidloss -1075.44924  last_update 16\n",
      "train: iter 308  trainloss -1158.28138  validloss -828.47632±0.00000  bestvalidloss -1075.44924  last_update 17\n",
      "train: iter 309  trainloss -1199.76908  validloss -1024.89945±0.00000  bestvalidloss -1075.44924  last_update 18\n",
      "train: iter 310  trainloss -965.08552  validloss -948.55444±0.00000  bestvalidloss -1075.44924  last_update 19\n",
      "train: iter 311  trainloss -1042.23131  validloss -679.30852±0.00000  bestvalidloss -1075.44924  last_update 20\n",
      "train: iter 312  trainloss -1193.27723  validloss -848.00951±0.00000  bestvalidloss -1075.44924  last_update 21\n",
      "train: iter 313  trainloss -1151.60040  validloss -1068.92692±0.00000  bestvalidloss -1075.44924  last_update 22\n",
      "train: iter 314  trainloss -978.60614  validloss -657.01385±0.00000  bestvalidloss -1075.44924  last_update 23\n",
      "train: iter 315  trainloss -1121.62884  validloss -960.27484±0.00000  bestvalidloss -1075.44924  last_update 24\n",
      "train: iter 316  trainloss -1037.83634  validloss -1044.31772±0.00000  bestvalidloss -1075.44924  last_update 25\n",
      "train: iter 317  trainloss -618.88979  validloss -492.40013±0.00000  bestvalidloss -1075.44924  last_update 26\n",
      "train: iter 318  trainloss -1134.79525  validloss -743.73543±0.00000  bestvalidloss -1075.44924  last_update 27\n",
      "train: iter 319  trainloss -1186.96053  validloss -971.02530±0.00000  bestvalidloss -1075.44924  last_update 28\n",
      "train: iter 320  trainloss -1175.91340  validloss -989.05881±0.00000  bestvalidloss -1075.44924  last_update 29\n",
      "train: iter 321  trainloss -968.67924  validloss -925.29480±0.00000  bestvalidloss -1075.44924  last_update 30\n",
      "train: iter 322  trainloss -1088.20165  validloss -984.72191±0.00000  bestvalidloss -1075.44924  last_update 31\n",
      "train: iter 323  trainloss -1044.07917  validloss -997.40065±0.00000  bestvalidloss -1075.44924  last_update 32\n",
      "train: iter 324  trainloss -1133.73631  validloss -827.96369±0.00000  bestvalidloss -1075.44924  last_update 33\n",
      "train: iter 325  trainloss -1065.80923  validloss -925.36193±0.00000  bestvalidloss -1075.44924  last_update 34\n",
      "train: iter 326  trainloss -911.86445  validloss -917.05833±0.00000  bestvalidloss -1075.44924  last_update 35\n",
      "train: iter 327  trainloss -1099.89955  validloss -647.33668±0.00000  bestvalidloss -1075.44924  last_update 36\n",
      "train: iter 328  trainloss -1123.93941  validloss -886.97567±0.00000  bestvalidloss -1075.44924  last_update 37\n",
      "train: iter 329  trainloss -1024.18686  validloss -996.55856±0.00000  bestvalidloss -1075.44924  last_update 38\n",
      "train: iter 330  trainloss -1161.89154  validloss -977.45007±0.00000  bestvalidloss -1075.44924  last_update 39\n",
      "train: iter 331  trainloss -1105.46261  validloss -834.30528±0.00000  bestvalidloss -1075.44924  last_update 40\n",
      "train: iter 332  trainloss -1232.67659  validloss -1079.99387±0.00000  bestvalidloss -1079.99387  last_update 0\n",
      "train: iter 333  trainloss -1171.12252  validloss -1065.63756±0.00000  bestvalidloss -1079.99387  last_update 1\n",
      "train: iter 334  trainloss -1157.04373  validloss -955.07582±0.00000  bestvalidloss -1079.99387  last_update 2\n",
      "train: iter 335  trainloss -1097.62654  validloss -707.14906±0.00000  bestvalidloss -1079.99387  last_update 3\n",
      "train: iter 336  trainloss -1255.98164  validloss -1039.31440±0.00000  bestvalidloss -1079.99387  last_update 4\n",
      "train: iter 337  trainloss -1246.66466  validloss -1058.36810±0.00000  bestvalidloss -1079.99387  last_update 5\n",
      "train: iter 338  trainloss -1242.18781  validloss -1077.23185±0.00000  bestvalidloss -1079.99387  last_update 6\n",
      "train: iter 339  trainloss -961.81624  validloss -1107.20137±0.00000  bestvalidloss -1107.20137  last_update 0\n",
      "train: iter 340  trainloss -1165.55392  validloss -890.40393±0.00000  bestvalidloss -1107.20137  last_update 1\n",
      "train: iter 341  trainloss -1245.50368  validloss -1014.39785±0.00000  bestvalidloss -1107.20137  last_update 2\n",
      "train: iter 342  trainloss -900.82649  validloss -1074.73051±0.00000  bestvalidloss -1107.20137  last_update 3\n",
      "train: iter 343  trainloss -1047.19551  validloss -699.47667±0.00000  bestvalidloss -1107.20137  last_update 4\n",
      "train: iter 344  trainloss -1123.92002  validloss -926.41201±0.00000  bestvalidloss -1107.20137  last_update 5\n",
      "train: iter 345  trainloss -1154.00611  validloss -828.38162±0.00000  bestvalidloss -1107.20137  last_update 6\n",
      "train: iter 346  trainloss -1231.01194  validloss -1062.96869±0.00000  bestvalidloss -1107.20137  last_update 7\n",
      "train: iter 347  trainloss -1156.27597  validloss -959.19996±0.00000  bestvalidloss -1107.20137  last_update 8\n",
      "train: iter 348  trainloss -1004.04288  validloss -984.15969±0.00000  bestvalidloss -1107.20137  last_update 9\n",
      "train: iter 349  trainloss -1112.22546  validloss -735.75572±0.00000  bestvalidloss -1107.20137  last_update 10\n",
      "train: iter 350  trainloss -1152.26615  validloss -967.48464±0.00000  bestvalidloss -1107.20137  last_update 11\n",
      "train: iter 351  trainloss -1262.08610  validloss -1071.83734±0.00000  bestvalidloss -1107.20137  last_update 12\n",
      "train: iter 352  trainloss -1197.94606  validloss -1059.03900±0.00000  bestvalidloss -1107.20137  last_update 13\n",
      "train: iter 353  trainloss -1105.85596  validloss -946.90863±0.00000  bestvalidloss -1107.20137  last_update 14\n",
      "train: iter 354  trainloss -1229.04041  validloss -624.52619±0.00000  bestvalidloss -1107.20137  last_update 15\n",
      "train: iter 355  trainloss -1168.26230  validloss -1094.69073±0.00000  bestvalidloss -1107.20137  last_update 16\n",
      "train: iter 356  trainloss -1251.71730  validloss -970.25089±0.00000  bestvalidloss -1107.20137  last_update 17\n",
      "train: iter 357  trainloss -1164.67886  validloss -999.11742±0.00000  bestvalidloss -1107.20137  last_update 18\n",
      "train: iter 358  trainloss -1247.06188  validloss -1102.59899±0.00000  bestvalidloss -1107.20137  last_update 19\n",
      "train: iter 359  trainloss -1291.57071  validloss -925.88676±0.00000  bestvalidloss -1107.20137  last_update 20\n",
      "train: iter 360  trainloss -1130.02550  validloss -1171.32792±0.00000  bestvalidloss -1171.32792  last_update 0\n",
      "train: iter 361  trainloss -1142.96636  validloss -723.68547±0.00000  bestvalidloss -1171.32792  last_update 1\n",
      "train: iter 362  trainloss -1238.49800  validloss -1054.32169±0.00000  bestvalidloss -1171.32792  last_update 2\n",
      "train: iter 363  trainloss -1033.22552  validloss -1020.75331±0.00000  bestvalidloss -1171.32792  last_update 3\n",
      "train: iter 364  trainloss -1202.64808  validloss -750.74840±0.00000  bestvalidloss -1171.32792  last_update 4\n",
      "train: iter 365  trainloss -1247.88444  validloss -989.38631±0.00000  bestvalidloss -1171.32792  last_update 5\n",
      "train: iter 366  trainloss -1221.79158  validloss -1094.95993±0.00000  bestvalidloss -1171.32792  last_update 6\n",
      "train: iter 367  trainloss -1159.87939  validloss -954.06501±0.00000  bestvalidloss -1171.32792  last_update 7\n",
      "train: iter 368  trainloss -1073.35336  validloss -1040.74248±0.00000  bestvalidloss -1171.32792  last_update 8\n",
      "train: iter 369  trainloss -1074.75671  validloss -827.13938±0.00000  bestvalidloss -1171.32792  last_update 9\n",
      "train: iter 370  trainloss -1066.20025  validloss -912.49934±0.00000  bestvalidloss -1171.32792  last_update 10\n",
      "train: iter 371  trainloss -1165.20672  validloss -1010.13330±0.00000  bestvalidloss -1171.32792  last_update 11\n",
      "train: iter 372  trainloss -1171.67830  validloss -785.28411±0.00000  bestvalidloss -1171.32792  last_update 12\n",
      "train: iter 373  trainloss -1220.78961  validloss -904.49348±0.00000  bestvalidloss -1171.32792  last_update 13\n",
      "train: iter 374  trainloss -1290.98650  validloss -1033.95459±0.00000  bestvalidloss -1171.32792  last_update 14\n",
      "train: iter 375  trainloss -1275.53735  validloss -1178.06778±0.00000  bestvalidloss -1178.06778  last_update 0\n",
      "train: iter 376  trainloss -1096.35749  validloss -568.30978±0.00000  bestvalidloss -1178.06778  last_update 1\n",
      "train: iter 377  trainloss -1258.70425  validloss -1060.20139±0.00000  bestvalidloss -1178.06778  last_update 2\n",
      "train: iter 378  trainloss -1083.84632  validloss -1077.34848±0.00000  bestvalidloss -1178.06778  last_update 3\n",
      "train: iter 379  trainloss -1020.12271  validloss -538.76084±0.00000  bestvalidloss -1178.06778  last_update 4\n",
      "train: iter 380  trainloss -1253.36893  validloss -1004.85972±0.00000  bestvalidloss -1178.06778  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 381  trainloss -1221.92553  validloss -1108.97505±0.00000  bestvalidloss -1178.06778  last_update 6\n",
      "train: iter 382  trainloss -831.41549  validloss -992.82950±0.00000  bestvalidloss -1178.06778  last_update 7\n",
      "train: iter 383  trainloss -1191.01029  validloss -919.45993±0.00000  bestvalidloss -1178.06778  last_update 8\n",
      "train: iter 384  trainloss -1203.37311  validloss -1047.70579±0.00000  bestvalidloss -1178.06778  last_update 9\n",
      "train: iter 385  trainloss -1191.67383  validloss -1049.68679±0.00000  bestvalidloss -1178.06778  last_update 10\n",
      "train: iter 386  trainloss -1128.94349  validloss -968.64396±0.00000  bestvalidloss -1178.06778  last_update 11\n",
      "train: iter 387  trainloss -1283.16489  validloss -1093.36967±0.00000  bestvalidloss -1178.06778  last_update 12\n",
      "train: iter 388  trainloss -1247.97481  validloss -906.39036±0.00000  bestvalidloss -1178.06778  last_update 13\n",
      "train: iter 389  trainloss -1287.84977  validloss -1061.46583±0.00000  bestvalidloss -1178.06778  last_update 14\n",
      "train: iter 390  trainloss -1286.89387  validloss -1148.52899±0.00000  bestvalidloss -1178.06778  last_update 15\n",
      "train: iter 391  trainloss -1291.03848  validloss -1126.58723±0.00000  bestvalidloss -1178.06778  last_update 16\n",
      "train: iter 392  trainloss -1242.24098  validloss -1082.02591±0.00000  bestvalidloss -1178.06778  last_update 17\n",
      "train: iter 393  trainloss -1025.32882  validloss -799.48508±0.00000  bestvalidloss -1178.06778  last_update 18\n",
      "train: iter 394  trainloss -1323.52840  validloss -1138.74912±0.00000  bestvalidloss -1178.06778  last_update 19\n",
      "train: iter 395  trainloss -1236.11877  validloss -1043.30003±0.00000  bestvalidloss -1178.06778  last_update 20\n",
      "train: iter 396  trainloss -1306.17352  validloss -950.42179±0.00000  bestvalidloss -1178.06778  last_update 21\n",
      "train: iter 397  trainloss -1257.75324  validloss -1079.09294±0.00000  bestvalidloss -1178.06778  last_update 22\n",
      "train: iter 398  trainloss -1319.72627  validloss -1116.55032±0.00000  bestvalidloss -1178.06778  last_update 23\n",
      "train: iter 399  trainloss -1190.55221  validloss -1056.83199±0.00000  bestvalidloss -1178.06778  last_update 24\n",
      "train: iter 400  trainloss -772.77499  validloss -959.41073±0.00000  bestvalidloss -1178.06778  last_update 25\n",
      "train: iter 401  trainloss -1187.37560  validloss -969.57045±0.00000  bestvalidloss -1178.06778  last_update 26\n",
      "train: iter 402  trainloss -1276.78645  validloss -829.33945±0.00000  bestvalidloss -1178.06778  last_update 27\n",
      "train: iter 403  trainloss -1326.81127  validloss -1094.56809±0.00000  bestvalidloss -1178.06778  last_update 28\n",
      "train: iter 404  trainloss -1058.14548  validloss -982.03982±0.00000  bestvalidloss -1178.06778  last_update 29\n",
      "train: iter 405  trainloss -1256.93758  validloss -1082.12457±0.00000  bestvalidloss -1178.06778  last_update 30\n",
      "train: iter 406  trainloss -1175.43185  validloss -779.38838±0.00000  bestvalidloss -1178.06778  last_update 31\n",
      "train: iter 407  trainloss -1048.57530  validloss -1153.45300±0.00000  bestvalidloss -1178.06778  last_update 32\n",
      "train: iter 408  trainloss -1212.62467  validloss -709.92882±0.00000  bestvalidloss -1178.06778  last_update 33\n",
      "train: iter 409  trainloss -1202.97747  validloss -1030.27774±0.00000  bestvalidloss -1178.06778  last_update 34\n",
      "train: iter 410  trainloss -1300.61168  validloss -1078.24296±0.00000  bestvalidloss -1178.06778  last_update 35\n",
      "train: iter 411  trainloss -1208.35668  validloss -925.33820±0.00000  bestvalidloss -1178.06778  last_update 36\n",
      "train: iter 412  trainloss -1284.04896  validloss -1088.45612±0.00000  bestvalidloss -1178.06778  last_update 37\n",
      "train: iter 413  trainloss -1332.66654  validloss -1138.19659±0.00000  bestvalidloss -1178.06778  last_update 38\n",
      "train: iter 414  trainloss -1140.97180  validloss -1123.04429±0.00000  bestvalidloss -1178.06778  last_update 39\n",
      "train: iter 415  trainloss -1322.18344  validloss -1067.49331±0.00000  bestvalidloss -1178.06778  last_update 40\n",
      "train: iter 416  trainloss -1205.60636  validloss -1167.81454±0.00000  bestvalidloss -1178.06778  last_update 41\n",
      "train: iter 417  trainloss -1201.00430  validloss -848.23373±0.00000  bestvalidloss -1178.06778  last_update 42\n",
      "train: iter 418  trainloss -1145.17484  validloss -794.35590±0.00000  bestvalidloss -1178.06778  last_update 43\n",
      "train: iter 419  trainloss -1349.68740  validloss -1148.04300±0.00000  bestvalidloss -1178.06778  last_update 44\n",
      "train: iter 420  trainloss -1235.53236  validloss -1235.40723±0.00000  bestvalidloss -1235.40723  last_update 0\n",
      "train: iter 421  trainloss -1238.45756  validloss -916.97054±0.00000  bestvalidloss -1235.40723  last_update 1\n",
      "train: iter 422  trainloss -1188.64930  validloss -572.87343±0.00000  bestvalidloss -1235.40723  last_update 2\n",
      "train: iter 423  trainloss -1327.40520  validloss -1013.46537±0.00000  bestvalidloss -1235.40723  last_update 3\n",
      "train: iter 424  trainloss -1088.74966  validloss -857.02893±0.00000  bestvalidloss -1235.40723  last_update 4\n",
      "train: iter 425  trainloss -1265.53434  validloss -983.03107±0.00000  bestvalidloss -1235.40723  last_update 5\n",
      "train: iter 426  trainloss -1255.92224  validloss -1067.04217±0.00000  bestvalidloss -1235.40723  last_update 6\n",
      "train: iter 427  trainloss -1231.37913  validloss -1007.55050±0.00000  bestvalidloss -1235.40723  last_update 7\n",
      "train: iter 428  trainloss -1306.43047  validloss -1046.45963±0.00000  bestvalidloss -1235.40723  last_update 8\n",
      "train: iter 429  trainloss -1344.18174  validloss -1137.67306±0.00000  bestvalidloss -1235.40723  last_update 9\n",
      "train: iter 430  trainloss -1162.81299  validloss -1114.26950±0.00000  bestvalidloss -1235.40723  last_update 10\n",
      "train: iter 431  trainloss -1282.85479  validloss -886.54709±0.00000  bestvalidloss -1235.40723  last_update 11\n",
      "train: iter 432  trainloss -1221.26972  validloss -1081.29598±0.00000  bestvalidloss -1235.40723  last_update 12\n",
      "train: iter 433  trainloss -1197.29412  validloss -1176.60161±0.00000  bestvalidloss -1235.40723  last_update 13\n",
      "train: iter 434  trainloss -1339.55797  validloss -1006.30800±0.00000  bestvalidloss -1235.40723  last_update 14\n",
      "train: iter 435  trainloss -1283.01873  validloss -1169.90147±0.00000  bestvalidloss -1235.40723  last_update 15\n",
      "train: iter 436  trainloss -1269.93324  validloss -788.13998±0.00000  bestvalidloss -1235.40723  last_update 16\n",
      "train: iter 437  trainloss -1252.60121  validloss -1096.36295±0.00000  bestvalidloss -1235.40723  last_update 17\n",
      "train: iter 438  trainloss -1121.00680  validloss -908.43697±0.00000  bestvalidloss -1235.40723  last_update 18\n",
      "train: iter 439  trainloss -1160.29275  validloss -1088.44632±0.00000  bestvalidloss -1235.40723  last_update 19\n",
      "train: iter 440  trainloss -1330.29372  validloss -1085.22074±0.00000  bestvalidloss -1235.40723  last_update 20\n",
      "train: iter 441  trainloss -1250.83368  validloss -1136.29327±0.00000  bestvalidloss -1235.40723  last_update 21\n",
      "train: iter 442  trainloss -1313.57098  validloss -994.27873±0.00000  bestvalidloss -1235.40723  last_update 22\n",
      "train: iter 443  trainloss -1385.83328  validloss -1118.30280±0.00000  bestvalidloss -1235.40723  last_update 23\n",
      "train: iter 444  trainloss -1284.86802  validloss -1187.35381±0.00000  bestvalidloss -1235.40723  last_update 24\n",
      "train: iter 445  trainloss -1193.68366  validloss -816.68149±0.00000  bestvalidloss -1235.40723  last_update 25\n",
      "train: iter 446  trainloss -1325.36963  validloss -1019.29391±0.00000  bestvalidloss -1235.40723  last_update 26\n",
      "train: iter 447  trainloss -1334.16111  validloss -1217.51192±0.00000  bestvalidloss -1235.40723  last_update 27\n",
      "train: iter 448  trainloss -1227.27997  validloss -1016.66291±0.00000  bestvalidloss -1235.40723  last_update 28\n",
      "train: iter 449  trainloss -1348.35456  validloss -1106.94870±0.00000  bestvalidloss -1235.40723  last_update 29\n",
      "train: iter 450  trainloss -1366.72563  validloss -1045.07809±0.00000  bestvalidloss -1235.40723  last_update 30\n",
      "train: iter 451  trainloss -1326.08010  validloss -1197.29227±0.00000  bestvalidloss -1235.40723  last_update 31\n",
      "train: iter 452  trainloss -1210.73693  validloss -631.24098±0.00000  bestvalidloss -1235.40723  last_update 32\n",
      "train: iter 453  trainloss -1364.65906  validloss -1183.92042±0.00000  bestvalidloss -1235.40723  last_update 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 454  trainloss -1211.22768  validloss -1048.31811±0.00000  bestvalidloss -1235.40723  last_update 34\n",
      "train: iter 455  trainloss -1348.83712  validloss -1061.36906±0.00000  bestvalidloss -1235.40723  last_update 35\n",
      "train: iter 456  trainloss -1286.79291  validloss -1013.05613±0.00000  bestvalidloss -1235.40723  last_update 36\n",
      "train: iter 457  trainloss -1340.45470  validloss -1139.83706±0.00000  bestvalidloss -1235.40723  last_update 37\n",
      "train: iter 458  trainloss -1180.56367  validloss -1134.90016±0.00000  bestvalidloss -1235.40723  last_update 38\n",
      "train: iter 459  trainloss -1348.00738  validloss -1070.07535±0.00000  bestvalidloss -1235.40723  last_update 39\n",
      "train: iter 460  trainloss -1359.16762  validloss -1182.07611±0.00000  bestvalidloss -1235.40723  last_update 40\n",
      "train: iter 461  trainloss -1270.39704  validloss -1212.65367±0.00000  bestvalidloss -1235.40723  last_update 41\n",
      "train: iter 462  trainloss -1325.54115  validloss -957.06841±0.00000  bestvalidloss -1235.40723  last_update 42\n",
      "train: iter 463  trainloss -1245.98579  validloss -933.80394±0.00000  bestvalidloss -1235.40723  last_update 43\n",
      "train: iter 464  trainloss -1203.38746  validloss -944.75108±0.00000  bestvalidloss -1235.40723  last_update 44\n",
      "train: iter 465  trainloss -1185.30404  validloss -869.75947±0.00000  bestvalidloss -1235.40723  last_update 45\n",
      "train: iter 466  trainloss -1358.61418  validloss -1074.60628±0.00000  bestvalidloss -1235.40723  last_update 46\n",
      "train: iter 467  trainloss -1337.90911  validloss -1157.98086±0.00000  bestvalidloss -1235.40723  last_update 47\n",
      "train: iter 468  trainloss -1285.76054  validloss -1110.26786±0.00000  bestvalidloss -1235.40723  last_update 48\n",
      "train: iter 469  trainloss -1382.35353  validloss -1010.58035±0.00000  bestvalidloss -1235.40723  last_update 49\n",
      "train: iter 470  trainloss -1280.82404  validloss -1258.76749±0.00000  bestvalidloss -1258.76749  last_update 0\n",
      "train: iter 471  trainloss -1306.31025  validloss -957.86497±0.00000  bestvalidloss -1258.76749  last_update 1\n",
      "train: iter 472  trainloss -1374.57716  validloss -1212.85192±0.00000  bestvalidloss -1258.76749  last_update 2\n",
      "train: iter 473  trainloss -1241.86392  validloss -1080.61480±0.00000  bestvalidloss -1258.76749  last_update 3\n",
      "train: iter 474  trainloss -1264.75831  validloss -1120.36328±0.00000  bestvalidloss -1258.76749  last_update 4\n",
      "train: iter 475  trainloss -1324.99154  validloss -1183.30731±0.00000  bestvalidloss -1258.76749  last_update 5\n",
      "train: iter 476  trainloss -1383.25278  validloss -1188.21829±0.00000  bestvalidloss -1258.76749  last_update 6\n",
      "train: iter 477  trainloss -1322.79651  validloss -1199.45321±0.00000  bestvalidloss -1258.76749  last_update 7\n",
      "train: iter 478  trainloss -1197.58679  validloss -628.27914±0.00000  bestvalidloss -1258.76749  last_update 8\n",
      "train: iter 479  trainloss -1298.78068  validloss -1094.08794±0.00000  bestvalidloss -1258.76749  last_update 9\n",
      "train: iter 480  trainloss -1067.13910  validloss -862.72613±0.00000  bestvalidloss -1258.76749  last_update 10\n",
      "train: iter 481  trainloss -1357.72627  validloss -1002.48494±0.00000  bestvalidloss -1258.76749  last_update 11\n",
      "train: iter 482  trainloss -1306.59866  validloss -1128.69058±0.00000  bestvalidloss -1258.76749  last_update 12\n",
      "train: iter 483  trainloss -1268.26074  validloss -977.29236±0.00000  bestvalidloss -1258.76749  last_update 13\n",
      "train: iter 484  trainloss -1346.23849  validloss -1039.43852±0.00000  bestvalidloss -1258.76749  last_update 14\n",
      "train: iter 485  trainloss -1362.80670  validloss -1188.74125±0.00000  bestvalidloss -1258.76749  last_update 15\n",
      "train: iter 486  trainloss -1415.10846  validloss -1190.89833±0.00000  bestvalidloss -1258.76749  last_update 16\n",
      "train: iter 487  trainloss -1410.69451  validloss -1217.54794±0.00000  bestvalidloss -1258.76749  last_update 17\n",
      "train: iter 488  trainloss -924.36582  validloss -1136.51974±0.00000  bestvalidloss -1258.76749  last_update 18\n",
      "train: iter 489  trainloss -1174.60042  validloss -528.57617±0.00000  bestvalidloss -1258.76749  last_update 19\n",
      "train: iter 490  trainloss -1267.79688  validloss -1055.92505±0.00000  bestvalidloss -1258.76749  last_update 20\n",
      "train: iter 491  trainloss -1382.74026  validloss -1159.60298±0.00000  bestvalidloss -1258.76749  last_update 21\n",
      "train: iter 492  trainloss -1361.37606  validloss -1251.82227±0.00000  bestvalidloss -1258.76749  last_update 22\n",
      "train: iter 493  trainloss -1296.72236  validloss -1126.48849±0.00000  bestvalidloss -1258.76749  last_update 23\n",
      "train: iter 494  trainloss -977.91039  validloss -1124.88563±0.00000  bestvalidloss -1258.76749  last_update 24\n",
      "train: iter 495  trainloss -1212.79006  validloss -736.49612±0.00000  bestvalidloss -1258.76749  last_update 25\n",
      "train: iter 496  trainloss -1360.98286  validloss -1098.97058±0.00000  bestvalidloss -1258.76749  last_update 26\n",
      "train: iter 497  trainloss -1308.37844  validloss -1142.78598±0.00000  bestvalidloss -1258.76749  last_update 27\n",
      "train: iter 498  trainloss -1140.41647  validloss -413.64594±0.00000  bestvalidloss -1258.76749  last_update 28\n",
      "train: iter 499  trainloss -1204.01611  validloss -954.10553±0.00000  bestvalidloss -1258.76749  last_update 29\n",
      "train: iter 500  trainloss -1371.90763  validloss -1129.24178±0.00000  bestvalidloss -1258.76749  last_update 30\n",
      "train: iter 501  trainloss -1402.13281  validloss -1135.30029±0.00000  bestvalidloss -1258.76749  last_update 31\n",
      "train: iter 502  trainloss -1159.77463  validloss -1215.02338±0.00000  bestvalidloss -1258.76749  last_update 32\n",
      "train: iter 503  trainloss -1234.62336  validloss -774.36229±0.00000  bestvalidloss -1258.76749  last_update 33\n",
      "train: iter 504  trainloss -1370.40752  validloss -1115.28915±0.00000  bestvalidloss -1258.76749  last_update 34\n",
      "train: iter 505  trainloss -1385.96462  validloss -1145.33602±0.00000  bestvalidloss -1258.76749  last_update 35\n",
      "train: iter 506  trainloss -1397.02856  validloss -1153.70831±0.00000  bestvalidloss -1258.76749  last_update 36\n",
      "train: iter 507  trainloss -1274.55120  validloss -1248.81498±0.00000  bestvalidloss -1258.76749  last_update 37\n",
      "train: iter 508  trainloss -1342.52795  validloss -764.45742±0.00000  bestvalidloss -1258.76749  last_update 38\n",
      "train: iter 509  trainloss -1372.16822  validloss -1070.63046±0.00000  bestvalidloss -1258.76749  last_update 39\n",
      "train: iter 510  trainloss -1424.62032  validloss -1200.29526±0.00000  bestvalidloss -1258.76749  last_update 40\n",
      "train: iter 511  trainloss -1381.10720  validloss -1259.91845±0.00000  bestvalidloss -1259.91845  last_update 0\n",
      "train: iter 512  trainloss -1311.95562  validloss -966.22903±0.00000  bestvalidloss -1259.91845  last_update 1\n",
      "train: iter 513  trainloss -1356.56487  validloss -1163.71525±0.00000  bestvalidloss -1259.91845  last_update 2\n",
      "train: iter 514  trainloss -1449.69514  validloss -1221.55442±0.00000  bestvalidloss -1259.91845  last_update 3\n",
      "train: iter 515  trainloss -1300.96139  validloss -1261.76992±0.00000  bestvalidloss -1261.76992  last_update 0\n",
      "train: iter 516  trainloss -1284.56535  validloss -1114.98760±0.00000  bestvalidloss -1261.76992  last_update 1\n",
      "train: iter 517  trainloss -1391.08550  validloss -867.64299±0.00000  bestvalidloss -1261.76992  last_update 2\n",
      "train: iter 518  trainloss -1338.20599  validloss -1143.26918±0.00000  bestvalidloss -1261.76992  last_update 3\n",
      "train: iter 519  trainloss -1429.47267  validloss -1084.44665±0.00000  bestvalidloss -1261.76992  last_update 4\n",
      "train: iter 520  trainloss -998.65490  validloss -1197.49325±0.00000  bestvalidloss -1261.76992  last_update 5\n",
      "train: iter 521  trainloss -1212.00501  validloss -970.66698±0.00000  bestvalidloss -1261.76992  last_update 6\n",
      "train: iter 522  trainloss -1324.97157  validloss -957.34393±0.00000  bestvalidloss -1261.76992  last_update 7\n",
      "train: iter 523  trainloss -1411.02178  validloss -1215.00993±0.00000  bestvalidloss -1261.76992  last_update 8\n",
      "train: iter 524  trainloss -1388.68321  validloss -1238.60635±0.00000  bestvalidloss -1261.76992  last_update 9\n",
      "train: iter 525  trainloss -1369.62700  validloss -1161.71918±0.00000  bestvalidloss -1261.76992  last_update 10\n",
      "train: iter 526  trainloss -1248.11777  validloss -1048.32998±0.00000  bestvalidloss -1261.76992  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 527  trainloss -1123.11554  validloss -847.64900±0.00000  bestvalidloss -1261.76992  last_update 12\n",
      "train: iter 528  trainloss -1378.87644  validloss -1163.26360±0.00000  bestvalidloss -1261.76992  last_update 13\n",
      "train: iter 529  trainloss -1418.62802  validloss -1204.50655±0.00000  bestvalidloss -1261.76992  last_update 14\n",
      "train: iter 530  trainloss -1360.40260  validloss -1225.01423±0.00000  bestvalidloss -1261.76992  last_update 15\n",
      "train: iter 531  trainloss -1284.26535  validloss -1216.36869±0.00000  bestvalidloss -1261.76992  last_update 16\n",
      "train: iter 532  trainloss -1287.15504  validloss -1057.56650±0.00000  bestvalidloss -1261.76992  last_update 17\n",
      "train: iter 533  trainloss -1386.47658  validloss -1076.39500±0.00000  bestvalidloss -1261.76992  last_update 18\n",
      "train: iter 534  trainloss -1393.38155  validloss -1214.41217±0.00000  bestvalidloss -1261.76992  last_update 19\n",
      "train: iter 535  trainloss -1395.14799  validloss -1085.88569±0.00000  bestvalidloss -1261.76992  last_update 20\n",
      "train: iter 536  trainloss -1406.52671  validloss -1179.74509±0.00000  bestvalidloss -1261.76992  last_update 21\n",
      "train: iter 537  trainloss -1027.95717  validloss -995.54794±0.00000  bestvalidloss -1261.76992  last_update 22\n",
      "train: iter 538  trainloss -1395.88961  validloss -1079.43746±0.00000  bestvalidloss -1261.76992  last_update 23\n",
      "train: iter 539  trainloss -1398.98748  validloss -1190.63796±0.00000  bestvalidloss -1261.76992  last_update 24\n",
      "train: iter 540  trainloss -1424.27591  validloss -1145.85957±0.00000  bestvalidloss -1261.76992  last_update 25\n",
      "train: iter 541  trainloss -1387.09468  validloss -1187.80695±0.00000  bestvalidloss -1261.76992  last_update 26\n",
      "train: iter 542  trainloss -1316.71401  validloss -1168.79578±0.00000  bestvalidloss -1261.76992  last_update 27\n",
      "train: iter 543  trainloss -1394.31570  validloss -1105.31657±0.00000  bestvalidloss -1261.76992  last_update 28\n",
      "train: iter 544  trainloss -1426.29731  validloss -1168.61752±0.00000  bestvalidloss -1261.76992  last_update 29\n",
      "train: iter 545  trainloss -1180.10750  validloss -997.24793±0.00000  bestvalidloss -1261.76992  last_update 30\n",
      "train: iter 546  trainloss -1301.58729  validloss -582.20116±0.00000  bestvalidloss -1261.76992  last_update 31\n",
      "train: iter 547  trainloss -1372.52561  validloss -1160.78727±0.00000  bestvalidloss -1261.76992  last_update 32\n",
      "train: iter 548  trainloss -1448.26485  validloss -1167.37196±0.00000  bestvalidloss -1261.76992  last_update 33\n",
      "train: iter 549  trainloss -1391.76728  validloss -1289.84872±0.00000  bestvalidloss -1289.84872  last_update 0\n",
      "train: iter 550  trainloss -1381.14636  validloss -1037.50803±0.00000  bestvalidloss -1289.84872  last_update 1\n",
      "train: iter 551  trainloss -1387.18811  validloss -1235.85091±0.00000  bestvalidloss -1289.84872  last_update 2\n",
      "train: iter 552  trainloss -1370.63748  validloss -1158.97000±0.00000  bestvalidloss -1289.84872  last_update 3\n",
      "train: iter 553  trainloss -1411.70459  validloss -1204.17552±0.00000  bestvalidloss -1289.84872  last_update 4\n",
      "train: iter 554  trainloss -1394.54911  validloss -1201.31505±0.00000  bestvalidloss -1289.84872  last_update 5\n",
      "train: iter 555  trainloss -1234.15250  validloss -1280.18324±0.00000  bestvalidloss -1289.84872  last_update 6\n",
      "train: iter 556  trainloss -1381.76279  validloss -1107.56503±0.00000  bestvalidloss -1289.84872  last_update 7\n",
      "train: iter 557  trainloss -1426.17555  validloss -1204.62674±0.00000  bestvalidloss -1289.84872  last_update 8\n",
      "train: iter 558  trainloss -1411.89397  validloss -1139.56022±0.00000  bestvalidloss -1289.84872  last_update 9\n",
      "train: iter 559  trainloss -1365.59217  validloss -1260.85826±0.00000  bestvalidloss -1289.84872  last_update 10\n",
      "train: iter 560  trainloss -1249.82630  validloss -1017.67256±0.00000  bestvalidloss -1289.84872  last_update 11\n",
      "train: iter 561  trainloss -1409.65607  validloss -1138.51369±0.00000  bestvalidloss -1289.84872  last_update 12\n",
      "train: iter 562  trainloss -1438.38545  validloss -1211.57967±0.00000  bestvalidloss -1289.84872  last_update 13\n",
      "train: iter 563  trainloss -1415.10781  validloss -1255.16401±0.00000  bestvalidloss -1289.84872  last_update 14\n",
      "train: iter 564  trainloss -1241.19382  validloss -191.56201±0.00000  bestvalidloss -1289.84872  last_update 15\n",
      "train: iter 565  trainloss -1294.29192  validloss -1061.16860±0.00000  bestvalidloss -1289.84872  last_update 16\n",
      "train: iter 566  trainloss -1160.71142  validloss -964.95028±0.00000  bestvalidloss -1289.84872  last_update 17\n",
      "train: iter 567  trainloss -1299.58021  validloss -760.56139±0.00000  bestvalidloss -1289.84872  last_update 18\n",
      "train: iter 568  trainloss -1417.82399  validloss -1194.67456±0.00000  bestvalidloss -1289.84872  last_update 19\n",
      "train: iter 569  trainloss -1419.23212  validloss -1258.12421±0.00000  bestvalidloss -1289.84872  last_update 20\n",
      "train: iter 570  trainloss -1444.78640  validloss -1201.98288±0.00000  bestvalidloss -1289.84872  last_update 21\n",
      "train: iter 571  trainloss -1367.60901  validloss -1245.45691±0.00000  bestvalidloss -1289.84872  last_update 22\n",
      "train: iter 572  trainloss -1377.73715  validloss -1132.20379±0.00000  bestvalidloss -1289.84872  last_update 23\n",
      "train: iter 573  trainloss -1344.07429  validloss -1205.10829±0.00000  bestvalidloss -1289.84872  last_update 24\n",
      "train: iter 574  trainloss -1361.49707  validloss -1159.78259±0.00000  bestvalidloss -1289.84872  last_update 25\n",
      "train: iter 575  trainloss -1392.96183  validloss -1162.34933±0.00000  bestvalidloss -1289.84872  last_update 26\n",
      "train: iter 576  trainloss -1391.92426  validloss -1175.65195±0.00000  bestvalidloss -1289.84872  last_update 27\n",
      "train: iter 577  trainloss -1401.69011  validloss -1181.46875±0.00000  bestvalidloss -1289.84872  last_update 28\n",
      "train: iter 578  trainloss -1376.96990  validloss -1171.47256±0.00000  bestvalidloss -1289.84872  last_update 29\n",
      "train: iter 579  trainloss -1272.29154  validloss -1142.52396±0.00000  bestvalidloss -1289.84872  last_update 30\n",
      "train: iter 580  trainloss -1401.94228  validloss -1186.34698±0.00000  bestvalidloss -1289.84872  last_update 31\n",
      "train: iter 581  trainloss -1438.89031  validloss -1228.71257±0.00000  bestvalidloss -1289.84872  last_update 32\n",
      "train: iter 582  trainloss -1387.87058  validloss -1185.95836±0.00000  bestvalidloss -1289.84872  last_update 33\n",
      "train: iter 583  trainloss -1444.07798  validloss -1204.07688±0.00000  bestvalidloss -1289.84872  last_update 34\n",
      "train: iter 584  trainloss -1380.91102  validloss -845.40718±0.00000  bestvalidloss -1289.84872  last_update 35\n",
      "train: iter 585  trainloss -1337.45967  validloss -1127.93175±0.00000  bestvalidloss -1289.84872  last_update 36\n",
      "train: iter 586  trainloss -1312.63781  validloss -1107.40397±0.00000  bestvalidloss -1289.84872  last_update 37\n",
      "train: iter 587  trainloss -1371.56219  validloss -1184.82417±0.00000  bestvalidloss -1289.84872  last_update 38\n",
      "train: iter 588  trainloss -1429.52631  validloss -1260.89308±0.00000  bestvalidloss -1289.84872  last_update 39\n",
      "train: iter 589  trainloss -1328.79322  validloss -1160.44483±0.00000  bestvalidloss -1289.84872  last_update 40\n",
      "train: iter 590  trainloss -1354.37779  validloss -1188.13946±0.00000  bestvalidloss -1289.84872  last_update 41\n",
      "train: iter 591  trainloss -1354.31389  validloss -886.31525±0.00000  bestvalidloss -1289.84872  last_update 42\n",
      "train: iter 592  trainloss -1428.29248  validloss -1255.76944±0.00000  bestvalidloss -1289.84872  last_update 43\n",
      "train: iter 593  trainloss -1406.37611  validloss -1225.26340±0.00000  bestvalidloss -1289.84872  last_update 44\n",
      "train: iter 594  trainloss -1377.66985  validloss -1211.94580±0.00000  bestvalidloss -1289.84872  last_update 45\n",
      "train: iter 595  trainloss -1447.36808  validloss -1221.79998±0.00000  bestvalidloss -1289.84872  last_update 46\n",
      "train: iter 596  trainloss -1273.70413  validloss -1106.37452±0.00000  bestvalidloss -1289.84872  last_update 47\n",
      "train: iter 597  trainloss -1361.55858  validloss -889.29124±0.00000  bestvalidloss -1289.84872  last_update 48\n",
      "train: iter 598  trainloss -1321.18792  validloss -758.30422±0.00000  bestvalidloss -1289.84872  last_update 49\n",
      "train: iter 599  trainloss -1306.98252  validloss -1172.76909±0.00000  bestvalidloss -1289.84872  last_update 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 600  trainloss -1322.71404  validloss -828.09889±0.00000  bestvalidloss -1289.84872  last_update 51\n",
      "train: iter 601  trainloss -1452.74522  validloss -1227.26555±0.00000  bestvalidloss -1289.84872  last_update 52\n",
      "train: iter 602  trainloss -1325.86017  validloss -1243.76726±0.00000  bestvalidloss -1289.84872  last_update 53\n",
      "train: iter 603  trainloss -1433.63280  validloss -1087.95142±0.00000  bestvalidloss -1289.84872  last_update 54\n",
      "train: iter 604  trainloss -1451.89328  validloss -1313.90755±0.00000  bestvalidloss -1313.90755  last_update 0\n",
      "train: iter 605  trainloss -1319.89386  validloss -1231.66184±0.00000  bestvalidloss -1313.90755  last_update 1\n",
      "train: iter 606  trainloss -1262.76439  validloss -789.20202±0.00000  bestvalidloss -1313.90755  last_update 2\n",
      "train: iter 607  trainloss -1356.43400  validloss -1215.58671±0.00000  bestvalidloss -1313.90755  last_update 3\n",
      "train: iter 608  trainloss -1403.86533  validloss -930.10527±0.00000  bestvalidloss -1313.90755  last_update 4\n",
      "train: iter 609  trainloss -1479.86583  validloss -1142.51450±0.00000  bestvalidloss -1313.90755  last_update 5\n",
      "train: iter 610  trainloss -1406.94447  validloss -1311.02151±0.00000  bestvalidloss -1313.90755  last_update 6\n",
      "train: iter 611  trainloss -1397.75131  validloss -1172.93620±0.00000  bestvalidloss -1313.90755  last_update 7\n",
      "train: iter 612  trainloss -1388.03383  validloss -1041.01888±0.00000  bestvalidloss -1313.90755  last_update 8\n",
      "train: iter 613  trainloss -1403.24548  validloss -1166.08333±0.00000  bestvalidloss -1313.90755  last_update 9\n",
      "train: iter 614  trainloss -1368.26149  validloss -1293.87846±0.00000  bestvalidloss -1313.90755  last_update 10\n",
      "train: iter 615  trainloss -1427.67003  validloss -1102.40109±0.00000  bestvalidloss -1313.90755  last_update 11\n",
      "train: iter 616  trainloss -1382.98275  validloss -1203.46377±0.00000  bestvalidloss -1313.90755  last_update 12\n",
      "train: iter 617  trainloss -1351.23727  validloss -874.90768±0.00000  bestvalidloss -1313.90755  last_update 13\n",
      "train: iter 618  trainloss -1406.76302  validloss -1202.57252±0.00000  bestvalidloss -1313.90755  last_update 14\n",
      "train: iter 619  trainloss -1466.71264  validloss -1227.46690±0.00000  bestvalidloss -1313.90755  last_update 15\n",
      "train: iter 620  trainloss -1443.32749  validloss -1312.23133±0.00000  bestvalidloss -1313.90755  last_update 16\n",
      "train: iter 621  trainloss -1098.35440  validloss -1237.56212±0.00000  bestvalidloss -1313.90755  last_update 17\n",
      "train: iter 622  trainloss -1266.96117  validloss -794.47714±0.00000  bestvalidloss -1313.90755  last_update 18\n",
      "train: iter 623  trainloss -1380.21903  validloss -1110.01206±0.00000  bestvalidloss -1313.90755  last_update 19\n",
      "train: iter 624  trainloss -1343.96303  validloss -1111.23648±0.00000  bestvalidloss -1313.90755  last_update 20\n",
      "train: iter 625  trainloss -1439.46717  validloss -1136.11089±0.00000  bestvalidloss -1313.90755  last_update 21\n",
      "train: iter 626  trainloss -1471.75640  validloss -1225.05558±0.00000  bestvalidloss -1313.90755  last_update 22\n",
      "train: iter 627  trainloss -1475.60396  validloss -1276.66216±0.00000  bestvalidloss -1313.90755  last_update 23\n",
      "train: iter 628  trainloss -1493.36583  validloss -1294.83260±0.00000  bestvalidloss -1313.90755  last_update 24\n",
      "train: iter 629  trainloss -1327.05765  validloss -1297.64084±0.00000  bestvalidloss -1313.90755  last_update 25\n",
      "train: iter 630  trainloss -1200.21257  validloss -805.70327±0.00000  bestvalidloss -1313.90755  last_update 26\n",
      "train: iter 631  trainloss -1415.16703  validloss -1068.75059±0.00000  bestvalidloss -1313.90755  last_update 27\n",
      "train: iter 632  trainloss -1448.09665  validloss -1231.03156±0.00000  bestvalidloss -1313.90755  last_update 28\n",
      "train: iter 633  trainloss -1470.37303  validloss -1279.89341±0.00000  bestvalidloss -1313.90755  last_update 29\n",
      "train: iter 634  trainloss -1383.17665  validloss -1203.12769±0.00000  bestvalidloss -1313.90755  last_update 30\n",
      "train: iter 635  trainloss -1432.67997  validloss -1245.37289±0.00000  bestvalidloss -1313.90755  last_update 31\n",
      "train: iter 636  trainloss -1425.76904  validloss -1200.05551±0.00000  bestvalidloss -1313.90755  last_update 32\n",
      "train: iter 637  trainloss -1318.21016  validloss -1266.86133±0.00000  bestvalidloss -1313.90755  last_update 33\n",
      "train: iter 638  trainloss -1475.97818  validloss -1275.78630±0.00000  bestvalidloss -1313.90755  last_update 34\n",
      "train: iter 639  trainloss -1466.44380  validloss -1312.38512±0.00000  bestvalidloss -1313.90755  last_update 35\n",
      "train: iter 640  trainloss -1392.43256  validloss -1255.50452±0.00000  bestvalidloss -1313.90755  last_update 36\n",
      "train: iter 641  trainloss -1446.53289  validloss -1249.44697±0.00000  bestvalidloss -1313.90755  last_update 37\n",
      "train: iter 642  trainloss -1396.98506  validloss -1053.66736±0.00000  bestvalidloss -1313.90755  last_update 38\n",
      "train: iter 643  trainloss -1364.21177  validloss -1168.16131±0.00000  bestvalidloss -1313.90755  last_update 39\n",
      "train: iter 644  trainloss -1334.04094  validloss -894.94287±0.00000  bestvalidloss -1313.90755  last_update 40\n",
      "train: iter 645  trainloss -1374.05225  validloss -1244.93199±0.00000  bestvalidloss -1313.90755  last_update 41\n",
      "train: iter 646  trainloss -1449.15066  validloss -1115.35855±0.00000  bestvalidloss -1313.90755  last_update 42\n",
      "train: iter 647  trainloss -1475.11354  validloss -1318.10610±0.00000  bestvalidloss -1318.10610  last_update 0\n",
      "train: iter 648  trainloss -1455.50693  validloss -1224.16402±0.00000  bestvalidloss -1318.10610  last_update 1\n",
      "train: iter 649  trainloss -1379.13540  validloss -1263.68793±0.00000  bestvalidloss -1318.10610  last_update 2\n",
      "train: iter 650  trainloss -1473.87738  validloss -1228.85549±0.00000  bestvalidloss -1318.10610  last_update 3\n",
      "train: iter 651  trainloss -1484.11290  validloss -1295.94080±0.00000  bestvalidloss -1318.10610  last_update 4\n",
      "train: iter 652  trainloss -1379.90796  validloss -1173.96393±0.00000  bestvalidloss -1318.10610  last_update 5\n",
      "train: iter 653  trainloss -1407.20882  validloss -1114.99349±0.00000  bestvalidloss -1318.10610  last_update 6\n",
      "train: iter 654  trainloss -1458.56706  validloss -1184.86746±0.00000  bestvalidloss -1318.10610  last_update 7\n",
      "train: iter 655  trainloss -1366.78282  validloss -1243.32099±0.00000  bestvalidloss -1318.10610  last_update 8\n",
      "train: iter 656  trainloss -1319.44125  validloss -979.28912±0.00000  bestvalidloss -1318.10610  last_update 9\n",
      "train: iter 657  trainloss -1432.66073  validloss -1194.69240±0.00000  bestvalidloss -1318.10610  last_update 10\n",
      "train: iter 658  trainloss -1410.70909  validloss -1252.09402±0.00000  bestvalidloss -1318.10610  last_update 11\n",
      "train: iter 659  trainloss -1431.68410  validloss -1278.96969±0.00000  bestvalidloss -1318.10610  last_update 12\n",
      "train: iter 660  trainloss -1421.72705  validloss -1099.38657±0.00000  bestvalidloss -1318.10610  last_update 13\n",
      "train: iter 661  trainloss -1454.86174  validloss -1276.23713±0.00000  bestvalidloss -1318.10610  last_update 14\n",
      "train: iter 662  trainloss -1360.12371  validloss -1262.16862±0.00000  bestvalidloss -1318.10610  last_update 15\n",
      "train: iter 663  trainloss -1436.09633  validloss -1049.37188±0.00000  bestvalidloss -1318.10610  last_update 16\n",
      "train: iter 664  trainloss -1479.60516  validloss -1295.31744±0.00000  bestvalidloss -1318.10610  last_update 17\n",
      "train: iter 665  trainloss -1340.52198  validloss -1312.90415±0.00000  bestvalidloss -1318.10610  last_update 18\n",
      "train: iter 666  trainloss -1293.64209  validloss -1126.54993±0.00000  bestvalidloss -1318.10610  last_update 19\n",
      "train: iter 667  trainloss -1470.31569  validloss -1236.75053±0.00000  bestvalidloss -1318.10610  last_update 20\n",
      "train: iter 668  trainloss -1389.96638  validloss -1305.91489±0.00000  bestvalidloss -1318.10610  last_update 21\n",
      "train: iter 669  trainloss -1424.88572  validloss -1198.32112±0.00000  bestvalidloss -1318.10610  last_update 22\n",
      "train: iter 670  trainloss -1345.67320  validloss -859.37130±0.00000  bestvalidloss -1318.10610  last_update 23\n",
      "train: iter 671  trainloss -1474.00766  validloss -1246.85619±0.00000  bestvalidloss -1318.10610  last_update 24\n",
      "train: iter 672  trainloss -1459.23381  validloss -1302.56543±0.00000  bestvalidloss -1318.10610  last_update 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 673  trainloss -1492.20320  validloss -1303.74549±0.00000  bestvalidloss -1318.10610  last_update 26\n",
      "train: iter 674  trainloss -1329.33592  validloss -1296.45917±0.00000  bestvalidloss -1318.10610  last_update 27\n",
      "train: iter 675  trainloss -1332.24605  validloss -663.54229±0.00000  bestvalidloss -1318.10610  last_update 28\n",
      "train: iter 676  trainloss -1472.66255  validloss -1277.49496±0.00000  bestvalidloss -1318.10610  last_update 29\n",
      "train: iter 677  trainloss -1441.15360  validloss -1298.27605±0.00000  bestvalidloss -1318.10610  last_update 30\n",
      "train: iter 678  trainloss -1458.31376  validloss -1185.43745±0.00000  bestvalidloss -1318.10610  last_update 31\n",
      "train: iter 679  trainloss -1449.40254  validloss -1269.10730±0.00000  bestvalidloss -1318.10610  last_update 32\n",
      "train: iter 680  trainloss -1441.31083  validloss -1266.85479±0.00000  bestvalidloss -1318.10610  last_update 33\n",
      "train: iter 681  trainloss -1458.35187  validloss -1202.09976±0.00000  bestvalidloss -1318.10610  last_update 34\n",
      "train: iter 682  trainloss -1256.95417  validloss -1124.31825±0.00000  bestvalidloss -1318.10610  last_update 35\n",
      "train: iter 683  trainloss -895.00750  validloss -1009.96255±0.00000  bestvalidloss -1318.10610  last_update 36\n",
      "train: iter 684  trainloss -1249.09376  validloss -715.82728±0.00000  bestvalidloss -1318.10610  last_update 37\n",
      "train: iter 685  trainloss -1384.43159  validloss -1072.80529±0.00000  bestvalidloss -1318.10610  last_update 38\n",
      "train: iter 686  trainloss -1379.11328  validloss -1163.62410±0.00000  bestvalidloss -1318.10610  last_update 39\n",
      "train: iter 687  trainloss -1435.59850  validloss -1153.93957±0.00000  bestvalidloss -1318.10610  last_update 40\n",
      "train: iter 688  trainloss -1250.27681  validloss -1130.39726±0.00000  bestvalidloss -1318.10610  last_update 41\n",
      "train: iter 689  trainloss -1461.33077  validloss -1181.43044±0.00000  bestvalidloss -1318.10610  last_update 42\n",
      "train: iter 690  trainloss -1441.77972  validloss -1273.95322±0.00000  bestvalidloss -1318.10610  last_update 43\n",
      "train: iter 691  trainloss -1396.55179  validloss -965.10145±0.00000  bestvalidloss -1318.10610  last_update 44\n",
      "train: iter 692  trainloss -1359.67293  validloss -1242.33199±0.00000  bestvalidloss -1318.10610  last_update 45\n",
      "train: iter 693  trainloss -1418.40052  validloss -964.23459±0.00000  bestvalidloss -1318.10610  last_update 46\n",
      "train: iter 694  trainloss -1501.17978  validloss -1288.88766±0.00000  bestvalidloss -1318.10610  last_update 47\n",
      "train: iter 695  trainloss -1084.29472  validloss -1314.82955±0.00000  bestvalidloss -1318.10610  last_update 48\n",
      "train: iter 696  trainloss -1238.75887  validloss -617.46324±0.00000  bestvalidloss -1318.10610  last_update 49\n",
      "train: iter 697  trainloss -1415.38502  validloss -1127.10799±0.00000  bestvalidloss -1318.10610  last_update 50\n",
      "train: iter 698  trainloss -1474.41778  validloss -1233.70705±0.00000  bestvalidloss -1318.10610  last_update 51\n",
      "train: iter 699  trainloss -1458.36079  validloss -1274.05827±0.00000  bestvalidloss -1318.10610  last_update 52\n",
      "train: iter 700  trainloss -1464.77472  validloss -1230.80715±0.00000  bestvalidloss -1318.10610  last_update 53\n",
      "train: iter 701  trainloss -1499.05840  validloss -1253.49640±0.00000  bestvalidloss -1318.10610  last_update 54\n",
      "train: iter 702  trainloss -1498.07775  validloss -1275.02515±0.00000  bestvalidloss -1318.10610  last_update 55\n",
      "train: iter 703  trainloss -1462.66910  validloss -1281.74291±0.00000  bestvalidloss -1318.10610  last_update 56\n",
      "train: iter 704  trainloss -1398.58711  validloss -1156.36216±0.00000  bestvalidloss -1318.10610  last_update 57\n",
      "train: iter 705  trainloss -1455.59017  validloss -972.26405±0.00000  bestvalidloss -1318.10610  last_update 58\n",
      "train: iter 706  trainloss -1482.15961  validloss -1205.70202±0.00000  bestvalidloss -1318.10610  last_update 59\n",
      "train: iter 707  trainloss -1441.34955  validloss -1312.29931±0.00000  bestvalidloss -1318.10610  last_update 60\n",
      "train: iter 708  trainloss -1460.41739  validloss -1114.63234±0.00000  bestvalidloss -1318.10610  last_update 61\n",
      "train: iter 709  trainloss -1388.71812  validloss -1221.08640±0.00000  bestvalidloss -1318.10610  last_update 62\n",
      "train: iter 710  trainloss -1486.87112  validloss -1266.60707±0.00000  bestvalidloss -1318.10610  last_update 63\n",
      "train: iter 711  trainloss -1438.85737  validloss -1234.24599±0.00000  bestvalidloss -1318.10610  last_update 64\n",
      "train: iter 712  trainloss -1492.28932  validloss -1291.43343±0.00000  bestvalidloss -1318.10610  last_update 65\n",
      "train: iter 713  trainloss -1466.82640  validloss -1124.26489±0.00000  bestvalidloss -1318.10610  last_update 66\n",
      "train: iter 714  trainloss -1256.43746  validloss -1103.21924±0.00000  bestvalidloss -1318.10610  last_update 67\n",
      "train: iter 715  trainloss -1458.40063  validloss -1177.06098±0.00000  bestvalidloss -1318.10610  last_update 68\n",
      "train: iter 716  trainloss -1465.40970  validloss -1211.78357±0.00000  bestvalidloss -1318.10610  last_update 69\n",
      "train: iter 717  trainloss -1493.30035  validloss -1221.86028±0.00000  bestvalidloss -1318.10610  last_update 70\n",
      "train: iter 718  trainloss -1473.96744  validloss -1327.98857±0.00000  bestvalidloss -1327.98857  last_update 0\n",
      "train: iter 719  trainloss -1398.69742  validloss -1222.59710±0.00000  bestvalidloss -1327.98857  last_update 1\n",
      "train: iter 720  trainloss -1450.68263  validloss -1114.82558±0.00000  bestvalidloss -1327.98857  last_update 2\n",
      "train: iter 721  trainloss -1489.93795  validloss -1265.73827±0.00000  bestvalidloss -1327.98857  last_update 3\n",
      "train: iter 722  trainloss -1307.62827  validloss -1168.29381±0.00000  bestvalidloss -1327.98857  last_update 4\n",
      "train: iter 723  trainloss -1293.74829  validloss -575.45895±0.00000  bestvalidloss -1327.98857  last_update 5\n",
      "train: iter 724  trainloss -1464.85119  validloss -1241.07468±0.00000  bestvalidloss -1327.98857  last_update 6\n",
      "train: iter 725  trainloss -1477.10112  validloss -1251.81216±0.00000  bestvalidloss -1327.98857  last_update 7\n",
      "train: iter 726  trainloss -1487.75342  validloss -1272.52548±0.00000  bestvalidloss -1327.98857  last_update 8\n",
      "train: iter 727  trainloss -1468.36203  validloss -1144.96735±0.00000  bestvalidloss -1327.98857  last_update 9\n",
      "train: iter 728  trainloss -1464.03403  validloss -1225.26089±0.00000  bestvalidloss -1327.98857  last_update 10\n",
      "train: iter 729  trainloss -1471.43186  validloss -1066.67626±0.00000  bestvalidloss -1327.98857  last_update 11\n",
      "train: iter 730  trainloss -1448.76168  validloss -1306.10362±0.00000  bestvalidloss -1327.98857  last_update 12\n",
      "train: iter 731  trainloss -1362.11227  validloss -1103.00512±0.00000  bestvalidloss -1327.98857  last_update 13\n",
      "train: iter 732  trainloss -1445.81126  validloss -1193.60036±0.00000  bestvalidloss -1327.98857  last_update 14\n",
      "train: iter 733  trainloss -1474.62819  validloss -1328.20869±0.00000  bestvalidloss -1328.20869  last_update 0\n",
      "train: iter 734  trainloss -1479.75673  validloss -1332.58024±0.00000  bestvalidloss -1332.58024  last_update 0\n",
      "train: iter 735  trainloss -675.91003  validloss -1299.20225±0.00000  bestvalidloss -1332.58024  last_update 1\n",
      "train: iter 736  trainloss -319.36414  validloss -279.95886±0.00000  bestvalidloss -1332.58024  last_update 2\n",
      "train: iter 737  trainloss -885.38689  validloss -426.24501±0.00000  bestvalidloss -1332.58024  last_update 3\n",
      "train: iter 738  trainloss -1155.72307  validloss -631.48223±0.00000  bestvalidloss -1332.58024  last_update 4\n",
      "train: iter 739  trainloss -1271.78299  validloss -835.23149±0.00000  bestvalidloss -1332.58024  last_update 5\n",
      "train: iter 740  trainloss -1357.57333  validloss -995.22035±0.00000  bestvalidloss -1332.58024  last_update 6\n",
      "train: iter 741  trainloss -1239.10421  validloss -1000.15375±0.00000  bestvalidloss -1332.58024  last_update 7\n",
      "train: iter 742  trainloss -1379.16549  validloss -964.62340±0.00000  bestvalidloss -1332.58024  last_update 8\n",
      "train: iter 743  trainloss -1421.75508  validloss -1080.53361±0.00000  bestvalidloss -1332.58024  last_update 9\n",
      "train: iter 744  trainloss -1433.34686  validloss -1211.77416±0.00000  bestvalidloss -1332.58024  last_update 10\n",
      "train: iter 745  trainloss -1444.63326  validloss -1175.02162±0.00000  bestvalidloss -1332.58024  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 746  trainloss -1418.44429  validloss -1191.77907±0.00000  bestvalidloss -1332.58024  last_update 12\n",
      "train: iter 747  trainloss -1461.50837  validloss -1213.32316±0.00000  bestvalidloss -1332.58024  last_update 13\n",
      "train: iter 748  trainloss -1451.27073  validloss -1229.84700±0.00000  bestvalidloss -1332.58024  last_update 14\n",
      "train: iter 749  trainloss -1381.27090  validloss -1133.40755±0.00000  bestvalidloss -1332.58024  last_update 15\n",
      "train: iter 750  trainloss -1481.35537  validloss -1206.96389±0.00000  bestvalidloss -1332.58024  last_update 16\n",
      "train: iter 751  trainloss -1461.53671  validloss -1249.98336±0.00000  bestvalidloss -1332.58024  last_update 17\n",
      "train: iter 752  trainloss -1443.89014  validloss -1013.30350±0.00000  bestvalidloss -1332.58024  last_update 18\n",
      "train: iter 753  trainloss -1425.36400  validloss -1278.83440±0.00000  bestvalidloss -1332.58024  last_update 19\n",
      "train: iter 754  trainloss -1419.23519  validloss -1124.41343±0.00000  bestvalidloss -1332.58024  last_update 20\n",
      "train: iter 755  trainloss -1309.19982  validloss -1161.56501±0.00000  bestvalidloss -1332.58024  last_update 21\n",
      "train: iter 756  trainloss -1465.54865  validloss -1141.70628±0.00000  bestvalidloss -1332.58024  last_update 22\n",
      "train: iter 757  trainloss -1499.25535  validloss -1271.54759±0.00000  bestvalidloss -1332.58024  last_update 23\n",
      "train: iter 758  trainloss -1487.79433  validloss -1316.76040±0.00000  bestvalidloss -1332.58024  last_update 24\n",
      "train: iter 759  trainloss -1507.88814  validloss -1302.16023±0.00000  bestvalidloss -1332.58024  last_update 25\n",
      "train: iter 760  trainloss -1439.28906  validloss -1240.43422±0.00000  bestvalidloss -1332.58024  last_update 26\n",
      "train: iter 761  trainloss -1292.08678  validloss -1255.22346±0.00000  bestvalidloss -1332.58024  last_update 27\n",
      "train: iter 762  trainloss -1439.17943  validloss -1025.21569±0.00000  bestvalidloss -1332.58024  last_update 28\n",
      "train: iter 763  trainloss -1449.77765  validloss -1264.14445±0.00000  bestvalidloss -1332.58024  last_update 29\n",
      "train: iter 764  trainloss -1412.70792  validloss -1201.23049±0.00000  bestvalidloss -1332.58024  last_update 30\n",
      "train: iter 765  trainloss -1476.45100  validloss -987.60108±0.00000  bestvalidloss -1332.58024  last_update 31\n",
      "train: iter 766  trainloss -1508.14213  validloss -1317.06630±0.00000  bestvalidloss -1332.58024  last_update 32\n",
      "train: iter 767  trainloss -1450.21960  validloss -1320.74277±0.00000  bestvalidloss -1332.58024  last_update 33\n",
      "train: iter 768  trainloss -1494.17788  validloss -1240.58579±0.00000  bestvalidloss -1332.58024  last_update 34\n",
      "train: iter 769  trainloss -1488.91977  validloss -1310.89274±0.00000  bestvalidloss -1332.58024  last_update 35\n",
      "train: iter 770  trainloss -1505.68482  validloss -1281.26095±0.00000  bestvalidloss -1332.58024  last_update 36\n",
      "train: iter 771  trainloss -1469.21110  validloss -1164.47874±0.00000  bestvalidloss -1332.58024  last_update 37\n",
      "train: iter 772  trainloss -1410.54217  validloss -1167.69174±0.00000  bestvalidloss -1332.58024  last_update 38\n",
      "train: iter 773  trainloss -1446.90683  validloss -1296.95568±0.00000  bestvalidloss -1332.58024  last_update 39\n",
      "train: iter 774  trainloss -1357.04779  validloss -931.53917±0.00000  bestvalidloss -1332.58024  last_update 40\n",
      "train: iter 775  trainloss -1476.20461  validloss -1171.07937±0.00000  bestvalidloss -1332.58024  last_update 41\n",
      "train: iter 776  trainloss -1426.24008  validloss -1267.82207±0.00000  bestvalidloss -1332.58024  last_update 42\n",
      "train: iter 777  trainloss -1381.45764  validloss -1205.44121±0.00000  bestvalidloss -1332.58024  last_update 43\n",
      "train: iter 778  trainloss -1455.15239  validloss -1125.21159±0.00000  bestvalidloss -1332.58024  last_update 44\n",
      "train: iter 779  trainloss -1372.85891  validloss -1298.56756±0.00000  bestvalidloss -1332.58024  last_update 45\n",
      "train: iter 780  trainloss -1418.12887  validloss -1157.86574±0.00000  bestvalidloss -1332.58024  last_update 46\n",
      "train: iter 781  trainloss -1490.59103  validloss -1289.01143±0.00000  bestvalidloss -1332.58024  last_update 47\n",
      "train: iter 782  trainloss -1471.57389  validloss -1314.55661±0.00000  bestvalidloss -1332.58024  last_update 48\n",
      "train: iter 783  trainloss -1504.38751  validloss -1278.65102±0.00000  bestvalidloss -1332.58024  last_update 49\n",
      "train: iter 784  trainloss -1449.49151  validloss -1341.83374±0.00000  bestvalidloss -1341.83374  last_update 0\n",
      "train: iter 785  trainloss -1466.51648  validloss -1249.04785±0.00000  bestvalidloss -1341.83374  last_update 1\n",
      "train: iter 786  trainloss -1496.85577  validloss -1304.92617±0.00000  bestvalidloss -1341.83374  last_update 2\n",
      "train: iter 787  trainloss -1483.53040  validloss -1237.76009±0.00000  bestvalidloss -1341.83374  last_update 3\n",
      "train: iter 788  trainloss -1435.07403  validloss -1272.63015±0.00000  bestvalidloss -1341.83374  last_update 4\n",
      "train: iter 789  trainloss -1471.83209  validloss -1277.92328±0.00000  bestvalidloss -1341.83374  last_update 5\n",
      "train: iter 790  trainloss -1289.93089  validloss -1275.64169±0.00000  bestvalidloss -1341.83374  last_update 6\n",
      "train: iter 791  trainloss -1401.80464  validloss -748.20713±0.00000  bestvalidloss -1341.83374  last_update 7\n",
      "train: iter 792  trainloss -1447.33428  validloss -1197.63419±0.00000  bestvalidloss -1341.83374  last_update 8\n",
      "train: iter 793  trainloss -1457.23059  validloss -1216.30436±0.00000  bestvalidloss -1341.83374  last_update 9\n",
      "train: iter 794  trainloss -1481.70861  validloss -1269.90611±0.00000  bestvalidloss -1341.83374  last_update 10\n",
      "train: iter 795  trainloss -1375.54076  validloss -827.58196±0.00000  bestvalidloss -1341.83374  last_update 11\n",
      "train: iter 796  trainloss -1316.41881  validloss -1232.20148±0.00000  bestvalidloss -1341.83374  last_update 12\n",
      "train: iter 797  trainloss -1437.50255  validloss -995.18725±0.00000  bestvalidloss -1341.83374  last_update 13\n",
      "train: iter 798  trainloss -1512.39251  validloss -1283.18525±0.00000  bestvalidloss -1341.83374  last_update 14\n",
      "train: iter 799  trainloss -1465.26300  validloss -1305.00623±0.00000  bestvalidloss -1341.83374  last_update 15\n",
      "train: iter 800  trainloss -1362.65133  validloss -1115.96630±0.00000  bestvalidloss -1341.83374  last_update 16\n",
      "train: iter 801  trainloss -1475.87762  validloss -1208.96662±0.00000  bestvalidloss -1341.83374  last_update 17\n",
      "train: iter 802  trainloss -1469.26382  validloss -1286.76124±0.00000  bestvalidloss -1341.83374  last_update 18\n",
      "train: iter 803  trainloss -1505.32076  validloss -1293.19033±0.00000  bestvalidloss -1341.83374  last_update 19\n",
      "train: iter 804  trainloss -1508.54003  validloss -1338.89930±0.00000  bestvalidloss -1341.83374  last_update 20\n",
      "train: iter 805  trainloss -1424.31815  validloss -1059.91710±0.00000  bestvalidloss -1341.83374  last_update 21\n",
      "train: iter 806  trainloss -1364.09768  validloss -1236.17059±0.00000  bestvalidloss -1341.83374  last_update 22\n",
      "train: iter 807  trainloss -1429.77028  validloss -1008.90319±0.00000  bestvalidloss -1341.83374  last_update 23\n",
      "train: iter 808  trainloss -1520.65740  validloss -1328.41527±0.00000  bestvalidloss -1341.83374  last_update 24\n",
      "train: iter 809  trainloss -1296.94784  validloss -1299.26562±0.00000  bestvalidloss -1341.83374  last_update 25\n",
      "train: iter 810  trainloss -1410.53919  validloss -1158.37230±0.00000  bestvalidloss -1341.83374  last_update 26\n",
      "train: iter 811  trainloss -1492.55502  validloss -1242.51299±0.00000  bestvalidloss -1341.83374  last_update 27\n",
      "train: iter 812  trainloss -1416.04448  validloss -1318.06798±0.00000  bestvalidloss -1341.83374  last_update 28\n",
      "train: iter 813  trainloss -1508.31093  validloss -1232.91406±0.00000  bestvalidloss -1341.83374  last_update 29\n",
      "train: iter 814  trainloss -1424.21123  validloss -1319.73220±0.00000  bestvalidloss -1341.83374  last_update 30\n",
      "train: iter 815  trainloss -1441.22266  validloss -1057.81300±0.00000  bestvalidloss -1341.83374  last_update 31\n",
      "train: iter 816  trainloss -1482.30397  validloss -1290.22148±0.00000  bestvalidloss -1341.83374  last_update 32\n",
      "train: iter 817  trainloss -1091.02888  validloss -1150.42053±0.00000  bestvalidloss -1341.83374  last_update 33\n",
      "train: iter 818  trainloss -1366.99099  validloss -723.84764±0.00000  bestvalidloss -1341.83374  last_update 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 819  trainloss -1472.76418  validloss -1188.25216±0.00000  bestvalidloss -1341.83374  last_update 35\n",
      "train: iter 820  trainloss -1458.23579  validloss -1240.60381±0.00000  bestvalidloss -1341.83374  last_update 36\n",
      "train: iter 821  trainloss -1458.00475  validloss -1223.99529±0.00000  bestvalidloss -1341.83374  last_update 37\n",
      "train: iter 822  trainloss -1491.15393  validloss -1261.73312±0.00000  bestvalidloss -1341.83374  last_update 38\n",
      "train: iter 823  trainloss -1513.31836  validloss -1301.65218±0.00000  bestvalidloss -1341.83374  last_update 39\n",
      "train: iter 824  trainloss -1517.89646  validloss -1299.70525±0.00000  bestvalidloss -1341.83374  last_update 40\n",
      "train: iter 825  trainloss -1501.91099  validloss -1225.37470±0.00000  bestvalidloss -1341.83374  last_update 41\n",
      "train: iter 826  trainloss -1468.67308  validloss -1191.23439±0.00000  bestvalidloss -1341.83374  last_update 42\n",
      "train: iter 827  trainloss -1366.44800  validloss -970.40899±0.00000  bestvalidloss -1341.83374  last_update 43\n",
      "train: iter 828  trainloss -1463.85720  validloss -1224.35383±0.00000  bestvalidloss -1341.83374  last_update 44\n",
      "train: iter 829  trainloss -1468.31992  validloss -1222.27021±0.00000  bestvalidloss -1341.83374  last_update 45\n",
      "train: iter 830  trainloss -1520.50727  validloss -1352.03934±0.00000  bestvalidloss -1352.03934  last_update 0\n",
      "train: iter 831  trainloss -1490.19244  validloss -1367.58870±0.00000  bestvalidloss -1367.58870  last_update 0\n",
      "train: iter 832  trainloss -1108.23175  validloss -1153.49164±0.00000  bestvalidloss -1367.58870  last_update 1\n",
      "train: iter 833  trainloss -1014.19612  validloss 5.78129±0.00000  bestvalidloss -1367.58870  last_update 2\n",
      "train: iter 834  trainloss -1363.07865  validloss -966.36287±0.00000  bestvalidloss -1367.58870  last_update 3\n",
      "train: iter 835  trainloss -1419.97147  validloss -1028.68602±0.00000  bestvalidloss -1367.58870  last_update 4\n",
      "train: iter 836  trainloss -1323.56478  validloss -787.02878±0.00000  bestvalidloss -1367.58870  last_update 5\n",
      "train: iter 837  trainloss -1406.43884  validloss -1137.03882±0.00000  bestvalidloss -1367.58870  last_update 6\n",
      "train: iter 838  trainloss -1452.49258  validloss -487.66696±0.00000  bestvalidloss -1367.58870  last_update 7\n",
      "train: iter 839  trainloss -1454.98078  validloss -1251.21509±0.00000  bestvalidloss -1367.58870  last_update 8\n",
      "train: iter 840  trainloss -1453.36032  validloss -925.31382±0.00000  bestvalidloss -1367.58870  last_update 9\n",
      "train: iter 841  trainloss -1481.67319  validloss -1240.14292±0.00000  bestvalidloss -1367.58870  last_update 10\n",
      "train: iter 842  trainloss -1490.74681  validloss -1224.02964±0.00000  bestvalidloss -1367.58870  last_update 11\n",
      "train: iter 843  trainloss -1426.94920  validloss -1268.66310±0.00000  bestvalidloss -1367.58870  last_update 12\n",
      "train: iter 844  trainloss -1496.25248  validloss -1253.32420±0.00000  bestvalidloss -1367.58870  last_update 13\n",
      "train: iter 845  trainloss -1501.69391  validloss -1194.38866±0.00000  bestvalidloss -1367.58870  last_update 14\n",
      "train: iter 846  trainloss -1497.18923  validloss -1319.41348±0.00000  bestvalidloss -1367.58870  last_update 15\n",
      "train: iter 847  trainloss -1343.73045  validloss -1309.24405±0.00000  bestvalidloss -1367.58870  last_update 16\n",
      "train: iter 848  trainloss -1441.42001  validloss -1164.85018±0.00000  bestvalidloss -1367.58870  last_update 17\n",
      "train: iter 849  trainloss -1489.55266  validloss -1264.33231±0.00000  bestvalidloss -1367.58870  last_update 18\n",
      "train: iter 850  trainloss -1514.97517  validloss -1327.09187±0.00000  bestvalidloss -1367.58870  last_update 19\n",
      "train: iter 851  trainloss -1502.48091  validloss -1341.46539±0.00000  bestvalidloss -1367.58870  last_update 20\n",
      "train: iter 852  trainloss -1506.31703  validloss -1315.52201±0.00000  bestvalidloss -1367.58870  last_update 21\n",
      "train: iter 853  trainloss -1393.98988  validloss -1290.59883±0.00000  bestvalidloss -1367.58870  last_update 22\n",
      "train: iter 854  trainloss -1477.77951  validloss -1233.38848±0.00000  bestvalidloss -1367.58870  last_update 23\n",
      "train: iter 855  trainloss -1475.02286  validloss -1298.45332±0.00000  bestvalidloss -1367.58870  last_update 24\n",
      "train: iter 856  trainloss -1491.92708  validloss -1271.78162±0.00000  bestvalidloss -1367.58870  last_update 25\n",
      "train: iter 857  trainloss -1499.80690  validloss -1323.73026±0.00000  bestvalidloss -1367.58870  last_update 26\n",
      "train: iter 858  trainloss -1094.41393  validloss -1074.13187±0.00000  bestvalidloss -1367.58870  last_update 27\n",
      "train: iter 859  trainloss -1408.39445  validloss -1024.12013±0.00000  bestvalidloss -1367.58870  last_update 28\n",
      "train: iter 860  trainloss -1474.50015  validloss -1251.35998±0.00000  bestvalidloss -1367.58870  last_update 29\n",
      "train: iter 861  trainloss -1448.38943  validloss -1283.41057±0.00000  bestvalidloss -1367.58870  last_update 30\n",
      "train: iter 862  trainloss -1515.57152  validloss -1264.92797±0.00000  bestvalidloss -1367.58870  last_update 31\n",
      "train: iter 863  trainloss -1485.41314  validloss -1282.41423±0.00000  bestvalidloss -1367.58870  last_update 32\n",
      "train: iter 864  trainloss -1451.31189  validloss -1295.77168±0.00000  bestvalidloss -1367.58870  last_update 33\n",
      "train: iter 865  trainloss -1447.26673  validloss -1064.42670±0.00000  bestvalidloss -1367.58870  last_update 34\n",
      "train: iter 866  trainloss -1469.75042  validloss -1239.27602±0.00000  bestvalidloss -1367.58870  last_update 35\n",
      "train: iter 867  trainloss -1481.34768  validloss -1228.95966±0.00000  bestvalidloss -1367.58870  last_update 36\n",
      "train: iter 868  trainloss -1503.83731  validloss -1250.27352±0.00000  bestvalidloss -1367.58870  last_update 37\n",
      "train: iter 869  trainloss -1493.31899  validloss -1334.32717±0.00000  bestvalidloss -1367.58870  last_update 38\n",
      "train: iter 870  trainloss -1497.59574  validloss -1287.50341±0.00000  bestvalidloss -1367.58870  last_update 39\n",
      "train: iter 871  trainloss -1429.75577  validloss -810.52779±0.00000  bestvalidloss -1367.58870  last_update 40\n",
      "train: iter 872  trainloss -1444.60482  validloss -1178.32030±0.00000  bestvalidloss -1367.58870  last_update 41\n",
      "train: iter 873  trainloss -1448.52383  validloss -1314.91703±0.00000  bestvalidloss -1367.58870  last_update 42\n",
      "train: iter 874  trainloss -1491.97631  validloss -1321.77262±0.00000  bestvalidloss -1367.58870  last_update 43\n",
      "train: iter 875  trainloss -1511.23615  validloss -1189.38368±0.00000  bestvalidloss -1367.58870  last_update 44\n",
      "train: iter 876  trainloss -1474.39672  validloss -1178.67738±0.00000  bestvalidloss -1367.58870  last_update 45\n",
      "train: iter 877  trainloss -1498.66650  validloss -1258.87147±0.00000  bestvalidloss -1367.58870  last_update 46\n",
      "train: iter 878  trainloss -1338.81594  validloss -1069.94276±0.00000  bestvalidloss -1367.58870  last_update 47\n",
      "train: iter 879  trainloss -1425.56939  validloss -1112.77547±0.00000  bestvalidloss -1367.58870  last_update 48\n",
      "train: iter 880  trainloss -1443.92302  validloss -1276.18193±0.00000  bestvalidloss -1367.58870  last_update 49\n",
      "train: iter 881  trainloss -1519.82773  validloss -1270.27361±0.00000  bestvalidloss -1367.58870  last_update 50\n",
      "train: iter 882  trainloss -1476.07750  validloss -1018.45428±0.00000  bestvalidloss -1367.58870  last_update 51\n",
      "train: iter 883  trainloss -1025.30719  validloss -885.54889±0.00000  bestvalidloss -1367.58870  last_update 52\n",
      "train: iter 884  trainloss -1423.49389  validloss -1112.93222±0.00000  bestvalidloss -1367.58870  last_update 53\n",
      "train: iter 885  trainloss -1431.17747  validloss -1176.35587±0.00000  bestvalidloss -1367.58870  last_update 54\n",
      "train: iter 886  trainloss -1489.18894  validloss -1213.87889±0.00000  bestvalidloss -1367.58870  last_update 55\n",
      "train: iter 887  trainloss -1501.36125  validloss -1264.50177±0.00000  bestvalidloss -1367.58870  last_update 56\n",
      "train: iter 888  trainloss -1520.93645  validloss -1274.37958±0.00000  bestvalidloss -1367.58870  last_update 57\n",
      "train: iter 889  trainloss -1404.81265  validloss -996.40396±0.00000  bestvalidloss -1367.58870  last_update 58\n",
      "train: iter 890  trainloss -1518.07797  validloss -1229.93482±0.00000  bestvalidloss -1367.58870  last_update 59\n",
      "train: iter 891  trainloss -1539.20884  validloss -1314.60694±0.00000  bestvalidloss -1367.58870  last_update 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 892  trainloss -1506.65270  validloss -1233.57646±0.00000  bestvalidloss -1367.58870  last_update 61\n",
      "train: iter 893  trainloss -1441.97903  validloss -1298.31835±0.00000  bestvalidloss -1367.58870  last_update 62\n",
      "train: iter 894  trainloss -1351.33341  validloss -696.48233±0.00000  bestvalidloss -1367.58870  last_update 63\n",
      "train: iter 895  trainloss -1435.78602  validloss -1041.55340±0.00000  bestvalidloss -1367.58870  last_update 64\n",
      "train: iter 896  trainloss -1428.04594  validloss -1224.91777±0.00000  bestvalidloss -1367.58870  last_update 65\n",
      "train: iter 897  trainloss -1507.90372  validloss -1221.53383±0.00000  bestvalidloss -1367.58870  last_update 66\n",
      "train: iter 898  trainloss -1547.02229  validloss -1308.38764±0.00000  bestvalidloss -1367.58870  last_update 67\n",
      "train: iter 899  trainloss -1471.43526  validloss -1346.35700±0.00000  bestvalidloss -1367.58870  last_update 68\n",
      "train: iter 900  trainloss -1454.22697  validloss -1263.86442±0.00000  bestvalidloss -1367.58870  last_update 69\n",
      "train: iter 901  trainloss -1379.39489  validloss -1041.61859±0.00000  bestvalidloss -1367.58870  last_update 70\n",
      "train: iter 902  trainloss -1496.15496  validloss -1235.95413±0.00000  bestvalidloss -1367.58870  last_update 71\n",
      "train: iter 903  trainloss -1512.80014  validloss -1299.38483±0.00000  bestvalidloss -1367.58870  last_update 72\n",
      "train: iter 904  trainloss -1355.92594  validloss -1266.28568±0.00000  bestvalidloss -1367.58870  last_update 73\n",
      "train: iter 905  trainloss -1418.48965  validloss -1103.60467±0.00000  bestvalidloss -1367.58870  last_update 74\n",
      "train: iter 906  trainloss -1514.42891  validloss -1227.19841±0.00000  bestvalidloss -1367.58870  last_update 75\n",
      "train: iter 907  trainloss -1530.01349  validloss -1354.14971±0.00000  bestvalidloss -1367.58870  last_update 76\n",
      "train: iter 908  trainloss -1532.43435  validloss -1350.95859±0.00000  bestvalidloss -1367.58870  last_update 77\n",
      "train: iter 909  trainloss -1205.59001  validloss -1337.39621±0.00000  bestvalidloss -1367.58870  last_update 78\n",
      "train: iter 910  trainloss -1354.13756  validloss -186.32729±0.00000  bestvalidloss -1367.58870  last_update 79\n",
      "train: iter 911  trainloss -1474.82060  validloss -1174.04116±0.00000  bestvalidloss -1367.58870  last_update 80\n",
      "train: iter 912  trainloss -1507.22542  validloss -1188.54125±0.00000  bestvalidloss -1367.58870  last_update 81\n",
      "train: iter 913  trainloss -1520.56731  validloss -1299.56743±0.00000  bestvalidloss -1367.58870  last_update 82\n",
      "train: iter 914  trainloss -1456.32066  validloss -1078.62504±0.00000  bestvalidloss -1367.58870  last_update 83\n",
      "train: iter 915  trainloss -1503.29790  validloss -1330.46628±0.00000  bestvalidloss -1367.58870  last_update 84\n",
      "train: iter 916  trainloss -1513.64372  validloss -1315.24376±0.00000  bestvalidloss -1367.58870  last_update 85\n",
      "train: iter 917  trainloss -1528.91040  validloss -1242.54540±0.00000  bestvalidloss -1367.58870  last_update 86\n",
      "train: iter 918  trainloss -1232.56850  validloss -1361.70070±0.00000  bestvalidloss -1367.58870  last_update 87\n",
      "train: iter 919  trainloss -1424.31541  validloss -925.96304±0.00000  bestvalidloss -1367.58870  last_update 88\n",
      "train: iter 920  trainloss -1498.59113  validloss -1238.89823±0.00000  bestvalidloss -1367.58870  last_update 89\n",
      "train: iter 921  trainloss -1520.89378  validloss -1295.77746±0.00000  bestvalidloss -1367.58870  last_update 90\n",
      "train: iter 922  trainloss -1536.90725  validloss -1336.11234±0.00000  bestvalidloss -1367.58870  last_update 91\n",
      "train: iter 923  trainloss -1544.69385  validloss -1335.94033±0.00000  bestvalidloss -1367.58870  last_update 92\n",
      "train: iter 924  trainloss -1362.23067  validloss -1089.71807±0.00000  bestvalidloss -1367.58870  last_update 93\n",
      "train: iter 925  trainloss -1435.21333  validloss -1073.77112±0.00000  bestvalidloss -1367.58870  last_update 94\n",
      "train: iter 926  trainloss -1485.80993  validloss -1251.43429±0.00000  bestvalidloss -1367.58870  last_update 95\n",
      "train: iter 927  trainloss -1522.65896  validloss -1268.58655±0.00000  bestvalidloss -1367.58870  last_update 96\n",
      "train: iter 928  trainloss -1534.36378  validloss -1274.51912±0.00000  bestvalidloss -1367.58870  last_update 97\n",
      "train: iter 929  trainloss -1533.10132  validloss -1310.73088±0.00000  bestvalidloss -1367.58870  last_update 98\n",
      "train: iter 930  trainloss -983.53608  validloss -1338.49784±0.00000  bestvalidloss -1367.58870  last_update 99\n",
      "train: iter 931  trainloss -1307.64029  validloss -722.96858±0.00000  bestvalidloss -1367.58870  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-11.0670) penalty_target_max tensor(4.6784)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "plt.ylim([min(min(train_curve1),min(valid_curve1) ), \n",
    "          max(max(train_curve1[50:]),max(valid_curve1[50:])) ])\n",
    "# plt.xlim([50, len(train_curve1)])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.72984  validloss 4.80181±0.00000  bestvalidloss 4.80181  last_update 0\n",
      "train: iter 1  trainloss 4.37938  validloss 4.43105±0.00000  bestvalidloss 4.43105  last_update 0\n",
      "train: iter 2  trainloss 4.09008  validloss 4.12912±0.00000  bestvalidloss 4.12912  last_update 0\n",
      "train: iter 3  trainloss 3.85755  validloss 3.88959±0.00000  bestvalidloss 3.88959  last_update 0\n",
      "train: iter 4  trainloss 3.64648  validloss 3.67987±0.00000  bestvalidloss 3.67987  last_update 0\n",
      "train: iter 5  trainloss 3.45332  validloss 3.46278±0.00000  bestvalidloss 3.46278  last_update 0\n",
      "train: iter 6  trainloss 3.27802  validloss 3.29563±0.00000  bestvalidloss 3.29563  last_update 0\n",
      "train: iter 7  trainloss 3.11269  validloss 3.12368±0.00000  bestvalidloss 3.12368  last_update 0\n",
      "train: iter 8  trainloss 2.95540  validloss 2.95976±0.00000  bestvalidloss 2.95976  last_update 0\n",
      "train: iter 9  trainloss 2.80580  validloss 2.81743±0.00000  bestvalidloss 2.81743  last_update 0\n",
      "train: iter 10  trainloss 2.65669  validloss 2.67986±0.00000  bestvalidloss 2.67986  last_update 0\n",
      "train: iter 11  trainloss 2.52008  validloss 2.53568±0.00000  bestvalidloss 2.53568  last_update 0\n",
      "train: iter 12  trainloss 2.38851  validloss 2.40889±0.00000  bestvalidloss 2.40889  last_update 0\n",
      "train: iter 13  trainloss 2.26870  validloss 2.29008±0.00000  bestvalidloss 2.29008  last_update 0\n",
      "train: iter 14  trainloss 2.15143  validloss 2.16925±0.00000  bestvalidloss 2.16925  last_update 0\n",
      "train: iter 15  trainloss 2.04454  validloss 2.06951±0.00000  bestvalidloss 2.06951  last_update 0\n",
      "train: iter 16  trainloss 1.94911  validloss 1.96477±0.00000  bestvalidloss 1.96477  last_update 0\n",
      "train: iter 17  trainloss 1.85870  validloss 1.88459±0.00000  bestvalidloss 1.88459  last_update 0\n",
      "train: iter 18  trainloss 1.77316  validloss 1.79418±0.00000  bestvalidloss 1.79418  last_update 0\n",
      "train: iter 19  trainloss 1.68755  validloss 1.73127±0.00000  bestvalidloss 1.73127  last_update 0\n",
      "train: iter 20  trainloss 1.60478  validloss 1.65098±0.00000  bestvalidloss 1.65098  last_update 0\n",
      "train: iter 21  trainloss 1.52557  validloss 1.57248±0.00000  bestvalidloss 1.57248  last_update 0\n",
      "train: iter 22  trainloss 1.45238  validloss 1.48105±0.00000  bestvalidloss 1.48105  last_update 0\n",
      "train: iter 23  trainloss 1.37867  validloss 1.42632±0.00000  bestvalidloss 1.42632  last_update 0\n",
      "train: iter 24  trainloss 1.29027  validloss 1.34324±0.00000  bestvalidloss 1.34324  last_update 0\n",
      "train: iter 25  trainloss 1.21583  validloss 1.26533±0.00000  bestvalidloss 1.26533  last_update 0\n",
      "train: iter 26  trainloss 1.13779  validloss 1.19971±0.00000  bestvalidloss 1.19971  last_update 0\n",
      "train: iter 27  trainloss 1.06473  validloss 1.11672±0.00000  bestvalidloss 1.11672  last_update 0\n",
      "train: iter 28  trainloss 0.98381  validloss 1.04285±0.00000  bestvalidloss 1.04285  last_update 0\n",
      "train: iter 29  trainloss 0.89974  validloss 0.97290±0.00000  bestvalidloss 0.97290  last_update 0\n",
      "train: iter 30  trainloss 0.81804  validloss 0.86265±0.00000  bestvalidloss 0.86265  last_update 0\n",
      "train: iter 31  trainloss 0.73987  validloss 0.81393±0.00000  bestvalidloss 0.81393  last_update 0\n",
      "train: iter 32  trainloss 0.65790  validloss 0.73684±0.00000  bestvalidloss 0.73684  last_update 0\n",
      "train: iter 33  trainloss 0.58085  validloss 0.65505±0.00000  bestvalidloss 0.65505  last_update 0\n",
      "train: iter 34  trainloss 0.51634  validloss 0.59490±0.00000  bestvalidloss 0.59490  last_update 0\n",
      "train: iter 35  trainloss 0.43056  validloss 0.52172±0.00000  bestvalidloss 0.52172  last_update 0\n",
      "train: iter 36  trainloss 0.35377  validloss 0.46155±0.00000  bestvalidloss 0.46155  last_update 0\n",
      "train: iter 37  trainloss 0.29481  validloss 0.37351±0.00000  bestvalidloss 0.37351  last_update 0\n",
      "train: iter 38  trainloss 0.22194  validloss 0.33062±0.00000  bestvalidloss 0.33062  last_update 0\n",
      "train: iter 39  trainloss 0.16812  validloss 0.27371±0.00000  bestvalidloss 0.27371  last_update 0\n",
      "train: iter 40  trainloss 0.10986  validloss 0.21052±0.00000  bestvalidloss 0.21052  last_update 0\n",
      "train: iter 41  trainloss 0.06390  validloss 0.14923±0.00000  bestvalidloss 0.14923  last_update 0\n",
      "train: iter 42  trainloss 0.01925  validloss 0.11451±0.00000  bestvalidloss 0.11451  last_update 0\n",
      "train: iter 43  trainloss -0.04530  validloss 0.04754±0.00000  bestvalidloss 0.04754  last_update 0\n",
      "train: iter 44  trainloss -0.10250  validloss 0.08023±0.00000  bestvalidloss 0.04754  last_update 1\n",
      "train: iter 45  trainloss -0.12902  validloss -0.00495±0.00000  bestvalidloss -0.00495  last_update 0\n",
      "train: iter 46  trainloss -0.18976  validloss -0.07399±0.00000  bestvalidloss -0.07399  last_update 0\n",
      "train: iter 47  trainloss -0.22591  validloss -0.10768±0.00000  bestvalidloss -0.10768  last_update 0\n",
      "train: iter 48  trainloss -0.28573  validloss -0.18660±0.00000  bestvalidloss -0.18660  last_update 0\n",
      "train: iter 49  trainloss -0.31708  validloss -0.19755±0.00000  bestvalidloss -0.19755  last_update 0\n",
      "train: iter 50  trainloss -0.35323  validloss -0.22328±0.00000  bestvalidloss -0.22328  last_update 0\n",
      "train: iter 51  trainloss -0.38131  validloss -0.29387±0.00000  bestvalidloss -0.29387  last_update 0\n",
      "train: iter 52  trainloss -0.44952  validloss -0.28697±0.00000  bestvalidloss -0.29387  last_update 1\n",
      "train: iter 53  trainloss -0.48292  validloss -0.37161±0.00000  bestvalidloss -0.37161  last_update 0\n",
      "train: iter 54  trainloss -0.50540  validloss -0.34253±0.00000  bestvalidloss -0.37161  last_update 1\n",
      "train: iter 55  trainloss -0.53395  validloss -0.44439±0.00000  bestvalidloss -0.44439  last_update 0\n",
      "train: iter 56  trainloss -0.58036  validloss -0.43948±0.00000  bestvalidloss -0.44439  last_update 1\n",
      "train: iter 57  trainloss -0.61975  validloss -0.40686±0.00000  bestvalidloss -0.44439  last_update 2\n",
      "train: iter 58  trainloss -0.66372  validloss -0.43126±0.00000  bestvalidloss -0.44439  last_update 3\n",
      "train: iter 59  trainloss -0.68654  validloss -0.48811±0.00000  bestvalidloss -0.48811  last_update 0\n",
      "train: iter 60  trainloss -0.71283  validloss -0.58764±0.00000  bestvalidloss -0.58764  last_update 0\n",
      "train: iter 61  trainloss -0.73377  validloss -0.52299±0.00000  bestvalidloss -0.58764  last_update 1\n",
      "train: iter 62  trainloss -0.76998  validloss -0.61132±0.00000  bestvalidloss -0.61132  last_update 0\n",
      "train: iter 63  trainloss -0.82136  validloss -0.65358±0.00000  bestvalidloss -0.65358  last_update 0\n",
      "train: iter 64  trainloss -0.80734  validloss -0.65740±0.00000  bestvalidloss -0.65740  last_update 0\n",
      "train: iter 65  trainloss -0.85720  validloss -0.64891±0.00000  bestvalidloss -0.65740  last_update 1\n",
      "train: iter 66  trainloss -0.84481  validloss -0.75527±0.00000  bestvalidloss -0.75527  last_update 0\n",
      "train: iter 67  trainloss -0.87046  validloss -0.64936±0.00000  bestvalidloss -0.75527  last_update 1\n",
      "train: iter 68  trainloss -0.88418  validloss -0.67365±0.00000  bestvalidloss -0.75527  last_update 2\n",
      "train: iter 69  trainloss -0.91172  validloss -0.73705±0.00000  bestvalidloss -0.75527  last_update 3\n",
      "train: iter 70  trainloss -0.95121  validloss -0.84108±0.00000  bestvalidloss -0.84108  last_update 0\n",
      "train: iter 71  trainloss -0.95882  validloss -0.69413±0.00000  bestvalidloss -0.84108  last_update 1\n",
      "train: iter 72  trainloss -0.98551  validloss -0.74816±0.00000  bestvalidloss -0.84108  last_update 2\n",
      "train: iter 73  trainloss -0.97567  validloss -0.77483±0.00000  bestvalidloss -0.84108  last_update 3\n",
      "train: iter 74  trainloss -0.99797  validloss -0.82270±0.00000  bestvalidloss -0.84108  last_update 4\n",
      "train: iter 75  trainloss -1.01150  validloss -0.80166±0.00000  bestvalidloss -0.84108  last_update 5\n",
      "train: iter 76  trainloss -1.05613  validloss -0.88593±0.00000  bestvalidloss -0.88593  last_update 0\n",
      "train: iter 77  trainloss -1.05068  validloss -0.83207±0.00000  bestvalidloss -0.88593  last_update 1\n",
      "train: iter 78  trainloss -1.06687  validloss -0.78110±0.00000  bestvalidloss -0.88593  last_update 2\n",
      "train: iter 79  trainloss -1.05151  validloss -0.86954±0.00000  bestvalidloss -0.88593  last_update 3\n",
      "train: iter 80  trainloss -1.06683  validloss -0.96194±0.00000  bestvalidloss -0.96194  last_update 0\n",
      "train: iter 81  trainloss -1.04206  validloss -0.85303±0.00000  bestvalidloss -0.96194  last_update 1\n",
      "train: iter 82  trainloss -1.05426  validloss -0.82300±0.00000  bestvalidloss -0.96194  last_update 2\n",
      "train: iter 83  trainloss -1.06641  validloss -0.84621±0.00000  bestvalidloss -0.96194  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss -1.08702  validloss -0.86396±0.00000  bestvalidloss -0.96194  last_update 4\n",
      "train: iter 85  trainloss -1.09689  validloss -0.93144±0.00000  bestvalidloss -0.96194  last_update 5\n",
      "train: iter 86  trainloss -1.12695  validloss -0.86643±0.00000  bestvalidloss -0.96194  last_update 6\n",
      "train: iter 87  trainloss -1.09967  validloss -0.91521±0.00000  bestvalidloss -0.96194  last_update 7\n",
      "train: iter 88  trainloss -1.06496  validloss -0.70350±0.00000  bestvalidloss -0.96194  last_update 8\n",
      "train: iter 89  trainloss -1.10335  validloss -0.89811±0.00000  bestvalidloss -0.96194  last_update 9\n",
      "train: iter 90  trainloss -1.12460  validloss -0.81737±0.00000  bestvalidloss -0.96194  last_update 10\n",
      "train: iter 91  trainloss -1.12712  validloss -0.89919±0.00000  bestvalidloss -0.96194  last_update 11\n",
      "train: iter 92  trainloss -1.15041  validloss -0.92966±0.00000  bestvalidloss -0.96194  last_update 12\n",
      "train: iter 93  trainloss -1.11109  validloss -0.88014±0.00000  bestvalidloss -0.96194  last_update 13\n",
      "train: iter 94  trainloss -1.10743  validloss -0.80561±0.00000  bestvalidloss -0.96194  last_update 14\n",
      "train: iter 95  trainloss -1.09442  validloss -0.97563±0.00000  bestvalidloss -0.97563  last_update 0\n",
      "train: iter 96  trainloss -1.12800  validloss -0.92297±0.00000  bestvalidloss -0.97563  last_update 1\n",
      "train: iter 97  trainloss -1.11922  validloss -1.03098±0.00000  bestvalidloss -1.03098  last_update 0\n",
      "train: iter 98  trainloss -1.07956  validloss -0.92651±0.00000  bestvalidloss -1.03098  last_update 1\n",
      "train: iter 99  trainloss -1.05272  validloss -0.89725±0.00000  bestvalidloss -1.03098  last_update 2\n",
      "train: iter 100  trainloss -1.09574  validloss -0.84086±0.00000  bestvalidloss -1.03098  last_update 3\n",
      "train: iter 101  trainloss -1.14161  validloss -0.84899±0.00000  bestvalidloss -1.03098  last_update 4\n",
      "train: iter 102  trainloss -1.13716  validloss -0.99457±0.00000  bestvalidloss -1.03098  last_update 5\n",
      "train: iter 103  trainloss -1.12612  validloss -0.90353±0.00000  bestvalidloss -1.03098  last_update 6\n",
      "train: iter 104  trainloss -1.08954  validloss -0.83609±0.00000  bestvalidloss -1.03098  last_update 7\n",
      "train: iter 105  trainloss -1.09900  validloss -0.85777±0.00000  bestvalidloss -1.03098  last_update 8\n",
      "train: iter 106  trainloss -1.12208  validloss -0.88556±0.00000  bestvalidloss -1.03098  last_update 9\n",
      "train: iter 107  trainloss -1.08128  validloss -0.93312±0.00000  bestvalidloss -1.03098  last_update 10\n",
      "train: iter 108  trainloss -1.14251  validloss -0.93925±0.00000  bestvalidloss -1.03098  last_update 11\n",
      "train: iter 109  trainloss -1.10586  validloss -0.83621±0.00000  bestvalidloss -1.03098  last_update 12\n",
      "train: iter 110  trainloss -1.14164  validloss -0.91796±0.00000  bestvalidloss -1.03098  last_update 13\n",
      "train: iter 111  trainloss -1.13141  validloss -0.96385±0.00000  bestvalidloss -1.03098  last_update 14\n",
      "train: iter 112  trainloss -1.12498  validloss -0.87150±0.00000  bestvalidloss -1.03098  last_update 15\n",
      "train: iter 113  trainloss -1.16343  validloss -1.00471±0.00000  bestvalidloss -1.03098  last_update 16\n",
      "train: iter 114  trainloss -1.14681  validloss -0.78739±0.00000  bestvalidloss -1.03098  last_update 17\n",
      "train: iter 115  trainloss -1.13258  validloss -0.84387±0.00000  bestvalidloss -1.03098  last_update 18\n",
      "train: iter 116  trainloss -1.15635  validloss -0.84540±0.00000  bestvalidloss -1.03098  last_update 19\n",
      "train: iter 117  trainloss -1.09901  validloss -0.91271±0.00000  bestvalidloss -1.03098  last_update 20\n",
      "train: iter 118  trainloss -1.12348  validloss -0.83687±0.00000  bestvalidloss -1.03098  last_update 21\n",
      "train: iter 119  trainloss -1.11415  validloss -0.90360±0.00000  bestvalidloss -1.03098  last_update 22\n",
      "train: iter 120  trainloss -1.13086  validloss -0.90123±0.00000  bestvalidloss -1.03098  last_update 23\n",
      "train: iter 121  trainloss -1.12774  validloss -0.75231±0.00000  bestvalidloss -1.03098  last_update 24\n",
      "train: iter 122  trainloss -1.11385  validloss -0.92383±0.00000  bestvalidloss -1.03098  last_update 25\n",
      "train: iter 123  trainloss -1.14676  validloss -0.97162±0.00000  bestvalidloss -1.03098  last_update 26\n",
      "train: iter 124  trainloss -1.10656  validloss -0.82430±0.00000  bestvalidloss -1.03098  last_update 27\n",
      "train: iter 125  trainloss -1.15501  validloss -0.96785±0.00000  bestvalidloss -1.03098  last_update 28\n",
      "train: iter 126  trainloss -1.12157  validloss -0.85916±0.00000  bestvalidloss -1.03098  last_update 29\n",
      "train: iter 127  trainloss -1.14748  validloss -0.88200±0.00000  bestvalidloss -1.03098  last_update 30\n",
      "train: iter 128  trainloss -1.11264  validloss -0.96676±0.00000  bestvalidloss -1.03098  last_update 31\n",
      "train: iter 129  trainloss -1.14965  validloss -0.93454±0.00000  bestvalidloss -1.03098  last_update 32\n",
      "train: iter 130  trainloss -1.09095  validloss -0.96360±0.00000  bestvalidloss -1.03098  last_update 33\n",
      "train: iter 131  trainloss -1.16855  validloss -0.96662±0.00000  bestvalidloss -1.03098  last_update 34\n",
      "train: iter 132  trainloss -1.14237  validloss -0.95313±0.00000  bestvalidloss -1.03098  last_update 35\n",
      "train: iter 133  trainloss -1.12438  validloss -0.82881±0.00000  bestvalidloss -1.03098  last_update 36\n",
      "train: iter 134  trainloss -1.11902  validloss -0.88449±0.00000  bestvalidloss -1.03098  last_update 37\n",
      "train: iter 135  trainloss -1.16071  validloss -0.84051±0.00000  bestvalidloss -1.03098  last_update 38\n",
      "train: iter 136  trainloss -1.17868  validloss -0.94710±0.00000  bestvalidloss -1.03098  last_update 39\n",
      "train: iter 137  trainloss -1.15415  validloss -0.91085±0.00000  bestvalidloss -1.03098  last_update 40\n",
      "train: iter 138  trainloss -1.18157  validloss -0.81491±0.00000  bestvalidloss -1.03098  last_update 41\n",
      "train: iter 139  trainloss -1.12380  validloss -0.89141±0.00000  bestvalidloss -1.03098  last_update 42\n",
      "train: iter 140  trainloss -1.11973  validloss -0.93604±0.00000  bestvalidloss -1.03098  last_update 43\n",
      "train: iter 141  trainloss -1.14215  validloss -0.76753±0.00000  bestvalidloss -1.03098  last_update 44\n",
      "train: iter 142  trainloss -1.12717  validloss -0.90295±0.00000  bestvalidloss -1.03098  last_update 45\n",
      "train: iter 143  trainloss -1.10453  validloss -0.79938±0.00000  bestvalidloss -1.03098  last_update 46\n",
      "train: iter 144  trainloss -1.11685  validloss -0.92553±0.00000  bestvalidloss -1.03098  last_update 47\n",
      "train: iter 145  trainloss -1.14410  validloss -0.84910±0.00000  bestvalidloss -1.03098  last_update 48\n",
      "train: iter 146  trainloss -1.14552  validloss -0.77866±0.00000  bestvalidloss -1.03098  last_update 49\n",
      "train: iter 147  trainloss -1.11585  validloss -0.80705±0.00000  bestvalidloss -1.03098  last_update 50\n",
      "train: iter 148  trainloss -1.09312  validloss -0.93783±0.00000  bestvalidloss -1.03098  last_update 51\n",
      "train: iter 149  trainloss -1.14179  validloss -0.77663±0.00000  bestvalidloss -1.03098  last_update 52\n",
      "train: iter 150  trainloss -1.14967  validloss -0.96375±0.00000  bestvalidloss -1.03098  last_update 53\n",
      "train: iter 151  trainloss -1.12698  validloss -0.78230±0.00000  bestvalidloss -1.03098  last_update 54\n",
      "train: iter 152  trainloss -1.16369  validloss -0.79915±0.00000  bestvalidloss -1.03098  last_update 55\n",
      "train: iter 153  trainloss -1.14062  validloss -1.05741±0.00000  bestvalidloss -1.05741  last_update 0\n",
      "train: iter 154  trainloss -1.13510  validloss -0.99117±0.00000  bestvalidloss -1.05741  last_update 1\n",
      "train: iter 155  trainloss -1.09809  validloss -0.79923±0.00000  bestvalidloss -1.05741  last_update 2\n",
      "train: iter 156  trainloss -1.14128  validloss -0.86566±0.00000  bestvalidloss -1.05741  last_update 3\n",
      "train: iter 157  trainloss -1.10469  validloss -0.82294±0.00000  bestvalidloss -1.05741  last_update 4\n",
      "train: iter 158  trainloss -1.10522  validloss -0.84618±0.00000  bestvalidloss -1.05741  last_update 5\n",
      "train: iter 159  trainloss -1.17803  validloss -0.92779±0.00000  bestvalidloss -1.05741  last_update 6\n",
      "train: iter 160  trainloss -1.11659  validloss -0.82905±0.00000  bestvalidloss -1.05741  last_update 7\n",
      "train: iter 161  trainloss -1.18389  validloss -0.88804±0.00000  bestvalidloss -1.05741  last_update 8\n",
      "train: iter 162  trainloss -1.10109  validloss -0.66767±0.00000  bestvalidloss -1.05741  last_update 9\n",
      "train: iter 163  trainloss -1.11250  validloss -0.87925±0.00000  bestvalidloss -1.05741  last_update 10\n",
      "train: iter 164  trainloss -1.13537  validloss -1.01078±0.00000  bestvalidloss -1.05741  last_update 11\n",
      "train: iter 165  trainloss -1.10191  validloss -0.75248±0.00000  bestvalidloss -1.05741  last_update 12\n",
      "train: iter 166  trainloss -1.20957  validloss -0.80065±0.00000  bestvalidloss -1.05741  last_update 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 167  trainloss -1.16038  validloss -0.94792±0.00000  bestvalidloss -1.05741  last_update 14\n",
      "train: iter 168  trainloss -1.15294  validloss -0.80555±0.00000  bestvalidloss -1.05741  last_update 15\n",
      "train: iter 169  trainloss -1.10883  validloss -0.83868±0.00000  bestvalidloss -1.05741  last_update 16\n",
      "train: iter 170  trainloss -1.12982  validloss -0.80555±0.00000  bestvalidloss -1.05741  last_update 17\n",
      "train: iter 171  trainloss -1.17013  validloss -0.82711±0.00000  bestvalidloss -1.05741  last_update 18\n",
      "train: iter 172  trainloss -1.11429  validloss -0.81141±0.00000  bestvalidloss -1.05741  last_update 19\n",
      "train: iter 173  trainloss -1.12620  validloss -0.78896±0.00000  bestvalidloss -1.05741  last_update 20\n",
      "train: iter 174  trainloss -1.13568  validloss -0.95377±0.00000  bestvalidloss -1.05741  last_update 21\n",
      "train: iter 175  trainloss -1.13974  validloss -0.87206±0.00000  bestvalidloss -1.05741  last_update 22\n",
      "train: iter 176  trainloss -1.17521  validloss -0.73776±0.00000  bestvalidloss -1.05741  last_update 23\n",
      "train: iter 177  trainloss -1.16385  validloss -0.84699±0.00000  bestvalidloss -1.05741  last_update 24\n",
      "train: iter 178  trainloss -1.19646  validloss -0.88703±0.00000  bestvalidloss -1.05741  last_update 25\n",
      "train: iter 179  trainloss -1.13958  validloss -0.71169±0.00000  bestvalidloss -1.05741  last_update 26\n",
      "train: iter 180  trainloss -1.12784  validloss -0.82471±0.00000  bestvalidloss -1.05741  last_update 27\n",
      "train: iter 181  trainloss -1.11943  validloss -0.89009±0.00000  bestvalidloss -1.05741  last_update 28\n",
      "train: iter 182  trainloss -1.14021  validloss -0.83069±0.00000  bestvalidloss -1.05741  last_update 29\n",
      "train: iter 183  trainloss -1.16974  validloss -1.00630±0.00000  bestvalidloss -1.05741  last_update 30\n",
      "train: iter 184  trainloss -1.12746  validloss -0.88936±0.00000  bestvalidloss -1.05741  last_update 31\n",
      "train: iter 185  trainloss -1.12253  validloss -0.86358±0.00000  bestvalidloss -1.05741  last_update 32\n",
      "train: iter 186  trainloss -1.13603  validloss -0.76478±0.00000  bestvalidloss -1.05741  last_update 33\n",
      "train: iter 187  trainloss -1.13459  validloss -0.84592±0.00000  bestvalidloss -1.05741  last_update 34\n",
      "train: iter 188  trainloss -1.14963  validloss -0.88328±0.00000  bestvalidloss -1.05741  last_update 35\n",
      "train: iter 189  trainloss -1.14386  validloss -0.92258±0.00000  bestvalidloss -1.05741  last_update 36\n",
      "train: iter 190  trainloss -1.12390  validloss -0.88449±0.00000  bestvalidloss -1.05741  last_update 37\n",
      "train: iter 191  trainloss -1.15934  validloss -0.86926±0.00000  bestvalidloss -1.05741  last_update 38\n",
      "train: iter 192  trainloss -1.12217  validloss -0.86514±0.00000  bestvalidloss -1.05741  last_update 39\n",
      "train: iter 193  trainloss -1.15412  validloss -0.81039±0.00000  bestvalidloss -1.05741  last_update 40\n",
      "train: iter 194  trainloss -1.13102  validloss -0.86992±0.00000  bestvalidloss -1.05741  last_update 41\n",
      "train: iter 195  trainloss -1.14325  validloss -0.92037±0.00000  bestvalidloss -1.05741  last_update 42\n",
      "train: iter 196  trainloss -1.14855  validloss -1.00001±0.00000  bestvalidloss -1.05741  last_update 43\n",
      "train: iter 197  trainloss -1.15142  validloss -0.79436±0.00000  bestvalidloss -1.05741  last_update 44\n",
      "train: iter 198  trainloss -1.19187  validloss -0.77017±0.00000  bestvalidloss -1.05741  last_update 45\n",
      "train: iter 199  trainloss -1.12272  validloss -0.86017±0.00000  bestvalidloss -1.05741  last_update 46\n",
      "train: iter 200  trainloss -1.13982  validloss -0.93932±0.00000  bestvalidloss -1.05741  last_update 47\n",
      "train: iter 201  trainloss -1.16171  validloss -0.83340±0.00000  bestvalidloss -1.05741  last_update 48\n",
      "train: iter 202  trainloss -1.10527  validloss -0.84121±0.00000  bestvalidloss -1.05741  last_update 49\n",
      "train: iter 203  trainloss -1.18854  validloss -0.78878±0.00000  bestvalidloss -1.05741  last_update 50\n",
      "train: iter 204  trainloss -1.09339  validloss -0.93834±0.00000  bestvalidloss -1.05741  last_update 51\n",
      "train: iter 205  trainloss -1.15837  validloss -0.90609±0.00000  bestvalidloss -1.05741  last_update 52\n",
      "train: iter 206  trainloss -1.12981  validloss -0.89405±0.00000  bestvalidloss -1.05741  last_update 53\n",
      "train: iter 207  trainloss -1.11630  validloss -0.84705±0.00000  bestvalidloss -1.05741  last_update 54\n",
      "train: iter 208  trainloss -1.11926  validloss -0.78195±0.00000  bestvalidloss -1.05741  last_update 55\n",
      "train: iter 209  trainloss -1.12565  validloss -0.88633±0.00000  bestvalidloss -1.05741  last_update 56\n",
      "train: iter 210  trainloss -1.10605  validloss -0.83512±0.00000  bestvalidloss -1.05741  last_update 57\n",
      "train: iter 211  trainloss -1.16743  validloss -0.92175±0.00000  bestvalidloss -1.05741  last_update 58\n",
      "train: iter 212  trainloss -1.15145  validloss -0.85175±0.00000  bestvalidloss -1.05741  last_update 59\n",
      "train: iter 213  trainloss -1.17954  validloss -0.86731±0.00000  bestvalidloss -1.05741  last_update 60\n",
      "train: iter 214  trainloss -1.13223  validloss -0.74324±0.00000  bestvalidloss -1.05741  last_update 61\n",
      "train: iter 215  trainloss -1.10373  validloss -0.81117±0.00000  bestvalidloss -1.05741  last_update 62\n",
      "train: iter 216  trainloss -1.12890  validloss -0.87968±0.00000  bestvalidloss -1.05741  last_update 63\n",
      "train: iter 217  trainloss -1.14107  validloss -0.87548±0.00000  bestvalidloss -1.05741  last_update 64\n",
      "train: iter 218  trainloss -1.12900  validloss -0.84336±0.00000  bestvalidloss -1.05741  last_update 65\n",
      "train: iter 219  trainloss -1.13995  validloss -0.86585±0.00000  bestvalidloss -1.05741  last_update 66\n",
      "train: iter 220  trainloss -1.11286  validloss -0.81494±0.00000  bestvalidloss -1.05741  last_update 67\n",
      "train: iter 221  trainloss -1.11706  validloss -0.80331±0.00000  bestvalidloss -1.05741  last_update 68\n",
      "train: iter 222  trainloss -1.12118  validloss -0.86209±0.00000  bestvalidloss -1.05741  last_update 69\n",
      "train: iter 223  trainloss -1.12893  validloss -0.79259±0.00000  bestvalidloss -1.05741  last_update 70\n",
      "train: iter 224  trainloss -1.14800  validloss -0.60665±0.00000  bestvalidloss -1.05741  last_update 71\n",
      "train: iter 225  trainloss -1.18139  validloss -0.86882±0.00000  bestvalidloss -1.05741  last_update 72\n",
      "train: iter 226  trainloss -1.14000  validloss -0.83343±0.00000  bestvalidloss -1.05741  last_update 73\n",
      "train: iter 227  trainloss -1.11067  validloss -0.88803±0.00000  bestvalidloss -1.05741  last_update 74\n",
      "train: iter 228  trainloss -1.10457  validloss -0.74286±0.00000  bestvalidloss -1.05741  last_update 75\n",
      "train: iter 229  trainloss -1.13670  validloss -0.75462±0.00000  bestvalidloss -1.05741  last_update 76\n",
      "train: iter 230  trainloss -1.12868  validloss -0.80901±0.00000  bestvalidloss -1.05741  last_update 77\n",
      "train: iter 231  trainloss -1.12622  validloss -0.79568±0.00000  bestvalidloss -1.05741  last_update 78\n",
      "train: iter 232  trainloss -1.10417  validloss -0.89510±0.00000  bestvalidloss -1.05741  last_update 79\n",
      "train: iter 233  trainloss -1.15327  validloss -0.95322±0.00000  bestvalidloss -1.05741  last_update 80\n",
      "train: iter 234  trainloss -1.11499  validloss -0.86748±0.00000  bestvalidloss -1.05741  last_update 81\n",
      "train: iter 235  trainloss -1.09993  validloss -0.92872±0.00000  bestvalidloss -1.05741  last_update 82\n",
      "train: iter 236  trainloss -1.15132  validloss -0.97230±0.00000  bestvalidloss -1.05741  last_update 83\n",
      "train: iter 237  trainloss -1.15402  validloss -0.99052±0.00000  bestvalidloss -1.05741  last_update 84\n",
      "train: iter 238  trainloss -1.12952  validloss -0.92500±0.00000  bestvalidloss -1.05741  last_update 85\n",
      "train: iter 239  trainloss -1.12876  validloss -0.83598±0.00000  bestvalidloss -1.05741  last_update 86\n",
      "train: iter 240  trainloss -1.11313  validloss -0.94189±0.00000  bestvalidloss -1.05741  last_update 87\n",
      "train: iter 241  trainloss -1.12231  validloss -0.95212±0.00000  bestvalidloss -1.05741  last_update 88\n",
      "train: iter 242  trainloss -1.15271  validloss -0.89756±0.00000  bestvalidloss -1.05741  last_update 89\n",
      "train: iter 243  trainloss -1.13315  validloss -0.85473±0.00000  bestvalidloss -1.05741  last_update 90\n",
      "train: iter 244  trainloss -1.16825  validloss -0.97101±0.00000  bestvalidloss -1.05741  last_update 91\n",
      "train: iter 245  trainloss -1.18438  validloss -0.91187±0.00000  bestvalidloss -1.05741  last_update 92\n",
      "train: iter 246  trainloss -1.12068  validloss -0.89296±0.00000  bestvalidloss -1.05741  last_update 93\n",
      "train: iter 247  trainloss -1.13751  validloss -0.91142±0.00000  bestvalidloss -1.05741  last_update 94\n",
      "train: iter 248  trainloss -1.14433  validloss -0.97001±0.00000  bestvalidloss -1.05741  last_update 95\n",
      "train: iter 249  trainloss -1.10764  validloss -0.84039±0.00000  bestvalidloss -1.05741  last_update 96\n",
      "train: iter 250  trainloss -1.15809  validloss -0.84714±0.00000  bestvalidloss -1.05741  last_update 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 251  trainloss -1.16860  validloss -0.81826±0.00000  bestvalidloss -1.05741  last_update 98\n",
      "train: iter 252  trainloss -1.11444  validloss -0.89537±0.00000  bestvalidloss -1.05741  last_update 99\n",
      "train: iter 253  trainloss -1.18770  validloss -0.90287±0.00000  bestvalidloss -1.05741  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.1706, -2.1829, -3.7513, -4.1640], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 57.03997  validloss 52.89835±0.00000  bestvalidloss 52.89835  last_update 0\n",
      "train: iter 1  trainloss 43.16734  validloss 41.77089±0.00000  bestvalidloss 41.77089  last_update 0\n",
      "train: iter 2  trainloss 31.74101  validloss 29.98835±0.00000  bestvalidloss 29.98835  last_update 0\n",
      "train: iter 3  trainloss 24.12806  validloss 22.59710±0.00000  bestvalidloss 22.59710  last_update 0\n",
      "train: iter 4  trainloss 18.95311  validloss 17.78958±0.00000  bestvalidloss 17.78958  last_update 0\n",
      "train: iter 5  trainloss 15.16128  validloss 14.59157±0.00000  bestvalidloss 14.59157  last_update 0\n",
      "train: iter 6  trainloss 12.45225  validloss 12.31845±0.00000  bestvalidloss 12.31845  last_update 0\n",
      "train: iter 7  trainloss 10.64951  validloss 10.78667±0.00000  bestvalidloss 10.78667  last_update 0\n",
      "train: iter 8  trainloss 9.41188  validloss 9.91302±0.00000  bestvalidloss 9.91302  last_update 0\n",
      "train: iter 9  trainloss 8.57332  validloss 9.37111±0.00000  bestvalidloss 9.37111  last_update 0\n",
      "train: iter 10  trainloss 8.02114  validloss 8.92466±0.00000  bestvalidloss 8.92466  last_update 0\n",
      "train: iter 11  trainloss 7.59746  validloss 8.89011±0.00000  bestvalidloss 8.89011  last_update 0\n",
      "train: iter 12  trainloss 7.28748  validloss 8.80333±0.00000  bestvalidloss 8.80333  last_update 0\n",
      "train: iter 13  trainloss 7.02882  validloss 8.96876±0.00000  bestvalidloss 8.80333  last_update 1\n",
      "train: iter 14  trainloss 6.87763  validloss 8.73537±0.00000  bestvalidloss 8.73537  last_update 0\n",
      "train: iter 15  trainloss 6.71453  validloss 8.49590±0.00000  bestvalidloss 8.49590  last_update 0\n",
      "train: iter 16  trainloss 6.36477  validloss 8.05115±0.00000  bestvalidloss 8.05115  last_update 0\n",
      "train: iter 17  trainloss 6.02171  validloss 7.32097±0.00000  bestvalidloss 7.32097  last_update 0\n",
      "train: iter 18  trainloss 5.78522  validloss 6.85978±0.00000  bestvalidloss 6.85978  last_update 0\n",
      "train: iter 19  trainloss 5.59289  validloss 6.45959±0.00000  bestvalidloss 6.45959  last_update 0\n",
      "train: iter 20  trainloss 5.45248  validloss 6.16015±0.00000  bestvalidloss 6.16015  last_update 0\n",
      "train: iter 21  trainloss 5.25845  validloss 6.04325±0.00000  bestvalidloss 6.04325  last_update 0\n",
      "train: iter 22  trainloss 5.19753  validloss 5.77210±0.00000  bestvalidloss 5.77210  last_update 0\n",
      "train: iter 23  trainloss 5.03135  validloss 5.57774±0.00000  bestvalidloss 5.57774  last_update 0\n",
      "train: iter 24  trainloss 4.93262  validloss 5.62647±0.00000  bestvalidloss 5.57774  last_update 1\n",
      "train: iter 25  trainloss 4.83534  validloss 5.56142±0.00000  bestvalidloss 5.56142  last_update 0\n",
      "train: iter 26  trainloss 4.75992  validloss 5.40216±0.00000  bestvalidloss 5.40216  last_update 0\n",
      "train: iter 27  trainloss 4.66590  validloss 5.39809±0.00000  bestvalidloss 5.39809  last_update 0\n",
      "train: iter 28  trainloss 4.58420  validloss 5.27525±0.00000  bestvalidloss 5.27525  last_update 0\n",
      "train: iter 29  trainloss 4.54143  validloss 5.39536±0.00000  bestvalidloss 5.27525  last_update 1\n",
      "train: iter 30  trainloss 4.50510  validloss 5.26257±0.00000  bestvalidloss 5.26257  last_update 0\n",
      "train: iter 31  trainloss 4.43505  validloss 5.27536±0.00000  bestvalidloss 5.26257  last_update 1\n",
      "train: iter 32  trainloss 4.42078  validloss 5.30019±0.00000  bestvalidloss 5.26257  last_update 2\n",
      "train: iter 33  trainloss 4.35827  validloss 5.22149±0.00000  bestvalidloss 5.22149  last_update 0\n",
      "train: iter 34  trainloss 4.29994  validloss 5.29763±0.00000  bestvalidloss 5.22149  last_update 1\n",
      "train: iter 35  trainloss 4.28227  validloss 5.17853±0.00000  bestvalidloss 5.17853  last_update 0\n",
      "train: iter 36  trainloss 4.24760  validloss 5.15710±0.00000  bestvalidloss 5.15710  last_update 0\n",
      "train: iter 37  trainloss 4.28242  validloss 5.06863±0.00000  bestvalidloss 5.06863  last_update 0\n",
      "train: iter 38  trainloss 4.24049  validloss 5.28187±0.00000  bestvalidloss 5.06863  last_update 1\n",
      "train: iter 39  trainloss 4.18960  validloss 5.11251±0.00000  bestvalidloss 5.06863  last_update 2\n",
      "train: iter 40  trainloss 4.18284  validloss 5.23261±0.00000  bestvalidloss 5.06863  last_update 3\n",
      "train: iter 41  trainloss 4.16013  validloss 5.04899±0.00000  bestvalidloss 5.04899  last_update 0\n",
      "train: iter 42  trainloss 4.11452  validloss 5.12267±0.00000  bestvalidloss 5.04899  last_update 1\n",
      "train: iter 43  trainloss 4.12252  validloss 5.16215±0.00000  bestvalidloss 5.04899  last_update 2\n",
      "train: iter 44  trainloss 4.10642  validloss 5.12673±0.00000  bestvalidloss 5.04899  last_update 3\n",
      "train: iter 45  trainloss 4.09635  validloss 5.08604±0.00000  bestvalidloss 5.04899  last_update 4\n",
      "train: iter 46  trainloss 4.13233  validloss 5.00852±0.00000  bestvalidloss 5.00852  last_update 0\n",
      "train: iter 47  trainloss 4.08666  validloss 5.15688±0.00000  bestvalidloss 5.00852  last_update 1\n",
      "train: iter 48  trainloss 4.05568  validloss 5.05426±0.00000  bestvalidloss 5.00852  last_update 2\n",
      "train: iter 49  trainloss 4.10431  validloss 4.99454±0.00000  bestvalidloss 4.99454  last_update 0\n",
      "train: iter 50  trainloss 4.06447  validloss 4.98854±0.00000  bestvalidloss 4.98854  last_update 0\n",
      "train: iter 51  trainloss 4.03821  validloss 5.02925±0.00000  bestvalidloss 4.98854  last_update 1\n",
      "train: iter 52  trainloss 4.03237  validloss 4.98208±0.00000  bestvalidloss 4.98208  last_update 0\n",
      "train: iter 53  trainloss 4.03388  validloss 4.99412±0.00000  bestvalidloss 4.98208  last_update 1\n",
      "train: iter 54  trainloss 4.01246  validloss 4.98935±0.00000  bestvalidloss 4.98208  last_update 2\n",
      "train: iter 55  trainloss 4.01287  validloss 5.11578±0.00000  bestvalidloss 4.98208  last_update 3\n",
      "train: iter 56  trainloss 4.00824  validloss 4.94117±0.00000  bestvalidloss 4.94117  last_update 0\n",
      "train: iter 57  trainloss 3.98058  validloss 5.05095±0.00000  bestvalidloss 4.94117  last_update 1\n",
      "train: iter 58  trainloss 3.96349  validloss 4.88390±0.00000  bestvalidloss 4.88390  last_update 0\n",
      "train: iter 59  trainloss 3.95122  validloss 4.89000±0.00000  bestvalidloss 4.88390  last_update 1\n",
      "train: iter 60  trainloss 3.94313  validloss 4.98136±0.00000  bestvalidloss 4.88390  last_update 2\n",
      "train: iter 61  trainloss 3.91001  validloss 5.06175±0.00000  bestvalidloss 4.88390  last_update 3\n",
      "train: iter 62  trainloss 3.89998  validloss 4.88628±0.00000  bestvalidloss 4.88390  last_update 4\n",
      "train: iter 63  trainloss 3.87036  validloss 4.86996±0.00000  bestvalidloss 4.86996  last_update 0\n",
      "train: iter 64  trainloss 3.87703  validloss 5.16122±0.00000  bestvalidloss 4.86996  last_update 1\n",
      "train: iter 65  trainloss 3.84116  validloss 4.81264±0.00000  bestvalidloss 4.81264  last_update 0\n",
      "train: iter 66  trainloss 3.84864  validloss 4.73569±0.00000  bestvalidloss 4.73569  last_update 0\n",
      "train: iter 67  trainloss 3.84796  validloss 4.87263±0.00000  bestvalidloss 4.73569  last_update 1\n",
      "train: iter 68  trainloss 3.81888  validloss 4.81918±0.00000  bestvalidloss 4.73569  last_update 2\n",
      "train: iter 69  trainloss 3.80994  validloss 4.72982±0.00000  bestvalidloss 4.72982  last_update 0\n",
      "train: iter 70  trainloss 3.83631  validloss 4.84416±0.00000  bestvalidloss 4.72982  last_update 1\n",
      "train: iter 71  trainloss 3.77025  validloss 4.83901±0.00000  bestvalidloss 4.72982  last_update 2\n",
      "train: iter 72  trainloss 3.80585  validloss 4.82834±0.00000  bestvalidloss 4.72982  last_update 3\n",
      "train: iter 73  trainloss 3.74967  validloss 4.81761±0.00000  bestvalidloss 4.72982  last_update 4\n",
      "train: iter 74  trainloss 3.80355  validloss 4.80603±0.00000  bestvalidloss 4.72982  last_update 5\n",
      "train: iter 75  trainloss 3.82276  validloss 4.90955±0.00000  bestvalidloss 4.72982  last_update 6\n",
      "train: iter 76  trainloss 3.75327  validloss 4.81192±0.00000  bestvalidloss 4.72982  last_update 7\n",
      "train: iter 77  trainloss 3.76807  validloss 4.96257±0.00000  bestvalidloss 4.72982  last_update 8\n",
      "train: iter 78  trainloss 3.73762  validloss 4.72571±0.00000  bestvalidloss 4.72571  last_update 0\n",
      "train: iter 79  trainloss 3.74919  validloss 4.78341±0.00000  bestvalidloss 4.72571  last_update 1\n",
      "train: iter 80  trainloss 3.73390  validloss 4.75572±0.00000  bestvalidloss 4.72571  last_update 2\n",
      "train: iter 81  trainloss 3.76912  validloss 4.85616±0.00000  bestvalidloss 4.72571  last_update 3\n",
      "train: iter 82  trainloss 3.73035  validloss 4.70280±0.00000  bestvalidloss 4.70280  last_update 0\n",
      "train: iter 83  trainloss 3.71984  validloss 4.79124±0.00000  bestvalidloss 4.70280  last_update 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 84  trainloss 3.71138  validloss 4.88204±0.00000  bestvalidloss 4.70280  last_update 2\n",
      "train: iter 85  trainloss 3.71024  validloss 4.64373±0.00000  bestvalidloss 4.64373  last_update 0\n",
      "train: iter 86  trainloss 3.69178  validloss 4.84646±0.00000  bestvalidloss 4.64373  last_update 1\n",
      "train: iter 87  trainloss 3.74958  validloss 4.63584±0.00000  bestvalidloss 4.63584  last_update 0\n",
      "train: iter 88  trainloss 3.69482  validloss 4.69712±0.00000  bestvalidloss 4.63584  last_update 1\n",
      "train: iter 89  trainloss 3.73269  validloss 4.71548±0.00000  bestvalidloss 4.63584  last_update 2\n",
      "train: iter 90  trainloss 3.77258  validloss 4.80829±0.00000  bestvalidloss 4.63584  last_update 3\n",
      "train: iter 91  trainloss 3.69429  validloss 4.73354±0.00000  bestvalidloss 4.63584  last_update 4\n",
      "train: iter 92  trainloss 3.69271  validloss 4.75357±0.00000  bestvalidloss 4.63584  last_update 5\n",
      "train: iter 93  trainloss 3.72019  validloss 4.80248±0.00000  bestvalidloss 4.63584  last_update 6\n",
      "train: iter 94  trainloss 3.68028  validloss 4.81647±0.00000  bestvalidloss 4.63584  last_update 7\n",
      "train: iter 95  trainloss 3.71822  validloss 4.64156±0.00000  bestvalidloss 4.63584  last_update 8\n",
      "train: iter 96  trainloss 3.69357  validloss 4.75457±0.00000  bestvalidloss 4.63584  last_update 9\n",
      "train: iter 97  trainloss 3.71804  validloss 4.65705±0.00000  bestvalidloss 4.63584  last_update 10\n",
      "train: iter 98  trainloss 3.71386  validloss 4.72353±0.00000  bestvalidloss 4.63584  last_update 11\n",
      "train: iter 99  trainloss 3.68827  validloss 4.74784±0.00000  bestvalidloss 4.63584  last_update 12\n",
      "train: iter 100  trainloss 3.72180  validloss 4.68131±0.00000  bestvalidloss 4.63584  last_update 13\n",
      "train: iter 101  trainloss 3.68324  validloss 4.84768±0.00000  bestvalidloss 4.63584  last_update 14\n",
      "train: iter 102  trainloss 3.71643  validloss 4.78549±0.00000  bestvalidloss 4.63584  last_update 15\n",
      "train: iter 103  trainloss 3.72894  validloss 4.57710±0.00000  bestvalidloss 4.57710  last_update 0\n",
      "train: iter 104  trainloss 3.67832  validloss 4.68994±0.00000  bestvalidloss 4.57710  last_update 1\n",
      "train: iter 105  trainloss 3.72031  validloss 4.70959±0.00000  bestvalidloss 4.57710  last_update 2\n",
      "train: iter 106  trainloss 3.68330  validloss 4.67454±0.00000  bestvalidloss 4.57710  last_update 3\n",
      "train: iter 107  trainloss 3.70744  validloss 4.63554±0.00000  bestvalidloss 4.57710  last_update 4\n",
      "train: iter 108  trainloss 3.68507  validloss 4.77386±0.00000  bestvalidloss 4.57710  last_update 5\n",
      "train: iter 109  trainloss 3.70009  validloss 4.66133±0.00000  bestvalidloss 4.57710  last_update 6\n",
      "train: iter 110  trainloss 3.66220  validloss 4.64333±0.00000  bestvalidloss 4.57710  last_update 7\n",
      "train: iter 111  trainloss 3.67688  validloss 4.77648±0.00000  bestvalidloss 4.57710  last_update 8\n",
      "train: iter 112  trainloss 3.68465  validloss 4.61513±0.00000  bestvalidloss 4.57710  last_update 9\n",
      "train: iter 113  trainloss 3.68563  validloss 4.74198±0.00000  bestvalidloss 4.57710  last_update 10\n",
      "train: iter 114  trainloss 3.65445  validloss 4.58153±0.00000  bestvalidloss 4.57710  last_update 11\n",
      "train: iter 115  trainloss 3.64849  validloss 4.56834±0.00000  bestvalidloss 4.56834  last_update 0\n",
      "train: iter 116  trainloss 3.65362  validloss 4.64219±0.00000  bestvalidloss 4.56834  last_update 1\n",
      "train: iter 117  trainloss 3.68345  validloss 4.62233±0.00000  bestvalidloss 4.56834  last_update 2\n",
      "train: iter 118  trainloss 3.67754  validloss 4.61944±0.00000  bestvalidloss 4.56834  last_update 3\n",
      "train: iter 119  trainloss 3.62637  validloss 4.70497±0.00000  bestvalidloss 4.56834  last_update 4\n",
      "train: iter 120  trainloss 3.65411  validloss 4.55839±0.00000  bestvalidloss 4.55839  last_update 0\n",
      "train: iter 121  trainloss 3.63755  validloss 4.67832±0.00000  bestvalidloss 4.55839  last_update 1\n",
      "train: iter 122  trainloss 3.65591  validloss 4.68416±0.00000  bestvalidloss 4.55839  last_update 2\n",
      "train: iter 123  trainloss 3.66361  validloss 4.62556±0.00000  bestvalidloss 4.55839  last_update 3\n",
      "train: iter 124  trainloss 3.66224  validloss 4.68291±0.00000  bestvalidloss 4.55839  last_update 4\n",
      "train: iter 125  trainloss 3.67554  validloss 4.74280±0.00000  bestvalidloss 4.55839  last_update 5\n",
      "train: iter 126  trainloss 3.66127  validloss 4.81040±0.00000  bestvalidloss 4.55839  last_update 6\n",
      "train: iter 127  trainloss 3.66456  validloss 4.59757±0.00000  bestvalidloss 4.55839  last_update 7\n",
      "train: iter 128  trainloss 3.69627  validloss 4.62861±0.00000  bestvalidloss 4.55839  last_update 8\n",
      "train: iter 129  trainloss 3.66856  validloss 4.62712±0.00000  bestvalidloss 4.55839  last_update 9\n",
      "train: iter 130  trainloss 3.62618  validloss 4.65441±0.00000  bestvalidloss 4.55839  last_update 10\n",
      "train: iter 131  trainloss 3.64245  validloss 4.66911±0.00000  bestvalidloss 4.55839  last_update 11\n",
      "train: iter 132  trainloss 3.67031  validloss 4.52766±0.00000  bestvalidloss 4.52766  last_update 0\n",
      "train: iter 133  trainloss 3.66469  validloss 4.55023±0.00000  bestvalidloss 4.52766  last_update 1\n",
      "train: iter 134  trainloss 3.62465  validloss 4.64518±0.00000  bestvalidloss 4.52766  last_update 2\n",
      "train: iter 135  trainloss 3.67606  validloss 4.81814±0.00000  bestvalidloss 4.52766  last_update 3\n",
      "train: iter 136  trainloss 3.64032  validloss 4.69103±0.00000  bestvalidloss 4.52766  last_update 4\n",
      "train: iter 137  trainloss 3.63704  validloss 4.59214±0.00000  bestvalidloss 4.52766  last_update 5\n",
      "train: iter 138  trainloss 3.59403  validloss 4.53069±0.00000  bestvalidloss 4.52766  last_update 6\n",
      "train: iter 139  trainloss 3.64595  validloss 4.70561±0.00000  bestvalidloss 4.52766  last_update 7\n",
      "train: iter 140  trainloss 3.67826  validloss 4.58516±0.00000  bestvalidloss 4.52766  last_update 8\n",
      "train: iter 141  trainloss 3.62906  validloss 4.62299±0.00000  bestvalidloss 4.52766  last_update 9\n",
      "train: iter 142  trainloss 3.62353  validloss 4.58299±0.00000  bestvalidloss 4.52766  last_update 10\n",
      "train: iter 143  trainloss 3.60517  validloss 4.56646±0.00000  bestvalidloss 4.52766  last_update 11\n",
      "train: iter 144  trainloss 3.69281  validloss 4.74065±0.00000  bestvalidloss 4.52766  last_update 12\n",
      "train: iter 145  trainloss 3.65741  validloss 4.52588±0.00000  bestvalidloss 4.52588  last_update 0\n",
      "train: iter 146  trainloss 3.65268  validloss 4.66746±0.00000  bestvalidloss 4.52588  last_update 1\n",
      "train: iter 147  trainloss 3.62941  validloss 4.74608±0.00000  bestvalidloss 4.52588  last_update 2\n",
      "train: iter 148  trainloss 3.65502  validloss 4.69835±0.00000  bestvalidloss 4.52588  last_update 3\n",
      "train: iter 149  trainloss 3.63709  validloss 4.70379±0.00000  bestvalidloss 4.52588  last_update 4\n",
      "train: iter 150  trainloss 3.62604  validloss 4.58660±0.00000  bestvalidloss 4.52588  last_update 5\n",
      "train: iter 151  trainloss 3.63938  validloss 4.51093±0.00000  bestvalidloss 4.51093  last_update 0\n",
      "train: iter 152  trainloss 3.65999  validloss 4.54105±0.00000  bestvalidloss 4.51093  last_update 1\n",
      "train: iter 153  trainloss 3.64823  validloss 4.67553±0.00000  bestvalidloss 4.51093  last_update 2\n",
      "train: iter 154  trainloss 3.62318  validloss 4.55146±0.00000  bestvalidloss 4.51093  last_update 3\n",
      "train: iter 155  trainloss 3.62905  validloss 4.62506±0.00000  bestvalidloss 4.51093  last_update 4\n",
      "train: iter 156  trainloss 3.62385  validloss 4.57282±0.00000  bestvalidloss 4.51093  last_update 5\n",
      "train: iter 157  trainloss 3.65264  validloss 4.52460±0.00000  bestvalidloss 4.51093  last_update 6\n",
      "train: iter 158  trainloss 3.62140  validloss 4.67871±0.00000  bestvalidloss 4.51093  last_update 7\n",
      "train: iter 159  trainloss 3.61067  validloss 4.53359±0.00000  bestvalidloss 4.51093  last_update 8\n",
      "train: iter 160  trainloss 3.64686  validloss 4.47772±0.00000  bestvalidloss 4.47772  last_update 0\n",
      "train: iter 161  trainloss 3.64230  validloss 4.60257±0.00000  bestvalidloss 4.47772  last_update 1\n",
      "train: iter 162  trainloss 3.62199  validloss 4.81615±0.00000  bestvalidloss 4.47772  last_update 2\n",
      "train: iter 163  trainloss 3.65007  validloss 4.52908±0.00000  bestvalidloss 4.47772  last_update 3\n",
      "train: iter 164  trainloss 3.62063  validloss 4.65014±0.00000  bestvalidloss 4.47772  last_update 4\n",
      "train: iter 165  trainloss 3.65742  validloss 4.56486±0.00000  bestvalidloss 4.47772  last_update 5\n",
      "train: iter 166  trainloss 3.63681  validloss 4.66588±0.00000  bestvalidloss 4.47772  last_update 6\n",
      "train: iter 167  trainloss 3.63629  validloss 4.58301±0.00000  bestvalidloss 4.47772  last_update 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 168  trainloss 3.59757  validloss 4.52045±0.00000  bestvalidloss 4.47772  last_update 8\n",
      "train: iter 169  trainloss 3.57968  validloss 4.58193±0.00000  bestvalidloss 4.47772  last_update 9\n",
      "train: iter 170  trainloss 3.60338  validloss 4.62788±0.00000  bestvalidloss 4.47772  last_update 10\n",
      "train: iter 171  trainloss 3.59095  validloss 4.61456±0.00000  bestvalidloss 4.47772  last_update 11\n",
      "train: iter 172  trainloss 3.62856  validloss 4.60294±0.00000  bestvalidloss 4.47772  last_update 12\n",
      "train: iter 173  trainloss 3.63179  validloss 4.48724±0.00000  bestvalidloss 4.47772  last_update 13\n",
      "train: iter 174  trainloss 3.62132  validloss 4.53087±0.00000  bestvalidloss 4.47772  last_update 14\n",
      "train: iter 175  trainloss 3.63690  validloss 4.55837±0.00000  bestvalidloss 4.47772  last_update 15\n",
      "train: iter 176  trainloss 3.59639  validloss 4.48171±0.00000  bestvalidloss 4.47772  last_update 16\n",
      "train: iter 177  trainloss 3.65371  validloss 4.48085±0.00000  bestvalidloss 4.47772  last_update 17\n",
      "train: iter 178  trainloss 3.63296  validloss 4.49127±0.00000  bestvalidloss 4.47772  last_update 18\n",
      "train: iter 179  trainloss 3.61359  validloss 4.54483±0.00000  bestvalidloss 4.47772  last_update 19\n",
      "train: iter 180  trainloss 3.61027  validloss 4.51834±0.00000  bestvalidloss 4.47772  last_update 20\n",
      "train: iter 181  trainloss 3.58335  validloss 4.55311±0.00000  bestvalidloss 4.47772  last_update 21\n",
      "train: iter 182  trainloss 3.62906  validloss 4.62810±0.00000  bestvalidloss 4.47772  last_update 22\n",
      "train: iter 183  trainloss 3.60287  validloss 4.52092±0.00000  bestvalidloss 4.47772  last_update 23\n",
      "train: iter 184  trainloss 3.62953  validloss 4.53448±0.00000  bestvalidloss 4.47772  last_update 24\n",
      "train: iter 185  trainloss 3.56421  validloss 4.52632±0.00000  bestvalidloss 4.47772  last_update 25\n",
      "train: iter 186  trainloss 3.64383  validloss 4.57513±0.00000  bestvalidloss 4.47772  last_update 26\n",
      "train: iter 187  trainloss 3.61026  validloss 4.51807±0.00000  bestvalidloss 4.47772  last_update 27\n",
      "train: iter 188  trainloss 3.60797  validloss 4.54065±0.00000  bestvalidloss 4.47772  last_update 28\n",
      "train: iter 189  trainloss 3.59349  validloss 4.52670±0.00000  bestvalidloss 4.47772  last_update 29\n",
      "train: iter 190  trainloss 3.62748  validloss 4.62062±0.00000  bestvalidloss 4.47772  last_update 30\n",
      "train: iter 191  trainloss 3.61297  validloss 4.46365±0.00000  bestvalidloss 4.46365  last_update 0\n",
      "train: iter 192  trainloss 3.63176  validloss 4.53753±0.00000  bestvalidloss 4.46365  last_update 1\n",
      "train: iter 193  trainloss 3.57561  validloss 4.57916±0.00000  bestvalidloss 4.46365  last_update 2\n",
      "train: iter 194  trainloss 3.62826  validloss 4.61171±0.00000  bestvalidloss 4.46365  last_update 3\n",
      "train: iter 195  trainloss 3.57873  validloss 4.57333±0.00000  bestvalidloss 4.46365  last_update 4\n",
      "train: iter 196  trainloss 3.59367  validloss 4.70493±0.00000  bestvalidloss 4.46365  last_update 5\n",
      "train: iter 197  trainloss 3.58371  validloss 4.55180±0.00000  bestvalidloss 4.46365  last_update 6\n",
      "train: iter 198  trainloss 3.60638  validloss 4.45637±0.00000  bestvalidloss 4.45637  last_update 0\n",
      "train: iter 199  trainloss 3.59111  validloss 4.46884±0.00000  bestvalidloss 4.45637  last_update 1\n",
      "train: iter 200  trainloss 3.60373  validloss 4.54190±0.00000  bestvalidloss 4.45637  last_update 2\n",
      "train: iter 201  trainloss 3.59231  validloss 4.54901±0.00000  bestvalidloss 4.45637  last_update 3\n",
      "train: iter 202  trainloss 3.60558  validloss 4.63756±0.00000  bestvalidloss 4.45637  last_update 4\n",
      "train: iter 203  trainloss 3.57207  validloss 4.48173±0.00000  bestvalidloss 4.45637  last_update 5\n",
      "train: iter 204  trainloss 3.62031  validloss 4.58443±0.00000  bestvalidloss 4.45637  last_update 6\n",
      "train: iter 205  trainloss 3.60176  validloss 4.66489±0.00000  bestvalidloss 4.45637  last_update 7\n",
      "train: iter 206  trainloss 3.56186  validloss 4.49981±0.00000  bestvalidloss 4.45637  last_update 8\n",
      "train: iter 207  trainloss 3.58429  validloss 4.50213±0.00000  bestvalidloss 4.45637  last_update 9\n",
      "train: iter 208  trainloss 3.57960  validloss 4.50862±0.00000  bestvalidloss 4.45637  last_update 10\n",
      "train: iter 209  trainloss 3.63118  validloss 4.37539±0.00000  bestvalidloss 4.37539  last_update 0\n",
      "train: iter 210  trainloss 3.60012  validloss 4.62337±0.00000  bestvalidloss 4.37539  last_update 1\n",
      "train: iter 211  trainloss 3.61009  validloss 4.61816±0.00000  bestvalidloss 4.37539  last_update 2\n",
      "train: iter 212  trainloss 3.61899  validloss 4.45223±0.00000  bestvalidloss 4.37539  last_update 3\n",
      "train: iter 213  trainloss 3.53772  validloss 4.46267±0.00000  bestvalidloss 4.37539  last_update 4\n",
      "train: iter 214  trainloss 3.60885  validloss 4.46322±0.00000  bestvalidloss 4.37539  last_update 5\n",
      "train: iter 215  trainloss 3.56419  validloss 4.53115±0.00000  bestvalidloss 4.37539  last_update 6\n",
      "train: iter 216  trainloss 3.61134  validloss 4.48900±0.00000  bestvalidloss 4.37539  last_update 7\n",
      "train: iter 217  trainloss 3.56817  validloss 4.48865±0.00000  bestvalidloss 4.37539  last_update 8\n",
      "train: iter 218  trainloss 3.60283  validloss 4.37959±0.00000  bestvalidloss 4.37539  last_update 9\n",
      "train: iter 219  trainloss 3.58192  validloss 4.46359±0.00000  bestvalidloss 4.37539  last_update 10\n",
      "train: iter 220  trainloss 3.57945  validloss 4.53945±0.00000  bestvalidloss 4.37539  last_update 11\n",
      "train: iter 221  trainloss 3.58239  validloss 4.54655±0.00000  bestvalidloss 4.37539  last_update 12\n",
      "train: iter 222  trainloss 3.58163  validloss 4.48717±0.00000  bestvalidloss 4.37539  last_update 13\n",
      "train: iter 223  trainloss 3.57556  validloss 4.45220±0.00000  bestvalidloss 4.37539  last_update 14\n",
      "train: iter 224  trainloss 3.61463  validloss 4.55668±0.00000  bestvalidloss 4.37539  last_update 15\n",
      "train: iter 225  trainloss 3.58614  validloss 4.47990±0.00000  bestvalidloss 4.37539  last_update 16\n",
      "train: iter 226  trainloss 3.59095  validloss 4.55756±0.00000  bestvalidloss 4.37539  last_update 17\n",
      "train: iter 227  trainloss 3.59595  validloss 4.48262±0.00000  bestvalidloss 4.37539  last_update 18\n",
      "train: iter 228  trainloss 3.58198  validloss 4.54596±0.00000  bestvalidloss 4.37539  last_update 19\n",
      "train: iter 229  trainloss 3.59529  validloss 4.50248±0.00000  bestvalidloss 4.37539  last_update 20\n",
      "train: iter 230  trainloss 3.55854  validloss 4.37472±0.00000  bestvalidloss 4.37472  last_update 0\n",
      "train: iter 231  trainloss 3.60564  validloss 4.46691±0.00000  bestvalidloss 4.37472  last_update 1\n",
      "train: iter 232  trainloss 3.64712  validloss 4.42986±0.00000  bestvalidloss 4.37472  last_update 2\n",
      "train: iter 233  trainloss 3.57698  validloss 4.48146±0.00000  bestvalidloss 4.37472  last_update 3\n",
      "train: iter 234  trainloss 3.55844  validloss 4.50407±0.00000  bestvalidloss 4.37472  last_update 4\n",
      "train: iter 235  trainloss 3.56966  validloss 4.58801±0.00000  bestvalidloss 4.37472  last_update 5\n",
      "train: iter 236  trainloss 3.57054  validloss 4.48358±0.00000  bestvalidloss 4.37472  last_update 6\n",
      "train: iter 237  trainloss 3.58784  validloss 4.50133±0.00000  bestvalidloss 4.37472  last_update 7\n",
      "train: iter 238  trainloss 3.59213  validloss 4.57650±0.00000  bestvalidloss 4.37472  last_update 8\n",
      "train: iter 239  trainloss 3.58725  validloss 4.47535±0.00000  bestvalidloss 4.37472  last_update 9\n",
      "train: iter 240  trainloss 3.58713  validloss 4.41715±0.00000  bestvalidloss 4.37472  last_update 10\n",
      "train: iter 241  trainloss 3.56956  validloss 4.42916±0.00000  bestvalidloss 4.37472  last_update 11\n",
      "train: iter 242  trainloss 3.57139  validloss 4.36347±0.00000  bestvalidloss 4.36347  last_update 0\n",
      "train: iter 243  trainloss 3.54804  validloss 4.39770±0.00000  bestvalidloss 4.36347  last_update 1\n",
      "train: iter 244  trainloss 3.58367  validloss 4.47899±0.00000  bestvalidloss 4.36347  last_update 2\n",
      "train: iter 245  trainloss 3.54315  validloss 4.42728±0.00000  bestvalidloss 4.36347  last_update 3\n",
      "train: iter 246  trainloss 3.56498  validloss 4.61256±0.00000  bestvalidloss 4.36347  last_update 4\n",
      "train: iter 247  trainloss 3.57109  validloss 4.51629±0.00000  bestvalidloss 4.36347  last_update 5\n",
      "train: iter 248  trainloss 3.57542  validloss 4.46252±0.00000  bestvalidloss 4.36347  last_update 6\n",
      "train: iter 249  trainloss 3.55959  validloss 4.52174±0.00000  bestvalidloss 4.36347  last_update 7\n",
      "train: iter 250  trainloss 3.59671  validloss 4.49517±0.00000  bestvalidloss 4.36347  last_update 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 251  trainloss 3.58244  validloss 4.42297±0.00000  bestvalidloss 4.36347  last_update 9\n",
      "train: iter 252  trainloss 3.55342  validloss 4.38595±0.00000  bestvalidloss 4.36347  last_update 10\n",
      "train: iter 253  trainloss 3.58674  validloss 4.61055±0.00000  bestvalidloss 4.36347  last_update 11\n",
      "train: iter 254  trainloss 3.58136  validloss 4.48492±0.00000  bestvalidloss 4.36347  last_update 12\n",
      "train: iter 255  trainloss 3.55831  validloss 4.46678±0.00000  bestvalidloss 4.36347  last_update 13\n",
      "train: iter 256  trainloss 3.59206  validloss 4.43640±0.00000  bestvalidloss 4.36347  last_update 14\n",
      "train: iter 257  trainloss 3.56743  validloss 4.47140±0.00000  bestvalidloss 4.36347  last_update 15\n",
      "train: iter 258  trainloss 3.56074  validloss 4.58977±0.00000  bestvalidloss 4.36347  last_update 16\n",
      "train: iter 259  trainloss 3.58184  validloss 4.37491±0.00000  bestvalidloss 4.36347  last_update 17\n",
      "train: iter 260  trainloss 3.54181  validloss 4.50309±0.00000  bestvalidloss 4.36347  last_update 18\n",
      "train: iter 261  trainloss 3.58321  validloss 4.69961±0.00000  bestvalidloss 4.36347  last_update 19\n",
      "train: iter 262  trainloss 3.58218  validloss 4.47957±0.00000  bestvalidloss 4.36347  last_update 20\n",
      "train: iter 263  trainloss 3.58107  validloss 4.55155±0.00000  bestvalidloss 4.36347  last_update 21\n",
      "train: iter 264  trainloss 3.56270  validloss 4.49324±0.00000  bestvalidloss 4.36347  last_update 22\n",
      "train: iter 265  trainloss 3.56392  validloss 4.38963±0.00000  bestvalidloss 4.36347  last_update 23\n",
      "train: iter 266  trainloss 3.58038  validloss 4.38106±0.00000  bestvalidloss 4.36347  last_update 24\n",
      "train: iter 267  trainloss 3.57738  validloss 4.44701±0.00000  bestvalidloss 4.36347  last_update 25\n",
      "train: iter 268  trainloss 3.56402  validloss 4.57454±0.00000  bestvalidloss 4.36347  last_update 26\n",
      "train: iter 269  trainloss 3.56607  validloss 4.61386±0.00000  bestvalidloss 4.36347  last_update 27\n",
      "train: iter 270  trainloss 3.57606  validloss 4.41829±0.00000  bestvalidloss 4.36347  last_update 28\n",
      "train: iter 271  trainloss 3.61811  validloss 4.65851±0.00000  bestvalidloss 4.36347  last_update 29\n",
      "train: iter 272  trainloss 3.55601  validloss 4.37112±0.00000  bestvalidloss 4.36347  last_update 30\n",
      "train: iter 273  trainloss 3.55532  validloss 4.59149±0.00000  bestvalidloss 4.36347  last_update 31\n",
      "train: iter 274  trainloss 3.55526  validloss 4.53781±0.00000  bestvalidloss 4.36347  last_update 32\n",
      "train: iter 275  trainloss 3.58566  validloss 4.54872±0.00000  bestvalidloss 4.36347  last_update 33\n",
      "train: iter 276  trainloss 3.63476  validloss 4.47105±0.00000  bestvalidloss 4.36347  last_update 34\n",
      "train: iter 277  trainloss 3.56598  validloss 4.46452±0.00000  bestvalidloss 4.36347  last_update 35\n",
      "train: iter 278  trainloss 3.59300  validloss 4.49126±0.00000  bestvalidloss 4.36347  last_update 36\n",
      "train: iter 279  trainloss 3.59467  validloss 4.53155±0.00000  bestvalidloss 4.36347  last_update 37\n",
      "train: iter 280  trainloss 3.50466  validloss 4.41984±0.00000  bestvalidloss 4.36347  last_update 38\n",
      "train: iter 281  trainloss 3.55424  validloss 4.62925±0.00000  bestvalidloss 4.36347  last_update 39\n",
      "train: iter 282  trainloss 3.56044  validloss 4.43871±0.00000  bestvalidloss 4.36347  last_update 40\n",
      "train: iter 283  trainloss 3.57732  validloss 4.46745±0.00000  bestvalidloss 4.36347  last_update 41\n",
      "train: iter 284  trainloss 3.53079  validloss 4.45957±0.00000  bestvalidloss 4.36347  last_update 42\n",
      "train: iter 285  trainloss 3.54107  validloss 4.48891±0.00000  bestvalidloss 4.36347  last_update 43\n",
      "train: iter 286  trainloss 3.54587  validloss 4.48985±0.00000  bestvalidloss 4.36347  last_update 44\n",
      "train: iter 287  trainloss 3.55552  validloss 4.38031±0.00000  bestvalidloss 4.36347  last_update 45\n",
      "train: iter 288  trainloss 3.55305  validloss 4.49011±0.00000  bestvalidloss 4.36347  last_update 46\n",
      "train: iter 289  trainloss 3.54968  validloss 4.44819±0.00000  bestvalidloss 4.36347  last_update 47\n",
      "train: iter 290  trainloss 3.59278  validloss 4.55099±0.00000  bestvalidloss 4.36347  last_update 48\n",
      "train: iter 291  trainloss 3.54992  validloss 4.45912±0.00000  bestvalidloss 4.36347  last_update 49\n",
      "train: iter 292  trainloss 3.53056  validloss 4.47480±0.00000  bestvalidloss 4.36347  last_update 50\n",
      "train: iter 293  trainloss 3.56393  validloss 4.47589±0.00000  bestvalidloss 4.36347  last_update 51\n",
      "train: iter 294  trainloss 3.56509  validloss 4.49533±0.00000  bestvalidloss 4.36347  last_update 52\n",
      "train: iter 295  trainloss 3.58440  validloss 4.42050±0.00000  bestvalidloss 4.36347  last_update 53\n",
      "train: iter 296  trainloss 3.54351  validloss 4.45050±0.00000  bestvalidloss 4.36347  last_update 54\n",
      "train: iter 297  trainloss 3.53022  validloss 4.49224±0.00000  bestvalidloss 4.36347  last_update 55\n",
      "train: iter 298  trainloss 3.58869  validloss 4.59974±0.00000  bestvalidloss 4.36347  last_update 56\n",
      "train: iter 299  trainloss 3.58214  validloss 4.44456±0.00000  bestvalidloss 4.36347  last_update 57\n",
      "train: iter 300  trainloss 3.54354  validloss 4.43042±0.00000  bestvalidloss 4.36347  last_update 58\n",
      "train: iter 301  trainloss 3.56665  validloss 4.42895±0.00000  bestvalidloss 4.36347  last_update 59\n",
      "train: iter 302  trainloss 3.52701  validloss 4.44256±0.00000  bestvalidloss 4.36347  last_update 60\n",
      "train: iter 303  trainloss 3.56031  validloss 4.49327±0.00000  bestvalidloss 4.36347  last_update 61\n",
      "train: iter 304  trainloss 3.56124  validloss 4.51153±0.00000  bestvalidloss 4.36347  last_update 62\n",
      "train: iter 305  trainloss 3.54495  validloss 4.36173±0.00000  bestvalidloss 4.36173  last_update 0\n",
      "train: iter 306  trainloss 3.50222  validloss 4.45857±0.00000  bestvalidloss 4.36173  last_update 1\n",
      "train: iter 307  trainloss 3.58117  validloss 4.46532±0.00000  bestvalidloss 4.36173  last_update 2\n",
      "train: iter 308  trainloss 3.53921  validloss 4.51154±0.00000  bestvalidloss 4.36173  last_update 3\n",
      "train: iter 309  trainloss 3.51227  validloss 4.51797±0.00000  bestvalidloss 4.36173  last_update 4\n",
      "train: iter 310  trainloss 3.54540  validloss 4.40010±0.00000  bestvalidloss 4.36173  last_update 5\n",
      "train: iter 311  trainloss 3.55182  validloss 4.54119±0.00000  bestvalidloss 4.36173  last_update 6\n",
      "train: iter 312  trainloss 3.54160  validloss 4.31436±0.00000  bestvalidloss 4.31436  last_update 0\n",
      "train: iter 313  trainloss 3.58069  validloss 4.39663±0.00000  bestvalidloss 4.31436  last_update 1\n",
      "train: iter 314  trainloss 3.55464  validloss 4.45183±0.00000  bestvalidloss 4.31436  last_update 2\n",
      "train: iter 315  trainloss 3.54250  validloss 4.38764±0.00000  bestvalidloss 4.31436  last_update 3\n",
      "train: iter 316  trainloss 3.58223  validloss 4.50417±0.00000  bestvalidloss 4.31436  last_update 4\n",
      "train: iter 317  trainloss 3.55873  validloss 4.47016±0.00000  bestvalidloss 4.31436  last_update 5\n",
      "train: iter 318  trainloss 3.54408  validloss 4.56787±0.00000  bestvalidloss 4.31436  last_update 6\n",
      "train: iter 319  trainloss 3.55818  validloss 4.57172±0.00000  bestvalidloss 4.31436  last_update 7\n",
      "train: iter 320  trainloss 3.54882  validloss 4.56798±0.00000  bestvalidloss 4.31436  last_update 8\n",
      "train: iter 321  trainloss 3.50685  validloss 4.42157±0.00000  bestvalidloss 4.31436  last_update 9\n",
      "train: iter 322  trainloss 3.54357  validloss 4.52527±0.00000  bestvalidloss 4.31436  last_update 10\n",
      "train: iter 323  trainloss 3.55321  validloss 4.46700±0.00000  bestvalidloss 4.31436  last_update 11\n",
      "train: iter 324  trainloss 3.53258  validloss 4.35497±0.00000  bestvalidloss 4.31436  last_update 12\n",
      "train: iter 325  trainloss 3.53533  validloss 4.53659±0.00000  bestvalidloss 4.31436  last_update 13\n",
      "train: iter 326  trainloss 3.54211  validloss 4.48715±0.00000  bestvalidloss 4.31436  last_update 14\n",
      "train: iter 327  trainloss 3.54857  validloss 4.57158±0.00000  bestvalidloss 4.31436  last_update 15\n",
      "train: iter 328  trainloss 3.55080  validloss 4.35834±0.00000  bestvalidloss 4.31436  last_update 16\n",
      "train: iter 329  trainloss 3.55569  validloss 4.48393±0.00000  bestvalidloss 4.31436  last_update 17\n",
      "train: iter 330  trainloss 3.56875  validloss 4.42342±0.00000  bestvalidloss 4.31436  last_update 18\n",
      "train: iter 331  trainloss 3.56112  validloss 4.42254±0.00000  bestvalidloss 4.31436  last_update 19\n",
      "train: iter 332  trainloss 3.56497  validloss 4.47553±0.00000  bestvalidloss 4.31436  last_update 20\n",
      "train: iter 333  trainloss 3.58634  validloss 4.53850±0.00000  bestvalidloss 4.31436  last_update 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 334  trainloss 3.54305  validloss 4.50002±0.00000  bestvalidloss 4.31436  last_update 22\n",
      "train: iter 335  trainloss 3.55136  validloss 4.41029±0.00000  bestvalidloss 4.31436  last_update 23\n",
      "train: iter 336  trainloss 3.50274  validloss 4.45664±0.00000  bestvalidloss 4.31436  last_update 24\n",
      "train: iter 337  trainloss 3.51212  validloss 4.49047±0.00000  bestvalidloss 4.31436  last_update 25\n",
      "train: iter 338  trainloss 3.54063  validloss 4.56231±0.00000  bestvalidloss 4.31436  last_update 26\n",
      "train: iter 339  trainloss 3.51719  validloss 4.37888±0.00000  bestvalidloss 4.31436  last_update 27\n",
      "train: iter 340  trainloss 3.56960  validloss 4.38391±0.00000  bestvalidloss 4.31436  last_update 28\n",
      "train: iter 341  trainloss 3.49395  validloss 4.45019±0.00000  bestvalidloss 4.31436  last_update 29\n",
      "train: iter 342  trainloss 3.60029  validloss 4.39541±0.00000  bestvalidloss 4.31436  last_update 30\n",
      "train: iter 343  trainloss 3.51268  validloss 4.41510±0.00000  bestvalidloss 4.31436  last_update 31\n",
      "train: iter 344  trainloss 3.54094  validloss 4.52647±0.00000  bestvalidloss 4.31436  last_update 32\n",
      "train: iter 345  trainloss 3.60505  validloss 4.51577±0.00000  bestvalidloss 4.31436  last_update 33\n",
      "train: iter 346  trainloss 3.54347  validloss 4.45350±0.00000  bestvalidloss 4.31436  last_update 34\n",
      "train: iter 347  trainloss 3.53776  validloss 4.51204±0.00000  bestvalidloss 4.31436  last_update 35\n",
      "train: iter 348  trainloss 3.51849  validloss 4.45135±0.00000  bestvalidloss 4.31436  last_update 36\n",
      "train: iter 349  trainloss 3.50943  validloss 4.45461±0.00000  bestvalidloss 4.31436  last_update 37\n",
      "train: iter 350  trainloss 3.55681  validloss 4.50926±0.00000  bestvalidloss 4.31436  last_update 38\n",
      "train: iter 351  trainloss 3.50441  validloss 4.33519±0.00000  bestvalidloss 4.31436  last_update 39\n",
      "train: iter 352  trainloss 3.53043  validloss 4.49180±0.00000  bestvalidloss 4.31436  last_update 40\n",
      "train: iter 353  trainloss 3.49514  validloss 4.50302±0.00000  bestvalidloss 4.31436  last_update 41\n",
      "train: iter 354  trainloss 3.55951  validloss 4.43056±0.00000  bestvalidloss 4.31436  last_update 42\n",
      "train: iter 355  trainloss 3.53138  validloss 4.39280±0.00000  bestvalidloss 4.31436  last_update 43\n",
      "train: iter 356  trainloss 3.50712  validloss 4.39046±0.00000  bestvalidloss 4.31436  last_update 44\n",
      "train: iter 357  trainloss 3.52444  validloss 4.50886±0.00000  bestvalidloss 4.31436  last_update 45\n",
      "train: iter 358  trainloss 3.51661  validloss 4.38440±0.00000  bestvalidloss 4.31436  last_update 46\n",
      "train: iter 359  trainloss 3.54484  validloss 4.39320±0.00000  bestvalidloss 4.31436  last_update 47\n",
      "train: iter 360  trainloss 3.54311  validloss 4.63616±0.00000  bestvalidloss 4.31436  last_update 48\n",
      "train: iter 361  trainloss 3.53807  validloss 4.54628±0.00000  bestvalidloss 4.31436  last_update 49\n",
      "train: iter 362  trainloss 3.58396  validloss 4.46868±0.00000  bestvalidloss 4.31436  last_update 50\n",
      "train: iter 363  trainloss 3.53553  validloss 4.58247±0.00000  bestvalidloss 4.31436  last_update 51\n",
      "train: iter 364  trainloss 3.51982  validloss 4.41863±0.00000  bestvalidloss 4.31436  last_update 52\n",
      "train: iter 365  trainloss 3.55001  validloss 4.51725±0.00000  bestvalidloss 4.31436  last_update 53\n",
      "train: iter 366  trainloss 3.53967  validloss 4.40207±0.00000  bestvalidloss 4.31436  last_update 54\n",
      "train: iter 367  trainloss 3.49228  validloss 4.40764±0.00000  bestvalidloss 4.31436  last_update 55\n",
      "train: iter 368  trainloss 3.55872  validloss 4.59842±0.00000  bestvalidloss 4.31436  last_update 56\n",
      "train: iter 369  trainloss 3.50650  validloss 4.35840±0.00000  bestvalidloss 4.31436  last_update 57\n",
      "train: iter 370  trainloss 3.53953  validloss 4.38697±0.00000  bestvalidloss 4.31436  last_update 58\n",
      "train: iter 371  trainloss 3.49658  validloss 4.51699±0.00000  bestvalidloss 4.31436  last_update 59\n",
      "train: iter 372  trainloss 3.53207  validloss 4.51295±0.00000  bestvalidloss 4.31436  last_update 60\n",
      "train: iter 373  trainloss 3.51024  validloss 4.46587±0.00000  bestvalidloss 4.31436  last_update 61\n",
      "train: iter 374  trainloss 3.50488  validloss 4.35576±0.00000  bestvalidloss 4.31436  last_update 62\n",
      "train: iter 375  trainloss 3.55248  validloss 4.58245±0.00000  bestvalidloss 4.31436  last_update 63\n",
      "train: iter 376  trainloss 3.53353  validloss 4.37831±0.00000  bestvalidloss 4.31436  last_update 64\n",
      "train: iter 377  trainloss 3.51382  validloss 4.40614±0.00000  bestvalidloss 4.31436  last_update 65\n",
      "train: iter 378  trainloss 3.56302  validloss 4.43865±0.00000  bestvalidloss 4.31436  last_update 66\n",
      "train: iter 379  trainloss 3.48666  validloss 4.43719±0.00000  bestvalidloss 4.31436  last_update 67\n",
      "train: iter 380  trainloss 3.52568  validloss 4.64894±0.00000  bestvalidloss 4.31436  last_update 68\n",
      "train: iter 381  trainloss 3.52932  validloss 4.38014±0.00000  bestvalidloss 4.31436  last_update 69\n",
      "train: iter 382  trainloss 3.52971  validloss 4.47575±0.00000  bestvalidloss 4.31436  last_update 70\n",
      "train: iter 383  trainloss 3.53201  validloss 4.44823±0.00000  bestvalidloss 4.31436  last_update 71\n",
      "train: iter 384  trainloss 3.54831  validloss 4.38683±0.00000  bestvalidloss 4.31436  last_update 72\n",
      "train: iter 385  trainloss 3.51645  validloss 4.41193±0.00000  bestvalidloss 4.31436  last_update 73\n",
      "train: iter 386  trainloss 3.55151  validloss 4.36016±0.00000  bestvalidloss 4.31436  last_update 74\n",
      "train: iter 387  trainloss 3.54884  validloss 4.45207±0.00000  bestvalidloss 4.31436  last_update 75\n",
      "train: iter 388  trainloss 3.51724  validloss 4.38873±0.00000  bestvalidloss 4.31436  last_update 76\n",
      "train: iter 389  trainloss 3.50973  validloss 4.43069±0.00000  bestvalidloss 4.31436  last_update 77\n",
      "train: iter 390  trainloss 3.49879  validloss 4.44640±0.00000  bestvalidloss 4.31436  last_update 78\n",
      "train: iter 391  trainloss 3.54021  validloss 4.34548±0.00000  bestvalidloss 4.31436  last_update 79\n",
      "train: iter 392  trainloss 3.53698  validloss 4.44976±0.00000  bestvalidloss 4.31436  last_update 80\n",
      "train: iter 393  trainloss 3.49849  validloss 4.40250±0.00000  bestvalidloss 4.31436  last_update 81\n",
      "train: iter 394  trainloss 3.52648  validloss 4.41463±0.00000  bestvalidloss 4.31436  last_update 82\n",
      "train: iter 395  trainloss 3.54838  validloss 4.44097±0.00000  bestvalidloss 4.31436  last_update 83\n",
      "train: iter 396  trainloss 3.59494  validloss 4.50369±0.00000  bestvalidloss 4.31436  last_update 84\n",
      "train: iter 397  trainloss 3.50522  validloss 4.38773±0.00000  bestvalidloss 4.31436  last_update 85\n",
      "train: iter 398  trainloss 3.56651  validloss 4.57766±0.00000  bestvalidloss 4.31436  last_update 86\n",
      "train: iter 399  trainloss 3.47590  validloss 4.36489±0.00000  bestvalidloss 4.31436  last_update 87\n",
      "train: iter 400  trainloss 3.55596  validloss 4.49449±0.00000  bestvalidloss 4.31436  last_update 88\n",
      "train: iter 401  trainloss 3.48552  validloss 4.46140±0.00000  bestvalidloss 4.31436  last_update 89\n",
      "train: iter 402  trainloss 3.52356  validloss 4.50740±0.00000  bestvalidloss 4.31436  last_update 90\n",
      "train: iter 403  trainloss 3.50340  validloss 4.42279±0.00000  bestvalidloss 4.31436  last_update 91\n",
      "train: iter 404  trainloss 3.51295  validloss 4.28700±0.00000  bestvalidloss 4.28700  last_update 0\n",
      "train: iter 405  trainloss 3.53291  validloss 4.42985±0.00000  bestvalidloss 4.28700  last_update 1\n",
      "train: iter 406  trainloss 3.53034  validloss 4.47195±0.00000  bestvalidloss 4.28700  last_update 2\n",
      "train: iter 407  trainloss 3.54522  validloss 4.41109±0.00000  bestvalidloss 4.28700  last_update 3\n",
      "train: iter 408  trainloss 3.50468  validloss 4.36596±0.00000  bestvalidloss 4.28700  last_update 4\n",
      "train: iter 409  trainloss 3.51362  validloss 4.45470±0.00000  bestvalidloss 4.28700  last_update 5\n",
      "train: iter 410  trainloss 3.50392  validloss 4.45689±0.00000  bestvalidloss 4.28700  last_update 6\n",
      "train: iter 411  trainloss 3.49513  validloss 4.38897±0.00000  bestvalidloss 4.28700  last_update 7\n",
      "train: iter 412  trainloss 3.49976  validloss 4.72176±0.00000  bestvalidloss 4.28700  last_update 8\n",
      "train: iter 413  trainloss 3.50829  validloss 4.36003±0.00000  bestvalidloss 4.28700  last_update 9\n",
      "train: iter 414  trainloss 3.52732  validloss 4.42474±0.00000  bestvalidloss 4.28700  last_update 10\n",
      "train: iter 415  trainloss 3.53773  validloss 4.48059±0.00000  bestvalidloss 4.28700  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 416  trainloss 3.53991  validloss 4.37964±0.00000  bestvalidloss 4.28700  last_update 12\n",
      "train: iter 417  trainloss 3.55534  validloss 4.45999±0.00000  bestvalidloss 4.28700  last_update 13\n",
      "train: iter 418  trainloss 3.50984  validloss 4.30775±0.00000  bestvalidloss 4.28700  last_update 14\n",
      "train: iter 419  trainloss 3.54114  validloss 4.52545±0.00000  bestvalidloss 4.28700  last_update 15\n",
      "train: iter 420  trainloss 3.51231  validloss 4.39530±0.00000  bestvalidloss 4.28700  last_update 16\n",
      "train: iter 421  trainloss 3.48050  validloss 4.39717±0.00000  bestvalidloss 4.28700  last_update 17\n",
      "train: iter 422  trainloss 3.50434  validloss 4.40180±0.00000  bestvalidloss 4.28700  last_update 18\n",
      "train: iter 423  trainloss 3.52333  validloss 4.34477±0.00000  bestvalidloss 4.28700  last_update 19\n",
      "train: iter 424  trainloss 3.50119  validloss 4.41615±0.00000  bestvalidloss 4.28700  last_update 20\n",
      "train: iter 425  trainloss 3.53107  validloss 4.45066±0.00000  bestvalidloss 4.28700  last_update 21\n",
      "train: iter 426  trainloss 3.50040  validloss 4.47832±0.00000  bestvalidloss 4.28700  last_update 22\n",
      "train: iter 427  trainloss 3.48955  validloss 4.46635±0.00000  bestvalidloss 4.28700  last_update 23\n",
      "train: iter 428  trainloss 3.51927  validloss 4.33878±0.00000  bestvalidloss 4.28700  last_update 24\n",
      "train: iter 429  trainloss 3.50325  validloss 4.29352±0.00000  bestvalidloss 4.28700  last_update 25\n",
      "train: iter 430  trainloss 3.48695  validloss 4.41059±0.00000  bestvalidloss 4.28700  last_update 26\n",
      "train: iter 431  trainloss 3.49967  validloss 4.40524±0.00000  bestvalidloss 4.28700  last_update 27\n",
      "train: iter 432  trainloss 3.51316  validloss 4.36884±0.00000  bestvalidloss 4.28700  last_update 28\n",
      "train: iter 433  trainloss 3.53364  validloss 4.38560±0.00000  bestvalidloss 4.28700  last_update 29\n",
      "train: iter 434  trainloss 3.48933  validloss 4.44486±0.00000  bestvalidloss 4.28700  last_update 30\n",
      "train: iter 435  trainloss 3.51251  validloss 4.40160±0.00000  bestvalidloss 4.28700  last_update 31\n",
      "train: iter 436  trainloss 3.51607  validloss 4.43610±0.00000  bestvalidloss 4.28700  last_update 32\n",
      "train: iter 437  trainloss 3.50744  validloss 4.33415±0.00000  bestvalidloss 4.28700  last_update 33\n",
      "train: iter 438  trainloss 3.56015  validloss 4.36267±0.00000  bestvalidloss 4.28700  last_update 34\n",
      "train: iter 439  trainloss 3.49183  validloss 4.60358±0.00000  bestvalidloss 4.28700  last_update 35\n",
      "train: iter 440  trainloss 3.48275  validloss 4.54923±0.00000  bestvalidloss 4.28700  last_update 36\n",
      "train: iter 441  trainloss 3.50500  validloss 4.41273±0.00000  bestvalidloss 4.28700  last_update 37\n",
      "train: iter 442  trainloss 3.46494  validloss 4.35915±0.00000  bestvalidloss 4.28700  last_update 38\n",
      "train: iter 443  trainloss 3.51157  validloss 4.41053±0.00000  bestvalidloss 4.28700  last_update 39\n",
      "train: iter 444  trainloss 3.51646  validloss 4.45330±0.00000  bestvalidloss 4.28700  last_update 40\n",
      "train: iter 445  trainloss 3.52039  validloss 4.43156±0.00000  bestvalidloss 4.28700  last_update 41\n",
      "train: iter 446  trainloss 3.51124  validloss 4.37639±0.00000  bestvalidloss 4.28700  last_update 42\n",
      "train: iter 447  trainloss 3.52163  validloss 4.40271±0.00000  bestvalidloss 4.28700  last_update 43\n",
      "train: iter 448  trainloss 3.51033  validloss 4.37203±0.00000  bestvalidloss 4.28700  last_update 44\n",
      "train: iter 449  trainloss 3.51826  validloss 4.36273±0.00000  bestvalidloss 4.28700  last_update 45\n",
      "train: iter 450  trainloss 3.48772  validloss 4.40165±0.00000  bestvalidloss 4.28700  last_update 46\n",
      "train: iter 451  trainloss 3.49799  validloss 4.50077±0.00000  bestvalidloss 4.28700  last_update 47\n",
      "train: iter 452  trainloss 3.53513  validloss 4.47307±0.00000  bestvalidloss 4.28700  last_update 48\n",
      "train: iter 453  trainloss 3.49786  validloss 4.42110±0.00000  bestvalidloss 4.28700  last_update 49\n",
      "train: iter 454  trainloss 3.53829  validloss 4.47627±0.00000  bestvalidloss 4.28700  last_update 50\n",
      "train: iter 455  trainloss 3.52565  validloss 4.44681±0.00000  bestvalidloss 4.28700  last_update 51\n",
      "train: iter 456  trainloss 3.52666  validloss 4.65639±0.00000  bestvalidloss 4.28700  last_update 52\n",
      "train: iter 457  trainloss 3.47069  validloss 4.37547±0.00000  bestvalidloss 4.28700  last_update 53\n",
      "train: iter 458  trainloss 3.54713  validloss 4.52966±0.00000  bestvalidloss 4.28700  last_update 54\n",
      "train: iter 459  trainloss 3.52410  validloss 4.33183±0.00000  bestvalidloss 4.28700  last_update 55\n",
      "train: iter 460  trainloss 3.48401  validloss 4.45981±0.00000  bestvalidloss 4.28700  last_update 56\n",
      "train: iter 461  trainloss 3.49605  validloss 4.43100±0.00000  bestvalidloss 4.28700  last_update 57\n",
      "train: iter 462  trainloss 3.54075  validloss 4.42377±0.00000  bestvalidloss 4.28700  last_update 58\n",
      "train: iter 463  trainloss 3.49918  validloss 4.32660±0.00000  bestvalidloss 4.28700  last_update 59\n",
      "train: iter 464  trainloss 3.51530  validloss 4.50206±0.00000  bestvalidloss 4.28700  last_update 60\n",
      "train: iter 465  trainloss 3.47808  validloss 4.44066±0.00000  bestvalidloss 4.28700  last_update 61\n",
      "train: iter 466  trainloss 3.48102  validloss 4.39606±0.00000  bestvalidloss 4.28700  last_update 62\n",
      "train: iter 467  trainloss 3.50294  validloss 4.43185±0.00000  bestvalidloss 4.28700  last_update 63\n",
      "train: iter 468  trainloss 3.48987  validloss 4.37290±0.00000  bestvalidloss 4.28700  last_update 64\n",
      "train: iter 469  trainloss 3.50064  validloss 4.39273±0.00000  bestvalidloss 4.28700  last_update 65\n",
      "train: iter 470  trainloss 3.53675  validloss 4.37331±0.00000  bestvalidloss 4.28700  last_update 66\n",
      "train: iter 471  trainloss 3.51172  validloss 4.54484±0.00000  bestvalidloss 4.28700  last_update 67\n",
      "train: iter 472  trainloss 3.45531  validloss 4.38371±0.00000  bestvalidloss 4.28700  last_update 68\n",
      "train: iter 473  trainloss 3.48262  validloss 4.37360±0.00000  bestvalidloss 4.28700  last_update 69\n",
      "train: iter 474  trainloss 3.50055  validloss 4.41814±0.00000  bestvalidloss 4.28700  last_update 70\n",
      "train: iter 475  trainloss 3.48955  validloss 4.40577±0.00000  bestvalidloss 4.28700  last_update 71\n",
      "train: iter 476  trainloss 3.59525  validloss 4.52438±0.00000  bestvalidloss 4.28700  last_update 72\n",
      "train: iter 477  trainloss 3.52662  validloss 4.35744±0.00000  bestvalidloss 4.28700  last_update 73\n",
      "train: iter 478  trainloss 3.47848  validloss 4.34314±0.00000  bestvalidloss 4.28700  last_update 74\n",
      "train: iter 479  trainloss 3.49944  validloss 4.54759±0.00000  bestvalidloss 4.28700  last_update 75\n",
      "train: iter 480  trainloss 3.48530  validloss 4.48754±0.00000  bestvalidloss 4.28700  last_update 76\n",
      "train: iter 481  trainloss 3.54638  validloss 4.41217±0.00000  bestvalidloss 4.28700  last_update 77\n",
      "train: iter 482  trainloss 3.47678  validloss 4.35736±0.00000  bestvalidloss 4.28700  last_update 78\n",
      "train: iter 483  trainloss 3.48902  validloss 4.37528±0.00000  bestvalidloss 4.28700  last_update 79\n",
      "train: iter 484  trainloss 3.55285  validloss 4.33380±0.00000  bestvalidloss 4.28700  last_update 80\n",
      "train: iter 485  trainloss 3.52704  validloss 4.38074±0.00000  bestvalidloss 4.28700  last_update 81\n",
      "train: iter 486  trainloss 3.49011  validloss 4.39439±0.00000  bestvalidloss 4.28700  last_update 82\n",
      "train: iter 487  trainloss 3.51037  validloss 4.43527±0.00000  bestvalidloss 4.28700  last_update 83\n",
      "train: iter 488  trainloss 3.48303  validloss 4.35586±0.00000  bestvalidloss 4.28700  last_update 84\n",
      "train: iter 489  trainloss 3.47789  validloss 4.45280±0.00000  bestvalidloss 4.28700  last_update 85\n",
      "train: iter 490  trainloss 3.51901  validloss 4.31911±0.00000  bestvalidloss 4.28700  last_update 86\n",
      "train: iter 491  trainloss 3.48221  validloss 4.45861±0.00000  bestvalidloss 4.28700  last_update 87\n",
      "train: iter 492  trainloss 3.49901  validloss 4.38518±0.00000  bestvalidloss 4.28700  last_update 88\n",
      "train: iter 493  trainloss 3.48872  validloss 4.27546±0.00000  bestvalidloss 4.27546  last_update 0\n",
      "train: iter 494  trainloss 3.52188  validloss 4.39879±0.00000  bestvalidloss 4.27546  last_update 1\n",
      "train: iter 495  trainloss 3.51836  validloss 4.40174±0.00000  bestvalidloss 4.27546  last_update 2\n",
      "train: iter 496  trainloss 3.44753  validloss 4.38171±0.00000  bestvalidloss 4.27546  last_update 3\n",
      "train: iter 497  trainloss 3.49462  validloss 4.41432±0.00000  bestvalidloss 4.27546  last_update 4\n",
      "train: iter 498  trainloss 3.48541  validloss 4.36021±0.00000  bestvalidloss 4.27546  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 499  trainloss 3.46354  validloss 4.49746±0.00000  bestvalidloss 4.27546  last_update 6\n",
      "train: iter 500  trainloss 3.46539  validloss 4.48211±0.00000  bestvalidloss 4.27546  last_update 7\n",
      "train: iter 501  trainloss 3.53280  validloss 4.38784±0.00000  bestvalidloss 4.27546  last_update 8\n",
      "train: iter 502  trainloss 3.51472  validloss 4.58793±0.00000  bestvalidloss 4.27546  last_update 9\n",
      "train: iter 503  trainloss 3.47618  validloss 4.26614±0.00000  bestvalidloss 4.26614  last_update 0\n",
      "train: iter 504  trainloss 3.48440  validloss 4.52019±0.00000  bestvalidloss 4.26614  last_update 1\n",
      "train: iter 505  trainloss 3.52350  validloss 4.59657±0.00000  bestvalidloss 4.26614  last_update 2\n",
      "train: iter 506  trainloss 3.51159  validloss 4.42299±0.00000  bestvalidloss 4.26614  last_update 3\n",
      "train: iter 507  trainloss 3.48170  validloss 4.31945±0.00000  bestvalidloss 4.26614  last_update 4\n",
      "train: iter 508  trainloss 3.49013  validloss 4.44931±0.00000  bestvalidloss 4.26614  last_update 5\n",
      "train: iter 509  trainloss 3.48015  validloss 4.44968±0.00000  bestvalidloss 4.26614  last_update 6\n",
      "train: iter 510  trainloss 3.51540  validloss 4.45040±0.00000  bestvalidloss 4.26614  last_update 7\n",
      "train: iter 511  trainloss 3.46525  validloss 4.42286±0.00000  bestvalidloss 4.26614  last_update 8\n",
      "train: iter 512  trainloss 3.53151  validloss 4.37791±0.00000  bestvalidloss 4.26614  last_update 9\n",
      "train: iter 513  trainloss 3.52633  validloss 4.35196±0.00000  bestvalidloss 4.26614  last_update 10\n",
      "train: iter 514  trainloss 3.49627  validloss 4.28129±0.00000  bestvalidloss 4.26614  last_update 11\n",
      "train: iter 515  trainloss 3.45980  validloss 4.36150±0.00000  bestvalidloss 4.26614  last_update 12\n",
      "train: iter 516  trainloss 3.51217  validloss 4.37738±0.00000  bestvalidloss 4.26614  last_update 13\n",
      "train: iter 517  trainloss 3.48344  validloss 4.30451±0.00000  bestvalidloss 4.26614  last_update 14\n",
      "train: iter 518  trainloss 3.49803  validloss 4.29546±0.00000  bestvalidloss 4.26614  last_update 15\n",
      "train: iter 519  trainloss 3.55211  validloss 4.40900±0.00000  bestvalidloss 4.26614  last_update 16\n",
      "train: iter 520  trainloss 3.47171  validloss 4.37750±0.00000  bestvalidloss 4.26614  last_update 17\n",
      "train: iter 521  trainloss 3.50286  validloss 4.36015±0.00000  bestvalidloss 4.26614  last_update 18\n",
      "train: iter 522  trainloss 3.52344  validloss 4.47466±0.00000  bestvalidloss 4.26614  last_update 19\n",
      "train: iter 523  trainloss 3.47432  validloss 4.32961±0.00000  bestvalidloss 4.26614  last_update 20\n",
      "train: iter 524  trainloss 3.45325  validloss 4.38464±0.00000  bestvalidloss 4.26614  last_update 21\n",
      "train: iter 525  trainloss 3.47575  validloss 4.60097±0.00000  bestvalidloss 4.26614  last_update 22\n",
      "train: iter 526  trainloss 3.57800  validloss 4.36468±0.00000  bestvalidloss 4.26614  last_update 23\n",
      "train: iter 527  trainloss 3.47232  validloss 4.47431±0.00000  bestvalidloss 4.26614  last_update 24\n",
      "train: iter 528  trainloss 3.54441  validloss 4.40566±0.00000  bestvalidloss 4.26614  last_update 25\n",
      "train: iter 529  trainloss 3.48993  validloss 4.42767±0.00000  bestvalidloss 4.26614  last_update 26\n",
      "train: iter 530  trainloss 3.48842  validloss 4.44982±0.00000  bestvalidloss 4.26614  last_update 27\n",
      "train: iter 531  trainloss 3.48713  validloss 4.55595±0.00000  bestvalidloss 4.26614  last_update 28\n",
      "train: iter 532  trainloss 3.45702  validloss 4.47215±0.00000  bestvalidloss 4.26614  last_update 29\n",
      "train: iter 533  trainloss 3.50610  validloss 4.32957±0.00000  bestvalidloss 4.26614  last_update 30\n",
      "train: iter 534  trainloss 3.48633  validloss 4.47519±0.00000  bestvalidloss 4.26614  last_update 31\n",
      "train: iter 535  trainloss 3.49251  validloss 4.36267±0.00000  bestvalidloss 4.26614  last_update 32\n",
      "train: iter 536  trainloss 3.54229  validloss 4.38100±0.00000  bestvalidloss 4.26614  last_update 33\n",
      "train: iter 537  trainloss 3.46677  validloss 4.36021±0.00000  bestvalidloss 4.26614  last_update 34\n",
      "train: iter 538  trainloss 3.49304  validloss 4.41250±0.00000  bestvalidloss 4.26614  last_update 35\n",
      "train: iter 539  trainloss 3.51264  validloss 4.36900±0.00000  bestvalidloss 4.26614  last_update 36\n",
      "train: iter 540  trainloss 3.45768  validloss 4.36894±0.00000  bestvalidloss 4.26614  last_update 37\n",
      "train: iter 541  trainloss 3.46474  validloss 4.42231±0.00000  bestvalidloss 4.26614  last_update 38\n",
      "train: iter 542  trainloss 3.46096  validloss 4.28328±0.00000  bestvalidloss 4.26614  last_update 39\n",
      "train: iter 543  trainloss 3.47730  validloss 4.42401±0.00000  bestvalidloss 4.26614  last_update 40\n",
      "train: iter 544  trainloss 3.46352  validloss 4.31928±0.00000  bestvalidloss 4.26614  last_update 41\n",
      "train: iter 545  trainloss 3.47738  validloss 4.42934±0.00000  bestvalidloss 4.26614  last_update 42\n",
      "train: iter 546  trainloss 3.48098  validloss 4.41429±0.00000  bestvalidloss 4.26614  last_update 43\n",
      "train: iter 547  trainloss 3.49602  validloss 4.31028±0.00000  bestvalidloss 4.26614  last_update 44\n",
      "train: iter 548  trainloss 3.49544  validloss 4.25920±0.00000  bestvalidloss 4.25920  last_update 0\n",
      "train: iter 549  trainloss 3.53239  validloss 4.42666±0.00000  bestvalidloss 4.25920  last_update 1\n",
      "train: iter 550  trainloss 3.48971  validloss 4.42961±0.00000  bestvalidloss 4.25920  last_update 2\n",
      "train: iter 551  trainloss 3.46003  validloss 4.47175±0.00000  bestvalidloss 4.25920  last_update 3\n",
      "train: iter 552  trainloss 3.43820  validloss 4.41867±0.00000  bestvalidloss 4.25920  last_update 4\n",
      "train: iter 553  trainloss 3.48421  validloss 4.38765±0.00000  bestvalidloss 4.25920  last_update 5\n",
      "train: iter 554  trainloss 3.50111  validloss 4.41072±0.00000  bestvalidloss 4.25920  last_update 6\n",
      "train: iter 555  trainloss 3.53164  validloss 4.44138±0.00000  bestvalidloss 4.25920  last_update 7\n",
      "train: iter 556  trainloss 3.48043  validloss 4.32781±0.00000  bestvalidloss 4.25920  last_update 8\n",
      "train: iter 557  trainloss 3.46274  validloss 4.40582±0.00000  bestvalidloss 4.25920  last_update 9\n",
      "train: iter 558  trainloss 3.48059  validloss 4.36920±0.00000  bestvalidloss 4.25920  last_update 10\n",
      "train: iter 559  trainloss 3.48468  validloss 4.43382±0.00000  bestvalidloss 4.25920  last_update 11\n",
      "train: iter 560  trainloss 3.47463  validloss 4.33741±0.00000  bestvalidloss 4.25920  last_update 12\n",
      "train: iter 561  trainloss 3.48149  validloss 4.36961±0.00000  bestvalidloss 4.25920  last_update 13\n",
      "train: iter 562  trainloss 3.45589  validloss 4.42074±0.00000  bestvalidloss 4.25920  last_update 14\n",
      "train: iter 563  trainloss 3.48982  validloss 4.44148±0.00000  bestvalidloss 4.25920  last_update 15\n",
      "train: iter 564  trainloss 3.44570  validloss 4.38653±0.00000  bestvalidloss 4.25920  last_update 16\n",
      "train: iter 565  trainloss 3.47140  validloss 4.31902±0.00000  bestvalidloss 4.25920  last_update 17\n",
      "train: iter 566  trainloss 3.50680  validloss 4.35070±0.00000  bestvalidloss 4.25920  last_update 18\n",
      "train: iter 567  trainloss 3.49482  validloss 4.32709±0.00000  bestvalidloss 4.25920  last_update 19\n",
      "train: iter 568  trainloss 3.46496  validloss 4.44546±0.00000  bestvalidloss 4.25920  last_update 20\n",
      "train: iter 569  trainloss 3.51642  validloss 4.51636±0.00000  bestvalidloss 4.25920  last_update 21\n",
      "train: iter 570  trainloss 3.53257  validloss 4.41125±0.00000  bestvalidloss 4.25920  last_update 22\n",
      "train: iter 571  trainloss 3.48871  validloss 4.47780±0.00000  bestvalidloss 4.25920  last_update 23\n",
      "train: iter 572  trainloss 3.47914  validloss 4.45884±0.00000  bestvalidloss 4.25920  last_update 24\n",
      "train: iter 573  trainloss 3.46494  validloss 4.41647±0.00000  bestvalidloss 4.25920  last_update 25\n",
      "train: iter 574  trainloss 3.45604  validloss 4.44635±0.00000  bestvalidloss 4.25920  last_update 26\n",
      "train: iter 575  trainloss 3.44978  validloss 4.48204±0.00000  bestvalidloss 4.25920  last_update 27\n",
      "train: iter 576  trainloss 3.46456  validloss 4.31310±0.00000  bestvalidloss 4.25920  last_update 28\n",
      "train: iter 577  trainloss 3.47826  validloss 4.42169±0.00000  bestvalidloss 4.25920  last_update 29\n",
      "train: iter 578  trainloss 3.47914  validloss 4.42596±0.00000  bestvalidloss 4.25920  last_update 30\n",
      "train: iter 579  trainloss 3.51569  validloss 4.38016±0.00000  bestvalidloss 4.25920  last_update 31\n",
      "train: iter 580  trainloss 3.47247  validloss 4.41956±0.00000  bestvalidloss 4.25920  last_update 32\n",
      "train: iter 581  trainloss 3.43544  validloss 4.38762±0.00000  bestvalidloss 4.25920  last_update 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 582  trainloss 3.48493  validloss 4.51172±0.00000  bestvalidloss 4.25920  last_update 34\n",
      "train: iter 583  trainloss 3.47067  validloss 4.36160±0.00000  bestvalidloss 4.25920  last_update 35\n",
      "train: iter 584  trainloss 3.46930  validloss 4.35236±0.00000  bestvalidloss 4.25920  last_update 36\n",
      "train: iter 585  trainloss 3.49814  validloss 4.32570±0.00000  bestvalidloss 4.25920  last_update 37\n",
      "train: iter 586  trainloss 3.48781  validloss 4.60709±0.00000  bestvalidloss 4.25920  last_update 38\n",
      "train: iter 587  trainloss 3.47950  validloss 4.47252±0.00000  bestvalidloss 4.25920  last_update 39\n",
      "train: iter 588  trainloss 3.46787  validloss 4.55507±0.00000  bestvalidloss 4.25920  last_update 40\n",
      "train: iter 589  trainloss 3.46224  validloss 4.30495±0.00000  bestvalidloss 4.25920  last_update 41\n",
      "train: iter 590  trainloss 3.48603  validloss 4.34680±0.00000  bestvalidloss 4.25920  last_update 42\n",
      "train: iter 591  trainloss 3.44419  validloss 4.39151±0.00000  bestvalidloss 4.25920  last_update 43\n",
      "train: iter 592  trainloss 3.44683  validloss 4.44288±0.00000  bestvalidloss 4.25920  last_update 44\n",
      "train: iter 593  trainloss 3.47664  validloss 4.46535±0.00000  bestvalidloss 4.25920  last_update 45\n",
      "train: iter 594  trainloss 3.43698  validloss 4.35298±0.00000  bestvalidloss 4.25920  last_update 46\n",
      "train: iter 595  trainloss 3.49748  validloss 4.54807±0.00000  bestvalidloss 4.25920  last_update 47\n",
      "train: iter 596  trainloss 3.45988  validloss 4.42101±0.00000  bestvalidloss 4.25920  last_update 48\n",
      "train: iter 597  trainloss 3.51857  validloss 4.30416±0.00000  bestvalidloss 4.25920  last_update 49\n",
      "train: iter 598  trainloss 3.52358  validloss 4.53002±0.00000  bestvalidloss 4.25920  last_update 50\n",
      "train: iter 599  trainloss 3.45135  validloss 4.29181±0.00000  bestvalidloss 4.25920  last_update 51\n",
      "train: iter 600  trainloss 3.50952  validloss 4.56241±0.00000  bestvalidloss 4.25920  last_update 52\n",
      "train: iter 601  trainloss 3.50908  validloss 4.45811±0.00000  bestvalidloss 4.25920  last_update 53\n",
      "train: iter 602  trainloss 3.45829  validloss 4.31720±0.00000  bestvalidloss 4.25920  last_update 54\n",
      "train: iter 603  trainloss 3.48347  validloss 4.34761±0.00000  bestvalidloss 4.25920  last_update 55\n",
      "train: iter 604  trainloss 3.49031  validloss 4.34314±0.00000  bestvalidloss 4.25920  last_update 56\n",
      "train: iter 605  trainloss 3.53490  validloss 4.52368±0.00000  bestvalidloss 4.25920  last_update 57\n",
      "train: iter 606  trainloss 3.50249  validloss 4.45424±0.00000  bestvalidloss 4.25920  last_update 58\n",
      "train: iter 607  trainloss 3.45832  validloss 4.38680±0.00000  bestvalidloss 4.25920  last_update 59\n",
      "train: iter 608  trainloss 3.46185  validloss 4.49804±0.00000  bestvalidloss 4.25920  last_update 60\n",
      "train: iter 609  trainloss 3.49679  validloss 4.49772±0.00000  bestvalidloss 4.25920  last_update 61\n",
      "train: iter 610  trainloss 3.45781  validloss 4.37453±0.00000  bestvalidloss 4.25920  last_update 62\n",
      "train: iter 611  trainloss 3.49928  validloss 4.50995±0.00000  bestvalidloss 4.25920  last_update 63\n",
      "train: iter 612  trainloss 3.46382  validloss 4.23236±0.00000  bestvalidloss 4.23236  last_update 0\n",
      "train: iter 613  trainloss 3.47765  validloss 4.27701±0.00000  bestvalidloss 4.23236  last_update 1\n",
      "train: iter 614  trainloss 3.48376  validloss 4.26239±0.00000  bestvalidloss 4.23236  last_update 2\n",
      "train: iter 615  trainloss 3.47551  validloss 4.31619±0.00000  bestvalidloss 4.23236  last_update 3\n",
      "train: iter 616  trainloss 3.48431  validloss 4.36098±0.00000  bestvalidloss 4.23236  last_update 4\n",
      "train: iter 617  trainloss 3.50162  validloss 4.28688±0.00000  bestvalidloss 4.23236  last_update 5\n",
      "train: iter 618  trainloss 3.48979  validloss 4.31117±0.00000  bestvalidloss 4.23236  last_update 6\n",
      "train: iter 619  trainloss 3.48433  validloss 4.38275±0.00000  bestvalidloss 4.23236  last_update 7\n",
      "train: iter 620  trainloss 3.48864  validloss 4.37106±0.00000  bestvalidloss 4.23236  last_update 8\n",
      "train: iter 621  trainloss 3.43189  validloss 4.28485±0.00000  bestvalidloss 4.23236  last_update 9\n",
      "train: iter 622  trainloss 3.48838  validloss 4.34690±0.00000  bestvalidloss 4.23236  last_update 10\n",
      "train: iter 623  trainloss 3.48941  validloss 4.43278±0.00000  bestvalidloss 4.23236  last_update 11\n",
      "train: iter 624  trainloss 3.44339  validloss 4.44269±0.00000  bestvalidloss 4.23236  last_update 12\n",
      "train: iter 625  trainloss 3.47748  validloss 4.37059±0.00000  bestvalidloss 4.23236  last_update 13\n",
      "train: iter 626  trainloss 3.45708  validloss 4.34272±0.00000  bestvalidloss 4.23236  last_update 14\n",
      "train: iter 627  trainloss 3.45301  validloss 4.47563±0.00000  bestvalidloss 4.23236  last_update 15\n",
      "train: iter 628  trainloss 3.48201  validloss 4.46213±0.00000  bestvalidloss 4.23236  last_update 16\n",
      "train: iter 629  trainloss 3.43982  validloss 4.31262±0.00000  bestvalidloss 4.23236  last_update 17\n",
      "train: iter 630  trainloss 3.45191  validloss 4.44550±0.00000  bestvalidloss 4.23236  last_update 18\n",
      "train: iter 631  trainloss 3.54250  validloss 4.38009±0.00000  bestvalidloss 4.23236  last_update 19\n",
      "train: iter 632  trainloss 3.43826  validloss 4.39192±0.00000  bestvalidloss 4.23236  last_update 20\n",
      "train: iter 633  trainloss 3.48081  validloss 4.41068±0.00000  bestvalidloss 4.23236  last_update 21\n",
      "train: iter 634  trainloss 3.43122  validloss 4.31794±0.00000  bestvalidloss 4.23236  last_update 22\n",
      "train: iter 635  trainloss 3.48345  validloss 4.40715±0.00000  bestvalidloss 4.23236  last_update 23\n",
      "train: iter 636  trainloss 3.46998  validloss 4.44609±0.00000  bestvalidloss 4.23236  last_update 24\n",
      "train: iter 637  trainloss 3.44223  validloss 4.31753±0.00000  bestvalidloss 4.23236  last_update 25\n",
      "train: iter 638  trainloss 3.47547  validloss 4.34448±0.00000  bestvalidloss 4.23236  last_update 26\n",
      "train: iter 639  trainloss 3.47501  validloss 4.28043±0.00000  bestvalidloss 4.23236  last_update 27\n",
      "train: iter 640  trainloss 3.47347  validloss 4.34516±0.00000  bestvalidloss 4.23236  last_update 28\n",
      "train: iter 641  trainloss 3.50320  validloss 4.36967±0.00000  bestvalidloss 4.23236  last_update 29\n",
      "train: iter 642  trainloss 3.48140  validloss 4.32110±0.00000  bestvalidloss 4.23236  last_update 30\n",
      "train: iter 643  trainloss 3.48046  validloss 4.46128±0.00000  bestvalidloss 4.23236  last_update 31\n",
      "train: iter 644  trainloss 3.48847  validloss 4.29960±0.00000  bestvalidloss 4.23236  last_update 32\n",
      "train: iter 645  trainloss 3.44549  validloss 4.41151±0.00000  bestvalidloss 4.23236  last_update 33\n",
      "train: iter 646  trainloss 3.46396  validloss 4.29392±0.00000  bestvalidloss 4.23236  last_update 34\n",
      "train: iter 647  trainloss 3.45796  validloss 4.41377±0.00000  bestvalidloss 4.23236  last_update 35\n",
      "train: iter 648  trainloss 3.50830  validloss 4.24987±0.00000  bestvalidloss 4.23236  last_update 36\n",
      "train: iter 649  trainloss 3.43632  validloss 4.51023±0.00000  bestvalidloss 4.23236  last_update 37\n",
      "train: iter 650  trainloss 3.45363  validloss 4.40957±0.00000  bestvalidloss 4.23236  last_update 38\n",
      "train: iter 651  trainloss 3.46461  validloss 4.43006±0.00000  bestvalidloss 4.23236  last_update 39\n",
      "train: iter 652  trainloss 3.42651  validloss 4.28348±0.00000  bestvalidloss 4.23236  last_update 40\n",
      "train: iter 653  trainloss 3.46685  validloss 4.36079±0.00000  bestvalidloss 4.23236  last_update 41\n",
      "train: iter 654  trainloss 3.44552  validloss 4.37653±0.00000  bestvalidloss 4.23236  last_update 42\n",
      "train: iter 655  trainloss 3.46373  validloss 4.38198±0.00000  bestvalidloss 4.23236  last_update 43\n",
      "train: iter 656  trainloss 3.50227  validloss 4.24880±0.00000  bestvalidloss 4.23236  last_update 44\n",
      "train: iter 657  trainloss 3.39717  validloss 4.39260±0.00000  bestvalidloss 4.23236  last_update 45\n",
      "train: iter 658  trainloss 3.47418  validloss 4.63983±0.00000  bestvalidloss 4.23236  last_update 46\n",
      "train: iter 659  trainloss 3.44479  validloss 4.37849±0.00000  bestvalidloss 4.23236  last_update 47\n",
      "train: iter 660  trainloss 3.47995  validloss 4.32344±0.00000  bestvalidloss 4.23236  last_update 48\n",
      "train: iter 661  trainloss 3.48563  validloss 4.41244±0.00000  bestvalidloss 4.23236  last_update 49\n",
      "train: iter 662  trainloss 3.45531  validloss 4.30936±0.00000  bestvalidloss 4.23236  last_update 50\n",
      "train: iter 663  trainloss 3.46325  validloss 4.42901±0.00000  bestvalidloss 4.23236  last_update 51\n",
      "train: iter 664  trainloss 3.44518  validloss 4.40382±0.00000  bestvalidloss 4.23236  last_update 52\n",
      "train: iter 665  trainloss 3.48110  validloss 4.53122±0.00000  bestvalidloss 4.23236  last_update 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 666  trainloss 3.48582  validloss 4.37865±0.00000  bestvalidloss 4.23236  last_update 54\n",
      "train: iter 667  trainloss 3.44912  validloss 4.44099±0.00000  bestvalidloss 4.23236  last_update 55\n",
      "train: iter 668  trainloss 3.50324  validloss 4.57591±0.00000  bestvalidloss 4.23236  last_update 56\n",
      "train: iter 669  trainloss 3.47652  validloss 4.38032±0.00000  bestvalidloss 4.23236  last_update 57\n",
      "train: iter 670  trainloss 3.47875  validloss 4.48903±0.00000  bestvalidloss 4.23236  last_update 58\n",
      "train: iter 671  trainloss 3.49043  validloss 4.48785±0.00000  bestvalidloss 4.23236  last_update 59\n",
      "train: iter 672  trainloss 3.46860  validloss 4.52599±0.00000  bestvalidloss 4.23236  last_update 60\n",
      "train: iter 673  trainloss 3.47987  validloss 4.42824±0.00000  bestvalidloss 4.23236  last_update 61\n",
      "train: iter 674  trainloss 3.44435  validloss 4.37930±0.00000  bestvalidloss 4.23236  last_update 62\n",
      "train: iter 675  trainloss 3.45015  validloss 4.60978±0.00000  bestvalidloss 4.23236  last_update 63\n",
      "train: iter 676  trainloss 3.48433  validloss 4.46038±0.00000  bestvalidloss 4.23236  last_update 64\n",
      "train: iter 677  trainloss 3.47148  validloss 4.34885±0.00000  bestvalidloss 4.23236  last_update 65\n",
      "train: iter 678  trainloss 3.43307  validloss 4.33097±0.00000  bestvalidloss 4.23236  last_update 66\n",
      "train: iter 679  trainloss 3.46535  validloss 4.52382±0.00000  bestvalidloss 4.23236  last_update 67\n",
      "train: iter 680  trainloss 3.45599  validloss 4.40844±0.00000  bestvalidloss 4.23236  last_update 68\n",
      "train: iter 681  trainloss 3.50101  validloss 4.47785±0.00000  bestvalidloss 4.23236  last_update 69\n",
      "train: iter 682  trainloss 3.47429  validloss 4.34565±0.00000  bestvalidloss 4.23236  last_update 70\n",
      "train: iter 683  trainloss 3.44612  validloss 4.45667±0.00000  bestvalidloss 4.23236  last_update 71\n",
      "train: iter 684  trainloss 3.46078  validloss 4.37470±0.00000  bestvalidloss 4.23236  last_update 72\n",
      "train: iter 685  trainloss 3.45121  validloss 4.49330±0.00000  bestvalidloss 4.23236  last_update 73\n",
      "train: iter 686  trainloss 3.52225  validloss 4.57877±0.00000  bestvalidloss 4.23236  last_update 74\n",
      "train: iter 687  trainloss 3.43326  validloss 4.42862±0.00000  bestvalidloss 4.23236  last_update 75\n",
      "train: iter 688  trainloss 3.51708  validloss 4.30790±0.00000  bestvalidloss 4.23236  last_update 76\n",
      "train: iter 689  trainloss 3.46584  validloss 4.59193±0.00000  bestvalidloss 4.23236  last_update 77\n",
      "train: iter 690  trainloss 3.47333  validloss 4.33200±0.00000  bestvalidloss 4.23236  last_update 78\n",
      "train: iter 691  trainloss 3.46917  validloss 4.30123±0.00000  bestvalidloss 4.23236  last_update 79\n",
      "train: iter 692  trainloss 3.43682  validloss 4.43843±0.00000  bestvalidloss 4.23236  last_update 80\n",
      "train: iter 693  trainloss 3.45513  validloss 4.32235±0.00000  bestvalidloss 4.23236  last_update 81\n",
      "train: iter 694  trainloss 3.45117  validloss 4.26270±0.00000  bestvalidloss 4.23236  last_update 82\n",
      "train: iter 695  trainloss 3.45453  validloss 4.36842±0.00000  bestvalidloss 4.23236  last_update 83\n",
      "train: iter 696  trainloss 3.46759  validloss 4.18941±0.00000  bestvalidloss 4.18941  last_update 0\n",
      "train: iter 697  trainloss 3.43847  validloss 4.32721±0.00000  bestvalidloss 4.18941  last_update 1\n",
      "train: iter 698  trainloss 3.49544  validloss 4.35657±0.00000  bestvalidloss 4.18941  last_update 2\n",
      "train: iter 699  trainloss 3.46738  validloss 4.52604±0.00000  bestvalidloss 4.18941  last_update 3\n",
      "train: iter 700  trainloss 3.44854  validloss 4.45838±0.00000  bestvalidloss 4.18941  last_update 4\n",
      "train: iter 701  trainloss 3.43817  validloss 4.33094±0.00000  bestvalidloss 4.18941  last_update 5\n",
      "train: iter 702  trainloss 3.44861  validloss 4.33296±0.00000  bestvalidloss 4.18941  last_update 6\n",
      "train: iter 703  trainloss 3.46482  validloss 4.49745±0.00000  bestvalidloss 4.18941  last_update 7\n",
      "train: iter 704  trainloss 3.46962  validloss 4.49397±0.00000  bestvalidloss 4.18941  last_update 8\n",
      "train: iter 705  trainloss 3.46844  validloss 4.28397±0.00000  bestvalidloss 4.18941  last_update 9\n",
      "train: iter 706  trainloss 3.44710  validloss 4.34556±0.00000  bestvalidloss 4.18941  last_update 10\n",
      "train: iter 707  trainloss 3.45914  validloss 4.25546±0.00000  bestvalidloss 4.18941  last_update 11\n",
      "train: iter 708  trainloss 3.43870  validloss 4.38038±0.00000  bestvalidloss 4.18941  last_update 12\n",
      "train: iter 709  trainloss 3.48489  validloss 4.38458±0.00000  bestvalidloss 4.18941  last_update 13\n",
      "train: iter 710  trainloss 3.50471  validloss 4.34054±0.00000  bestvalidloss 4.18941  last_update 14\n",
      "train: iter 711  trainloss 3.45656  validloss 4.41863±0.00000  bestvalidloss 4.18941  last_update 15\n",
      "train: iter 712  trainloss 3.46499  validloss 4.34119±0.00000  bestvalidloss 4.18941  last_update 16\n",
      "train: iter 713  trainloss 3.43018  validloss 4.36922±0.00000  bestvalidloss 4.18941  last_update 17\n",
      "train: iter 714  trainloss 3.54104  validloss 4.25276±0.00000  bestvalidloss 4.18941  last_update 18\n",
      "train: iter 715  trainloss 3.44038  validloss 4.22489±0.00000  bestvalidloss 4.18941  last_update 19\n",
      "train: iter 716  trainloss 3.42311  validloss 4.37935±0.00000  bestvalidloss 4.18941  last_update 20\n",
      "train: iter 717  trainloss 3.48027  validloss 4.40871±0.00000  bestvalidloss 4.18941  last_update 21\n",
      "train: iter 718  trainloss 3.46106  validloss 4.40640±0.00000  bestvalidloss 4.18941  last_update 22\n",
      "train: iter 719  trainloss 3.45797  validloss 4.41776±0.00000  bestvalidloss 4.18941  last_update 23\n",
      "train: iter 720  trainloss 3.45790  validloss 4.38932±0.00000  bestvalidloss 4.18941  last_update 24\n",
      "train: iter 721  trainloss 3.45488  validloss 4.29831±0.00000  bestvalidloss 4.18941  last_update 25\n",
      "train: iter 722  trainloss 3.42644  validloss 4.40428±0.00000  bestvalidloss 4.18941  last_update 26\n",
      "train: iter 723  trainloss 3.44816  validloss 4.63605±0.00000  bestvalidloss 4.18941  last_update 27\n",
      "train: iter 724  trainloss 3.46907  validloss 4.31556±0.00000  bestvalidloss 4.18941  last_update 28\n",
      "train: iter 725  trainloss 3.43344  validloss 4.33214±0.00000  bestvalidloss 4.18941  last_update 29\n",
      "train: iter 726  trainloss 3.46753  validloss 4.42467±0.00000  bestvalidloss 4.18941  last_update 30\n",
      "train: iter 727  trainloss 3.47550  validloss 4.44227±0.00000  bestvalidloss 4.18941  last_update 31\n",
      "train: iter 728  trainloss 3.50219  validloss 4.57333±0.00000  bestvalidloss 4.18941  last_update 32\n",
      "train: iter 729  trainloss 3.49764  validloss 4.31147±0.00000  bestvalidloss 4.18941  last_update 33\n",
      "train: iter 730  trainloss 3.45678  validloss 4.38570±0.00000  bestvalidloss 4.18941  last_update 34\n",
      "train: iter 731  trainloss 3.44947  validloss 4.40016±0.00000  bestvalidloss 4.18941  last_update 35\n",
      "train: iter 732  trainloss 3.47317  validloss 4.38623±0.00000  bestvalidloss 4.18941  last_update 36\n",
      "train: iter 733  trainloss 3.46507  validloss 4.30872±0.00000  bestvalidloss 4.18941  last_update 37\n",
      "train: iter 734  trainloss 3.42794  validloss 4.28355±0.00000  bestvalidloss 4.18941  last_update 38\n",
      "train: iter 735  trainloss 3.44241  validloss 4.28381±0.00000  bestvalidloss 4.18941  last_update 39\n",
      "train: iter 736  trainloss 3.45715  validloss 4.35893±0.00000  bestvalidloss 4.18941  last_update 40\n",
      "train: iter 737  trainloss 3.48368  validloss 4.45457±0.00000  bestvalidloss 4.18941  last_update 41\n",
      "train: iter 738  trainloss 3.44148  validloss 4.49692±0.00000  bestvalidloss 4.18941  last_update 42\n",
      "train: iter 739  trainloss 3.42455  validloss 4.52711±0.00000  bestvalidloss 4.18941  last_update 43\n",
      "train: iter 740  trainloss 3.42169  validloss 4.40229±0.00000  bestvalidloss 4.18941  last_update 44\n",
      "train: iter 741  trainloss 3.45097  validloss 4.30773±0.00000  bestvalidloss 4.18941  last_update 45\n",
      "train: iter 742  trainloss 3.41253  validloss 4.35726±0.00000  bestvalidloss 4.18941  last_update 46\n",
      "train: iter 743  trainloss 3.47134  validloss 4.34023±0.00000  bestvalidloss 4.18941  last_update 47\n",
      "train: iter 744  trainloss 3.47392  validloss 4.34184±0.00000  bestvalidloss 4.18941  last_update 48\n",
      "train: iter 745  trainloss 3.46171  validloss 4.35319±0.00000  bestvalidloss 4.18941  last_update 49\n",
      "train: iter 746  trainloss 3.41437  validloss 4.41522±0.00000  bestvalidloss 4.18941  last_update 50\n",
      "train: iter 747  trainloss 3.46886  validloss 4.43400±0.00000  bestvalidloss 4.18941  last_update 51\n",
      "train: iter 748  trainloss 3.42651  validloss 4.37774±0.00000  bestvalidloss 4.18941  last_update 52\n",
      "train: iter 749  trainloss 3.42668  validloss 4.36362±0.00000  bestvalidloss 4.18941  last_update 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 750  trainloss 3.47909  validloss 4.35033±0.00000  bestvalidloss 4.18941  last_update 54\n",
      "train: iter 751  trainloss 3.43178  validloss 4.30621±0.00000  bestvalidloss 4.18941  last_update 55\n",
      "train: iter 752  trainloss 3.55265  validloss 4.31818±0.00000  bestvalidloss 4.18941  last_update 56\n",
      "train: iter 753  trainloss 3.42723  validloss 4.30094±0.00000  bestvalidloss 4.18941  last_update 57\n",
      "train: iter 754  trainloss 3.51408  validloss 4.77196±0.00000  bestvalidloss 4.18941  last_update 58\n",
      "train: iter 755  trainloss 3.48138  validloss 4.47551±0.00000  bestvalidloss 4.18941  last_update 59\n",
      "train: iter 756  trainloss 3.42758  validloss 4.55975±0.00000  bestvalidloss 4.18941  last_update 60\n",
      "train: iter 757  trainloss 3.46103  validloss 4.38336±0.00000  bestvalidloss 4.18941  last_update 61\n",
      "train: iter 758  trainloss 3.44217  validloss 4.49632±0.00000  bestvalidloss 4.18941  last_update 62\n",
      "train: iter 759  trainloss 3.42752  validloss 4.37808±0.00000  bestvalidloss 4.18941  last_update 63\n",
      "train: iter 760  trainloss 3.47284  validloss 4.38729±0.00000  bestvalidloss 4.18941  last_update 64\n",
      "train: iter 761  trainloss 3.44756  validloss 4.36120±0.00000  bestvalidloss 4.18941  last_update 65\n",
      "train: iter 762  trainloss 3.47178  validloss 4.44677±0.00000  bestvalidloss 4.18941  last_update 66\n",
      "train: iter 763  trainloss 3.46587  validloss 4.30515±0.00000  bestvalidloss 4.18941  last_update 67\n",
      "train: iter 764  trainloss 3.46172  validloss 4.42212±0.00000  bestvalidloss 4.18941  last_update 68\n",
      "train: iter 765  trainloss 3.46128  validloss 4.42723±0.00000  bestvalidloss 4.18941  last_update 69\n",
      "train: iter 766  trainloss 3.42723  validloss 4.42701±0.00000  bestvalidloss 4.18941  last_update 70\n",
      "train: iter 767  trainloss 3.42867  validloss 4.57056±0.00000  bestvalidloss 4.18941  last_update 71\n",
      "train: iter 768  trainloss 3.47856  validloss 4.51369±0.00000  bestvalidloss 4.18941  last_update 72\n",
      "train: iter 769  trainloss 3.47550  validloss 4.43460±0.00000  bestvalidloss 4.18941  last_update 73\n",
      "train: iter 770  trainloss 3.41912  validloss 4.40039±0.00000  bestvalidloss 4.18941  last_update 74\n",
      "train: iter 771  trainloss 3.43557  validloss 4.51720±0.00000  bestvalidloss 4.18941  last_update 75\n",
      "train: iter 772  trainloss 3.48341  validloss 4.32676±0.00000  bestvalidloss 4.18941  last_update 76\n",
      "train: iter 773  trainloss 3.44235  validloss 4.40137±0.00000  bestvalidloss 4.18941  last_update 77\n",
      "train: iter 774  trainloss 3.44002  validloss 4.47088±0.00000  bestvalidloss 4.18941  last_update 78\n",
      "train: iter 775  trainloss 3.44947  validloss 4.53631±0.00000  bestvalidloss 4.18941  last_update 79\n",
      "train: iter 776  trainloss 3.43436  validloss 4.61030±0.00000  bestvalidloss 4.18941  last_update 80\n",
      "train: iter 777  trainloss 3.42850  validloss 4.26168±0.00000  bestvalidloss 4.18941  last_update 81\n",
      "train: iter 778  trainloss 3.41461  validloss 4.39552±0.00000  bestvalidloss 4.18941  last_update 82\n",
      "train: iter 779  trainloss 3.45379  validloss 4.36668±0.00000  bestvalidloss 4.18941  last_update 83\n",
      "train: iter 780  trainloss 3.42175  validloss 4.42303±0.00000  bestvalidloss 4.18941  last_update 84\n",
      "train: iter 781  trainloss 3.46517  validloss 4.35046±0.00000  bestvalidloss 4.18941  last_update 85\n",
      "train: iter 782  trainloss 3.41665  validloss 4.39560±0.00000  bestvalidloss 4.18941  last_update 86\n",
      "train: iter 783  trainloss 3.45405  validloss 4.42708±0.00000  bestvalidloss 4.18941  last_update 87\n",
      "train: iter 784  trainloss 3.42333  validloss 4.40381±0.00000  bestvalidloss 4.18941  last_update 88\n",
      "train: iter 785  trainloss 3.46916  validloss 4.40244±0.00000  bestvalidloss 4.18941  last_update 89\n",
      "train: iter 786  trainloss 3.46200  validloss 4.35630±0.00000  bestvalidloss 4.18941  last_update 90\n",
      "train: iter 787  trainloss 3.39382  validloss 4.46537±0.00000  bestvalidloss 4.18941  last_update 91\n",
      "train: iter 788  trainloss 3.48135  validloss 4.37518±0.00000  bestvalidloss 4.18941  last_update 92\n",
      "train: iter 789  trainloss 3.43787  validloss 4.43610±0.00000  bestvalidloss 4.18941  last_update 93\n",
      "train: iter 790  trainloss 3.41290  validloss 4.33587±0.00000  bestvalidloss 4.18941  last_update 94\n",
      "train: iter 791  trainloss 3.44487  validloss 4.60459±0.00000  bestvalidloss 4.18941  last_update 95\n",
      "train: iter 792  trainloss 3.42366  validloss 4.34200±0.00000  bestvalidloss 4.18941  last_update 96\n",
      "train: iter 793  trainloss 3.41375  validloss 4.40578±0.00000  bestvalidloss 4.18941  last_update 97\n",
      "train: iter 794  trainloss 3.48501  validloss 4.43861±0.00000  bestvalidloss 4.18941  last_update 98\n",
      "train: iter 795  trainloss 3.46160  validloss 4.42812±0.00000  bestvalidloss 4.18941  last_update 99\n",
      "train: iter 796  trainloss 3.45240  validloss 4.42054±0.00000  bestvalidloss 4.18941  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-11.2688)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(18.2626)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4455875819564994\n",
      "tensor([-0.2217])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242caa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a98b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112819ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfff682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c9ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e0943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198825bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f45ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33660c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f08a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d77961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129676a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7f114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c970e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
