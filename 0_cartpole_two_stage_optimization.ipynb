{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f49dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import datetime\n",
    "import torch\n",
    "import gym\n",
    "import custom_gym\n",
    "import random\n",
    "from config import cfg_seed, cfg_env, cfg_z_dim, cfg_default_lr, cfg_default_early\n",
    "seed = cfg_seed\n",
    "env_str=cfg_env\n",
    "default_lr=cfg_default_lr\n",
    "default_early=cfg_default_early\n",
    "\n",
    "if cfg_env == \"pendulum\":\n",
    "    env_name = \"CustomPendulum-v0\"\n",
    "if cfg_env == \"cartpole\":\n",
    "    env_name = \"CustomCartPole-v0\"\n",
    "\n",
    "figfilenamehead = \"fig_policy_evaluation_\"+cfg_env+\"_\"\n",
    "\n",
    "num_iter_max=200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf77b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "env.action_space.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "s_dim = env.reset().flatten().shape[0]\n",
    "a_dim = env.action_space.sample().flatten().shape[0]\n",
    "z_dim = cfg_z_dim\n",
    "print(s_dim, a_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sac import SAC\n",
    "# agent = SAC(env.observation_space.shape[0], env.action_space)\n",
    "# agent.load_checkpoint(ckpt_path=\"checkpoints/sac_checkpoint_custom_\"+env_str+\"_mdp_\", evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9c09c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proxima-hishinuma/anaconda3/envs/iwvi/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# データ生成\n",
    "from get_offline_data import getOfflineData\n",
    "getOfflineData(env_name=env_name, episode_num=100, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d57437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_data[1].sum() tensor(1755.6847)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "offline_data = pickle.load(open(\"offline_data_\"+env_str+\".pkl\",\"rb\"))\n",
    "\n",
    "debug_info = pickle.load(open(\"offline_data_debug_info_\"+env_str+\".pkl\",\"rb\"))\n",
    "debug_info = np.array(debug_info)\n",
    "print(\"offline_data[1].sum()\", offline_data[1].sum())\n",
    "print(debug_info.shape)\n",
    "# c_array = debug_info[:,1]\n",
    "\n",
    "# episode_index = 9\n",
    "# plt.plot(offline_data[episode_index][:,0],offline_data[episode_index][:,1])\n",
    "# print(\"env_param: \",debug_info[episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767b8aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec: h_dim 48\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(vi_base)\n",
    "import vi_base\n",
    "\n",
    "args_init_dict = {\n",
    "    \"offline_data\": offline_data,\n",
    "    \"s_dim\": s_dim,\n",
    "    \"a_dim\": a_dim,\n",
    "    \"z_dim\": z_dim,\n",
    "    #              \"policy\":agent.select_action,\n",
    "    \"mdp_policy\":None,\n",
    "    \"bamdp_policy\":None,\n",
    "    \"debug_info\":debug_info,\n",
    "    \"env\" : env,\n",
    "    \"ckpt_suffix\" : env_str,\n",
    "    }\n",
    "\n",
    "vi = vi_base.baseVI(args_init_dict)\n",
    "# print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c06f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vae: enc_dec\n",
      "train: iter 0  trainloss 644.83899  validloss 918.06659±0.00000  bestvalidloss 918.06659  last_update 0\n",
      "train: iter 1  trainloss 210.76613  validloss 567.49333±0.00000  bestvalidloss 567.49333  last_update 0\n",
      "train: iter 2  trainloss -15.76951  validloss 332.83773±0.00000  bestvalidloss 332.83773  last_update 0\n",
      "train: iter 3  trainloss -373.80603  validloss -183.93672±0.00000  bestvalidloss -183.93672  last_update 0\n",
      "train: iter 4  trainloss -561.17897  validloss -372.32037±0.00000  bestvalidloss -372.32037  last_update 0\n",
      "train: iter 5  trainloss -667.97685  validloss -534.59201±0.00000  bestvalidloss -534.59201  last_update 0\n",
      "train: iter 6  trainloss -740.27102  validloss -578.61188±0.00000  bestvalidloss -578.61188  last_update 0\n",
      "train: iter 7  trainloss -814.38953  validloss -614.98794±0.00000  bestvalidloss -614.98794  last_update 0\n",
      "train: iter 8  trainloss -824.69510  validloss -753.59732±0.00000  bestvalidloss -753.59732  last_update 0\n",
      "train: iter 9  trainloss -960.06510  validloss -754.31796±0.00000  bestvalidloss -754.31796  last_update 0\n",
      "train: iter 10  trainloss -1007.87900  validloss -704.59109±0.00000  bestvalidloss -754.31796  last_update 1\n",
      "train: iter 11  trainloss -912.22127  validloss -897.06408±0.00000  bestvalidloss -897.06408  last_update 0\n",
      "train: iter 12  trainloss -962.51349  validloss -378.57582±0.00000  bestvalidloss -897.06408  last_update 1\n",
      "train: iter 13  trainloss -1049.85348  validloss -1035.44098±0.00000  bestvalidloss -1035.44098  last_update 0\n",
      "train: iter 14  trainloss -1216.81363  validloss -900.53027±0.00000  bestvalidloss -1035.44098  last_update 1\n",
      "train: iter 15  trainloss -1197.28269  validloss -1134.70601±0.00000  bestvalidloss -1134.70601  last_update 0\n",
      "train: iter 16  trainloss -1292.13942  validloss -1099.33451±0.00000  bestvalidloss -1134.70601  last_update 1\n",
      "train: iter 17  trainloss -1274.97470  validloss -718.71492±0.00000  bestvalidloss -1134.70601  last_update 2\n",
      "train: iter 18  trainloss -1305.33590  validloss -999.35978±0.00000  bestvalidloss -1134.70601  last_update 3\n",
      "train: iter 19  trainloss -1327.16231  validloss -1150.55221±0.00000  bestvalidloss -1150.55221  last_update 0\n",
      "train: iter 20  trainloss -1373.57833  validloss -1217.38279±0.00000  bestvalidloss -1217.38279  last_update 0\n",
      "train: iter 21  trainloss -1370.41398  validloss -1225.67040±0.00000  bestvalidloss -1225.67040  last_update 0\n",
      "train: iter 22  trainloss -1358.38048  validloss -1143.38716±0.00000  bestvalidloss -1225.67040  last_update 1\n",
      "train: iter 23  trainloss -1422.12567  validloss -1251.36077±0.00000  bestvalidloss -1251.36077  last_update 0\n",
      "train: iter 24  trainloss -1333.57541  validloss -1313.46178±0.00000  bestvalidloss -1313.46178  last_update 0\n",
      "train: iter 25  trainloss -1461.68812  validloss -1165.90449±0.00000  bestvalidloss -1313.46178  last_update 1\n",
      "train: iter 26  trainloss -1474.40258  validloss -1362.74519±0.00000  bestvalidloss -1362.74519  last_update 0\n",
      "train: iter 27  trainloss -1459.43789  validloss -1249.99550±0.00000  bestvalidloss -1362.74519  last_update 1\n",
      "train: iter 28  trainloss -1462.88248  validloss -1323.75258±0.00000  bestvalidloss -1362.74519  last_update 2\n",
      "train: iter 29  trainloss -1464.60767  validloss -1320.63500±0.00000  bestvalidloss -1362.74519  last_update 3\n",
      "train: iter 30  trainloss -1490.05094  validloss -1332.05633±0.00000  bestvalidloss -1362.74519  last_update 4\n",
      "train: iter 31  trainloss -1306.95768  validloss -1201.66703±0.00000  bestvalidloss -1362.74519  last_update 5\n",
      "train: iter 32  trainloss -1404.86576  validloss -799.12199±0.00000  bestvalidloss -1362.74519  last_update 6\n",
      "train: iter 33  trainloss -1525.76987  validloss -1334.75696±0.00000  bestvalidloss -1362.74519  last_update 7\n",
      "train: iter 34  trainloss -1543.82243  validloss -1312.63060±0.00000  bestvalidloss -1362.74519  last_update 8\n",
      "train: iter 35  trainloss -1527.79309  validloss -1406.92485±0.00000  bestvalidloss -1406.92485  last_update 0\n",
      "train: iter 36  trainloss -1446.21194  validloss -1269.73259±0.00000  bestvalidloss -1406.92485  last_update 1\n",
      "train: iter 37  trainloss -1516.05863  validloss -1318.11200±0.00000  bestvalidloss -1406.92485  last_update 2\n",
      "train: iter 38  trainloss -1551.13156  validloss -1358.37982±0.00000  bestvalidloss -1406.92485  last_update 3\n",
      "train: iter 39  trainloss -1581.88663  validloss -1272.31419±0.00000  bestvalidloss -1406.92485  last_update 4\n",
      "train: iter 40  trainloss -1550.64515  validloss -1326.88040±0.00000  bestvalidloss -1406.92485  last_update 5\n",
      "train: iter 41  trainloss -1468.43314  validloss -1187.83986±0.00000  bestvalidloss -1406.92485  last_update 6\n",
      "train: iter 42  trainloss -1594.34286  validloss -1268.96862±0.00000  bestvalidloss -1406.92485  last_update 7\n",
      "train: iter 43  trainloss -1580.90843  validloss -1378.88698±0.00000  bestvalidloss -1406.92485  last_update 8\n",
      "train: iter 44  trainloss -1588.23128  validloss -1342.81349±0.00000  bestvalidloss -1406.92485  last_update 9\n",
      "train: iter 45  trainloss -1487.70365  validloss -1330.43262±0.00000  bestvalidloss -1406.92485  last_update 10\n",
      "train: iter 46  trainloss -1595.97087  validloss -1353.68781±0.00000  bestvalidloss -1406.92485  last_update 11\n",
      "train: iter 47  trainloss -1572.39511  validloss -1291.51377±0.00000  bestvalidloss -1406.92485  last_update 12\n",
      "train: iter 48  trainloss -1542.45813  validloss -1146.30477±0.00000  bestvalidloss -1406.92485  last_update 13\n",
      "train: iter 49  trainloss -1610.56340  validloss -1263.32025±0.00000  bestvalidloss -1406.92485  last_update 14\n",
      "train: iter 50  trainloss -1620.50285  validloss -1275.91271±0.00000  bestvalidloss -1406.92485  last_update 15\n",
      "train: iter 51  trainloss -1577.31140  validloss -1362.31777±0.00000  bestvalidloss -1406.92485  last_update 16\n",
      "train: iter 52  trainloss -1526.00938  validloss -1276.20348±0.00000  bestvalidloss -1406.92485  last_update 17\n",
      "train: iter 53  trainloss -1569.78872  validloss -1409.75934±0.00000  bestvalidloss -1409.75934  last_update 0\n",
      "train: iter 54  trainloss -1411.85874  validloss -1302.31110±0.00000  bestvalidloss -1409.75934  last_update 1\n",
      "train: iter 55  trainloss -1595.70768  validloss -1320.66282±0.00000  bestvalidloss -1409.75934  last_update 2\n",
      "train: iter 56  trainloss -1609.73723  validloss -1366.91198±0.00000  bestvalidloss -1409.75934  last_update 3\n",
      "train: iter 57  trainloss -1636.14973  validloss -1270.63369±0.00000  bestvalidloss -1409.75934  last_update 4\n",
      "train: iter 58  trainloss -1657.39698  validloss -1292.88447±0.00000  bestvalidloss -1409.75934  last_update 5\n",
      "train: iter 59  trainloss -1665.13982  validloss -1360.36158±0.00000  bestvalidloss -1409.75934  last_update 6\n",
      "train: iter 60  trainloss -1640.14558  validloss -1421.77021±0.00000  bestvalidloss -1421.77021  last_update 0\n",
      "train: iter 61  trainloss -1661.78896  validloss -1389.38672±0.00000  bestvalidloss -1421.77021  last_update 1\n",
      "train: iter 62  trainloss -1672.71274  validloss -1380.31819±0.00000  bestvalidloss -1421.77021  last_update 2\n",
      "train: iter 63  trainloss -1645.82690  validloss -1463.89630±0.00000  bestvalidloss -1463.89630  last_update 0\n",
      "train: iter 64  trainloss -1625.32904  validloss -1313.63054±0.00000  bestvalidloss -1463.89630  last_update 1\n",
      "train: iter 65  trainloss -1671.58824  validloss -1398.40475±0.00000  bestvalidloss -1463.89630  last_update 2\n",
      "train: iter 66  trainloss -1664.49709  validloss -1295.13528±0.00000  bestvalidloss -1463.89630  last_update 3\n",
      "train: iter 67  trainloss -1587.67265  validloss -1265.65406±0.00000  bestvalidloss -1463.89630  last_update 4\n",
      "train: iter 68  trainloss -1651.74013  validloss -1421.25478±0.00000  bestvalidloss -1463.89630  last_update 5\n",
      "train: iter 69  trainloss -1676.62570  validloss -1402.39206±0.00000  bestvalidloss -1463.89630  last_update 6\n",
      "train: iter 70  trainloss -1567.52840  validloss -1433.63142±0.00000  bestvalidloss -1463.89630  last_update 7\n",
      "train: iter 71  trainloss -1673.77491  validloss -1394.10612±0.00000  bestvalidloss -1463.89630  last_update 8\n",
      "train: iter 72  trainloss -1572.16893  validloss -1204.00887±0.00000  bestvalidloss -1463.89630  last_update 9\n",
      "train: iter 73  trainloss -1654.07098  validloss -1237.36376±0.00000  bestvalidloss -1463.89630  last_update 10\n",
      "train: iter 74  trainloss -1671.85626  validloss -1247.18220±0.00000  bestvalidloss -1463.89630  last_update 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 75  trainloss -1691.21839  validloss -1368.58539±0.00000  bestvalidloss -1463.89630  last_update 12\n",
      "train: iter 76  trainloss -1641.69836  validloss -1295.26378±0.00000  bestvalidloss -1463.89630  last_update 13\n",
      "train: iter 77  trainloss -1702.17180  validloss -1464.33503±0.00000  bestvalidloss -1464.33503  last_update 0\n",
      "train: iter 78  trainloss -1707.44818  validloss -1496.89510±0.00000  bestvalidloss -1496.89510  last_update 0\n",
      "train: iter 79  trainloss -1720.26110  validloss -1522.61962±0.00000  bestvalidloss -1522.61962  last_update 0\n",
      "train: iter 80  trainloss -1720.45941  validloss -1451.67523±0.00000  bestvalidloss -1522.61962  last_update 1\n",
      "train: iter 81  trainloss -1723.66792  validloss -1409.84038±0.00000  bestvalidloss -1522.61962  last_update 2\n",
      "train: iter 82  trainloss -1680.01546  validloss -1505.46593±0.00000  bestvalidloss -1522.61962  last_update 3\n",
      "train: iter 83  trainloss -1753.49328  validloss -1548.85892±0.00000  bestvalidloss -1548.85892  last_update 0\n",
      "train: iter 84  trainloss -1756.21344  validloss -1532.93625±0.00000  bestvalidloss -1548.85892  last_update 1\n",
      "train: iter 85  trainloss -1716.95098  validloss -1508.84799±0.00000  bestvalidloss -1548.85892  last_update 2\n",
      "train: iter 86  trainloss -1708.30649  validloss -1396.54241±0.00000  bestvalidloss -1548.85892  last_update 3\n",
      "train: iter 87  trainloss -1763.46840  validloss -1556.33210±0.00000  bestvalidloss -1556.33210  last_update 0\n",
      "train: iter 88  trainloss -1661.32974  validloss -1450.61298±0.00000  bestvalidloss -1556.33210  last_update 1\n",
      "train: iter 89  trainloss -1725.07595  validloss -1525.58779±0.00000  bestvalidloss -1556.33210  last_update 2\n",
      "train: iter 90  trainloss -1754.44473  validloss -1522.69152±0.00000  bestvalidloss -1556.33210  last_update 3\n",
      "train: iter 91  trainloss -1762.19203  validloss -1432.42670±0.00000  bestvalidloss -1556.33210  last_update 4\n",
      "train: iter 92  trainloss -1763.18977  validloss -1349.20298±0.00000  bestvalidloss -1556.33210  last_update 5\n",
      "train: iter 93  trainloss -1755.99861  validloss -1537.64058±0.00000  bestvalidloss -1556.33210  last_update 6\n",
      "train: iter 94  trainloss -1801.41274  validloss -1481.45478±0.00000  bestvalidloss -1556.33210  last_update 7\n",
      "train: iter 95  trainloss -1795.23741  validloss -1453.02433±0.00000  bestvalidloss -1556.33210  last_update 8\n",
      "train: iter 96  trainloss -1806.83333  validloss -1491.88342±0.00000  bestvalidloss -1556.33210  last_update 9\n",
      "train: iter 97  trainloss -1839.63415  validloss -1362.76303±0.00000  bestvalidloss -1556.33210  last_update 10\n",
      "train: iter 98  trainloss -1816.13695  validloss -1391.51288±0.00000  bestvalidloss -1556.33210  last_update 11\n",
      "train: iter 99  trainloss -1755.23331  validloss -1502.71254±0.00000  bestvalidloss -1556.33210  last_update 12\n",
      "train: iter 100  trainloss -1837.24939  validloss -1604.79498±0.00000  bestvalidloss -1604.79498  last_update 0\n",
      "train: iter 101  trainloss -1837.65424  validloss -1346.49540±0.00000  bestvalidloss -1604.79498  last_update 1\n",
      "train: iter 102  trainloss -1775.54726  validloss -1430.92044±0.00000  bestvalidloss -1604.79498  last_update 2\n",
      "train: iter 103  trainloss -1848.46065  validloss -1432.29201±0.00000  bestvalidloss -1604.79498  last_update 3\n",
      "train: iter 104  trainloss -1881.11983  validloss -1555.17491±0.00000  bestvalidloss -1604.79498  last_update 4\n",
      "train: iter 105  trainloss -1882.28604  validloss -1578.28364±0.00000  bestvalidloss -1604.79498  last_update 5\n",
      "train: iter 106  trainloss -1906.56179  validloss -1531.12354±0.00000  bestvalidloss -1604.79498  last_update 6\n",
      "train: iter 107  trainloss -1899.43259  validloss -1595.49595±0.00000  bestvalidloss -1604.79498  last_update 7\n",
      "train: iter 108  trainloss -1893.68895  validloss -1543.77628±0.00000  bestvalidloss -1604.79498  last_update 8\n",
      "train: iter 109  trainloss -1843.94338  validloss -1519.86572±0.00000  bestvalidloss -1604.79498  last_update 9\n",
      "train: iter 110  trainloss -1859.68735  validloss -1519.83065±0.00000  bestvalidloss -1604.79498  last_update 10\n",
      "train: iter 111  trainloss -1906.10956  validloss -1611.66414±0.00000  bestvalidloss -1611.66414  last_update 0\n",
      "train: iter 112  trainloss -1901.61676  validloss -1619.68893±0.00000  bestvalidloss -1619.68893  last_update 0\n",
      "train: iter 113  trainloss -1915.90551  validloss -1601.05393±0.00000  bestvalidloss -1619.68893  last_update 1\n",
      "train: iter 114  trainloss -1900.68967  validloss -1630.84749±0.00000  bestvalidloss -1630.84749  last_update 0\n",
      "train: iter 115  trainloss -1898.97494  validloss -1650.88683±0.00000  bestvalidloss -1650.88683  last_update 0\n",
      "train: iter 116  trainloss -1928.45671  validloss -1601.52480±0.00000  bestvalidloss -1650.88683  last_update 1\n",
      "train: iter 117  trainloss -1806.57801  validloss -1614.53165±0.00000  bestvalidloss -1650.88683  last_update 2\n",
      "train: iter 118  trainloss -1894.76022  validloss -1623.49882±0.00000  bestvalidloss -1650.88683  last_update 3\n",
      "train: iter 119  trainloss -1754.10493  validloss -1561.95900±0.00000  bestvalidloss -1650.88683  last_update 4\n",
      "train: iter 120  trainloss -1869.95414  validloss -1512.65585±0.00000  bestvalidloss -1650.88683  last_update 5\n",
      "train: iter 121  trainloss -1930.79035  validloss -1664.46971±0.00000  bestvalidloss -1664.46971  last_update 0\n",
      "train: iter 122  trainloss -1909.53112  validloss -1589.46621±0.00000  bestvalidloss -1664.46971  last_update 1\n",
      "train: iter 123  trainloss -1951.45012  validloss -1620.46217±0.00000  bestvalidloss -1664.46971  last_update 2\n",
      "train: iter 124  trainloss -1892.81905  validloss -1637.35100±0.00000  bestvalidloss -1664.46971  last_update 3\n",
      "train: iter 125  trainloss -1907.20829  validloss -1660.17396±0.00000  bestvalidloss -1664.46971  last_update 4\n",
      "train: iter 126  trainloss -1897.13937  validloss -1661.86885±0.00000  bestvalidloss -1664.46971  last_update 5\n",
      "train: iter 127  trainloss -1945.75894  validloss -1600.82159±0.00000  bestvalidloss -1664.46971  last_update 6\n",
      "train: iter 128  trainloss -1935.43560  validloss -1562.68702±0.00000  bestvalidloss -1664.46971  last_update 7\n",
      "train: iter 129  trainloss -1957.31942  validloss -1700.53326±0.00000  bestvalidloss -1700.53326  last_update 0\n",
      "train: iter 130  trainloss -1946.31992  validloss -1670.69643±0.00000  bestvalidloss -1700.53326  last_update 1\n",
      "train: iter 131  trainloss -1965.23997  validloss -1647.16135±0.00000  bestvalidloss -1700.53326  last_update 2\n",
      "train: iter 132  trainloss -1922.77169  validloss -1624.80956±0.00000  bestvalidloss -1700.53326  last_update 3\n",
      "train: iter 133  trainloss -1939.95635  validloss -1640.34653±0.00000  bestvalidloss -1700.53326  last_update 4\n",
      "train: iter 134  trainloss -1958.65421  validloss -1667.76503±0.00000  bestvalidloss -1700.53326  last_update 5\n",
      "train: iter 135  trainloss -1887.15118  validloss -1675.33958±0.00000  bestvalidloss -1700.53326  last_update 6\n",
      "train: iter 136  trainloss -1877.80469  validloss -1640.91891±0.00000  bestvalidloss -1700.53326  last_update 7\n",
      "train: iter 137  trainloss -1870.25375  validloss -1651.03442±0.00000  bestvalidloss -1700.53326  last_update 8\n",
      "train: iter 138  trainloss -1951.52004  validloss -1571.63958±0.00000  bestvalidloss -1700.53326  last_update 9\n",
      "train: iter 139  trainloss -1975.17357  validloss -1622.46102±0.00000  bestvalidloss -1700.53326  last_update 10\n",
      "train: iter 140  trainloss -1895.00152  validloss -1647.18975±0.00000  bestvalidloss -1700.53326  last_update 11\n",
      "train: iter 141  trainloss -1967.87087  validloss -1691.72413±0.00000  bestvalidloss -1700.53326  last_update 12\n",
      "train: iter 142  trainloss -1930.98787  validloss -1643.78629±0.00000  bestvalidloss -1700.53326  last_update 13\n",
      "train: iter 143  trainloss -1970.52342  validloss -1708.30377±0.00000  bestvalidloss -1708.30377  last_update 0\n",
      "train: iter 144  trainloss -1942.87853  validloss -1679.97131±0.00000  bestvalidloss -1708.30377  last_update 1\n",
      "train: iter 145  trainloss -1934.67110  validloss -1702.87849±0.00000  bestvalidloss -1708.30377  last_update 2\n",
      "train: iter 146  trainloss -1945.95678  validloss -1632.62893±0.00000  bestvalidloss -1708.30377  last_update 3\n",
      "train: iter 147  trainloss -1991.31436  validloss -1695.32992±0.00000  bestvalidloss -1708.30377  last_update 4\n",
      "train: iter 148  trainloss -1922.76246  validloss -1554.91345±0.00000  bestvalidloss -1708.30377  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 149  trainloss -1907.30765  validloss -1647.55800±0.00000  bestvalidloss -1708.30377  last_update 6\n",
      "train: iter 150  trainloss -1982.48886  validloss -1603.77586±0.00000  bestvalidloss -1708.30377  last_update 7\n",
      "train: iter 151  trainloss -1947.29486  validloss -1657.92908±0.00000  bestvalidloss -1708.30377  last_update 8\n",
      "train: iter 152  trainloss -1979.97981  validloss -1618.87960±0.00000  bestvalidloss -1708.30377  last_update 9\n",
      "train: iter 153  trainloss -1963.63572  validloss -1731.79442±0.00000  bestvalidloss -1731.79442  last_update 0\n",
      "train: iter 154  trainloss -1982.56985  validloss -1681.39502±0.00000  bestvalidloss -1731.79442  last_update 1\n",
      "train: iter 155  trainloss -1982.69956  validloss -1727.17161±0.00000  bestvalidloss -1731.79442  last_update 2\n",
      "train: iter 156  trainloss -1975.67164  validloss -1689.96225±0.00000  bestvalidloss -1731.79442  last_update 3\n",
      "train: iter 157  trainloss -1994.89955  validloss -1637.86611±0.00000  bestvalidloss -1731.79442  last_update 4\n",
      "train: iter 158  trainloss -1986.04632  validloss -1713.49246±0.00000  bestvalidloss -1731.79442  last_update 5\n",
      "train: iter 159  trainloss -1622.58541  validloss -1596.91243±0.00000  bestvalidloss -1731.79442  last_update 6\n",
      "train: iter 160  trainloss -1949.15409  validloss -1508.14572±0.00000  bestvalidloss -1731.79442  last_update 7\n",
      "train: iter 161  trainloss -1988.21983  validloss -1642.12232±0.00000  bestvalidloss -1731.79442  last_update 8\n",
      "train: iter 162  trainloss -1965.40577  validloss -1693.82090±0.00000  bestvalidloss -1731.79442  last_update 9\n",
      "train: iter 163  trainloss -1947.23034  validloss -1712.68336±0.00000  bestvalidloss -1731.79442  last_update 10\n",
      "train: iter 164  trainloss -1947.42444  validloss -1707.70775±0.00000  bestvalidloss -1731.79442  last_update 11\n",
      "train: iter 165  trainloss -1969.61131  validloss -1650.50778±0.00000  bestvalidloss -1731.79442  last_update 12\n",
      "train: iter 166  trainloss -2008.48958  validloss -1630.73418±0.00000  bestvalidloss -1731.79442  last_update 13\n",
      "train: iter 167  trainloss -2003.79195  validloss -1735.48243±0.00000  bestvalidloss -1735.48243  last_update 0\n",
      "train: iter 168  trainloss -1995.76435  validloss -1685.14608±0.00000  bestvalidloss -1735.48243  last_update 1\n",
      "train: iter 169  trainloss -1982.26442  validloss -1736.30660±0.00000  bestvalidloss -1736.30660  last_update 0\n",
      "train: iter 170  trainloss -1986.71274  validloss -1730.81287±0.00000  bestvalidloss -1736.30660  last_update 1\n",
      "train: iter 171  trainloss -1983.06845  validloss -1648.64669±0.00000  bestvalidloss -1736.30660  last_update 2\n",
      "train: iter 172  trainloss -2000.93340  validloss -1697.14145±0.00000  bestvalidloss -1736.30660  last_update 3\n",
      "train: iter 173  trainloss -1979.52027  validloss -1760.24625±0.00000  bestvalidloss -1760.24625  last_update 0\n",
      "train: iter 174  trainloss -1865.04147  validloss -1603.77946±0.00000  bestvalidloss -1760.24625  last_update 1\n",
      "train: iter 175  trainloss -2001.07435  validloss -1716.80344±0.00000  bestvalidloss -1760.24625  last_update 2\n",
      "train: iter 176  trainloss -1999.24816  validloss -1717.16845±0.00000  bestvalidloss -1760.24625  last_update 3\n",
      "train: iter 177  trainloss -1997.08646  validloss -1744.63874±0.00000  bestvalidloss -1760.24625  last_update 4\n",
      "train: iter 178  trainloss -1996.13379  validloss -1696.12654±0.00000  bestvalidloss -1760.24625  last_update 5\n",
      "train: iter 179  trainloss -1964.59912  validloss -1715.17527±0.00000  bestvalidloss -1760.24625  last_update 6\n",
      "train: iter 180  trainloss -1975.34866  validloss -1487.32045±0.00000  bestvalidloss -1760.24625  last_update 7\n",
      "train: iter 181  trainloss -2023.96540  validloss -1703.43553±0.00000  bestvalidloss -1760.24625  last_update 8\n",
      "train: iter 182  trainloss -2004.84446  validloss -1731.96169±0.00000  bestvalidloss -1760.24625  last_update 9\n",
      "train: iter 183  trainloss -2016.90918  validloss -1707.57284±0.00000  bestvalidloss -1760.24625  last_update 10\n",
      "train: iter 184  trainloss -1996.52345  validloss -1694.75829±0.00000  bestvalidloss -1760.24625  last_update 11\n",
      "train: iter 185  trainloss -2016.63022  validloss -1669.89567±0.00000  bestvalidloss -1760.24625  last_update 12\n",
      "train: iter 186  trainloss -1903.92043  validloss -1653.21840±0.00000  bestvalidloss -1760.24625  last_update 13\n",
      "train: iter 187  trainloss -1938.47962  validloss -1683.06751±0.00000  bestvalidloss -1760.24625  last_update 14\n",
      "train: iter 188  trainloss -1924.51285  validloss -1628.22483±0.00000  bestvalidloss -1760.24625  last_update 15\n",
      "train: iter 189  trainloss -1992.28609  validloss -1734.57585±0.00000  bestvalidloss -1760.24625  last_update 16\n",
      "train: iter 190  trainloss -1984.58535  validloss -1740.31866±0.00000  bestvalidloss -1760.24625  last_update 17\n",
      "train: iter 191  trainloss -1988.89270  validloss -1713.92498±0.00000  bestvalidloss -1760.24625  last_update 18\n",
      "train: iter 192  trainloss -2015.21922  validloss -1799.67966±0.00000  bestvalidloss -1799.67966  last_update 0\n",
      "train: iter 193  trainloss -2026.24939  validloss -1770.40308±0.00000  bestvalidloss -1799.67966  last_update 1\n",
      "train: iter 194  trainloss -1989.70611  validloss -1806.93073±0.00000  bestvalidloss -1806.93073  last_update 0\n",
      "train: iter 195  trainloss -2021.52713  validloss -1778.00184±0.00000  bestvalidloss -1806.93073  last_update 1\n",
      "train: iter 196  trainloss -2003.06048  validloss -1807.65711±0.00000  bestvalidloss -1807.65711  last_update 0\n",
      "train: iter 197  trainloss -1936.84691  validloss -1785.05131±0.00000  bestvalidloss -1807.65711  last_update 1\n",
      "train: iter 198  trainloss -1912.64996  validloss -1715.22068±0.00000  bestvalidloss -1807.65711  last_update 2\n",
      "train: iter 199  trainloss -2006.58160  validloss -1780.48655±0.00000  bestvalidloss -1807.65711  last_update 3\n",
      "train: iter 200  trainloss -1990.41730  validloss -1759.31614±0.00000  bestvalidloss -1807.65711  last_update 4\n",
      "train: iter 201  trainloss -1994.86837  validloss -1782.36439±0.00000  bestvalidloss -1807.65711  last_update 5\n",
      "train: iter 202  trainloss -2019.40009  validloss -1783.70660±0.00000  bestvalidloss -1807.65711  last_update 6\n",
      "train: iter 203  trainloss -1945.97267  validloss -1739.33912±0.00000  bestvalidloss -1807.65711  last_update 7\n",
      "train: iter 204  trainloss -2018.79373  validloss -1693.10095±0.00000  bestvalidloss -1807.65711  last_update 8\n",
      "train: iter 205  trainloss -2010.08354  validloss -1777.48700±0.00000  bestvalidloss -1807.65711  last_update 9\n",
      "train: iter 206  trainloss -2002.39174  validloss -1820.00191±0.00000  bestvalidloss -1820.00191  last_update 0\n",
      "train: iter 207  trainloss -2023.67418  validloss -1836.46785±0.00000  bestvalidloss -1836.46785  last_update 0\n",
      "train: iter 208  trainloss -2018.88171  validloss -1842.26263±0.00000  bestvalidloss -1842.26263  last_update 0\n",
      "train: iter 209  trainloss -2037.24030  validloss -1817.68955±0.00000  bestvalidloss -1842.26263  last_update 1\n",
      "train: iter 210  trainloss -2041.06165  validloss -1828.28785±0.00000  bestvalidloss -1842.26263  last_update 2\n",
      "train: iter 211  trainloss -2020.73942  validloss -1807.23525±0.00000  bestvalidloss -1842.26263  last_update 3\n",
      "train: iter 212  trainloss -2022.30952  validloss -1827.53352±0.00000  bestvalidloss -1842.26263  last_update 4\n",
      "train: iter 213  trainloss -1956.33295  validloss -1849.61802±0.00000  bestvalidloss -1849.61802  last_update 0\n",
      "train: iter 214  trainloss -1948.37940  validloss -1771.21055±0.00000  bestvalidloss -1849.61802  last_update 1\n",
      "train: iter 215  trainloss -2030.60994  validloss -1735.84937±0.00000  bestvalidloss -1849.61802  last_update 2\n",
      "train: iter 216  trainloss -2003.08888  validloss -1810.44984±0.00000  bestvalidloss -1849.61802  last_update 3\n",
      "train: iter 217  trainloss -2017.02391  validloss -1805.89940±0.00000  bestvalidloss -1849.61802  last_update 4\n",
      "train: iter 218  trainloss -1965.19862  validloss -1819.88492±0.00000  bestvalidloss -1849.61802  last_update 5\n",
      "train: iter 219  trainloss -2010.92915  validloss -1737.96179±0.00000  bestvalidloss -1849.61802  last_update 6\n",
      "train: iter 220  trainloss -2044.13727  validloss -1813.50632±0.00000  bestvalidloss -1849.61802  last_update 7\n",
      "train: iter 221  trainloss -2033.28128  validloss -1750.81276±0.00000  bestvalidloss -1849.61802  last_update 8\n",
      "train: iter 222  trainloss -2018.31650  validloss -1832.53246±0.00000  bestvalidloss -1849.61802  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 223  trainloss -2013.40259  validloss -1801.30527±0.00000  bestvalidloss -1849.61802  last_update 10\n",
      "train: iter 224  trainloss -1968.35074  validloss -1659.76085±0.00000  bestvalidloss -1849.61802  last_update 11\n",
      "train: iter 225  trainloss -2047.83895  validloss -1849.10380±0.00000  bestvalidloss -1849.61802  last_update 12\n",
      "train: iter 226  trainloss -2001.69892  validloss -1789.61177±0.00000  bestvalidloss -1849.61802  last_update 13\n",
      "train: iter 227  trainloss -2024.85898  validloss -1836.35016±0.00000  bestvalidloss -1849.61802  last_update 14\n",
      "train: iter 228  trainloss -2039.18457  validloss -1759.70344±0.00000  bestvalidloss -1849.61802  last_update 15\n",
      "train: iter 229  trainloss -2042.10115  validloss -1783.05242±0.00000  bestvalidloss -1849.61802  last_update 16\n",
      "train: iter 230  trainloss -2046.27014  validloss -1868.19142±0.00000  bestvalidloss -1868.19142  last_update 0\n",
      "train: iter 231  trainloss -2039.95170  validloss -1782.24736±0.00000  bestvalidloss -1868.19142  last_update 1\n",
      "train: iter 232  trainloss -1936.26999  validloss -1852.17348±0.00000  bestvalidloss -1868.19142  last_update 2\n",
      "train: iter 233  trainloss -2005.38181  validloss -1740.22006±0.00000  bestvalidloss -1868.19142  last_update 3\n",
      "train: iter 234  trainloss -1976.67167  validloss -1798.45607±0.00000  bestvalidloss -1868.19142  last_update 4\n",
      "train: iter 235  trainloss -2037.40272  validloss -1810.65322±0.00000  bestvalidloss -1868.19142  last_update 5\n",
      "train: iter 236  trainloss -2021.41605  validloss -1832.12192±0.00000  bestvalidloss -1868.19142  last_update 6\n",
      "train: iter 237  trainloss -2046.87359  validloss -1898.09629±0.00000  bestvalidloss -1898.09629  last_update 0\n",
      "train: iter 238  trainloss -2050.98665  validloss -1896.64146±0.00000  bestvalidloss -1898.09629  last_update 1\n",
      "train: iter 239  trainloss -2022.65360  validloss -1877.63143±0.00000  bestvalidloss -1898.09629  last_update 2\n",
      "train: iter 240  trainloss -2038.58060  validloss -1847.36992±0.00000  bestvalidloss -1898.09629  last_update 3\n",
      "train: iter 241  trainloss -2031.01177  validloss -1811.77538±0.00000  bestvalidloss -1898.09629  last_update 4\n",
      "train: iter 242  trainloss -2048.05583  validloss -1816.36102±0.00000  bestvalidloss -1898.09629  last_update 5\n",
      "train: iter 243  trainloss -2057.79530  validloss -1891.83623±0.00000  bestvalidloss -1898.09629  last_update 6\n",
      "train: iter 244  trainloss -1999.82206  validloss -1859.32861±0.00000  bestvalidloss -1898.09629  last_update 7\n",
      "train: iter 245  trainloss -1957.52909  validloss -1845.32285±0.00000  bestvalidloss -1898.09629  last_update 8\n",
      "train: iter 246  trainloss -1963.12829  validloss -1619.38635±0.00000  bestvalidloss -1898.09629  last_update 9\n",
      "train: iter 247  trainloss -1964.86192  validloss -1832.89418±0.00000  bestvalidloss -1898.09629  last_update 10\n",
      "train: iter 248  trainloss -2018.98495  validloss -1854.67485±0.00000  bestvalidloss -1898.09629  last_update 11\n",
      "train: iter 249  trainloss -2046.13336  validloss -1828.39769±0.00000  bestvalidloss -1898.09629  last_update 12\n",
      "train: iter 250  trainloss -2033.81051  validloss -1863.14419±0.00000  bestvalidloss -1898.09629  last_update 13\n",
      "train: iter 251  trainloss -2024.16583  validloss -1852.97895±0.00000  bestvalidloss -1898.09629  last_update 14\n",
      "train: iter 252  trainloss -2040.27904  validloss -1863.39335±0.00000  bestvalidloss -1898.09629  last_update 15\n",
      "train: iter 253  trainloss -2060.68657  validloss -1876.55972±0.00000  bestvalidloss -1898.09629  last_update 16\n",
      "train: iter 254  trainloss -2061.94513  validloss -1801.44854±0.00000  bestvalidloss -1898.09629  last_update 17\n",
      "train: iter 255  trainloss -2070.14792  validloss -1910.94429±0.00000  bestvalidloss -1910.94429  last_update 0\n",
      "train: iter 256  trainloss -2045.73769  validloss -1831.45374±0.00000  bestvalidloss -1910.94429  last_update 1\n",
      "train: iter 257  trainloss -2058.23680  validloss -1874.63101±0.00000  bestvalidloss -1910.94429  last_update 2\n",
      "train: iter 258  trainloss -2009.01206  validloss -1878.60062±0.00000  bestvalidloss -1910.94429  last_update 3\n",
      "train: iter 259  trainloss -2017.86860  validloss -1815.05288±0.00000  bestvalidloss -1910.94429  last_update 4\n",
      "train: iter 260  trainloss -2029.86978  validloss -1888.92127±0.00000  bestvalidloss -1910.94429  last_update 5\n",
      "train: iter 261  trainloss -2051.80793  validloss -1877.90044±0.00000  bestvalidloss -1910.94429  last_update 6\n",
      "train: iter 262  trainloss -1998.70613  validloss -1857.63728±0.00000  bestvalidloss -1910.94429  last_update 7\n",
      "train: iter 263  trainloss -1838.81599  validloss -1531.94594±0.00000  bestvalidloss -1910.94429  last_update 8\n",
      "train: iter 264  trainloss -2015.88246  validloss -1738.23644±0.00000  bestvalidloss -1910.94429  last_update 9\n",
      "train: iter 265  trainloss -2006.43358  validloss -1858.08556±0.00000  bestvalidloss -1910.94429  last_update 10\n",
      "train: iter 266  trainloss -2045.80518  validloss -1818.59364±0.00000  bestvalidloss -1910.94429  last_update 11\n",
      "train: iter 267  trainloss -2077.48316  validloss -1870.44564±0.00000  bestvalidloss -1910.94429  last_update 12\n",
      "train: iter 268  trainloss -2068.70081  validloss -1880.54714±0.00000  bestvalidloss -1910.94429  last_update 13\n",
      "train: iter 269  trainloss -2060.04116  validloss -1871.78201±0.00000  bestvalidloss -1910.94429  last_update 14\n",
      "train: iter 270  trainloss -2014.84046  validloss -1768.19937±0.00000  bestvalidloss -1910.94429  last_update 15\n",
      "train: iter 271  trainloss -2036.26678  validloss -1767.49001±0.00000  bestvalidloss -1910.94429  last_update 16\n",
      "train: iter 272  trainloss -2047.97717  validloss -1848.90025±0.00000  bestvalidloss -1910.94429  last_update 17\n",
      "train: iter 273  trainloss -1930.22726  validloss -1808.52064±0.00000  bestvalidloss -1910.94429  last_update 18\n",
      "train: iter 274  trainloss -2062.80260  validloss -1879.57385±0.00000  bestvalidloss -1910.94429  last_update 19\n",
      "train: iter 275  trainloss -2045.44512  validloss -1830.67383±0.00000  bestvalidloss -1910.94429  last_update 20\n",
      "train: iter 276  trainloss -2077.84160  validloss -1899.33125±0.00000  bestvalidloss -1910.94429  last_update 21\n",
      "train: iter 277  trainloss -2057.71244  validloss -1907.29078±0.00000  bestvalidloss -1910.94429  last_update 22\n",
      "train: iter 278  trainloss -2021.83277  validloss -1910.88975±0.00000  bestvalidloss -1910.94429  last_update 23\n",
      "train: iter 279  trainloss -1931.09093  validloss -1790.04651±0.00000  bestvalidloss -1910.94429  last_update 24\n",
      "train: iter 280  trainloss -2038.45202  validloss -1835.52229±0.00000  bestvalidloss -1910.94429  last_update 25\n",
      "train: iter 281  trainloss -2076.73590  validloss -1897.79780±0.00000  bestvalidloss -1910.94429  last_update 26\n",
      "train: iter 282  trainloss -2064.82258  validloss -1914.77255±0.00000  bestvalidloss -1914.77255  last_update 0\n",
      "train: iter 283  trainloss -2068.75107  validloss -1884.22297±0.00000  bestvalidloss -1914.77255  last_update 1\n",
      "train: iter 284  trainloss -2075.03492  validloss -1894.68352±0.00000  bestvalidloss -1914.77255  last_update 2\n",
      "train: iter 285  trainloss -2082.70261  validloss -1894.39771±0.00000  bestvalidloss -1914.77255  last_update 3\n",
      "train: iter 286  trainloss -2056.32051  validloss -1898.57728±0.00000  bestvalidloss -1914.77255  last_update 4\n",
      "train: iter 287  trainloss -2085.83250  validloss -1898.97634±0.00000  bestvalidloss -1914.77255  last_update 5\n",
      "train: iter 288  trainloss -2062.42760  validloss -1908.12757±0.00000  bestvalidloss -1914.77255  last_update 6\n",
      "train: iter 289  trainloss -2073.00858  validloss -1875.85363±0.00000  bestvalidloss -1914.77255  last_update 7\n",
      "train: iter 290  trainloss -1999.82463  validloss -1907.42442±0.00000  bestvalidloss -1914.77255  last_update 8\n",
      "train: iter 291  trainloss -2013.67508  validloss -1812.56015±0.00000  bestvalidloss -1914.77255  last_update 9\n",
      "train: iter 292  trainloss -2061.16290  validloss -1929.34614±0.00000  bestvalidloss -1929.34614  last_update 0\n",
      "train: iter 293  trainloss -2035.52958  validloss -1874.40045±0.00000  bestvalidloss -1929.34614  last_update 1\n",
      "train: iter 294  trainloss -2030.88435  validloss -1896.79333±0.00000  bestvalidloss -1929.34614  last_update 2\n",
      "train: iter 295  trainloss -2060.28445  validloss -1931.72602±0.00000  bestvalidloss -1931.72602  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 296  trainloss -2079.60911  validloss -1872.68477±0.00000  bestvalidloss -1931.72602  last_update 1\n",
      "train: iter 297  trainloss -2055.49340  validloss -1890.34636±0.00000  bestvalidloss -1931.72602  last_update 2\n",
      "train: iter 298  trainloss -2030.31448  validloss -1830.48787±0.00000  bestvalidloss -1931.72602  last_update 3\n",
      "train: iter 299  trainloss -2025.57617  validloss -1908.31396±0.00000  bestvalidloss -1931.72602  last_update 4\n",
      "train: iter 300  trainloss -2043.68853  validloss -1874.28888±0.00000  bestvalidloss -1931.72602  last_update 5\n",
      "train: iter 301  trainloss -2079.39541  validloss -1912.26583±0.00000  bestvalidloss -1931.72602  last_update 6\n",
      "train: iter 302  trainloss -2068.28329  validloss -1900.35543±0.00000  bestvalidloss -1931.72602  last_update 7\n",
      "train: iter 303  trainloss -2080.15102  validloss -1887.34265±0.00000  bestvalidloss -1931.72602  last_update 8\n",
      "train: iter 304  trainloss -2085.97267  validloss -1892.88532±0.00000  bestvalidloss -1931.72602  last_update 9\n",
      "train: iter 305  trainloss -2059.00861  validloss -1922.26045±0.00000  bestvalidloss -1931.72602  last_update 10\n",
      "train: iter 306  trainloss -1813.07019  validloss -1746.15179±0.00000  bestvalidloss -1931.72602  last_update 11\n",
      "train: iter 307  trainloss -2052.10556  validloss -1815.16406±0.00000  bestvalidloss -1931.72602  last_update 12\n",
      "train: iter 308  trainloss -2074.21670  validloss -1891.95644±0.00000  bestvalidloss -1931.72602  last_update 13\n",
      "train: iter 309  trainloss -2076.81535  validloss -1900.81865±0.00000  bestvalidloss -1931.72602  last_update 14\n",
      "train: iter 310  trainloss -2064.62910  validloss -1914.41331±0.00000  bestvalidloss -1931.72602  last_update 15\n",
      "train: iter 311  trainloss -2081.64960  validloss -1827.48547±0.00000  bestvalidloss -1931.72602  last_update 16\n",
      "train: iter 312  trainloss -2083.89378  validloss -1847.20536±0.00000  bestvalidloss -1931.72602  last_update 17\n",
      "train: iter 313  trainloss -2044.66311  validloss -1853.00980±0.00000  bestvalidloss -1931.72602  last_update 18\n",
      "train: iter 314  trainloss -2030.07473  validloss -1898.16696±0.00000  bestvalidloss -1931.72602  last_update 19\n",
      "train: iter 315  trainloss -2075.29483  validloss -1930.04412±0.00000  bestvalidloss -1931.72602  last_update 20\n",
      "train: iter 316  trainloss -2061.04881  validloss -1889.20056±0.00000  bestvalidloss -1931.72602  last_update 21\n",
      "train: iter 317  trainloss -2044.41991  validloss -1764.37028±0.00000  bestvalidloss -1931.72602  last_update 22\n",
      "train: iter 318  trainloss -2025.27007  validloss -1874.13443±0.00000  bestvalidloss -1931.72602  last_update 23\n",
      "train: iter 319  trainloss -2006.78534  validloss -1786.59700±0.00000  bestvalidloss -1931.72602  last_update 24\n",
      "train: iter 320  trainloss -2056.06409  validloss -1846.89023±0.00000  bestvalidloss -1931.72602  last_update 25\n",
      "train: iter 321  trainloss -2082.64827  validloss -1891.57795±0.00000  bestvalidloss -1931.72602  last_update 26\n",
      "train: iter 322  trainloss -2093.60842  validloss -1871.19521±0.00000  bestvalidloss -1931.72602  last_update 27\n",
      "train: iter 323  trainloss -2077.37633  validloss -1858.96547±0.00000  bestvalidloss -1931.72602  last_update 28\n",
      "train: iter 324  trainloss -2082.55036  validloss -1851.96586±0.00000  bestvalidloss -1931.72602  last_update 29\n",
      "train: iter 325  trainloss -2085.30638  validloss -1859.81171±0.00000  bestvalidloss -1931.72602  last_update 30\n",
      "train: iter 326  trainloss -2061.24334  validloss -1908.68367±0.00000  bestvalidloss -1931.72602  last_update 31\n",
      "train: iter 327  trainloss -2070.15691  validloss -1856.54579±0.00000  bestvalidloss -1931.72602  last_update 32\n",
      "train: iter 328  trainloss -1974.60536  validloss -1771.03218±0.00000  bestvalidloss -1931.72602  last_update 33\n",
      "train: iter 329  trainloss -2006.30606  validloss -1804.98465±0.00000  bestvalidloss -1931.72602  last_update 34\n",
      "train: iter 330  trainloss -2054.73637  validloss -1847.58940±0.00000  bestvalidloss -1931.72602  last_update 35\n",
      "train: iter 331  trainloss -2085.42686  validloss -1891.33274±0.00000  bestvalidloss -1931.72602  last_update 36\n",
      "train: iter 332  trainloss -2092.57879  validloss -1893.20371±0.00000  bestvalidloss -1931.72602  last_update 37\n",
      "train: iter 333  trainloss -2078.74118  validloss -1895.03790±0.00000  bestvalidloss -1931.72602  last_update 38\n",
      "train: iter 334  trainloss -2020.18639  validloss -1778.08428±0.00000  bestvalidloss -1931.72602  last_update 39\n",
      "train: iter 335  trainloss -2060.20758  validloss -1844.67430±0.00000  bestvalidloss -1931.72602  last_update 40\n",
      "train: iter 336  trainloss -2074.78252  validloss -1862.09517±0.00000  bestvalidloss -1931.72602  last_update 41\n",
      "train: iter 337  trainloss -2099.94206  validloss -1841.39149±0.00000  bestvalidloss -1931.72602  last_update 42\n",
      "train: iter 338  trainloss -2089.28308  validloss -1813.57484±0.00000  bestvalidloss -1931.72602  last_update 43\n",
      "train: iter 339  trainloss -2066.45829  validloss -1875.63065±0.00000  bestvalidloss -1931.72602  last_update 44\n",
      "train: iter 340  trainloss -2086.08020  validloss -1869.40710±0.00000  bestvalidloss -1931.72602  last_update 45\n",
      "train: iter 341  trainloss -2060.72300  validloss -1865.76888±0.00000  bestvalidloss -1931.72602  last_update 46\n",
      "train: iter 342  trainloss -2011.08461  validloss -1898.01861±0.00000  bestvalidloss -1931.72602  last_update 47\n",
      "train: iter 343  trainloss -2073.72786  validloss -1824.44735±0.00000  bestvalidloss -1931.72602  last_update 48\n",
      "train: iter 344  trainloss -2058.87322  validloss -1854.62037±0.00000  bestvalidloss -1931.72602  last_update 49\n",
      "train: iter 345  trainloss -2081.94895  validloss -1864.56185±0.00000  bestvalidloss -1931.72602  last_update 50\n",
      "train: iter 346  trainloss -2025.69682  validloss -1911.55523±0.00000  bestvalidloss -1931.72602  last_update 51\n",
      "train: iter 347  trainloss -2083.47457  validloss -1866.38409±0.00000  bestvalidloss -1931.72602  last_update 52\n",
      "train: iter 348  trainloss -2071.91022  validloss -1900.27817±0.00000  bestvalidloss -1931.72602  last_update 53\n",
      "train: iter 349  trainloss -2088.75324  validloss -1899.21995±0.00000  bestvalidloss -1931.72602  last_update 54\n",
      "train: iter 350  trainloss -2085.12295  validloss -1885.89633±0.00000  bestvalidloss -1931.72602  last_update 55\n",
      "train: iter 351  trainloss -2028.08601  validloss -1832.17589±0.00000  bestvalidloss -1931.72602  last_update 56\n",
      "train: iter 352  trainloss -2047.83455  validloss -1913.33496±0.00000  bestvalidloss -1931.72602  last_update 57\n",
      "train: iter 353  trainloss -2063.69668  validloss -1863.67350±0.00000  bestvalidloss -1931.72602  last_update 58\n",
      "train: iter 354  trainloss -2078.43129  validloss -1862.50155±0.00000  bestvalidloss -1931.72602  last_update 59\n",
      "train: iter 355  trainloss -2008.45613  validloss -1868.56809±0.00000  bestvalidloss -1931.72602  last_update 60\n",
      "train: iter 356  trainloss -2055.84815  validloss -1863.68806±0.00000  bestvalidloss -1931.72602  last_update 61\n",
      "train: iter 357  trainloss -2026.03074  validloss -1816.31150±0.00000  bestvalidloss -1931.72602  last_update 62\n",
      "train: iter 358  trainloss -2072.09516  validloss -1927.42701±0.00000  bestvalidloss -1931.72602  last_update 63\n",
      "train: iter 359  trainloss -2102.81020  validloss -1920.80046±0.00000  bestvalidloss -1931.72602  last_update 64\n",
      "train: iter 360  trainloss -2099.52819  validloss -1920.76029±0.00000  bestvalidloss -1931.72602  last_update 65\n",
      "train: iter 361  trainloss -2105.73461  validloss -1912.20107±0.00000  bestvalidloss -1931.72602  last_update 66\n",
      "train: iter 362  trainloss -2087.25050  validloss -1905.79673±0.00000  bestvalidloss -1931.72602  last_update 67\n",
      "train: iter 363  trainloss -2100.71572  validloss -1971.05059±0.00000  bestvalidloss -1971.05059  last_update 0\n",
      "train: iter 364  trainloss -2092.19228  validloss -1932.60914±0.00000  bestvalidloss -1971.05059  last_update 1\n",
      "train: iter 365  trainloss -2094.41696  validloss -1943.53161±0.00000  bestvalidloss -1971.05059  last_update 2\n",
      "train: iter 366  trainloss -2106.14932  validloss -1953.74096±0.00000  bestvalidloss -1971.05059  last_update 3\n",
      "train: iter 367  trainloss -2064.39004  validloss -1863.21079±0.00000  bestvalidloss -1971.05059  last_update 4\n",
      "train: iter 368  trainloss -2054.98197  validloss -1866.57278±0.00000  bestvalidloss -1971.05059  last_update 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 369  trainloss -2077.34131  validloss -1954.79042±0.00000  bestvalidloss -1971.05059  last_update 6\n",
      "train: iter 370  trainloss -2076.15350  validloss -1850.97345±0.00000  bestvalidloss -1971.05059  last_update 7\n",
      "train: iter 371  trainloss -2097.56250  validloss -1929.63522±0.00000  bestvalidloss -1971.05059  last_update 8\n",
      "train: iter 372  trainloss -2096.22708  validloss -1911.42777±0.00000  bestvalidloss -1971.05059  last_update 9\n",
      "train: iter 373  trainloss -1862.02768  validloss -1743.36571±0.00000  bestvalidloss -1971.05059  last_update 10\n",
      "train: iter 374  trainloss -2045.21155  validloss -1636.62992±0.00000  bestvalidloss -1971.05059  last_update 11\n",
      "train: iter 375  trainloss -2103.33569  validloss -1892.81840±0.00000  bestvalidloss -1971.05059  last_update 12\n",
      "train: iter 376  trainloss -2098.99404  validloss -1922.51117±0.00000  bestvalidloss -1971.05059  last_update 13\n",
      "train: iter 377  trainloss -2095.59128  validloss -1955.66007±0.00000  bestvalidloss -1971.05059  last_update 14\n",
      "train: iter 378  trainloss -2097.84505  validloss -1862.26225±0.00000  bestvalidloss -1971.05059  last_update 15\n",
      "train: iter 379  trainloss -2046.05490  validloss -1878.98674±0.00000  bestvalidloss -1971.05059  last_update 16\n",
      "train: iter 380  trainloss -2113.03017  validloss -1954.49316±0.00000  bestvalidloss -1971.05059  last_update 17\n",
      "train: iter 381  trainloss -2092.37401  validloss -1917.23929±0.00000  bestvalidloss -1971.05059  last_update 18\n",
      "train: iter 382  trainloss -2079.62526  validloss -1956.39006±0.00000  bestvalidloss -1971.05059  last_update 19\n",
      "train: iter 383  trainloss -2060.18194  validloss -1906.67791±0.00000  bestvalidloss -1971.05059  last_update 20\n",
      "train: iter 384  trainloss -2032.78624  validloss -1896.40800±0.00000  bestvalidloss -1971.05059  last_update 21\n",
      "train: iter 385  trainloss -2037.95348  validloss -1702.93323±0.00000  bestvalidloss -1971.05059  last_update 22\n",
      "train: iter 386  trainloss -2065.22716  validloss -1916.17304±0.00000  bestvalidloss -1971.05059  last_update 23\n",
      "train: iter 387  trainloss -2110.80257  validloss -1940.86387±0.00000  bestvalidloss -1971.05059  last_update 24\n",
      "train: iter 388  trainloss -2081.80958  validloss -1808.06293±0.00000  bestvalidloss -1971.05059  last_update 25\n",
      "train: iter 389  trainloss -2109.53852  validloss -1918.86764±0.00000  bestvalidloss -1971.05059  last_update 26\n",
      "train: iter 390  trainloss -2100.79964  validloss -1947.94756±0.00000  bestvalidloss -1971.05059  last_update 27\n",
      "train: iter 391  trainloss -2099.90997  validloss -1922.43063±0.00000  bestvalidloss -1971.05059  last_update 28\n",
      "train: iter 392  trainloss -2081.20009  validloss -1965.98725±0.00000  bestvalidloss -1971.05059  last_update 29\n",
      "train: iter 393  trainloss -2115.10815  validloss -1914.52473±0.00000  bestvalidloss -1971.05059  last_update 30\n",
      "train: iter 394  trainloss -2096.88660  validloss -1917.40337±0.00000  bestvalidloss -1971.05059  last_update 31\n",
      "train: iter 395  trainloss -2080.93524  validloss -1894.22287±0.00000  bestvalidloss -1971.05059  last_update 32\n",
      "train: iter 396  trainloss -2071.89445  validloss -1858.62369±0.00000  bestvalidloss -1971.05059  last_update 33\n",
      "train: iter 397  trainloss -2092.36936  validloss -1874.27215±0.00000  bestvalidloss -1971.05059  last_update 34\n",
      "train: iter 398  trainloss -2094.64525  validloss -1896.18572±0.00000  bestvalidloss -1971.05059  last_update 35\n",
      "train: iter 399  trainloss -2044.67156  validloss -1876.10584±0.00000  bestvalidloss -1971.05059  last_update 36\n",
      "train: iter 400  trainloss -2112.71100  validloss -1981.76264±0.00000  bestvalidloss -1981.76264  last_update 0\n",
      "train: iter 401  trainloss -2097.65087  validloss -1951.60443±0.00000  bestvalidloss -1981.76264  last_update 1\n",
      "train: iter 402  trainloss -2017.80586  validloss -1871.93376±0.00000  bestvalidloss -1981.76264  last_update 2\n",
      "train: iter 403  trainloss -2076.77478  validloss -1761.88446±0.00000  bestvalidloss -1981.76264  last_update 3\n",
      "train: iter 404  trainloss -2051.23504  validloss -1942.38474±0.00000  bestvalidloss -1981.76264  last_update 4\n",
      "train: iter 405  trainloss -2107.99360  validloss -1957.83050±0.00000  bestvalidloss -1981.76264  last_update 5\n",
      "train: iter 406  trainloss -2108.51533  validloss -1969.89453±0.00000  bestvalidloss -1981.76264  last_update 6\n",
      "train: iter 407  trainloss -2107.47312  validloss -1957.13784±0.00000  bestvalidloss -1981.76264  last_update 7\n",
      "train: iter 408  trainloss -2101.55362  validloss -1961.62644±0.00000  bestvalidloss -1981.76264  last_update 8\n",
      "train: iter 409  trainloss -2095.65343  validloss -1967.48746±0.00000  bestvalidloss -1981.76264  last_update 9\n",
      "train: iter 410  trainloss -2119.00079  validloss -1912.83671±0.00000  bestvalidloss -1981.76264  last_update 10\n",
      "train: iter 411  trainloss -2118.97143  validloss -1943.85394±0.00000  bestvalidloss -1981.76264  last_update 11\n",
      "train: iter 412  trainloss -2111.35226  validloss -1912.93621±0.00000  bestvalidloss -1981.76264  last_update 12\n",
      "train: iter 413  trainloss -2060.96885  validloss -1920.29383±0.00000  bestvalidloss -1981.76264  last_update 13\n",
      "train: iter 414  trainloss -2088.91555  validloss -1861.33470±0.00000  bestvalidloss -1981.76264  last_update 14\n",
      "train: iter 415  trainloss -2093.70125  validloss -1975.36822±0.00000  bestvalidloss -1981.76264  last_update 15\n",
      "train: iter 416  trainloss -2117.02263  validloss -1951.78873±0.00000  bestvalidloss -1981.76264  last_update 16\n",
      "train: iter 417  trainloss -2054.00674  validloss -1935.86170±0.00000  bestvalidloss -1981.76264  last_update 17\n",
      "train: iter 418  trainloss -2057.34821  validloss -1901.79359±0.00000  bestvalidloss -1981.76264  last_update 18\n",
      "train: iter 419  trainloss -2098.61676  validloss -1810.77581±0.00000  bestvalidloss -1981.76264  last_update 19\n",
      "train: iter 420  trainloss -2123.47305  validloss -1935.36454±0.00000  bestvalidloss -1981.76264  last_update 20\n",
      "train: iter 421  trainloss -2103.94332  validloss -1928.59588±0.00000  bestvalidloss -1981.76264  last_update 21\n",
      "train: iter 422  trainloss -2118.63540  validloss -1969.32764±0.00000  bestvalidloss -1981.76264  last_update 22\n",
      "train: iter 423  trainloss -1952.64086  validloss -1956.03756±0.00000  bestvalidloss -1981.76264  last_update 23\n",
      "train: iter 424  trainloss -2087.65007  validloss -1855.40698±0.00000  bestvalidloss -1981.76264  last_update 24\n",
      "train: iter 425  trainloss -2116.66774  validloss -1932.90348±0.00000  bestvalidloss -1981.76264  last_update 25\n",
      "train: iter 426  trainloss -2093.76649  validloss -1949.28459±0.00000  bestvalidloss -1981.76264  last_update 26\n",
      "train: iter 427  trainloss -2113.15641  validloss -1921.11408±0.00000  bestvalidloss -1981.76264  last_update 27\n",
      "train: iter 428  trainloss -2116.58846  validloss -1954.44937±0.00000  bestvalidloss -1981.76264  last_update 28\n",
      "train: iter 429  trainloss -2096.00637  validloss -1941.89303±0.00000  bestvalidloss -1981.76264  last_update 29\n",
      "train: iter 430  trainloss -2112.13379  validloss -1968.66646±0.00000  bestvalidloss -1981.76264  last_update 30\n",
      "train: iter 431  trainloss -2106.93116  validloss -1941.01173±0.00000  bestvalidloss -1981.76264  last_update 31\n",
      "train: iter 432  trainloss -2118.11855  validloss -1964.29693±0.00000  bestvalidloss -1981.76264  last_update 32\n",
      "train: iter 433  trainloss -2042.36944  validloss -1868.09074±0.00000  bestvalidloss -1981.76264  last_update 33\n",
      "train: iter 434  trainloss -2089.00952  validloss -1826.00135±0.00000  bestvalidloss -1981.76264  last_update 34\n",
      "train: iter 435  trainloss -2105.46438  validloss -1967.71591±0.00000  bestvalidloss -1981.76264  last_update 35\n",
      "train: iter 436  trainloss -2115.58346  validloss -1914.72020±0.00000  bestvalidloss -1981.76264  last_update 36\n",
      "train: iter 437  trainloss -2004.03310  validloss -1854.55842±0.00000  bestvalidloss -1981.76264  last_update 37\n",
      "train: iter 438  trainloss -2109.55807  validloss -1984.88303±0.00000  bestvalidloss -1984.88303  last_update 0\n",
      "train: iter 439  trainloss -2116.38360  validloss -1973.37931±0.00000  bestvalidloss -1984.88303  last_update 1\n",
      "train: iter 440  trainloss -2103.04496  validloss -1959.15564±0.00000  bestvalidloss -1984.88303  last_update 2\n",
      "train: iter 441  trainloss -2129.46525  validloss -2016.19532±0.00000  bestvalidloss -2016.19532  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 442  trainloss -2095.12511  validloss -1983.43298±0.00000  bestvalidloss -2016.19532  last_update 1\n",
      "train: iter 443  trainloss -2121.64075  validloss -1984.53942±0.00000  bestvalidloss -2016.19532  last_update 2\n",
      "train: iter 444  trainloss -2116.77093  validloss -1991.36818±0.00000  bestvalidloss -2016.19532  last_update 3\n",
      "train: iter 445  trainloss -2104.81289  validloss -1970.51722±0.00000  bestvalidloss -2016.19532  last_update 4\n",
      "train: iter 446  trainloss -2099.85991  validloss -1970.43383±0.00000  bestvalidloss -2016.19532  last_update 5\n",
      "train: iter 447  trainloss -2112.82757  validloss -1992.95078±0.00000  bestvalidloss -2016.19532  last_update 6\n",
      "train: iter 448  trainloss -2110.51509  validloss -1955.17617±0.00000  bestvalidloss -2016.19532  last_update 7\n",
      "train: iter 449  trainloss -2106.71914  validloss -1913.08384±0.00000  bestvalidloss -2016.19532  last_update 8\n",
      "train: iter 450  trainloss -2103.63819  validloss -1929.84637±0.00000  bestvalidloss -2016.19532  last_update 9\n",
      "train: iter 451  trainloss -2109.73619  validloss -1963.41763±0.00000  bestvalidloss -2016.19532  last_update 10\n",
      "train: iter 452  trainloss -2077.60503  validloss -1890.55198±0.00000  bestvalidloss -2016.19532  last_update 11\n",
      "train: iter 453  trainloss -2111.07363  validloss -1819.37002±0.00000  bestvalidloss -2016.19532  last_update 12\n",
      "train: iter 454  trainloss -2078.55269  validloss -1934.04865±0.00000  bestvalidloss -2016.19532  last_update 13\n",
      "train: iter 455  trainloss -2102.96386  validloss -1957.40092±0.00000  bestvalidloss -2016.19532  last_update 14\n",
      "train: iter 456  trainloss -2127.47091  validloss -1979.35952±0.00000  bestvalidloss -2016.19532  last_update 15\n",
      "train: iter 457  trainloss -2100.23049  validloss -1985.62251±0.00000  bestvalidloss -2016.19532  last_update 16\n",
      "train: iter 458  trainloss -2115.84068  validloss -1930.61898±0.00000  bestvalidloss -2016.19532  last_update 17\n",
      "train: iter 459  trainloss -2049.51002  validloss -1897.56503±0.00000  bestvalidloss -2016.19532  last_update 18\n",
      "train: iter 460  trainloss -2108.17837  validloss -1807.27309±0.00000  bestvalidloss -2016.19532  last_update 19\n",
      "train: iter 461  trainloss -2059.88492  validloss -1940.79488±0.00000  bestvalidloss -2016.19532  last_update 20\n",
      "train: iter 462  trainloss -2104.29428  validloss -1954.11661±0.00000  bestvalidloss -2016.19532  last_update 21\n",
      "train: iter 463  trainloss -2092.83547  validloss -1941.36791±0.00000  bestvalidloss -2016.19532  last_update 22\n",
      "train: iter 464  trainloss -2107.78686  validloss -1955.08793±0.00000  bestvalidloss -2016.19532  last_update 23\n",
      "train: iter 465  trainloss -2078.09962  validloss -1999.07663±0.00000  bestvalidloss -2016.19532  last_update 24\n",
      "train: iter 466  trainloss -2073.29908  validloss -1970.74860±0.00000  bestvalidloss -2016.19532  last_update 25\n",
      "train: iter 467  trainloss -2102.49180  validloss -1916.35253±0.00000  bestvalidloss -2016.19532  last_update 26\n",
      "train: iter 468  trainloss -2104.37404  validloss -1965.46476±0.00000  bestvalidloss -2016.19532  last_update 27\n",
      "train: iter 469  trainloss -2121.00958  validloss -1939.63816±0.00000  bestvalidloss -2016.19532  last_update 28\n",
      "train: iter 470  trainloss -2111.96414  validloss -1937.36410±0.00000  bestvalidloss -2016.19532  last_update 29\n",
      "train: iter 471  trainloss -2110.41111  validloss -1911.05009±0.00000  bestvalidloss -2016.19532  last_update 30\n",
      "train: iter 472  trainloss -2108.36819  validloss -1959.17808±0.00000  bestvalidloss -2016.19532  last_update 31\n",
      "train: iter 473  trainloss -2101.16245  validloss -1935.28698±0.00000  bestvalidloss -2016.19532  last_update 32\n",
      "train: iter 474  trainloss -2113.15969  validloss -1981.28281±0.00000  bestvalidloss -2016.19532  last_update 33\n",
      "train: iter 475  trainloss -2123.64514  validloss -2000.93029±0.00000  bestvalidloss -2016.19532  last_update 34\n",
      "train: iter 476  trainloss -2135.56978  validloss -1976.88008±0.00000  bestvalidloss -2016.19532  last_update 35\n",
      "train: iter 477  trainloss -2125.91538  validloss -1935.84229±0.00000  bestvalidloss -2016.19532  last_update 36\n",
      "train: iter 478  trainloss -2127.64720  validloss -1968.46691±0.00000  bestvalidloss -2016.19532  last_update 37\n",
      "train: iter 479  trainloss -2121.87217  validloss -1982.84022±0.00000  bestvalidloss -2016.19532  last_update 38\n",
      "train: iter 480  trainloss -2075.06994  validloss -1920.33216±0.00000  bestvalidloss -2016.19532  last_update 39\n",
      "train: iter 481  trainloss -2047.84846  validloss -1805.49244±0.00000  bestvalidloss -2016.19532  last_update 40\n",
      "train: iter 482  trainloss -2098.61031  validloss -1818.70723±0.00000  bestvalidloss -2016.19532  last_update 41\n",
      "train: iter 483  trainloss -2087.77561  validloss -1961.66061±0.00000  bestvalidloss -2016.19532  last_update 42\n",
      "train: iter 484  trainloss -2137.27447  validloss -1947.85578±0.00000  bestvalidloss -2016.19532  last_update 43\n",
      "train: iter 485  trainloss -2137.60549  validloss -2024.44924±0.00000  bestvalidloss -2024.44924  last_update 0\n",
      "train: iter 486  trainloss -2088.73825  validloss -1997.94346±0.00000  bestvalidloss -2024.44924  last_update 1\n",
      "train: iter 487  trainloss -2122.09209  validloss -1986.35808±0.00000  bestvalidloss -2024.44924  last_update 2\n",
      "train: iter 488  trainloss -1998.04329  validloss -1919.12897±0.00000  bestvalidloss -2024.44924  last_update 3\n",
      "train: iter 489  trainloss -2090.10127  validloss -1841.87901±0.00000  bestvalidloss -2024.44924  last_update 4\n",
      "train: iter 490  trainloss -2109.60544  validloss -2026.36814±0.00000  bestvalidloss -2026.36814  last_update 0\n",
      "train: iter 491  trainloss -2122.34430  validloss -1999.07712±0.00000  bestvalidloss -2026.36814  last_update 1\n",
      "train: iter 492  trainloss -2072.87856  validloss -1988.42950±0.00000  bestvalidloss -2026.36814  last_update 2\n",
      "train: iter 493  trainloss -2133.08030  validloss -1982.09569±0.00000  bestvalidloss -2026.36814  last_update 3\n",
      "train: iter 494  trainloss -2141.02251  validloss -2013.23887±0.00000  bestvalidloss -2026.36814  last_update 4\n",
      "train: iter 495  trainloss -2101.44886  validloss -2005.84146±0.00000  bestvalidloss -2026.36814  last_update 5\n",
      "train: iter 496  trainloss -2127.58543  validloss -1995.89752±0.00000  bestvalidloss -2026.36814  last_update 6\n",
      "train: iter 497  trainloss -2098.66345  validloss -1994.06995±0.00000  bestvalidloss -2026.36814  last_update 7\n",
      "train: iter 498  trainloss -2114.24093  validloss -1975.35118±0.00000  bestvalidloss -2026.36814  last_update 8\n",
      "train: iter 499  trainloss -2131.78608  validloss -2032.42557±0.00000  bestvalidloss -2032.42557  last_update 0\n",
      "train: iter 500  trainloss -2119.73364  validloss -1959.32888±0.00000  bestvalidloss -2032.42557  last_update 1\n",
      "train: iter 501  trainloss -2113.76444  validloss -2011.48398±0.00000  bestvalidloss -2032.42557  last_update 2\n",
      "train: iter 502  trainloss -2133.63717  validloss -2020.33220±0.00000  bestvalidloss -2032.42557  last_update 3\n",
      "train: iter 503  trainloss -2103.07898  validloss -1994.71553±0.00000  bestvalidloss -2032.42557  last_update 4\n",
      "train: iter 504  trainloss -2111.35356  validloss -2022.64660±0.00000  bestvalidloss -2032.42557  last_update 5\n",
      "train: iter 505  trainloss -2019.46363  validloss -1940.79039±0.00000  bestvalidloss -2032.42557  last_update 6\n",
      "train: iter 506  trainloss -2096.59282  validloss -1722.39331±0.00000  bestvalidloss -2032.42557  last_update 7\n",
      "train: iter 507  trainloss -2087.51457  validloss -1981.43002±0.00000  bestvalidloss -2032.42557  last_update 8\n",
      "train: iter 508  trainloss -2135.61837  validloss -1992.87309±0.00000  bestvalidloss -2032.42557  last_update 9\n",
      "train: iter 509  trainloss -2134.72835  validloss -2013.41374±0.00000  bestvalidloss -2032.42557  last_update 10\n",
      "train: iter 510  trainloss -2114.76204  validloss -1992.13653±0.00000  bestvalidloss -2032.42557  last_update 11\n",
      "train: iter 511  trainloss -2120.74405  validloss -2015.85116±0.00000  bestvalidloss -2032.42557  last_update 12\n",
      "train: iter 512  trainloss -2132.61457  validloss -2034.97523±0.00000  bestvalidloss -2034.97523  last_update 0\n",
      "train: iter 513  trainloss -2099.18399  validloss -1952.96684±0.00000  bestvalidloss -2034.97523  last_update 1\n",
      "train: iter 514  trainloss -2104.35889  validloss -1850.65389±0.00000  bestvalidloss -2034.97523  last_update 2\n",
      "train: iter 515  trainloss -2081.10467  validloss -1899.08091±0.00000  bestvalidloss -2034.97523  last_update 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 516  trainloss -2115.83728  validloss -1989.08333±0.00000  bestvalidloss -2034.97523  last_update 4\n",
      "train: iter 517  trainloss -2114.07775  validloss -2016.71940±0.00000  bestvalidloss -2034.97523  last_update 5\n",
      "train: iter 518  trainloss -2107.84601  validloss -2007.35705±0.00000  bestvalidloss -2034.97523  last_update 6\n",
      "train: iter 519  trainloss -2129.68251  validloss -2035.29883±0.00000  bestvalidloss -2035.29883  last_update 0\n",
      "train: iter 520  trainloss -2108.83248  validloss -2004.49064±0.00000  bestvalidloss -2035.29883  last_update 1\n",
      "train: iter 521  trainloss -2122.26054  validloss -1955.89626±0.00000  bestvalidloss -2035.29883  last_update 2\n",
      "train: iter 522  trainloss -2100.14681  validloss -2010.31910±0.00000  bestvalidloss -2035.29883  last_update 3\n",
      "train: iter 523  trainloss -2013.14221  validloss -2015.85083±0.00000  bestvalidloss -2035.29883  last_update 4\n",
      "train: iter 524  trainloss -2095.43769  validloss -1935.44478±0.00000  bestvalidloss -2035.29883  last_update 5\n",
      "train: iter 525  trainloss -2095.52531  validloss -1955.91419±0.00000  bestvalidloss -2035.29883  last_update 6\n",
      "train: iter 526  trainloss -2114.01037  validloss -1991.27050±0.00000  bestvalidloss -2035.29883  last_update 7\n",
      "train: iter 527  trainloss -2130.13952  validloss -2036.96838±0.00000  bestvalidloss -2036.96838  last_update 0\n",
      "train: iter 528  trainloss -2129.08759  validloss -2030.38887±0.00000  bestvalidloss -2036.96838  last_update 1\n",
      "train: iter 529  trainloss -2146.16166  validloss -1995.77038±0.00000  bestvalidloss -2036.96838  last_update 2\n",
      "train: iter 530  trainloss -2098.51753  validloss -2006.40656±0.00000  bestvalidloss -2036.96838  last_update 3\n",
      "train: iter 531  trainloss -2126.32016  validloss -1929.70215±0.00000  bestvalidloss -2036.96838  last_update 4\n",
      "train: iter 532  trainloss -2133.82778  validloss -2016.12188±0.00000  bestvalidloss -2036.96838  last_update 5\n",
      "train: iter 533  trainloss -2123.29097  validloss -2015.85852±0.00000  bestvalidloss -2036.96838  last_update 6\n",
      "train: iter 534  trainloss -2145.93465  validloss -2036.98918±0.00000  bestvalidloss -2036.98918  last_update 0\n",
      "train: iter 535  trainloss -2128.59765  validloss -2030.15101±0.00000  bestvalidloss -2036.98918  last_update 1\n",
      "train: iter 536  trainloss -2135.31601  validloss -2027.49854±0.00000  bestvalidloss -2036.98918  last_update 2\n",
      "train: iter 537  trainloss -2134.69496  validloss -2025.24493±0.00000  bestvalidloss -2036.98918  last_update 3\n",
      "train: iter 538  trainloss -2139.14088  validloss -2037.77108±0.00000  bestvalidloss -2037.77108  last_update 0\n",
      "train: iter 539  trainloss -2121.95549  validloss -2053.56781±0.00000  bestvalidloss -2053.56781  last_update 0\n",
      "train: iter 540  trainloss -2096.40247  validloss -1956.87306±0.00000  bestvalidloss -2053.56781  last_update 1\n",
      "train: iter 541  trainloss -2007.52609  validloss -1930.38106±0.00000  bestvalidloss -2053.56781  last_update 2\n",
      "train: iter 542  trainloss -2115.63328  validloss -1940.62324±0.00000  bestvalidloss -2053.56781  last_update 3\n",
      "train: iter 543  trainloss -2138.99784  validloss -2014.81237±0.00000  bestvalidloss -2053.56781  last_update 4\n",
      "train: iter 544  trainloss -2139.15744  validloss -2010.31891±0.00000  bestvalidloss -2053.56781  last_update 5\n",
      "train: iter 545  trainloss -2098.41928  validloss -2033.04207±0.00000  bestvalidloss -2053.56781  last_update 6\n",
      "train: iter 546  trainloss -2102.46159  validloss -2000.86448±0.00000  bestvalidloss -2053.56781  last_update 7\n",
      "train: iter 547  trainloss -2111.73399  validloss -1990.55533±0.00000  bestvalidloss -2053.56781  last_update 8\n",
      "train: iter 548  trainloss -1999.85829  validloss -1953.32960±0.00000  bestvalidloss -2053.56781  last_update 9\n",
      "train: iter 549  trainloss -2122.92099  validloss -2031.26954±0.00000  bestvalidloss -2053.56781  last_update 10\n",
      "train: iter 550  trainloss -2130.53439  validloss -1991.54141±0.00000  bestvalidloss -2053.56781  last_update 11\n",
      "train: iter 551  trainloss -2108.19483  validloss -2014.57539±0.00000  bestvalidloss -2053.56781  last_update 12\n",
      "train: iter 552  trainloss -2123.89420  validloss -1960.40319±0.00000  bestvalidloss -2053.56781  last_update 13\n",
      "train: iter 553  trainloss -2142.23377  validloss -2029.50565±0.00000  bestvalidloss -2053.56781  last_update 14\n",
      "train: iter 554  trainloss -2094.36322  validloss -1972.03358±0.00000  bestvalidloss -2053.56781  last_update 15\n",
      "train: iter 555  trainloss -2116.58849  validloss -2034.73418±0.00000  bestvalidloss -2053.56781  last_update 16\n",
      "train: iter 556  trainloss -2103.78774  validloss -1982.40751±0.00000  bestvalidloss -2053.56781  last_update 17\n",
      "train: iter 557  trainloss -2135.07099  validloss -2025.74178±0.00000  bestvalidloss -2053.56781  last_update 18\n",
      "train: iter 558  trainloss -2142.89062  validloss -2002.79048±0.00000  bestvalidloss -2053.56781  last_update 19\n",
      "train: iter 559  trainloss -2147.89253  validloss -2047.14896±0.00000  bestvalidloss -2053.56781  last_update 20\n",
      "train: iter 560  trainloss -2149.54576  validloss -1934.02679±0.00000  bestvalidloss -2053.56781  last_update 21\n",
      "train: iter 561  trainloss -2142.53561  validloss -1987.20670±0.00000  bestvalidloss -2053.56781  last_update 22\n",
      "train: iter 562  trainloss -2132.91954  validloss -2011.43788±0.00000  bestvalidloss -2053.56781  last_update 23\n",
      "train: iter 563  trainloss -2137.59263  validloss -2038.10606±0.00000  bestvalidloss -2053.56781  last_update 24\n",
      "train: iter 564  trainloss -2145.11228  validloss -2050.53351±0.00000  bestvalidloss -2053.56781  last_update 25\n",
      "train: iter 565  trainloss -2141.43017  validloss -2020.79951±0.00000  bestvalidloss -2053.56781  last_update 26\n",
      "train: iter 566  trainloss -2127.25258  validloss -1978.19427±0.00000  bestvalidloss -2053.56781  last_update 27\n",
      "train: iter 567  trainloss -2019.26396  validloss -1974.71238±0.00000  bestvalidloss -2053.56781  last_update 28\n",
      "train: iter 568  trainloss -2129.43104  validloss -2009.03700±0.00000  bestvalidloss -2053.56781  last_update 29\n",
      "train: iter 569  trainloss -2117.58013  validloss -1990.82032±0.00000  bestvalidloss -2053.56781  last_update 30\n",
      "train: iter 570  trainloss -2144.67917  validloss -2034.22116±0.00000  bestvalidloss -2053.56781  last_update 31\n",
      "train: iter 571  trainloss -2125.85494  validloss -2045.29824±0.00000  bestvalidloss -2053.56781  last_update 32\n",
      "train: iter 572  trainloss -2110.19278  validloss -2005.06318±0.00000  bestvalidloss -2053.56781  last_update 33\n",
      "train: iter 573  trainloss -2136.09081  validloss -2019.67040±0.00000  bestvalidloss -2053.56781  last_update 34\n",
      "train: iter 574  trainloss -2116.26701  validloss -1981.28180±0.00000  bestvalidloss -2053.56781  last_update 35\n",
      "train: iter 575  trainloss -2147.41452  validloss -2051.82022±0.00000  bestvalidloss -2053.56781  last_update 36\n",
      "train: iter 576  trainloss -2144.51715  validloss -2023.57799±0.00000  bestvalidloss -2053.56781  last_update 37\n",
      "train: iter 577  trainloss -2144.92521  validloss -1986.66074±0.00000  bestvalidloss -2053.56781  last_update 38\n",
      "train: iter 578  trainloss -2134.21119  validloss -2045.15594±0.00000  bestvalidloss -2053.56781  last_update 39\n",
      "train: iter 579  trainloss -2121.12600  validloss -2014.58624±0.00000  bestvalidloss -2053.56781  last_update 40\n",
      "train: iter 580  trainloss -2152.96439  validloss -2050.04312±0.00000  bestvalidloss -2053.56781  last_update 41\n",
      "train: iter 581  trainloss -2133.04545  validloss -2051.70180±0.00000  bestvalidloss -2053.56781  last_update 42\n",
      "train: iter 582  trainloss -2131.76941  validloss -2052.29798±0.00000  bestvalidloss -2053.56781  last_update 43\n",
      "train: iter 583  trainloss -2114.05378  validloss -2005.51179±0.00000  bestvalidloss -2053.56781  last_update 44\n",
      "train: iter 584  trainloss -2125.12302  validloss -2024.49271±0.00000  bestvalidloss -2053.56781  last_update 45\n",
      "train: iter 585  trainloss -2126.97069  validloss -1971.19789±0.00000  bestvalidloss -2053.56781  last_update 46\n",
      "train: iter 586  trainloss -2139.28973  validloss -2015.72225±0.00000  bestvalidloss -2053.56781  last_update 47\n",
      "train: iter 587  trainloss -2134.48273  validloss -2000.20566±0.00000  bestvalidloss -2053.56781  last_update 48\n",
      "train: iter 588  trainloss -1967.62051  validloss -1958.90153±0.00000  bestvalidloss -2053.56781  last_update 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 589  trainloss -2089.49310  validloss -1898.53723±0.00000  bestvalidloss -2053.56781  last_update 50\n",
      "train: iter 590  trainloss -2131.55747  validloss -2030.11595±0.00000  bestvalidloss -2053.56781  last_update 51\n",
      "train: iter 591  trainloss -2121.32598  validloss -2009.63397±0.00000  bestvalidloss -2053.56781  last_update 52\n",
      "train: iter 592  trainloss -2120.80427  validloss -2024.13652±0.00000  bestvalidloss -2053.56781  last_update 53\n",
      "train: iter 593  trainloss -2151.50146  validloss -2035.12371±0.00000  bestvalidloss -2053.56781  last_update 54\n",
      "train: iter 594  trainloss -2155.26951  validloss -2057.38666±0.00000  bestvalidloss -2057.38666  last_update 0\n",
      "train: iter 595  trainloss -2145.56961  validloss -2041.07909±0.00000  bestvalidloss -2057.38666  last_update 1\n",
      "train: iter 596  trainloss -2118.77183  validloss -1998.81875±0.00000  bestvalidloss -2057.38666  last_update 2\n",
      "train: iter 597  trainloss -2136.09333  validloss -1996.63437±0.00000  bestvalidloss -2057.38666  last_update 3\n",
      "train: iter 598  trainloss -2122.93189  validloss -2011.84055±0.00000  bestvalidloss -2057.38666  last_update 4\n",
      "train: iter 599  trainloss -2137.39642  validloss -1968.52835±0.00000  bestvalidloss -2057.38666  last_update 5\n",
      "train: iter 600  trainloss -2136.17652  validloss -2043.79170±0.00000  bestvalidloss -2057.38666  last_update 6\n",
      "train: iter 601  trainloss -2049.96165  validloss -1966.87904±0.00000  bestvalidloss -2057.38666  last_update 7\n",
      "train: iter 602  trainloss -2063.92507  validloss -2047.29431±0.00000  bestvalidloss -2057.38666  last_update 8\n",
      "train: iter 603  trainloss -2096.78043  validloss -1905.85531±0.00000  bestvalidloss -2057.38666  last_update 9\n",
      "train: iter 604  trainloss -2125.06572  validloss -1964.62162±0.00000  bestvalidloss -2057.38666  last_update 10\n",
      "train: iter 605  trainloss -2149.56773  validloss -2039.31219±0.00000  bestvalidloss -2057.38666  last_update 11\n",
      "train: iter 606  trainloss -2135.95074  validloss -2011.81641±0.00000  bestvalidloss -2057.38666  last_update 12\n",
      "train: iter 607  trainloss -2142.45613  validloss -2046.51652±0.00000  bestvalidloss -2057.38666  last_update 13\n",
      "train: iter 608  trainloss -2141.24079  validloss -2060.46586±0.00000  bestvalidloss -2060.46586  last_update 0\n",
      "train: iter 609  trainloss -2158.51808  validloss -2046.58341±0.00000  bestvalidloss -2060.46586  last_update 1\n",
      "train: iter 610  trainloss -2124.23589  validloss -2028.71018±0.00000  bestvalidloss -2060.46586  last_update 2\n",
      "train: iter 611  trainloss -2102.81763  validloss -1982.94986±0.00000  bestvalidloss -2060.46586  last_update 3\n",
      "train: iter 612  trainloss -2126.04216  validloss -2043.13536±0.00000  bestvalidloss -2060.46586  last_update 4\n",
      "train: iter 613  trainloss -2141.50426  validloss -2027.67219±0.00000  bestvalidloss -2060.46586  last_update 5\n",
      "train: iter 614  trainloss -2133.47914  validloss -2044.15857±0.00000  bestvalidloss -2060.46586  last_update 6\n",
      "train: iter 615  trainloss -2157.60750  validloss -2057.05805±0.00000  bestvalidloss -2060.46586  last_update 7\n",
      "train: iter 616  trainloss -2145.94130  validloss -2036.56863±0.00000  bestvalidloss -2060.46586  last_update 8\n",
      "train: iter 617  trainloss -2137.04127  validloss -1986.26055±0.00000  bestvalidloss -2060.46586  last_update 9\n",
      "train: iter 618  trainloss -2115.91271  validloss -2015.97091±0.00000  bestvalidloss -2060.46586  last_update 10\n",
      "train: iter 619  trainloss -2139.11163  validloss -1981.02587±0.00000  bestvalidloss -2060.46586  last_update 11\n",
      "train: iter 620  trainloss -2146.88993  validloss -1987.53692±0.00000  bestvalidloss -2060.46586  last_update 12\n",
      "train: iter 621  trainloss -2139.79085  validloss -1984.28190±0.00000  bestvalidloss -2060.46586  last_update 13\n",
      "train: iter 622  trainloss -2147.38459  validloss -2033.79190±0.00000  bestvalidloss -2060.46586  last_update 14\n",
      "train: iter 623  trainloss -2129.33107  validloss -2035.48676±0.00000  bestvalidloss -2060.46586  last_update 15\n",
      "train: iter 624  trainloss -2164.98561  validloss -2057.02347±0.00000  bestvalidloss -2060.46586  last_update 16\n",
      "train: iter 625  trainloss -2158.24152  validloss -2042.64247±0.00000  bestvalidloss -2060.46586  last_update 17\n",
      "train: iter 626  trainloss -2154.83852  validloss -2033.81277±0.00000  bestvalidloss -2060.46586  last_update 18\n",
      "train: iter 627  trainloss -2148.70303  validloss -2039.14919±0.00000  bestvalidloss -2060.46586  last_update 19\n",
      "train: iter 628  trainloss -2024.83169  validloss -2010.14009±0.00000  bestvalidloss -2060.46586  last_update 20\n",
      "train: iter 629  trainloss -2031.14373  validloss -1815.43471±0.00000  bestvalidloss -2060.46586  last_update 21\n",
      "train: iter 630  trainloss -2094.28823  validloss -2025.34173±0.00000  bestvalidloss -2060.46586  last_update 22\n",
      "train: iter 631  trainloss -2144.13936  validloss -2041.25244±0.00000  bestvalidloss -2060.46586  last_update 23\n",
      "train: iter 632  trainloss -2113.07009  validloss -1998.28757±0.00000  bestvalidloss -2060.46586  last_update 24\n",
      "train: iter 633  trainloss -2142.23367  validloss -2029.27053±0.00000  bestvalidloss -2060.46586  last_update 25\n",
      "train: iter 634  trainloss -2156.39277  validloss -2006.65365±0.00000  bestvalidloss -2060.46586  last_update 26\n",
      "train: iter 635  trainloss -2135.09182  validloss -2034.80709±0.00000  bestvalidloss -2060.46586  last_update 27\n",
      "train: iter 636  trainloss -2117.96958  validloss -2024.31818±0.00000  bestvalidloss -2060.46586  last_update 28\n",
      "train: iter 637  trainloss -2142.17637  validloss -2035.65042±0.00000  bestvalidloss -2060.46586  last_update 29\n",
      "train: iter 638  trainloss -2140.33278  validloss -2019.71140±0.00000  bestvalidloss -2060.46586  last_update 30\n",
      "train: iter 639  trainloss -2139.73176  validloss -2019.59966±0.00000  bestvalidloss -2060.46586  last_update 31\n",
      "train: iter 640  trainloss -2159.55899  validloss -2055.28298±0.00000  bestvalidloss -2060.46586  last_update 32\n",
      "train: iter 641  trainloss -2141.17298  validloss -2015.07927±0.00000  bestvalidloss -2060.46586  last_update 33\n",
      "train: iter 642  trainloss -2099.52298  validloss -1988.35103±0.00000  bestvalidloss -2060.46586  last_update 34\n",
      "train: iter 643  trainloss -2152.28469  validloss -2050.53607±0.00000  bestvalidloss -2060.46586  last_update 35\n",
      "train: iter 644  trainloss -2138.69982  validloss -2036.73298±0.00000  bestvalidloss -2060.46586  last_update 36\n",
      "train: iter 645  trainloss -2084.22724  validloss -2009.91100±0.00000  bestvalidloss -2060.46586  last_update 37\n",
      "train: iter 646  trainloss -2117.15545  validloss -2019.15742±0.00000  bestvalidloss -2060.46586  last_update 38\n",
      "train: iter 647  trainloss -2137.93472  validloss -2044.61319±0.00000  bestvalidloss -2060.46586  last_update 39\n",
      "train: iter 648  trainloss -2151.00111  validloss -2003.18348±0.00000  bestvalidloss -2060.46586  last_update 40\n",
      "train: iter 649  trainloss -2156.34059  validloss -2040.39576±0.00000  bestvalidloss -2060.46586  last_update 41\n",
      "train: iter 650  trainloss -2134.34644  validloss -1987.39177±0.00000  bestvalidloss -2060.46586  last_update 42\n",
      "train: iter 651  trainloss -2148.86446  validloss -2020.32369±0.00000  bestvalidloss -2060.46586  last_update 43\n",
      "train: iter 652  trainloss -2158.34963  validloss -2026.14498±0.00000  bestvalidloss -2060.46586  last_update 44\n",
      "train: iter 653  trainloss -2162.04599  validloss -2056.22123±0.00000  bestvalidloss -2060.46586  last_update 45\n",
      "train: iter 654  trainloss -2153.98017  validloss -1984.72721±0.00000  bestvalidloss -2060.46586  last_update 46\n",
      "train: iter 655  trainloss -2149.76658  validloss -2023.15020±0.00000  bestvalidloss -2060.46586  last_update 47\n",
      "train: iter 656  trainloss -2153.20267  validloss -2045.57720±0.00000  bestvalidloss -2060.46586  last_update 48\n",
      "train: iter 657  trainloss -2116.86694  validloss -2059.23834±0.00000  bestvalidloss -2060.46586  last_update 49\n",
      "train: iter 658  trainloss -2104.47109  validloss -1970.25611±0.00000  bestvalidloss -2060.46586  last_update 50\n",
      "train: iter 659  trainloss -2107.70582  validloss -1979.21111±0.00000  bestvalidloss -2060.46586  last_update 51\n",
      "train: iter 660  trainloss -2121.48091  validloss -2002.78007±0.00000  bestvalidloss -2060.46586  last_update 52\n",
      "train: iter 661  trainloss -2166.32925  validloss -2030.21212±0.00000  bestvalidloss -2060.46586  last_update 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 662  trainloss -2138.30215  validloss -2022.70504±0.00000  bestvalidloss -2060.46586  last_update 54\n",
      "train: iter 663  trainloss -2160.90389  validloss -2038.23311±0.00000  bestvalidloss -2060.46586  last_update 55\n",
      "train: iter 664  trainloss -2162.80188  validloss -2034.33532±0.00000  bestvalidloss -2060.46586  last_update 56\n",
      "train: iter 665  trainloss -2155.74004  validloss -2044.85422±0.00000  bestvalidloss -2060.46586  last_update 57\n",
      "train: iter 666  trainloss -2135.27576  validloss -2044.88251±0.00000  bestvalidloss -2060.46586  last_update 58\n",
      "train: iter 667  trainloss -2140.89100  validloss -2009.96195±0.00000  bestvalidloss -2060.46586  last_update 59\n",
      "train: iter 668  trainloss -2126.33566  validloss -1997.19860±0.00000  bestvalidloss -2060.46586  last_update 60\n",
      "train: iter 669  trainloss -2155.24910  validloss -2007.06501±0.00000  bestvalidloss -2060.46586  last_update 61\n",
      "train: iter 670  trainloss -2143.20688  validloss -2038.20334±0.00000  bestvalidloss -2060.46586  last_update 62\n",
      "train: iter 671  trainloss -2144.84173  validloss -2045.05407±0.00000  bestvalidloss -2060.46586  last_update 63\n",
      "train: iter 672  trainloss -2094.84882  validloss -2029.20470±0.00000  bestvalidloss -2060.46586  last_update 64\n",
      "train: iter 673  trainloss -2113.47861  validloss -1986.92314±0.00000  bestvalidloss -2060.46586  last_update 65\n",
      "train: iter 674  trainloss -2137.20494  validloss -2038.54870±0.00000  bestvalidloss -2060.46586  last_update 66\n",
      "train: iter 675  trainloss -2162.02640  validloss -2016.88475±0.00000  bestvalidloss -2060.46586  last_update 67\n",
      "train: iter 676  trainloss -2154.64572  validloss -2051.14132±0.00000  bestvalidloss -2060.46586  last_update 68\n",
      "train: iter 677  trainloss -2145.99454  validloss -2030.10060±0.00000  bestvalidloss -2060.46586  last_update 69\n",
      "train: iter 678  trainloss -2103.10420  validloss -2051.63618±0.00000  bestvalidloss -2060.46586  last_update 70\n",
      "train: iter 679  trainloss -2069.36659  validloss -2012.70530±0.00000  bestvalidloss -2060.46586  last_update 71\n",
      "train: iter 680  trainloss -2155.68088  validloss -1952.30033±0.00000  bestvalidloss -2060.46586  last_update 72\n",
      "train: iter 681  trainloss -2142.04304  validloss -2042.95860±0.00000  bestvalidloss -2060.46586  last_update 73\n",
      "train: iter 682  trainloss -2139.49923  validloss -1920.01468±0.00000  bestvalidloss -2060.46586  last_update 74\n",
      "train: iter 683  trainloss -2147.27679  validloss -2026.93273±0.00000  bestvalidloss -2060.46586  last_update 75\n",
      "train: iter 684  trainloss -2151.04892  validloss -1975.42451±0.00000  bestvalidloss -2060.46586  last_update 76\n",
      "train: iter 685  trainloss -2123.68448  validloss -2053.63087±0.00000  bestvalidloss -2060.46586  last_update 77\n",
      "train: iter 686  trainloss -2076.39544  validloss -2020.51686±0.00000  bestvalidloss -2060.46586  last_update 78\n",
      "train: iter 687  trainloss -2148.55035  validloss -2040.50203±0.00000  bestvalidloss -2060.46586  last_update 79\n",
      "train: iter 688  trainloss -2154.21036  validloss -2049.85139±0.00000  bestvalidloss -2060.46586  last_update 80\n",
      "train: iter 689  trainloss -2165.30094  validloss -2030.84462±0.00000  bestvalidloss -2060.46586  last_update 81\n",
      "train: iter 690  trainloss -2164.58505  validloss -2039.20153±0.00000  bestvalidloss -2060.46586  last_update 82\n",
      "train: iter 691  trainloss -2157.58016  validloss -2008.55685±0.00000  bestvalidloss -2060.46586  last_update 83\n",
      "train: iter 692  trainloss -2152.58299  validloss -2060.99298±0.00000  bestvalidloss -2060.99298  last_update 0\n",
      "train: iter 693  trainloss -2153.62495  validloss -2006.85446±0.00000  bestvalidloss -2060.99298  last_update 1\n",
      "train: iter 694  trainloss -2140.12421  validloss -1992.23094±0.00000  bestvalidloss -2060.99298  last_update 2\n",
      "train: iter 695  trainloss -2155.39918  validloss -2030.00983±0.00000  bestvalidloss -2060.99298  last_update 3\n",
      "train: iter 696  trainloss -2145.60430  validloss -2042.59262±0.00000  bestvalidloss -2060.99298  last_update 4\n",
      "train: iter 697  trainloss -2129.08458  validloss -2034.23849±0.00000  bestvalidloss -2060.99298  last_update 5\n",
      "train: iter 698  trainloss -2151.53795  validloss -2029.12990±0.00000  bestvalidloss -2060.99298  last_update 6\n",
      "train: iter 699  trainloss -2157.80607  validloss -2057.41055±0.00000  bestvalidloss -2060.99298  last_update 7\n",
      "train: iter 700  trainloss -2140.88829  validloss -2031.35732±0.00000  bestvalidloss -2060.99298  last_update 8\n",
      "train: iter 701  trainloss -2120.75661  validloss -2020.33885±0.00000  bestvalidloss -2060.99298  last_update 9\n",
      "train: iter 702  trainloss -2130.32183  validloss -1942.71243±0.00000  bestvalidloss -2060.99298  last_update 10\n",
      "train: iter 703  trainloss -2132.02206  validloss -1999.72093±0.00000  bestvalidloss -2060.99298  last_update 11\n",
      "train: iter 704  trainloss -2145.56909  validloss -1972.22037±0.00000  bestvalidloss -2060.99298  last_update 12\n",
      "train: iter 705  trainloss -2154.59624  validloss -2020.14909±0.00000  bestvalidloss -2060.99298  last_update 13\n",
      "train: iter 706  trainloss -2154.00366  validloss -2033.05480±0.00000  bestvalidloss -2060.99298  last_update 14\n",
      "train: iter 707  trainloss -2093.97426  validloss -2011.84325±0.00000  bestvalidloss -2060.99298  last_update 15\n",
      "train: iter 708  trainloss -1948.85152  validloss -1866.36964±0.00000  bestvalidloss -2060.99298  last_update 16\n",
      "train: iter 709  trainloss -2112.44077  validloss -2017.14006±0.00000  bestvalidloss -2060.99298  last_update 17\n",
      "train: iter 710  trainloss -2157.05710  validloss -2038.05859±0.00000  bestvalidloss -2060.99298  last_update 18\n",
      "train: iter 711  trainloss -2140.85375  validloss -2059.49260±0.00000  bestvalidloss -2060.99298  last_update 19\n",
      "train: iter 712  trainloss -2167.04674  validloss -2053.78261±0.00000  bestvalidloss -2060.99298  last_update 20\n",
      "train: iter 713  trainloss -2172.80578  validloss -2042.80809±0.00000  bestvalidloss -2060.99298  last_update 21\n",
      "train: iter 714  trainloss -2154.90682  validloss -2043.64971±0.00000  bestvalidloss -2060.99298  last_update 22\n",
      "train: iter 715  trainloss -2161.55405  validloss -2058.90563±0.00000  bestvalidloss -2060.99298  last_update 23\n",
      "train: iter 716  trainloss -2166.94673  validloss -2049.05224±0.00000  bestvalidloss -2060.99298  last_update 24\n",
      "train: iter 717  trainloss -2156.36928  validloss -2050.19512±0.00000  bestvalidloss -2060.99298  last_update 25\n",
      "train: iter 718  trainloss -2162.59331  validloss -2027.30250±0.00000  bestvalidloss -2060.99298  last_update 26\n",
      "train: iter 719  trainloss -2166.87247  validloss -2053.09647±0.00000  bestvalidloss -2060.99298  last_update 27\n",
      "train: iter 720  trainloss -2141.55278  validloss -2044.30845±0.00000  bestvalidloss -2060.99298  last_update 28\n",
      "train: iter 721  trainloss -2161.12640  validloss -2050.48782±0.00000  bestvalidloss -2060.99298  last_update 29\n",
      "train: iter 722  trainloss -2146.25478  validloss -2038.46307±0.00000  bestvalidloss -2060.99298  last_update 30\n",
      "train: iter 723  trainloss -2074.78790  validloss -2010.82910±0.00000  bestvalidloss -2060.99298  last_update 31\n",
      "train: iter 724  trainloss -2165.08738  validloss -2027.96388±0.00000  bestvalidloss -2060.99298  last_update 32\n",
      "train: iter 725  trainloss -2167.96495  validloss -2050.57626±0.00000  bestvalidloss -2060.99298  last_update 33\n",
      "train: iter 726  trainloss -2144.20387  validloss -2038.52253±0.00000  bestvalidloss -2060.99298  last_update 34\n",
      "train: iter 727  trainloss -2156.76768  validloss -2010.38665±0.00000  bestvalidloss -2060.99298  last_update 35\n",
      "train: iter 728  trainloss -2156.95820  validloss -1987.47860±0.00000  bestvalidloss -2060.99298  last_update 36\n",
      "train: iter 729  trainloss -2163.02158  validloss -2053.47108±0.00000  bestvalidloss -2060.99298  last_update 37\n",
      "train: iter 730  trainloss -2168.10356  validloss -2013.77431±0.00000  bestvalidloss -2060.99298  last_update 38\n",
      "train: iter 731  trainloss -2160.65727  validloss -2025.63817±0.00000  bestvalidloss -2060.99298  last_update 39\n",
      "train: iter 732  trainloss -2162.82094  validloss -2061.57369±0.00000  bestvalidloss -2061.57369  last_update 0\n",
      "train: iter 733  trainloss -2159.24184  validloss -2033.46181±0.00000  bestvalidloss -2061.57369  last_update 1\n",
      "train: iter 734  trainloss -2151.66787  validloss -2030.86656±0.00000  bestvalidloss -2061.57369  last_update 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 735  trainloss -2127.56969  validloss -1990.59520±0.00000  bestvalidloss -2061.57369  last_update 3\n",
      "train: iter 736  trainloss -2113.80330  validloss -2014.72219±0.00000  bestvalidloss -2061.57369  last_update 4\n",
      "train: iter 737  trainloss -2087.28393  validloss -2027.83203±0.00000  bestvalidloss -2061.57369  last_update 5\n",
      "train: iter 738  trainloss -1993.62358  validloss -1913.57029±0.00000  bestvalidloss -2061.57369  last_update 6\n",
      "train: iter 739  trainloss -2149.98714  validloss -2005.43168±0.00000  bestvalidloss -2061.57369  last_update 7\n",
      "train: iter 740  trainloss -2129.18684  validloss -2031.86689±0.00000  bestvalidloss -2061.57369  last_update 8\n",
      "train: iter 741  trainloss -2093.47821  validloss -1951.14850±0.00000  bestvalidloss -2061.57369  last_update 9\n",
      "train: iter 742  trainloss -2153.59584  validloss -2057.69765±0.00000  bestvalidloss -2061.57369  last_update 10\n",
      "train: iter 743  trainloss -2160.61304  validloss -2041.69499±0.00000  bestvalidloss -2061.57369  last_update 11\n",
      "train: iter 744  trainloss -2156.53241  validloss -2050.64955±0.00000  bestvalidloss -2061.57369  last_update 12\n",
      "train: iter 745  trainloss -2167.87550  validloss -2044.18685±0.00000  bestvalidloss -2061.57369  last_update 13\n",
      "train: iter 746  trainloss -2177.01459  validloss -2049.93049±0.00000  bestvalidloss -2061.57369  last_update 14\n",
      "train: iter 747  trainloss -2149.83665  validloss -2056.72255±0.00000  bestvalidloss -2061.57369  last_update 15\n",
      "train: iter 748  trainloss -2128.74056  validloss -2040.55153±0.00000  bestvalidloss -2061.57369  last_update 16\n",
      "train: iter 749  trainloss -2162.86530  validloss -2014.86732±0.00000  bestvalidloss -2061.57369  last_update 17\n",
      "train: iter 750  trainloss -2154.62809  validloss -2049.06912±0.00000  bestvalidloss -2061.57369  last_update 18\n",
      "train: iter 751  trainloss -2151.85735  validloss -1995.19301±0.00000  bestvalidloss -2061.57369  last_update 19\n",
      "train: iter 752  trainloss -2169.11331  validloss -2052.58053±0.00000  bestvalidloss -2061.57369  last_update 20\n",
      "train: iter 753  trainloss -2145.71587  validloss -1976.85313±0.00000  bestvalidloss -2061.57369  last_update 21\n",
      "train: iter 754  trainloss -2154.88750  validloss -2019.85762±0.00000  bestvalidloss -2061.57369  last_update 22\n",
      "train: iter 755  trainloss -2100.28937  validloss -2006.37373±0.00000  bestvalidloss -2061.57369  last_update 23\n",
      "train: iter 756  trainloss -2133.44940  validloss -2035.82945±0.00000  bestvalidloss -2061.57369  last_update 24\n",
      "train: iter 757  trainloss -2166.85883  validloss -2041.42036±0.00000  bestvalidloss -2061.57369  last_update 25\n",
      "train: iter 758  trainloss -2158.70967  validloss -2032.76115±0.00000  bestvalidloss -2061.57369  last_update 26\n",
      "train: iter 759  trainloss -2161.08339  validloss -2049.95296±0.00000  bestvalidloss -2061.57369  last_update 27\n",
      "train: iter 760  trainloss -2167.43969  validloss -2035.22980±0.00000  bestvalidloss -2061.57369  last_update 28\n",
      "train: iter 761  trainloss -2161.33991  validloss -2052.96680±0.00000  bestvalidloss -2061.57369  last_update 29\n",
      "train: iter 762  trainloss -2117.97451  validloss -2021.90934±0.00000  bestvalidloss -2061.57369  last_update 30\n",
      "train: iter 763  trainloss -2154.06432  validloss -2031.99336±0.00000  bestvalidloss -2061.57369  last_update 31\n",
      "train: iter 764  trainloss -2144.68704  validloss -2021.38945±0.00000  bestvalidloss -2061.57369  last_update 32\n",
      "train: iter 765  trainloss -2165.68546  validloss -2004.77429±0.00000  bestvalidloss -2061.57369  last_update 33\n",
      "train: iter 766  trainloss -2164.31613  validloss -2022.52158±0.00000  bestvalidloss -2061.57369  last_update 34\n",
      "train: iter 767  trainloss -2147.97834  validloss -2051.52827±0.00000  bestvalidloss -2061.57369  last_update 35\n",
      "train: iter 768  trainloss -2145.85234  validloss -1954.77302±0.00000  bestvalidloss -2061.57369  last_update 36\n",
      "train: iter 769  trainloss -2165.75074  validloss -2049.18757±0.00000  bestvalidloss -2061.57369  last_update 37\n",
      "train: iter 770  trainloss -2156.29600  validloss -2058.42349±0.00000  bestvalidloss -2061.57369  last_update 38\n",
      "train: iter 771  trainloss -2170.07883  validloss -2043.14825±0.00000  bestvalidloss -2061.57369  last_update 39\n",
      "train: iter 772  trainloss -2144.37020  validloss -2051.26504±0.00000  bestvalidloss -2061.57369  last_update 40\n",
      "train: iter 773  trainloss -2152.86922  validloss -2031.11334±0.00000  bestvalidloss -2061.57369  last_update 41\n",
      "train: iter 774  trainloss -2140.31987  validloss -2047.77258±0.00000  bestvalidloss -2061.57369  last_update 42\n",
      "train: iter 775  trainloss -2171.66433  validloss -2026.18923±0.00000  bestvalidloss -2061.57369  last_update 43\n",
      "train: iter 776  trainloss -2170.75933  validloss -2056.93586±0.00000  bestvalidloss -2061.57369  last_update 44\n",
      "train: iter 777  trainloss -2167.31208  validloss -2007.63190±0.00000  bestvalidloss -2061.57369  last_update 45\n",
      "train: iter 778  trainloss -2159.71536  validloss -2064.53145±0.00000  bestvalidloss -2064.53145  last_update 0\n",
      "train: iter 779  trainloss -2153.91719  validloss -2056.33435±0.00000  bestvalidloss -2064.53145  last_update 1\n",
      "train: iter 780  trainloss -2158.46938  validloss -2010.37081±0.00000  bestvalidloss -2064.53145  last_update 2\n",
      "train: iter 781  trainloss -2142.83610  validloss -2020.36604±0.00000  bestvalidloss -2064.53145  last_update 3\n",
      "train: iter 782  trainloss -2155.55910  validloss -2029.41385±0.00000  bestvalidloss -2064.53145  last_update 4\n",
      "train: iter 783  trainloss -2066.95494  validloss -2011.79246±0.00000  bestvalidloss -2064.53145  last_update 5\n",
      "train: iter 784  trainloss -2121.93044  validloss -1952.38226±0.00000  bestvalidloss -2064.53145  last_update 6\n",
      "train: iter 785  trainloss -2085.48714  validloss -1961.08225±0.00000  bestvalidloss -2064.53145  last_update 7\n",
      "train: iter 786  trainloss -2121.26400  validloss -1963.11236±0.00000  bestvalidloss -2064.53145  last_update 8\n",
      "train: iter 787  trainloss -2156.05252  validloss -2054.38638±0.00000  bestvalidloss -2064.53145  last_update 9\n",
      "train: iter 788  trainloss -2169.76425  validloss -2047.77437±0.00000  bestvalidloss -2064.53145  last_update 10\n",
      "train: iter 789  trainloss -2178.77249  validloss -2061.84357±0.00000  bestvalidloss -2064.53145  last_update 11\n",
      "train: iter 790  trainloss -2168.81260  validloss -2023.84047±0.00000  bestvalidloss -2064.53145  last_update 12\n",
      "train: iter 791  trainloss -2172.83319  validloss -2055.09734±0.00000  bestvalidloss -2064.53145  last_update 13\n",
      "train: iter 792  trainloss -2162.14658  validloss -2021.87744±0.00000  bestvalidloss -2064.53145  last_update 14\n",
      "train: iter 793  trainloss -2176.16441  validloss -2060.89889±0.00000  bestvalidloss -2064.53145  last_update 15\n",
      "train: iter 794  trainloss -2162.59281  validloss -2036.07026±0.00000  bestvalidloss -2064.53145  last_update 16\n",
      "train: iter 795  trainloss -2163.14978  validloss -2033.96153±0.00000  bestvalidloss -2064.53145  last_update 17\n",
      "train: iter 796  trainloss -2148.37426  validloss -1980.03219±0.00000  bestvalidloss -2064.53145  last_update 18\n",
      "train: iter 797  trainloss -2171.20564  validloss -2028.49771±0.00000  bestvalidloss -2064.53145  last_update 19\n",
      "train: iter 798  trainloss -2165.84022  validloss -2070.13260±0.00000  bestvalidloss -2070.13260  last_update 0\n",
      "train: iter 799  trainloss -2163.87923  validloss -1995.00203±0.00000  bestvalidloss -2070.13260  last_update 1\n",
      "train: iter 800  trainloss -2171.61276  validloss -2053.89791±0.00000  bestvalidloss -2070.13260  last_update 2\n",
      "train: iter 801  trainloss -2152.24188  validloss -2051.95665±0.00000  bestvalidloss -2070.13260  last_update 3\n",
      "train: iter 802  trainloss -2120.00076  validloss -2042.67261±0.00000  bestvalidloss -2070.13260  last_update 4\n",
      "train: iter 803  trainloss -2137.89038  validloss -1997.02308±0.00000  bestvalidloss -2070.13260  last_update 5\n",
      "train: iter 804  trainloss -2121.77956  validloss -2032.82631±0.00000  bestvalidloss -2070.13260  last_update 6\n",
      "train: iter 805  trainloss -2109.98897  validloss -1970.28350±0.00000  bestvalidloss -2070.13260  last_update 7\n",
      "train: iter 806  trainloss -2118.88682  validloss -2068.13795±0.00000  bestvalidloss -2070.13260  last_update 8\n",
      "train: iter 807  trainloss -2164.88451  validloss -2044.76025±0.00000  bestvalidloss -2070.13260  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 808  trainloss -2168.48027  validloss -1996.04191±0.00000  bestvalidloss -2070.13260  last_update 10\n",
      "train: iter 809  trainloss -2173.18331  validloss -2058.10583±0.00000  bestvalidloss -2070.13260  last_update 11\n",
      "train: iter 810  trainloss -2155.35272  validloss -1993.63942±0.00000  bestvalidloss -2070.13260  last_update 12\n",
      "train: iter 811  trainloss -2153.14597  validloss -2035.97913±0.00000  bestvalidloss -2070.13260  last_update 13\n",
      "train: iter 812  trainloss -2109.41022  validloss -1994.37494±0.00000  bestvalidloss -2070.13260  last_update 14\n",
      "train: iter 813  trainloss -2107.22019  validloss -1973.73915±0.00000  bestvalidloss -2070.13260  last_update 15\n",
      "train: iter 814  trainloss -2125.95538  validloss -2001.52775±0.00000  bestvalidloss -2070.13260  last_update 16\n",
      "train: iter 815  trainloss -2143.15835  validloss -1921.29524±0.00000  bestvalidloss -2070.13260  last_update 17\n",
      "train: iter 816  trainloss -2165.36744  validloss -2041.83184±0.00000  bestvalidloss -2070.13260  last_update 18\n",
      "train: iter 817  trainloss -2177.89339  validloss -2005.36613±0.00000  bestvalidloss -2070.13260  last_update 19\n",
      "train: iter 818  trainloss -2156.45918  validloss -2057.76336±0.00000  bestvalidloss -2070.13260  last_update 20\n",
      "train: iter 819  trainloss -2180.57259  validloss -2040.29410±0.00000  bestvalidloss -2070.13260  last_update 21\n",
      "train: iter 820  trainloss -2175.17807  validloss -2066.48844±0.00000  bestvalidloss -2070.13260  last_update 22\n",
      "train: iter 821  trainloss -2160.83437  validloss -2016.76796±0.00000  bestvalidloss -2070.13260  last_update 23\n",
      "train: iter 822  trainloss -2167.24817  validloss -2054.20766±0.00000  bestvalidloss -2070.13260  last_update 24\n",
      "train: iter 823  trainloss -2158.30764  validloss -2041.11601±0.00000  bestvalidloss -2070.13260  last_update 25\n",
      "train: iter 824  trainloss -2143.78414  validloss -2042.02986±0.00000  bestvalidloss -2070.13260  last_update 26\n",
      "train: iter 825  trainloss -2176.66118  validloss -2056.43954±0.00000  bestvalidloss -2070.13260  last_update 27\n",
      "train: iter 826  trainloss -2131.04819  validloss -1984.03066±0.00000  bestvalidloss -2070.13260  last_update 28\n",
      "train: iter 827  trainloss -2106.75321  validloss -2030.22656±0.00000  bestvalidloss -2070.13260  last_update 29\n",
      "train: iter 828  trainloss -2168.31702  validloss -2030.92622±0.00000  bestvalidloss -2070.13260  last_update 30\n",
      "train: iter 829  trainloss -2168.60889  validloss -2056.73059±0.00000  bestvalidloss -2070.13260  last_update 31\n",
      "train: iter 830  trainloss -2166.76257  validloss -2047.21931±0.00000  bestvalidloss -2070.13260  last_update 32\n",
      "train: iter 831  trainloss -2162.37129  validloss -2033.78306±0.00000  bestvalidloss -2070.13260  last_update 33\n",
      "train: iter 832  trainloss -2172.19922  validloss -2045.91888±0.00000  bestvalidloss -2070.13260  last_update 34\n",
      "train: iter 833  trainloss -2144.06728  validloss -1982.88531±0.00000  bestvalidloss -2070.13260  last_update 35\n",
      "train: iter 834  trainloss -2175.79633  validloss -2039.79219±0.00000  bestvalidloss -2070.13260  last_update 36\n",
      "train: iter 835  trainloss -2133.01340  validloss -2042.24615±0.00000  bestvalidloss -2070.13260  last_update 37\n",
      "train: iter 836  trainloss -2055.80800  validloss -1991.75280±0.00000  bestvalidloss -2070.13260  last_update 38\n",
      "train: iter 837  trainloss -2177.07288  validloss -2054.32379±0.00000  bestvalidloss -2070.13260  last_update 39\n",
      "train: iter 838  trainloss -2180.70230  validloss -2060.66843±0.00000  bestvalidloss -2070.13260  last_update 40\n",
      "train: iter 839  trainloss -2170.93390  validloss -2040.78822±0.00000  bestvalidloss -2070.13260  last_update 41\n",
      "train: iter 840  trainloss -2177.48523  validloss -2039.85382±0.00000  bestvalidloss -2070.13260  last_update 42\n",
      "train: iter 841  trainloss -2178.34610  validloss -2033.81260±0.00000  bestvalidloss -2070.13260  last_update 43\n",
      "train: iter 842  trainloss -2175.74239  validloss -2056.52838±0.00000  bestvalidloss -2070.13260  last_update 44\n",
      "train: iter 843  trainloss -2176.05612  validloss -2055.54495±0.00000  bestvalidloss -2070.13260  last_update 45\n",
      "train: iter 844  trainloss -2175.08332  validloss -2059.45139±0.00000  bestvalidloss -2070.13260  last_update 46\n",
      "train: iter 845  trainloss -2172.11414  validloss -2071.06862±0.00000  bestvalidloss -2071.06862  last_update 0\n",
      "train: iter 846  trainloss -2187.55641  validloss -2072.08633±0.00000  bestvalidloss -2072.08633  last_update 0\n",
      "train: iter 847  trainloss -2140.38531  validloss -1974.55068±0.00000  bestvalidloss -2072.08633  last_update 1\n",
      "train: iter 848  trainloss -2158.28421  validloss -2069.48098±0.00000  bestvalidloss -2072.08633  last_update 2\n",
      "train: iter 849  trainloss -2167.01969  validloss -2031.60501±0.00000  bestvalidloss -2072.08633  last_update 3\n",
      "train: iter 850  trainloss -2184.21229  validloss -2051.10628±0.00000  bestvalidloss -2072.08633  last_update 4\n",
      "train: iter 851  trainloss -2159.51170  validloss -2055.74416±0.00000  bestvalidloss -2072.08633  last_update 5\n",
      "train: iter 852  trainloss -2159.17414  validloss -2033.72827±0.00000  bestvalidloss -2072.08633  last_update 6\n",
      "train: iter 853  trainloss -2135.93461  validloss -2050.08796±0.00000  bestvalidloss -2072.08633  last_update 7\n",
      "train: iter 854  trainloss -2117.35436  validloss -1953.42688±0.00000  bestvalidloss -2072.08633  last_update 8\n",
      "train: iter 855  trainloss -2166.47726  validloss -2020.16797±0.00000  bestvalidloss -2072.08633  last_update 9\n",
      "train: iter 856  trainloss -2184.19096  validloss -2044.08562±0.00000  bestvalidloss -2072.08633  last_update 10\n",
      "train: iter 857  trainloss -2168.06484  validloss -2033.64969±0.00000  bestvalidloss -2072.08633  last_update 11\n",
      "train: iter 858  trainloss -2172.21581  validloss -2041.34617±0.00000  bestvalidloss -2072.08633  last_update 12\n",
      "train: iter 859  trainloss -2172.64206  validloss -2034.21932±0.00000  bestvalidloss -2072.08633  last_update 13\n",
      "train: iter 860  trainloss -2180.80336  validloss -2056.85366±0.00000  bestvalidloss -2072.08633  last_update 14\n",
      "train: iter 861  trainloss -2170.17435  validloss -2027.53553±0.00000  bestvalidloss -2072.08633  last_update 15\n",
      "train: iter 862  trainloss -2187.21493  validloss -2069.48378±0.00000  bestvalidloss -2072.08633  last_update 16\n",
      "train: iter 863  trainloss -2142.68836  validloss -2066.85570±0.00000  bestvalidloss -2072.08633  last_update 17\n",
      "train: iter 864  trainloss -2151.27306  validloss -1972.85812±0.00000  bestvalidloss -2072.08633  last_update 18\n",
      "train: iter 865  trainloss -2160.55054  validloss -2058.24233±0.00000  bestvalidloss -2072.08633  last_update 19\n",
      "train: iter 866  trainloss -2151.53708  validloss -2040.66534±0.00000  bestvalidloss -2072.08633  last_update 20\n",
      "train: iter 867  trainloss -2158.68649  validloss -1970.45635±0.00000  bestvalidloss -2072.08633  last_update 21\n",
      "train: iter 868  trainloss -2175.10867  validloss -2040.62360±0.00000  bestvalidloss -2072.08633  last_update 22\n",
      "train: iter 869  trainloss -2178.57080  validloss -2020.35692±0.00000  bestvalidloss -2072.08633  last_update 23\n",
      "train: iter 870  trainloss -2153.48830  validloss -2013.16316±0.00000  bestvalidloss -2072.08633  last_update 24\n",
      "train: iter 871  trainloss -2110.17693  validloss -2033.39880±0.00000  bestvalidloss -2072.08633  last_update 25\n",
      "train: iter 872  trainloss -2167.44715  validloss -2055.74887±0.00000  bestvalidloss -2072.08633  last_update 26\n",
      "train: iter 873  trainloss -2158.45528  validloss -2031.31156±0.00000  bestvalidloss -2072.08633  last_update 27\n",
      "train: iter 874  trainloss -2170.04921  validloss -2034.74828±0.00000  bestvalidloss -2072.08633  last_update 28\n",
      "train: iter 875  trainloss -2143.19601  validloss -2053.21791±0.00000  bestvalidloss -2072.08633  last_update 29\n",
      "train: iter 876  trainloss -2173.34923  validloss -2063.01967±0.00000  bestvalidloss -2072.08633  last_update 30\n",
      "train: iter 877  trainloss -2183.53708  validloss -2069.64125±0.00000  bestvalidloss -2072.08633  last_update 31\n",
      "train: iter 878  trainloss -2171.34904  validloss -2046.11286±0.00000  bestvalidloss -2072.08633  last_update 32\n",
      "train: iter 879  trainloss -2172.93978  validloss -2023.00157±0.00000  bestvalidloss -2072.08633  last_update 33\n",
      "train: iter 880  trainloss -2169.08981  validloss -2068.53714±0.00000  bestvalidloss -2072.08633  last_update 34\n",
      "train: iter 881  trainloss -2179.24188  validloss -2057.36063±0.00000  bestvalidloss -2072.08633  last_update 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 882  trainloss -2156.71019  validloss -2011.17379±0.00000  bestvalidloss -2072.08633  last_update 36\n",
      "train: iter 883  trainloss -2171.99836  validloss -2064.71990±0.00000  bestvalidloss -2072.08633  last_update 37\n",
      "train: iter 884  trainloss -2110.69007  validloss -2033.25225±0.00000  bestvalidloss -2072.08633  last_update 38\n",
      "train: iter 885  trainloss -2018.95761  validloss -1928.79472±0.00000  bestvalidloss -2072.08633  last_update 39\n",
      "train: iter 886  trainloss -2156.95410  validloss -1940.89371±0.00000  bestvalidloss -2072.08633  last_update 40\n",
      "train: iter 887  trainloss -2168.68498  validloss -2029.04060±0.00000  bestvalidloss -2072.08633  last_update 41\n",
      "train: iter 888  trainloss -2182.21403  validloss -2033.10417±0.00000  bestvalidloss -2072.08633  last_update 42\n",
      "train: iter 889  trainloss -2183.25520  validloss -2056.12357±0.00000  bestvalidloss -2072.08633  last_update 43\n",
      "train: iter 890  trainloss -2172.96533  validloss -2051.50364±0.00000  bestvalidloss -2072.08633  last_update 44\n",
      "train: iter 891  trainloss -2178.55603  validloss -2039.63592±0.00000  bestvalidloss -2072.08633  last_update 45\n",
      "train: iter 892  trainloss -2171.14048  validloss -2011.95001±0.00000  bestvalidloss -2072.08633  last_update 46\n",
      "train: iter 893  trainloss -2176.65755  validloss -2031.52955±0.00000  bestvalidloss -2072.08633  last_update 47\n",
      "train: iter 894  trainloss -2190.83504  validloss -2054.97551±0.00000  bestvalidloss -2072.08633  last_update 48\n",
      "train: iter 895  trainloss -2172.28640  validloss -2053.81997±0.00000  bestvalidloss -2072.08633  last_update 49\n",
      "train: iter 896  trainloss -2178.77730  validloss -2017.04067±0.00000  bestvalidloss -2072.08633  last_update 50\n",
      "train: iter 897  trainloss -2194.40671  validloss -2052.90206±0.00000  bestvalidloss -2072.08633  last_update 51\n",
      "train: iter 898  trainloss -2184.45016  validloss -2032.33403±0.00000  bestvalidloss -2072.08633  last_update 52\n",
      "train: iter 899  trainloss -2175.06535  validloss -2044.38511±0.00000  bestvalidloss -2072.08633  last_update 53\n",
      "train: iter 900  trainloss -2181.67480  validloss -2053.88282±0.00000  bestvalidloss -2072.08633  last_update 54\n",
      "train: iter 901  trainloss -2178.66654  validloss -2049.28747±0.00000  bestvalidloss -2072.08633  last_update 55\n",
      "train: iter 902  trainloss -2176.87263  validloss -2034.15294±0.00000  bestvalidloss -2072.08633  last_update 56\n",
      "train: iter 903  trainloss -2176.60219  validloss -2026.79399±0.00000  bestvalidloss -2072.08633  last_update 57\n",
      "train: iter 904  trainloss -2154.39878  validloss -2035.41993±0.00000  bestvalidloss -2072.08633  last_update 58\n",
      "train: iter 905  trainloss -2178.95209  validloss -2036.74283±0.00000  bestvalidloss -2072.08633  last_update 59\n",
      "train: iter 906  trainloss -2166.99939  validloss -2043.75127±0.00000  bestvalidloss -2072.08633  last_update 60\n",
      "train: iter 907  trainloss -2164.08823  validloss -2035.33532±0.00000  bestvalidloss -2072.08633  last_update 61\n",
      "train: iter 908  trainloss -2148.61312  validloss -2036.02026±0.00000  bestvalidloss -2072.08633  last_update 62\n",
      "train: iter 909  trainloss -2121.28660  validloss -1918.34927±0.00000  bestvalidloss -2072.08633  last_update 63\n",
      "train: iter 910  trainloss -2130.56228  validloss -1838.80123±0.00000  bestvalidloss -2072.08633  last_update 64\n",
      "train: iter 911  trainloss -2161.36108  validloss -2048.03264±0.00000  bestvalidloss -2072.08633  last_update 65\n",
      "train: iter 912  trainloss -2157.05850  validloss -2060.59896±0.00000  bestvalidloss -2072.08633  last_update 66\n",
      "train: iter 913  trainloss -2162.34776  validloss -2064.13319±0.00000  bestvalidloss -2072.08633  last_update 67\n",
      "train: iter 914  trainloss -2089.44392  validloss -1919.56891±0.00000  bestvalidloss -2072.08633  last_update 68\n",
      "train: iter 915  trainloss -2160.60608  validloss -2019.79206±0.00000  bestvalidloss -2072.08633  last_update 69\n",
      "train: iter 916  trainloss -2184.16452  validloss -2037.27533±0.00000  bestvalidloss -2072.08633  last_update 70\n",
      "train: iter 917  trainloss -2184.70335  validloss -2036.48636±0.00000  bestvalidloss -2072.08633  last_update 71\n",
      "train: iter 918  trainloss -2182.53652  validloss -2055.42418±0.00000  bestvalidloss -2072.08633  last_update 72\n",
      "train: iter 919  trainloss -2172.45613  validloss -2018.12325±0.00000  bestvalidloss -2072.08633  last_update 73\n",
      "train: iter 920  trainloss -2181.56553  validloss -2049.58149±0.00000  bestvalidloss -2072.08633  last_update 74\n",
      "train: iter 921  trainloss -2180.53226  validloss -2032.53260±0.00000  bestvalidloss -2072.08633  last_update 75\n",
      "train: iter 922  trainloss -2174.37324  validloss -2051.22867±0.00000  bestvalidloss -2072.08633  last_update 76\n",
      "train: iter 923  trainloss -2183.55211  validloss -2040.20960±0.00000  bestvalidloss -2072.08633  last_update 77\n",
      "train: iter 924  trainloss -2175.48665  validloss -2057.49510±0.00000  bestvalidloss -2072.08633  last_update 78\n",
      "train: iter 925  trainloss -2177.75945  validloss -2027.70157±0.00000  bestvalidloss -2072.08633  last_update 79\n",
      "train: iter 926  trainloss -2165.19748  validloss -2027.25645±0.00000  bestvalidloss -2072.08633  last_update 80\n",
      "train: iter 927  trainloss -2179.94997  validloss -2069.18319±0.00000  bestvalidloss -2072.08633  last_update 81\n",
      "train: iter 928  trainloss -2186.88495  validloss -2063.17595±0.00000  bestvalidloss -2072.08633  last_update 82\n",
      "train: iter 929  trainloss -2185.13798  validloss -2049.59838±0.00000  bestvalidloss -2072.08633  last_update 83\n",
      "train: iter 930  trainloss -2146.16355  validloss -2038.73138±0.00000  bestvalidloss -2072.08633  last_update 84\n",
      "train: iter 931  trainloss -2127.48466  validloss -1960.40434±0.00000  bestvalidloss -2072.08633  last_update 85\n",
      "train: iter 932  trainloss -2169.11322  validloss -2063.73407±0.00000  bestvalidloss -2072.08633  last_update 86\n",
      "train: iter 933  trainloss -2172.34550  validloss -2035.03431±0.00000  bestvalidloss -2072.08633  last_update 87\n",
      "train: iter 934  trainloss -2167.42950  validloss -2039.02763±0.00000  bestvalidloss -2072.08633  last_update 88\n",
      "train: iter 935  trainloss -2192.84462  validloss -2064.36526±0.00000  bestvalidloss -2072.08633  last_update 89\n",
      "train: iter 936  trainloss -2152.82226  validloss -2018.14875±0.00000  bestvalidloss -2072.08633  last_update 90\n",
      "train: iter 937  trainloss -2174.82089  validloss -2051.22219±0.00000  bestvalidloss -2072.08633  last_update 91\n",
      "train: iter 938  trainloss -2169.76291  validloss -2029.27307±0.00000  bestvalidloss -2072.08633  last_update 92\n",
      "train: iter 939  trainloss -2167.98676  validloss -2044.20650±0.00000  bestvalidloss -2072.08633  last_update 93\n",
      "train: iter 940  trainloss -2171.87195  validloss -2006.82281±0.00000  bestvalidloss -2072.08633  last_update 94\n",
      "train: iter 941  trainloss -2181.81320  validloss -2065.58998±0.00000  bestvalidloss -2072.08633  last_update 95\n",
      "train: iter 942  trainloss -2182.61313  validloss -2040.80070±0.00000  bestvalidloss -2072.08633  last_update 96\n",
      "train: iter 943  trainloss -2182.52216  validloss -2063.02286±0.00000  bestvalidloss -2072.08633  last_update 97\n",
      "train: iter 944  trainloss -2160.06833  validloss -2023.37385±0.00000  bestvalidloss -2072.08633  last_update 98\n",
      "train: iter 945  trainloss -2168.63626  validloss -1989.22057±0.00000  bestvalidloss -2072.08633  last_update 99\n",
      "train: iter 946  trainloss -2143.22696  validloss -2002.74570±0.00000  bestvalidloss -2072.08633  last_update 100\n",
      "train: fin\n",
      "penalty_target_min tensor(-12.3239) penalty_target_max tensor(5.4818)\n"
     ]
    }
   ],
   "source": [
    "train_curve1, valid_curve1 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=1)\n",
    "vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve2, valid_curve2 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=2)\n",
    "# vi.update_mulogvar_offlinedata()\n",
    "\n",
    "# train_curve3, valid_curve3 = vi.train_unweighted_vae(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early, flag=3)\n",
    "# vi.update_mulogvar_offlinedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c548788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_curve1)\n",
    "plt.plot(valid_curve1)\n",
    "# plt.ylim([-2000, 1000])\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(train_curve2)\n",
    "# plt.plot(valid_curve2)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(train_curve3)\n",
    "# plt.plot(valid_curve3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2656b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd778499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 4.66633  validloss 4.85537±0.00000  bestvalidloss 4.85537  last_update 0\n",
      "train: iter 1  trainloss 4.30226  validloss 4.44165±0.00000  bestvalidloss 4.44165  last_update 0\n",
      "train: iter 2  trainloss 3.98751  validloss 4.11872±0.00000  bestvalidloss 4.11872  last_update 0\n",
      "train: iter 3  trainloss 3.73411  validloss 3.83494±0.00000  bestvalidloss 3.83494  last_update 0\n",
      "train: iter 4  trainloss 3.51169  validloss 3.59657±0.00000  bestvalidloss 3.59657  last_update 0\n",
      "train: iter 5  trainloss 3.31457  validloss 3.40007±0.00000  bestvalidloss 3.40007  last_update 0\n",
      "train: iter 6  trainloss 3.15500  validloss 3.21392±0.00000  bestvalidloss 3.21392  last_update 0\n",
      "train: iter 7  trainloss 3.01282  validloss 3.06445±0.00000  bestvalidloss 3.06445  last_update 0\n",
      "train: iter 8  trainloss 2.88658  validloss 2.92705±0.00000  bestvalidloss 2.92705  last_update 0\n",
      "train: iter 9  trainloss 2.76818  validloss 2.80436±0.00000  bestvalidloss 2.80436  last_update 0\n",
      "train: iter 10  trainloss 2.66750  validloss 2.69768±0.00000  bestvalidloss 2.69768  last_update 0\n",
      "train: iter 11  trainloss 2.57212  validloss 2.59676±0.00000  bestvalidloss 2.59676  last_update 0\n",
      "train: iter 12  trainloss 2.48335  validloss 2.49712±0.00000  bestvalidloss 2.49712  last_update 0\n",
      "train: iter 13  trainloss 2.40641  validloss 2.42098±0.00000  bestvalidloss 2.42098  last_update 0\n",
      "train: iter 14  trainloss 2.33009  validloss 2.34005±0.00000  bestvalidloss 2.34005  last_update 0\n",
      "train: iter 15  trainloss 2.26370  validloss 2.26067±0.00000  bestvalidloss 2.26067  last_update 0\n",
      "train: iter 16  trainloss 2.20064  validloss 2.19265±0.00000  bestvalidloss 2.19265  last_update 0\n",
      "train: iter 17  trainloss 2.13456  validloss 2.13274±0.00000  bestvalidloss 2.13274  last_update 0\n",
      "train: iter 18  trainloss 2.06580  validloss 2.06995±0.00000  bestvalidloss 2.06995  last_update 0\n",
      "train: iter 19  trainloss 2.02580  validloss 2.00185±0.00000  bestvalidloss 2.00185  last_update 0\n",
      "train: iter 20  trainloss 1.96160  validloss 1.93906±0.00000  bestvalidloss 1.93906  last_update 0\n",
      "train: iter 21  trainloss 1.90328  validloss 1.87851±0.00000  bestvalidloss 1.87851  last_update 0\n",
      "train: iter 22  trainloss 1.84096  validloss 1.82791±0.00000  bestvalidloss 1.82791  last_update 0\n",
      "train: iter 23  trainloss 1.79676  validloss 1.77428±0.00000  bestvalidloss 1.77428  last_update 0\n",
      "train: iter 24  trainloss 1.74915  validloss 1.71588±0.00000  bestvalidloss 1.71588  last_update 0\n",
      "train: iter 25  trainloss 1.69751  validloss 1.65714±0.00000  bestvalidloss 1.65714  last_update 0\n",
      "train: iter 26  trainloss 1.63777  validloss 1.60602±0.00000  bestvalidloss 1.60602  last_update 0\n",
      "train: iter 27  trainloss 1.59327  validloss 1.54626±0.00000  bestvalidloss 1.54626  last_update 0\n",
      "train: iter 28  trainloss 1.54091  validloss 1.48062±0.00000  bestvalidloss 1.48062  last_update 0\n",
      "train: iter 29  trainloss 1.48405  validloss 1.42925±0.00000  bestvalidloss 1.42925  last_update 0\n",
      "train: iter 30  trainloss 1.43898  validloss 1.38899±0.00000  bestvalidloss 1.38899  last_update 0\n",
      "train: iter 31  trainloss 1.38425  validloss 1.32313±0.00000  bestvalidloss 1.32313  last_update 0\n",
      "train: iter 32  trainloss 1.31440  validloss 1.26262±0.00000  bestvalidloss 1.26262  last_update 0\n",
      "train: iter 33  trainloss 1.26405  validloss 1.19200±0.00000  bestvalidloss 1.19200  last_update 0\n",
      "train: iter 34  trainloss 1.19896  validloss 1.16286±0.00000  bestvalidloss 1.16286  last_update 0\n",
      "train: iter 35  trainloss 1.14213  validloss 1.09350±0.00000  bestvalidloss 1.09350  last_update 0\n",
      "train: iter 36  trainloss 1.08995  validloss 1.02095±0.00000  bestvalidloss 1.02095  last_update 0\n",
      "train: iter 37  trainloss 1.02810  validloss 0.96576±0.00000  bestvalidloss 0.96576  last_update 0\n",
      "train: iter 38  trainloss 0.97302  validloss 0.90421±0.00000  bestvalidloss 0.90421  last_update 0\n",
      "train: iter 39  trainloss 0.92003  validloss 0.84884±0.00000  bestvalidloss 0.84884  last_update 0\n",
      "train: iter 40  trainloss 0.86068  validloss 0.79196±0.00000  bestvalidloss 0.79196  last_update 0\n",
      "train: iter 41  trainloss 0.81398  validloss 0.70933±0.00000  bestvalidloss 0.70933  last_update 0\n",
      "train: iter 42  trainloss 0.75787  validloss 0.64547±0.00000  bestvalidloss 0.64547  last_update 0\n",
      "train: iter 43  trainloss 0.69470  validloss 0.59327±0.00000  bestvalidloss 0.59327  last_update 0\n",
      "train: iter 44  trainloss 0.65068  validloss 0.55773±0.00000  bestvalidloss 0.55773  last_update 0\n",
      "train: iter 45  trainloss 0.58580  validloss 0.50142±0.00000  bestvalidloss 0.50142  last_update 0\n",
      "train: iter 46  trainloss 0.53943  validloss 0.44776±0.00000  bestvalidloss 0.44776  last_update 0\n",
      "train: iter 47  trainloss 0.51315  validloss 0.38861±0.00000  bestvalidloss 0.38861  last_update 0\n",
      "train: iter 48  trainloss 0.45319  validloss 0.36075±0.00000  bestvalidloss 0.36075  last_update 0\n",
      "train: iter 49  trainloss 0.42236  validloss 0.28857±0.00000  bestvalidloss 0.28857  last_update 0\n",
      "train: iter 50  trainloss 0.37502  validloss 0.27319±0.00000  bestvalidloss 0.27319  last_update 0\n",
      "train: iter 51  trainloss 0.34013  validloss 0.24298±0.00000  bestvalidloss 0.24298  last_update 0\n",
      "train: iter 52  trainloss 0.30393  validloss 0.17515±0.00000  bestvalidloss 0.17515  last_update 0\n",
      "train: iter 53  trainloss 0.24305  validloss 0.13307±0.00000  bestvalidloss 0.13307  last_update 0\n",
      "train: iter 54  trainloss 0.21084  validloss 0.09028±0.00000  bestvalidloss 0.09028  last_update 0\n",
      "train: iter 55  trainloss 0.16027  validloss 0.05042±0.00000  bestvalidloss 0.05042  last_update 0\n",
      "train: iter 56  trainloss 0.13391  validloss -0.00598±0.00000  bestvalidloss -0.00598  last_update 0\n",
      "train: iter 57  trainloss 0.08341  validloss -0.05337±0.00000  bestvalidloss -0.05337  last_update 0\n",
      "train: iter 58  trainloss 0.05761  validloss -0.08790±0.00000  bestvalidloss -0.08790  last_update 0\n",
      "train: iter 59  trainloss 0.01731  validloss -0.12556±0.00000  bestvalidloss -0.12556  last_update 0\n",
      "train: iter 60  trainloss -0.02968  validloss -0.14369±0.00000  bestvalidloss -0.14369  last_update 0\n",
      "train: iter 61  trainloss -0.07312  validloss -0.19681±0.00000  bestvalidloss -0.19681  last_update 0\n",
      "train: iter 62  trainloss -0.10891  validloss -0.22009±0.00000  bestvalidloss -0.22009  last_update 0\n",
      "train: iter 63  trainloss -0.14302  validloss -0.23688±0.00000  bestvalidloss -0.23688  last_update 0\n",
      "train: iter 64  trainloss -0.20493  validloss -0.32463±0.00000  bestvalidloss -0.32463  last_update 0\n",
      "train: iter 65  trainloss -0.22862  validloss -0.36064±0.00000  bestvalidloss -0.36064  last_update 0\n",
      "train: iter 66  trainloss -0.26770  validloss -0.36798±0.00000  bestvalidloss -0.36798  last_update 0\n",
      "train: iter 67  trainloss -0.29017  validloss -0.45392±0.00000  bestvalidloss -0.45392  last_update 0\n",
      "train: iter 68  trainloss -0.32703  validloss -0.46704±0.00000  bestvalidloss -0.46704  last_update 0\n",
      "train: iter 69  trainloss -0.36840  validloss -0.46363±0.00000  bestvalidloss -0.46704  last_update 1\n",
      "train: iter 70  trainloss -0.42142  validloss -0.53729±0.00000  bestvalidloss -0.53729  last_update 0\n",
      "train: iter 71  trainloss -0.45010  validloss -0.61288±0.00000  bestvalidloss -0.61288  last_update 0\n",
      "train: iter 72  trainloss -0.46954  validloss -0.60698±0.00000  bestvalidloss -0.61288  last_update 1\n",
      "train: iter 73  trainloss -0.49789  validloss -0.66600±0.00000  bestvalidloss -0.66600  last_update 0\n",
      "train: iter 74  trainloss -0.55909  validloss -0.67708±0.00000  bestvalidloss -0.67708  last_update 0\n",
      "train: iter 75  trainloss -0.57836  validloss -0.70001±0.00000  bestvalidloss -0.70001  last_update 0\n",
      "train: iter 76  trainloss -0.60772  validloss -0.76567±0.00000  bestvalidloss -0.76567  last_update 0\n",
      "train: iter 77  trainloss -0.66342  validloss -0.80367±0.00000  bestvalidloss -0.80367  last_update 0\n",
      "train: iter 78  trainloss -0.69309  validloss -0.86534±0.00000  bestvalidloss -0.86534  last_update 0\n",
      "train: iter 79  trainloss -0.71830  validloss -0.88115±0.00000  bestvalidloss -0.88115  last_update 0\n",
      "train: iter 80  trainloss -0.75003  validloss -0.87705±0.00000  bestvalidloss -0.88115  last_update 1\n",
      "train: iter 81  trainloss -0.77647  validloss -0.94825±0.00000  bestvalidloss -0.94825  last_update 0\n",
      "train: iter 82  trainloss -0.80862  validloss -0.95505±0.00000  bestvalidloss -0.95505  last_update 0\n",
      "train: iter 83  trainloss -0.85643  validloss -1.02781±0.00000  bestvalidloss -1.02781  last_update 0\n",
      "train: iter 84  trainloss -0.85167  validloss -1.01249±0.00000  bestvalidloss -1.02781  last_update 1\n",
      "train: iter 85  trainloss -0.90304  validloss -1.08338±0.00000  bestvalidloss -1.08338  last_update 0\n",
      "train: iter 86  trainloss -0.92781  validloss -1.13320±0.00000  bestvalidloss -1.13320  last_update 0\n",
      "train: iter 87  trainloss -0.94395  validloss -1.12129±0.00000  bestvalidloss -1.13320  last_update 1\n",
      "train: iter 88  trainloss -0.97844  validloss -1.13360±0.00000  bestvalidloss -1.13360  last_update 0\n",
      "train: iter 89  trainloss -1.00503  validloss -1.18756±0.00000  bestvalidloss -1.18756  last_update 0\n",
      "train: iter 90  trainloss -1.03782  validloss -1.23203±0.00000  bestvalidloss -1.23203  last_update 0\n",
      "train: iter 91  trainloss -1.04641  validloss -1.20048±0.00000  bestvalidloss -1.23203  last_update 1\n",
      "train: iter 92  trainloss -1.05231  validloss -1.25953±0.00000  bestvalidloss -1.25953  last_update 0\n",
      "train: iter 93  trainloss -1.07557  validloss -1.29675±0.00000  bestvalidloss -1.29675  last_update 0\n",
      "train: iter 94  trainloss -1.08768  validloss -1.33197±0.00000  bestvalidloss -1.33197  last_update 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 95  trainloss -1.08825  validloss -1.32806±0.00000  bestvalidloss -1.33197  last_update 1\n",
      "train: iter 96  trainloss -1.14189  validloss -1.39154±0.00000  bestvalidloss -1.39154  last_update 0\n",
      "train: iter 97  trainloss -1.14887  validloss -1.34206±0.00000  bestvalidloss -1.39154  last_update 1\n",
      "train: iter 98  trainloss -1.16007  validloss -1.36999±0.00000  bestvalidloss -1.39154  last_update 2\n",
      "train: iter 99  trainloss -1.17302  validloss -1.48219±0.00000  bestvalidloss -1.48219  last_update 0\n",
      "train: iter 100  trainloss -1.16684  validloss -1.44080±0.00000  bestvalidloss -1.48219  last_update 1\n",
      "train: iter 101  trainloss -1.18486  validloss -1.40949±0.00000  bestvalidloss -1.48219  last_update 2\n",
      "train: iter 102  trainloss -1.15643  validloss -1.42497±0.00000  bestvalidloss -1.48219  last_update 3\n",
      "train: iter 103  trainloss -1.21348  validloss -1.49715±0.00000  bestvalidloss -1.49715  last_update 0\n",
      "train: iter 104  trainloss -1.19834  validloss -1.49607±0.00000  bestvalidloss -1.49715  last_update 1\n",
      "train: iter 105  trainloss -1.22649  validloss -1.46349±0.00000  bestvalidloss -1.49715  last_update 2\n",
      "train: iter 106  trainloss -1.21307  validloss -1.41257±0.00000  bestvalidloss -1.49715  last_update 3\n",
      "train: iter 107  trainloss -1.22764  validloss -1.44586±0.00000  bestvalidloss -1.49715  last_update 4\n",
      "train: iter 108  trainloss -1.24663  validloss -1.46353±0.00000  bestvalidloss -1.49715  last_update 5\n",
      "train: iter 109  trainloss -1.27289  validloss -1.53735±0.00000  bestvalidloss -1.53735  last_update 0\n",
      "train: iter 110  trainloss -1.27517  validloss -1.54671±0.00000  bestvalidloss -1.54671  last_update 0\n",
      "train: iter 111  trainloss -1.22408  validloss -1.55985±0.00000  bestvalidloss -1.55985  last_update 0\n",
      "train: iter 112  trainloss -1.23395  validloss -1.55091±0.00000  bestvalidloss -1.55985  last_update 1\n",
      "train: iter 113  trainloss -1.15679  validloss -1.42724±0.00000  bestvalidloss -1.55985  last_update 2\n",
      "train: iter 114  trainloss -1.24679  validloss -1.51805±0.00000  bestvalidloss -1.55985  last_update 3\n",
      "train: iter 115  trainloss -1.27091  validloss -1.52501±0.00000  bestvalidloss -1.55985  last_update 4\n",
      "train: iter 116  trainloss -1.25723  validloss -1.53018±0.00000  bestvalidloss -1.55985  last_update 5\n",
      "train: iter 117  trainloss -1.27645  validloss -1.46087±0.00000  bestvalidloss -1.55985  last_update 6\n",
      "train: iter 118  trainloss -1.25795  validloss -1.47709±0.00000  bestvalidloss -1.55985  last_update 7\n",
      "train: iter 119  trainloss -1.30865  validloss -1.54375±0.00000  bestvalidloss -1.55985  last_update 8\n",
      "train: iter 120  trainloss -1.28077  validloss -1.55260±0.00000  bestvalidloss -1.55985  last_update 9\n",
      "train: iter 121  trainloss -1.23769  validloss -1.52754±0.00000  bestvalidloss -1.55985  last_update 10\n",
      "train: iter 122  trainloss -1.27544  validloss -1.53702±0.00000  bestvalidloss -1.55985  last_update 11\n",
      "train: iter 123  trainloss -1.22912  validloss -1.53112±0.00000  bestvalidloss -1.55985  last_update 12\n",
      "train: iter 124  trainloss -1.21775  validloss -1.56483±0.00000  bestvalidloss -1.56483  last_update 0\n",
      "train: iter 125  trainloss -1.23308  validloss -1.53244±0.00000  bestvalidloss -1.56483  last_update 1\n",
      "train: iter 126  trainloss -1.26232  validloss -1.62298±0.00000  bestvalidloss -1.62298  last_update 0\n",
      "train: iter 127  trainloss -1.28574  validloss -1.61259±0.00000  bestvalidloss -1.62298  last_update 1\n",
      "train: iter 128  trainloss -1.30105  validloss -1.62513±0.00000  bestvalidloss -1.62513  last_update 0\n",
      "train: iter 129  trainloss -1.29336  validloss -1.55648±0.00000  bestvalidloss -1.62513  last_update 1\n",
      "train: iter 130  trainloss -1.24144  validloss -1.65934±0.00000  bestvalidloss -1.65934  last_update 0\n",
      "train: iter 131  trainloss -1.26678  validloss -1.53580±0.00000  bestvalidloss -1.65934  last_update 1\n",
      "train: iter 132  trainloss -1.30478  validloss -1.64500±0.00000  bestvalidloss -1.65934  last_update 2\n",
      "train: iter 133  trainloss -1.26580  validloss -1.59510±0.00000  bestvalidloss -1.65934  last_update 3\n",
      "train: iter 134  trainloss -1.29945  validloss -1.56565±0.00000  bestvalidloss -1.65934  last_update 4\n",
      "train: iter 135  trainloss -1.25001  validloss -1.61580±0.00000  bestvalidloss -1.65934  last_update 5\n",
      "train: iter 136  trainloss -1.22565  validloss -1.64768±0.00000  bestvalidloss -1.65934  last_update 6\n",
      "train: iter 137  trainloss -1.25945  validloss -1.48334±0.00000  bestvalidloss -1.65934  last_update 7\n",
      "train: iter 138  trainloss -1.30204  validloss -1.58092±0.00000  bestvalidloss -1.65934  last_update 8\n",
      "train: iter 139  trainloss -1.18539  validloss -1.53073±0.00000  bestvalidloss -1.65934  last_update 9\n",
      "train: iter 140  trainloss -1.26575  validloss -1.54711±0.00000  bestvalidloss -1.65934  last_update 10\n",
      "train: iter 141  trainloss -1.23705  validloss -1.53502±0.00000  bestvalidloss -1.65934  last_update 11\n",
      "train: iter 142  trainloss -1.22535  validloss -1.58583±0.00000  bestvalidloss -1.65934  last_update 12\n",
      "train: iter 143  trainloss -1.25454  validloss -1.54917±0.00000  bestvalidloss -1.65934  last_update 13\n",
      "train: iter 144  trainloss -1.25314  validloss -1.58496±0.00000  bestvalidloss -1.65934  last_update 14\n",
      "train: iter 145  trainloss -1.23668  validloss -1.63237±0.00000  bestvalidloss -1.65934  last_update 15\n",
      "train: iter 146  trainloss -1.21865  validloss -1.58206±0.00000  bestvalidloss -1.65934  last_update 16\n",
      "train: iter 147  trainloss -1.25193  validloss -1.60479±0.00000  bestvalidloss -1.65934  last_update 17\n",
      "train: iter 148  trainloss -1.23342  validloss -1.63552±0.00000  bestvalidloss -1.65934  last_update 18\n",
      "train: iter 149  trainloss -1.25752  validloss -1.50185±0.00000  bestvalidloss -1.65934  last_update 19\n",
      "train: iter 150  trainloss -1.23837  validloss -1.61816±0.00000  bestvalidloss -1.65934  last_update 20\n",
      "train: iter 151  trainloss -1.27028  validloss -1.60339±0.00000  bestvalidloss -1.65934  last_update 21\n",
      "train: iter 152  trainloss -1.25705  validloss -1.58412±0.00000  bestvalidloss -1.65934  last_update 22\n",
      "train: iter 153  trainloss -1.29399  validloss -1.56483±0.00000  bestvalidloss -1.65934  last_update 23\n",
      "train: iter 154  trainloss -1.29953  validloss -1.52534±0.00000  bestvalidloss -1.65934  last_update 24\n",
      "train: iter 155  trainloss -1.31677  validloss -1.52115±0.00000  bestvalidloss -1.65934  last_update 25\n",
      "train: iter 156  trainloss -1.26958  validloss -1.57595±0.00000  bestvalidloss -1.65934  last_update 26\n",
      "train: iter 157  trainloss -1.32006  validloss -1.58514±0.00000  bestvalidloss -1.65934  last_update 27\n",
      "train: iter 158  trainloss -1.25327  validloss -1.56296±0.00000  bestvalidloss -1.65934  last_update 28\n",
      "train: iter 159  trainloss -1.29403  validloss -1.53562±0.00000  bestvalidloss -1.65934  last_update 29\n",
      "train: iter 160  trainloss -1.23153  validloss -1.59894±0.00000  bestvalidloss -1.65934  last_update 30\n",
      "train: iter 161  trainloss -1.25007  validloss -1.65469±0.00000  bestvalidloss -1.65934  last_update 31\n",
      "train: iter 162  trainloss -1.22388  validloss -1.59282±0.00000  bestvalidloss -1.65934  last_update 32\n",
      "train: iter 163  trainloss -1.29115  validloss -1.57313±0.00000  bestvalidloss -1.65934  last_update 33\n",
      "train: iter 164  trainloss -1.23178  validloss -1.70617±0.00000  bestvalidloss -1.70617  last_update 0\n",
      "train: iter 165  trainloss -1.31624  validloss -1.63595±0.00000  bestvalidloss -1.70617  last_update 1\n",
      "train: iter 166  trainloss -1.21686  validloss -1.56399±0.00000  bestvalidloss -1.70617  last_update 2\n",
      "train: iter 167  trainloss -1.24616  validloss -1.59432±0.00000  bestvalidloss -1.70617  last_update 3\n",
      "train: iter 168  trainloss -1.21981  validloss -1.56468±0.00000  bestvalidloss -1.70617  last_update 4\n",
      "train: iter 169  trainloss -1.27642  validloss -1.51352±0.00000  bestvalidloss -1.70617  last_update 5\n",
      "train: iter 170  trainloss -1.28602  validloss -1.64411±0.00000  bestvalidloss -1.70617  last_update 6\n",
      "train: iter 171  trainloss -1.26077  validloss -1.52383±0.00000  bestvalidloss -1.70617  last_update 7\n",
      "train: iter 172  trainloss -1.27503  validloss -1.69369±0.00000  bestvalidloss -1.70617  last_update 8\n",
      "train: iter 173  trainloss -1.22950  validloss -1.53574±0.00000  bestvalidloss -1.70617  last_update 9\n",
      "train: iter 174  trainloss -1.30596  validloss -1.55526±0.00000  bestvalidloss -1.70617  last_update 10\n",
      "train: iter 175  trainloss -1.23203  validloss -1.58594±0.00000  bestvalidloss -1.70617  last_update 11\n",
      "train: iter 176  trainloss -1.23660  validloss -1.58686±0.00000  bestvalidloss -1.70617  last_update 12\n",
      "train: iter 177  trainloss -1.27297  validloss -1.54343±0.00000  bestvalidloss -1.70617  last_update 13\n",
      "train: iter 178  trainloss -1.23819  validloss -1.54382±0.00000  bestvalidloss -1.70617  last_update 14\n",
      "train: iter 179  trainloss -1.24240  validloss -1.57492±0.00000  bestvalidloss -1.70617  last_update 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 180  trainloss -1.27436  validloss -1.60326±0.00000  bestvalidloss -1.70617  last_update 16\n",
      "train: iter 181  trainloss -1.28809  validloss -1.61669±0.00000  bestvalidloss -1.70617  last_update 17\n",
      "train: iter 182  trainloss -1.25721  validloss -1.62204±0.00000  bestvalidloss -1.70617  last_update 18\n",
      "train: iter 183  trainloss -1.24788  validloss -1.65876±0.00000  bestvalidloss -1.70617  last_update 19\n",
      "train: iter 184  trainloss -1.26335  validloss -1.62314±0.00000  bestvalidloss -1.70617  last_update 20\n",
      "train: iter 185  trainloss -1.27120  validloss -1.52070±0.00000  bestvalidloss -1.70617  last_update 21\n",
      "train: iter 186  trainloss -1.27790  validloss -1.53058±0.00000  bestvalidloss -1.70617  last_update 22\n",
      "train: iter 187  trainloss -1.28196  validloss -1.66726±0.00000  bestvalidloss -1.70617  last_update 23\n",
      "train: iter 188  trainloss -1.26811  validloss -1.57524±0.00000  bestvalidloss -1.70617  last_update 24\n",
      "train: iter 189  trainloss -1.25589  validloss -1.49128±0.00000  bestvalidloss -1.70617  last_update 25\n",
      "train: iter 190  trainloss -1.20895  validloss -1.58562±0.00000  bestvalidloss -1.70617  last_update 26\n",
      "train: iter 191  trainloss -1.20239  validloss -1.63786±0.00000  bestvalidloss -1.70617  last_update 27\n",
      "train: iter 192  trainloss -1.30340  validloss -1.53743±0.00000  bestvalidloss -1.70617  last_update 28\n",
      "train: iter 193  trainloss -1.24247  validloss -1.54437±0.00000  bestvalidloss -1.70617  last_update 29\n",
      "train: iter 194  trainloss -1.22068  validloss -1.68370±0.00000  bestvalidloss -1.70617  last_update 30\n",
      "train: iter 195  trainloss -1.25432  validloss -1.64969±0.00000  bestvalidloss -1.70617  last_update 31\n",
      "train: iter 196  trainloss -1.22906  validloss -1.62841±0.00000  bestvalidloss -1.70617  last_update 32\n",
      "train: iter 197  trainloss -1.30052  validloss -1.56441±0.00000  bestvalidloss -1.70617  last_update 33\n",
      "train: iter 198  trainloss -1.27135  validloss -1.57922±0.00000  bestvalidloss -1.70617  last_update 34\n",
      "train: iter 199  trainloss -1.22599  validloss -1.65834±0.00000  bestvalidloss -1.70617  last_update 35\n",
      "train: iter 200  trainloss -1.20814  validloss -1.61692±0.00000  bestvalidloss -1.70617  last_update 36\n",
      "train: iter 201  trainloss -1.22566  validloss -1.54832±0.00000  bestvalidloss -1.70617  last_update 37\n",
      "train: iter 202  trainloss -1.20344  validloss -1.59992±0.00000  bestvalidloss -1.70617  last_update 38\n",
      "train: iter 203  trainloss -1.31737  validloss -1.65553±0.00000  bestvalidloss -1.70617  last_update 39\n",
      "train: iter 204  trainloss -1.31105  validloss -1.65418±0.00000  bestvalidloss -1.70617  last_update 40\n",
      "train: iter 205  trainloss -1.26324  validloss -1.56000±0.00000  bestvalidloss -1.70617  last_update 41\n",
      "train: iter 206  trainloss -1.23287  validloss -1.57325±0.00000  bestvalidloss -1.70617  last_update 42\n",
      "train: iter 207  trainloss -1.25049  validloss -1.60527±0.00000  bestvalidloss -1.70617  last_update 43\n",
      "train: iter 208  trainloss -1.27996  validloss -1.66543±0.00000  bestvalidloss -1.70617  last_update 44\n",
      "train: iter 209  trainloss -1.25825  validloss -1.67138±0.00000  bestvalidloss -1.70617  last_update 45\n",
      "train: iter 210  trainloss -1.23119  validloss -1.61398±0.00000  bestvalidloss -1.70617  last_update 46\n",
      "train: iter 211  trainloss -1.20110  validloss -1.61806±0.00000  bestvalidloss -1.70617  last_update 47\n",
      "train: iter 212  trainloss -1.28705  validloss -1.53903±0.00000  bestvalidloss -1.70617  last_update 48\n",
      "train: iter 213  trainloss -1.28005  validloss -1.45153±0.00000  bestvalidloss -1.70617  last_update 49\n",
      "train: iter 214  trainloss -1.26603  validloss -1.60642±0.00000  bestvalidloss -1.70617  last_update 50\n",
      "train: iter 215  trainloss -1.23705  validloss -1.68237±0.00000  bestvalidloss -1.70617  last_update 51\n",
      "train: iter 216  trainloss -1.27976  validloss -1.58252±0.00000  bestvalidloss -1.70617  last_update 52\n",
      "train: iter 217  trainloss -1.29815  validloss -1.61155±0.00000  bestvalidloss -1.70617  last_update 53\n",
      "train: iter 218  trainloss -1.27284  validloss -1.47044±0.00000  bestvalidloss -1.70617  last_update 54\n",
      "train: iter 219  trainloss -1.28415  validloss -1.63215±0.00000  bestvalidloss -1.70617  last_update 55\n",
      "train: iter 220  trainloss -1.25034  validloss -1.58239±0.00000  bestvalidloss -1.70617  last_update 56\n",
      "train: iter 221  trainloss -1.26701  validloss -1.57136±0.00000  bestvalidloss -1.70617  last_update 57\n",
      "train: iter 222  trainloss -1.30444  validloss -1.47048±0.00000  bestvalidloss -1.70617  last_update 58\n",
      "train: iter 223  trainloss -1.23384  validloss -1.68090±0.00000  bestvalidloss -1.70617  last_update 59\n",
      "train: iter 224  trainloss -1.28467  validloss -1.64574±0.00000  bestvalidloss -1.70617  last_update 60\n",
      "train: iter 225  trainloss -1.30206  validloss -1.61501±0.00000  bestvalidloss -1.70617  last_update 61\n",
      "train: iter 226  trainloss -1.27439  validloss -1.58870±0.00000  bestvalidloss -1.70617  last_update 62\n",
      "train: iter 227  trainloss -1.21993  validloss -1.64345±0.00000  bestvalidloss -1.70617  last_update 63\n",
      "train: iter 228  trainloss -1.27125  validloss -1.52575±0.00000  bestvalidloss -1.70617  last_update 64\n",
      "train: iter 229  trainloss -1.28231  validloss -1.64521±0.00000  bestvalidloss -1.70617  last_update 65\n",
      "train: iter 230  trainloss -1.20517  validloss -1.57054±0.00000  bestvalidloss -1.70617  last_update 66\n",
      "train: iter 231  trainloss -1.23146  validloss -1.61816±0.00000  bestvalidloss -1.70617  last_update 67\n",
      "train: iter 232  trainloss -1.18248  validloss -1.51309±0.00000  bestvalidloss -1.70617  last_update 68\n",
      "train: iter 233  trainloss -1.25614  validloss -1.57867±0.00000  bestvalidloss -1.70617  last_update 69\n",
      "train: iter 234  trainloss -1.28011  validloss -1.60697±0.00000  bestvalidloss -1.70617  last_update 70\n",
      "train: iter 235  trainloss -1.26680  validloss -1.69808±0.00000  bestvalidloss -1.70617  last_update 71\n",
      "train: iter 236  trainloss -1.29325  validloss -1.52188±0.00000  bestvalidloss -1.70617  last_update 72\n",
      "train: iter 237  trainloss -1.25915  validloss -1.50231±0.00000  bestvalidloss -1.70617  last_update 73\n",
      "train: iter 238  trainloss -1.21069  validloss -1.57046±0.00000  bestvalidloss -1.70617  last_update 74\n",
      "train: iter 239  trainloss -1.22833  validloss -1.63482±0.00000  bestvalidloss -1.70617  last_update 75\n",
      "train: iter 240  trainloss -1.29462  validloss -1.67103±0.00000  bestvalidloss -1.70617  last_update 76\n",
      "train: iter 241  trainloss -1.28375  validloss -1.61891±0.00000  bestvalidloss -1.70617  last_update 77\n",
      "train: iter 242  trainloss -1.24093  validloss -1.56932±0.00000  bestvalidloss -1.70617  last_update 78\n",
      "train: iter 243  trainloss -1.18673  validloss -1.48102±0.00000  bestvalidloss -1.70617  last_update 79\n",
      "train: iter 244  trainloss -1.19819  validloss -1.56145±0.00000  bestvalidloss -1.70617  last_update 80\n",
      "train: iter 245  trainloss -1.25478  validloss -1.51448±0.00000  bestvalidloss -1.70617  last_update 81\n",
      "train: iter 246  trainloss -1.24736  validloss -1.62638±0.00000  bestvalidloss -1.70617  last_update 82\n",
      "train: iter 247  trainloss -1.24511  validloss -1.59547±0.00000  bestvalidloss -1.70617  last_update 83\n",
      "train: iter 248  trainloss -1.26037  validloss -1.57201±0.00000  bestvalidloss -1.70617  last_update 84\n",
      "train: iter 249  trainloss -1.23609  validloss -1.49194±0.00000  bestvalidloss -1.70617  last_update 85\n",
      "train: iter 250  trainloss -1.28572  validloss -1.60292±0.00000  bestvalidloss -1.70617  last_update 86\n",
      "train: iter 251  trainloss -1.23063  validloss -1.57017±0.00000  bestvalidloss -1.70617  last_update 87\n",
      "train: iter 252  trainloss -1.25813  validloss -1.63929±0.00000  bestvalidloss -1.70617  last_update 88\n",
      "train: iter 253  trainloss -1.27263  validloss -1.60231±0.00000  bestvalidloss -1.70617  last_update 89\n",
      "train: iter 254  trainloss -1.30516  validloss -1.60202±0.00000  bestvalidloss -1.70617  last_update 90\n",
      "train: iter 255  trainloss -1.27720  validloss -1.61244±0.00000  bestvalidloss -1.70617  last_update 91\n",
      "train: iter 256  trainloss -1.24439  validloss -1.54449±0.00000  bestvalidloss -1.70617  last_update 92\n",
      "train: iter 257  trainloss -1.25474  validloss -1.60183±0.00000  bestvalidloss -1.70617  last_update 93\n",
      "train: iter 258  trainloss -1.22935  validloss -1.63743±0.00000  bestvalidloss -1.70617  last_update 94\n",
      "train: iter 259  trainloss -1.21709  validloss -1.54820±0.00000  bestvalidloss -1.70617  last_update 95\n",
      "train: iter 260  trainloss -1.25227  validloss -1.53868±0.00000  bestvalidloss -1.70617  last_update 96\n",
      "train: iter 261  trainloss -1.25091  validloss -1.68917±0.00000  bestvalidloss -1.70617  last_update 97\n",
      "train: iter 262  trainloss -1.20652  validloss -1.59992±0.00000  bestvalidloss -1.70617  last_update 98\n",
      "train: iter 263  trainloss -1.26955  validloss -1.60324±0.00000  bestvalidloss -1.70617  last_update 99\n",
      "train: iter 264  trainloss -1.33429  validloss -1.67742±0.00000  bestvalidloss -1.70617  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_initial_belief(num_iter=100000, lr=1e-3, early_stop_step=default_early)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117822aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.3397, -2.4293, -2.6460, -5.5429], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(vi.initial_belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90db667c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 0  trainloss 110.14550  validloss 110.28274±0.00000  bestvalidloss 110.28274  last_update 0\n",
      "train: iter 1  trainloss 81.84276  validloss 86.77912±0.00000  bestvalidloss 86.77912  last_update 0\n",
      "train: iter 2  trainloss 59.78473  validloss 60.05809±0.00000  bestvalidloss 60.05809  last_update 0\n",
      "train: iter 3  trainloss 46.75796  validloss 45.09714±0.00000  bestvalidloss 45.09714  last_update 0\n",
      "train: iter 4  trainloss 37.10675  validloss 35.24743±0.00000  bestvalidloss 35.24743  last_update 0\n",
      "train: iter 5  trainloss 29.26794  validloss 27.52791±0.00000  bestvalidloss 27.52791  last_update 0\n",
      "train: iter 6  trainloss 23.19252  validloss 21.67563±0.00000  bestvalidloss 21.67563  last_update 0\n",
      "train: iter 7  trainloss 18.48563  validloss 16.78290±0.00000  bestvalidloss 16.78290  last_update 0\n",
      "train: iter 8  trainloss 14.61096  validloss 13.09779±0.00000  bestvalidloss 13.09779  last_update 0\n",
      "train: iter 9  trainloss 11.47013  validloss 10.33539±0.00000  bestvalidloss 10.33539  last_update 0\n",
      "train: iter 10  trainloss 9.09234  validloss 8.00529±0.00000  bestvalidloss 8.00529  last_update 0\n",
      "train: iter 11  trainloss 7.26061  validloss 6.49374±0.00000  bestvalidloss 6.49374  last_update 0\n",
      "train: iter 12  trainloss 5.79315  validloss 5.22827±0.00000  bestvalidloss 5.22827  last_update 0\n",
      "train: iter 13  trainloss 4.71359  validloss 4.32837±0.00000  bestvalidloss 4.32837  last_update 0\n",
      "train: iter 14  trainloss 3.88342  validloss 3.66388±0.00000  bestvalidloss 3.66388  last_update 0\n",
      "train: iter 15  trainloss 3.27904  validloss 3.41076±0.00000  bestvalidloss 3.41076  last_update 0\n",
      "train: iter 16  trainloss 2.81759  validloss 3.07594±0.00000  bestvalidloss 3.07594  last_update 0\n",
      "train: iter 17  trainloss 2.52889  validloss 2.87877±0.00000  bestvalidloss 2.87877  last_update 0\n",
      "train: iter 18  trainloss 2.28725  validloss 2.84603±0.00000  bestvalidloss 2.84603  last_update 0\n",
      "train: iter 19  trainloss 2.15950  validloss 2.80441±0.00000  bestvalidloss 2.80441  last_update 0\n",
      "train: iter 20  trainloss 2.05695  validloss 2.80446±0.00000  bestvalidloss 2.80441  last_update 1\n",
      "train: iter 21  trainloss 1.98833  validloss 2.89084±0.00000  bestvalidloss 2.80441  last_update 2\n",
      "train: iter 22  trainloss 1.93548  validloss 2.84793±0.00000  bestvalidloss 2.80441  last_update 3\n",
      "train: iter 23  trainloss 1.91650  validloss 3.01372±0.00000  bestvalidloss 2.80441  last_update 4\n",
      "train: iter 24  trainloss 1.90671  validloss 3.01219±0.00000  bestvalidloss 2.80441  last_update 5\n",
      "train: iter 25  trainloss 1.90144  validloss 2.90537±0.00000  bestvalidloss 2.80441  last_update 6\n",
      "train: iter 26  trainloss 1.88578  validloss 2.92772±0.00000  bestvalidloss 2.80441  last_update 7\n",
      "train: iter 27  trainloss 1.89446  validloss 2.93501±0.00000  bestvalidloss 2.80441  last_update 8\n",
      "train: iter 28  trainloss 1.87454  validloss 3.02546±0.00000  bestvalidloss 2.80441  last_update 9\n",
      "train: iter 29  trainloss 1.88244  validloss 3.26453±0.00000  bestvalidloss 2.80441  last_update 10\n",
      "train: iter 30  trainloss 1.88495  validloss 3.00526±0.00000  bestvalidloss 2.80441  last_update 11\n",
      "train: iter 31  trainloss 1.87845  validloss 3.18946±0.00000  bestvalidloss 2.80441  last_update 12\n",
      "train: iter 32  trainloss 1.86634  validloss 3.08195±0.00000  bestvalidloss 2.80441  last_update 13\n",
      "train: iter 33  trainloss 1.86623  validloss 3.13527±0.00000  bestvalidloss 2.80441  last_update 14\n",
      "train: iter 34  trainloss 1.85578  validloss 3.25990±0.00000  bestvalidloss 2.80441  last_update 15\n",
      "train: iter 35  trainloss 1.85535  validloss 3.34221±0.00000  bestvalidloss 2.80441  last_update 16\n",
      "train: iter 36  trainloss 1.85135  validloss 3.22185±0.00000  bestvalidloss 2.80441  last_update 17\n",
      "train: iter 37  trainloss 1.82313  validloss 3.11838±0.00000  bestvalidloss 2.80441  last_update 18\n",
      "train: iter 38  trainloss 1.80455  validloss 3.28576±0.00000  bestvalidloss 2.80441  last_update 19\n",
      "train: iter 39  trainloss 1.77430  validloss 3.06273±0.00000  bestvalidloss 2.80441  last_update 20\n",
      "train: iter 40  trainloss 1.76661  validloss 2.99910±0.00000  bestvalidloss 2.80441  last_update 21\n",
      "train: iter 41  trainloss 1.74178  validloss 3.21699±0.00000  bestvalidloss 2.80441  last_update 22\n",
      "train: iter 42  trainloss 1.72929  validloss 3.06031±0.00000  bestvalidloss 2.80441  last_update 23\n",
      "train: iter 43  trainloss 1.71285  validloss 2.96439±0.00000  bestvalidloss 2.80441  last_update 24\n",
      "train: iter 44  trainloss 1.68935  validloss 2.90593±0.00000  bestvalidloss 2.80441  last_update 25\n",
      "train: iter 45  trainloss 1.67758  validloss 2.82363±0.00000  bestvalidloss 2.80441  last_update 26\n",
      "train: iter 46  trainloss 1.65984  validloss 3.10549±0.00000  bestvalidloss 2.80441  last_update 27\n",
      "train: iter 47  trainloss 1.65320  validloss 2.91439±0.00000  bestvalidloss 2.80441  last_update 28\n",
      "train: iter 48  trainloss 1.62671  validloss 2.72880±0.00000  bestvalidloss 2.72880  last_update 0\n",
      "train: iter 49  trainloss 1.61043  validloss 3.00126±0.00000  bestvalidloss 2.72880  last_update 1\n",
      "train: iter 50  trainloss 1.61883  validloss 2.88891±0.00000  bestvalidloss 2.72880  last_update 2\n",
      "train: iter 51  trainloss 1.59644  validloss 3.03832±0.00000  bestvalidloss 2.72880  last_update 3\n",
      "train: iter 52  trainloss 1.51506  validloss 2.76925±0.00000  bestvalidloss 2.72880  last_update 4\n",
      "train: iter 53  trainloss 1.44137  validloss 2.61574±0.00000  bestvalidloss 2.61574  last_update 0\n",
      "train: iter 54  trainloss 1.38259  validloss 2.85080±0.00000  bestvalidloss 2.61574  last_update 1\n",
      "train: iter 55  trainloss 1.30992  validloss 2.56107±0.00000  bestvalidloss 2.56107  last_update 0\n",
      "train: iter 56  trainloss 1.26486  validloss 2.77140±0.00000  bestvalidloss 2.56107  last_update 1\n",
      "train: iter 57  trainloss 1.23077  validloss 2.56321±0.00000  bestvalidloss 2.56107  last_update 2\n",
      "train: iter 58  trainloss 1.22170  validloss 2.97497±0.00000  bestvalidloss 2.56107  last_update 3\n",
      "train: iter 59  trainloss 1.17738  validloss 2.72853±0.00000  bestvalidloss 2.56107  last_update 4\n",
      "train: iter 60  trainloss 1.18327  validloss 2.74056±0.00000  bestvalidloss 2.56107  last_update 5\n",
      "train: iter 61  trainloss 1.20152  validloss 2.62023±0.00000  bestvalidloss 2.56107  last_update 6\n",
      "train: iter 62  trainloss 1.14543  validloss 2.71163±0.00000  bestvalidloss 2.56107  last_update 7\n",
      "train: iter 63  trainloss 1.18478  validloss 2.53432±0.00000  bestvalidloss 2.53432  last_update 0\n",
      "train: iter 64  trainloss 1.15794  validloss 2.67262±0.00000  bestvalidloss 2.53432  last_update 1\n",
      "train: iter 65  trainloss 1.12781  validloss 2.59200±0.00000  bestvalidloss 2.53432  last_update 2\n",
      "train: iter 66  trainloss 1.12452  validloss 2.56484±0.00000  bestvalidloss 2.53432  last_update 3\n",
      "train: iter 67  trainloss 1.14396  validloss 2.95123±0.00000  bestvalidloss 2.53432  last_update 4\n",
      "train: iter 68  trainloss 1.12066  validloss 2.50750±0.00000  bestvalidloss 2.50750  last_update 0\n",
      "train: iter 69  trainloss 1.11567  validloss 2.41434±0.00000  bestvalidloss 2.41434  last_update 0\n",
      "train: iter 70  trainloss 1.10513  validloss 2.86279±0.00000  bestvalidloss 2.41434  last_update 1\n",
      "train: iter 71  trainloss 1.07330  validloss 2.45417±0.00000  bestvalidloss 2.41434  last_update 2\n",
      "train: iter 72  trainloss 1.10217  validloss 2.63014±0.00000  bestvalidloss 2.41434  last_update 3\n",
      "train: iter 73  trainloss 1.10923  validloss 2.35452±0.00000  bestvalidloss 2.35452  last_update 0\n",
      "train: iter 74  trainloss 1.08333  validloss 2.51013±0.00000  bestvalidloss 2.35452  last_update 1\n",
      "train: iter 75  trainloss 1.08829  validloss 2.59672±0.00000  bestvalidloss 2.35452  last_update 2\n",
      "train: iter 76  trainloss 1.06685  validloss 2.70380±0.00000  bestvalidloss 2.35452  last_update 3\n",
      "train: iter 77  trainloss 1.09499  validloss 2.61288±0.00000  bestvalidloss 2.35452  last_update 4\n",
      "train: iter 78  trainloss 1.09457  validloss 2.66370±0.00000  bestvalidloss 2.35452  last_update 5\n",
      "train: iter 79  trainloss 1.05017  validloss 2.63475±0.00000  bestvalidloss 2.35452  last_update 6\n",
      "train: iter 80  trainloss 1.08386  validloss 2.48519±0.00000  bestvalidloss 2.35452  last_update 7\n",
      "train: iter 81  trainloss 1.08598  validloss 2.46316±0.00000  bestvalidloss 2.35452  last_update 8\n",
      "train: iter 82  trainloss 1.08424  validloss 2.66738±0.00000  bestvalidloss 2.35452  last_update 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 83  trainloss 1.09652  validloss 2.61431±0.00000  bestvalidloss 2.35452  last_update 10\n",
      "train: iter 84  trainloss 1.06646  validloss 2.44215±0.00000  bestvalidloss 2.35452  last_update 11\n",
      "train: iter 85  trainloss 1.07447  validloss 2.44255±0.00000  bestvalidloss 2.35452  last_update 12\n",
      "train: iter 86  trainloss 1.05979  validloss 2.57544±0.00000  bestvalidloss 2.35452  last_update 13\n",
      "train: iter 87  trainloss 1.08437  validloss 2.55892±0.00000  bestvalidloss 2.35452  last_update 14\n",
      "train: iter 88  trainloss 1.07194  validloss 2.46484±0.00000  bestvalidloss 2.35452  last_update 15\n",
      "train: iter 89  trainloss 1.07946  validloss 2.64614±0.00000  bestvalidloss 2.35452  last_update 16\n",
      "train: iter 90  trainloss 1.07450  validloss 2.58346±0.00000  bestvalidloss 2.35452  last_update 17\n",
      "train: iter 91  trainloss 1.06193  validloss 2.58589±0.00000  bestvalidloss 2.35452  last_update 18\n",
      "train: iter 92  trainloss 1.07786  validloss 2.60647±0.00000  bestvalidloss 2.35452  last_update 19\n",
      "train: iter 93  trainloss 1.04207  validloss 2.67285±0.00000  bestvalidloss 2.35452  last_update 20\n",
      "train: iter 94  trainloss 1.07337  validloss 2.49103±0.00000  bestvalidloss 2.35452  last_update 21\n",
      "train: iter 95  trainloss 1.07653  validloss 2.60235±0.00000  bestvalidloss 2.35452  last_update 22\n",
      "train: iter 96  trainloss 1.05558  validloss 2.58509±0.00000  bestvalidloss 2.35452  last_update 23\n",
      "train: iter 97  trainloss 1.06206  validloss 2.78584±0.00000  bestvalidloss 2.35452  last_update 24\n",
      "train: iter 98  trainloss 1.08357  validloss 2.44551±0.00000  bestvalidloss 2.35452  last_update 25\n",
      "train: iter 99  trainloss 1.06356  validloss 2.65956±0.00000  bestvalidloss 2.35452  last_update 26\n",
      "train: iter 100  trainloss 1.04695  validloss 2.64657±0.00000  bestvalidloss 2.35452  last_update 27\n",
      "train: iter 101  trainloss 1.05822  validloss 2.63283±0.00000  bestvalidloss 2.35452  last_update 28\n",
      "train: iter 102  trainloss 1.07053  validloss 2.51463±0.00000  bestvalidloss 2.35452  last_update 29\n",
      "train: iter 103  trainloss 1.07014  validloss 2.41099±0.00000  bestvalidloss 2.35452  last_update 30\n",
      "train: iter 104  trainloss 1.05024  validloss 2.42366±0.00000  bestvalidloss 2.35452  last_update 31\n",
      "train: iter 105  trainloss 1.06516  validloss 2.72559±0.00000  bestvalidloss 2.35452  last_update 32\n",
      "train: iter 106  trainloss 1.08466  validloss 2.54113±0.00000  bestvalidloss 2.35452  last_update 33\n",
      "train: iter 107  trainloss 1.07144  validloss 2.50832±0.00000  bestvalidloss 2.35452  last_update 34\n",
      "train: iter 108  trainloss 1.04636  validloss 2.65201±0.00000  bestvalidloss 2.35452  last_update 35\n",
      "train: iter 109  trainloss 1.03006  validloss 2.50597±0.00000  bestvalidloss 2.35452  last_update 36\n",
      "train: iter 110  trainloss 1.04638  validloss 2.60794±0.00000  bestvalidloss 2.35452  last_update 37\n",
      "train: iter 111  trainloss 1.06987  validloss 2.43155±0.00000  bestvalidloss 2.35452  last_update 38\n",
      "train: iter 112  trainloss 1.04452  validloss 2.60754±0.00000  bestvalidloss 2.35452  last_update 39\n",
      "train: iter 113  trainloss 1.06063  validloss 2.59770±0.00000  bestvalidloss 2.35452  last_update 40\n",
      "train: iter 114  trainloss 1.04318  validloss 2.58262±0.00000  bestvalidloss 2.35452  last_update 41\n",
      "train: iter 115  trainloss 1.06144  validloss 2.59794±0.00000  bestvalidloss 2.35452  last_update 42\n",
      "train: iter 116  trainloss 1.05643  validloss 2.58247±0.00000  bestvalidloss 2.35452  last_update 43\n",
      "train: iter 117  trainloss 1.06057  validloss 2.45622±0.00000  bestvalidloss 2.35452  last_update 44\n",
      "train: iter 118  trainloss 1.06673  validloss 2.50418±0.00000  bestvalidloss 2.35452  last_update 45\n",
      "train: iter 119  trainloss 1.05516  validloss 2.59713±0.00000  bestvalidloss 2.35452  last_update 46\n",
      "train: iter 120  trainloss 1.06206  validloss 2.68349±0.00000  bestvalidloss 2.35452  last_update 47\n",
      "train: iter 121  trainloss 1.05913  validloss 2.71774±0.00000  bestvalidloss 2.35452  last_update 48\n",
      "train: iter 122  trainloss 1.04983  validloss 2.99771±0.00000  bestvalidloss 2.35452  last_update 49\n",
      "train: iter 123  trainloss 1.03863  validloss 2.59019±0.00000  bestvalidloss 2.35452  last_update 50\n",
      "train: iter 124  trainloss 1.03719  validloss 2.74075±0.00000  bestvalidloss 2.35452  last_update 51\n",
      "train: iter 125  trainloss 1.05346  validloss 2.77429±0.00000  bestvalidloss 2.35452  last_update 52\n",
      "train: iter 126  trainloss 1.06126  validloss 2.56095±0.00000  bestvalidloss 2.35452  last_update 53\n",
      "train: iter 127  trainloss 1.04972  validloss 2.56165±0.00000  bestvalidloss 2.35452  last_update 54\n",
      "train: iter 128  trainloss 1.05077  validloss 2.51254±0.00000  bestvalidloss 2.35452  last_update 55\n",
      "train: iter 129  trainloss 1.04235  validloss 2.38585±0.00000  bestvalidloss 2.35452  last_update 56\n",
      "train: iter 130  trainloss 1.04005  validloss 2.66142±0.00000  bestvalidloss 2.35452  last_update 57\n",
      "train: iter 131  trainloss 1.03971  validloss 2.62892±0.00000  bestvalidloss 2.35452  last_update 58\n",
      "train: iter 132  trainloss 1.04963  validloss 2.64641±0.00000  bestvalidloss 2.35452  last_update 59\n",
      "train: iter 133  trainloss 1.03745  validloss 2.76834±0.00000  bestvalidloss 2.35452  last_update 60\n",
      "train: iter 134  trainloss 1.03953  validloss 2.49641±0.00000  bestvalidloss 2.35452  last_update 61\n",
      "train: iter 135  trainloss 1.05132  validloss 2.56734±0.00000  bestvalidloss 2.35452  last_update 62\n",
      "train: iter 136  trainloss 1.04490  validloss 2.59942±0.00000  bestvalidloss 2.35452  last_update 63\n",
      "train: iter 137  trainloss 1.07100  validloss 2.27473±0.00000  bestvalidloss 2.27473  last_update 0\n",
      "train: iter 138  trainloss 1.04685  validloss 2.68048±0.00000  bestvalidloss 2.27473  last_update 1\n",
      "train: iter 139  trainloss 1.04115  validloss 2.43014±0.00000  bestvalidloss 2.27473  last_update 2\n",
      "train: iter 140  trainloss 1.07423  validloss 2.52174±0.00000  bestvalidloss 2.27473  last_update 3\n",
      "train: iter 141  trainloss 1.03393  validloss 2.53921±0.00000  bestvalidloss 2.27473  last_update 4\n",
      "train: iter 142  trainloss 1.03916  validloss 2.60209±0.00000  bestvalidloss 2.27473  last_update 5\n",
      "train: iter 143  trainloss 1.04502  validloss 2.69381±0.00000  bestvalidloss 2.27473  last_update 6\n",
      "train: iter 144  trainloss 1.03429  validloss 2.89330±0.00000  bestvalidloss 2.27473  last_update 7\n",
      "train: iter 145  trainloss 1.02976  validloss 2.63468±0.00000  bestvalidloss 2.27473  last_update 8\n",
      "train: iter 146  trainloss 1.04267  validloss 2.65605±0.00000  bestvalidloss 2.27473  last_update 9\n",
      "train: iter 147  trainloss 1.02905  validloss 2.71837±0.00000  bestvalidloss 2.27473  last_update 10\n",
      "train: iter 148  trainloss 1.03596  validloss 2.30997±0.00000  bestvalidloss 2.27473  last_update 11\n",
      "train: iter 149  trainloss 1.03783  validloss 2.73613±0.00000  bestvalidloss 2.27473  last_update 12\n",
      "train: iter 150  trainloss 1.03648  validloss 2.64311±0.00000  bestvalidloss 2.27473  last_update 13\n",
      "train: iter 151  trainloss 1.04914  validloss 2.36113±0.00000  bestvalidloss 2.27473  last_update 14\n",
      "train: iter 152  trainloss 1.03322  validloss 2.70093±0.00000  bestvalidloss 2.27473  last_update 15\n",
      "train: iter 153  trainloss 1.04632  validloss 2.60473±0.00000  bestvalidloss 2.27473  last_update 16\n",
      "train: iter 154  trainloss 1.03132  validloss 2.57194±0.00000  bestvalidloss 2.27473  last_update 17\n",
      "train: iter 155  trainloss 1.04373  validloss 2.52867±0.00000  bestvalidloss 2.27473  last_update 18\n",
      "train: iter 156  trainloss 1.04328  validloss 2.52375±0.00000  bestvalidloss 2.27473  last_update 19\n",
      "train: iter 157  trainloss 1.02893  validloss 2.53596±0.00000  bestvalidloss 2.27473  last_update 20\n",
      "train: iter 158  trainloss 1.04067  validloss 2.68128±0.00000  bestvalidloss 2.27473  last_update 21\n",
      "train: iter 159  trainloss 1.03326  validloss 2.54536±0.00000  bestvalidloss 2.27473  last_update 22\n",
      "train: iter 160  trainloss 1.05836  validloss 2.64244±0.00000  bestvalidloss 2.27473  last_update 23\n",
      "train: iter 161  trainloss 1.02658  validloss 2.64104±0.00000  bestvalidloss 2.27473  last_update 24\n",
      "train: iter 162  trainloss 1.04152  validloss 2.51694±0.00000  bestvalidloss 2.27473  last_update 25\n",
      "train: iter 163  trainloss 1.00614  validloss 2.51864±0.00000  bestvalidloss 2.27473  last_update 26\n",
      "train: iter 164  trainloss 1.01756  validloss 2.72544±0.00000  bestvalidloss 2.27473  last_update 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: iter 165  trainloss 1.04079  validloss 2.51094±0.00000  bestvalidloss 2.27473  last_update 28\n",
      "train: iter 166  trainloss 1.04031  validloss 2.68847±0.00000  bestvalidloss 2.27473  last_update 29\n",
      "train: iter 167  trainloss 1.03055  validloss 2.59348±0.00000  bestvalidloss 2.27473  last_update 30\n",
      "train: iter 168  trainloss 1.03368  validloss 2.50337±0.00000  bestvalidloss 2.27473  last_update 31\n",
      "train: iter 169  trainloss 1.04427  validloss 2.72649±0.00000  bestvalidloss 2.27473  last_update 32\n",
      "train: iter 170  trainloss 1.03442  validloss 2.79438±0.00000  bestvalidloss 2.27473  last_update 33\n",
      "train: iter 171  trainloss 1.02556  validloss 2.53903±0.00000  bestvalidloss 2.27473  last_update 34\n",
      "train: iter 172  trainloss 1.03130  validloss 2.50764±0.00000  bestvalidloss 2.27473  last_update 35\n",
      "train: iter 173  trainloss 1.00893  validloss 2.76040±0.00000  bestvalidloss 2.27473  last_update 36\n",
      "train: iter 174  trainloss 1.02356  validloss 2.53887±0.00000  bestvalidloss 2.27473  last_update 37\n",
      "train: iter 175  trainloss 1.04619  validloss 2.70608±0.00000  bestvalidloss 2.27473  last_update 38\n",
      "train: iter 176  trainloss 1.05907  validloss 2.72407±0.00000  bestvalidloss 2.27473  last_update 39\n",
      "train: iter 177  trainloss 1.02017  validloss 2.51832±0.00000  bestvalidloss 2.27473  last_update 40\n",
      "train: iter 178  trainloss 1.02919  validloss 2.61686±0.00000  bestvalidloss 2.27473  last_update 41\n",
      "train: iter 179  trainloss 0.99594  validloss 2.49865±0.00000  bestvalidloss 2.27473  last_update 42\n",
      "train: iter 180  trainloss 1.02444  validloss 2.85313±0.00000  bestvalidloss 2.27473  last_update 43\n",
      "train: iter 181  trainloss 1.03379  validloss 2.58787±0.00000  bestvalidloss 2.27473  last_update 44\n",
      "train: iter 182  trainloss 1.04198  validloss 2.56179±0.00000  bestvalidloss 2.27473  last_update 45\n",
      "train: iter 183  trainloss 1.01930  validloss 2.44182±0.00000  bestvalidloss 2.27473  last_update 46\n",
      "train: iter 184  trainloss 1.03045  validloss 2.54277±0.00000  bestvalidloss 2.27473  last_update 47\n",
      "train: iter 185  trainloss 1.03651  validloss 2.79219±0.00000  bestvalidloss 2.27473  last_update 48\n",
      "train: iter 186  trainloss 1.02596  validloss 2.54084±0.00000  bestvalidloss 2.27473  last_update 49\n",
      "train: iter 187  trainloss 1.02465  validloss 2.53860±0.00000  bestvalidloss 2.27473  last_update 50\n",
      "train: iter 188  trainloss 1.03450  validloss 2.79975±0.00000  bestvalidloss 2.27473  last_update 51\n",
      "train: iter 189  trainloss 1.04242  validloss 2.51334±0.00000  bestvalidloss 2.27473  last_update 52\n",
      "train: iter 190  trainloss 1.02869  validloss 2.70984±0.00000  bestvalidloss 2.27473  last_update 53\n",
      "train: iter 191  trainloss 1.03988  validloss 2.55623±0.00000  bestvalidloss 2.27473  last_update 54\n",
      "train: iter 192  trainloss 1.02137  validloss 2.41087±0.00000  bestvalidloss 2.27473  last_update 55\n",
      "train: iter 193  trainloss 1.03134  validloss 2.72685±0.00000  bestvalidloss 2.27473  last_update 56\n",
      "train: iter 194  trainloss 1.01804  validloss 2.71810±0.00000  bestvalidloss 2.27473  last_update 57\n",
      "train: iter 195  trainloss 1.02441  validloss 2.66308±0.00000  bestvalidloss 2.27473  last_update 58\n",
      "train: iter 196  trainloss 1.04111  validloss 2.43644±0.00000  bestvalidloss 2.27473  last_update 59\n",
      "train: iter 197  trainloss 1.02340  validloss 2.51002±0.00000  bestvalidloss 2.27473  last_update 60\n",
      "train: iter 198  trainloss 1.01927  validloss 2.48634±0.00000  bestvalidloss 2.27473  last_update 61\n",
      "train: iter 199  trainloss 1.02359  validloss 2.73723±0.00000  bestvalidloss 2.27473  last_update 62\n",
      "train: iter 200  trainloss 1.02447  validloss 2.72870±0.00000  bestvalidloss 2.27473  last_update 63\n",
      "train: iter 201  trainloss 1.02912  validloss 2.67879±0.00000  bestvalidloss 2.27473  last_update 64\n",
      "train: iter 202  trainloss 1.02680  validloss 2.57916±0.00000  bestvalidloss 2.27473  last_update 65\n",
      "train: iter 203  trainloss 1.03253  validloss 2.57586±0.00000  bestvalidloss 2.27473  last_update 66\n",
      "train: iter 204  trainloss 1.04326  validloss 2.69611±0.00000  bestvalidloss 2.27473  last_update 67\n",
      "train: iter 205  trainloss 1.02047  validloss 2.53586±0.00000  bestvalidloss 2.27473  last_update 68\n",
      "train: iter 206  trainloss 1.02207  validloss 2.78129±0.00000  bestvalidloss 2.27473  last_update 69\n",
      "train: iter 207  trainloss 1.04461  validloss 2.51754±0.00000  bestvalidloss 2.27473  last_update 70\n",
      "train: iter 208  trainloss 1.02799  validloss 2.58655±0.00000  bestvalidloss 2.27473  last_update 71\n",
      "train: iter 209  trainloss 1.01982  validloss 2.91524±0.00000  bestvalidloss 2.27473  last_update 72\n",
      "train: iter 210  trainloss 1.01893  validloss 2.62742±0.00000  bestvalidloss 2.27473  last_update 73\n",
      "train: iter 211  trainloss 1.02405  validloss 2.58334±0.00000  bestvalidloss 2.27473  last_update 74\n",
      "train: iter 212  trainloss 1.03671  validloss 2.82011±0.00000  bestvalidloss 2.27473  last_update 75\n",
      "train: iter 213  trainloss 1.02773  validloss 2.63376±0.00000  bestvalidloss 2.27473  last_update 76\n",
      "train: iter 214  trainloss 1.00690  validloss 2.67369±0.00000  bestvalidloss 2.27473  last_update 77\n",
      "train: iter 215  trainloss 1.01260  validloss 2.63960±0.00000  bestvalidloss 2.27473  last_update 78\n",
      "train: iter 216  trainloss 1.01260  validloss 2.70612±0.00000  bestvalidloss 2.27473  last_update 79\n",
      "train: iter 217  trainloss 1.01204  validloss 2.55056±0.00000  bestvalidloss 2.27473  last_update 80\n",
      "train: iter 218  trainloss 1.01059  validloss 2.75755±0.00000  bestvalidloss 2.27473  last_update 81\n",
      "train: iter 219  trainloss 1.01613  validloss 2.50981±0.00000  bestvalidloss 2.27473  last_update 82\n",
      "train: iter 220  trainloss 1.02078  validloss 2.56306±0.00000  bestvalidloss 2.27473  last_update 83\n",
      "train: iter 221  trainloss 1.00949  validloss 2.54991±0.00000  bestvalidloss 2.27473  last_update 84\n",
      "train: iter 222  trainloss 1.02338  validloss 2.64176±0.00000  bestvalidloss 2.27473  last_update 85\n",
      "train: iter 223  trainloss 1.01690  validloss 2.60787±0.00000  bestvalidloss 2.27473  last_update 86\n",
      "train: iter 224  trainloss 1.02746  validloss 2.89817±0.00000  bestvalidloss 2.27473  last_update 87\n",
      "train: iter 225  trainloss 1.00103  validloss 2.54659±0.00000  bestvalidloss 2.27473  last_update 88\n",
      "train: iter 226  trainloss 1.00895  validloss 2.56967±0.00000  bestvalidloss 2.27473  last_update 89\n",
      "train: iter 227  trainloss 1.03530  validloss 2.68734±0.00000  bestvalidloss 2.27473  last_update 90\n",
      "train: iter 228  trainloss 1.01116  validloss 2.90429±0.00000  bestvalidloss 2.27473  last_update 91\n",
      "train: iter 229  trainloss 0.99515  validloss 2.49835±0.00000  bestvalidloss 2.27473  last_update 92\n",
      "train: iter 230  trainloss 1.02829  validloss 2.51895±0.00000  bestvalidloss 2.27473  last_update 93\n",
      "train: iter 231  trainloss 1.01394  validloss 2.55216±0.00000  bestvalidloss 2.27473  last_update 94\n",
      "train: iter 232  trainloss 0.98729  validloss 2.53665±0.00000  bestvalidloss 2.27473  last_update 95\n",
      "train: iter 233  trainloss 0.99940  validloss 2.50076±0.00000  bestvalidloss 2.27473  last_update 96\n",
      "train: iter 234  trainloss 1.03766  validloss 2.53963±0.00000  bestvalidloss 2.27473  last_update 97\n",
      "train: iter 235  trainloss 1.01383  validloss 2.54717±0.00000  bestvalidloss 2.27473  last_update 98\n",
      "train: iter 236  trainloss 1.02199  validloss 2.41721±0.00000  bestvalidloss 2.27473  last_update 99\n",
      "train: iter 237  trainloss 1.01304  validloss 2.72720±0.00000  bestvalidloss 2.27473  last_update 100\n",
      "train: fin\n"
     ]
    }
   ],
   "source": [
    "train_curve, valid_curve = vi.train_penalty(num_iter=num_iter_max, lr=default_lr, early_stop_step=default_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ae20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78af8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base save ckpt ckpt_basevi_cartpole_unweighted\n",
      "base load self.initial_belief.data.sum() tensor(-10.9579)\n",
      "base load dec.state_dict()['net_phat.0.weight'].sum() tensor(6.7339)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vi.save(ckpt_key=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1af86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672208e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c8f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2757576564829165\n",
      "tensor([1.3300])\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility check\n",
    "print(np.random.randn())\n",
    "print(torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6ba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce713d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727f804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c69747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85609792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde31bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110262f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
